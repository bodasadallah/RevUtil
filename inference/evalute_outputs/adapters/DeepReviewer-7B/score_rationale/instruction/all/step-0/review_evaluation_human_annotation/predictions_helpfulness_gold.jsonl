{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" choice of operators, specifically the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min instead. It implies that the authors should consider the union and intersection concepts from the or operator and elementwise min, respectively, and provide a reason for their choice. However, the comment does not explicitly instruct the authors to consider these alternatives or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the suggested operators and provide a rationale. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 261 and 272, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the authors\" choice of operators, suggesting that they might have considered the or operator or elementwise min instead, and provides a rationale for why the chosen operators might be better. This level of detail helps the authors understand the specific issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" choice of operators, specifically the and operator or elementwise max, and suggests that they might have considered the or operator or elementwise min instead. It implies that the chosen operators might be better options due to their correspondence with the union and intersection concepts from the or operator and elementwise min. However, the comment does not provide any specific reasoning, examples, or references to support why the chosen operators are better or why the alternatives were not considered. This lack of detailed justification makes the claim 3, as the authors are left to infer the reasoning behind the question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the choice of operators in the paper, specifically questioning why the authors did not consider the and operator or elementwise max. It suggests that the or operator or elementwise min might have been more appropriate and provides a rationale for this consideration. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer that they should consider the suggested operators and provide a rationale for their choice, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors may have selected sentences from raw data sources, which contradicts the claim that the data already contains syntactic information. It implies that the data selected is a subset of Li et al. (2019a)\u2019s dataset. The comment provides an implicit action by suggesting that the authors revise the description to clarify and make it precise. However, it does not explicitly instruct the authors on how to revise the description or what specific changes should be made. The action is somewhat vague, as the authors need to infer the exact changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (226238 and 242244), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the discrepancy in the description of the data selection process and the suggestion to revise the description to mention Li et al. (2019a) earlier. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors may have selected sentences from raw data sources, which contradicts the claim that the data already contains syntactic information. It suggests that the data selected is a subset of Li et al. (2019a)\u2019s dataset and recommends revising the description to clarify this. The comment provides a logical reasoning by pointing out the inconsistency in the description of the data selection process. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the description of the data selection process, specifically regarding whether the authors selected sentences from raw data or if the data already contained syntactic information. It suggests that the data selected is a subset of Li et al. (2019a)\u2019s dataset and recommends revising the description to clarify this. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it included additional guidance on how to revise the description or what specific changes should be made. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. The comment is explicit in pointing out the missing antecedent and provides concrete guidance on how to address the issue by checking the references for specific formatting details. This allows the authors to directly apply the feedback and improve the formatting of their references. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section of the paper where the issue is located, specifically \"both tasks\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be done, such as checking the references for format, capitalization, and bibliographic details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. While the comment provides a clear instruction for improvement, it lacks specific examples or references to support the claim that the references are missing or need correction. This makes the claim 3, as the authors can infer the need for correction but may require additional guidance to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the formatting of their references. By addressing this issue, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it provided additional guidance on how to check the references or examples of correct formatting. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the baseline models used in the paper. First, it points out that the authors do not compare their model to Campos et al. (2020), which also uses feedback in QA tasks. This suggests that the authors should include this comparison to provide a more comprehensive evaluation of their model\"s performance. Second, the comment notes that the authors do not compare their model to other domain adaptation methods, such as those mentioned in Section 8. This implies that the authors should include these comparisons to better contextualize their work. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to implement these suggestions, such as which specific methods to compare or how to conduct the comparisons. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses the baseline models used in the paper, specifically mentioning the absence of comparison to Campos et al. (2020) and other domain adaptation methods cited in Section 8. This provides clear grounding as the authors can accurately identify the sections where these comparisons should be made. The comment is also specific, as it details the exact issues with the baseline models and suggests specific comparisons that should be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the adopted baseline models are weak and suggests that the authors should compare their model to Campos et al. (2020) and other domain adaptation methods. The comment provides specific examples of missing comparisons, such as the work cited in Section 8. However, it lacks detailed reasoning or references to support why these comparisons are necessary or how they would strengthen the paper. The claim is 3 as it provides some justification but lacks depth and specific examples to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the baseline models used are weak. It specifically mentions the absence of comparison to Campos et al. (2020), which also uses feedback in QA tasks, and notes the lack of comparison with other domain adaptation methods cited in Section 8. This feedback is valuable as it directs the authors to include additional comparisons to provide a more comprehensive evaluation of their model\"s performance. However, the comment could be more helpful by suggesting specific methods or providing guidance on how to conduct these comparisons. Overall, the comment is 4 as it highlights important areas for improvement and encourages the authors to enhance their evaluation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider adding information about the use of word embeddings in the BiLSTMCRF model, similar to Lample et al. It also questions whether the KNs in Figure 3 are in the source language or in English, given that mentions have been translated to English. The comment implies that this clarification is necessary for the authors to improve their draft. However, the action is implicit, as the authors need to infer that they should add this information and clarify the figure. The comment is 3 because it provides a clear direction for improvement, but it lacks explicit instructions on how to implement these suggestions. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, such as adding information about word embeddings and clarifying the KNs in Figure 3. This provides clear guidance on what changes are required, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should consider adding information about the use of word embeddings in the BiLSTMCRF model, similar to Lample et al., and that the KNs in Figure 3 should be clarified regarding their language (source or English). However, the comment does not provide any specific reasoning or evidence to support these claims. It lacks detailed explanations or references to justify why these additions are necessary or beneficial. As a result, the claim is 1, as it lacks sufficient support for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement, such as adding information about the use of word embeddings in the BiLSTMCRF model, similar to Lample et al., and clarifying the KNs in Figure 3. It also mentions that the authors will correct the figure in their response, indicating a clear path for improvement. However, the comment could be more helpful if it provided additional guidance on how to implement these suggestions or if it addressed other potential weaknesses in the paper. Overall, the feedback is 4 as it offers actionable and constructive advice, but it could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific issues regarding the presentation of the model. It asks for clarification on the pooling method used for embedding features, referencing line 397, and questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC. The comment also suggests that the lefthand side of the equation might be a conditional probability. While the comment identifies two areas for clarification, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors need to infer that they should clarify the pooling method and the definition of E_i in Equation (7). Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (397 and 472) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed: the pooling method used for embedding features and the clarity of Equation (7), including the definition of E_i and the nature of the lefthand side of the equation. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two specific questions about the presentation of the model, focusing on the pooling method used for embedding features and the clarity of Equation (7). The first question asks for clarification on the pooling method referenced in line 397, which is a factual request for information. The second question questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC and suggests that the lefthand side of the equation might be a conditional probability. While the comment does not provide explicit reasoning or references to support the need for clarification, it is 3 as it points out areas where the authors need to improve the clarity of their presentation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the presentation of the model could be improved. It asks for clarification on the pooling method used for embedding features, referencing line 397, and questions the clarity of Equation (7) in line 472, specifically regarding whether E_i represents the type or identity of an AC. The comment also suggests that the lefthand side of the equation might be a conditional probability. This feedback is clear and actionable, as it provides specific areas for the authors to address and improve their draft. By highlighting these issues, the comment guides the authors to enhance the clarity and precision of their presentation, making it 4. However, it could be more helpful if it provided more detailed guidance on how to address these issues, such as suggesting specific ways to clarify the pooling method or the definition of E_i. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions how the experiments relate to the underlying research question and the specific hypothesis tested. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks concrete guidance on how to improve the clarity or coherence of the paper, leaving the authors without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper, questioning how the experiments relate to the underlying research question and the specific hypothesis tested. However, it does not specify which part of the paper this issue is addressed in, making it difficult for the authors to pinpoint the exact section or figure that needs clarification. The comment is specific in its critique but weakly grounded as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the clarity of the empirical results and analyses presented in the paper, questioning how they relate to the underlying research question and the specific hypothesis tested. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that while it contains many empirical results and analyses, it lacks clarity in explaining how these results relate to the underlying research question and the specific hypothesis being tested. The reviewer questions how the different pieces of evidence presented in the experiments fit together to provide a coherent understanding. This feedback is valuable as it highlights a critical gap in the paper\"s presentation, making it difficult for readers to grasp the overall significance of the findings. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors could improve the clarity and coherence of their presentation. Without actionable advice, the comment is 3, as it points out an important area for improvement but does not fully address the authors\" needs for enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). While the comment implies that the authors should conduct these additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are not enough and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, it does not specify which part of the paper these comparisons are made or which sections of the paper need to be revised. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the need for additional experiments, it does not provide specific guidance on how to conduct these experiments or what results to expect. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental comparisons are not enough and suggests testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, the comment lacks specific reasoning or examples to support this claim. It does not provide a clear rationale for why these additional comparisons are necessary or how they would enhance the paper\"s contribution. Without detailed justification or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental comparisons by suggesting that the proposed method, InvP, could be tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback is 3 as it provides a specific direction for improving the experimental setup and potentially enhancing the robustness of the results. However, the comment lacks depth and does not offer detailed guidance on how to conduct these additional experiments or what specific results to expect. While it points out an area for improvement, it does not fully address the authors\" needs for a comprehensive evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not drawn formally enough to be considered more than motivational. It recommends that the authors either formalize this connection or adjust the language to clarify it. The comment provides explicit guidance on what needs to be done, namely, to formalize the connection or clarify the language. This action is concrete and directly instructs the authors on how to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the probabilistic connection in the paper is not drawn formally enough, implying that it is considered motivational. It recommends that the authors either formalize this connection or adjust the language to clarify it. However, the comment does not specify which part of the paper discusses the probabilistic connection, making it weakly grounded. It is specific in suggesting ways to improve the formalization or clarity of the connection, but without explicit references to the relevant sections, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not drawn formally enough, making it appear as motivational rather than substantiated. The comment suggests that the authors should either formalize this connection or adjust the language to clarify it. However, the comment lacks specific examples or references to support the claim that the connection is indeed not formal enough. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the probabilistic connection is not drawn formally enough, making it appear as motivational rather than substantiated. The comment suggests that the authors should either formalize this connection or adjust the language to clarify it. This feedback is clear and actionable, providing the authors with a specific direction to enhance the rigor and clarity of their work. However, the comment could be more helpful if it offered additional guidance on how to formalize the connection or examples of how to adjust the language. Despite this, the comment is 4 as it directs the authors towards improving a critical aspect of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for correcting the placement of a callout in Table 5 to Table 3 and for improving the clarity of the callout in Figure 6. These actions are concrete and specific, allowing the authors to directly apply the corrections. The comment is clear and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout in Figure 6, indicating that the authors need to ensure the callout is directing properly. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point consists of factual observations about the placement of callouts in the paper. It points out that the callout to Table 5 should be in Table 3 and that the callout for Figure 6 is not directing properly. These observations are based on direct examination of the paper and do not require additional evidence or reasoning to be understood. Therefore, the comment is classified as \"No\" because it is factual and does not contain any claims that need verification.", "helpfulness_rationale": "The review comment provides specific feedback on the placement of callouts in the paper, noting that the callout for Table 5 should be in Table 3 and that the callout for Figure 6 is not directing properly. This feedback is clear and actionable, as it directly points out the issue and suggests a correction. By addressing these specific issues, the authors can improve the clarity and accuracy of their paper. The comment is detailed and provides clear guidance, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the experiments in the paper, specifically noting that the paper only reports selfcomparisons and lacks explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to address the lack of explanation for the selfcomparisons or to include comparisons with SketchRNN. The action is implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the issue of only reporting selfcomparisons and the lack of explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. However, the comment does not specify which part of the experiments section this issue is discussed, making it weakly grounded. The comment is specific in detailing the issue of selfcomparisons and the suggestion to include comparisons with SketchRNN, which provides clear guidance for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only reports selfcomparisons and lacks explanation for this choice, which adds to the poor motivation problem. It suggests that comparisons with SketchRNN could be performed. However, the comment does not provide specific examples or references to support the claim about the lack of explanation or the suggestion to include comparisons with SketchRNN. This makes the claim 3, as it lacks detailed reasoning or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the experiments section of the paper, specifically noting that the paper only reports selfcomparisons and lacks explanation for this choice. This observation highlights a potential weakness in the motivation and depth of the experimental analysis. The comment also suggests that comparisons with SketchRNN could be performed, which provides a concrete direction for improvement. However, the comment could be more helpful if it provided additional guidance on how to address the lack of explanation or how to incorporate comparisons with SketchRNN effectively. Overall, the comment is 4 as it points out a critical area for improvement and offers a specific suggestion, but it could be more comprehensive with additional details or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more analysis and comments are needed regarding the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It disagrees with the authors\" viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The comment provides specific observations about the performance of DeiT models on different datasets, noting that DeiTB does not outperform DeiTT and DeiTS on APTOS2019, ISIC2019, and CheXpert, while CNNs show more consistent improvements. However, the comment does not explicitly instruct the authors on how to conduct this additional analysis or what specific aspects to focus on. While the authors can infer that they need to provide more analysis, the lack of explicit guidance on how to do so makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed observations about the performance trends of DeiT models compared to CNNs, highlighting discrepancies in their performance across different datasets. The authors are informed about what specific aspects need further analysis, making the comment both 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" viewpoint regarding the performance trends of increasing model capacity for ViT (DeiT) is incorrect. It provides specific observations about the performance of DeiT models on different datasets, noting that DeiTB does not outperform DeiTT and DeiTS on APTOS2019, ISIC2019, and CheXpert, while CNNs show more consistent improvements. However, the comment lacks detailed reasoning or references to support these claims, making it 3. The authors would need to rely on their own judgment and potentially seek additional evidence to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed analysis of the performance trends of increasing model capacity for ViT (DeiT) in Figure 3, offering specific observations and comparisons with CNNs. It disagrees with the authors\" viewpoint that both architectures benefit similarly from increased capacity, highlighting discrepancies in performance across different datasets. This feedback is valuable as it challenges the authors\" claims and suggests areas for further analysis and discussion. However, the comment could be more helpful if it provided guidance on how to conduct this additional analysis or what specific aspects of the performance trends should be explored. Despite this, the comment offers actionable insights that can guide the authors in improving their draft, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not provide explicit guidance on what needs to be addressed in those areas or how the authors should improve the clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the confusing parts mentioned in point 3. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not specify which part of the paper these areas of confusion are located in, making it difficult for the authors to pinpoint the exact issues. The comment is weakly grounded because it does not provide full grounding, and it is not specific because it does not detail what needs to be addressed in those areas. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point acknowledges that the paper is not difficult to follow but identifies several places that may cause confusion, referring to \"point 3.\" However, it does not provide any specific examples or detailed reasoning to support the claim that these areas are indeed confusing. Without concrete examples or references, the authors are left to interpret the comment, making it difficult to understand the specific issues that need to be addressed. Therefore, the comment is barely verifiable, as it lacks sufficient evidence to support the claim.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies several places that may cause confusion, referring to \"point 3.\" However, it does not provide specific examples or detailed reasoning to support the claim that these areas are indeed confusing. Without concrete examples or references, the authors are left to interpret the comment, making it difficult to understand the specific issues that need to be addressed. The feedback is 3 as it points out areas for improvement, but it lacks depth and actionable guidance, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency to understand. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the results need clarification. The comment implies that the authors should consider making the results more accessible or providing additional context, but it lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results being based on \"standard\" techniques, which allows the authors to identify the specific part of the paper being addressed. It also specifies what the issue is: the results are not obvious a priori and require a degree of technical competency to understand. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not obvious a priori and require a fair degree of technical competency to understand. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the assertion. Without detailed evidence or examples, the claim remains 3, as it lacks the necessary substantiation to fully convince the authors. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, noting that they are based on \"standard\" techniques but are not immediately obvious or accessible to a broader audience. This suggests that the results may require additional context or explanation to be fully understood. However, the comment does not provide specific guidance on how the authors might address this issue or what aspects of the results need clarification. While it highlights a potential area for improvement, the feedback lacks actionable suggestions or detailed examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the implementation of the bilinear layer, asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the comment provides specific questions that the authors should address, it does not offer explicit guidance on how to clarify these points or what specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer how to address the questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L290,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs clarification, such as the differences between the bilinear layer and other approaches, the dimensionality of embeddings, and the swapping of the bilinear layer with Hadamard product and MCB approaches. Additionally, it questions whether the compression of representations using Equation (3) is still applied. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the implementation of the bilinear layer, specifically asking for clarification on its differences from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. It also questions whether the compression of representations using Equation (3) is still applied. While the questions are specific and require detailed explanations, the comment lacks explicit reasoning or references to support the need for clarification. The authors would need to infer the importance of these questions and provide detailed justifications to address them. Therefore, the comment is 3, as it provides specific questions but lacks sufficient evidence or reasoning to fully support the need for clarification.", "helpfulness_rationale": "The review comment raises several specific questions about the implementation of the bilinear layer, which is a crucial aspect of the paper. It asks for clarification on how the bilinear layer differs from other approaches, the dimensionality of embeddings, and how it is swapped out with Hadamard product and MCB approaches. Additionally, it questions whether the compression of representations using Equation (3) is still applied. These questions are detailed and actionable, providing the authors with specific areas to address and improve their draft. However, the comment could be more helpful if it offered suggestions or guidance on how to address these questions or provide additional context. Overall, the feedback is 4 as it identifies key areas for clarification and improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The comment lacks concrete actions or detailed instructions on how to modify the analysis or presentation of the results. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment refers to \"Fig. 3 e,\" which is a specific part of the paper, allowing the authors to accurately identify the section being addressed. It also specifies the issue by questioning the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, the comment does not provide any specific reasoning, examples, or references to support why cosine similarity is an appropriate measure in this context. Without additional justification or explanation, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. This question prompts the authors to consider alternative ways of presenting their results, such as directly illustrating the latter loss term of Eqn 13. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the presentation of the results. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific details or suggestions on what changes might be necessary to clarify the concept. Without actionable steps or concrete advice, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the issue of confusion regarding the implicit call to the Witness oracle. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the required implicit call to the Witness oracle is confusing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the call is confusing or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the implicit call to the Witness oracle, which could be confusing for readers. However, the comment lacks specific details or suggestions on how the authors might address this confusion. Without actionable guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it points out a potential area for improvement but does not provide sufficient detail or direction for the authors to act upon."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify the distinction between weak and semisupervised training of the proposed method. It provides specific examples, such as renaming a column in Table 1 to \u201cFully supervised\u201d and suggests a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These instructions are clear and provide concrete guidance on how the authors should address the issue. The comment is fully actionable, as it directly instructs the authors on what changes to make to improve the clarity of their paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to clarify the distinction between weak and semisupervised training, suggesting renaming a column and categorizing training data. This detailed feedback helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific suggestions for improving the clarity of the paper, such as renaming a column in Table 1 and categorizing training data. These suggestions are logical and actionable, as they offer clear guidance on how the authors can enhance the presentation of their work. However, the comment lacks references or detailed reasoning to fully substantiate the claims. While the suggestions are wellsupported, the absence of additional evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback on the clarity of the distinction between weak and semisupervised training in the proposed method. It suggests renaming a column in Table 1 to \u201cFully supervised\u201d and proposes a more detailed categorization of training data into \u201cMixture training data\u201d and \u201cSingle source data.\u201d These suggestions are specific and provide a clear path for the authors to improve the clarity and organization of their paper. The feedback is 4 as it offers detailed guidance but could be further expanded to include additional aspects of the method or data. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the small contributions of the proposed method over previous methods, such as NCNet [6] and Sparse NCNet [21]. It also notes that the work is mostly engineeringfocused and suggests that it is challenging to differentiate the proposed method from its predecessors due to similar performance in practice. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the differentiation or to enhance the novelty of the contributions. As a result, the authors are left without clear directions on how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions \"NCNet [6]\" and \"Sparse NCNet [21]\" as examples of previous methods, providing specific references to previous work. It also notes that the contributions are mostly engineeringfocused and that it is difficult to differentiate the proposed method from its predecessors. This allows the authors to identify the specific parts of the paper being addressed, making the comment fully grounded. However, the comment does not specify what needs to be addressed in terms of differentiation or enhancement of novelty, which makes it somewhat specific. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point claims that the contributions of the proposed method are mostly engineeringfocused and that it is challenging to differentiate it from its predecessors due to similar performance in practice. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or detailed analysis to substantiate the assertion that the contributions are mostly engineeringfocused or that differentiation is difficult. Without concrete evidence or examples, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the small contributions of the proposed method over previous methods, such as NCNet [6] and Sparse NCNet [21], and notes that the work is mostly engineeringfocused. It also points out that it is challenging to differentiate the proposed method from its predecessors due to similar performance in practice. While the comment identifies a potential area for improvement in terms of differentiating the contributions, it lacks specific guidance or suggestions on how to address this issue. The feedback is 3 as it highlights a critical aspect of the paper that needs attention, but it does not provide actionable steps or detailed insights to enhance the authors\" work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their methodology. The feedback is somewhat vague and lacks concrete suggestions, making it challenging for the authors to understand how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not specify which part of the paper discusses the methodology or the results, making it weakly grounded. The comment is specific in detailing the concerns about the methodology and the difficulty in interpreting the results, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It also notes that previous work has considered multiple vulnerabilities simultaneously, which the authors have not addressed. The comment suggests that the results are difficult to interpret, implying a lack of clarity in the findings. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to provide more detailed reasoning or evidence to address these concerns effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It also notes that previous work has considered multiple vulnerabilities simultaneously, which the authors have not addressed. The comment suggests that the results are difficult to interpret, implying a lack of clarity in the findings. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. While it identifies a potential issue with the methodology, it does not provide actionable guidance on how the authors might address these concerns or improve their approach. Therefore, the comment is rated as 3, as it offers some insight but requires further elaboration to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might enhance the originality of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. Without explicit references or context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the originality of the work. Therefore, the comment is 1 and lacks specificity, making it unsuitable for the authors to improve their draft. This aligns with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the originality of the paper, specifically noting that the main idea of variable splitting and the algorithm are not new. However, it does not provide any suggestions or insights on how the authors might address this issue or enhance the originality of their work. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a concern but lacks depth and direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that INRs operate on a perdatainstance basis, arguing that this is not an advantage and that such a model would be almost useless. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors might infer that they need to reconsider the framing of their argument or provide a more nuanced perspective on the utility of perdatainstance models. The lack of concrete suggestions or specific actions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that the claim about INRs operating on a perdatainstance basis is true but not an advantage, and that such a model would be almost useless. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR\" is true but argues that it is not an advantage. The comment provides a logical reasoning by suggesting that a model capable of handling only a single timeseries instance is almost useless. However, it lacks specific examples or references to support the claim that this limitation is indeed a significant drawback. While the reasoning is clear, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper, stating that INRs operate on a perdatainstance basis, and argues that this is not an advantage. The reviewer provides a logical reasoning by suggesting that such a model would be almost useless. While the comment highlights a potential weakness in the paper, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a critical aspect that needs attention, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the experiments are limited to RoBERTabase and raises concerns about the generalizability of the results to other models, such as those with learnable APEs, different model sizes, objective functions, and architectures. It also recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT2. The comment provides clear guidance on what needs to be addressed and how to do it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"most of the experiments\" and \"Section 4.1.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of limited experiments, the need to generalize results to other models with learnable APEs, and suggests including more analysis for GPT2, providing detailed guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and suggests that the results may not be generalizable to other models, such as those with learnable APEs, different model sizes, objective functions, and architectures. It recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT2. However, the comment lacks specific examples or references to support the claim about the generalizability of the results. While it provides a logical reasoning for the concern, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experiments conducted, noting that most of the experiments are limited to the RoBERTabase model. It raises concerns about the generalizability of the results to other models, particularly those with learnable APEs, different model sizes, objective functions, and architectures. The comment suggests that the authors should investigate these aspects to ensure the robustness and applicability of their findings. Additionally, it recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT2, which would provide valuable insights. This feedback is clear, actionable, and constructive, offering specific guidance on how the authors can enhance their experiments and improve the generalizability of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the abstract effectively explains the proposed idea but does not provide details on how the idea was evaluated or what the outcome was. It also mentions minor language issues. While the comment identifies a gap in the abstract\"s content, it does not explicitly instruct the authors to include details about the evaluation process or the outcome. The suggestion to address minor language issues is vague and lacks specific guidance. Therefore, the comment is 3, as it highlights an area for improvement but does not provide clear instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description regarding how the proposed idea was evaluated and what the outcome was, as well as mentioning minor language issues. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract effectively explains the proposed idea but lacks details on how it was evaluated and what the outcome was. It also mentions minor language issues. However, the comment does not provide specific examples or references to support the claim about the lack of detail in the evaluation process or the outcome. While it identifies a gap in the abstract, it lacks sufficient evidence or guidance to help the authors address this issue effectively. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the abstract, noting that while it effectively explains the proposed idea, it lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include additional information that would enhance the comprehensiveness of the abstract. However, the comment could be more helpful if it provided specific examples of how the evaluation process could be described or suggestions for presenting the outcome. Despite this, the feedback is 4 as it offers a clear direction for improvement, allowing the authors to address the identified gap in their abstract."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a confusion in the description of the MFDA setting in the first paragraph of the Method Section. It points out that the notation for the target domain \tau is unlabeled, which is inconsistent with the original MFDA paper (Yue et al., 2021a). The comment questions whether unlabeled data from source domains is used during training, as in the original paper. This feedback is explicit and provides a clear action for the authors to take: they should clarify the notation and explain the use of unlabeled data from source domains in their method. The comment is specific and actionable, as it directly addresses a potential issue in the paper and suggests a concrete step for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first paragraph of the Method Section, providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue with the description of the MFDA setting, particularly the confusion regarding the notation for the target domain \tau and the use of unlabeled data from source domains. This level of detail makes the comment specific, as it clearly identifies what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the consistency of the description of the MFDA setting in the paper with the original MFDA paper (Yue et al., 2021a). It points out that the notation for the target domain \tau is unlabeled, which is inconsistent with the original paper. The comment questions whether unlabeled data from source domains is used during training, as in the original paper. While the comment identifies a potential issue, it does not provide specific examples or detailed reasoning to fully substantiate the claim. The lack of detailed explanation or references makes it 3, as the authors would need to infer the basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the description of the MFDA setting within the Method Section, particularly concerning the notation for the target domain \tau and the use of unlabeled data from source domains. It highlights a potential inconsistency with the original MFDA paper (Yue et al., 2021a), which could confuse readers. The comment is clear and actionable, as it directs the authors to clarify the notation and explain the use of unlabeled data from source domains in their method. This feedback is valuable as it provides a concrete step for the authors to improve the clarity and consistency of their paper. However, the comment could be more helpful if it offered additional suggestions or examples to further enhance the explanation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of distinguishing between derogatory and exclusionary extreme speech, providing an example to illustrate the issue. It questions the annotators\" consideration of local regulations and their impact on zeroshot crosscountry classification. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the distinction. The action is implicit and vague, as the authors are left to infer that they need to clarify the definitions and provide more detailed explanations. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Paper Summary,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of distinguishing between derogatory and exclusionary extreme speech, providing an example to illustrate the confusion. The comment is specific in detailing what needs to be addressed, including the need for clearer definitions and explanations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the distinction between derogatory and exclusionary extreme speech, providing an example to illustrate the confusion. It also questions the role of local regulations in the annotations and their impact on zeroshot crosscountry classification. However, the comment lacks specific examples or references to support the claim that the distinction is unclear or that the impact of local regulations is significant. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of distinguishing between derogatory and exclusionary extreme speech, providing an example to illustrate the confusion. It questions the role of local regulations in the annotations and their impact on zeroshot crosscountry classification, which is a relevant concern for the authors to address. However, the comment could be more helpful if it provided additional guidance or suggestions on how to improve the distinction or clarify the role of local regulations. As it stands, the feedback is 3, as it highlights an important area for improvement but lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, noting that the baseline and timeaware models show similar performance. It suggests that the proposed method might be more effective under different timestep scenarios. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be needed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same, suggesting that the method might be more effective under different scenarios. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, based on the observation that Figure 5 shows similar performance between the baseline and timeaware models. While the comment questions the effectiveness of the proposed methods under this specific scenario, it does not provide any additional evidence or reasoning to support the claim that the method might be more effective under different timestep scenarios. The lack of detailed explanation or references makes the claim 3, as the authors may need to infer the reasoning or seek additional information to fully understand the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as evidenced by the similar performance shown in Figure 5. The comment suggests that the proposed method might be more effective under different timestep scenarios, which is a relevant point for consideration. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments or analyses could be conducted to strengthen the evaluation. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to obtaining fully disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is explicit and provides a clear action for the authors to take, which is to elaborate on the mechanisms and guarantees of disentanglement. However, the comment does not specify exactly how this should be done, leaving some room for interpretation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation related to obtaining fully disentangled latent vectors. However, the comment does not specify which part of the paper discusses disentanglement or how it is realized. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the issue of disentanglement, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to obtaining fully disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is 3 as it points out a specific area where the paper could be clearer, but it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to obtaining fully disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain bias types. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation regarding the disentanglement process. However, the comment could be more helpful if it provided specific examples or suggestions for how to address this issue. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit, as the authors need to infer that they should expand the discussion to address the accuracy drop. While the action is somewhat concrete, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the ICLHAR improves consistency and verifiability but negatively impacts accuracy scores, which need to be discussed in more detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that the ICLHAR improves consistency and verifiability but negatively impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This claim is supported by the numerical data provided, making it 5. The comment is clear and provides specific evidence to support the claim, allowing the authors to understand and address the issue effectively. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that while it improves consistency and verifiability, it negatively impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This observation is crucial for the authors to address, as it highlights a potential tradeoff between consistency and accuracy. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text, which is a clear and actionable piece of feedback. By prompting the authors to address this tradeoff, the comment provides valuable guidance on how to improve the paper. However, it could be more helpful if it suggested specific ways to discuss or address the issue. Overall, the comment is 4, as it effectively highlights a critical area for improvement and encourages the authors to expand on their discussion."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take or address this observation. The comment lacks guidance on how the authors might investigate or explain this phenomenon, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps or suggestions for improvement. Therefore, it aligns with a score of 1.", "grounding_specificity_rationale": "The comment describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is related to, such as a particular section, table, or figure. Without this context, the authors cannot confidently determine where the issue lies, making the comment weakly grounded. Additionally, the comment is specific in detailing the observed phenomenon, but it lacks guidance on how to address or explain this issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any specific evidence, examples, or references to support this observation. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. While this observation is interesting and potentially significant, the comment lacks actionable guidance or suggestions for the authors to address or explain this phenomenon. It does not provide any insights into how the authors might investigate or interpret this correlation drop, nor does it offer any suggestions for improving the paper\"s clarity or robustness. As a result, the comment is 2, as it does not provide the authors with a clear path forward for improving their work. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the derivation, namely the temperature \u03c4, and suggests ways to address this issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This claim is 3 as it points out a specific issue in the derivation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the missing details or provide additional context to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the omission of the temperature parameter \u03c4 in the derivation from Eqn. 3 to Eqn. 4. It suggests that this omission should be addressed by showing the temperature in a rigorous manner or mentioning it in the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve the rigor and completeness of their work. By addressing this issue, the authors can enhance the clarity and accuracy of their derivation, making the paper more robust and understandable. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the authors\" claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors without a clear understanding of how to improve their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the authors\" claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. However, the comment does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the specific issue and address it effectively. While the comment is specific in its critique of the strategic setting, the absence of grounding limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the authors\" claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. This critique is based on a logical assessment of the paper\"s content and the authors\" claims. However, the comment lacks specific examples or references to support the claim that the opponent does not behave strategically. Without detailed evidence or examples, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is 3, as it provides a basis for the authors to consider but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" claim of \"strategic predictions\" and suggests that their setting is only partially strategic, as the opponent does not behave strategically. This critique is clear and provides a specific point of concern that the authors should consider. However, the comment does not offer detailed guidance or suggestions on how the authors might address this issue or improve their draft. While it highlights a potential area for revision, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit instructions for the authors to address specific issues in their draft. It instructs them to run experiments for untrained networks and add the results to the figures and Table 1. Additionally, it requests clarification on whether the figures show results for networks trained on random data or unaltered data, and whether the nonrandom data is normalized. The comment also suggests showing examples of random data in the appendix. These instructions are clear and provide concrete guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3) mentioned above,\" which implies a specific part of the paper being addressed. It also specifies what needs to be addressed, such as running experiments for untrained networks and adding results to figures and Table 1. The comment further requests clarification on whether the figures show results for networks trained on random data or unaltered data, and whether the nonrandom data is normalized, suggesting the inclusion of examples in the appendix. This level of detail provides clear guidance for the authors to improve their draft, making the comment 5.", "verifiability_rationale": "The review point raises a question about the importance of figures showing results for untrained networks and requests clarification on the data used in the figures. It also asks for clarification on whether the data is normalized and suggests showing examples of random data in the appendix. While the comment is clear and specific, it does not provide any additional reasoning or references to support the claims made. The authors are expected to infer the need for these clarifications and actions, which makes the comment 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on areas that need improvement in the draft. It requests the authors to run experiments for untrained networks and add the results to the figures and Table 1, which is a clear and direct action. Additionally, it asks for clarification on the data used in the figures, specifically whether the networks are trained on random data or unaltered data, and whether the nonrandom data is normalized. The suggestion to show examples of random data in the appendix further enhances the clarity and completeness of the draft. This feedback is detailed and constructive, making it 5 for the authors to improve their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the task setup description, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. While the comment identifies a specific issue with the clarity of the task setup, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify these aspects in their draft, but the action is not concrete or detailed. Therefore, the comment is 3, as it points out a specific area for improvement but lacks explicit instructions on how to implement it.", "grounding_specificity_rationale": "The comment addresses the task setup description, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper discusses the task setup, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the input notes in the EHR and the distance of the outcomes from the last note date. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, the comment aligns with category 3.", "verifiability_rationale": "The review point claims that the task setup is not described clearly, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or references, the authors are left to assume the claim is valid, which makes it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the task setup description in the paper. It points out that the authors need to clarify which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address to enhance the clarity and completeness of their paper. However, the comment could be more helpful if it suggested specific ways to improve the clarity or provided examples of how to present this information effectively. Overall, the comment is 4, as it directs the authors to a critical area for revision, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. While the comment provides a clear action\u2014mentioning and comparing with untrained neural networks\u2014it does not specify how to implement this comparison or where in the paper this discussion should be included. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OOD experiments\" and \"imaging in the recent few years,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests mentioning and comparing the current method with untrained neural networks used for solving inverse problems, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging, referencing a specific paper. This claim is 3 as it provides a specific example of a relevant area for comparison, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would benefit from additional context or references to fully understand the implications of this comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement by suggesting that the paper should mention and compare its method with untrained neural networks used for solving inverse problems in imaging. This feedback provides a clear direction for the authors to enhance the context and relevance of their work. However, the comment could be more helpful if it included specific examples or guidance on how to compare the methods. Overall, the feedback is actionable and constructive, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used, which would be interesting to demonstrate. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to incorporate real data into their experiments. While the suggestion is clear, the lack of detailed instructions or examples makes it somewhat vague and leaves the authors uncertain about how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments being limited to toy data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, suggesting that the method\"s performance should be evaluated on real data where barycenters can be used. This provides a clear direction for improvement, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests evaluating the method\"s performance on real data where barycenters can be used. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used, which would be interesting to demonstrate. This feedback is 3 as it points out a specific area for improvement and encourages the authors to consider a broader range of data for their experiments. However, the comment could be more helpful if it provided additional guidance on how to select or generate real data for evaluation or suggested specific types of real data that might be relevant. Overall, the comment offers a clear direction for enhancing the paper, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two specific sections of the paper that are hard to read and points out a lack of clarity in the explanation of previous approaches. It provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. However, the comment does not offer explicit guidance on how the authors should improve the clarity of these sections or provide specific suggestions for revisions. The action is implicit, as the authors need to infer that they should clarify the explanations in these sections. The lack of concrete guidance on how to address these issues makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the explanations are unclear, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. This level of detail helps the authors understand exactly what needs to be clarified. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises specific questions about the clarity of explanations in the paper, particularly regarding the conversion of a stacked LSTM to a sequential LSTM and the meaning of certain variables in a figure. While the reviewer provides examples of where the explanations are unclear, the comment does not offer any additional evidence or reasoning to support the claim that the paper is hard to read or that the explanations are lacking. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific sections of the paper that are difficult to read, particularly the first two sections, due to the lack of clear explanations of previous approaches. It provides detailed examples of where the authors fail to explain certain concepts, such as the conversion of a stacked LSTM to a sequential LSTM and the meaning of specific variables in a figure. This feedback is 3 as it highlights areas where the authors need to improve the clarity of their explanations. However, the comment could be more helpful if it offered suggestions on how to clarify these sections or provide additional context. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the captions should be more descriptive, implying that the authors need to make them more detailed to avoid the need for readers to search for interpretations of the figures. It also suggests explaining the \"scramble network\" better, which provides a clear action for the authors to take. The comment is explicit and concrete, as it directly instructs the authors to improve the captions and provide more context for the \"scramble network.\" Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests making the captions more descriptive, implying that the authors need to provide more detailed explanations of the figures. It also recommends explaining the \"scramble network\" better, which provides a clear action for the authors to take. However, the comment does not specify which part of the paper the captions or the \"scramble network\" are located in, making it weakly grounded. The comment is specific in its suggestions, as it clearly indicates what needs to be improved. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the captions should be more descriptive and that the \"scramble network\" should be explained better. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues or how to address them. Without detailed reasoning or examples, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully actionable. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the need to make figure captions more descriptive and to explain the \"scramble network\" better. This feedback is actionable and constructive, as it directs the authors to improve the clarity and context of their figures, which is crucial for effective communication. By addressing these points, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it provided additional guidance on how to make the captions more descriptive or how to explain the \"scramble network\" effectively. Overall, the comment is 4, as it offers clear directions for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It also provides references to support the claim that these issues hinder understanding. The comment explicitly suggests that these issues should be addressed by defining the abbreviations and clarifying the notation. However, it does not provide detailed guidance on how to define the abbreviations or clarify the notation, leaving the authors to infer the necessary actions. The action is explicit but somewhat vague, as it lacks concrete steps for implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the abbreviation \"NE\" on line 73 and the superscript notation in Equation 6, which are clearly referenced. It also provides references to support the claim that these issues hinder understanding. The comment is specific because it details what needs to be addressed, namely the lack of definition for abbreviations and the delayed definition of notation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined, specifically mentioning \"NE\" on L73 and the superscript notation in Eq 6, which is only defined later in the paper. The comment also provides references to support the claim that these issues hinder understanding. However, the claim lacks detailed reasoning or examples to fully substantiate the assertion that these undefined abbreviations and notations hinder understanding. The references provided are relevant but do not offer a comprehensive explanation of how these issues impact the paper\"s clarity. Therefore, the comment is 3, as it provides some support but lacks depth and detail.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It also provides references to support the claim that these issues hinder understanding. While the comment highlights these areas for improvement, it does not offer detailed guidance on how to define the abbreviations or clarify the notation. The feedback is 3 as it points out areas that need attention, but it lacks depth and actionable suggestions for the authors to address these issues effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve their evaluation or select more appropriate baselines. As a result, the authors are left without a clear understanding of what steps to follow to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not detail what aspects of the evaluation are weak or why the baselines are not suitable for fair classification. Without this information, the authors cannot effectively address the feedback. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment lacks specific details or examples to support this claim. It does not provide any references or logical reasoning to substantiate the assertion that the baselines are unsuitable for fair classification. Without this additional information, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation section of the paper, specifically noting that the baselines used are not designed for fair classification. This feedback is 3 as it highlights an area that could be improved, but it lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The comment does not offer actionable advice or examples of how to enhance the evaluation process, leaving the authors with limited insight into how to improve their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, suggesting that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This implies that the authors should revise their statement to accurately reflect the capabilities of the Walkman algorithm. Second, the comment points out a lack of clarity in the reference \"it\" in Section 3, first paragraph, which could hinder the reader\"s understanding. While the comment identifies areas for improvement, it does not provide explicit instructions on how to revise the statements or clarify the references. The actions are somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, namely the Related Work section (Page 2, second paragraph) and Section 3, first paragraph. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed feedback on the accuracy of a statement regarding the Walkman algorithm and the clarity of a reference, offering concrete suggestions for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point contains two claims. The first claim critiques the accuracy of a statement regarding the related work, specifically mentioning the Walkman algorithm and its solvers. The comment provides a detailed explanation of the algorithm\"s capabilities, suggesting that the original statement is inaccurate. This claim is 4 as it offers a clear reasoning and specific examples to support the critique. The second claim points out a lack of clarity in a reference within Section 3, first paragraph, which could hinder understanding. However, the comment does not provide specific examples or references to address this issue, making it 3. Overall, the comment is 4, as it provides some justification but lacks complete detail and references for both claims.", "helpfulness_rationale": "The review comment provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, particularly the Walkman algorithm, which is solved by ADMM with two versions, not just SGD. This feedback is valuable as it highlights a potential misrepresentation in the paper and suggests that the authors should revise their statement for accuracy. Second, the comment points out a lack of clarity in a reference within Section 3, first paragraph, where the term \"it\" is used without a clear reference, which could hinder the reader\"s understanding. While the comment identifies areas for improvement, it could be more helpful if it provided specific suggestions on how to revise the statements or clarify the references. Overall, the feedback is 3 as it directs the authors to specific areas that need attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of longcontext language models. It mentions specific areas, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, and provides references to support these suggestions. The comment is clear and specific, offering concrete guidance on what needs to be included in the Related Work section. This allows the authors to directly address the feedback and improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Related Work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the section by discussing specific methods and their limitations, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. This level of detail helps the authors understand exactly what needs to be added or improved in the Related Work section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the Related Work section lacks details and should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of longcontext language models. It suggests discussing specific methods such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods, providing references to support these suggestions. The claim is wellsupported by specific examples and references, making it 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the Related Work section. It identifies a significant gap in the current draft by noting the lack of detail and suggesting specific areas that need to be expanded, such as sparseattention mechanisms, segmentationbased approaches, memoryenhanced segmentation strategies, and recursive methods. By offering concrete examples and references, the comment guides the authors in enhancing the Related Work section, which is crucial for situating their work within the existing literature. This detailed feedback empowers the authors to significantly improve the comprehensiveness and depth of their paper, making it a valuable and 4 comment."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the proposed solution is an incremental step considering the relaxation proposed by Guzman et. al. However, it does not provide any specific actions or suggestions for improvement. The comment lacks detail on what aspects of the solution need to be addressed or how the authors can enhance their work. As a result, the authors are left without guidance on how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment acknowledges that the proposed solution is an incremental step considering the relaxation proposed by Guzman et. al. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. The comment is vague and does not provide specific guidance on what needs to be addressed or how the authors can enhance their work. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point acknowledges that the proposed solution is an incremental step considering the relaxation proposed by Guzman et. al. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the comment or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the proposed solution is an incremental step considering the relaxation proposed by Guzman et. al. However, it does not provide any specific suggestions or feedback on how the authors might improve their work or address this incremental nature. The comment lacks actionable insights and detailed guidance, leaving the authors with limited information on how to enhance their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which figures to revise or how to add the scatter plot. While the action is somewhat inferred, it lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not specify which parts of the paper these figures are located in, making it weakly grounded. The suggestion to highlight best results in tables is also vague and lacks specific guidance on how to implement it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The suggestion to highlight best results in tables is also vague and lacks detailed guidance. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or depth to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies areas for improvement in the results presentation, specifically mentioning the ambiguity of the yaxis labels in Figures 2 and 3 and the absence of runtime representation. It suggests a scatter plot with runtime and performance axes as a way to enhance the reader\"s understanding and interpretation of the results. Additionally, it proposes highlighting the best results in tables, which could improve clarity. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific steps or examples. While it provides some actionable feedback, the lack of depth and specificity makes it 3, as it gives the authors a general idea of what to improve but not a comprehensive roadmap. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not provide explicit guidance or suggestions on how the authors should address this question or what aspects of the analysis might need to be reconsidered. The action is implicit, as the authors are left to infer that they should explore other technical considerations related to the use of advantage instead of qvalue. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the comment is relevant. While the comment is specific in its inquiry about technical considerations, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not provide any specific reasoning, examples, or references to support why this choice might be made or what other considerations might exist. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. This feedback is 3 as it prompts the authors to consider alternative approaches or additional factors that might influence their analysis. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to address the question or what aspects of the analysis might need to be reconsidered. The feedback is incomplete and could be more actionable with additional details or examples. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies specific instances of writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment highlights these errors, it does not provide explicit guidance on how the authors should correct them or what specific changes need to be made. The action is implicit, as the authors can infer that they need to revise these parts of the paper to improve clarity and accuracy. However, the lack of detailed instructions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not specify which sections or parts of the paper these errors are located in, making it difficult for the authors to pinpoint the exact areas that need correction. While the comment is specific about the nature of the errors, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment highlights these errors, it does not provide any reasoning, examples, or references to support why these errors are problematic or how they impact the paper. The lack of detailed explanation or justification makes it difficult for the authors to understand the significance of these errors and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment points out these issues, it does not provide any suggestions or guidance on how the authors might address these errors or improve the clarity of their writing. The feedback is limited in scope and lacks actionable advice, making it difficult for the authors to effectively respond and improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the hGRU architecture appears to be adhoc and lacks motivation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment is vague and does not offer concrete steps for improvement, leaving the authors without a clear understanding of what actions to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the hGRU architecture is adhoc and lacks motivation, but it does not specify which part of the paper this observation pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where the issue is being addressed. Additionally, the comment lacks specificity in detailing what aspects of the architecture are adhoc or how they could be better motivated. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture is \"adhoc and not very well motivated.\" However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the architecture might be adhoc or poorly motivated. This lack of supporting evidence makes the claim difficult to verify, and the comment is therefore considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the hGRU architecture, suggesting that it is adhoc and lacks motivation. However, the comment does not provide specific details or suggestions on how the authors might address this issue or improve the motivation behind the architecture. Without actionable guidance or examples, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 2, as it highlights a concern but does not offer substantial feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these points. The authors would need to infer that they should correct the algorithm, analyze the asymptotic performance, and provide additional results. Therefore, the comment is 3, as it provides guidance but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1 Line 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the use of s_t instead of s_n, as well as questions about the asymptotic performance and the need for additional results with more environment steps. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies areas for clarification and improvement, it lacks specific reasoning or references to support the claims. The authors would need to infer the basis for these suggestions, making the comment 2. Therefore, it aligns with a score of 2.", "helpfulness_rationale": "The review comment identifies a specific issue in Algorithm 1, line 8, questioning the use of s_t instead of s_n. It also raises questions about the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment points out a potential error and suggests areas for further analysis, it lacks detailed guidance on how to address these issues or provide the additional results. The feedback is 3 as it highlights areas for improvement but does not offer comprehensive suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but could be more comprehensive in its guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It also questions the claim of COCOLM being parameterefficient, noting that the conclusion would apply to related works. The comment implicitly suggests that the authors should provide a more nuanced comparison and address the impact of BPE vocabulary changes on performance. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address them. The action is somewhat vague, as the authors need to infer the specific areas to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron, suggesting it is overrated and that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCOLM being parameterefficient, implying that the conclusion would apply to related works. However, the comment does not specify which part of the paper this comparison is made or which sections discuss the performance of these models. This makes it difficult for the authors to pinpoint the exact areas that need revision. The comment is specific in its critique of the comparison but lacks grounding as it does not provide clear references or sections to address. Therefore, it is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCOLM being parameterefficient, noting that the conclusion would apply to related works. However, the comment lacks specific examples or detailed reasoning to substantiate these claims. It does not provide references or logical arguments to support the assertion that the comparison is overrated or that the conclusion applies to other works. As a result, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises a valid concern about the overstatement of the comparison with Megatron, suggesting that the performance of Megatron and COCOLM is close to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of COCOLM being parameterefficient, implying that the conclusion would apply to related works. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or provide a more nuanced comparison. While it identifies an area for improvement, it does not offer detailed feedback or actionable steps for the authors to take, making it 3. The feedback is 3 as it points out a potential issue with the comparison, but it could be more comprehensive with additional suggestions or guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the analysis presented in lines 128 to 149, noting that it is not convincing enough. It highlights a specific observation from a histogram in Figure 3, where the GSP50 model is claimed to have smaller class selectivity scores, suggesting that it shares more features with ResNet50, which learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide explicit guidance on how to improve the analysis or address the concerns raised. While it identifies a potential issue with the analysis, it lacks actionable steps for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It provides a detailed explanation of the observation, noting that the GSP50 model has smaller class selectivity scores, which implies it shares more features with ResNet50, while ResNet50 learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. The comment is fully grounded as it explicitly mentions the specific section and figure being addressed. It is also specific because it provides a detailed explanation of the observation and the reasoning behind the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It claims that the GSP50 model has smaller class selectivity scores, suggesting it shares more features with ResNet50, which learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide any specific examples or detailed reasoning to support the claim that this observation indicates GSP50 learns better representations. While the reasoning is somewhat logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the analysis presented in lines 128 to 149, specifically referencing a histogram in Figure 3. It highlights a potential issue with the analysis, noting that the GSP50 model has smaller class selectivity scores, which suggests it shares more features with ResNet50, while ResNet50 learns more classspecific features. The authors hypothesize that additional context may allow the network to reduce its dependency. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the analysis. While it identifies a potential area for improvement, it lacks actionable advice, making it 2. Therefore, the comment is rated as 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific guidance or actions for the authors to take to address this concern. The comment lacks explicit instructions on how the authors should consider or address the hardware and software dependencies in their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which part of the paper these observations and decisions are discussed in, nor does it provide any specific examples or guidance on how to address this issue. The lack of grounding makes it difficult for the authors to understand which sections need revision, and the comment lacks specificity in detailing what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some observations and design decisions might be hardware and software dependent, which is a valid concern. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without additional context or examples, the authors may struggle to understand the implications of this observation or how to incorporate it into their work. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer actionable advice or detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, suggesting that the AMP algorithm may not be useful for nonGaussian problems. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the study could be improved to enhance the practical relevance of the AMP algorithm. The comment lacks concrete suggestions or actionable steps for the authors to take, making it difficult for them to understand how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the practical impact of the weak recovery problem studied, suggesting that the AMP algorithm may not be useful for nonGaussian problems. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the algorithm\"s applicability but lacks grounding as it does not provide clear guidance on which part of the paper to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and that the AMP algorithm may not be useful for nonGaussian problems, limiting its practical impact. However, the comment does not provide specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical impact of the weak recovery problem studied, specifically questioning the usefulness of the AMP algorithm for nonGaussian problems. This feedback highlights a gap in the paper\"s discussion and suggests that the authors may need to address the practical relevance of their findings. However, the comment lacks detailed guidance or suggestions on how the authors could improve the practical impact of their work or what specific aspects of the study could be expanded to address this concern. While it points out an important issue, the feedback is somewhat limited in its actionable value, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and explicit action for the authors to take, as they need to conduct these experiments to demonstrate the effectiveness of their method. The action is also concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this comparison should be made or which section discusses the proposed method. This makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment is specific about the comparison criteria, it lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This claim is 3 as it provides a clear rationale for the comparison, but it lacks specific examples or references to support the claim. The authors would need to provide more detailed reasoning or evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by conducting additional experiments. By comparing their method with others in terms of learnable parameters and GFLOPs, the authors can better demonstrate the effectiveness and efficiency of their approach. This feedback is 4 as it offers a concrete suggestion for improvement, but it could be more comprehensive if it included guidance on how to conduct the ablation experiments or what specific metrics to focus on. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it lacks explicit guidance on how to address them. The comment suggests exploring other bit operations, providing more explanations for Figure 5a, and dealing with DVS input when the input is in aer format. It also suggests analyzing energy consumption as reference [15] did to strengthen the paper. However, the authors are left without clear instructions on how to implement these suggestions or what specific actions to take. The feedback is somewhat vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment raises several questions and suggestions for improvement, but it does not specify which part of the paper these issues relate to. The references to \"11,\" \"Fig. 5 a,\" and \"aer format\" are vague and do not allow the authors to pinpoint the exact sections or figures being discussed. While the suggestions are relevant, the lack of grounding makes it difficult for the authors to understand which parts of the paper need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and suggestions for improvement, such as exploring other bit operations, providing more explanations for Figure 5a, and dealing with DVS input when the input is in aer format. It also suggests analyzing energy consumption as reference [15] did to strengthen the paper. However, the comment lacks specific reasoning, examples, or references to support these suggestions, making it difficult for the authors to understand the basis of the claims. The feedback is 4 as it provides some direction but lacks detailed justification or evidence. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises several questions and suggestions for improvement, such as exploring other bit operations, providing more explanations for Figure 5a, and dealing with DVS input when the input is in aer format. It also suggests analyzing energy consumption as reference [15] did to strengthen the paper. However, the comment lacks specific guidance on how to address these points or what actions the authors should take to improve their draft. While it identifies areas for enhancement, it does not provide detailed feedback or actionable steps, making it 3. The feedback is 3 as it offers some direction but could be more comprehensive and detailed to fully assist the authors in improving their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point requests the authors to define the dashed lines in figures 2AB and 4B. This is a clear and explicit action that the authors can readily take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment requests the authors to define the dashed lines in figures 2AB and 4B. While it does not explicitly mention which part of the paper these figures are located in, the authors can infer that they are referring to specific sections or figures mentioned in the paper. This makes the comment weakly grounded, as the authors can make an educated guess but cannot precisely identify the referenced part. However, the comment is specific in its request to define the dashed lines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point requests the authors to define the dashed lines in figures 2AB and 4B. This is a factual request for clarification, as it does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment requests the authors to define the dashed lines in figures 2AB and 4B. This is a clear and actionable suggestion that directly addresses a specific aspect of the paper that needs clarification. By defining these lines, the authors can improve the readability and understanding of their figures, which is crucial for effective communication of their work. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, it is rated as 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a plot showing how different weights of the model change after unlearning, specifically focusing on which layers are most affected. This feedback is explicit and concrete, as it directly instructs the authors on what action to take and how to implement it. The comment provides a clear and detailed action, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. The comment is specific in its suggestion to include a plot and analyze weight changes, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. This claim is 3 as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim. The authors would need to infer the need for such a plot based on the feedback, which could be improved by providing more detailed reasoning or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors include a plot illustrating how different weights of the model change after unlearning. This feedback is actionable and directly addresses a potential area for clarification or further analysis in the paper. By suggesting a visual representation of weight changes across layers, the comment offers a concrete way for the authors to enhance the understanding and presentation of their results. However, the comment could be more helpful if it provided additional guidance on how to create or interpret the plot effectively. Overall, the feedback is 4 as it directs the authors towards a specific and actionable improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. It also mentions that this formatting issue effectively violates the 9page paper limit, which is a significant concern. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the formatting. While the authors can infer that they need to adjust the spacing and layout, the lack of concrete instructions or suggestions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1,\" indicating a specific part of the paper being addressed. It also specifies the issue by detailing the formatting problems with equations and captions, which are common elements in academic papers. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace, causing equations to be crammed together and captions to be too close to the figures. This issue is presented as a violation of the 9page paper limit, which is a factual observation. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the problem and how to address it. Without detailed examples or references, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. This observation is presented as a violation of the 9page paper limit, which is a significant concern. While the comment highlights a clear weakness in the paper\"s presentation, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a critical formatting problem that needs attention, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant risk of methods exploiting relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, mentioning that AU6 can occur in both expressions of pain and happiness, and that this cooccurrence differs in datasets like SEMAINE and UNBC pain dataset. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. The comment is explicit in identifying the issue and provides a clear action for the authors to take, which is to conduct crossdataset experiments. This makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"action units\" and \"action units relationships,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by highlighting the potential differences in cooccurrences across datasets, such as SEMAINE and UNBC pain dataset, and suggests a way to test generalization through crossdataset experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that methods exploiting relationships between action units can lead to different cooccurrences across datasets, such as AU6 in pain and happiness, and that this difference is evident in Figure 1. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. While the claim is supported by the observation of different cooccurrences in Figure 1, the reasoning could be more detailed, and the suggestion for crossdataset experiments is clear. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the potential for these relationships to vary across different datasets. It provides a clear example, noting that AU6 can occur in both expressions of pain and happiness, and that this cooccurrence differs significantly between datasets like SEMAINE and UNBC pain dataset. The comment suggests that crossdataset experiments would be a good way to test the generalization of such work, noting that the paper lacks these experiments. This feedback is 4 as it provides a specific and actionable suggestion for the authors to address a critical gap in their work. However, it could be more comprehensive if it offered additional guidance or suggestions for improvement beyond the crossdataset experiments. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not provide any explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the clarity of the motivation or how to differentiate their work from incremental contributions. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not specify which part of the paper is difficult to follow or where the motivation is discussed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide detailed feedback on what aspects of the motivation are unclear or how the paper might be perceived as incremental. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that it is \"very difficult to follow the motivation of this paper\" and suggests that it might be an incremental engineering paper. However, the comment lacks specific examples or detailed reasoning to support these claims. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the difficulty in following the motivation and the perception of it being an incremental engineering paper. While these points highlight areas for improvement, the comment lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out areas that need attention, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and MPHATE in Figure 3. Additionally, the comment questions the purpose of examining the learning curves, asks whether worseperforming models always lead to structural collapse, and inquires about the accuracy numbers for the last task or average. While the comment provides several specific actions, it lacks a clear, stepbystep guide on how to implement these suggestions. The actions are somewhat vague, making it challenging for the authors to fully understand and execute them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and MPHATE in Figure 3. However, the comment does not specify which part of the paper these sections or figures are located in, making it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the content that needs to be addressed, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the experimental setting, the correspondence between learning curves and MPHATE, and the interpretation of the results. However, it does not contain any subjective opinions or claims that require verification. The comment is primarily factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment provides several specific suggestions for improving the paper, such as adding more sentences to explain the experimental setting for continual learning and clarifying the correspondence between learning curves and MPHATE in Figure 3. It also raises questions about the purpose of examining the learning curves and the interpretation of accuracy numbers. However, the comment lacks depth and does not offer detailed guidance on how to address these issues or provide specific examples of what the authors should include. While the suggestions are 3, the comment could be more helpful if it provided more detailed feedback or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the paper should include a plot comparing the flexibility of SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is explicit and detailed, guiding the authors on how to implement the suggested improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SGC\" and \"LoRA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a concrete action: including a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed and how to do it, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that PEFT methods typically target computeconstrained scenarios, where finegrained control may require extra tuning, thus reducing practicality. The comment suggests including a plot comparing SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. This claim is 3 as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim about PEFT methods. The suggestion to include a plot is clear and actionable, but the claim about PEFT methods could be strengthened with more detailed reasoning or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim regarding the applicability of SGC, suggesting that PEFT methods, such as LoRA, are more practical in computeconstrained scenarios due to their need for extra tuning. The comment provides a specific suggestion to include a plot comparing SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. This visualization would help illustrate the practical performance benefits of SGC at different sparsity levels, offering a clear and actionable improvement for the paper. The feedback is detailed and constructive, making it 5 for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point provides several specific questions and suggestions for the authors to address. It asks for an example of synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggests explicitly writing down the model used in the appendix. These actions are clear and direct, allowing the authors to understand exactly what needs to be done to improve their draft. The comment is fully actionable as it provides concrete guidance on how to address the issues raised. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"synthetic data,\" \"Figure 1,\" and \"predicted training count data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear questions and suggestions for the authors to clarify and improve their work, such as asking for an example of synthetic data and explaining the meaning of \"support data\" and \"predicted training count data.\" This level of detail ensures that the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for the authors to clarify and improve their paper. It does not contain any subjective opinions or claims that require verification. The questions are logical and straightforward, guiding the authors to provide more context and detail. Therefore, this comment is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment provides specific questions and suggestions for the authors to address, such as asking for an example of synthetic data, clarifying the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggesting explicitly writing down the model used in the appendix. These requests are clear and actionable, offering the authors concrete guidance on how to improve their draft. By addressing these points, the authors can enhance the clarity and completeness of their work. Therefore, the comment is 4, as it provides valuable feedback that can significantly improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the originality of the paper, suggesting that the findings are similar to those reported in previous works, particularly in the context of NNbased clustering algorithms. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of their work could be improved to demonstrate novelty. The comment implies that the authors should consider expanding their analysis or providing a more detailed comparison with existing literature to highlight the unique contributions of their work. While the action is somewhat inferred, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the originality of the paper by questioning the novelty of the findings in the context of previous works, particularly NNbased clustering algorithms. It mentions that the findings are similar to those reported in previous works, especially in the context of simplified settings. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the originality of the findings, but without clear references to specific sections or parts of the paper, it is difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the findings are similar to those reported in previous works, particularly in the context of NNbased clustering algorithms, and that the paper does not contribute novelly to the understanding of this behavior with its simplified settings. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning whether the findings are similar to those reported in previous works, particularly in the context of NNbased clustering algorithms. It suggests that the paper does not contribute novelly to the understanding of the winnertakeall property, especially given the simplified settings used. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. While it identifies a potential weakness, it lacks actionable advice or detailed feedback, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits the comment\"s overall impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. The comment is explicit in its request for clarification and provides a specific direction for improvement. It instructs the authors to explain how the spatial arrangement of sensors might influence the process, which is a concrete action they can take to enhance the clarity of their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to elucidate the EEG token quantization process and to understand the role of the spatial arrangement of EEG sensors in this process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with a classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of ambiguity in the presentation of EEG topography plots in Figure 3, particularly regarding the EEG token quantization process. It suggests that the authors should provide more detail on this process, specifically questioning the role of the spatial arrangement of EEG sensors. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation. By addressing this suggestion, the authors can improve the interpretability of their results and provide a more comprehensive understanding of their methodology. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive if it included additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by NguyenTang et al. (AAAI\u201921). It implies that this discussion should be included when talking about various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide explicit guidance on how the authors should incorporate this information into their draft or suggest specific sections to address. The action is implicit and somewhat vague, as the authors need to infer that they should discuss moment matching and its relevance to DRL. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, lines 2230, where the discussion of distributional RL occurs. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue: the paper lacks relevant literature on using moment matching for DRL, suggesting that this should be discussed. The authors are informed about the specific area where the literature gap exists, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically mentioning the work by NguyenTang et al. (AAAI\u201921). The comment suggests that this discussion should be included when talking about various approaches to DRL, even though the paper currently uses quantile regression. However, the comment does not provide specific examples or detailed reasoning to support why moment matching is relevant or how it differs from quantile regression. While the suggestion is logical, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where additional literature could be discussed, particularly regarding the use of moment matching in distributional reinforcement learning. It provides a specific example of relevant work, referencing NguyenTang et al. (AAAI\u201921), which could enhance the paper\"s comprehensiveness and depth. However, the comment could be more helpful by suggesting how this additional discussion might impact the paper\"s overall argument or findings. While it offers a clear direction for improvement, the feedback is 4 as it provides actionable guidance for the authors to expand their discussion on DRL approaches. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, it does not provide explicit guidance on how to conduct this analysis or what specific steps the authors should take. The comment implies that the authors should consider adding this analysis, but it lacks concrete details on how to implement it. Therefore, the comment is 3, as it identifies a potential improvement but does not provide detailed instructions on how to achieve it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of local minima, particularly the approximation ratio, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggested improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that while the paper analyzes the convergence of Algorithm 1 to permutations as local minima, it does not delve into the quality of these local minima. The comment suggests that the authors should consider analyzing the approximation ratio of these local minima under certain assumptions, which is a valuable and actionable suggestion. By highlighting this gap, the reviewer provides the authors with a clear direction for enhancing their work. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or provided examples of relevant literature. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper does not provide insight into this aspect, which is important for task domain adaptation. However, the comment does not explicitly instruct the authors to address these questions or provide guidance on how to do so. The action is implicit and vague, as it leaves the authors to infer the need for more detailed explanations and examples. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questioning of the methodology and assumptions regarding morphologic segmentation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper does not provide insight into this aspect, which is important for task domain adaptation. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the paper does not provide insight into this aspect. Without these elements, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is barely verifiable, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises important questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It highlights a potential gap in the paper\"s discussion, noting that the authors assume morphologic segmentation will be invariant without providing insight into this aspect. This feedback is valuable as it points out a specific area where the paper could be strengthened by offering more detailed explanations or examples. However, the comment could be more helpful if it provided some guidance on how to address these questions or suggested specific areas where the authors could expand their discussion. Overall, the comment is 3, as it identifies a crucial aspect that needs further exploration, but it lacks depth and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a deficiency in the analysis of experimental results, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. While the comment identifies a gap in the analysis, it does not offer explicit guidance on how the authors should address this issue or what specific aspects of the results need further exploration. The action is implicit, as the authors are expected to infer that they should provide a more detailed analysis of the results. However, the lack of concrete suggestions or examples makes the comment somewhat vague and challenging for the authors to act upon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, providing a clear indication of what needs to be addressed. This level of detail helps the authors understand exactly where the issue lies and what kind of analysis is required. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or references to support the assertion. The authors are expected to infer that they should provide a more detailed analysis to address this issue, but the comment does not offer detailed guidance or examples to enhance the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the analysis of experimental results, specifically pointing out that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to enhance their analysis by delving deeper into the reasons behind the observed results. By suggesting a more thorough analysis, the comment provides a specific direction for improvement, which is valuable for the authors to address in their revisions. Therefore, the comment is 4, as it offers clear guidance on how to strengthen the analysis section of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to explicitly specify the labels for each dataset in section 4.1, including their source. It questions whether the labels are derived from the dataset itself or from additional information, particularly for caspealr1 and mugshot. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so or offer guidance on how to present the labels. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the labels and their sources. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions section 4.1, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is needed: the labels for each dataset in section 4.1, including their source (from the dataset itself or from additional information). This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to clarify the labels for each dataset in section 4.1, specifically questioning the source of these labels for caspealr1 and mugshot. While the comment is clear and specific, it does not provide any additional context or justification for why this clarification is necessary or how it would impact the paper. The authors are left to infer the importance of this clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of the paper that needs clarification, namely the labels for each dataset in section 4.1. It questions the source of these labels, particularly for caspealr1 and mugshot, which could be crucial for understanding the context and validity of the results. However, the comment lacks detailed guidance on how the authors might address this issue or what specific information they should provide. While it points out a potential area for improvement, it does not offer actionable steps or suggestions for the authors to take, making it 3 rather than fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit guidance or suggestions on how to address these issues or improve the clarity of the explanation. The authors are left to infer that they need to clarify the calculation of \u03bb and provide a clearer explanation of the ELLA\"s sample efficiency in COMBO environments. This lack of explicit and concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (Page 9, lines 310313 and Page 8, lines 281285), allowing the authors to accurately identify the parts being addressed. It also specifies what the authors need to understand, namely the process of calculating \u03bb and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. Additionally, the comment references specific papers [1], [2], and [3], which provides context and suggests further reading. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment lacks specific evidence or references to support these claims, making it difficult for the authors to understand the basis of the concern. The absence of detailed reasoning or examples makes the claim 3, as the authors may need to infer the basis of the concern themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment, referencing specific papers that could provide additional context. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the clarity of the explanation. While it identifies areas for improvement, it does not provide actionable steps or specific advice, making it 3. The authors would need to infer the need for clarification and additional context, which limits the comment\"s overall impact."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear understanding of how to respond to this critique and improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the novelty, it lacks grounding because it does not provide clear references or sections within the paper that the authors can focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the paper, suggesting that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance the novelty of their work. It does not provide actionable feedback or guidance on what aspects of the paper could be improved to differentiate it from existing methods. As a result, the comment is 3, as it highlights a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to expand the experiments or what additional baselines should be included. The authors are left with a general idea of what needs to be done but lack concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not specify which parts of the paper these issues are related to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues with the experiments, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments should be more comprehensive and general, specifically noting that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of these suggestions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiments section, noting that they should be more comprehensive and general. It highlights the limitations of the current experiments, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. This feedback provides a clear direction for the authors to enhance their experimental setup, but it lacks detailed guidance on how to achieve this comprehensiveness or generality. While the comment is 3 in pointing out areas for improvement, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using fewshot examples for ChainofThought (CoT). However, it does not provide explicit guidance on how the authors should conduct or present this ablation study. The action is implicit, as the authors need to infer that they should include an ablation study to justify their prompt choice. While the comment is 3, it lacks concrete details on how to implement the suggested improvement, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using fewshot examples for ChainofThought (CoT). However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental section. The comment is fully grounded in that it implies the authors should address this issue, but it is not specific about which part of the paper needs revision. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using fewshot examples for ChainofThought (CoT). However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of an ablation study explaining the choice of prompt, particularly the use of fewshot examples for ChainofThought (CoT). This feedback is 3 as it highlights a potential gap in the paper\"s analysis and suggests a way to strengthen the justification for the chosen methodology. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the ablation study or why fewshot examples might be beneficial. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment implies that the authors should consider whether the performance drop is significant enough to support the claim of \"better than random.\" However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to strengthen their argument. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"You write: \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance\"\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the claim that \"better than random\" is a strong demonstration of capability, providing a clear direction for the authors to consider and potentially address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"better than random\" is a strong demonstration of capability, specifically challenging the authors to consider whether the performance drop is significant enough. While the comment raises a valid point about the need for a more robust demonstration of capability, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the reasoning behind the critique, which makes the comment 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically challenging whether this demonstrates a strong capability. The comment is 3 as it identifies a potential weakness in the authors\" argument, prompting them to reconsider the significance of their results. However, it could be more helpful if it provided specific suggestions or guidance on how the authors might strengthen their demonstration of capability. Without actionable advice or examples, the feedback is limited in its ability to guide the authors effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the results in section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might extend their results to deeper networks or how they could improve the scope of their findings. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results in section 4 apply only to shallow fullyconnected ReLU networks, providing a clear and specific issue to address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. This is a specific observation that could be verified by examining the content of section 4. However, the comment does not provide any additional context, examples, or references to support this claim, making it 3. The authors would need to independently verify the claim by reviewing section 4 to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment points out a specific limitation in the results presented in section 4, noting that they apply only to shallow fullyconnected ReLU networks. This is a clear and actionable piece of feedback that highlights a potential constraint on the scope of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or expand their findings to include deeper networks. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. While the comment provides a clear direction for improvement, it lacks specific guidance on which aspects of the experiments need to be expanded or what specific types of additional experiments would be beneficial. The action is explicit but somewhat vague, as it does not detail the exact nature of the additional experiments or how they should be conducted. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment does not specify which part of the paper the experiments are related to, making it weakly grounded. It is specific in suggesting the need for more experiments, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas that require improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are not sufficient and suggests that more empirical or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment lacks specific details or examples of what kind of additional experiments would be beneficial or how they should be conducted. While the suggestion is logical and aligns with common practices in empirical research, the absence of detailed guidance or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the experiments are not sufficient to fully validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that additional empirical or toy experiments should be conducted to address this gap. While the comment provides a clear direction for improvement, it lacks specific guidance on the types of experiments that would be beneficial or how they should be designed. This leaves the authors with a general idea of what needs to be done but without detailed instructions, making the feedback 3. Therefore, the comment aligns with a score of 3, as it offers a clear but incomplete suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This comment provides a specific and explicit action for the authors to consider, as they can verify whether the operation is indeed necessary. The suggestion is clear and concrete, allowing the authors to understand exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the definition of the Frobenius norm, suggesting that the absolute value operation is not needed since tensor entries are real numbers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This claim is logical and verifiable as it is based on the understanding that the Frobenius norm is typically defined for realvalued tensors, where the absolute value is not necessary. The comment provides a clear reasoning for the suggestion, making it 4. However, it could be strengthened by explicitly stating that the Frobenius norm is defined for realvalued tensors, which would enhance the clarity and robustness of the justification. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a minor issue in the definition of the Frobenius norm, specifically pointing out that the absolute value operation might be unnecessary because tensor entries are real numbers. This feedback is clear and actionable, as it provides a specific suggestion for improvement. By highlighting this detail, the comment helps the authors refine their definition and ensure its accuracy. However, the comment could be more helpful if it provided additional context or examples to support the claim. Overall, the feedback is 4, as it offers a clear direction for improvement but could be expanded for greater depth and impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include an experiment where the image is occluded, similar to a previous suggestion. It provides two reasons for this suggestion: (a) to simulate irregularity in neural/behavioral data, such as keypoint detection failures, and (b) to allow the inspection of the model\"s longrange inference capacity. The comment implies that these experiments should be included in the final version of the paper, unless the authors can provide a reason for exclusion. However, the action is implicit, as the authors need to infer that they should run these experiments. The suggestion is somewhat vague in terms of how to implement the occlusion or how to analyze the results, making it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests an additional experiment involving occluding parts of the image, which is relevant to simulating irregularity in neural/behavioral data and assessing the model\"s inference capacity. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. It is specific in detailing the type of experiment and its potential benefits, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests an additional experiment involving occluding parts of the image, which is relevant to simulating irregularity in neural/behavioral data and assessing the model\"s inference capacity. The comment provides two reasons for this suggestion: (a) to simulate irregularity in neural/behavioral data, such as keypoint detection failures, and (b) to allow the inspection of the model\"s longrange inference capacity. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the relevance of the suggested experiment and its potential benefits, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests an additional experiment involving occluding parts of the image, which could simulate irregularity in neural/behavioral data and allow for the inspection of the model\"s longrange inference capacity. This feedback is specific and actionable, as it provides a clear direction for improving the paper by suggesting a new experiment that could enhance the understanding of the model\"s capabilities. However, the comment could be more helpful if it included details on how to implement the occlusion or how to analyze the results of the experiment. Despite this, the suggestion is 4 as it offers a concrete and valuable addition to the draft, guiding the authors to enhance their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 6C is awkward and implies negative rates, which is not the case. It recommends using a second yaxis or another visualization that is more physically accurate. While the comment provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit, as the authors can infer that they need to revise the figure to address the issue. However, the comment lacks concrete details on how to implement this suggestion, such as specific examples of how to use a second yaxis or another visualization. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 6C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates, which is not physically accurate. The suggestion to use a second yaxis or another visualization is a concrete and actionable step that the authors can take to improve the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 6C is awkward and implies negative rates, which is not the case. It suggests using a second yaxis or another visualization for better accuracy. However, the comment lacks specific examples or references to support the claim about the figure\"s accuracy. Without detailed evidence or examples, the claim is 3, as it provides a general suggestion but does not offer a thorough justification or detailed reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not physically accurate. It suggests using a second yaxis or another visualization to improve the figure\"s accuracy and clarity. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. However, the comment could be more helpful if it included examples of how to implement the suggested changes or additional context on why the current visualization is problematic. Despite this, the comment offers valuable guidance for enhancing the presentation of the data, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. While the comment identifies a specific area needing clarification, it does not provide explicit guidance on how to address this issue or what actions the authors should take to improve their draft. The action is implicit and vague, as the authors are left to infer how to enhance their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/f few training steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue, as it highlights the lack of consideration for how the method leverages the fewshot nature and ensures generalization. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically regarding how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. It does not provide a clear explanation of why the current approach is insufficient or how it could be improved. As a result, the claim is not verifiable, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. This feedback is valuable as it highlights a critical area that needs further clarification and justification. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues. While it points out a crucial weakness, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation. It suggests that using robotic manipulation in general might be more appropriate. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the methodology. The action is implicit, as the authors need to infer that they should provide more detail on the methodology\"s specificity. The action is vague because it lacks concrete steps on how to demonstrate the methodology\"s relevance to bimanual manipulation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion regarding the methodology\"s specificity, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. This feedback highlights a potential ambiguity in the paper, as it does not clearly define the scope or application of the methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the methodology\"s relevance. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this setting. However, the comment does not offer explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly what to do. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of the advantage of the UNIFORM procedure over other methods, specifically noting that the results are not always clear, especially in the 1shot setting. However, it does not specify which part of the paper this issue is discussed in, such as a particular table or section. The comment is specific in its critique of the results but lacks grounding as it does not provide explicit references to the sections or figures where the results are presented. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this setting. However, the comment does not provide any specific evidence, examples, or references to support the claim that the results are not always clear or that a theory is needed. This lack of substantiation makes the claim difficult to verify, as the authors may not have a clear understanding of why the method is not as effective in the 1shot setting. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of the UNIFORM procedure\"s advantage over other methods, particularly in the 1shot setting. It points out that the results are not always clear and suggests that the authors should provide a theory to explain why the method is not as effective in this setting. This feedback is 3 as it highlights a potential area for improvement and encourages the authors to delve deeper into the theoretical underpinnings of their method. However, the comment could be more helpful if it provided specific guidance on how to develop or test this theory or suggested additional experiments to address the issue. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main concerns: the confusion regarding the empirical analysis in Figure 3 and the large spacing in Equations (9) and (10). For the first concern, the authors are asked to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This action is explicit and concrete, as it clearly instructs the authors to provide detailed explanations. However, the comment does not specify how to address the confusion or what aspects of the analysis need clarification, leaving the authors to infer the necessary steps. For the second concern, the comment is explicit and concrete, instructing the authors to address the large spacing in Equations (9) and (10). This provides clear guidance on how to improve the presentation of the paper. Overall, the comment is 4, as it provides explicit instructions for addressing two distinct issues.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs clarification regarding the empirical analysis, particularly the adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score and their impact on model prediction accuracy. Additionally, the comment requests an explanation of why these adjustments are effective in enhancing the model\"s performance. This level of specificity provides clear guidance on what aspects of the analysis need clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two questions: one about the confusion regarding the empirical analysis in Figure 3 and another about the large spacing in Equations (9) and (10). The first question prompts the authors to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This is a request for explanation and clarification, which is a subjective claim. The second part of the comment is a factual observation about the formatting of Equations (9) and (10), which does not require verification. Therefore, the comment contains a subjective claim that is not fully supported by evidence, making it 2.", "helpfulness_rationale": "The review comment provides specific feedback on two distinct issues: the confusion regarding the empirical analysis in Figure 3 and the formatting of Equations (9) and (10). It requests additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This is a valuable suggestion that could help the authors improve the clarity and understanding of their empirical analysis. Additionally, the comment points out the large spacing in Equations (9) and (10), which could be addressed to enhance the readability of the paper. While the comment is clear and actionable, it could be more helpful if it provided specific guidance on how to address the confusion or formatting issues. Overall, the feedback is 4, as it offers clear directions for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not provide explicit instructions on how to improve the figure or what specific aspects need to be enhanced. The action is implicit and somewhat vague, as the authors are left to infer the exact changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to Figure 1, specifically mentioning the need to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what aspects of the figure need improvement, providing clear guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide specific examples, detailed explanations, or references to support why these improvements are necessary or beneficial. Without additional context or evidence, the claim remains 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving Figure 1, which could enhance the clarity and effectiveness of the paper. By suggesting that the figure should better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring, the comment offers actionable feedback that could help the authors improve the presentation of their work. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of how the figure could be improved. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and detail."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This comment provides a clear and explicit action for the authors to take: they should remove or define the abbreviations in the section header. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that abbreviations like \"MoCo\" should not appear in the section header, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This claim is 3 as it provides a logical reasoning for why the inclusion of such abbreviations could be problematic. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of abbreviations in the section header, noting that readers might not understand them. This feedback is clear and actionable, as it provides a direct suggestion for improvement. By recommending that abbreviations like \"MoCo\" should not appear in the section header, the comment helps the authors enhance the clarity and accessibility of their paper. However, the comment could be more helpful if it provided additional guidance on how to define or remove abbreviations effectively. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or what aspects of the analysis need to be clarified. The comment lacks explicit instructions or concrete examples, making it difficult for the authors to understand what needs to be improved. As a result, the comment is 1, as it does not provide actionable feedback that would help the authors improve their draft.", "grounding_specificity_rationale": "The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact issue. The comment lacks grounding as it does not provide specific references or sections of the paper that need attention. Additionally, it does not offer specific suggestions or guidance on how to improve the clarity of the technical contribution or the novelty of the analysis. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is unclear and that most of the analysis is standard. However, it does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the technical contribution of the paper, suggesting that it is unclear and that most of the analysis is standard. However, the comment lacks specific details or actionable suggestions on how the authors might address this issue. It does not provide guidance on what aspects of the analysis need clarification or how the authors can enhance the novelty of their contribution. Without concrete feedback or suggestions, the authors may find it challenging to improve their draft. Therefore, the comment is 2, as it points out a problem but does not offer substantial guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation as more tasks are added. However, the comment does not provide explicit guidance on how the authors might address this issue or what changes could be made to the method to incorporate a sparsity constraint. The action is implicit and vague, as it does not specify how the authors should implement or address the issue. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proposed method, noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in detailing the problem with the lack of a sparsity constraint, which could lead to increased factors and computation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint, which could lead to an increase in the number of factors and computation as more tasks are added. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation as more tasks are added, which is a significant concern. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or incorporate a sparsity constraint. While it highlights a potential problem, it lacks actionable advice, making it 3. The authors would need to infer how to improve their method based on this feedback, which limits the comment\"s overall impact."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a discrepancy in the regularization methods used for the LN model and the GLM, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to reproduce the features of previous models. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the regularization methods used in the LN model and the GLMs, specifically noting a discrepancy in the regularization techniques. It mentions the LN model needing regularization and then applying regularization in the form of a cropped stimulus to both LN models and GLMs. The comment also references the work of Pillow et al., which did not use L1 regularization but employed a lowrank approximation for the spatial filter. This provides a clear and specific reference to the issue, allowing the authors to understand the context and the specific aspect of the paper that needs attention. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, and it is specific because it details the discrepancy in regularization methods and suggests a way to make the comparison fair. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point raises a claim about a discrepancy in the regularization methods used for the LN model and the GLMs. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. The comment provides specific references to the work of Pillow et al., which did not use L1 regularization but employed a lowrank approximation for the spatial filter. This provides a basis for the claim, making it 3. However, the comment could be more robust if it included additional examples or a more detailed explanation of why reproducing previous models is important. Overall, the claim is 4, as it is supported by specific references and logical reasoning, but it could be strengthened with more detailed evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with the regularization methods used in the LN model and the GLMs, noting a discrepancy in the techniques employed. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. This feedback is clear and actionable, providing the authors with a specific direction to improve their work. However, the comment could be more helpful if it offered additional guidance on how to reproduce the features of previous models or suggested specific steps to take. Despite this, the comment is 4 as it directs the authors towards an important area of improvement, enhancing the overall quality of the paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not provide explicit instructions or suggestions on how to address these issues, such as suggesting alternative indexing or revisiting the calculation. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the indexing of the input x and the calculation of the sum of squares of the second layer weights, specifying exactly what needs to be clarified or corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not contain any subjective opinions or claims that require verification. The questions are factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment identifies specific issues in the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It points out that the input is a vector, not a matrix, and questions the correctness of the equation \u2211 k ( W k ( 2 ) ) 2 = 1 / d , instead of d. While the comment highlights areas that need clarification, it does not provide detailed suggestions or guidance on how to address these issues. The feedback is 3 as it directs the authors to specific areas of concern, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of terms like \"somewhat\" and \"good generative ability\" in the description of results, particularly in sections 4.3 and 4.4. It questions the accuracy of the results, noting that only 77% of the results list contains the ground truth logical forms. The reviewer also asks about the percentage of correct entities and relationships plugged in when no ground truth is available. While the comment identifies specific areas of concern and questions the accuracy of the results, it does not provide explicit guidance on how the authors should address these issues or what actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific sections of the paper, 4.3 and 4.4, making it fully grounded. It also specifies the issue with the use of terms like \"somewhat\" and \"good generative ability\" in the description of results, particularly concerning the accuracy of the results. The reviewer questions the accuracy of the results, noting that only 77% of the results list contains the ground truth logical forms. The comment also asks about the percentage of correct entities and relationships plugged in when no ground truth is available, providing specific guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the accuracy of the results presented in sections 4.3 and 4.4, specifically questioning the use of terms like \"somewhat\" and \"good generative ability.\" It highlights that only 77% of the results list contains the ground truth logical forms, which raises concerns about the reliability of the findings. The reviewer also asks about the percentage of correct entities and relationships plugged in when no ground truth is available, suggesting a need for clarification and further analysis. However, the comment lacks specific examples or references to support the claim that the results are not accurate or that the use of these terms is problematic. Without detailed evidence or examples, the claim is 3, as it provides a basis for concern but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the accuracy of the results presented in sections 4.3 and 4.4, specifically questioning the use of terms like \"somewhat\" and \"good generative ability.\" It highlights that only 77% of the results list contains the ground truth logical forms, which raises concerns about the reliability of the findings. The reviewer also asks about the percentage of correct entities and relationships plugged in when no ground truth is available, suggesting a need for clarification and further analysis. While the comment identifies a potential issue with the accuracy of the results, it does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out a critical area for improvement but lacks actionable advice, making it difficult for the authors to fully address the concerns. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include supervised baselines in their experiments, particularly for datasets of a certain scale. It provides a rationale for why this is important, explaining that full annotation is often available for datasets of this size and that it would be informative to compare selfsupervised methods to fully supervised pretrained networks. However, the comment does not explicitly instruct the authors on how to implement this suggestion, such as which specific baselines to include or how to compare the results. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for supervised baselines in the experiments, which is a specific part of the paper. It provides a clear rationale for why these baselines are important, explaining that they are relevant for datasets of a certain scale and that comparing selfsupervised methods to fully supervised pretrained networks would be informative. This level of detail helps the authors understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks supervised baselines, which is a reasonable suggestion given the scale of the datasets used in the experiments. The comment provides a rationale for why these baselines are important, explaining that full annotation is often available for datasets of this scale and that comparing selfsupervised methods to fully supervised pretrained networks would be informative. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the need for these baselines and understand the reasoning behind the suggestion, which aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why these baselines are important, particularly for datasets of a certain scale where full annotation is often available. The suggestion to include these baselines and compare them to fully supervised pretrained networks is actionable and would help the authors contextualize their findings. However, the comment could be more helpful if it provided specific examples of what these baselines might be or suggested particular methods for comparison. Overall, the feedback is 4 as it highlights a crucial aspect of the paper that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. It provides a specific reason for this suggestion, indicating that the histogram should include the multiplicities of labels. However, the comment does not explicitly instruct the authors to make this change or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should revise the definition of \"X\" and consider the implications for the histogram representation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and detailed explanation of why the term \"X\" should be a multiset instead of a set, explaining the need to include multiplicities of labels for accurate histogram representation. This level of detail helps the authors understand the specific issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"X\" in section 4 should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a logical reasoning by explaining that including the multiplicities of labels is necessary for the histogram to honestly represent such graphs. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in section 4, suggesting that the term \"X\" should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and actionable, as it provides a specific correction that the authors can implement to improve the accuracy of their representation. By addressing this issue, the authors can enhance the clarity and correctness of their work. The comment is 4 as it offers a clear direction for improvement, though it could be more comprehensive if it included additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing could be improved and recommends drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks for justification regarding the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides explicit suggestions for improvement, such as drawing a table and justifying assumptions, it lacks concrete guidance on how to implement these suggestions. The authors are left with a general idea of what needs to be done but without detailed steps or examples, making the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weaknesses/feedback\" and \"section 4.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the writing quality, suggesting improvements such as drawing a table to compare CoT prompting methods and questioning the assumption about error clusters. The comment also asks for justification regarding the selection criteria, which is a clear and specific request for clarification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the writing quality and suggests improvements, such as drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks for justification regarding the selection criteria in section 4.2, specifically why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides some reasoning and questions, it lacks detailed examples or references to support the claims fully. The feedback is 4, as it offers logical reasoning and suggests areas for improvement, but it could be more robust with additional evidence or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies areas for improvement in the paper, specifically suggesting that the writing could be enhanced by drawing a table to compare different CoT prompting methods across various dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and requests justification for the selection criteria in section 4.2, particularly why questions with more than 60 tokens and rationales with more than 5 reasoning steps were not chosen. While the comment provides clear suggestions for improvement, it lacks detailed guidance on how to implement these suggestions or expand on the reasoning behind the questions. The feedback is 3 as it offers actionable insights but could be more comprehensive with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of significance testing to support the claims made about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT4, and suggests that the authors should conduct significance testing to substantiate their claims. However, the comment does not provide explicit guidance on how to perform the significance testing or what specific statistical methods should be used. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines of the paper (line 486) and provides examples of claims made in the draft. It specifies what needs to be addressed by suggesting the inclusion of significance testing to support the claims about the differences between various methods. This provides clear guidance on how the authors can improve their draft, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors should conduct significance testing to support their claims about the differences between various methods, such as ChatGPT and GPT4. It provides specific examples and numerical data to illustrate the differences in scores. However, the comment lacks detailed reasoning or references to justify why significance testing is necessary or how it should be conducted. The authors are left to infer the need for such testing, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by pointing out the lack of significance testing to support claims about the differences between various methods. It provides specific examples, such as the comparison between ChatGPT and GPT4, and highlights the minimal differences in scores, making it difficult to determine if these differences are significant without proper testing. The comment suggests that the authors should conduct significance testing, including checking the distribution and accounting for multiple comparisons, to substantiate their claims. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and provides a clear path for addressing the issue. Therefore, the comment is 5, as it offers detailed guidance on how to enhance the rigor and validity of the paper\"s claims."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This provides a clear and explicit action for the authors to take, as they need to average their results over multiple runs to ensure the statistical significance of their findings. The comment is specific in its suggestion, detailing exactly what needs to be done to improve the statistical validity of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion, the absence of grounding limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This is a logical and common practice in scientific research to ensure the reliability and validity of results. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors would need to infer the need for averaging results based on common knowledge in the field. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that directly addresses a potential weakness in the paper, namely the lack of statistical rigor in the results. By averaging results over multiple runs, the authors can strengthen the reliability and validity of their findings, making the paper more robust and credible. This feedback is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not provide any specific suggestions or actions for the authors to take to address this concern. The comment lacks explicit guidance on how the authors might enhance the contribution or make the model more significant. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the limited contribution and incremental nature of the proposed model, but it does not specify which part of the paper this opinion pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the contribution or model are considered limited or incremental. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it lacks specific evidence or reasoning to support this claim. Without detailed examples or references to other works that might challenge the authors\" assessment, the claim remains subjective and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion about the limited contribution and incremental nature of the proposed model. While it identifies a potential weakness in the paper, it does not provide specific suggestions or actionable feedback on how the authors might address this issue or enhance the contribution of their work. The comment lacks depth and guidance, making it 3 as it highlights an area for improvement but does not offer a comprehensive solution. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the experimental setup, noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. While the comment identifies a potential issue with the experimental design, it does not provide explicit guidance on how the authors should address this discrepancy or what specific changes should be made to the evaluation methods. The action is implicit, as the authors need to infer that they should consider the differences between the two sets of benchmarks and potentially adjust their experimental design accordingly. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment addresses the experimental part of the paper, specifically mentioning Figure 4 and Figure 5, which contain different evaluation methods for OPE methods. However, it does not specify which sections of the paper these figures are located in, making it weakly grounded. The comment is specific in that it highlights a discrepancy in the experimental setup, suggesting that the differences between the two sets of benchmarks are significant. This provides clear guidance on what needs to be addressed, but the lack of explicit section references makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between two sets of evaluation methods used in the experimental part of the paper, specifically mentioning Figure 4 and Figure 5. While the comment highlights a potential issue with the experimental design, it does not provide any specific evidence, reasoning, or references to support the claim that the differences between the two sets of benchmarks are significant. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue in the experimental part of the paper, specifically noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. This observation raises a question about the consistency and comparability of the results presented in Figure 4 and Figure 5. While the comment highlights a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this discrepancy or improve the experimental design. The feedback is 3 as it points out a potential issue that needs attention, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the regularization term appears to be adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide explicit guidance on how to implement these suggestions or how to address the issue of the adhoc nature of the regularization term. While it identifies a potential area for improvement, the lack of detailed instructions or concrete steps makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the regularization term being adhoc and lacking theoretical support, suggesting that other statistics could be used instead of the mean and standard deviation. However, it does not specify which part of the paper discusses the regularization term or where the intuitive explanation is provided. This makes it difficult for the authors to pinpoint the exact section or figure that needs revision. While the comment is specific about the issue of the regularization term, it lacks grounding as it does not provide clear references or sections to focus on. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, suggesting that other statistics could be used instead of the mean and standard deviation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion that the regularization term is adhoc or lacks theoretical support. Without additional context or justification, the claim remains 3, as it lacks the necessary depth and clarity to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, noting that it appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide specific guidance on how to implement these suggestions or how to address the issue of the adhoc nature of the regularization term. While it points out a potential area for improvement, it lacks detailed feedback or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential area for enhancement but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several specific suggestions for improvement in the experimental section. It suggests that the authors should report average results over multiple runs to make the results more robust and easier to compare. It also recommends discussing the decision boundaries in Section 3.1 and clarifying the information presented in Figure 9. These suggestions are explicit and concrete, providing clear guidance on what actions the authors should take to enhance their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improvement in the experimental section, including the need to report average results over multiple runs, discussing decision boundaries in Section 3.1, and clarifying the information in Figure 9. However, it does not explicitly mention which part of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as reporting averages, discussing decision boundaries, and clarifying figure content. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of three parts, each providing specific suggestions for improvement in the experimental section. The first part suggests reporting average results over multiple runs, which is a standard practice in experimental evaluations. The second part recommends discussing decision boundaries in Section 3.1, which is a logical suggestion to enhance the understanding of the results. The third part asks for clarification on the information presented in Figure 9, which is a request for additional detail. While the suggestions are logical and common, they lack specific examples or references, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement in the experimental section, such as reporting average results over multiple runs to enhance the robustness and comparability of the results. It also suggests discussing the decision boundaries in Section 3.1 to provide a deeper understanding of the results. Additionally, it requests clarification on the information presented in Figure 9, which is a valuable feedback for improving the clarity and completeness of the paper. While the comment is clear and actionable, it could be more comprehensive by offering additional guidance on how to implement these suggestions. Overall, the feedback is 4, as it provides actionable insights that can significantly improve the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on the experimental evaluation, highlighting two main issues. First, it points out that the paper claims a distinction in the \"picking\" step but does not ablate it, suggesting that this aspect needs further investigation. Second, it criticizes the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and that the use of DEN is unclear, recommending that the authors use the same setup as in the original DEN paper for a fair comparison. The comment explicitly suggests actions to take, such as conducting an ablation study and ensuring a fair comparison, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Evaluation\" and \"Experiments on CIFAR,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the \"picking\" step, the lack of ablation, and the limited comparison on CIFAR, suggesting that the authors should conduct more extensive experiments and ensure a fair comparison with the DEN paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study for the \"picking\" step, which is a specific aspect of the experimental evaluation. It also criticizes the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and that the use of DEN is unclear. The comment suggests that the authors should use the same setup as in the original DEN paper for a fair comparison. However, the claim lacks detailed reasoning or specific examples to fully substantiate the critique, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the experimental evaluation, highlighting two main issues. First, it points out that the paper claims a distinction in the \"picking\" step but does not ablate it, suggesting that this aspect needs further investigation. Second, it criticizes the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and that the use of DEN is unclear, recommending that the authors use the same setup as in the original DEN paper for a fair comparison. This feedback is clear and actionable, offering specific suggestions for improvement, such as conducting an ablation study and ensuring a fair comparison. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the ablation study or how to ensure a fair comparison with the DEN paper. Overall, the comment is 4, as it provides valuable insights for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are explicit and concrete, as they clearly indicate what changes need to be made to the paper. The authors can directly apply these actions to improve the visual presentation of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are fully grounded as they explicitly mention specific parts of the paper, such as legends, axis labels, and captions, which allows the authors to accurately identify the sections that need improvement. The comment is also specific as it details what needs to be changed in these parts, such as increasing the font size and aligning it with the text size. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are based on common practices for enhancing the visual presentation of figures and tables, making them 3. However, the comment lacks detailed reasoning or references to support why these changes are necessary or beneficial. While the suggestions are logical and align with standard practices, the lack of specific examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are clear and actionable, as they directly address the need for improved visual presentation, which is crucial for the clarity and understanding of the paper. By making these changes, the authors can enhance the overall quality and impact of their work. Therefore, the comment is 5, as it offers concrete guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments, specifically mentioning Figure 2 of [1] which demonstrates a larger effect of removing highscoring images. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a comparison against Journey TRAK, particularly referencing Figure 2 of [1], which highlights a significant effect of removing highscoring images. This provides clear guidance on what needs to be addressed in the counterfactual experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a comparison against Journey TRAK in the counterfactual experiments, referencing Figure 2 of [1] which shows a larger effect of removing highscoring images. However, the comment lacks specific details on how this comparison should be implemented or what aspects of the comparison are crucial. It does not provide a clear rationale or evidence for why this comparison is necessary or how it would enhance the paper. As a result, the claim is 3, as it lacks sufficient justification and examples to fully support the suggestion.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending a comparison against Journey TRAK in the counterfactual experiments. It highlights a particular aspect of the comparison, referencing Figure 2 of [1], which demonstrates a larger effect of removing highscoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is actionable and constructive, as it guides the authors to include a relevant comparison that could strengthen their analysis and provide a more comprehensive understanding of their results. However, the comment could be more helpful if it offered additional guidance on how to implement the comparison or what specific aspects of the comparison should be emphasized. Overall, the comment is 4, as it provides a clear direction for improvement but could be expanded for greater depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF, such as the sufficient amount of training data points needed. However, it does not explicitly instruct the authors to include these results or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should add these results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the paper these discussions are in, making it weakly grounded. The comment is specific in its suggestion to include additional results, but the lack of grounding makes it difficult for the authors to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems are directly related to the algorithm design and wellknown properties of mutual information. It proposes that the authors should consider including sample complexitytype results for not returning NSF, such as the sufficient amount of training data points needed. This feedback is actionable and provides a clear direction for enhancing the theoretical analysis. However, it could be more helpful if it included specific examples or guidance on how to derive these results. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of definitions, it does not provide explicit guidance on how the authors should address this concern or clarify the definitions. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the definitions in the paper. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. It suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment does not specify which part of the paper contains these definitions or where the confusion arises. The authors cannot confidently determine which section or table is being addressed, making the comment weakly grounded. Additionally, while it highlights a potential issue with clarity, it does not provide specific guidance on how to address the lack of distinction or improve the motivation. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises doubts about the definitions in Table 1, specifically questioning the difference between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. However, the comment lacks specific examples or detailed reasoning to support the claim that the definitions are unclear or that the motivation is weak. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the clarity of definitions in Table 1, specifically questioning the distinction between \"anchorbased regression\" and \"regression in RepPoints\" in the context of RepPoints, RetinaNet, and ATSS. The reviewer suggests that the distinction between these methods is not clear and that the motivation for the work is weak. While the comment identifies a potential issue with the clarity of the definitions, it does not provide specific suggestions or detailed guidance on how the authors might address this concern. The feedback is 3 as it highlights an area that needs clarification, but it lacks depth and actionable advice, making it difficult for the authors to fully address the issue. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable suggestion that provides clear guidance on how the authors can improve their draft. By explicitly stating the need for clarification, the comment directs the authors to a specific area where they should make adjustments. The action is both explicit and concrete, as it clearly indicates what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. However, it does not specify which part of the paper this clarification is needed, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable piece of feedback that directly addresses a potential ambiguity in the paper. By providing a clear direction for improvement, the comment helps the authors enhance the clarity and precision of their work. However, the comment could be more helpful if it offered additional guidance or examples on how to clarify this point effectively. Overall, the feedback is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional suggestions. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to correct a specific error in the text, stating that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a concrete suggestion for improving the LaTeX formatting by placing the label after the caption. This direct and specific feedback allows the authors to easily identify the error and understand how to correct it. The comment is clear and actionable, providing both the correction and the method for implementation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 205,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the error, stating that \"it should be Fig. 1 instead of Fig. 5.1\" and provides a concrete suggestion for improvement regarding LaTeX formatting by recommending placing the label after the caption. This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should correct a specific error in the text, stating that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a suggestion for improving LaTeX formatting by placing the label after the caption. While the comment is factual and points out a specific error, it lacks detailed reasoning or references to support why this correction is necessary or how it impacts the paper. The suggestion for LaTeX formatting is clear and actionable, but the overall claim is 3 due to the lack of comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific error in the text, pointing out that \"it should be Fig. 1 instead of Fig. 5.1.\" It also provides a clear suggestion for improving LaTeX formatting by recommending placing the label after the caption. This feedback is actionable and constructive, as it directly addresses a factual error and offers a practical solution for improving the presentation of the paper. However, the comment could be more helpful if it included additional guidance on why this correction is necessary or how it affects the overall understanding of the paper. Despite this, the comment provides valuable insights that can significantly enhance the authors\" draft. Therefore, it is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not specify what aspects of the comparison need to be supplemented or what additional information would be beneficial. The comment lacks explicit guidance on how to enhance the comparison, leaving the authors uncertain about the exact actions to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not specify which part of the paper this comparison is located in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment does not provide specific guidance on what aspects of the comparison should be supplemented or what additional information would be beneficial. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it does not provide any specific reasoning, examples, or references to support why this comparison should be supplemented. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the result comparison between \"Iteratively greedy Search\" and \"random search\" on the model structure should be supplemented. However, it lacks specific guidance on what aspects of the comparison need to be supplemented or what additional information would be beneficial. The comment is vague and does not provide actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics\". This provides a clear and direct action for the authors to take, which is to correct the caption. The comment is specific and concrete, as it identifies the exact figure and the correct caption, allowing the authors to know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption from \"Node Dynamics\" to \"Edge Dynamics\". This provides the authors with precise guidance on how to improve the figure caption. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a factual correction based on the content of the figure caption. However, the comment does not provide any reasoning or evidence to support why the caption is incorrect or why the suggested correction is appropriate. Without additional context or justification, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the caption of Figure 7, which is a factual mistake. It provides a clear and actionable suggestion to correct the caption from \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is precise and directly addresses a minor but important detail that could improve the clarity and accuracy of the paper. By correcting this error, the authors can enhance the overall quality and readability of their work. Therefore, the comment is 4, as it offers a clear and actionable improvement that the authors can easily implement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pretraining for AMR parsing and generation. However, the comment does not explicitly instruct the authors to include these elements or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they should add case studies and error studies to their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including case studies and error studies to enhance the paper\"s effectiveness, providing an example of a case study in the context of graph pretraining for AMR parsing and generation. However, it does not specify which part of the paper should be addressed or how these studies should be integrated. The authors can infer that the feedback pertains to the methodology or results sections, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of case studies and error studies, but the absence of detailed guidance on implementation makes it somewhat grounded and specific. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pretraining for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed reasoning or references to support the claim that these studies would be beneficial. While the example provides some context, it does not fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pretraining for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed guidance on how to implement these studies or what specific aspects should be covered. While it offers a valuable suggestion for improvement, the feedback could be more helpful if it included more detailed examples or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also suggests that the improvement brought by SoRA compared to the baseline might be due to random fluctuations. The comment implies that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are actual improvements due to SoRA. While the action is implicit, it is clear and concrete, as it directs the authors to address the missing standard deviation information and clarify the results. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section of the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on what needs to be addressed: the lack of standard deviation information and the need to clarify which effects are within the range of standard deviation fluctuations and which are improvements due to the SoRA method. This level of detail helps the authors understand exactly what revisions are necessary. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided, which may lead to the conclusion that the improvement brought by SoRA compared to the baseline is due to random fluctuations. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also suggests that the improvement brought by SoRA compared to the baseline might be due to random fluctuations, and recommends clarifying which effects fall within the range of standard deviation fluctuations and which are actual improvements. This feedback is clear and actionable, as it provides a direct suggestion for the authors to address a missing piece of information and improve the clarity of their results. However, it could be more helpful if it included additional guidance on how to present the data or interpret the results. Overall, the comment is 4, as it offers valuable insights and actionable feedback that the authors can use to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. While the comment identifies a specific issue and provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this evaluation or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which consists of two major components: a generative shape model and a word parsing model. It highlights the lack of clarity regarding which component contributes to the performance gain. The comment suggests evaluating the proposed approach separately against baseline detection and parsing techniques to better support the claim. However, the comment does not specify which part of the paper discusses the proposed method or the evaluation of the components. This makes it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the issue of evaluating the components, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. However, the comment does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would strengthen the claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key issue with the proposed method, specifically questioning the contribution of each component to the performance gain. It suggests that the authors should evaluate the proposed approach separately against baseline detection and parsing techniques to better support their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their evaluation and strengthen their claims. However, the comment could be more helpful if it included additional guidance on how to conduct the evaluation or what specific metrics to use. Overall, the comment is 4, as it offers valuable insights and actionable feedback that the authors can use to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the method. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying a potential area for clarification or improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not provide any specific evidence, reasoning, or references to support why this is a concern or how it might affect the method. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the method\"s behavior without the Lipschitz Hessian assumption, which is a critical aspect of the paper. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or what changes could be made to the method. The comment lacks depth and actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer substantial guidance or suggestions for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind two specific design choices in Figure 1: the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide explicit or implicit suggestions on how the authors should address these questions or provide further justification for their design choices. The comment lacks concrete guidance on what needs to be done or how the authors can improve their draft. As a result, the comment is 1, as the authors are left without a clear path to follow to address the concerns raised. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what questions the authors should consider regarding the rationale behind two design choices in the figure. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. However, it does not provide any claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or reasoning to support the questions posed. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. While it prompts the authors to consider the reasons behind these choices, it does not provide any suggestions or guidance on how to address these questions or improve the draft. The feedback is 3 as it identifies areas for clarification, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that Table 4 is incomplete and should include results for all four datasets. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to the table. The comment is specific in its suggestion, detailing which part of the paper needs improvement and what should be included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the table should include results for all four datasets, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. While the comment identifies a specific issue with the table, it does not provide any reasoning or evidence to support why this is a necessary or important addition. Without additional context or justification, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct instruction on what needs to be addressed to improve the completeness and accuracy of their results. By specifying the exact issue and the necessary addition, the comment offers a clear path for improvement, making it 4. However, it could be more helpful if it suggested alternative ways to present the results or provided guidance on how to ensure the completeness of the table."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is explicit and provides a clear action for the authors to take, which is to include a gradient comparison between KL and PCC. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC)\" as key components of the paper. It also specifies the issue with the assumption that PCC is a more relaxed constraint compared to KL divergence, suggesting that the constraint strength should be defined by the gradient distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is 4 as it provides a logical reasoning and an example to support the claim, but it lacks specific references or detailed explanations of how the gradient comparison would be conducted. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence. It provides a logical argument based on the concept of constraint strength being defined by the gradient distribution, and it offers an example comparing KL divergence and MSE loss to illustrate the point. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim, which is a clear and actionable feedback for the authors. This feedback is 4 as it guides the authors to address a specific aspect of their work and improve its rigor. However, it could be more helpful if it included more detailed guidance on how to conduct the gradient comparison or provided additional examples. Overall, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the authors\" choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions in the context of limited information propagation speed. The reviewer suggests that the authors should explain why the lack of locality in the transformer model is not a concern. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the model need to be clarified. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the suitability of using a transformer model without locality bias, questioning whether it is the best option given the nature of neighborhood interactions and limited information propagation speed. However, the comment does not specify which part of the paper this concern pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the model choice, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the authors\" choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions and limited information propagation speed. The reviewer suggests that the authors should explain why the lack of locality in the transformer model is not a concern. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the authors\" choice is questionable or needs further explanation. Without these elements, the claim is difficult to verify, making the comment 2.", "helpfulness_rationale": "The review comment raises a concern about the authors\" choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions and limited information propagation speed. The reviewer suggests that the authors should explain why the lack of locality in the transformer model is not a concern. However, the comment lacks specific guidance or detailed reasoning to help the authors address this concern. It does not provide actionable steps or examples to clarify the issue, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not offer substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, it does not provide explicit instructions or detailed guidance on how to achieve this clarification. The action is implicit, as the authors need to infer that they should elaborate on the improvements of their method over ODA. While the comment is 3, it lacks concrete details on how to implement the suggested improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA, one of the methods of solving the MOIP problem,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors need to clarify how their presented method improves performance and computation speed compared to using ODA. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the paper regarding the performance and computation speed improvements of the presented method compared to ODA. It highlights that while the method may learn to imitate problemsolving methods, it does not clearly explain how it improves performance and speed. This feedback is 3 as it points out a specific area where the authors need to clarify their claims. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or if it offered examples of how the method achieves these improvements. Overall, the comment provides a clear direction for improvement but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that some figures are not selfexplanatory, specifically mentioning Figure 4 where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. While the comment identifies a specific issue with the figures, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to make the figures more selfexplanatory, but the comment lacks concrete instructions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies an issue with the figure, noting that the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some figures are not selfexplanatory, specifically mentioning Figure 4 where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. While the comment identifies a potential issue with the figures, it lacks specific examples or detailed reasoning to support the claim. The authors are left to infer the exact nature of the problem, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures, noting that some figures are not selfexplanatory. It provides a concrete example, mentioning Figure 4, where the lines \"No adapt or Finetune\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it directs the authors to improve the clarity and selfexplanatory nature of their figures. However, the comment could be more helpful if it offered suggestions on how to make the figures more selfexplanatory, such as adding labels or legends. Overall, the comment is 4 as it highlights a specific area for improvement and provides a clear example, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline [31, 33, *]. However, the comment does not specify how the authors should conduct this analysis or what specific aspects of the computational effort need to be addressed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide this analysis for a fair comparison with the baseline, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a complete lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This is a crucial aspect that needs to be addressed for a fair comparison with the baseline. However, the comment lacks specific guidance on how the authors should conduct this analysis or what specific aspects of the computational effort need to be considered. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction but could be more comprehensive with actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the analysis. While the authors can infer that they need to clarify the analysis and provide theoretical evidence, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, but it does not specify which part of the paper this analysis is discussed. The authors cannot confidently determine which section or figure this analysis is related to, making the comment weakly grounded. However, the comment is specific in detailing the issue of the lack of clarity in the analysis and the absence of theoretical evidence. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, noting that the trend is not clear across different model architectures and that no theoretical evidence is provided. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of concern in the paper, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It highlights that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. This feedback is valuable as it points out a gap in the analysis and suggests that the authors should consider expanding their discussion to include theoretical evidence or clarify the analysis. However, the comment could be more helpful if it provided specific guidance on how to address these issues or suggested alternative approaches. Overall, the comment is 3, as it directs the authors to areas that need improvement but lacks detailed actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the definition of approximation error is ambiguous and could be better clarified by providing a mathematical characterization. While the comment implies that the authors should provide a mathematical characterization, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to add a mathematical characterization. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the definition of approximation error is ambiguous and could be better clarified by providing a mathematical characterization. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the need for a mathematical characterization, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the definition of approximation error is ambiguous and suggests that it would be better to provide a mathematical characterization. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the definition is ambiguous or how a mathematical characterization would address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the definition of approximation error, noting that it is ambiguous and could be clarified with a mathematical characterization. This feedback is specific and actionable, as it suggests a concrete way to improve the clarity and precision of the paper. By recommending a mathematical characterization, the authors are provided with a clear direction for enhancing the presentation of their work. However, the comment could be more helpful if it included examples or further elaboration on how to implement the mathematical characterization. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the crossdomain recommendation setting. However, the comment does not provide any specific suggestions or guidance on how the authors might address this limitation or enhance their work. The authors are left without a clear understanding of what needs to be done to improve the technical contribution of their paper. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what aspects of the technical contribution are limited or how the authors might address this limitation. Without specific references or details, the authors cannot effectively respond to the comment. Therefore, this comment is rated as 1 and Not Specific.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited, as it does not offer significant technical contributions or extensions based on a typical model for the crossdomain recommendation setting. However, the comment lacks specific details or examples to support this claim. It does not provide any references or evidence to substantiate the assertion that the technical contribution is limited. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the lack of technical contribution and extension based on a typical model for the crossdomain recommendation setting. This feedback is clear and actionable, as it highlights a critical area where the authors could enhance their work. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this limitation or propose potential extensions. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, allowing them to focus on enhancing the technical contribution of their paper. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify which aspects of the discussion are missing or what specific areas need to be addressed. The comment lacks explicit guidance on how the authors should expand their discussion, making it somewhat vague and difficult for the authors to know exactly what to do. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, such as a specific section or paragraph. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its critique, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the extent of the issue or how to address it. Without additional information or references, the claim remains 3, as it is based on an assertion without clear evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of a comprehensive discussion of previous work on the topic. This feedback is valuable as it highlights an area where the authors could enhance the depth and context of their research. However, the comment could be more helpful if it provided specific suggestions or guidance on how to expand the discussion, such as mentioning particular areas of previous work that are relevant or suggesting ways to integrate those discussions into the paper. Without these details, the authors may struggle to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for improvement regarding the OT sample selection process described in section 2.4.3. It asks whether the process runs once or iteratively, whether the optimization of the loss in equation (10) and the solving of OT in equation (3) are conducted by turns iteratively, and suggests that adding more details and a flow chart would make it easier for readers to understand the whole process. Additionally, the comment questions the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment provides explicit questions and suggestions for improvement, it lacks concrete guidance on how to address these points or what specific actions the authors should take. The actions are implicit and require the authors to infer the necessary steps, making the comment 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the OT sample selection process in section 2.4.3, making it fully grounded as it explicitly mentions the section being discussed. It also specifies what needs to be addressed, such as whether the process runs once or iteratively, the iterative nature of optimization and OT solving, and the runtime for solving the entropic regularized discrete OT problem and OT sample selection. This level of detail provides clear guidance for the authors to improve their draft. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and whether the optimization of the loss in equation (10) and the solving of OT in equation (3) are conducted by turns iteratively. It also asks for the runtime of solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment does not provide specific evidence or references to support these claims, it raises important questions that could help the authors clarify their methodology and improve the clarity of their paper. The questions are logical and require the authors to provide more detailed information, making the comment 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises several important questions and suggestions for improvement regarding the OT sample selection process described in section 2.4.3. It asks whether the process runs once or iteratively, whether the optimization of the loss in equation (10) and the solving of OT in equation (3) are conducted by turns iteratively, and suggests that adding more details and a flow chart would make it easier for readers to understand the whole process. Additionally, the comment questions the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. These questions and suggestions are clear and actionable, providing the authors with specific areas to address and improve their draft. However, the comment could be more helpful if it included guidance on how to address these issues or provided examples of how to present the information more effectively. Overall, the comment is 4, as it offers valuable feedback that can significantly enhance the clarity and comprehensiveness of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While it implies that human evaluation is a good idea, it does not provide explicit instructions or guidance on how to implement this suggestion. The authors are left to infer that they should conduct a human evaluation, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to understand where to apply the suggestion. Additionally, the comment does not provide specific details on how to conduct a human evaluation or why it would be more convincing. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional justification or evidence, the claim remains unsubstantiated, making it difficult for the authors to understand why this suggestion is important or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. This feedback is valuable as it highlights a potential limitation in the current evaluation approach and suggests an alternative method that could provide more reliable results. However, the comment lacks specific guidance on how to conduct a human evaluation or why it would be more convincing. While it identifies an area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a clear direction but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment identifies these areas, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to motivate the applications and consider using streaming datasets. However, the lack of specific suggestions or examples makes the action vague and difficult to implement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s objective of designing fast label aggregation algorithms for a streaming setting, noting that it lacks motivation for the applications. It also points out that the empirical analysis uses static datasets, which limits the paper\"s usefulness. However, the comment does not specify which part of the paper discusses the motivation or the datasets used, making it weakly grounded. The comment is specific in identifying the issues with motivation and the use of static datasets, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting and that the empirical analysis uses static datasets, limiting the paper\"s usefulness. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that need attention, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. While the comment provides a general direction for improvement, it lacks specific guidance on which parts of the GAT training process need to be addressed or how the rewriting should be done. The authors are left with a broad understanding of what needs to be done but without concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"245,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences need rewriting for clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. However, the comment lacks specific details or references to support these claims. It does not provide any evidence or reasoning to justify why the GAT is trained with the whole model or why it needs to be reviewed by an English native speaker. Without this additional information, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the GAT training process, noting that it is trained with the whole model. It also suggests that the paper needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. While the comment points out a potential area for improvement, it lacks detailed guidance on how to address these issues or what specific changes might be necessary. The feedback is 3 as it highlights areas that need attention, but it does not provide actionable steps or suggestions for improvement, leaving the authors with a general idea of what to work on rather than a comprehensive roadmap. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should analyze the domain gap between datasets and discuss how this gap might affect the adaption of the method. It also recommends exploring the possibility of finetuning a pretrained model on synthetic data to enhance the value of the approach. While the comment provides explicit actions\u2014analyzing the domain gap and discussing its impact, as well as exploring finetuning on synthetic data\u2014the actions are somewhat vague. The authors are not given specific guidance on how to analyze the domain gap or what aspects to discuss. However, the comment does offer a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends exploring the possibility of finetuning a pretrained model on synthetic data to enhance the value of the approach. However, the comment does not specify which part of the paper addresses the domain gap or synthetic data, making it weakly grounded. The comment is specific in its suggestions regarding the analysis and exploration of the domain gap and finetuning, but without explicit references to sections or figures, it is weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends exploring the possibility of finetuning a pretrained model on synthetic data to enhance the value of the approach. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The suggestions are somewhat vague and do not provide a clear path for the authors to address the issues. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft by analyzing the domain gap between datasets and discussing its potential impact on the adaptation of the method. It also recommends exploring the possibility of finetuning a pretrained model on synthetic data to enhance the value of the approach. These suggestions are clear and actionable, offering the authors a direction for enhancing their work. However, the comment could be more helpful if it provided more detailed guidance on how to analyze the domain gap or what aspects to discuss. Overall, the feedback is 4, as it identifies areas for improvement and offers constructive suggestions, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue and suggests a direction for improvement, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer how to scale up the method. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and discusses the performance of the method with an increasing number of identities, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of performance degradation and suggests a potential solution by presetting the capacity to a small number. The comment provides clear guidance on how to address the scalability issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that performance degrades with an increasing number of identities. The reasoning is somewhat vague, as it does not provide detailed evidence or guidance on how to address the scalability issue. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the proposed method, noting that performance degrades as the number of identities increases. It provides a specific example from Table 3 (a) to illustrate this issue, which is valuable for the authors to understand the limitations of their method. The comment also suggests a potential solution by presetting the capacity to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the scalability issue. However, the comment could be more helpful if it offered additional guidance on how to scale up the method or explored alternative solutions. Overall, the comment is 4, as it identifies a significant area for improvement and provides a starting point for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the quantitative evaluation results, noting that Figure 3 only reflects middle outputs and Figure 4 compares final results with a single data sample. The comment suggests that the current evaluations are not convincing enough to confirm ModelAngelo\u2019s superiority to competitors and asks if a quantitative comparison on the final outputs is possible. While the comment identifies a specific issue with the evaluation, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the evaluation process. The action is implicit, as the authors would need to infer that they should include a quantitative comparison of final outputs. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the quantitative evaluation results and the comparison of final outputs. This provides clear guidance on how the authors should improve their evaluation process. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the quantitative evaluation results, specifically questioning whether the current evaluations are convincing enough to confirm ModelAngelo\u2019s superiority to competitors. It suggests that the evaluations only reflect middle outputs and that a comparison of final outputs with a single data sample is provided. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that the evaluations are insufficient. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique, rendering the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the quantitative evaluation results, noting that Figure 3 only reflects middle outputs and Figure 4 compares final results with a single data sample. This observation is insightful and highlights a potential gap in the evaluation process, as it questions the sufficiency of the current comparisons to confirm ModelAngelo\"s superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be more convincing, which provides a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct such a comparison or suggested specific metrics to consider. Overall, the feedback is 3 as it points out a critical area for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several areas where the paper lacks detail, making it difficult for the authors to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide explicit instructions or suggestions on how the authors should address these issues. While it identifies the areas needing more detail, it does not offer concrete guidance on how to improve the paper. Therefore, the comment is 3, as it points out specific areas for improvement but lacks detailed guidance on how to implement these suggestions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detail in the techniques, making it difficult to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This allows the authors to accurately identify the parts of the paper that need improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several concerns about the lack of detail in the techniques described in the paper, making it difficult to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide any references or logical reasoning to support these claims, making it difficult for the authors to address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of detail regarding the techniques used, which hinders the reproducibility of the results. It provides specific examples of areas where the paper lacks clarity, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not offer any suggestions or guidance on how the authors might address these issues or improve the clarity of their techniques. While it highlights the need for more detail, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars and more random trials to potentially eliminate random fluctuations in the results. While the comment provides explicit guidance on what should be added to the figure, it does not specify how to implement these changes or where to add them. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests improvements to Figure 1, specifically mentioning the need for error bars and more random trials to address potential random fluctuations. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed to enhance the figure, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with error bars and more random trials to address potential random fluctuations. However, it does not provide any specific reasoning, examples, or references to support why these changes would be beneficial or how they would impact the results. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion and how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improving Figure 1, such as adding error bars and conducting more random trials to address potential random fluctuations in the results. These suggestions are actionable and directly address a potential weakness in the figure\"s presentation. By offering concrete improvements, the comment empowers the authors to enhance the clarity and robustness of their results. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or why these changes are expected to improve the figure. Overall, the comment is 4 as it provides clear and actionable feedback, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. It also points out that Figure 1 lacks clarity regarding the correspondence of different learning rates and steps to the points in the graph. This feedback provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment suggests providing a brief introduction to energy models in the related work section, which is specific and actionable. It also highlights a lack of clarity in Figure 1 regarding the correspondence of different learning rates and steps to the points in the graph. This feedback is fully grounded as it explicitly mentions the related work section and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed in terms of providing context and clarifying the correspondence in the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. It also highlights a lack of clarity in Figure 1 regarding the correspondence of different learning rates and steps to the points in the graph. The comment provides specific references to related works, such as [1], [2], and [3], which support the suggestions. However, the reasoning could be more detailed, and the claim about the lack of clarity in Figure 1 could be strengthened with examples or further explanation. Overall, the comment is 4, as it provides some support but could be more comprehensive.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper, such as adding a brief introduction to energy models in the related work section and clarifying the correspondence of different learning rates and steps in Figure 1. These suggestions are actionable and offer clear guidance on how the authors can enhance the clarity and completeness of their work. However, the comment could be more helpful if it included additional details or examples to further clarify the suggestions. Overall, the feedback is 4, as it provides a solid foundation for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the FIITED approach, which relies on utilitybased eviction decisions. It suggests that this method might introduce biases, particularly by prematurely evicting valuable chunks due to their temporary high utility. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the approach. The action is implicit, as the authors would need to infer that they should consider alternative eviction strategies or incorporate additional factors to mitigate potential biases. The comment is 3 because it identifies a potential problem but lacks concrete steps for resolution. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the FIITED approach, which is described as utilitybased for determining chunk significance. It highlights a potential issue with relying solely on utility scores for eviction decisions, suggesting that this could introduce biases. However, the comment does not specify which part of the paper discusses the FIITED approach or the utilitybased method, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in identifying the issue with the eviction strategy, it lacks grounding as it does not provide clear references to the relevant sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that relying solely on utility scores for eviction decisions in the FIITED approach might introduce biases. The reviewer provides an example of how recent chunks might gain a temporary high utility, potentially leading to premature evictions of other valuable chunks. This claim is 3 as it offers a logical explanation of the potential issue, but it lacks specific examples or references to support the claim fully. The reasoning is clear, but additional evidence or references could strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the FIITED approach, which relies on utilitybased eviction decisions. It highlights that this method might introduce biases, particularly by prematurely evicting valuable chunks due to their temporary high utility. While the comment points out a specific concern, it does not provide detailed guidance or suggestions on how to address this issue or improve the approach. The feedback is 3 as it raises a valid point about potential biases, but it lacks actionable advice or specific recommendations for the authors to consider. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It notes that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific experiments or comparisons to include. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments and provide more detailed explanations to clarify the performance of the framework. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It mentions that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for quantitative experiments and comparisons between algorithms. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It suggests that the paper lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones, making it unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim, leaving the authors uncertain about the validity of the critique. Therefore, the claim is not 5, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by highlighting the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, the paper lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. This feedback is valuable as it directs the authors to areas where they need to provide more comprehensive evidence and analysis to support their claims. However, the comment could be more helpful if it suggested specific experiments or comparisons that the authors could include to address the identified gap. Overall, the comment is 3, as it provides a clear direction for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using styles like dashed lines or adding color to differentiate between the curves in Figure 2. While the comment provides a clear direction for improvement, it does not specify which curves need to be distinguished or how the styles should be applied. The action is explicit but somewhat vague, as it lacks detailed guidance on implementation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure by suggesting the use of styles like dashed lines or adding color to differentiate between the curves. This feedback is actionable and provides detailed instructions for the authors to follow. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 2 right is difficult to distinguish between different curves and recommends using styles like dashed lines or adding color. This is a subjective observation and suggestion for improvement, but it lacks specific reasoning or examples to support why this is an issue. The comment does not provide any evidence or references to back up the claim that the figure is difficult to distinguish, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between different curves. It provides a clear suggestion for improvement by recommending the use of styles like dashed lines or adding color to differentiate the curves. This feedback is actionable and directly addresses a potential weakness in the presentation of the figure, offering a concrete way for the authors to enhance its clarity. However, the comment could be more helpful if it provided additional context or suggestions for alternative visualization methods. Overall, the comment is 4 as it offers a clear and actionable improvement suggestion."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. It recommends toning down the introduction and suggesting that the task is more accurately described as a feedbackdriven QA in the form of a dialog. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to tone down the introduction or provide specific examples of what should be included. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the claims made in the introduction, suggesting that they are not aligned with the tasks and models described. It recommends toning down the introduction and suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment does not specify which part of the introduction is being referred to, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. The reviewer suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they do not align with the tasks and models described. It suggests that the authors should tone down the introduction and reconsider the characterization of the task as \"language learning,\" instead describing it as a feedbackdriven questionanswering task in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific direction for revising their introduction to better reflect the actual content of the paper. However, the comment could be more helpful if it included additional suggestions or examples to guide the authors in making the necessary changes. Overall, the comment is 4, as it offers a clear and constructive critique that empowers the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, it does not provide explicit guidance on how the authors should address this point or what changes might be needed in their draft. The action is implicit, as the authors would need to infer that they should consider the efficiency of their implementation or provide a rationale for their choice of framework. The comment lacks concrete details on how to implement or address this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Kernels are implemented with OpenAI\"s Triton, not CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains why the implementation choice is unnecessary due to engineering improvements. This provides the authors with a clear understanding of what needs to be addressed and why. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, the comment does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the claim and how it applies to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific implementation detail regarding the use of OpenAI\"s Triton instead of CUDA for kernels, noting that it is unnecessary due to wellknown engineering improvements. While the comment highlights a potential area for clarification or justification, it does not provide detailed reasoning or suggestions for how the authors might address this point. The feedback is 3 as it points out a potential issue that could be addressed, but it lacks depth and actionable guidance, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the zeroshot nature of the study and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides examples of tasks, such as \"walkerrun\" being harder than \"walkerwalk,\" and \"3prong task with both clockwise and counterclockwise rotations\" being sufficient for the target task. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the transferability and provide more information about the tasks. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the study and questions the transferability due to the difficulty of the source and target tasks. It provides examples of tasks, such as \"walkerrun\" being harder than \"walkerwalk,\" and suggests that the manipulation scenario with rotations might be sufficient for the target task. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues with the transferability and the complexity of the tasks, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the study and the transferability of policies due to the difficulty of the source and target tasks. It provides examples, such as \"walkerrun\" being harder than \"walkerwalk,\" and suggests that the manipulation scenario with rotations might be sufficient for the target task. However, the comment lacks specific references or detailed reasoning to fully support its claims. While the examples are logical, the absence of external references or indepth analysis makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the zeroshot nature of the study and suggests that the transferability of policies might be limited due to the difficulty of the source and target tasks. It provides examples, such as \"walkerrun\" being harder than \"walkerwalk,\" and suggests that the manipulation scenario with rotations might be sufficient for the target task. This feedback is 3 as it identifies a potential issue with the study\"s methodology and provides some context for the authors to consider. However, the comment could be more helpful if it offered specific guidance on how to address these concerns or suggested alternative approaches to improve the study\"s robustness. Overall, the comment is 3, as it highlights important areas for consideration but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting that the paper only compares ELF (the author\"s method) with a baseline without Mid Vision Feedback (MVF) but lacks a comparison with the image classification results of Mid Vision Feedback (MVF). This feedback suggests that the authors should include such a comparison to better demonstrate the contribution of their method. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors need to infer the need for a comparison and deduce the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of sufficient experimental demonstration of the contribution points, specifically highlighting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of comparison with the image classification results of MVF, which is crucial for demonstrating the superiority of the schema searched by ELF. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The comment suggests that this lack of comparison does not prove the superiority of the schema searched by ELF (the author\"s method) over the schema in MVF. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains 3, as it lacks the necessary depth and clarity to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It highlights the lack of comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for demonstrating the superiority of the schema searched by ELF (the author\"s method). This feedback is valuable as it directs the authors to include a more comprehensive experimental comparison, thereby strengthening the paper\"s claims. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects of the comparison should be included. Overall, the comment is 4, as it points out a critical area for improvement but lacks detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, especially concerning occupant comfort and energy efficiency. While the comment identifies a specific area that needs more attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to expand their discussion on the dataset types and their relevance to occupant comfort and energy efficiency. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This allows the authors to accurately identify the part of the paper that needs attention. The comment is also specific because it clearly specifies what the authors should cover, namely the types of activities and their relevance to occupant comfort and energy efficiency. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. This feedback is 3 as it highlights a specific area that needs improvement, but it lacks detailed guidance on how the authors might address this gap. The comment provides a clear direction for the authors to expand their discussion, but it does not offer specific suggestions or examples of how to incorporate this information into the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. It recommends using different notation to avoid this ambiguity. The comment is explicit in identifying the issue and provides a clear suggestion for improvement. However, it does not specify which parts of the paper use \"D\" for both purposes or how the authors should implement the change. While the action is clear, the lack of specific guidance on implementation makes it 3.", "grounding_specificity_rationale": "The comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, it does not specify which part of the paper uses \"D\" for both purposes, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to use different notation, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this confusion could arise or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the symbol \"D\" in the paper, suggesting that it might be confusing as it represents both the dimensionality of points and the dilation factor. This feedback is clear and actionable, as it points out a specific area where clarity could be improved. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue, such as suggesting alternative notations or providing examples of how the confusion might manifest. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not provide explicit guidance on how to detail the innovative aspects or what specific aspects need to be elaborated upon. The action is implicit and vague, as the authors are left to infer that they need to provide more details on the innovative aspects of the FRM. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not specify which part of the paper this comment is addressing, such as a specific section or figure. The comment is vague and does not provide any guidance on what needs to be detailed or how to elaborate on the innovative aspects. As a result, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Since the comment lacks specificity in detailing what needs to be addressed, it is not specific. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspects should be detailed. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the FRM is a simple combination of these attention mechanisms. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed FRM, suggesting that it is a simple combination of channel attention and spatial attention. It implies that the innovative aspects of the FRM should be detailed. However, the comment lacks specificity and does not provide concrete suggestions or guidance on how to elaborate on the innovative aspects. Without additional details or examples, the authors may struggle to understand what specific aspects need to be detailed or how to improve the presentation of the FRM. Therefore, the comment is 2, as it provides a general observation but lacks actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" claim about the lack of negative social impact, suggesting that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method. While the comment provides a clear direction for the authors to address the issue, it does not specify which part of the paper should be revised or how to incorporate these suggestions. The action is explicit but somewhat vague, as it lacks detailed guidance on how to implement the changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the societal impact of the work, specifically questioning the authors\" claim that there are no negative social impacts. However, it does not specify which part of the paper this claim is made or where the authors should discuss the potential social impacts. The comment is weakly grounded as it does not provide explicit references to sections or parts of the paper, making it difficult for the authors to pinpoint the exact area that needs revision. It is specific in that it suggests considering the social impact of increased automation and the risks from dual use, but without grounding, the authors may struggle to apply this feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim that their work has no negative social impact, suggesting that this claim is questionable and that the authors should consider mentioning the social impact of increased automation or the risks from the dual use of their method. The comment provides a logical reasoning by questioning the authors\" assertion and offering potential areas for discussion. However, it lacks specific examples or references to support the claim, making it 3. The authors would benefit from providing more detailed reasoning or evidence to substantiate their claim or to address the reviewer\"s concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim regarding the lack of negative social impact of their work. It questions the authors\" assertion and suggests that they should consider discussing the potential social impact of increased automation or the risks associated with the dual use of their method. This feedback is 3 as it provides a direction for the authors to address a potential weakness in their work. However, the comment could be more helpful if it offered specific examples or guidance on how to incorporate these considerations into the paper. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the applicability of the methods to realworld problems due to strong assumptions about camera parameters and object segmentation. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might relax these assumptions or improve the methods to be more applicable to realworld scenarios. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the strong assumptions made about camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper discusses these assumptions or how they impact the applicability of the methods. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment identifies a specific issue, it does not provide detailed guidance on how to address it or what changes might be necessary. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the applicability of the methods to realworld problems is limited due to strong assumptions about camera parameters and object segmentation. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods to realworld problems, specifically due to strong assumptions about camera parameters and object segmentation. This feedback is clear and actionable, as it highlights a critical area for improvement in the paper. However, the comment could be more helpful if it provided suggestions on how the authors might address these limitations or relax the assumptions to enhance the methods\" applicability. Despite this, the comment offers valuable insight into a significant issue that needs attention, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor, specifically in terms of epsilon. It does not provide explicit instructions or suggestions on how the authors should address this issue, such as whether they should explore theoretical bounds or conduct additional experiments. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its inquiry about the theoretical effect and error bounds, but it lacks grounding as it does not mention specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. It does not provide any claims or opinions, but rather poses a question that could be addressed with further analysis or experimentation. Since the comment does not include any supporting evidence or reasoning, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. It highlights a potential area for further clarification or investigation, which could be valuable for the authors to address. However, the comment lacks actionable suggestions or guidance on how the authors might explore this issue or what steps they could take to address it. Without specific advice or suggestions, the comment is 3 as it identifies a potential area for improvement but does not provide a comprehensive or detailed response. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify what additional evidence or reasoning should be included, nor does it provide concrete guidance on how to achieve this. The comment is vague and lacks explicit instructions, making it difficult for the authors to understand what action to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is vague and lacks specificity, as it does not detail what evidence or reasoning should be included. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to address it. Without additional context or references, the claim remains vague and challenging to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the authors should provide more evidence or reasoning to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specificity and does not offer detailed guidance or suggestions on how to achieve this. It is vague and does not provide actionable feedback, making it 2. The authors are left without a clear understanding of what additional information or reasoning is needed to strengthen their claims. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This provides a clear and explicit action for the authors to take, which is to include a description of the form of p near the specified line. The comment is concrete, as it directs the authors to a specific location in the paper where the description should be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the form of p should be described near line 135, which provides full grounding as the authors can accurately identify the specific location in the paper. It is also specific because it clearly specifies what needs to be addressed, namely the description of the form of p. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This claim is 3 as it provides a specific location in the paper where the description should be included, but it lacks detailed reasoning or examples to fully support the suggestion. The authors are guided to address a specific issue, but the comment could be more robust with additional context or justification. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the form of p should be described near line 135. It acknowledges that the authors assume p is a Gaussian distribution but do not explicitly state it, which is a clear and actionable piece of feedback. By directing the authors to a specific location in the paper where this description should be included, the comment offers a concrete step to enhance the clarity and completeness of their draft. This feedback is 4 as it provides a clear direction for improvement, but it could be more comprehensive if it suggested additional areas for enhancement. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" discussion of regret, specifically asking if the prediction error over the entire horizon T cannot be sublinear. It implies that the authors should clarify their discussion of regret, but it does not provide explicit instructions on how to do so. The action is implicit, as the authors need to infer that they should clarify their discussion of regret. However, the comment lacks concrete guidance on what specific aspects of the discussion need clarification or how to address the issue. Therefore, the comment is 3, as it provides a clear area for improvement but does not offer detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 3237 of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies the issue with the discussion of regret, questioning whether the prediction error over the entire horizon T cannot be sublinear. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the authors\" discussion of regret, specifically asking if the prediction error over the entire horizon T cannot be sublinear. This is a subjective question that requires the authors to clarify their discussion. However, the comment does not provide any evidence, reasoning, or references to support the claim that the authors are discussing sublinear regret. Without additional context or justification, the claim is difficult to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper regarding the discussion of regret. It questions whether the authors are discussing the sublinear nature of the prediction error over the entire horizon T, which is a critical aspect of the paper\"s theoretical analysis. While the comment highlights a potential area of ambiguity, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a specific area that needs clarification, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment does not explicitly instruct the authors to run the suggested experiment or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the doubly stochastic construction and the use of VGAE with a vamp prior, which are relevant to the paper. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. This provides clear guidance on what needs to be addressed in the paper, making it fully grounded. The comment is specific in detailing the issues and suggestions, such as the potential benefits of using a vamp prior and the need for a clearer comparison of representations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks specific examples or references to support the claim that this approach would provide a more accurate comparison. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. This is a valuable point that could guide the authors in refining their model or inference process. Additionally, the comment provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks specific guidance or detailed suggestions on how to implement these changes, which limits its helpfulness. While it offers some insight, the feedback could be more comprehensive and actionable to fully assist the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the necessity of longrange dependencies for powerful predictors in the context of semantic segmentation. It suggests that the paper should discuss whether locality with respect to the 2D image space is encoded in the graph structure and how this might affect prediction. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paper opens that learning longrange dependencies is important for powerful predictors,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the necessity of longrange dependencies in the context of semantic segmentation and suggests a discussion about the balance between locality and longrange dependencies. The comment is specific in its critique and provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of longrange dependencies in the context of semantic segmentation, suggesting that the paper should discuss the balance between locality and longrange dependencies. However, the comment lacks specific examples or references to support the claim that the paper does not adequately address this issue. Without detailed reasoning or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some basis for discussion but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a pertinent question about the necessity of longrange dependencies in the context of semantic segmentation, specifically questioning whether locality with respect to the 2D image space is encoded in the graph structure. This feedback is 3 as it identifies a potential area for further discussion and exploration, which could enhance the paper\"s depth and clarity. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as suggesting additional experiments or analyses. Without concrete recommendations, the authors may find it challenging to fully understand and incorporate the feedback into their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the observed performance degradation compared to standard random features. While the comment identifies specific issues, it does not provide explicit guidance on how the authors should address these concerns or what actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific issues related to the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also mentions the observed performance degradation compared to standard random features, which could indicate a weakness in the proposed approaches or theoretical results. However, the comment does not explicitly mention specific sections, tables, or figures that need attention, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues that need to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact parts of the paper that require revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the paper, including the lack of clarity regarding the term $e_l$ in Eq. (3), the exponential dependence of the results on the diameter $M$ of the data domain, and the observed performance degradation compared to standard random features. The claim about the exponential dependence is supported by the mention of Corollaries 1, 2, and 3 and Theorem 4, which all have exponential dependence on $M$. However, the claim about the performance degradation is based on the observation in Figure 1, which provides some visual evidence but lacks detailed explanation or references to support the claim fully. Therefore, the comment is 4, as it provides some evidence but could be strengthened with more detailed reasoning or references.", "helpfulness_rationale": "The review comment identifies specific issues in the paper, such as the lack of clarity regarding the term $e_l$ in Eq. (3) and the exponential dependence of the results on the diameter $M$ of the data domain. It also points out the observed performance degradation compared to standard random features, suggesting a potential weakness in the proposed approaches or theoretical results. While the comment provides some insights into areas that need improvement, it lacks detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it highlights important areas for attention, but it could be more comprehensive with additional recommendations or detailed explanations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the authors\" explanation of the poor longrange modelling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The comment implies that the authors should consider discussing oversmoothing, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment addresses the poor longrange modelling ability of DGNs, specifically mentioning oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific paper to support the claim about oversmoothing. However, the comment does not explicitly mention which part of the paper it is addressing, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the part of the paper being discussed. The comment is specific in detailing the issue and suggesting an additional factor to consider, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modelling ability of DGNs could be due to oversmoothing, in addition to oversquashing and vanishing/exploding gradients, referencing a specific paper. This claim is 3 as it provides a logical reasoning by referencing a specific paper that discusses oversmoothing in the context of deep graph networks. However, the comment could be more robust by providing a brief summary or explanation of the paper\"s findings or by including examples of how oversmoothing affects the performance of DGNs. Overall, the claim is 4, as it is supported by a reference but lacks some depth in explanation or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the authors\" explanation of the poor longrange modelling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. It references a specific paper to support the claim about oversmoothing, which provides a basis for the authors to consider this factor in their analysis. However, the comment does not offer detailed guidance on how the authors should address this issue or incorporate the additional factor into their discussion. While it points out a potential area for improvement, it lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use longterm storage through pose graphs in SLAM, like those discussed in the appendix. However, the comment does not provide explicit guidance on how to incorporate this discussion into the paper or what specific aspects of the proposed method should be compared. The action is implicit and somewhat vague, as the authors are left to infer how to implement the suggested discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"general ideas\" and provides specific examples of methods that are already present in other approaches, such as topological reasoning using generalized Voronoi graphs or semantic maps, and longterm storage through pose graphs in SLAM. It also references the appendix section on graphbased SLAM, which provides additional context. The comment is specific because it clearly specifies what needs to be addressed by discussing the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some general ideas are already present in other methods for exploration, specifically mentioning topological reasoning and longterm storage through pose graphs in SLAM. The comment provides specific examples of these methods, such as those using generalized Voronoi graphs or semantic maps, and references the appendix section on graphbased SLAM. This level of detail and specificity supports the claim, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific methods, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that some general ideas are already present in other methods for exploration, such as topological reasoning and longterm storage through pose graphs in SLAM. It suggests that the paper should discuss the proposed method in relation to these existing methods, which could provide valuable context and enhance the paper\"s contribution. However, the comment lacks specific guidance on how to incorporate this discussion or what aspects of the proposed method should be compared. While it offers a clear direction for improvement, the feedback could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is 3, as it identifies an important area for improvement but does not fully guide the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide explicit guidance on which parts are vital or how to address this issue. The comment implies that the authors should clarify the discussion, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment also suggests that the discussion is necessary but does not provide specific guidance on what needs to be discussed or how to distinguish the paper from related work. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the assertion that the discussion is necessary. Therefore, the claim is considered 2, as it provides some context but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the importance of different parts of the framework in using CLIP for weakly supervised learning. It suggests that the discussion is necessary but does not provide specific guidance or examples to help the authors address this issue. While the comment identifies a potential area for improvement, it lacks depth and actionable suggestions, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its helpfulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining content and style more broadly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic.\" However, the comment does not provide explicit guidance on how to define content and style, nor does it offer concrete steps on how to address the ambiguity surrounding the meaning of \"style.\" The action is implicit and vague, leaving the authors uncertain about how to implement the suggested changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic.\" However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. While the suggestion is specific about the need for broader definitions, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the definitions of content and style in the context of a specific neural application, referencing Gabbay & Hosehn (2018). It suggests that style should be instancespecific and includes information transferable among groups. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed explanation or references makes the claim 3, as it lacks sufficient evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the definitions of content and style in the context of the authors\" specific neural application, referencing Gabbay & Hosehn (2018). It highlights the need for a broader understanding of these concepts, particularly in relation to instancespecific style and information transferability among groups. The comment also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic,\" which could help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided specific examples or suggestions for how to address these issues. Overall, the feedback is 3 as it identifies areas for improvement but lacks detailed guidance, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific examples and comparisons to support the claim that the analysis of vit quantification could be explained in depth. It highlights discrepancies in the variance difference between the proposed approach and the baseline, and mentions that the quantization of MHSA introduces a large loss of precision, a finding already established in other models. However, the comment does not explicitly instruct the authors to provide a detailed explanation of the vit quantification analysis or to address the discrepancies and the loss of precision. While the authors can infer that they need to expand on the analysis, the action is somewhat vague and lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Line 45 and Figures 1(b) and 5(b), allowing the authors to accurately identify the sections being addressed. It also specifies what needs to be addressed, namely the depth of the analysis of vit quantification and the discrepancies in variance differences and the loss of precision in MHSA quantization. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, providing specific examples and comparisons to support this claim. It highlights discrepancies in variance differences and the loss of precision in MHSA quantization, referencing findings in other models like QBERT and Q8BERT. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors would need to infer the basis for the claim, which could be improved with more explicit evidence or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed analysis of the paper\"s claims regarding vit quantification, offering specific examples and comparisons to support the argument that the analysis could be explained in depth. It highlights discrepancies in variance differences and the loss of precision in MHSA quantization, referencing findings in other models like QBERT and Q8BERT. This feedback is 4 as it provides clear insights into areas where the paper could be improved, offering actionable suggestions for the authors to enhance the depth and clarity of their analysis. However, it could be more helpful if it included specific recommendations on how to address these issues or provide additional context. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the paper. The action is implicit, as the authors would need to infer that they should clarify the source of the reward and provide more detailed explanations of the network model. While the comment is 3, it lacks concrete details on how to implement the suggested improvements, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of Eq. 12, specifically regarding the source of the reward at each trial and whether it is derived from Eq. 11. It suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. The comment is specific in its request for clarification and suggestions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of Eq. 12 and suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely Eq. 12, where the source of the reward at each trial is unclear. It also suggests that explaining the network model in Sec. 4.2 with equations would enhance clarity. However, the comment lacks detailed guidance on how to address these issues or what specific changes should be made to the paper. While it points out areas for improvement, it does not provide actionable steps or detailed suggestions, making it 3. The feedback is 3 as it highlights areas that need clarification, but it could be more comprehensive with additional guidance on how to improve the clarity of the equations and the network model explanation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\". This is an explicit action that the authors can directly implement by making the correction in the specified location. The comment is clear and provides a concrete instruction, allowing the authors to know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, \"Ln 32 on Page 1,\" allowing the authors to accurately identify the section being addressed. It is also specific because it points out a minor grammatical error, \"Empiically\" should be \"Empirically,\" which is a clear and actionable suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\". This is a factual correction that does not require any additional reasoning or references to be understood. The comment is clear and provides a specific suggestion for improvement, making it 5. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment identifies a minor grammatical error in the text, specifically pointing out that \"Empiically\" should be corrected to \"Empirically\". This is a clear and actionable suggestion that the authors can easily implement to improve the accuracy and clarity of their writing. While the comment is brief, it provides a specific and direct feedback that can enhance the quality of the paper. Therefore, the comment is 3, as it offers a clear and actionable improvement, but it could be more comprehensive if it suggested additional areas for revision or provided more detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, it does not provide any specific guidance or suggestions on how the authors might address these issues or improve the novelty of their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, it does not specify which part of the paper discusses the novelty or the new metric/method, making it difficult for the authors to identify the exact sections that need attention. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail what aspects of the novelty or methods are lacking. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is not enough and that both the new metric and method are straightforward. However, the comment lacks specific details or examples to support this claim. It does not provide any references or evidence to substantiate the assertion that the novelty is insufficient or that the methods are straightforward. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the novelty of the idea and suggests that both the new metric and method are straightforward. However, it lacks specific details or actionable feedback on how the authors might address these issues or enhance the novelty of their work. The comment provides a general critique but does not offer concrete suggestions or guidance on how to improve the draft. As a result, the feedback is 3, as it points out areas for improvement but does not provide a comprehensive or detailed response. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential issue with the clarity of the \"bold\" text in Figure 2, suggesting that it might be difficult to see. However, it does not provide explicit guidance on how to address this issue, such as recommending a different color or font size. The comment is somewhat vague and lacks concrete details on how to improve the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the \"bold\" text being hard to see, suggesting improvements such as using another color or a bigger font. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales is not a simple problem, particularly for complex NLP tasks like machine translation. It also notes that the paper is wellorganized and easy to follow, but points out that Figure 2 is cluttered and the \"bold\" text is difficult to see. The comment suggests that using another color or a bigger font could improve the visibility of the text. However, the claim about the complexity of identifying rationales lacks specific evidence or references to support it. The feedback is 3 as it provides a clear observation about the figure\"s clarity but does not offer detailed reasoning or examples to substantiate the claim about the difficulty of identifying rationales. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the \"bold\" text in Figure 2, suggesting that it might be difficult to see. While the comment points out a specific aspect of the paper that could be improved, it does not provide broader guidance or suggestions for enhancing the overall presentation or organization of the paper. The feedback is 3 as it highlights a minor issue that could impact the readability of the paper, but it lacks depth and does not offer actionable advice for addressing the problem. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, as shown in \"3)\". It also points out that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that similar tradeoffs could be explored by changing hyperparameters in Decouple [Kang et al.]. The comment encourages the authors to continue this line of work for future submission. However, the comment does not provide specific guidance on how to address these issues or what changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3)\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies what needs to be addressed, namely the performance comparison with Decouple [Kang et al.] and the tradeoff between head and tail categories. The comment also suggests that similar tradeoffs could be explored by changing hyperparameters in Decouple [Kang et al.], providing specific guidance on how to improve the analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance, as shown in \"3)\". It also notes that Table 5 demonstrates a tradeoff between head and tail categories but does not fully investigate this tradeoff for the baselines, suggesting that similar tradeoffs could be explored by changing hyperparameters in Decouple [Kang et al.]. This claim is 3 as it provides a logical reasoning based on the performance comparison and suggests a potential area for further investigation. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights that the tradeoff between head and tail categories is not fully investigated for the baselines, suggesting that similar tradeoffs could be explored by adjusting hyperparameters in Decouple [Kang et al.]. This feedback is valuable as it provides a clear direction for improvement, encouraging the authors to conduct further analysis and potentially enhance the performance of their approach. However, the comment could be more helpful if it offered specific guidance on how to address these issues or suggested additional experiments to explore the tradeoffs. Overall, the comment is 4, as it provides actionable feedback that aligns with the concerns raised in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions about the notation and assumptions in the paper. It suggests that the authors should clarify the function pi and explain why the dimensions of X and pi(X) do not match due to the removal of the noop action. It also questions whether it would be simpler to assume the first column of X_t is always 0. These questions provide clear and explicit guidance on what needs to be addressed, making the comment 5. The authors know exactly how to apply the feedback to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 75 of the paper, allowing the authors to accurately identify the section being addressed. It also specifies the issue with the notation and assumptions regarding the function pi and the dimensions of X and pi(X), as well as the question about the noop action. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises questions about the notation and assumptions in the paper, specifically regarding the function pi and the dimensions of X and pi(X). It also questions the rationale behind dropping the noop action. While the questions are logical and based on common knowledge in the field, they do not provide specific references or detailed reasoning to support the claims. The feedback is 3 as it offers clear points for clarification but lacks depth in terms of evidence or examples. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on the notation and assumptions in the paper, particularly regarding the function pi and the dimensions of X and pi(X). It questions the rationale behind dropping the noop action and suggests an alternative approach by assuming the first column of X_t is always 0. This feedback is clear and actionable, offering the authors specific areas to address and improve their draft. However, it could be more helpful if it included additional suggestions or elaborated on the implications of the changes. Overall, the comment is 4, as it provides valuable insights and guidance for the authors to enhance their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" However, the comment does not provide explicit guidance on how to conduct this comparison or what aspects of the comparison should be highlighted. The action is implicit, as the authors need to infer that they should perform a comparative analysis, but it lacks concrete details on how to implement this comparison. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment suggests comparing the proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" However, it does not specify which part of the paper this comparison should be made or how it should be conducted. The authors cannot confidently determine which section or part of the paper this comment addresses, making it weakly grounded. The comment is specific in suggesting a comparison with a particular existing model, but the lack of grounding makes it difficult for the authors to understand the exact context of the suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This claim is 3 as it provides a specific example of a comparison that could be made to strengthen the paper. However, it lacks detailed reasoning or references to support the suggestion comprehensively, which could make it difficult for the authors to fully understand and implement the comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests comparing the proposed model with existing models that use answers as inputs, specifically mentioning \"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\" This feedback is 3 as it identifies a potential area for comparison that could enhance the paper\"s contribution. However, the comment lacks depth and does not provide specific guidance on how to conduct the comparison or what aspects of the existing models should be considered. Without more detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests an ablation study on the number of layers versus performance, which is an interesting idea. However, it does not provide explicit guidance on how to conduct this study or what specific aspects of performance should be analyzed. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply this suggestion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests an ablation study on the number of layers versus performance, which is a specific and actionable suggestion. However, it does not specify which part of the paper this study should be conducted in or how it relates to the overall content. The authors can infer that it might be relevant to the sections discussing model architecture or experimental results, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting an improvement, but the lack of grounding makes it 3. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point suggests an ablation study on the number of layers versus performance, which is an interesting idea. However, it does not provide any specific reasoning, examples, or references to support why this study would be beneficial or how it could be conducted. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests an interesting idea for an ablation study on the number of layers versus performance, which could provide valuable insights into the model\"s architecture and effectiveness. However, the comment lacks specific guidance on how to conduct this study or what aspects of performance should be analyzed. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a potential direction for further exploration but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the discussion of computational aspects, noting that the authors do not provide a detailed analysis of how their proposed methods can be practically useful for highdimensional data. It also points out that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for their experiments being conducted on smallscale datasets, which does not reflect the practical applicability of the methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer how to improve the discussion and experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and highlights the challenges associated with solving LPs in such settings. It also points out that the experiments are performed on smallscale datasets, which does not reflect the practical applicability of the methods. However, the comment does not specify which part of the paper discusses computational aspects or which sections should be expanded. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss computational aspects, particularly in high dimensions, and that their algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for conducting experiments on smallscale datasets, which does not reflect the practical applicability of the methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, as the authors may struggle to address the concerns effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a gap in the discussion of computational aspects, particularly in high dimensions, and highlights the challenges associated with solving linear programs (LPs) in such settings. It points out that the algorithm requires solving several LPs in high dimensions, where a key parameter is not easily calculable, and notes that the experiments are conducted on smallscale datasets, which does not reflect the practical applicability of the methods. While the comment raises important concerns about the practical utility of the proposed methods, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bagofwords question model. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what changes could be made to the model or the question design. Without specific advice or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L254,\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies what the authors should consider regarding the design choice of trimming questions, particularly in the context of a bagofwords question model. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bagofwords question model. While the comment raises a valid concern about the efficiency of encoding longer sequences, it does not provide specific evidence or reasoning to support the claim that this design choice is \"odd.\" The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific design choice in the paper, namely the decision to trim questions after the first 10, and questions its effectiveness, especially given the use of a bagofwords question model. This feedback is valuable as it highlights a potential inefficiency or area for improvement in the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to the model or question design. While it points out a weakness, it lacks actionable advice, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies specific instances where the text color should be changed from red to green in the Supplementary Material (SuppMat). It also specifies the exact lines and sections where these changes need to be made, including L502, L507, and L509. The comment provides clear and explicit instructions on how the authors should update the document, making it 5. The feedback is detailed and specific, allowing the authors to understand exactly what needs to be done to improve the presentation of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L502, L507, and L509) in the paper where the text color should be changed from red to green. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides clear instructions on which lines need to be changed and what the correct colors should be. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of factual statements about specific line numbers and sections in the paper that require changes in color. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on formatting inconsistencies in the Supplementary Material. It explicitly points out that certain lines and sections should be in green instead of red, and it specifies the exact line numbers and sections where these changes need to be made. This detailed guidance allows the authors to easily correct the formatting issues, improving the clarity and presentation of their work. The comment is clear, concise, and directly addresses a specific aspect of the paper, making it highly valuable for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. While the comment prompts the authors to address these questions, it does not provide explicit instructions on how to incorporate the suggested comparisons or clarify the reasoning behind the exclusion of online learning approaches. The action is implicit and somewhat vague, as the authors need to infer the specific actions to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other instances where the authors discuss the limitations of online learning formulations. It also specifies the need for a proper comparison against online learning approaches and RL, highlighting the importance of considering retraining costs and incremental updates. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. While the questions are logical and relevant, they do not provide specific evidence or references to support the claims made. The comment lacks detailed reasoning or examples to substantiate the need for a comparison against online learning approaches. Therefore, the claim is considered 2, as it provides some logical reasoning but lacks sufficient evidence or references to fully support the assertion.", "helpfulness_rationale": "The review comment raises several important questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation. It asks for clarification on why online learning is overlooked, what challenges there are in including it, and how retraining costs are compared with incremental updates. This feedback is valuable as it prompts the authors to address a critical gap in their evaluation and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions or guidance on how to incorporate these comparisons into the paper. Overall, the comment is 4, as it identifies a significant area for improvement and encourages the authors to address it, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide explicit instructions on how to achieve this, such as specific sections or formatting to include. The action is implicit, as the authors need to infer that they should add a summary of the supplement experiments to the main text. This makes the comment 3, as it provides a clear direction but lacks concrete guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its suggestion to clarify and summarize the experiments, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it lacks specific guidance on how to achieve this, such as suggesting where to add the summary or what kind of summary to include. The feedback is 3 as it points out an area for improvement, but it does not provide detailed instructions or examples, leaving the authors with limited actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. The comment provides a clear action for the authors to take, which is to add these references and conduct a comparison. However, it does not specify how to implement this action, such as which sections of the paper should be compared or what specific aspects of the comparison should be highlighted. While the action is explicit, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, GFF[1] and EfficientFCN[2], which are relevant to the paper. It also specifies what needs to be addressed by encouraging a comprehensive comparison with these works. The comment is specific in detailing the need for a comparison and mentions the societal impact, providing clear guidance on what the authors should do. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works. However, the comment lacks specific examples or detailed reasoning to support the claim that these references are indeed important and missing. Without additional context or justification, the authors may find it challenging to understand why these references are crucial. Therefore, the claim is considered 2, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2]. It encourages the authors to include a comprehensive comparison with these works, which is a valuable suggestion for enhancing the paper\"s context and relevance. However, the comment could be more helpful if it provided more detailed guidance on how to conduct this comparison or what aspects of the comparison should be emphasized. Despite this, the feedback is 4 as it directs the authors towards a crucial improvement that could strengthen their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. While the comment highlights a potential limitation, it does not provide explicit guidance on how to address the scalability issue or suggest specific solutions. The action is implicit, as the authors need to infer that they should consider the scalability issue and explore potential solutions. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not specify which part of the paper discusses the proposed NC measure or the scalability issue, making it difficult for the authors to identify the exact section to address. While the comment is specific about the issue of scalability, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim about the scalability issue. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a significant concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be learned and applied to largescale datasets, such as ImageNet, and suggests that the practical contribution of the paper might be reduced without addressing this issue. While the comment highlights a critical limitation, it does not provide specific suggestions or guidance on how to address the scalability issue or improve the method\"s applicability to large datasets. The feedback is 3 as it identifies a key area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. While the comment highlights areas that need further discussion and analysis, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. However, the comment does not specify which part of the paper discusses the FMN, making it difficult for the authors to identify the exact section being addressed. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The questions are openended and lack depth, making it difficult for the authors to understand the basis of the feedback and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. These questions highlight areas where the authors could provide more detailed analysis and discussion. However, the comment lacks specific suggestions or guidance on how to address these issues, making it 3. The feedback provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It points out that the comparison of computational complexity is expected in the experiment part. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the method. The action is implicit, as the authors are expected to infer that they need to compare the computational complexity of their method with the baselines. While the action is somewhat vague, it is clear that the authors need to address the computational complexity issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational complexity of the proposed PSA method, specifically mentioning that it requires more computation than baselines. It also notes that the comparison of computational complexity is expected in the experiment part. However, the comment does not specify which part of the paper discusses the algorithm or the experimental setup, making it weakly grounded. The comment is specific in identifying the issue with the computational complexity of the PSA method, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed PSA method requires more computation than baselines, specifically noting that it involves calculating all previous layer outputs in the current layer. The comment suggests that a comparison of computational complexity is expected in the experiment part. However, the comment lacks specific details or references to support this claim, such as examples of how the computation is performed or comparisons with baseline methods. Without these details, the claim is difficult for the authors to verify and address effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than baselines. It highlights a potential area for improvement by suggesting that a comparison of computational complexity should be included in the experiment part. This feedback is 3 as it points out a potential weakness in the method and suggests an area for further analysis. However, the comment could be more helpful if it provided specific guidance on how to address the computational complexity issue or suggested alternative approaches to improve efficiency. Overall, the comment offers a clear direction for improvement but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggesting that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. While the comment provides several specific actions, it could be more actionable if it included explicit instructions on how to implement these suggestions, such as providing examples of how to increase font sizes or include the \"CTRL\" explanation. However, the comment does offer a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. While the comment is specific about the issues with the figures and the lack of details comparison, it does not explicitly mention which parts of the paper these issues relate to, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. While the comment provides specific suggestions and examples, it lacks detailed reasoning or references to support the claims fully. The feedback is 4 as it offers clear directions for improvement, but it could be more robust with additional justification or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the figures, such as increasing the font size of labels and text in figures 1 and 2, and suggests that the words in the grey box be larger. It also points out that the font sizes for V_mem, Th_i, and U_i^t are too small. Additionally, the comment suggests that the \"CTRL\" long form explanation be included. The reviewer also notes the lack of details comparison, such as epochs and number of parameters, with other stateoftheart Transformer designs, and suggests that a \"table\" manner might better emphasize the data for readers to justify the improved accuracy. While the comment offers several specific actions for improvement, it could be more helpful if it provided more detailed guidance on how to implement these suggestions or included examples of how to present the information more effectively. However, the feedback is 4 as it directs the authors to specific areas for enhancement, providing a clear path for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks the authors to rewrite a specific sentence in the paper, indicating that the original phrasing is unclear. This provides a clear and direct action for the authors to take, making the comment 5. The comment is also concrete as it specifies exactly what needs to be done, which is to rewrite the sentence. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence \"While a smaller j to simulate more accumulate errors along with the inference steps,\" and specifies the location in the paper (P. 5, p. 3, l.). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it requests a rewrite of the sentence, which is a clear and actionable request for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding a specific sentence in the paper, rather than a claim that requires verification. It does not contain any subjective opinions, logical reasoning, or references, making it a factual statement. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment is 5 as it directly identifies a specific issue with the clarity of a sentence in the paper. It requests a rewrite of the sentence, which is a clear and actionable suggestion for improvement. By addressing this issue, the authors can enhance the readability and understanding of their work. The comment is specific and provides a clear direction for the authors to take, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the paper\"s motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. While the comment implies that the authors should provide more context and examples to clarify the motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the motivation and provide examples of domain adaptation tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the paper\"s motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not specify which part of the paper discusses the motivation or the application of the proposed method, making it weakly grounded. It is specific in detailing what needs to be addressed, such as clarifying the motivation and providing examples of domain adaptation tasks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the paper\"s motivation and the absence of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it highlights a potential area for improvement but does not fully substantiate the concern.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by questioning the clarity of the motivation and the lack of a clear application for the proposed method. It highlights the absence of a clear demonstration of how the domain adaptation technique would be useful in practical scenarios, such as adapting a model trained on a synthetic dataset to a real dataset. The comment suggests that including such examples would enhance the paper\"s impact and relevance. However, the feedback could be more helpful if it provided specific examples or guidance on how to demonstrate the method\"s utility in realworld tasks. Overall, the comment is 3 as it points out an important area for improvement but lacks detailed suggestions for action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, as it is already compared to \"FP\" in Table 1 and is reported to be better. This provides a clear and explicit action for the authors to take, which is to include \"ATA\" in the comparison in Table 2. The action is concrete as it specifies exactly what needs to be done to improve the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and the specific setting \"leave one out,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comparison of the proposed method to \"ATA\" in the context of the leaveoneout setting, given that \"ATA\" is already compared to \"FP\" in Table 1 and is reported to be better. This provides a clear and actionable direction for the authors to improve their comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the proposed method should be compared to \"ATA\" in Table 2, given that \"ATA\" is already compared to \"FP\" in Table 1 and is reported to be better. This claim is 3 as it provides a logical reasoning for why \"ATA\" should be included in the comparison, but it lacks specific examples or references to support the claim fully. The authors can infer the need for the comparison but may require additional justification or evidence to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the proposed method should be compared to \"ATA\" in Table 2. This is based on the observation that \"ATA\" is already compared to \"FP\" in Table 1 and is reported to be better. The comment provides a clear and actionable suggestion for the authors to enhance the comparison and potentially strengthen the results. By including \"ATA\" in the comparison, the authors can provide a more comprehensive evaluation of their method, making the paper more convincing. This feedback is 4 as it offers a specific and constructive suggestion for improvement, though it could be further elaborated to provide additional context or rationale for the comparison."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison with some baselines is unfair because these baselines lack prior knowledge of users or language embedding computation. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the comparison. The action is implicit, as the authors need to infer that they should consider a more fair comparison by incorporating prior knowledge or language embedding computation into the baselines. While the action is clear, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the comparison, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 3, as it lacks sufficient justification to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed method with some baselines, noting that these baselines lack prior knowledge of users or language embedding computation, which could make the comparison unfair. While the comment highlights a valid concern, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparison. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including why the outputside layers do not benefit from the proposed method, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies several areas that need clarification or improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about specific aspects of the paper, including the benefits of outputside layers, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. However, it does not explicitly mention which sections or parts of the paper these issues relate to, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its questioning of certain details, the lack of explicit grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the benefits of outputside layers, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. However, it does not provide any specific evidence, reasoning, or references to support these claims. The questions are openended and do not offer a clear path for the authors to address the issues. As a result, the comment is considered 1, as it lacks the necessary justification or evidence to guide the authors in improving their work.", "helpfulness_rationale": "The review comment raises several questions and concerns about the paper, including the benefits of outputside layers, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies areas that need clarification or improvement, it lacks specific guidance on how the authors should address these issues. The feedback is 3 as it points out areas for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses difficulty in following the presentation of the paper but does not provide any specific guidance or suggestions on how the authors might improve the clarity or organization of their work. Without explicit instructions or concrete advice, the authors are left without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the presentation of the paper but does not specify which part of the paper is hard to follow. It lacks grounding as the authors cannot determine which section or aspect of the paper is causing the issue. Additionally, the comment does not provide specific details or suggestions for improvement, making it unspecific. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses difficulty in following the presentation of the paper, but it does not provide any specific claims, opinions, or suggestions for improvement. It lacks detailed reasoning, examples, or references to support the claim. As a result, the comment is classified as \"No\" because it does not contain a claim that requires verification.", "helpfulness_rationale": "The comment expresses difficulty in following the presentation of the paper, which is a valid concern for authors. However, it lacks specificity and actionable advice on how the authors might improve the clarity or organization of their work. Without detailed suggestions or guidance, the feedback is vague and does not provide the authors with a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the level of detail provided about the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should provide more information about the computation requirements of these models, particularly in relation to the timedependent LGSSM parameters \u03b3. While the comment implies that the authors should elaborate on these aspects, it does not explicitly instruct them to add more details or clarify the computation requirements. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the computation requirements of the models. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a more detailed presentation of the compared models, specifically DMM, DVBF, and KVAE. It also references Table 1, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the computation requirements of the three methods compared in Table 1. This provides the authors with a clear understanding of what additional information is needed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the level of detail provided regarding the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should provide more information about the computation requirements of these models, particularly in relation to the timedependent LGSSM parameters \u03b3. However, the comment does not offer any specific examples, references, or detailed reasoning to support the claim that the current presentation lacks detail. Without additional context or evidence, the authors may find it challenging to understand the basis of the reviewer\"s concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the level of detail provided about the compared models, particularly DMM, DVBF, and KVAE. It highlights the need for a more detailed presentation of these models, especially regarding their computation requirements, which is a crucial aspect for understanding their differences with KVAE. However, the comment could be more helpful if it provided specific suggestions or examples of what additional details would be beneficial. For instance, it could suggest including a brief explanation of the linear state space transition in KVAE or discussing the practical implications of the timedependent LGSSM parameters \u03b3. Without these details, the authors may find it challenging to fully address the feedback. Therefore, the comment is 3, as it points out an area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the work should include and compare to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also recommends a discussion on how the work differs from other chatbox research works. However, the comment does not provide explicit guidance on how to incorporate these comparisons or discussions into the paper. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including and comparing to specific related works, such as Li et al. (2017) and He et al. (2015), which are mentioned by name. This provides clear grounding as the authors can accurately identify the sections or parts of the paper where these works are discussed. The comment also recommends a discussion on how the work differs from other chatbox research works, which is specific and provides a clear direction for the authors to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and comparing to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also recommends a discussion on how the work differs from other chatbox research works. However, the comment lacks specific examples or detailed reasoning to support why these comparisons are necessary or how they would enhance the paper. The absence of detailed justification or references makes it difficult for the authors to understand the basis for the claim, leading to a score of 1.", "helpfulness_rationale": "The review comment identifies the need to include and compare the current work with specific related studies, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also suggests a discussion on how the work differs from other chatbox research works. This feedback provides a clear direction for the authors to enhance their paper by situating their work within the existing literature and highlighting its unique contributions. However, the comment could be more helpful if it provided specific examples or detailed guidance on how to incorporate these comparisons and discussions into the paper. Overall, the comment is 4 as it offers actionable suggestions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the experimental strengths of the proposed approach, suggesting that running the algorithm on 40 different networks from the training phase might be unnecessary. It proposes an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their experimental setup. The action is implicit and vague, as it does not specify how the authors should compare their approach to the suggested alternative or what specific aspects of their experimental design need to be reconsidered. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It provides a clear and specific suggestion for an alternative approach, which is to run vanilla Adam on the final network with 40 random initial points. This allows the authors to understand exactly what part of the paper needs to be addressed and what specific changes should be made. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the proposed approach is unnecessary or that the suggested alternative is a viable alternative. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 2, as it provides a basis for discussion but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. This feedback provides a clear point of comparison and challenges the authors to consider a more efficient approach. However, the comment lacks specific guidance on how the authors should address this concern or what modifications they should make to their experimental setup. While it identifies a potential weakness, it does not offer detailed suggestions or actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3, as it provides a clear insight but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to correct a typographical error in the phrase \"for \"inbetween\" uncertainty,\" specifically mentioning that the first quotation mark should be a forward mark rather than a backward mark. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be corrected and how to implement the suggestion. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty\" and provides a specific correction regarding the quotation mark. It clearly specifies what needs to be addressed, making it fully grounded. However, the comment does not provide any additional context or explanation about why this correction is necessary or how it impacts the overall understanding of the paper. Therefore, it is fully grounded but not specific, aligning with category 4.", "verifiability_rationale": "The review point is a factual correction regarding a typographical error in the phrase \"for \"inbetween\" uncertainty.\" It specifies that the first quotation mark should be a forward mark rather than a backward mark. While the comment is accurate, it does not provide any additional reasoning, examples, or references to support the claim. However, the correction is clear and unambiguous, making it 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for correcting a typographical error in the paper. The comment clearly identifies the issue with the quotation mark in the phrase \"for \"inbetween\" uncertainty\" and specifies the correct mark to use. This feedback is precise and directly addresses a minor but important detail that could improve the clarity and accuracy of the paper. By providing a clear and concise correction, the comment empowers the authors to enhance their draft, making it a valuable piece of feedback. Therefore, this comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific guidance or suggestions on how the authors might explore the dataset further. The comment lacks explicit instructions or concrete details on what aspects of the dataset should be investigated or how it could be integrated into the paper. As a result, the authors are left without a clear understanding of how to address this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this exploration should occur, leaving the authors uncertain about the exact location or scope of the suggestion. Additionally, the comment lacks specificity in terms of what aspects of the dataset should be explored or how it could be integrated into the paper. Without these details, the authors cannot confidently address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why this suggestion is important or how it could be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specific guidance or suggestions on how the authors might explore the dataset further or what aspects of the dataset should be investigated. The comment is vague and does not provide actionable feedback, leaving the authors with limited insight into how to address the feedback. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement. It also points out that the improvement is evident from the axes but might be difficult to characterize as remarkable. This feedback provides a clear and explicit action for the authors to take, which is to revise the language used to describe the improvement. The comment is specific in its suggestion and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, indicated by the reference to \"[218]\". This allows the authors to accurately identify the section being discussed. The comment is also specific because it provides clear guidance on how to improve the language used to describe the accuracy improvement, suggesting the use of more objective terms. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement. While the comment provides a suggestion for improvement, it lacks specific examples or references to support why \"remarkable\" is inappropriate in this context. The authors would need to infer the reasoning behind the suggestion, which could be challenging. Therefore, the comment is 3, as it offers a suggestion but lacks detailed justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment provides specific feedback on the language used in the paper, suggesting that terms like \"remarkable\" should be replaced with more objective terms. It also points out that the improvement is evident from the axes but might be difficult to characterize as remarkable. This feedback is clear and actionable, offering a direct suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it provided additional guidance on how to revise the language or suggested alternative terms. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks specific guidance on how to refine the performance or what aspects of the future work need improvement. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment is somewhat specific in that it suggests future refinement, but without detailed guidance on what aspects to focus on, it remains vague. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest, suggesting room for further refinement in the future. However, the comment lacks specific evidence or examples to support this claim. It does not provide any references or detailed reasoning to substantiate the assertion that the enhancements are modest. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work could be improved. The comment lacks actionable advice, leaving the authors without a clear path to enhance their draft. As a result, the feedback is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235. It also points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. These instructions are clear and direct, allowing the authors to know exactly what needs to be addressed. The comment is fully actionable as it provides specific guidance on what information is missing and how it should be addressed. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230234 and 234235,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, providing references for two passages and clarifying the term \"MLP\" in Figure 2. This level of detail ensures that the authors can understand the specific areas that require attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: requesting references for specific passages in Section 3.2 and asking for clarification on the term \"MLP\" in Figure 2. The request for references is logical and verifiable, as it is a standard practice to provide citations for key concepts or methods. However, the request for clarification on \"MLP\" lacks specific examples or references, making it 3. Overall, the comment is 4, as it provides some justification but could be more robust with additional details or references. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment provides specific feedback by requesting references for two passages in Section 3.2 and asking for clarification on the term \"MLP\" in Figure 2. This feedback is actionable and constructive, as it directs the authors to areas where they need to improve the clarity and completeness of their paper. By providing these specific requests, the comment helps the authors address potential gaps in their explanation and ensure that all terms are clearly defined. However, the comment could be more helpful if it included suggestions for how to improve the references or clarify the term \"MLP\" in more detail. Overall, the comment is 4, as it offers clear guidance for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the experimental setup. The action is implicit, as the authors are left to infer that they need to investigate the similarity in performance and potentially refine their experiments. The lack of concrete steps or detailed guidance makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not specify which part of the paper these datasets are associated with, making it weakly grounded. It is specific in pointing out the issue with the experimental results, but without clear references, the authors may struggle to identify the exact sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a concern regarding the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. While the comment highlights a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their experimental setup. The feedback is 3 as it points out a weakness in the experimental validation, but it lacks actionable advice or detailed insights that would guide the authors in enhancing their work. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of empirical validation in the paper and suggests that the authors would like to see experiments where the bounds are validated. However, the comment does not provide explicit guidance on how to conduct these experiments or what specific aspects of the bounds need validation. The action is implicit, as the authors can infer that they need to add empirical validation, but the lack of concrete details makes it vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical validation, which is a specific aspect of the paper. It also suggests that the authors would like to see experiments where the bounds are validated, providing a clear direction for improvement. However, the comment does not specify which part of the paper lacks empirical validation or what specific aspects of the bounds need validation. This makes the comment specific but not fully specific. Therefore, it aligns with category 4.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation, suggesting that the authors would like to see experiments where the bounds are validated. However, the comment does not provide any specific examples, references, or reasoning to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of empirical validation. It suggests that the authors would benefit from including experiments that validate the bounds discussed in the paper. However, the comment does not provide specific guidance on how to conduct these experiments or what aspects of the bounds need validation. While it highlights an important area for improvement, the lack of detailed suggestions or examples limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for the authors to take but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading. The comment also proposes that zooming on the region of interest using bilinear sampling could provide better results. While the comment identifies a potential issue and suggests an alternative approach, it does not explicitly instruct the authors to address the discrepancy or implement the proposed solution. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the discrepancy and consider the suggested alternative. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment does not specify which part of the paper contains the equation or figure, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. However, the comment lacks specific examples or detailed reasoning to support the claim that the output patches are masked versions. Without further elaboration or evidence, the claim remains 3, as the authors may need to infer the reasoning behind the question and the proposed solution. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between equation 9 and Figure 1, specifically questioning whether the output patches are cropped parts of the input image or just masked versions. It suggests that if the output patches are indeed masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. This feedback is clear and actionable, as it points out a potential issue in the paper and offers a constructive suggestion for improvement. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the claim about the discrepancy. Overall, the comment is 4, as it guides the authors to address a specific issue and improve the clarity of their presentation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue regarding the discussion of training time reduction and parameter reduction. It notes that the discussion section does not address the observation that training time reduction is less drastic than parameter reduction due to the continued computation of gradients for early downsampling layers. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue or improve the discussion. The action is implicit, as the authors would need to infer that they should revisit the discussion to include this observation. The lack of concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the discussion section, which should include the observation about training time reduction being less drastic than parameter reduction. This provides clear guidance on what part of the paper requires revision. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion section does not address the observation about training time reduction being less drastic than parameter reduction. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue in the discussion section of the paper, noting that the observation about training time reduction being less drastic than parameter reduction is not addressed. This feedback is clear and actionable, as it directs the authors to revisit the discussion and include this observation. However, the comment could be more helpful if it provided additional guidance on how to incorporate this observation into the discussion or suggested specific ways to improve the clarity of the discussion. Despite this, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the font size in Figure 6 is small, which could be a minor issue. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the font size or what specific changes are needed. Without further clarification or suggestions, the authors are left without a clear path to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies an issue with the font size in Figure 6, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the font size in Figure 6 is small. While this is a factual observation, the comment does not provide any reasoning or justification for why this is an issue or how it affects the paper. Without additional context or explanation, the authors may find it difficult to understand the significance of this observation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with the font size in Figure 6, which could affect the readability of the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue. Without actionable advice or examples of how to improve the font size, the comment is 3 as it highlights a potential area for improvement but does not provide a comprehensive or detailed response. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the clarity of the paper\"s goal in the introduction and suggests that the examples provided do not effectively convey the need for interprocess communication. It also offers a specific suggestion for improvement, recommending that the authors focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. While the comment provides a clear action\u2014improving the clarity of the introduction and suggesting specific areas for focus\u2014it does not offer detailed guidance on how to achieve this. The suggestion is concrete but lacks specific steps or examples, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the introduction by suggesting that the examples chosen do not effectively convey the need for interprocess communication. The authors are given specific advice on focusing on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the paper\"s goal in the introduction and suggests that the examples provided do not effectively convey the need for interprocess communication. The reviewer offers specific examples, such as samplingbased Bayesian methods, to illustrate this point. However, the comment lacks detailed reasoning or references to support the claim that the examples are not convincing. While the suggestion for improvement is clear, the absence of supporting evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a lack of clarity in the paper\"s goal in the introduction and suggests specific areas for improvement. The reviewer provides examples, such as samplingbased Bayesian methods, to illustrate the issue and offers a constructive suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, it could be more helpful if it included additional guidance on how to effectively convey the paper\"s goal or more detailed examples of the suggested problems. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure fair comparisons. The action is implicit and vague, as it does not specify how the authors can mitigate the risk of information leakage or how they should adjust their methodology to ensure fairness. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the comparisons with existing SSL methods. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in identifying the issue, the absence of explicit references to the paper\"s sections or content makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the incorporation of prior knowledge could lead to unfair comparisons. Without concrete evidence or examples, the claim remains 3, as the authors may need to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential risk that the pretrained visual model and target dataset might leak additional information, skewing results and leading to unfair comparisons. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to ensure fair comparisons. While it identifies a critical concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is explicit and provides a clear action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is concrete as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of definition for the FLOT cost matrix in Algorithm 1. This provides the authors with a clear understanding of what needs to be addressed to improve the paper.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is clear and actionable, as it directly points out a missing element that needs to be addressed. By defining the FLOT cost matrix, the authors can improve the clarity and completeness of their algorithm description. However, the comment could be more helpful if it provided additional context or suggestions on how to define the cost matrix effectively. Overall, the comment is 3 as it highlights a crucial aspect that needs attention, but it lacks depth in terms of guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the convergence of a bound in Theorem 2, specifically concerning the second term in Eq. (30). It notes that a similar bound in [Grunewalder et al, 2010], Eq. (27), does converge to 0, but it is not trivial to prove that the second term in Eq. (30) also converges to 0. The comment suggests that the authors prove this, but it does not provide explicit guidance on how to approach the proof or what specific steps to take. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27)\" from [Grunewalder et al, 2010], allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the bound in Theorem 2, Eq. (30), particularly regarding the convergence of the second term as T approaches infinity. The comment requests proof of this convergence, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of a bound in Theorem 2, specifically concerning the second term in Eq. (30). It notes that a similar bound in [Grunewalder et al, 2010], Eq. (27), does converge to 0, but it is not trivial to prove that the second term in Eq. (30) also converges to 0. The comment suggests that the authors prove this, but it does not provide specific examples or detailed reasoning to support the claim. While the reasoning is logical, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the convergence of a bound in Theorem 2, Eq. (30), noting that while a similar bound in [Grunewalder et al, 2010], Eq. (27), converges to 0, the second term in Eq. (30) does not trivially converge to 0. The comment requests proof of this convergence, which is a clear and actionable suggestion for the authors to address. However, the comment could be more helpful if it provided additional context or guidance on how to approach the proof. Despite this, the feedback is 4 as it directs the authors to a specific area of concern and encourages them to provide a detailed proof. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not use the structural connections between the brain and body. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not specify how the authors should revise the term or what changes are needed to clarify the issue. Without concrete guidance, the authors are left without a clear path to address the concern, making the comment 1.", "grounding_specificity_rationale": "The comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not use the structural connections between the brain and body. However, the comment does not specify which part of the paper discusses \"connectivity\" or provide any context for the authors to understand the issue fully. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect that needs revision. Additionally, the comment does not specify what changes should be made to address the issue, leaving the authors without clear guidance. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not use the structural connections between the brain and body. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not use the structural connections between the brain and body. While the comment highlights a specific concern, it lacks depth and does not provide actionable guidance or suggestions for improvement. The authors are left without a clear understanding of how to address the issue or what changes might be necessary. Therefore, the comment is 2, as it points out a problem but does not offer substantial assistance for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the methodology, suggesting that the authors should study the importance of orthogonal matrix weights in their model. It implies that the current approach might be unnecessary and that a deeper analysis is needed to justify the use of orthogonal matrices. However, the comment does not provide explicit guidance on how to conduct this study or what specific aspects of the model should be examined. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the methodology of the paper, specifically focusing on the use of orthogonal matrix weights. It suggests that the authors should study the importance of orthogonal matrix weights in their model, implying that the current approach might be unnecessary. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or step. This makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific about the issue of orthogonal matrix weights, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors should study the importance of orthogonal matrix weights in their model, suggesting that the current approach might be unnecessary. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the argument. Without detailed reasoning or evidence, the claim remains 3, as it is based on an inference rather than a clear and substantiated assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically suggesting that the authors should study the importance of orthogonal matrix weights in their model. It points out that the current approach might be unnecessary and implies that a deeper analysis is needed to justify the use of orthogonal matrices. However, the comment lacks specific guidance on how to conduct this study or what aspects of the model should be examined. While it highlights a potential area for improvement, the feedback is somewhat vague and could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to state how they handle comparisons between episodes with different lengths, providing a clear and concrete action to take. It also highlights a specific issue with the lack of a normalization factor in the distance calculation, which could bias the results towards longer trajectories. The comment is fully grounded as it directly references the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. The action is explicit and concrete, providing detailed guidance on how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the equation between lines 282 and 283, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with how comparisons between episodes with different lengths are handled, including the method used (padding) and the potential bias introduced by the lack of a normalization factor. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should state how they handle comparisons between episodes with different lengths, specifically mentioning that the authors pad shorter sequences by replicating their last state. It also highlights a potential issue with the lack of a normalization factor of 1/T, which could bias the results towards longer trajectories. The comment provides specific details about the method used and the potential bias, making it 4. However, it could be strengthened by including examples or references to support the claim about the bias. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on a critical aspect of the paper. It identifies a potential issue with how comparisons between episodes with different lengths are handled, noting that the authors pad shorter sequences by replicating their last state. The comment also points out a potential bias introduced by the lack of a normalization factor of 1/T, which could favor longer trajectories. This feedback is detailed and constructive, guiding the authors to clarify their methodology and address a potential weakness in their approach. By providing clear suggestions and highlighting specific areas for improvement, the comment empowers the authors to enhance the clarity and robustness of their work. Therefore, this comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the absence of consideration for Vision Transformer in the experiment and the uncertainty of its effectiveness on larger datasets like ImageNet. It also questions whether the pruning strategy might differ in selfattention layers. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take. The suggestions are implicit and lack concrete details, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also inquires about the potential differences in pruning strategies in selfattention layers. However, the comment does not specify which part of the paper discusses the experimental setup or the results related to image classification, making it difficult for the authors to pinpoint the exact areas that need attention. The lack of specific guidance on what aspects of the paper should be revised or expanded limits the comment\"s effectiveness. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also asks about the potential differences in pruning strategies in selfattention layers. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the authors may find it challenging to address these concerns effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental evaluation by pointing out the absence of consideration for Vision Transformer, a stateoftheart model in image classification. It also raises questions about the effectiveness of the proposed technique on larger datasets like ImageNet and the potential differences in pruning strategies in selfattention layers. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues or what experiments could be conducted to address them. The feedback is 3 as it points out critical weaknesses, but it could be more actionable with detailed suggestions or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the figures, including their readability, the clarity of the text, the explanation of inputs and outputs, and the selfcontained nature of the captions. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the figures, such as suggesting specific changes or providing examples of how to enhance readability. Without concrete suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.1 to Fig.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the figures, such as the difficulty in parsing them, the small text size, the lack of clear explanation of inputs and outputs, and the unselfcontained nature of the captions. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figures 1 to 3 are difficult to parse due to small text, lack of clear explanation of inputs and outputs, and unselfcontained captions. However, the comment does not provide specific examples or references to support these claims. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies specific issues with the figures, such as their readability, the clarity of the text, the explanation of inputs and outputs, and the selfcontained nature of the captions. It highlights the difficulty in parsing the figures and the lack of clear explanations, which are crucial for understanding the content. However, the comment does not provide actionable suggestions or guidance on how the authors might improve the figures. While it points out areas for improvement, it lacks depth and specificity, making it 3. The authors would need to infer how to address these issues, which limits the comment\"s overall impact. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that GDSS, despite not explicitly presenting a conditional framework, proposes a conditional molecule generation framework using classifier guidance, which could serve as a baseline. However, the comment does not provide explicit guidance on how to implement this suggestion or compare the models in Table 3. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. The comment provides clear guidance on what needs to be addressed, making it specific. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the continuous diffusion model, as evidenced by its performance in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that while GDSS does not explicitly present a conditional framework, recent work [2] proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could be used as a baseline. The claim is supported by the performance data in Table 2 and the reference to recent work [2], providing a logical basis for the suggestion. However, the comment could be more robust if it included specific examples or a detailed explanation of how the conditional framework could be integrated. Overall, the claim is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the continuous diffusion model, which outperforms the discrete diffusion model in Table 2, should be compared as a baseline in Table 3 for the conditional generation task. It also mentions that while GDSS does not explicitly present a conditional framework, recent work proposes a conditional molecule generation framework using classifier guidance based on GDSS, which could serve as a baseline. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their draft by including a relevant baseline comparison. However, the comment could be more helpful if it included more detailed guidance on how to implement this suggestion or compare the models in Table 3. Overall, the comment is 4, as it offers valuable insights for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This provides a clear and explicit action for the authors to take, as they need to add this comparison to their draft. The suggestion is concrete, as it specifies which loss functions to include and provides examples, making it easy for the authors to understand and implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests adding a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. However, it does not specify which part of the paper this comparison should be made or which sections or figures would benefit from this addition. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of the loss functions to include, the lack of grounding makes it difficult for the authors to understand where to apply this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This claim is 3 as it provides specific examples of loss functions that could be included, offering a clear direction for the authors to enhance their work. However, it lacks detailed reasoning or references to support why these specific loss functions are relevant or beneficial. The authors would need to infer the importance of these comparisons, which could be improved with additional justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include a comparison against stateoftheart loss functions used in face/iris verification, such as CenterLoss, ASoftmax, AMSoftmax, and ArcFace. This feedback is specific and actionable, as it provides clear examples of loss functions that could enhance the paper\"s contribution. By adding this comparison, the authors can strengthen their work and provide a more comprehensive evaluation of their proposed method. However, the comment could be more helpful if it included a brief explanation of why these specific loss functions are relevant or how they might impact the results. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater depth."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including confusion due to the use of undefined notation (M and N), suggesting that the authors spell out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be crossreferenced. The actions are explicit and concrete, as the authors know exactly what needs to be done to address each issue. For example, the suggestion to spell out F.L.T.R in Figure 4 is clear and actionable, and the recommendation to crossreference notation and figures provides a specific direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses issues with notation in the paper, specifically mentioning that M and N are used without definition. It also suggests improvements such as spelling out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be crossreferenced. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The suggestions are specific and provide clear guidance on how to improve the paper, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several issues with the paper, including confusion due to the use of undefined notation (M and N), suggesting that the authors spell out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be crossreferenced. These suggestions are clear and actionable, providing specific guidance on how the authors can improve their paper. However, the comment lacks detailed reasoning or references to support these claims, making it 3. The authors can infer the need for clarification and improvement based on the feedback, but the lack of explicit justification or examples weakens the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the confusion caused by undefined notation (M and N), the need to spell out F.L.T.R in Figure 4, the small text in Figure 1, and the recommendation to crossreference notation and figures. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance the clarity and readability of their work. However, the comment could be more helpful if it included additional details or examples to further clarify the issues. Overall, the feedback is 4 as it offers constructive advice for improvement, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and requests for additional information regarding the experiments conducted. It asks for the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST2. While the comment explicitly asks for these details, it does not provide explicit guidance on how to incorporate them into the draft or suggest specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer how to address these requests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests additional information and comparisons regarding the performance of YOSO and linformer, particularly in terms of steps vs ppl, iterationwise convergence, and accuracy in downstream tasks. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the experimental results and comparisons between YOSO and linformer. It requests additional information such as steps vs ppl, iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks. However, the comment does not provide any evidence, reasoning, or references to support these claims or questions. Without additional context or justification, the authors may find it challenging to understand the basis of these requests or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the authors could improve their experimental results and analysis. It requests additional information, such as the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST2. While the comment is clear and provides specific suggestions for improvement, it lacks detailed guidance on how to incorporate these requests into the draft or what specific steps the authors should take. The feedback is 3 as it directs the authors to areas needing attention but could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3, indicating it is 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. It suggests that the authors should clarify the use of the name or provide a different label. However, the comment does not specify how the authors should address this issue, such as by providing a detailed explanation of the differences or by suggesting an alternative label. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the naming of \"PointNet\" in the referenced paper, which is not present in the current paper. The comment provides a clear reference to a specific paper and highlights a potential confusion, guiding the authors to clarify the use of the name or provide an alternative label. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the use of the name \"PointNet\" for Figure 1, referencing a paper with the same name that is not present in the current paper. The comment provides a specific reference to the paper \"PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation\" by Charles R. Qi et al., which helps the authors understand the issue and potentially address it. However, the comment could be more verifiable by providing a detailed explanation of why the name is confusing or how it differs from the referenced paper. Overall, the comment is 4, as it offers a clear reference but lacks some depth in explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the naming of \"PointNet\" in Figure 1, referencing a paper with the same name that is not present in the current paper. This critique is clear and provides a specific reference to help the authors understand the confusion and potentially address it by clarifying the use of the name or providing an alternative label. However, the comment could be more helpful if it offered additional suggestions or guidance on how to resolve the naming issue effectively. Overall, the feedback is 3 as it highlights a clear area for improvement but lacks depth in addressing the issue comprehensively. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. The comment provides a clear and explicit action for the authors to take, which is to define the threat model more explicitly and include it in a dedicated section. This action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. However, the comment does not specify which part of the paper discusses the threat model, making it weakly grounded. While it provides specific guidance on what needs to be addressed, the lack of explicit mention of the section or part of the paper makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender\"s available resources. It recommends including this information in a dedicated section to enhance clarity. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the threat model needs clarification. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the clarity of the threat model. It suggests that the authors should define the threat model more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender\"s available resources. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and comprehensiveness of their work. By including this information in a dedicated section, the authors can improve the overall understanding and coherence of the paper. Therefore, the comment is 4, as it offers a clear and constructive suggestion for improvement, though it could be further expanded to provide additional guidance or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some parts of the text could be written more clearly, specifically mentioning the need for explicit explanations of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being nonpositive semidefinite in lines 105106. While the comment provides specific areas where clarity is needed, it does not offer concrete guidance on how to improve the writing or what specific changes should be made. The authors are left with a general idea of what needs to be clarified but lack detailed instructions on how to achieve this clarity. Therefore, the comment is 3, as it identifies areas for improvement but does not provide explicit or detailed guidance on how to implement these suggestions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the text (line 97 and lines 105106), allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified: the definition of a proper rotation matrix and the meaning of solving the problem of the matrix being nonpositive semidefinite. This provides the authors with clear guidance on what aspects require further explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of certain parts of the text, specifically questioning the explanation of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being nonpositive semidefinite in lines 105106. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without additional context or justification, the authors are left to interpret the feedback, making it difficult to fully understand and address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies areas where the text could be written more clearly, specifically mentioning the need for explicit explanations of a proper rotation matrix in line 97 and the meaning of solving the problem of the matrix being nonpositive semidefinite in lines 105106. This feedback is 3 as it points out specific instances where clarity is lacking, providing the authors with a clear direction for improvement. However, the comment could be more helpful if it offered suggestions on how to clarify these concepts or provided examples to illustrate the issues. Overall, the feedback is 3, as it highlights areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. However, it does not provide explicit guidance on how to implement this change or what specific aspects of the paper would benefit from this adjustment. The action is implicit, as the authors need to infer that they should consider renaming the function and how it might impact the paper. The comment lacks concrete details on how to execute this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors might consider, suggesting that the function g could be renamed as a binary operator, similar to the approach in Cohen and Shashua, 2016. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This claim is 3 as it references a specific work that introduces a similar concept. However, it lacks detailed reasoning or examples to fully support the suggestion, making it 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by suggesting that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This suggestion is actionable and offers a clear direction for enhancing the clarity and consistency of the paper. However, the comment could be more helpful if it provided additional context or examples of how this change might impact the overall understanding of the paper. Despite this, the feedback is 4 as it guides the authors towards a specific improvement that could enhance the paper\"s clarity and coherence."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors\" content and recommends shrinking the captions to provide more space for the methods or related work sections. This feedback is explicit and provides a clear action for the authors to take, which is to adjust the captions. The comment is specific in its suggestion, detailing what needs to be done to improve the layout and presentation of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done, namely, to shrink the captions to leave more space for the methods or related work sections. This feedback is detailed and actionable, making the comment 5.", "verifiability_rationale": "The review point suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors\" content, recommending that the captions be shrunk to provide more space for the methods or related work sections. This claim is 3 as it provides a clear suggestion for improvement but lacks specific examples or references to support the claim. The authors would need to independently verify the extent of the overlap to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Figure 1 and Figure 2, noting that they have large overlaps with the authors\" content. It provides a clear suggestion to shrink the captions to make space for the methods or related work sections. This feedback is actionable and directly addresses a potential issue with the layout and presentation of the paper. By offering a specific and constructive suggestion, the comment empowers the authors to improve the clarity and readability of their work. Therefore, the comment is rated as 4, as it provides clear guidance but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. It implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to include or exclude the dataset. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work and why it is not used as a potential benchmark for evaluation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. The comment implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment lacks specific reasoning or examples to support the claim that Vidgen et al., 2021, is similar to the dataset or why it should be considered as a benchmark. Without detailed justification or references, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment raises a pertinent question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. The comment implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment does not provide any guidance or suggestions on how the authors might address this issue or why the dataset should or should not be included. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights a relevant concern but does not offer concrete steps for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more detail about the experimental environment, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. While the comment explicitly suggests what information should be included, it does not provide specific guidance on how to describe the environment or what aspects to focus on. The action is clear and explicit, but it lacks concrete details on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also highlights that different versions of the environment can impact training and inference speeds. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. While it provides some specificity by mentioning the versions and their potential impact, it lacks detailed guidance on what aspects of the environment need to be described. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this information is necessary or how it impacts the results. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more detail about the experimental environment, including the CUDA and PyTorch versions. It also highlights the importance of this information in understanding the impact on training and inference speeds. While the comment is clear and identifies a specific area for improvement, it lacks detailed guidance on how to describe the environment or what aspects to focus on. This makes the feedback 3, as it provides a direction for the authors to enhance their draft, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. It also acknowledges the authors\" judgment regarding the lack of immediate societal impact. However, the comment does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative datasets or methods to address the issue. Without specific guidance on how to improve the draft, the authors are left without actionable feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. Additionally, the comment does not provide specific guidance on how to address this issue or what aspects of variation need to be controlled. As a result, the authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how to address this concern or improve the draft. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insights on how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should study the behavior of the model under higher noise, given that the current noise level is not very high based on the observations in the plot. This comment provides a clear and explicit action for the authors to take, which is to conduct further experiments with higher noise levels. The suggestion is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" part of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear suggestion to study the behavior of the model under higher noise, based on the observation that the current noise level is not very high. This guidance is detailed and actionable, making the comment 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise in the simulation study is not very high, based on the observations in the plot compared to the true trajectories. This claim is 3 as it provides a basis for the suggestion to study the model\"s behavior under higher noise. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the simulation study, noting that the standard deviation of the noise is stated as 3, but the observations in the plot suggest it is not a very high noise value. The comment provides a clear suggestion to study the model\"s behavior under higher noise, which is a valuable and actionable piece of feedback. This feedback helps the authors improve the robustness and comprehensiveness of their simulation study. Therefore, the comment is 4, as it offers a clear direction for improvement but could be more detailed with additional suggestions or examples."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to resolve the issue or enhance the applicability of the approach. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the bounds, the absence of explicit grounding makes it challenging for the authors to understand where to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of a certain approach have o(1) terms and improve over previous results for arbitrarily long inputs, but it does not provide specific evidence or reasoning to support this claim. The comment lacks detailed explanations or references to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. Without clear justification or examples, the claim remains 1, as it lacks the necessary supporting evidence to be considered valid. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide any suggestions or guidance on how to address this issue or enhance the applicability of the approach. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to improve their draft. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work [1]. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to strengthen the connection between Section 2 and the methodology section and expand the theoretical analysis to include more depth and novelty. The lack of specific actions or concrete suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2\" and \"the methodology section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the limited connection between these sections and the simplicity of the theoretical analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work [1]. While the comment provides a general assessment of the connection and the complexity of the theoretical analysis, it lacks specific examples or detailed reasoning to substantiate these claims. The absence of detailed evidence or references makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for understanding but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the authors should strengthen this link. It also points out that the theoretical analysis is somewhat simplistic and closely related to a specific work [1], implying that the authors should expand or enhance the theoretical analysis to provide more depth and novelty. While the comment highlights areas for improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is 3 as it directs the authors to areas that need attention, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses doubt about the paper\"s strength for ICLR but does not provide any specific suggestions or actions for the authors to take to improve their draft. It lacks concrete guidance on what aspects of the paper need to be addressed or how the authors can enhance its quality. Without explicit or implicit actions, the authors are left without a clear path to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses doubt about the paper\"s strength for ICLR but does not specify which part of the paper is being questioned or what aspects need improvement. It lacks grounding as the authors cannot determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific, as it does not provide any details on what needs to be improved or how the authors can enhance the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses doubt about the paper\"s strength for ICLR but does not provide any specific evidence, reasoning, or references to support this claim. It lacks detailed justification or examples to substantiate the authors\" concerns. Without such support, the claim remains unsubstantiated, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses doubt about the paper\"s strength for ICLR, which is a valid concern for authors considering publication. However, the comment lacks specific details or suggestions on how the authors might address this issue. It does not provide actionable feedback or guidance on what aspects of the paper could be improved to meet the standards of ICLR. Without concrete suggestions or a clear path forward, the comment is 2, as it only raises a concern without offering any actionable advice. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It suggests that experiments should be run multiple times and that reporting statistics is essential. The comment provides a clear action for the authors to take, which is to address the reproducibility issue by running multiple experiments and reporting statistics. This explicit guidance makes the comment 5, as it provides a direct path for improvement. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of improvements. It highlights a longstanding issue and suggests a community effort towards reproducibility, referencing a specific paper [a]. The comment is fully grounded as it explicitly mentions the topic of deep RL experiments and provides a clear reference to support the claim. It also specifies the importance of running multiple experiments and reporting statistics, which are actionable steps for the authors to take. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that experiments should be run multiple times to address the reproducibility issue with deep reinforcement learning (RL). It references a paper [a] that suggests a community effort towards reproducibility. The comment provides a logical reasoning by highlighting the importance of reproducibility and referencing a relevant work. However, it lacks specific examples or detailed explanations of how multiple experiments should be conducted or what statistics should be reported. While the claim is somewhat supported by the reference, the absence of detailed guidance makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with deep reinforcement learning (RL) experiments, specifically their reproducibility and the significance of their improvements. It highlights a longstanding problem and suggests a community effort towards reproducibility, referencing a relevant paper [a]. The comment emphasizes the importance of running multiple experiments and reporting statistics, which are essential for ensuring the reliability and significance of the results. By pointing out this issue, the comment provides the authors with a clear direction for improving the reproducibility of their experiments. However, the comment could be more helpful if it offered specific guidance on how to conduct multiple experiments or what statistics to report. Overall, the feedback is 4 as it directs the authors towards addressing a significant concern in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the formatting of equations in the paper, noting that some end with a period while others end with a comma. It provides explicit instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. This feedback is clear and actionable, as it directly instructs the authors on what needs to be corrected. The comment is specific in its instructions, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figure 2, Line 433, and Line 468, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue with the formatting of equations, noting that some end with a period while others end with a comma. This provides clear guidance on what needs to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistency in punctuation marks used at the end of equations in specific parts of the paper (Figure 2, Line 433, and Line 468). It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a minor issue with the formatting of equations in the paper, specifically noting that some equations end with a period while others end with a comma. This feedback is clear and actionable, as it provides specific instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. By addressing this issue, the authors can improve the clarity and professionalism of their paper. However, the comment could be more helpful if it suggested alternative punctuation marks or provided guidance on why consistency is important. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point questions whether the figures in Figure 1 are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback provides a clear and explicit action for the authors to take, namely to verify the nature of the figures and potentially conduct additional experiments. The comment is specific in its request for clarification and suggests a concrete way to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors should determine if the figures are generated by real experiments or artificially and, if artificially generated, conduct realworld experiments to support the phenomenon. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This comment is 3 as it provides a clear question and a suggestion for further investigation, but it lacks specific examples or references to support the claim. The authors would need to conduct additional research or experiments to fully address the suggestion, making the comment 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback is valuable as it prompts the authors to consider the validity and reliability of their experimental results. By addressing this question, the authors can strengthen the credibility of their findings and provide a more robust evaluation of their proposed method. The comment is clear, actionable, and constructive, making it 5 for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. While the comment implies that these elements are necessary for clarity, it does not explicitly instruct the authors to include them or provide guidance on how to create them. The action is implicit and somewhat vague, as the authors are left to infer that adding an example and a figure would improve the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this explanation is intended for, making it difficult for the authors to identify the exact section or figure that needs improvement. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning, references, or examples to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. While this feedback is relevant and provides a clear direction for improvement, it lacks specificity and does not offer detailed guidance on how to create or integrate these elements effectively. The comment is 3 as it identifies a potential area for enhancement, but it could be more actionable with additional suggestions or examples. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the assumption among classes is not practical and suggests that the formulation or definition in the manuscript is somewhat trivial. It also highlights the importance of optimization and theoretical property analysis, noting that some conclusions or insights can be gained from this analysis. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific changes or improvements to address the issue. The authors are left without clear guidance on how to enhance the manuscript based on the feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the assumption among classes, suggesting it is not practical. However, it does not specify which part of the manuscript discusses this assumption, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment does not provide specific guidance on how to address the issue or improve the manuscript. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the assumption among classes, suggesting it is not practical. However, it does not provide specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, suggesting that it is not practical. It also notes that the formulation or definition in the manuscript is somewhat trivial, despite the importance of optimization and theoretical property analysis. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve the manuscript. Without actionable advice or detailed feedback, the authors are left without a clear path forward, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to clarify the explanation or what specific aspects need to be improved. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the relevant section. Additionally, the comment is vague and does not provide specific guidance on what needs to be addressed or improved. Therefore, it is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern that some explanations are vague, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the explanation is vague or how it could be improved. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of some explanations, specifically mentioning the last paragraph of Section 3 (lines 207210) on the single image case. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how to improve the clarity of these explanations. Without additional details or constructive feedback, the authors are left without a clear path to address the identified issue. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the evaluation of the proposed approach by noting the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it does not provide explicit guidance on how to conduct a direct comparison of test accuracy. The action is implicit, as the authors are expected to infer that they need to include a direct comparison of test accuracy to demonstrate the improvement of the proposed approach over the baseline. However, the lack of concrete instructions on how to perform this comparison makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.4\" and \"Section 3.5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue: the absence of direct comparisons with the prior approach PRANC in both language and vision tasks, and the lack of a direct comparison of test accuracy. This provides the authors with a clear understanding of what needs to be addressed to strengthen the evaluation of the proposed approach. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no direct comparisons with the prior approach PRANC in either the language or vision tasks used to evaluate the proposed approach. However, the comment does provide some evidence by mentioning comparisons of training loss in Section 3.4 and a comparison of the rank of possible solutions in Section 3.5. While these comparisons are mentioned, they do not directly address the lack of a direct comparison of test accuracy, which is the core of the claim. The lack of explicit examples or references to support the claim about the absence of direct test accuracy comparisons makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the evaluation of the proposed approach by pointing out the absence of direct comparisons with the prior approach PRANC in both language and vision tasks. While the comment mentions comparisons of training loss and the rank of possible solutions, it highlights the critical issue of the lack of a direct comparison of test accuracy, which is essential for demonstrating the improvement of the proposed approach over the baseline. This feedback is clear and actionable, as it directs the authors to include a direct comparison of test accuracy to strengthen their evaluation. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or suggested additional metrics to consider. Overall, the comment is 4, as it effectively guides the authors to address a key limitation in their evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments on generation tasks that are more likely to require a wellperforming language model, such as language modeling, machine translation, or text summarization. It also points out that the current experiments on word similarity and SquAD do not adequately reflect the language modeling capability. The comment provides clear guidance on what experiments to include to strengthen the paper, making it 5. The authors know exactly how to apply this feedback to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper claim regarding the importance of language modeling capability and suggests conducting experiments on generation tasks that are more likely to require a wellperforming language model. It also specifies the tasks that should be included, such as language modeling, machine translation, or text summarization, to strengthen the paper. This provides clear guidance on what experiments to include, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the authors did not conduct experiments on generation tasks that are more likely to require a wellperforming language model, such as language modeling, machine translation, or text summarization. It suggests that the current experiments on word similarity and SquAD do not adequately reflect the language modeling capability. The comment provides specific examples of tasks that could strengthen the paper, making it 4. However, it could be more robust with additional references or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting that while the authors claim the importance of language modeling capability, they did not conduct experiments on tasks that are more likely to require a wellperforming language model. The comment suggests including tasks such as language modeling, machine translation, or text summarization to strengthen the paper, aligning with the main motivation of COCOLM. This feedback is clear, actionable, and provides specific suggestions for improvement, making it 5 for the authors to enhance their draft. The comment effectively guides the authors in addressing a critical aspect of their work, ensuring that the paper aligns with its stated motivations."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern that the proposed method\"s improvement over existing RL methods is not impressive. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks concrete guidance on how the authors might enhance their method or present it more effectively to demonstrate its superiority. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment expresses a concern about the improvement of the proposed method over existing RL methods, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the improvement are not impressive or how the authors might address this issue. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the improvement of the proposed method over existing RL methods is not impressive. However, the comment lacks specific details or evidence to support this claim. It does not provide any examples, references, or logical reasoning to substantiate the assertion that the improvement is not impressive. Without further context or justification, the authors are left without a clear understanding of why this claim is made or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses concern about the improvement of the proposed method over existing RL methods, suggesting that it is not impressive. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance their method. It does not provide actionable feedback or guidance on what aspects of the method could be improved to demonstrate its superiority. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, it does not provide any specific suggestions or actions for the authors to take to address this limitation or enhance the novelty of their work. The comment lacks explicit guidance on how the authors might improve their design or what specific aspects need to be revised to make it more novel. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, it does not specify which part of the paper this claim is related to, such as the introduction, methodology, or results sections. Without explicit references or context, the authors cannot confidently determine which part of the paper the comment addresses. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the novelty of the design. Therefore, the comment is 1 and lacks specificity, making it ungrounded and not specific.", "verifiability_rationale": "The review point claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, the comment does not provide any specific evidence or references to support this claim, such as examples of prior work or detailed explanations of how the design aligns with existing methods. Without this additional context, the authors may find it difficult to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the design, noting that it is based on the use of attention for motion learning, which has been widely used in video understanding. This observation provides a clear and concise critique of the paper\"s contribution, highlighting a potential gap in its originality. However, the comment does not offer any suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. While it points out a significant issue, it lacks actionable advice, making it 3 but not fully supportive of the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of clarity in the model design and learning details, noting that they are fragmented or missing. It suggests that the authors could provide a model illustration plot, pseudocode table, or code repository to address this issue. The comment is explicit in identifying the need for additional details and provides concrete suggestions on how to improve the clarity of the model design. By offering specific examples of what could be included, the authors are given clear guidance on how to enhance the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of unclear model design and learning details, suggesting that the authors could provide a model illustration plot, pseudocode table, or code repository. However, it does not specify which part of the paper these details are missing from, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing visual aids or detailed descriptions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model architecture and learning details are fragmented or missing, suggesting that the authors could provide a model illustration plot, pseudocode table, or code repository. While the comment provides some guidance on what could be included, it lacks specific examples or references to support the claim that these details are indeed missing or fragmented. The suggestion to provide additional details is logical and helpful, but the lack of concrete evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of the model design and learning details, noting that they are fragmented or missing. It provides specific suggestions for improvement, such as including a model illustration plot, pseudocode table, or code repository. This feedback is actionable and constructive, as it guides the authors on what additional information is needed to enhance the clarity and reproducibility of their work. By offering concrete examples of what could be included, the comment empowers the authors to address the identified weakness effectively. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. While the comment provides a clear action\u2014either to include rejection rates or to consider misclassifications as rejections\u2014it does not specify how to implement this action. The authors are left with a general direction but lack concrete guidance on how to incorporate rejection rates into their results or how to justify viewing misclassifications as rejections. Therefore, the comment is 3, as it provides an explicit action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. However, it does not specify which part of the paper this issue pertains to, such as the results section or a specific table. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its suggestion to include rejection rates or view misclassifications as rejections, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments and suggests that it could be viewed as misclassifications. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that misclassifications could be viewed as rejections, which is a valuable insight for the authors to consider. However, the comment lacks actionable guidance on how to include rejection rates or how to justify viewing misclassifications as rejections. While it provides a direction for improvement, it does not offer detailed steps or suggestions for implementation, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. While this is a specific suggestion, it does not provide explicit guidance on how to achieve this optimization. The authors are left to infer that they need to adjust the figure\"s layout or design to reduce whitespace usage. However, the comment lacks concrete details on how to implement this optimization, such as specific design principles or techniques that could be applied. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests optimizing Figure 1 to use less whitespace, but it does not specify which part of the paper Figure 1 corresponds to or provide any context for why this optimization is necessary. The authors cannot confidently determine which section or figure is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the figure could be optimized or why less whitespace is beneficial. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While this is a specific observation, it lacks actionable guidance or suggestions on how to achieve this optimization. The authors are left without any direction on how to improve the figure\"s layout or design. The comment is vague and does not provide any insights into the potential benefits of optimizing whitespace usage or how it might impact the overall presentation of the paper. Therefore, the comment is 2, as it does not offer any meaningful feedback or suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly mentions that the paper formatting does not follow the NeurIPS style, specifically noting issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and provides specific actions for the authors to take, such as revising the formatting and restructuring the paper. The comment is explicit and concrete, allowing the authors to understand exactly what needs to be addressed and how to do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions issues with the paper formatting, specifically noting that it does not follow the NeurIPS style, with the abstract font being too large and the bottom page margins altered. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. This feedback is fully grounded as it clearly identifies the specific parts of the paper being addressed, and it is specific because it details the issues with the formatting and suggests concrete actions for improvement. Therefore, this comment is rated as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the paper formatting does not follow the NeurIPS style, specifically mentioning issues with the abstract font size and bottom page margins. It suggests that by fixing the formatting, the authors should gain space and potentially include the NLP experiments in the main body of the paper. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the issues or understand how to address them. The reasoning is logical but lacks detailed evidence, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper formatting, noting that it does not adhere to the NeurIPS style. It points out problems with the abstract font size and bottom page margins, which could hinder the presentation of the paper. The comment suggests that by addressing these formatting issues, the authors might gain space and potentially include the NLP experiments in the main body of the paper. This feedback is clear and actionable, providing the authors with specific areas to improve their draft. However, it could be more helpful if it included additional suggestions or guidance on how to address the formatting issues. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse\". This is a specific and actionable suggestion that the authors can easily address by correcting the label. The comment provides clear guidance on what needs to be done, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that one of the labels on the color bar should be \"worse,\" providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse.\" This is a specific observation that requires the authors to verify the correctness of the label. However, the comment does not provide any additional context, reasoning, or references to support why this correction is necessary or beneficial. Without further explanation or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides a specific observation but lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment points out a specific issue with Figure 4, suggesting that one of the labels on the color bar should be \"worse.\" This is a clear and actionable feedback that the authors can easily address by correcting the label. The comment is specific and provides a clear direction for improvement, making it 5 for the authors to enhance the accuracy and clarity of their paper. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific issue in the text, pointing out that the phrase \"training/validation/test\" should be \"training/validation/test sets\". This is an explicit action that the authors can take to correct the text. The comment is clear and provides a concrete instruction on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the correction needed, which is to change \"training/validation/test\" to \"training/validation/test sets\". This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, stating that the phrase \"training/validation/test\" should be \"training/validation/test sets\" in the specified location. This is a straightforward factual correction and does not require any additional reasoning, common knowledge, or external references to be understood or verified. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific error in the text, pointing out that the phrase \"training/validation/test\" should be corrected to \"training/validation/test sets\". This is a clear and actionable suggestion that directly addresses a factual inaccuracy in the paper. By providing this correction, the authors can improve the accuracy and clarity of their work. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets around the term or defining the bracketed term separately. These suggestions are explicit and provide concrete guidance on how the authors might address the issue. The comment is clear and actionable, allowing the authors to directly implement the proposed changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of the quantile, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides concrete suggestions for improving the clarity of the definition by adding extra brackets or defining the bracketed term separately. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the definition of the quantile could be confusing and proposes two potential improvements: adding extra brackets or defining the bracketed term separately. While the comment provides a suggestion for improvement, it does not offer any specific reasoning or evidence to support why this clarification would be beneficial. The authors are left to infer the value of these suggestions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the definition of the quantile, suggesting that adding extra brackets or defining the bracketed term separately could improve understanding. This feedback is specific and actionable, providing the authors with clear guidance on how to enhance the clarity of their paper. By offering concrete suggestions, the comment empowers the authors to make improvements that could benefit the overall readability and comprehension of their work. Therefore, the comment is 4, as it provides clear and actionable feedback that is likely to be beneficial for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where the proposed method (PE) is important. However, it does not provide any specific guidance or suggestions on how to achieve this, such as which tasks to include or how to demonstrate the importance of PE in those tasks. The comment lacks explicit instructions or concrete details, making it difficult for the authors to understand what actions they should take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not specify which tasks should be included or how they should be integrated into the paper. This makes it difficult for the authors to understand the exact scope of the suggestion, leaving them unable to confidently determine which part of the paper needs revision. Additionally, the comment lacks specificity in detailing what aspects of the tasks or the importance of PE are not adequately addressed. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to incorporate it into their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it lacks specific guidance or examples on how to achieve this, making it difficult for the authors to understand the implications of the suggestion or how to incorporate it into their work. The comment is vague and does not provide actionable feedback, which limits its helpfulness. Therefore, it aligns with a score of 2, as it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the inclusion of fewshot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not provide explicit guidance on how to implement this suggestion, such as which specific demonstrations to include or how they should be structured. The comment is somewhat vague, as it leaves the authors to infer the exact action needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the inclusion of fewshot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. The comment is vague in terms of specificity, as it does not provide detailed guidance on what aspects of the fewshot demonstrations should be included or how they should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. The comment does not provide specific examples or references to support the claim that the inclusion of zeroshot results is necessary or beneficial. As a result, the claim is considered 1 due to the lack of supporting evidence or logical reasoning. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting the inclusion of fewshot demonstrations to enhance the paper. However, it does not provide specific guidance on how to implement this suggestion, such as which demonstrations to include or how they should be structured. The comment also raises a question about the inclusion of zeroshot generation results, which could be addressed with more detailed reasoning or examples. While the feedback points out a potential area for improvement, it lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a minor issue regarding Figure 3, noting that the label \"OAA\" is not referenced in the body text. It also suggests that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address the issue, such as suggesting where the additional content might be or how to update the caption. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a specific issue regarding Figure 3, noting that the label \"OAA\" is not referenced in the body text. It also suggests that there might be additional content in the appendix that is missing or that the caption is out of date. However, the comment does not provide explicit guidance on which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section or figure being referred to. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a specific issue regarding Figure 3, noting that the label \"OAA\" is not referenced in the body text and suggesting that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment identifies a potential issue, it lacks detailed reasoning or references to support the claim that the label is missing or that the caption is out of date. The authors are left to infer the basis of the claim, which makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the label \"OAA\" is not referenced in the body text and suggesting that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment highlights a potential problem, it does not provide detailed guidance on how to address it or what specific steps the authors should take to resolve the issue. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the introduction by stating that the proposed solution is a \"fix\" of [12], rather than a new PIC approach. It provides a specific example of where this clarification should be made, in lines 2930. This direct instruction and explicit guidance on how to implement the change make the comment 5. The authors know exactly what needs to be added to the introduction to address the feedback. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section where the clarification should be made, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the authors must clarify the proposed solution as a \"fix\" of [12] rather than a new PIC approach, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors must be more clear in the introduction about the nature of the proposed solution, specifically that it is a \"fix\" of [12] rather than a new PIC approach. The comment provides a specific example of where this clarification should be made, in lines 2930. However, it does not offer additional reasoning, examples, or references to support this claim. While the comment is 3 due to the explicit instruction, it lacks depth and could be strengthened with more detailed justification or examples. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides a clear and specific suggestion for improvement. It instructs the authors to clarify the introduction by explicitly stating that the proposed solution is a \"fix\" of [12] rather than a new PIC approach. This guidance is actionable and directly addresses a potential ambiguity in the paper, helping the authors to improve the clarity and accuracy of their presentation. The comment is detailed and provides a clear direction for the authors to follow, making it highly beneficial for enhancing the draft. Therefore, it is rated as 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the absence of comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also suggests that the relevance of the occlusion experiment is unclear, as the method does not seem to propose anything specific to occlusion. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific comparisons or clarifying the relevance of the occlusion experiment. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific comparisons with NeRFbased methods, such as \"Zero1to3\" and \"pointe,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the relevance of the occlusion experiment, questioning its significance in the context of the method. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of comparison with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" It also questions the relevance of the occlusion experiment, suggesting that it does not align with the method\"s specific contributions. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of specific examples or justifications weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with NeRFbased methods, specifically mentioning \"Zero1to3\" and \"pointe.\" This feedback is valuable as it highlights the need for the authors to contextualize their work within the existing literature. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it does not align with the method\"s specific contributions. However, the comment lacks detailed guidance on how the authors should address these issues, such as providing specific comparisons or clarifying the relevance of the occlusion experiment. While the feedback is 3 in identifying areas for improvement, it could be more actionable with additional suggestions or guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. While the comment explicitly suggests that a brief explanation of \"multiaspect\" would be helpful, it does not provide guidance on how to implement this suggestion, such as what kind of explanation would be beneficial or how to integrate it into the paper. Similarly, the question about the subscripts in Figure 1 is specific but lacks guidance on how to address it. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to achieve them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 14, 47\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear feedback on the need for a brief explanation of \"multiaspect\" and questions the subscripts in Figure 1. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two specific questions about the paper: the need for a brief explanation of \"multiaspect\" and the correctness of the subscripts in Figure 1. While the questions are clear and specific, they do not contain any subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. While the feedback is clear and identifies areas for improvement, it lacks depth and actionable suggestions. The comment does not offer guidance on how to address the need for a brief explanation of \"multiaspect\" or how to correct the subscripts in Figure 1. As a result, the feedback is 3, as it provides some insight but does not fully empower the authors to improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors consider additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. While the comment provides a direction for improvement by suggesting specific methods to explore, it does not explicitly instruct the authors to implement or compare these methods. The action is implicit, as the authors need to infer that they should consider these additional approaches. However, the comment lacks concrete guidance on how to integrate these methods into their experiments or what specific comparisons would be beneficial. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment suggests considering additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore alternative methods, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas where these methods should be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. While the suggestion is logical and aligns with common practices in the field, it lacks specific examples or references to support the claim. The authors would need to infer the relevance of these methods to their work, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for improvement by suggesting that the authors consider additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. This feedback is valuable as it offers a clear direction for enhancing the experimental setup and potentially providing a more comprehensive comparison. However, the comment could be more helpful if it included specific examples of how these methods could be implemented or what kind of comparisons would be beneficial. Overall, the comment is 4 as it identifies a relevant area for improvement and provides a basis for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing citation for the public skipgram data set mentioned in line 425. While it points out the absence of a citation, it does not provide any explicit or implicit guidance on how the authors should address this issue. The authors are left without any direction on how to include the missing citation, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the section of the paper where the issue lies. It is also specific because it clearly identifies the missing citation for the public skipgram data set, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, namely the missing citation for the public skipgram data set mentioned in line 425. This feedback is clear and actionable, as it directs the authors to a specific part of the paper where a citation is required. However, the comment does not provide any suggestions or guidance on how the authors might address this issue beyond simply adding the citation. While it highlights a necessary correction, it lacks depth and could be more helpful if it offered additional insights or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific steps they should consider. Without concrete suggestions or a clear path forward, the authors are left without actionable feedback, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is vague and does not provide specific guidance on what needs to be addressed. Therefore, it is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of how to address the issue or what steps might be necessary. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they should consider. It does not provide actionable feedback or insights that would help the authors improve their draft. As a result, the comment is 2, as it identifies a potential problem but does not offer a clear path forward for the authors to resolve it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the discussion regarding the hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This feedback provides a clear and explicit action for the authors to take, which is to include a detailed discussion on how to set the hyperparameter in practice and to analyze its sensitivity. The comment is concrete, as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses the discussion on arbitrary hyperparameter \u03b3, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. However, it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in detailing what is missing, such as guidance on setting the hyperparameter and sensitivity analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the discussion on the hyperparameter \u03b3 is missing, specifically mentioning the absence of guidance on how to set it in practice for a given graph and the lack of analysis on its sensitivity. This claim is 3 as it highlights a gap in the paper but does not provide specific examples or references to support the claim. The authors would need to infer the missing information, which limits the verifiability of the comment. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the hyperparameter \u03b3, specifically mentioning the lack of guidance on how to set it in practice for a given graph and the absence of sensitivity analysis. This feedback is clear and actionable, as it provides the authors with specific areas to address in order to improve the completeness and clarity of their work. By highlighting these missing elements, the comment guides the authors to enhance the practical applicability and robustness of their research. Therefore, the comment is 4, as it offers clear and constructive feedback that can significantly improve the draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a primary concern that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It suggests simplifying the description and explaining the architecture and computations better. Additionally, it recommends reducing the content of Figure 7, Section 8, and lines 3964 to gain more space. While the comment provides explicit suggestions for improvement, such as simplifying descriptions and reducing content, it lacks concrete details on how to achieve these changes. The authors are left with a general idea of what needs to be done but without specific guidance on how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7, Section 8,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on how to improve the paper, such as simplifying the description and explaining the architecture and computations better. The suggestion to reduce the content of lines 3964 further emphasizes the need for conciseness. This level of detail and specificity makes the comment 5 and grounded, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It suggests simplifying the description and explaining the architecture and computations better, and recommends reducing the content of Figure 7, Section 8, and lines 3964 to gain more space. While the comment provides a general suggestion for improvement, it lacks specific examples or references to support the claim that the paper is too dense. The authors are left to infer the need for simplification and reduction, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a primary concern that the paper is too dense and difficult to follow, requiring multiple reads to grasp the concepts and contribution. It provides actionable suggestions for improvement, such as simplifying the description and explaining the architecture and computations better. Additionally, it recommends reducing the content of specific sections (Figure 7, Section 8, and lines 3964) to gain more space. This feedback is clear and constructive, offering the authors specific areas to focus on for improving the clarity and readability of their paper. However, the comment could be more helpful if it provided additional guidance on how to simplify the descriptions or reduce the content effectively. Overall, the comment is 4, as it provides valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clear, specifically mentioning sorting and ranking. The comment questions the complexity of the procedure to find upper bounds on gaps and its implications for solving a ranking problem. However, the comment does not provide explicit guidance on how to improve the discussion of the results or how to clarify the realworld applications. The suggestions are somewhat vague and lack concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clear, specifically mentioning sorting and ranking. However, the comment does not specify which part of the paper these discussions or applications are related to, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestions but lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experiment results could be discussed more and questions the realworld applications of the new problem setting, particularly in the context of sorting and ranking. It also raises concerns about the computational complexity of the procedure to find upper bounds on gaps. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is considered 2, as it provides some basis for discussion but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies areas for improvement in the paper, specifically suggesting that the discussion of experiment results could be more detailed and providing an example of how to conclude from the Streetview experiment. It also raises questions about the realworld applications of the new problem setting, particularly in the context of sorting and ranking, and highlights concerns about the computational complexity of the procedure to find upper bounds on gaps. While the comment provides some actionable feedback, it lacks depth and specificity, as it does not offer detailed guidance on how to enhance the discussion or address the concerns about realworld applications and computational complexity. The feedback is 3, as it points out areas for improvement but could be more comprehensive and detailed to fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention that the results for model (3) in Table 1 were computed by themselves, as they are not reported in the original paper. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be added to their draft to address this issue. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results for model (3) were not reported in the original paper and suggests that the authors should mention if they computed these results themselves. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) in Table 1 were not reported in the original paper and suggests that the authors should mention if they computed these results themselves. This claim is 3 as it provides a specific observation about the content of Table 1 and suggests a potential issue with the authors\" computation. However, it lacks detailed reasoning or references to support the claim fully, making it 3.", "helpfulness_rationale": "The review comment identifies a specific issue in Table 1, noting that the results for model (3) were not reported in the original paper and suggests that the authors should mention if they computed these results themselves. This feedback is clear and actionable, providing the authors with a direct instruction to address a potential inconsistency or error in their results. By highlighting this issue, the comment helps the authors improve the accuracy and transparency of their work. However, the comment could be more helpful if it provided additional guidance on how to ensure the accuracy of the results or suggested alternative ways to present the data. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should place more emphasis on prompt design, noting that different prompts can lead to varying performance outcomes. It implies that the authors should discuss effective prompt design strategies. However, the comment does not provide specific guidance on how to implement this suggestion, such as which aspects of prompt design should be emphasized or what techniques should be discussed. The action is implicit and somewhat vague, as the authors need to infer the specific areas where more emphasis is needed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment does not specify which part of the paper this issue is addressed in, making it weakly grounded. It is specific in detailing the need for more emphasis on prompt design and the importance of discussing effective strategies, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment lacks specific examples or references to support the claim that different prompts may result in varying performance outcomes or how to effectively design prompts. Without detailed examples or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, suggesting that more emphasis should be placed on prompt design. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. This feedback is clear and actionable, providing the authors with a specific direction to enhance their work. However, the comment could be more helpful if it offered additional guidance on which aspects of prompt design should be emphasized or what techniques could be used to improve prompt design. Despite this, the comment is 4 as it directs the authors towards a crucial area of improvement, making it a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment explicitly asks for clarification on these aspects, it does not provide concrete guidance on how the authors should address these questions or incorporate the suggestions. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not specify which part of the paper these questions or suggestions relate to, making it difficult for the authors to identify the exact sections or elements being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. While it provides some specificity by mentioning the choice of 0.6 and other loss functions, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises questions about the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not provide any specific reasoning, examples, or references to support these claims. The questions are openended and lack detailed justification, making it difficult for the authors to understand the basis of the concerns. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment identifies areas where the authors might need clarification or improvement, it lacks actionable guidance on how to address these issues. The suggestions are somewhat vague and do not provide specific steps or examples for the authors to follow. As a result, the comment is 3, as it offers some insight but does not fully support the authors in improving their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve the clarity of the table legends. The action is concrete, as it specifies the exact changes required, such as expanding the legends and clarifying the meaning of the numbers. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1, 2, 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified in the legends, namely whether the numbers represent % errors or % correct, and specifies the datasets (MNIST and CIFAR) where this clarification is needed. This level of detail ensures that the authors understand exactly what changes are required to improve the clarity of the table legends. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the legends of Table 1, 2, and 3 should be longer and clarify whether the numbers represent % errors or % correct, specifically mentioning MNIST and CIFAR. This claim is 3 as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim. The authors would need to infer the need for clarification based on the existing content of the tables. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the legends of Table 1, 2, and 3, suggesting that they should be longer and clarify whether the numbers represent % errors or % correct. This feedback is clear and actionable, providing the authors with a direct path to improve the clarity and interpretability of their results. By expanding the legends and clarifying the meaning of the numbers, the authors can enhance the understanding of their findings. The comment is 4 as it offers a clear direction for improvement, though it could be more comprehensive by suggesting additional ways to enhance the clarity of the tables. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific questions and suggestions for improvement regarding the description of the graph G in Section 3.3. It asks how G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W to enhance understanding of the DGCN model. These suggestions are explicit and concrete, as they directly instruct the authors on what needs to be added or clarified in their draft. The comment is fully actionable, as it provides clear guidance on how to improve the clarity and comprehensibility of the paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the size and elements of G, and adding the dimensions of G, X, and W to enhance understanding of the DGCN model. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and suggestions for improvement regarding the description of the graph G in Section 3.3. It asks how G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W to enhance understanding of the DGCN model. While the comment provides specific suggestions for improvement, it does not offer any logical reasoning, common knowledge, or external references to support the need for these changes. The authors would need to infer the importance of these details based on their own understanding of the paper. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and completeness of the description of the graph G in Section 3.3. It questions how G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W to enhance understanding of the DGCN model. This feedback is actionable and constructive, as it directly points out areas where the authors can improve the clarity and comprehensibility of their paper. By addressing these suggestions, the authors can significantly enhance the understanding of their methodology and the effectiveness of their model. Therefore, the comment is 5, as it provides clear guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the concept of energy, which is introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also points out that the concept of peak in Figure 5 is not described. The comment implies that the authors should consider providing additional context or hints about how to interpret energy, particularly in the context of morpheme splitting, and should clarify the concept of peak in the figure. However, the comment does not explicitly instruct the authors to add or modify content, making it 3. The action is clear but could be more explicit by directly instructing the authors to include these explanations and descriptions.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Section 3.1 and Section 5.2, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as refreshing the concept of energy and providing hints for interpretation, as well as clarifying the concept of peak in Figure 5. This level of detail provides clear guidance on what changes are needed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point suggests that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. It also points out that the concept of peak in Figure 5 is not described. The comment implies that the authors should consider providing additional context or hints about how to interpret energy, particularly in the context of morpheme splitting, and should clarify the concept of peak in the figure. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would need to infer the need for clarification and additional context, which could be improved with more explicit guidance.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the clarity and completeness of the paper. It points out that the concept of energy, introduced in Section 3.1, could be better explained or refreshed in Section 5.2, where it is used more extensively. Additionally, it notes that the concept of peak in Figure 5 is not described, which is a clear oversight. The comment offers actionable advice by suggesting that the authors should consider providing additional context or hints about how to interpret energy, particularly in the context of morpheme splitting, and should clarify the concept of peak in the figure. This feedback is 4 as it directs the authors to specific areas for improvement and provides a clear path for enhancing the draft, but it could be more comprehensive with additional suggestions or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific areas where details are missing in the paper, particularly regarding the grammar over kernels and the probabilities associated with it. It also questions the clarity of how inference is performed. While the comment identifies the need for more detailed explanations, it does not provide explicit instructions on how to address these issues or what specific actions the authors should take. The feedback is somewhat vague, as it leaves the authors to infer the necessary steps to improve the draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some of the details of the models are missing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by focusing on the \"grammar over kernels,\" which is a specific aspect of the models. The comment is specific in detailing what needs to be addressed, such as the lack of explanation for the grammar over kernels and the absence of probabilities associated with it, as well as questions about inference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of detail in the paper, specifically regarding the grammar over kernels and the absence of probabilities associated with it. It questions the clarity of how inference is performed, which is a critical aspect of understanding the approach. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The feedback is 3 as it identifies areas where the paper could be clearer, but it lacks the depth and specificity needed for the authors to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks detail, particularly regarding the grammar over kernels and the absence of probabilities associated with it. It also questions the clarity of how inference is performed, which is a critical aspect for understanding the approach. While the comment highlights these issues, it does not provide detailed suggestions or guidance on how to address them. The feedback is 3 as it points out areas that need improvement, but it lacks depth and specificity, making it challenging for the authors to fully understand and implement the suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. It also points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. The comment is fully actionable because it specifies exactly what needs to be done, including identifying and citing previous works on Lasso screening. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue: the lack of citation and comparison of previous works on Lasso screening, providing a clear example of what needs to be addressed. This feedback is detailed and actionable, guiding the authors to include relevant references and comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not provide any evidence or reasoning to support this claim. It suggests that previous works on Lasso screening are not cited or compared, specifically mentioning Ren et al. \"Safe feature screening for generalized LASSO.\" TPAMI 40.12 (2017): 29923006. However, the comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is barely verifiable, as it provides some evidence but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. However, it points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. By highlighting this gap, the comment helps the authors improve the completeness and accuracy of their paper. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions or examples."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This provides a clear and explicit action for the authors to take, as they can directly address the ambiguity in the title. The comment is specific in its suggestion, detailing exactly what needs to be done to improve the clarity of the title. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. However, it does not provide specific guidance on which part of the paper this issue pertains to, such as a particular section or figure. The authors may infer that the title is relevant to the introduction or conclusion, but without explicit mention, they cannot confidently determine the exact area of concern. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. While the comment identifies a potential issue with the title\"s clarity, it does not provide specific examples or references to support this claim. The authors may infer that the ambiguity could lead to misinterpretation, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This is a valuable piece of feedback as it helps the authors ensure that their work is accurately represented and easily understood by the readers. By addressing this ambiguity, the authors can improve the clarity and precision of their paper, making it more impactful. The comment is specific and actionable, providing a clear direction for improvement, which makes it 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the authors\" draft: the lack of confidence intervals for their results and the limited evaluation on only two datasets. While the comment identifies these areas as needing improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to include confidence intervals and expand their evaluation to more datasets. This lack of explicit and detailed guidance makes the comment 3, as the authors can infer the necessary actions but do not know exactly how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of confidence intervals for the results and the limited evaluation on only two datasets. It provides specific references to relevant works in the RNP community, which helps the authors understand the context and the importance of addressing these issues. However, the comment does not explicitly mention which part of the paper discusses the results or the evaluation, making it weakly grounded. The specificity of the comment is high as it clearly identifies the issues and provides references for further context. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not show confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The comment provides references to relevant works in the RNP community, which could be used to support the claim. However, the reasoning is somewhat vague, as it does not fully explain why the lack of confidence intervals and the limited dataset evaluation are significant issues. The references provided are relevant, but the overall claim is 4 as it is supported by logical reasoning and references, though it could be more detailed. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies two key issues with the authors\" draft: the absence of confidence intervals for the results and the limited evaluation on only two datasets. These are important points that could impact the statistical significance and generalizability of the findings. The comment also provides references to relevant works in the RNP community, which could help the authors understand the context and importance of addressing these issues. However, the comment lacks specific guidance on how the authors might incorporate confidence intervals or expand their evaluation to more datasets. While it highlights areas for improvement, it does not offer detailed suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the statistical significance of the improvements of the proposed model over the RL without feedback model, based on the data presented in row 3 and row 4 of Table 6. It suggests that the authors should verify if the improvements are statistically significant. However, the comment does not provide explicit guidance on how to perform this verification or what specific statistical tests should be used. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a statistical significance test. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the improvements of the proposed model over the RL without feedback model, particularly noting that the BLEU1 score is worse. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the statistical significance of the improvements of the proposed model over the RL without feedback model, based on the data presented in row 3 and row 4 of Table 6. While the comment identifies a potential issue with the BLEU1 score, it does not provide any specific reasoning, examples, or references to support the claim that the improvements are not statistically significant. The lack of detailed justification or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the statistical significance of the improvements of the proposed model over the RL without feedback model, as indicated in Table 6. It questions whether the observed improvements, particularly in BLEU1, are statistically significant. This feedback is valuable as it highlights a potential area for further analysis and strengthens the authors\" claims. However, the comment could be more helpful if it provided guidance on how to conduct the statistical significance test or suggested specific statistical methods to use. Without these details, the authors may struggle to address the concern effectively. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without significantly impacting the performance of predictive models. This provides a clear and explicit action for the authors to take, as they need to show the practical application of their method in achieving fair policy learning while maintaining predictive performance. The comment is specific in its request for demonstration and provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without \"severely damaging the performance of predictive model.\" This feedback is specific in its request for a demonstration of the method\"s application in achieving fair policy learning while maintaining predictive performance. However, it does not explicitly mention which part of the paper this demonstration should be included in, making it weakly grounded. The comment is specific in its suggestion, providing a clear direction for the authors to improve their draft. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use the proposed method to achieve fair policy learning without \"severely damaging the performance of predictive model.\" This claim is 3 as it provides a specific direction for the authors to improve their work by demonstrating the practical application of their method. However, it lacks detailed examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors demonstrate how their proposed method can achieve fair policy learning without significantly impacting the predictive model performance. This feedback is actionable and offers a clear direction for the authors to enhance their draft by providing a practical demonstration of their method. However, the comment could be more helpful if it included additional guidance or examples on how to achieve this demonstration effectively. Overall, the comment is 4 as it directs the authors towards a specific area of improvement, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the manuscript regarding the use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the usage of P throughout the manuscript, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific issue but does not offer detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment identifies a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. It provides examples, such as equations (3) and (4) and line 44 in the appendix, where this confusion arises. This allows the authors to accurately pinpoint the part of the paper that needs clarification. The comment is specific in detailing what needs to be addressed, as it highlights the inconsistency and suggests that the authors should clarify the usage of P. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. The comment provides examples, such as equations (3) and (4) and line 44 in the appendix, where this confusion arises. However, it does not offer any additional reasoning, references, or examples to support the claim that this inconsistency leads to confusion. While the authors can infer that the comment is valid, the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the manuscript, noting that the symbol P is used inconsistently, sometimes representing a probability and other times a cumulative distribution function. This inconsistency can lead to confusion for readers. While the comment highlights the problem, it does not provide specific suggestions or guidance on how the authors might address this issue, such as clarifying the usage of P throughout the manuscript or providing examples of how to use it consistently. Without actionable advice or detailed feedback, the comment is 3 as it points out a potential area for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the definition of the \"contrastive gap,\" which is a core concept of the work. It notes that while an intuitive example on an \"idealized\" dataset was provided, the setting of this example is less convincing, and a clear, formal definition is still missing. The comment implies that the authors should provide a clear and formal definition of the contrastive gap to address the issue. However, it does not specify how to implement this suggestion, such as providing a formal definition or additional examples. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" a specific concept in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the definition of the contrastive gap, noting that it lacks clarity and formality, and that the current intuitive example is less convincing. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed \"contrastive gap\" has never been defined clearly, which is a subjective opinion. It suggests that the current intuitive example on the \"idealized\" dataset is less convincing and that a clear, formal definition is still lacking. However, the comment does not provide specific examples or references to support the claim that the definition is unclear or lacking. Without additional evidence or reasoning, the claim remains subjective and lacks verifiability. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by pointing out that the proposed \"contrastive gap\" lacks a clear and formal definition. This is a critical oversight that could hinder the understanding and reproducibility of the work. The comment suggests that the authors should provide a clear, formal definition of the contrastive gap, which is essential for the paper\"s clarity and rigor. However, the comment does not offer specific guidance on how to define the gap or what aspects of the concept need clarification. While it highlights a crucial area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it identifies a significant issue but lacks actionable guidance for the authors."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text (L_task) and the notation used in Figure 1 (L_class). This suggests that the authors should ensure consistency in their notation throughout the paper. However, the comment does not provide explicit guidance on how to address this inconsistency or what specific changes need to be made to the text or figures. The action is implicit, as the authors can infer that they need to correct the notation, but the lack of detailed instructions makes the action vague and challenging to execute. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment points out a discrepancy in notation between the text and Figure 1, specifically mentioning that the task loss is referred to as L_task in the text but L_class in the figure. This provides clear guidance on what needs to be addressed, as it highlights a specific inconsistency that the authors should correct. The comment is fully grounded because it explicitly mentions the parts of the paper where the issue occurs, allowing the authors to accurately identify the sections to address. It is also specific because it clearly specifies the inconsistency in notation, making it easy for the authors to understand and implement the correction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in notation between the text and Figure 1, specifically mentioning that the task loss is referred to as L_task in the text but L_class in the figure. This observation is factual and requires no further justification or explanation to be understood. The comment is a normal statement, as it describes a factual observation without making any claims or suggestions. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the notation used for the task loss between the text and Figure 1. This is a clear and actionable piece of feedback that the authors can easily address by ensuring consistency in their notation throughout the paper. By correcting this inconsistency, the authors can improve the clarity and accuracy of their presentation, making it easier for readers to understand the methodology and results. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the performance of RSD4PG monotonically increasing with respect to \u03bb values and suggests exploring what happens when \u03bb is even smaller. It also points out missing variables (\u03c4 and \u03b7) in the bracket on Page 3, Line 2, and missing variables (\u03c4 and \u03b7) in the equation on Page 3, Line 4. While the comment identifies specific areas that need clarification or further exploration, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1\" and specific locations on \"Page 3, Line 2\" and \"Page 3, Line 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as the performance of RSD4PG with respect to \u03bb values and the missing variables in the equations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the performance of RSD4PG with respect to \u03bb values and points out missing variables in equations. While the questions are specific and require the authors to investigate further, the comment lacks detailed reasoning or references to support the claims. The authors are left to infer the need for additional analysis or clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises specific questions about the performance of RSD4PG with respect to \u03bb values and points out missing variables in equations. It suggests exploring the behavior of the model with even smaller \u03bb values, which could provide valuable insights into the model\"s performance. Additionally, it identifies missing variables (\u03c4 and \u03b7) in the equations, indicating areas where clarification or correction is needed. While the comment highlights important areas for further investigation and correction, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it directs the authors to specific areas that need attention, but it could be more comprehensive with additional guidance on how to improve the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific instances where the authors need to address certain claims or statements in their paper. It explicitly mentions that the claims on lines 7879, 129130, 156158, and 217218 require citations or evidence. However, the comment does not provide any guidance on how the authors should go about finding or providing these citations or evidence. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment provides specific line numbers (7879, 129130, 156158, and 217218) where the authors need to address certain claims or statements. This allows the authors to accurately identify the parts of the paper being addressed, making the comment fully grounded. Additionally, the comment specifies what needs to be addressed in each instance, such as the need for citations or evidence. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies specific claims in the paper that require citations or evidence. It provides line numbers (7879, 129130, 156158, and 217218) where these claims are made, allowing the authors to accurately pinpoint the sections that need attention. However, the comment does not provide any examples, detailed reasoning, or references to support these claims, making it 3. The authors are informed about the need for citations or evidence but are not given specific guidance on how to obtain or present them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific instances in the paper where claims are made without sufficient evidence or citations. It points out that the authors need to provide citations for the claims on lines 7879, 129130, 156158, and 217218. This feedback is clear and actionable, as it directs the authors to specific areas where they need to enhance the rigor and credibility of their work by providing supporting evidence or citations. However, the comment could be more helpful if it offered suggestions on how to find or present the evidence. Overall, the comment is 4, as it effectively guides the authors in addressing the identified weaknesses."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the results of the bottomup method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. While the comment provides explicit guidance on what data to include and how to evaluate performance, it lacks specific instructions on how to implement these suggestions, such as which columns or metrics to focus on. The action is somewhat vague, as it does not provide detailed steps or examples for inclusion and evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the bottomup method [9]\" and \"Table 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what data to include in the table and how to evaluate the performance of the authors\" method on the MS COCO dataset, particularly in easy (nonoccluded) settings. This level of detail helps the authors understand exactly what needs to be addressed and how to do it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including the results of the bottomup method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. While the comment provides a clear suggestion for improvement, it lacks specific examples or references to support the claim that the bottomup method outperforms all methods in Table 4. The reasoning is somewhat vague, as it does not provide detailed explanations or evidence to substantiate the claim. Therefore, the comment is rated as 2, as it offers a suggestion but lacks sufficient justification or examples to fully support the claim.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft by including the results of the bottomup method [9] on the crowdpose dataset in Table 4 and evaluating the performance of the authors\" method on the standard MS COCO dataset, particularly in easy (nonoccluded) settings. This feedback is actionable and constructive, as it guides the authors on what additional data and analysis to include to strengthen their paper. However, the comment could be more helpful if it provided more detailed guidance on how to present the results or what specific metrics to focus on. Overall, the comment is 4, as it offers clear directions for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to add this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these methods in their experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. However, it does not specify which part of the paper this comparison should be made, leaving the authors to infer that it should be in the experimental section. The comment is specific in its suggestion to include these methods, but it lacks grounding as it does not pinpoint the exact section or part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not provide specific reasoning or examples to support why such a comparison is important or how it would enhance the paper. The lack of detailed justification or references makes the claim 3, as the authors may need to infer the importance of the suggested comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section by suggesting that it should include a comparison to coordinateaware methods like TFN or SchNet. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s experimental evaluation. By comparing against methods that are aware of point coordinates, the authors can better demonstrate the effectiveness of their approach. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or why such a comparison is essential. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While it implies that the authors should consider optimizing and validating their approach, the comment does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed for optimization and validation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ProtPainter\" and \"binder design,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that ProtPainter provides an empirical conformation estimation but lacks further optimization and validation, suggesting that these aspects need to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While the comment suggests that further optimization and validation are required, it does not provide specific examples or references to support this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. This feedback is clear and actionable, as it directs the authors to consider enhancing the optimization and validation aspects of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to optimize and validate the approach. Despite this, the comment offers a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model\"s time scale of adaptation. While the comment provides some context and suggests a potential area for further exploration, it does not explicitly instruct the authors to provide this information or clarify it in their draft. The action is implicit, as the authors need to infer that they should provide more details about the training process and the impact of cycle duration. However, the comment lacks concrete guidance on how to address this, making it 3.", "grounding_specificity_rationale": "The comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model\"s time scale of adaptation. However, the comment does not specify which part of the paper Figure 7 is located in, making it weakly grounded. It is specific in detailing what needs to be clarified regarding the training process and the impact of cycle duration. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point requests clarification on how the model in Figure 7 was trained and suggests considering the impact of changing the cycle duration on the model\"s time scale of adaptation, referencing Smirnakis et al. Nature 1997. While the comment provides a specific example for consideration, it does not offer detailed reasoning or evidence to support the claim that the model cannot handle longer time scales. The lack of explicit justification or detailed explanation makes the claim 3, as the authors would need to provide more context to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model\"s time scale of adaptation. It references a specific study, Smirnakis et al. Nature 1997, to provide context for the discussion. While the comment identifies a potential area for clarification and provides a reference for further exploration, it does not offer detailed guidance or suggestions on how to address the issue. The feedback is 3 as it points out a specific area that needs clarification, but it lacks depth and actionable advice, making it a 3 comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors need to provide a figure demonstrating the decline in accuracy of a predictor over time in different settings to support their claim about the motivation. This action is clear and concrete, as it specifies exactly what the authors should do to address the issue. The comment is fully actionable, as it provides a direct and detailed instruction on how to improve the paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first question being raised, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of direct evidence for the motivation and suggests a way to support it by plotting a figure showing the decline in accuracy over time in different settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evidence of the motivation is not direct and suggests that the authors need to plot a figure to support their claim. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide more context or examples to fully understand the reasoning behind the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the evidence supporting the motivation is not direct. It suggests that the authors need to provide a figure demonstrating the decline in accuracy of a predictor over time in different settings to support their claim. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that the authors can easily implement. By addressing this issue, the authors can strengthen the motivation and provide more robust evidence for their claims. Therefore, the comment is 5, as it offers a clear and actionable direction for enhancing the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It asks the authors to explain how excessive risk is defined in line 103 and how it is calculated in practice, particularly in terms of expectation. The comment also questions why excessive risk is a good representation for fairness, given that the optimal solution \u03b8* is not the optimal solution for the loss function with respect to data of group a, potentially leading to negative values. The reviewer points out that all excessive risk values in Figure 3 and Figure 7 are positive and asks if values of excessive risk are comparable among different groups. These questions and requests for clarification provide explicit guidance on what the authors should address, making the comment 5. The authors know exactly what aspects of the paper need further explanation or clarification, which helps them improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 103,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, including the definition of excessive risk, its calculation, and its comparability across different groups. This level of detail provides clear guidance on how the authors should respond, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises several questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It does not contain any subjective opinions or claims that require verification. The questions are logical and seek to understand the methodology and reasoning behind the calculations, which aligns with normal statements. Therefore, the comment is classified as \"X\".", "helpfulness_rationale": "The review comment provides detailed questions and requests for clarification regarding the definition of excessive risk, its calculation, and its comparability across different groups. It specifically asks the authors to explain how excessive risk is defined in line 103, how it is calculated in practice, and why it is a good representation for fairness. The reviewer also points out a potential issue with the values in Figure 3 and Figure 7, noting that they are all positive despite the theoretical possibility of negative values. This feedback is clear and actionable, as it directs the authors to specific areas of the paper that need further explanation or clarification. By addressing these points, the authors can significantly improve the clarity and robustness of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This is an explicit action that the authors can directly implement by adding experiments with GPT3.5. The suggestion is clear and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs to be addressed. The comment is specific in its suggestion to include experiments with GPT3.5, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. While the suggestion is logical and aligns with the idea of costeffectiveness, it lacks specific examples or references to support the claim that GPT3.5 would provide a more comprehensive evaluation. The comment is 3 as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly suggests an improvement that could enhance the paper\"s evaluation. By including experiments with GPT3.5, the authors can address the cost concern and provide a more thorough assessment of their approach. This feedback is 4 as it offers a specific and actionable suggestion, but it could be further enhanced by providing more details on how the inclusion of GPT3.5 experiments would impact the evaluation. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4, specifically mentioning the BLEU score for WMT17WIKT. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be done to improve their draft, which aligns with the definition of a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be included in the table, namely bold numbers for the baselines of previous work, particularly for WMT17WIKT, where the best BLEU result is in the baselines. This level of detail helps the authors understand exactly what changes are required. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that requests the inclusion of specific formatting in Table 4, particularly for the baselines of previous work. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is specific and actionable, as it provides clear guidance on what needs to be included in Table 4. It requests the inclusion of bold numbers for the baselines of previous work, particularly for WMT17WIKT, where the best BLEU result is in the baselines. This feedback is valuable as it directly addresses a specific aspect of the paper and helps the authors improve the clarity and presentation of their results. However, the comment could be more helpful if it suggested additional improvements or provided more context. Overall, it is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for examples of \"unreliable neighbors,\" which implies that the authors should provide specific instances to clarify the concept. However, it does not explicitly instruct the authors to include these examples in their draft or suggest where they should be added. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples and understand the context of \"unreliable neighbors.\" Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 170 to 171, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests examples of \"unreliable neighbors,\" which directly points out what needs clarification or further explanation in that section. This provides clear guidance on what the authors should address to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks for examples of \"unreliable neighbors,\" which is a request for clarification and does not contain a subjective claim or suggestion that requires verification. It is a factual request for information, making it a \"No\" category.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area where the authors need to provide examples of \"unreliable neighbors.\" This feedback is clear and actionable, guiding the authors to clarify a particular concept in their draft. However, it could be more helpful if it suggested where these examples should be included or how they should be presented. Overall, the comment provides a clear direction for improvement, making it a 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the interesting findings of the work but expresses concern about the limited novelty, suggesting that the observations, such as tighter confidence intervals (CIs) with finetuning, are expected. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to enhance the novelty of the work or what specific aspects need to be improved. Without actionable suggestions or concrete steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the novelty of the findings, pointing out that the observations, such as tighter confidence intervals with finetuning, are expected. This allows the authors to understand the specific issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, suggesting that the observations, such as tighter confidence intervals (CIs) with finetuning, are expected. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the critique. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the work, specifically questioning the expected nature of observations like tighter confidence intervals (CIs) with finetuning. While it acknowledges the interesting findings, it does not provide actionable feedback or suggestions on how the authors might address this concern or enhance the novelty of their work. The comment lacks depth and specificity, making it 3 as it highlights an area for improvement but does not offer concrete guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. It provides a specific example of how the tables could be reorganized, suggesting that the 8 SFII columns and the 8 SPDI columns should be separated. This feedback is explicit and concrete, as it directly instructs the authors on how to improve the readability of the tables. The action is clear and actionable, providing a specific and detailed suggestion for the authors to implement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4 and 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion for improving the readability of these tables by splitting them into two tables each, with one table per measure. The example provided, such as separating the 8 SFII columns and the 8 SPDI columns, further clarifies the intended improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Tables 4 and 5 would be more readable if they were split into two tables each, with one table per measure. While the suggestion is logical and could improve readability, the comment lacks specific examples or references to support why this change would be beneficial. It does not provide detailed reasoning or evidence to justify the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the readability of Tables 4 and 5 by splitting them into two tables each, with one table per measure. This is a clear and actionable piece of feedback that directly addresses a potential issue with the presentation of the data. By separating the 8 SFII columns and the 8 SPDI columns, the authors can enhance the clarity and ease of understanding of the tables. This feedback is constructive and provides a concrete suggestion for improvement, making it 4. However, it could be more helpful if it included additional suggestions or considerations for further improvement. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "No", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a clear and explicit action that the authors can take to improve their draft. The comment provides a specific request for clarification, which helps the authors understand what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between \"valid\" and \"orig\". This provides the authors with a clear understanding of what revisions are necessary. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a request for clarification and does not contain a subjective opinion or claim that requires verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is helpful as it provides a specific request for clarification regarding the differences between \"valid\" and \"orig\" in Figure 5. This feedback is actionable and directly addresses a potential area of confusion for the authors, helping them improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it provided additional context or suggestions for how to clarify the differences. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could be improved by making comparisons more systematic with respect to the tuning of each method, specifically by comparing the best performance of each. However, it does not provide explicit guidance on how to achieve this, leaving the authors to infer the necessary steps. The action is implicit and somewhat vague, as it does not specify which parts of the paper need to be revised or how to conduct the systematic comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper by Zemel et al. (2013) and the comparison with the present work. It also specifies the need to make comparisons more systematic with respect to the tuning of each method, particularly by comparing the best performance of each. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method, specifically by comparing the best performance of each. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the suggestion, making it difficult for the authors to understand and implement the proposed improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper by suggesting that the comparisons with the work of Zemel et al. (2013) could be more systematic, particularly by comparing the best performance of each method. This feedback is actionable and provides a clear direction for the authors to enhance their work. However, the comment could be more helpful if it offered additional guidance on how to conduct these systematic comparisons or suggested specific metrics for evaluating performance. Despite this, the comment is 4 as it directs the authors towards a concrete improvement strategy, aligning with a score of 4."}
