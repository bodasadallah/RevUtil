{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the description of HIERENC, suggesting that the current explanation is unclear and that the method of averaging representations from all possible entity instantiations might introduce noise. However, the comment does not provide explicit guidance on how the authors should revise the description or address the issue of noise. While it identifies a problem, it lacks concrete steps or suggestions for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the description of HIERENC, providing a specific explanation of how the input (h_i) is processed. It highlights a potential issue with the method of averaging representations from all possible entity instantiations, suggesting that this approach might introduce noise. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific because it clearly specifies the issue with the description of HIERENC. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging representations from all possible entity instantiations might introduce noise. While the reviewer provides a specific example of how the input is processed, the claim lacks detailed reasoning or references to support the assertion that this approach is problematic. The comment could be more verifiable with additional explanation or evidence, but it is still 3 as it provides a basis for understanding the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the method of averaging representations from all possible entity instantiations might introduce noise. This feedback is clear and actionable, as it points out a potential problem with the methodology and suggests that the authors should consider alternative approaches or provide a more detailed explanation of the process. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address the issue of noise. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include an ablation study to demonstrate the importance of the postprocessing steps used to filter out \"falsepositive\" neurons. While the comment implies that an ablation study is needed, it does not explicitly instruct the authors to conduct one or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that an ablation study is necessary to validate the significance of the postprocessing steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of integrated gradients and postprocessing steps, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a gap in the paper by noting that the importance of these postprocessing steps is not shown, suggesting the need for an ablation study. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not show how important the postprocessing steps are, suggesting that an ablation study may be needed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim is 3, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the use of integrated gradients for measuring attribution has been studied in existing papers. It also notes that the paper proposes postprocessing steps to filter out \"falsepositive\" neurons but does not demonstrate their importance. The comment suggests that an ablation study might be needed to show the significance of these postprocessing steps. This feedback is 3 as it highlights a specific area where the paper could be strengthened by providing more evidence or analysis. However, it could be more helpful if it provided more detailed guidance on how to conduct the ablation study or suggested alternative approaches to demonstrate the importance of the postprocessing steps. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide explicit guidance or suggestions on how to address this issue or improve the method. The action is implicit, as the authors would need to infer that they should clarify the method or provide more details on how to handle nonpronoun head words. The comment is vague and lacks concrete details on how to implement the suggested action. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it weakly grounded. The comment is specific in its focus on the method proposed by the authors and the challenge of identifying antecedents when the prediction is a pronoun. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide any evidence, reasoning, or references to support the claim that the method is unclear or lacks detail. Without additional context or justification, the authors may find it difficult to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about how an antecedent can be identified when the prediction is a pronoun, particularly questioning the method proposed by the authors. It highlights a lack of clarity in handling situations where the head word is not a pronoun. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the method. The feedback is 3 as it identifies a potential area for clarification, but it lacks depth and actionable advice, leaving the authors with limited insights to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its suggestion to include additional baselines, but it lacks grounding as it does not provide context or references to specific sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of more diverse baselines. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to implement this suggestion or why character embeddings are particularly relevant. The authors are left with a general idea of what to add but without concrete steps or rationale, which limits the comment\"s overall helpfulness. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is easier to demonstrate that something does not work in sequencetosequence multitask learning (MTL) with attention, but the value lies in understanding why it fails and changing the attention mechanism to make it work. However, the comment does not provide explicit guidance on how to identify the reasons for failure or how to change the attention mechanism. It lacks concrete steps or suggestions for the authors to take, making it difficult for them to apply the feedback effectively. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that it is easier to demonstrate that something does not work in sequencetosequence multitask learning (MTL) with attention, but the value lies in understanding why it fails and changing the attention mechanism to make it work. However, the comment does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to understand where to focus their efforts. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that it is easier to demonstrate that something does not work in sequencetosequence multitask learning (MTL) with attention, but the value lies in understanding why it fails and changing the attention mechanism to make it work. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification for why this approach is valuable or how it could be implemented. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment provides a valuable insight by suggesting that it is easier to demonstrate why a sequencetosequence multitask learning (MTL) with attention mechanism does not work, but the value lies in understanding the reasons for its failure and proposing changes to make it work. This feedback is 3 as it highlights a potential area for improvement and encourages the authors to delve deeper into the problem. However, the comment could be more helpful if it provided specific guidance or suggestions on how to identify the reasons for failure or how to change the attention mechanism. Overall, the comment offers a direction for improvement but lacks detailed actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies the main weaknesses of the paper as the experiments, specifically noting that they are only conducted in an extremely lowresource regime and for a sentence classification task, which are not representative of realworld applications. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks but does not provide explicit guidance on how to address these issues or improve the experiments. While the comment highlights areas for improvement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides some direction but does not fully guide the authors on how to address the identified weaknesses.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically focusing on the experiments. It mentions that the experiments are only conducted in an extremely lowresource regime and for a sentence classification task, which are not representative of realworld applications. The reviewer also suggests that the proposed augmentation method has potential for use in more NLP tasks but notes that this was not shown. However, the comment does not specify which part of the paper discusses the experiments or the tasks, making it weakly grounded. It is specific in detailing the issues with the experiments, such as the lowresource regime and the sentence classification task, but lacks a clear reference to the specific sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point identifies two main weaknesses of the paper: the experiments being limited to an extremely lowresource regime and the sentence classification task being relatively easy. It also suggests that the proposed augmentation method has potential for use in more NLP tasks but notes that this was not shown. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning provided is somewhat vague, as it does not offer detailed explanations or evidence to substantiate the claims. Therefore, the comment is rated as 2, as it provides some basis for the claims but lacks sufficient detail or evidence to fully support the critique.", "helpfulness_rationale": "The review comment identifies the main weaknesses of the paper, specifically focusing on the experiments. It points out that the experiments are limited to an extremely lowresource regime and are conducted on a sentence classification task, which may not be representative of realworld applications. The reviewer also suggests that the proposed augmentation method has potential for use in more NLP tasks but notes that this was not shown. While the comment highlights areas for improvement, it lacks specific guidance or suggestions on how to address these weaknesses or enhance the experiments. The feedback is 3 as it provides a clear direction for the authors to consider, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some claims in the paper would benefit from more indepth analysis. However, it does not specify which claims need more analysis or provide any guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they should delve deeper into the analysis of certain claims. Without explicit instructions or concrete examples, the authors are unable to understand what specific aspects require more detailed analysis. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some claims in the paper would benefit from more indepth analysis. However, it does not specify which claims or sections of the paper are being referred to, nor does it provide any guidance on how to conduct this analysis. The lack of specific information makes it difficult for the authors to identify the exact parts of the paper that need improvement. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that some claims in the paper would benefit from more indepth analysis. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors are left to infer the need for more indepth analysis, making the claim 3. The comment lacks detailed evidence or logical reasoning to fully substantiate the suggestion, which limits its verifiability.", "helpfulness_rationale": "The review comment suggests that some claims in the paper would benefit from more indepth analysis. While this feedback provides a direction for improvement, it lacks specific details or actionable suggestions on which claims need more analysis or how to conduct this analysis. The comment is 3 as it identifies an area for enhancement but does not offer comprehensive guidance or examples, leaving the authors with a general idea of what to work on but without a clear roadmap. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" and suggests that it might be misleading, as it is typically used to refer to external knowledge like a knowledge base of entities. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should reconsider the representation of substructures and the use of the term \"knowledge.\" The comment is 3 because it identifies areas for improvement but lacks concrete details on how to implement the suggestions. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It also questions the use of the term \"knowledge\" and suggests that it might be misleading, as it is typically used to refer to external knowledge like a knowledge base of entities, whereas here it is really just syntax or arguably semantics if AMR parsing is used. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the representation of substructures and the use of the term \"knowledge,\" but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It questions the use of the term \"knowledge\" and suggests that it might be misleading, as it is typically used to refer to external knowledge like a knowledge base of entities, whereas here it is really just syntax or arguably semantics if AMR parsing is used. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the feedback. The lack of detailed reasoning or evidence makes the claim 3, as it is based on logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the claim that the model generalizes to different knowledge, suggesting that the substructure should be represented as a sequence of words rather than using constituent parse as knowledge. It questions the use of the term \"knowledge\" and suggests that it might be misleading, as it is typically used to refer to external knowledge like a knowledge base of entities, whereas here it is really just syntax or arguably semantics if AMR parsing is used. This feedback is 3 as it identifies a potential issue with the representation of substructures and the use of the term \"knowledge,\" which could guide the authors in refining their claims and terminology. However, the comment lacks specific suggestions or detailed guidance on how to address these concerns, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the performance of nouns compared to clustering approaches, noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific analyses or improvements to address the performance discrepancy or the contradiction. The authors are left without clear guidance on how to address these issues, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance of nouns and clustering approaches, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the higher oracle GAP for PPDBClus compared to most clustering approaches and the contradiction with the claim of generalizability to all parts of speech. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment lacks specific examples or references to support the claim that the clustering approach is generalizable to all parts of speech. Without additional evidence or context, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. This feedback is 3 as it identifies a potential issue with the clustering approach\"s generalizability and highlights an area that needs further investigation. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address the performance discrepancy or the contradiction. Without actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it contradicts itself by stating that this is false and providing references. However, it does not explicitly instruct the authors to include these tools or provide guidance on how to do so. The comment is vague and lacks specific instructions, leaving the authors uncertain about the exact actions they should take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reinforcement learning setting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it claims that there is no corresponding set of tools for this setting and provides references to support this claim. This feedback is clear and actionable, guiding the authors to consider the inclusion of such tools. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it contradicts itself by stating that this is false and provides references. However, the comment does not offer any detailed reasoning or explanation for why the claim is false or how the references support the argument. The lack of specific examples or detailed reasoning makes it difficult for the authors to understand and address the issue. Therefore, the comment is considered 2, as it provides some justification but lacks key elements for full clarity and support.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the absence of corresponding tools for the reinforcement learning setting. It claims that this is false and provides references to support the argument. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or incorporate the suggested tools. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides some insight but lacks depth and constructive suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. Second, it suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific comparisons or exploring the potential of the technique. The feedback lacks concrete guidance on how to address the concerns or implement the suggestions, leaving the authors without clear directions for improvement. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of a proposal generator pretrained on MSCOCO, questioning the fairness of comparisons with other methods. It also suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not specify which part of the paper discusses the comparison with other methods or the potential promotion of existing methods. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. While the comment is specific about the issues raised, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. It also suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without clear justification or evidence, the claims remain speculative and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. It also suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment lacks specific details or actionable suggestions on how to address these concerns or explore the potential of the technique. While it identifies an area for improvement, it does not provide clear guidance or insights that would help the authors enhance their work. Therefore, the comment is 3, as it points out a potential issue but does not offer substantial feedback for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Section 4 is written in a very concise manner, which might be due to space limitations. It implies that the section could have been written more slowly to improve readability. However, the comment does not provide explicit guidance on how to achieve this, such as suggesting specific ways to expand the section or what content could be added to enhance readability. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the section for better clarity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the section is written in a very concise manner and suggests that it could have been written more slowly for easier readability. This provides clear guidance on what needs to be improved in the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Section 4 is written in a very concise manner, which might be due to space limitations. It suggests that the section could have been written more slowly for easier readability. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style of Section 4, noting that it is written in a very concise manner, which could hinder readability. While the comment suggests that the section could have been written more slowly for easier comprehension, it lacks detailed guidance or suggestions on how to achieve this. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps or specific advice on how to enhance the readability of the section. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the lack of comparison to a highly relevant method that utilizes both intertask and intratask ensembles. It explicitly mentions that the authors did not include a method comparison or performance comparison with this relevant method. This feedback is clear and provides a direct action for the authors to take, which is to include a comparison with the mentioned method. The comment is explicit and concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with a highly relevant method, providing clear guidance on what part of the paper needs improvement. It specifies the issue by mentioning the method that should have been compared, which helps the authors understand exactly what needs to be addressed. The comment is also specific, as it clearly identifies the missing comparison and suggests that the authors should include it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors did not include a comparison with a highly relevant method that utilizes both intertask and intratask ensembles. However, the comment lacks specific details or references to support this claim. It does not provide examples of how the comparison could be made or why it is important. Without additional information or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comparison with a highly relevant method that utilizes both intertask and intratask ensembles. It highlights that the authors did not include a method comparison or performance comparison with this relevant method, which is a critical oversight. This feedback is clear and actionable, as it directs the authors to address this gap by incorporating a comparison with the mentioned method. By doing so, the authors can provide a more comprehensive and robust evaluation of their approach, enhancing the overall quality and impact of their work. Therefore, the comment is 5, as it provides specific guidance on how to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that the pipeline method does not yield better average results compared to baseline models. It also points out that the baseline models are not well introduced in the experiments. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes need to be made to the draft. The action is implicit, as the authors can infer that they need to improve the introduction of baseline models and potentially reevaluate the experimental results. The lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results of a pipeline method, specifically mentioning that it does not yield better average results for both XVNLI and MaRVL. It also notes that the baseline models are not well introduced in the experiments. However, the comment does not specify which part of the paper discusses the experimental results or the introduction of baseline models, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of baseline model introduction, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline method does not yield better average results for both XVNLI and MaRVL, and that the baseline models are not well introduced in the experiments. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or evidence to substantiate the assertion that the baseline models are poorly introduced. Without such evidence, the claim remains 3, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the pipeline method does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models are not well introduced in the experiments. While the comment highlights a potential weakness in the experimental setup, it lacks detailed guidance on how the authors might address this issue or what specific changes could be made to improve the results. The feedback is 3 as it directs the authors\" attention to a critical aspect of their experimental evaluation, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of reproducing a wellknown result using a \"coarse\" methodology, suggesting that the observation has been made at each step of the evolution of language models. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative methodologies or providing more detailed analysis. The comment lacks concrete guidance on how the authors might address this concern or improve their draft. As a result, the comment is 1, aligning with a score of 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used in reproducing a wellknown result in the literature, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the methodology, questioning its necessity given prior observations. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the authors have reproduced a wellknown result using a \"coarse\" methodology, questioning the necessity of this approach given prior observations. However, the comment lacks specific examples or references to support the claim that the observation has been made at each step of language model evolution. Without detailed evidence or examples, the claim remains 3, as the authors may need to provide more context or justification to fully understand the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the authors\" methodology for reproducing a wellknown result about political bias in language models, specifically questioning the necessity of using a \"coarse\" methodology given prior observations. While the comment identifies a potential issue with the approach, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their methodology. The feedback is 3 as it highlights a potential area for improvement, but it lacks actionable advice or detailed suggestions, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the explanation of how a small degree of bias can be derived from a clear community structure, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so or specify how to improve the explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the relationship between degree bias and community structure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the explanation of how a small degree of bias can be derived from a clear community structure, referencing Theorem 1 and 2. However, it does not specify which part of the paper this explanation is intended for, making it weakly grounded. The comment is specific in its critique of the lack of intuitive understanding of the relationship between degree bias and community structure, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the explanation of how a small degree of bias can be derived from a clear community structure, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. While the comment implies that the authors should provide more detailed explanations, it lacks specific examples or references to support the claim that the relationship is not intuitive enough. This makes the claim 3, as it highlights a potential area for improvement but does not provide sufficient evidence or guidance for the authors to address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing more detailed explanations. It points out that while Theorem 1 and 2 prove the relationship between a clear community structure and GCL, the connection to degree bias is not intuitive enough, suggesting that the authors should elaborate on this aspect. This feedback is clear and actionable, as it directs the authors to enhance the explanation of the relationship between community structure, GCL, and degree bias. However, the comment could be more helpful if it provided specific suggestions or examples of how to improve the explanation. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the clarity of the notation used in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a specific area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the clarity of notation in the paper, particularly the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the variables S and Xt, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact location of the problem. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that this confusion is significant or how it affects the paper. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of notation in the paper, specifically the confusion caused by the explicit split between \"static\" and temporal features into two variables, S and Xt. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for clarification, but it lacks actionable advice or detailed examples, which could leave the authors uncertain about how to proceed. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that INRs operate on a perdatainstance basis, arguing that this is not an advantage and that such a model would be almost useless. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors might infer that they need to reconsider the framing of their argument or provide a more nuanced perspective on the utility of perdatainstance operations. The comment lacks concrete details on how to implement this feedback, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the claim about INRs operating on a perdatainstance basis, arguing that this is not an advantage and that such a model would be almost useless. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR\" is true but argues that it is not an advantage. The reviewer provides a logical reasoning by suggesting that a model capable of handling only a single timeseries instance is almost useless. However, the comment lacks specific examples or references to support the claim that this limitation is indeed a significant drawback. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper, stating that INRs operate on a perdatainstance basis, and argues that this is not an advantage. The reviewer provides a logical reasoning by suggesting that such a model would be almost useless. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or improve their draft. While it highlights a potential weakness, it does not provide concrete steps or insights for the authors to enhance their work. Therefore, the comment is 3, as it points out a concern but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with largescale datasets. While the comment identifies a potential issue with the learning rate condition, it does not provide explicit guidance on how the authors might address this concern or what specific changes could be made to the draft. The action is implicit, as the authors would need to infer that they should consider alternative learning rate scaling strategies or provide a more realistic justification for the current condition. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the scalability of the required condition on the learning rate, which is a critical aspect of the paper. It highlights a concern that the learning rate scales with the number of samples, a point that is not realistic in practice. The comment is fully grounded as it explicitly mentions the learning rate condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the learning rate condition and its implications for scalability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with largescale datasets. The comment provides a logical reasoning for why the condition might be unrealistic, but it lacks specific examples or references to support the claim. Without additional evidence or references, the claim is 3, as it offers a plausible argument but does not provide a comprehensive basis for the authors to address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the scalability of the required condition on the learning rate, noting that it scales with the number of samples. The reviewer argues that this condition is not realistic in practice, as the step size does not typically grow with the sample size, potentially leading to unreasonably large learning rates for largescale datasets. While the comment highlights a potential issue with the learning rate condition, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the draft. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a potential issue with the use of unlabeled data, noting that the data is perfectly balanced and may not be practical in realworld applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This comment provides a clear and explicit action for the authors to take, which is to consider using a more realistic setting for their experiments. The suggestion is concrete and offers a specific example of how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"preprocessed Amazon review dataset (Blitzer version)\" and the \"2000 unlabeled data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear rationale for the issue, suggesting that the authors should consider using a more convincing setting as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This provides a specific example of how the authors could address the issue, making the comment 5.", "verifiability_rationale": "The review point claims that the use of perfectly balanced unlabeled data is impractical in realworld applications and suggests using a more convincing setting as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. The claim is supported by the reasoning that controlling label distribution during training is difficult in realworld scenarios, and the suggestion provides a specific example of a more realistic setting. However, the comment could be more robust if it included a detailed explanation of why the suggested approach is more convincing or how it addresses the limitations of the current method. Overall, the claim is 4, as it is supported by logical reasoning and a reference to a relevant work, but it could benefit from additional justification or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of unlabeled data, specifically noting that the data is perfectly balanced and may not be practical in realworld applications. It suggests that the authors should consider using a more convincing setting, such as sampling unlabeled data from millions of reviews, as done in Adaptive Semisupervised Learning for Crossdomain Sentiment Classification, He et al., EMNLP 2018. This feedback is clear and actionable, providing the authors with a specific direction to improve their experimental setup. By suggesting a more realistic setting, the comment helps the authors enhance the practical relevance and applicability of their work. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify the sampling process. The action is implicit, as the authors need to infer that they should seek clarification or provide more details on the sampling method. The comment is vague and lacks concrete suggestions, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. However, it does not provide a clear indication of which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in that it identifies a potential issue with the clarity of the sampling process, but it does not offer detailed guidance on how to address it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment lacks specific examples or detailed reasoning to support the claim that the sampling process is unclear or that it is similar to sampling from the leverage score. Without additional context or evidence, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this problem is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide any actionable guidance or suggestions on how the authors might address this issue or clarify the sampling process. It lacks depth and specificity, making it difficult for the authors to understand the exact nature of the problem and how to resolve it. Therefore, the comment is 2, as it highlights a potential area for improvement but does not offer concrete advice or solutions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. It suggests that the experiments section is not useful due to the absence of relevant experiments, even simulated ones. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the experimental section. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results of the paper and the specific examples used to motivate the solution for POMDP problems with nonconvex value functions. It clearly identifies the parts of the paper that need attention, making it easy for the authors to understand which sections are relevant. The comment is also specific because it details the issues with the experimental setup, questioning the motivation for the chosen examples and the lack of experiments on the described settings. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point expresses a concern about the experimental results, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. It provides examples of POMDP problems with nonconvex value functions, such as surveillance in museums with thresholded rewards and privacypreserving data collection. However, the comment does not offer any specific reasoning or evidence to support the claim that the experiments are not useful or that the examples are insufficient. The feedback lacks detailed justification or references, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 2, as it provides some context but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment raises concerns about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. The examples provided, such as surveillance in museums with thresholded rewards and privacypreserving data collection, are used to motivate the solution for POMDP problems with nonconvex value functions. However, the reviewer points out that there are no experiments on these settings, even simulated ones, which makes the experiments section less useful. While the comment identifies a potential weakness in the experimental design, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it highlights an area for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a critical limitation in the study of sequential ensembling, specifically the lack of consideration for noise accumulation in homomorphic encryption. It points out that this omission prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit, as the authors need to infer that they should study the effect of noise accumulation in the context of homomorphic encryption to address the identified limitation. While the action is somewhat vague, it is clear that the authors need to consider this aspect to improve their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to sequential ensembling and noise accumulation in the context of homomorphic encryption. It highlights a limitation that prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that for sequential ensembling, it is important to study the effect of noise accumulation in the context of homomorphic encryption. This limitation prevents the use of even single deep neural networks on homomorphically encrypted data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. While the logic is somewhat inferable, the lack of detailed evidence or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a specific limitation in the study of sequential ensembling, particularly the lack of consideration for noise accumulation in the context of homomorphic encryption. This limitation is significant because it prevents the use of even single deep neural networks on homomorphically encrypted data, which is a critical aspect of the research. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments or analyses could be conducted to overcome this limitation. While it highlights an important area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors would need to infer that they should focus on studying noise accumulation in homomorphic encryption to enhance their work, but the comment does not fully support this inference."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, it should be used a standard regularization trick. However, the comment does not provide any explicit or implicit guidance on how to implement this suggestion or what specific aspects of the comparison need to be addressed. The authors are left without a clear understanding of how to apply this feedback, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a stronglyconvave case. However, it does not specify which part of the paper this comparison is intended for or which section discusses the previous result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment is specific about the type of regularization trick, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, it should be used a standard regularization trick. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a stronglyconvex concave case, it should be used a standard regularization trick. This feedback is 3 as it identifies a specific area for improvement in the comparison of the proposed method with existing results. However, the comment lacks depth and does not provide detailed guidance on how to implement the suggested change or what specific aspects of the comparison need to be addressed. The authors would benefit from additional clarification or examples to fully understand and apply this feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the handling of different types of inputs and the disordered citation. For the first part, it suggests that the authors should discuss how they deal with various inputs, such as biomedical signals or speech, and present their solutions. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be addressed and how to do it. However, the comment does not specify which part of the paper this discussion should be included in, leaving some ambiguity. For the second part, the comment suggests that the citation is disordered, but it does not provide specific guidance on how to correct it. While the action is somewhat explicit for the first part, the second part lacks detail, making the comment 3 overall.", "grounding_specificity_rationale": "The comment addresses the handling of different types of inputs, such as biomedical signals or speech, suggesting that the authors should discuss this and present their solutions. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting that the authors should discuss how they handle these different types of inputs and present their solutions, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two main concerns: the handling of different types of inputs and the disordered citation. While the comment suggests that the authors should discuss how they deal with various inputs, such as biomedical signals or speech, it does not provide specific examples or references to support this claim. The suggestion to present solutions is clear, but the lack of detailed reasoning or examples makes the claim 3. The comment also mentions that the citation is disordered, but it does not elaborate on why it is disordered or how it should be corrected, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the handling of different types of inputs and the disordered citation. It suggests that the authors should discuss how they deal with various inputs, such as biomedical signals or speech, and present their solutions in the paper. This provides a clear direction for the authors to enhance their work. However, the comment lacks specific guidance on which sections of the paper should address this issue or how to present the solutions effectively. Additionally, while it points out the disordered citation, it does not offer detailed suggestions on how to correct it. Overall, the comment is 3 as it highlights important areas for improvement but could be more comprehensive with detailed guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit, as the authors need to infer that they should expand the discussion to address the accuracy drop. While the action is somewhat concrete, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the improvement in consistency and verifiability has negatively impacted accuracy scores, which need to be discussed in more detail. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that the ICLHAR, while improving consistency and verifiability, has negatively impacted accuracy scores, dropping from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. However, the claim lacks specific examples or references to support the claim that the accuracy drop is significant or requires detailed discussion. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides a basis for discussion but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the ICLHAR, noting that while it improves consistency and verifiability, it negatively impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This observation is important for the authors to address, as it highlights a potential tradeoff between consistency and accuracy. However, the comment lacks actionable guidance on how to address this issue or what specific aspects of the discussion should be expanded to acknowledge the accuracy drop. While it points out a critical area for improvement, it does not provide detailed suggestions or steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3, as it offers some insight but requires further elaboration to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any specific guidance or suggestions on how the authors should address these issues. The comment lacks explicit actions or concrete steps that the authors can take to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to resolve the identified issues. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which part of the paper these issues are present in, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is 1 as it does not provide specific references or sections of the paper that need attention. Additionally, it lacks specificity in detailing the nature of the writing issues, such as examples of unclear sentences or specific grammatical errors. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains \"severe writing issues such as grammatical errors, abuses of mathematical symbols, unclear sentences, etc.\" However, it does not provide any specific examples or references to support these claims. Without detailed examples or references, the authors may find it challenging to understand the nature and extent of the issues. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address these issues. Without actionable feedback or examples of how to improve the writing, the authors are left without a clear path forward. Therefore, the comment is 2, as it highlights areas for improvement but does not offer substantial assistance in enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should revise the statement or what specific changes are needed to make it more robust. While the authors can infer that they should strengthen the statement by acknowledging the debate and providing more context, the lack of concrete suggestions makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not specify which part of the introduction contains this statement, making it difficult for the authors to pinpoint the exact area that needs revision. While the authors can infer that the critique applies to the introduction, the lack of explicit grounding makes the comment weakly grounded. The comment is specific in its critique of the statement\"s weakness, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, suggesting that it is widely accepted that backpropagation is biologically implausible. The comment provides a logical reasoning by stating that the statement is too weak and that it is widely accepted that backpropagation is biologically implausible. However, it lacks specific examples or references to support the claim, making it 3. The authors can infer that the statement needs to be revised to acknowledge the debate and provide more context, but the lack of detailed justification or examples makes it challenging to fully understand the reasoning behind the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the statement regarding the biological plausibility of backpropagation is too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is clear and actionable, as it provides a direct critique of the statement and suggests that it should be revised to acknowledge the debate and provide more context. However, the comment could be more helpful if it offered specific guidance on how to revise the statement or what additional information could be included to strengthen the argument. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper by noting that it does not thoroughly explore the implications of the proposed method for other NLP tasks. While it points out this limitation, it does not provide explicit guidance on how the authors might address this issue or what specific steps they should take to enhance the generalizability of their results. The action is implicit, as the authors need to infer that they should explore the method\"s applicability to other NLP tasks. However, the comment lacks concrete details on how to implement this exploration, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s exploration of contrastive learning in code search tasks, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered 2, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by noting that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation highlights a potential gap in the paper\"s generalizability, as the results may not be applicable to a broader range of NLP tasks. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or explore the method\"s applicability to other NLP tasks. While it points out an important area for improvement, the feedback could be more helpful if it provided actionable steps or examples of how to expand the analysis. Therefore, the comment is 3, as it identifies a relevant issue but does not offer detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of the term \"certificate\" in the paper, specifically at line 267. It suggests that the term might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. The authors are left without a clear understanding of what changes are needed to clarify the terminology or how to avoid potential misinterpretations. Therefore, the comment is 1 as it lacks specific instructions or guidance on how to resolve the issue.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the use of the term \"certificate\" in the paper, particularly at line 267. It highlights a potential misinterpretation due to the strong meaning of \"certificate\" in complexity theory. However, the comment does not provide specific guidance on how the authors should address this issue or what changes might be necessary. The authors can infer that the issue pertains to the clarity and potential misinterpretation of the term, but the lack of explicit guidance makes the comment weakly grounded. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the use of the term \"certificate\" in the paper might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the context or address the issue effectively. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, specifically at line 267. It points out that the term might be misinterpreted due to its strong meaning in complexity theory. This feedback is 3 as it highlights a potential area of confusion that the authors should consider. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or clarify the terminology. Without actionable advice or examples, the authors may struggle to improve their draft based on this feedback alone. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used, which would be interesting to demonstrate. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the experiments. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments being limited to toy data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experiments, suggesting that the method\"s performance should be evaluated on real data where barycenters can be used. This provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests evaluating the method\"s performance on real data where barycenters can be used. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered verifiable. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used, which would be interesting to demonstrate. This feedback is 3 as it points out a specific area for improvement and suggests an interesting direction for future work. However, it lacks detailed guidance on how to implement this suggestion or what specific changes should be made to the experiments. Therefore, the comment is rated as 3, as it provides some insight but could be more comprehensive and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, making the motivation of Algorithm 1 unclear. However, it does not provide explicit guidance on how the authors should reformulate the subproblem or how this reformulation would clarify the motivation of Algorithm 1. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proxlinear subproblem in Eq.(1) and suggests that it can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This provides a clear and specific reference to the part of the paper being discussed, allowing the authors to accurately identify the section being addressed. The comment is fully grounded as it explicitly mentions the equation and algorithm, and it is specific because it details the suggestion for reformulation and its implications for the motivation of Algorithm 1. Therefore, this comment is classified as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, aligning with the subproblem in Algorithm 1. This claim is 3 as it provides a specific suggestion for reformulation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to understand the implications of this reformulation to fully grasp the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the proxlinear subproblem in Eq.(1) can be reformulated using the conjugate function, making the motivation unclear. While the comment points out a specific area that needs clarification, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a belief that KD can be viewed as a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting how to incorporate this perspective into their work or discussing the implications of this view. The comment lacks concrete guidance on how the authors might address this point or integrate it into their draft. Therefore, the comment is not actionable, as it does not provide any direction for the authors to improve their work.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. The authors cannot confidently determine which section or aspect of the paper is being discussed. Additionally, the comment is not specific because it does not detail what needs to be addressed or how the authors should approach the topic of KD and LS. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a belief that KD can be viewed as a special form of LS under specific conditions. However, it lacks detailed reasoning or examples to support this claim. Without specific evidence or logical reasoning, the claim is difficult for the authors to verify or address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a belief that KD can be viewed as a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. While this observation is interesting and could provide valuable insight into the relationship between KD and LS, the comment does not offer actionable guidance or suggestions on how the authors might incorporate this perspective into their work or explore its implications. The feedback lacks depth and does not provide specific advice on how the authors could address this point or integrate it into their draft. Therefore, the comment is 2, as it offers a minor insight but lacks substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the captions should be more descriptive and that the authors should explain the \"scramble network\" better. While the comment provides explicit guidance on what needs to be improved, it lacks specific details on how to make the captions more descriptive or how to explain the \"scramble network\" better. The authors are left with a general idea of what to do but without concrete steps to follow. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment suggests making the captions more descriptive and explains the \"scramble network\" better. However, it does not specify which parts of the paper these captions or explanations are located in, making it weakly grounded. The comment is specific in its suggestions regarding the need for more descriptive captions and a clearer explanation of the \"scramble network,\" but without explicit references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the captions should be more descriptive and that the authors should explain the \"scramble network\" better. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. Without detailed reasoning or examples, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the need to make figure captions more descriptive and to explain the \"scramble network\" better. This feedback is actionable, as it directs the authors to improve the clarity and comprehensibility of their figures and the explanation of a key concept. However, the comment could be more helpful if it offered additional guidance on how to make the captions more descriptive or how to explain the \"scramble network\" effectively. Despite this, the feedback is 4 as it identifies areas for improvement and provides a clear direction for the authors to follow, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that while the choice is interesting modulo other factors, it lacks a clear justification. The comment implies that the authors should provide a rationale for why this particular dimension of difficulty is interesting. However, it does not specify how the authors should address this issue or what specific aspects of the task they should consider to make the choice more meaningful. The action is implicit and somewhat vague, as the authors need to infer that they should provide a justification for the choice of CIFAR images. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It does not specify which part of the paper this issue is related to, making it difficult for the authors to identify the exact section being addressed. However, the comment is specific in its critique of the choice of CIFAR images and its impact on the task\"s difficulty. This suggests that the authors should provide a clear rationale for why this particular dimension of difficulty is interesting. The comment is weakly grounded as it does not explicitly mention a specific part of the paper, but it is specific in its critique. Therefore, this comment aligns with a score of 3.", "verifiability_rationale": "The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that while the choice is interesting modulo other factors, it lacks a clear justification. However, the comment does not provide any specific examples, reasoning, or references to support why this particular dimension of difficulty is interesting. Without additional context or evidence, the claim remains 3, as the authors are left to infer the reasoning behind the choice. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that while the choice is interesting modulo other factors, it lacks a clear justification. This feedback is 3 as it identifies a potential area for improvement by prompting the authors to provide a rationale for their choice of CIFAR images. However, the comment could be more helpful if it offered specific guidance or suggestions on how to justify the choice or if it provided examples of why this particular dimension of difficulty is interesting. Without these details, the authors may struggle to fully address the feedback. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, is used in most experiments, except for Experiment 1b, where the relationships involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. While the comment poses a question that could lead to further exploration, it does not provide explicit guidance on how to address this question or what actions the authors should take to investigate it. The action is implicit and vague, as the authors are left to infer how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It specifically mentions that the comparison model cannot capture periodic relationships and that most experiments, except for Experiment 1b, involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the role of periodicity in the results, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations to substantiate the question, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It highlights a specific aspect of the comparison model and questions whether adding periodicity to the spectral kernel could improve its performance. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this question or explore the impact of periodicity on their results. While it identifies an area for further investigation, it does not offer actionable advice or insights that would help the authors improve their draft. Therefore, the comment is 2, as it provides a starting point for discussion but lacks the necessary depth and guidance for the authors to make meaningful improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the goal of the paper, suggesting that the authors should clarify whether the work aims to develop a foundation model or simply demonstrate a proof of concept. It also points out the absence of a comparison with existing DAS earthquake detectors, such as PhaseNetDas, and questions the justification for the method\"s benefit over these existing approaches. The comment implies that the authors should provide a clearer explanation of their goal and demonstrate the practical utility of their method through additional experiments or justifications. However, the comment does not explicitly instruct the authors to address these issues, leaving the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the goal of the paper, specifically mentioning the existence of DAS earthquake detectors and the lack of comparison or justification against them. It also suggests that if the claim is about a foundation model, the authors should clarify this and demonstrate future applications. However, the comment does not specify which part of the paper discusses the goal or the comparison with existing methods, making it weakly grounded. The comment is specific in detailing the issues with the goal and the need for comparison and justification, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas, and questions the justification for the method\"s benefit over these existing approaches. The comment suggests that if the paper\"s claim is to be a foundation model, it should be clearer and demonstrate future applications. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would need to provide more evidence or justification to address this concern effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the paper\"s goal and the lack of comparison with existing DAS earthquake detectors, such as PhaseNetDas. It highlights the absence of a clear justification for the method\"s benefit over these existing approaches, which is a critical issue for the paper\"s credibility and impact. The comment also suggests that if the paper aims to present a foundation model, it should be clearer and demonstrate future applications. This feedback is 4 as it provides a clear direction for the authors to address the lack of comparison and justification, but it could be more comprehensive with additional suggestions or examples to guide the authors in improving their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is possible. While the comment implies that the authors should consider this limitation, it does not provide explicit guidance on how to address it or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration or discussion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this restriction is discussed in, making it difficult for the authors to pinpoint the exact section or figure being addressed. The comment is specific in its inquiry about the limitation but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the assertion, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation of the approach or that an extension to longer subsequences is straightforward. This feedback is valuable as it prompts the authors to consider the scope and limitations of their method. However, the comment lacks specific guidance or suggestions on how to address this limitation or explore potential extensions. While it identifies an important area for further consideration, the feedback is 3 as it encourages the authors to think critically about their approach and its potential for broader application. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the term \"sequence of episodes\" used in the paper, specifically asking for clarification on whether \"practice\" and \"evaluation\" are the two types of this sequence. It also mentions that the paper seems related but does not negate its novelty. While the comment explicitly asks for clarification, it does not provide concrete guidance on how the authors should address this question or what specific aspects of the term need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term and its types. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the clarification of the term \"sequence of episodes\" and the types of sequences mentioned. This provides clear guidance on what part of the paper requires attention and what specific issues need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the term \"sequence of episodes\" and suggests that the paper seems related but does not negate its novelty. While the comment identifies a potential area for clarification, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the basis of the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific point of confusion regarding the term \"sequence of episodes\" in the paper, asking for clarification on whether \"practice\" and \"evaluation\" are the two types of this sequence. It also notes that the paper seems related but does not negate its novelty. While the comment highlights a potential area for clarification, it does not provide detailed guidance or suggestions on how the authors might address this issue or what specific aspects of the term need clarification. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point recommends that the authors distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This recommendation provides a clear and explicit action for the authors to take, as they need to clarify the distinction between these two concepts in their paper. The action is concrete, as it specifies exactly what needs to be done to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction is relevant to, making it difficult for the authors to identify the exact section or context where this clarification is needed. The comment is specific in its suggestion but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This feedback is specific and actionable, as it provides a clear direction for the authors to improve the clarity and context of their work. By highlighting the need to differentiate these concepts, the comment helps the authors enhance the understanding of their findings within the broader context of machine learning research. However, the comment could be more helpful if it provided additional context or examples to illustrate the distinction. Overall, the feedback is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the proof of Theorem 8 or provide a clearer explanation of how the linear convergence rates are derived. The action is implicit and somewhat vague, as it does not specify the exact steps the authors should take to improve the clarity of the proof. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" which is located at the end of the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue with the proof of Theorem 8, which is the lack of clarity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that all linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This claim is 3 as it points out a specific issue with the clarity of the proof, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the lack of clarity, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This feedback is 3 as it highlights a potential area for improvement, specifically the clarity of the proof. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue, such as suggesting alternative approaches or providing additional explanations. While it points out a problem, it lacks the depth and actionable advice needed for the authors to effectively improve their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, suggesting that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This implies that the authors should revise their statement to accurately reflect the capabilities of the Walkman algorithm. Second, the comment points out a lack of clarity in the reference \"it\" in Section 3, first paragraph, which could hinder the reader\"s understanding. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues, such as suggesting specific revisions or clarifications. Therefore, the comment is 3, as it highlights areas that need attention but lacks detailed instructions for implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, namely \"Page 2, second paragraph in Related Work\" and \"Section 3, first paragraph.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it provides detailed feedback on the accuracy of a statement regarding the Walkman algorithm and the clarity of a reference, offering concrete suggestions for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point contains two claims. The first claim critiques the accuracy of a statement regarding the related work, specifically mentioning the Walkman algorithm and its solvers. The comment provides a detailed explanation of the two versions of the algorithm, suggesting that the original statement is inaccurate. This provides a clear justification for the critique. The second claim points out a lack of clarity in the reference \"it\" in Section 3, first paragraph, which could hinder the reader\"s understanding. However, the comment does not provide specific examples or references to clarify the issue, making it 3. Overall, the comment is 4 as it provides some justification but lacks detailed evidence or references for the first claim and is vague for the second claim.", "helpfulness_rationale": "The review comment provides specific feedback on two aspects of the paper. First, it critiques the accuracy of a statement regarding the related work, pointing out that the Walkman algorithm is solved by ADMM with two versions, not just SGD. This feedback is valuable as it highlights a potential misrepresentation in the paper and encourages the authors to revise their claims for accuracy. Second, the comment identifies a lack of clarity in a reference within Section 3, which could hinder the reader\"s understanding. While the comment is 3, it could be more comprehensive by offering specific suggestions for improvement, such as providing additional context or clarifying the reference. Overall, the feedback is 4 as it provides actionable insights for the authors to enhance the accuracy and clarity of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the analysis of BRPNAS, noting that it only compares against three basic alternatives and omits consideration of other NAS approaches like supernets or oneshot methods. While the comment identifies a specific area where the analysis could be improved, it does not provide explicit guidance on how to address this issue or what specific comparisons should be included. The action is implicit, as the authors would need to infer that they should expand the analysis to include more comprehensive comparisons. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BRPNAS\" and its analysis, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis, noting that it only compares against three basic alternatives and omits consideration of other NAS approaches like supernets or oneshot methods. This provides the authors with a clear understanding of what needs to be addressed to improve the analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is \"barebones\" because it only compares against three basic alternatives and ignores other NAS approaches like supernets or oneshot methods. This claim is 3 as it provides a specific example of what is missing in the analysis. However, it lacks detailed reasoning or references to support the claim fully, making it 3. The authors would need to infer the reasoning behind the claim, which could be improved with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the analysis of BRPNAS, noting that it only compares against three basic alternatives and omits consideration of other NAS approaches like supernets or oneshot methods. This feedback is clear and actionable, as it provides the authors with a specific area to expand their analysis. However, the comment could be more helpful if it suggested specific comparisons or approaches that should be included to enhance the comprehensiveness of the analysis. Despite this, the comment offers valuable guidance for improving the draft, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not provide explicit instructions or concrete guidance on how to implement these suggestions. The authors are left to infer that they need to add more diverse attacks and analyze the impact of thresholds, but without specific steps or examples, the action remains vague. Therefore, the comment is 3, as it provides a general direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint where to address the issue. While the comment is specific about the nature of the enrichment needed, the absence of explicit references to the paper\"s sections or figures makes it weakly grounded. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting that they could be enriched with attacks of varying strengths and by exploring the influence of different thresholds on detection performance. This feedback is 3 as it points out specific aspects that could enhance the depth and comprehensiveness of the experimental analysis. However, the comment lacks detailed guidance or suggestions on how to implement these enhancements, such as specific types of attacks or methods for analyzing threshold influence. Without concrete examples or detailed instructions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. While the comment highlights a potential limitation of the method, it does not provide explicit guidance on how the authors might address this issue or what changes could be made to broaden the method\"s applicability. The action is implicit, as the authors would need to infer that they should consider testing the method on natural images and potentially modify their approach. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. However, it does not specify which part of the paper discusses the method\"s application or testing, making it weakly grounded. The comment is specific in identifying the issue of applicability to natural images, but without clear references to the sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. This is a valid concern, as the applicability of a method to a broader range of images is an important aspect of its generalizability. However, the comment does not provide specific examples or references to support the claim that the method is limited to digit and text images. While the reasoning is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. This is a pertinent point, as the applicability of a method to a broader range of images is crucial for its realworld relevance. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or expand the method\"s applicability. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences are squeezed together. While the comment identifies a specific issue with the organization of the prompts, it does not provide explicit guidance on how to improve the organization or suggest specific actions to take. The authors are left to infer that they need to reorganize the prompts and adjust the formatting of the sentences. This lack of explicit and concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6, 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the organization of the prompts and the formatting of the sentences, providing detailed feedback on what needs improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the style design is clean but criticizes the organization of the prompts in Table 6 and 7, noting that all sentences are squeezed together. While the comment identifies a specific issue with the organization and formatting of the prompts, it does not provide any supporting evidence or reasoning to substantiate the claim. The authors are left to interpret the feedback, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the prompts in Table 6 and 7, noting that the sentences are squeezed together. This feedback is clear and actionable, as it provides the authors with a specific area to improve the presentation of their work. However, the comment could be more helpful if it suggested specific ways to reorganize the prompts or adjust the formatting to enhance readability. Despite this, the feedback is 4 as it directs the authors to a clear area for improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights issues with the clarity of the figures, specifically mentioning that Figure 2 is confusing due to the relationship between its subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to clarify the relationships between the subfigures and label the missing modules. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the clarity of the figures, such as the confusion between subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning confusion in Figure 2 due to the relationship between subfigures and the lack of labels for modules like CMAF, L_BT, and VoLTA. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without specific examples or references, the authors are left to question the validity of the feedback, making it difficult to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the figures, particularly in Figure 2, where the relationship between subfigures is confusing and certain modules are not labeled. This feedback is clear and actionable, as it provides the authors with specific areas to improve the presentation of their figures. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or labeling of the figures, such as proposing specific design changes or providing examples of clearer labeling practices. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It also points out that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. The authors are directed to consider and address these concerns, making the comment 5.", "grounding_specificity_rationale": "The comment raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It highlights that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear direction for the authors to address these concerns. However, the comment does not specify which part of the paper discusses these design choices or how they are controlled, making it weakly grounded. The specificity of the comment is good as it clearly identifies the issue and asks for clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of perplexity as a measure of semantic information retention after finetuning, questioning its relevance to domain drift. It asks how such factors are controlled, which implies a need for clarification and further explanation. However, the comment lacks specific examples or references to support the claim that perplexity is insufficient for capturing domain drift. Without detailed reasoning or evidence, the claim is 3, as it provides a basis for discussion but lacks depth. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of perplexity as a measure of semantic information retention after finetuning, specifically questioning its relevance to domain drift. It asks how such factors are controlled, which provides a clear direction for the authors to address these concerns. However, the comment could be more helpful by offering specific suggestions or examples of how to control for domain drift or by suggesting alternative measures that might be more appropriate. While it prompts the authors to consider these aspects, it lacks detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific changes could be made to the dataset. While it identifies a potential problem, the lack of actionable advice makes it difficult for the authors to respond effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. While it provides some specificity by mentioning the concern about the dataset size, the lack of explicit grounding makes it challenging for the authors to understand the exact context of the comment. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment lacks specific examples or references to support the claim that 44k dialogues are insufficient. While it provides a logical argument based on common knowledge about LLM training data, the absence of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can adequately capture a wide range of user traits and personalities across different content topics. It highlights a potential issue with the dataset size, noting that LLMs are typically trained on trillions of tokens, suggesting that the current dataset may be insufficient. This feedback is 3 as it identifies a potential limitation that could impact the generalizability and effectiveness of the model. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as exploring methods for expanding the dataset or considering alternative approaches. Without specific recommendations, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not provide any explicit or implicit suggestions on how the authors might address this limitation or extend their method to handle these feature types. The comment lacks concrete guidance on how to modify the method or what specific changes might be necessary. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not specify which part of the paper this issue is discussed or addressed. The authors cannot confidently determine which section or aspect of the paper is being referred to, making the comment weakly grounded. Additionally, the comment is specific in identifying a gap in the applicability of the method, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the method to real and categorical features, given that the work uses only binary features. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the method is not applicable to real and categorical features. As a result, the claim is considered 1, as the authors are left without a clear understanding of why the method might not be applicable to these feature types.", "helpfulness_rationale": "The review comment identifies a potential limitation in the applicability of the method to real and categorical features, which are common in realworld data. It questions whether the method is applicable to these feature types, given that the work primarily uses binary features. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or extend their method to handle these feature types. While it highlights an important consideration, the lack of actionable feedback limits its helpfulness to the authors. Therefore, the comment is rated as 2, as it points out a potential issue but does not offer constructive advice for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not provide specific guidance on what aspects of the writing are unclear or how the authors should improve them. The comment lacks concrete actions or suggestions, leaving the authors without a clear path to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which parts of the paper are unclear or provide any guidance on how to address these issues. The authors cannot confidently determine which sections or points require clarification, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the writing are unclear or how the authors should improve them. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the writing should be improved and that some points in the paper are unclear. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the feedback and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the writing needs improvement and that some points in the paper are unclear. However, it lacks specific details or actionable suggestions on how the authors can address these issues. The feedback is vague and does not provide guidance on what aspects of the writing are unclear or how the authors might improve their clarity. As a result, the comment is 2, as it does not offer substantial insights or constructive advice for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use other metrics to evaluate the Results, such as BERTScore. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve their draft. The comment is specific in its recommendation, indicating which alternative metrics could be used. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not specify which part of the paper the results are presented in, making it difficult for the authors to identify the exact section that needs revision. While the suggestion is specific in terms of the metrics, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not provide any reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the evaluation process. The comment lacks specific justification or evidence, making it difficult for the authors to understand the basis of the claim and how it applies to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests using other metrics, such as BERTScore, to evaluate the results. This provides a clear and actionable suggestion for the authors to consider, as it offers a specific alternative to the current evaluation method. However, the comment lacks depth and does not elaborate on why these additional metrics would be beneficial or how they might impact the results. While it offers a starting point for improvement, the feedback could be more comprehensive and helpful if it included more detailed reasoning or examples. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper regarding the discussion of scalability bounds, specifically mentioning the absence of a thorough exploration of the upper limits of FedDES\"s scalability, as well as the lack of discussion on memory requirements or computational complexity. While the comment identifies a specific area that needs improvement, it does not provide explicit guidance on how the authors should address these issues or what specific aspects of the discussion should be expanded upon. The action is implicit, as the authors would need to infer that they need to include a more detailed discussion of these aspects. However, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, namely the limited discussion of scalability bounds, memory requirements, and computational complexity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it points out the absence of a thorough exploration of these aspects, which could be addressed by the authors. However, without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the upper limits of FedDES\"s scalability, specifically mentioning the absence of a discussion on memory requirements or computational complexity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains 3, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of a thorough discussion of scalability bounds, memory requirements, and computational complexity. This feedback is valuable as it highlights an area where the authors could enhance the depth and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues, such as suggesting additional experiments or analyses that could be included. Without such guidance, the authors may find it challenging to effectively incorporate the feedback into their draft. Therefore, the comment is 3, as it identifies an important area for improvement but lacks detailed actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks for clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment prompts the authors to clarify their understanding, it does not provide explicit instructions or suggestions on how to address this clarification. The action is implicit, as the authors need to infer that they should clarify the statement. However, the comment lacks concrete guidance on what specific aspects to focus on or how to provide the clarification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It does not explicitly mention a specific part of the paper, such as a section, table, or figure, making it weakly grounded. However, the comment is specific in its request for clarification regarding the impact of the base node on the ordering, key nodes for attention, and model performance. This specificity allows the authors to understand the exact issue being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It does not contain a subjective claim or suggestion but rather asks for clarification on the implications of this statement. The comment is factual and does not require verification, as it is a request for understanding rather than a critique or assertion. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, key nodes for attention, and model performance. This question prompts the authors to clarify their understanding of the statement, which could help them better understand the implications of the method. However, the comment does not provide any suggestions or guidance on how to address this clarification or what specific aspects to focus on. While it identifies an area for improvement, it lacks depth and actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). While it prompts the authors to consider the rationale behind the arrow\"s direction, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the purpose of the arrow and its impact on n^(i). However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space to the latent space instead of the other way around. It also questions the purpose of this arrow in influencing n^(i). However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the question is specific about the content of the figure, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the direction of an arrow in Figure 2 and its purpose in influencing n^(i). While it prompts the authors to consider the rationale behind the arrow\"s direction, it does not provide any specific evidence, reasoning, or references to support the claim that the arrow should be directed from the latent space to n^(i). The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the direction of an arrow in Figure 2 and its purpose in influencing n^(i). It challenges the authors to consider the rationale behind the arrow\"s direction, which could be crucial for understanding the model\"s behavior. However, the comment does not provide any suggestions or guidance on how to address this question or what changes might be necessary. While it identifies a potential area for clarification, it lacks actionable advice, making it 3. The authors would need to infer that they should consider the rationale behind the arrow\"s direction and its impact on n^(i), but without further guidance, the feedback is limited in its usefulness. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the use of abbreviations in Table 5, noting that they are not defined. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to define the abbreviations, but the comment lacks concrete instructions on which abbreviations need to be defined and how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the abbreviations in Table 5 are not defined, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \u201cAR\u201d in Table 5 stands for domain adaptation tasks and algorithms. While the comment identifies a potential issue with clarity and consistency in the use of abbreviations, it does not provide specific examples or references to support the claim. The authors are left to infer that the lack of definition for abbreviations could hinder understanding, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in Table 5, noting that they are not defined. This is a clear and actionable piece of feedback that could help the authors improve the clarity and readability of their paper. By defining the abbreviations, the authors can ensure that their work is easily understood by readers. However, the comment could be more helpful if it provided guidance on which abbreviations need to be defined or suggested specific definitions. Overall, the comment is 3 as it highlights a clear area for improvement, but it lacks depth and detail to fully assist the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not provide explicit guidance or suggestions on how the authors should address this question or what aspects of the analysis might need to be reconsidered. The action is implicit, as the authors are left to infer that they should explore other technical considerations related to the use of advantage instead of qvalue. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the choice of advantage over qvalue, but it does not provide detailed guidance on what other considerations might exist. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. This feedback is 3 as it prompts the authors to consider alternative approaches or additional factors that might influence their analysis. However, the comment lacks depth and specificity, as it does not provide detailed guidance or suggestions on how to address the question or what aspects of the analysis might need to be reconsidered. The authors are left to infer the implications of the comment, which limits its usefulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the setting, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the \"Unsupervised Online Adaptation\" setting, specifically questioning whether the inclusion of labels in the training set aligns with the definition of unsupervised learning. This critique is 3 as it highlights a potential inconsistency in the methodology, prompting the authors to reconsider the nature of their adaptation process. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training, unlike most compared baselines. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the fairness of their comparison. The comment implies that the authors should consider the impact of different sample weights on the performance comparison, but it lacks concrete steps or actionable advice on how to do so. Therefore, the comment is not actionable.", "grounding_specificity_rationale": "The comment addresses the fairness of the performance comparison in Table 1, specifically pointing out that VINS uses different sample weights during training, unlike most compared baselines. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the comparison, but the lack of grounding makes it difficult for the authors to pinpoint the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair because VINS uses different sample weights during training, unlike most compared baselines. This claim is 3 as it highlights a specific difference in the experimental setup that could potentially affect the fairness of the comparison. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training, unlike most compared baselines. This observation is important as it highlights a potential bias in the experimental setup that could affect the validity of the comparison. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparison. While it points out a critical aspect of the evaluation, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the results are presented in a convoluted manner and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. It also notes that the reason for this presentation is unclear. While the comment identifies a potential issue with the clarity of the results and the omission of safety violations, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the presentation and include the safety violations in their results. This lack of explicit action makes the comment 3, as it points out areas for improvement but does not provide detailed instructions on how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the presentation of results in a convoluted manner, specifically mentioning the disregard of safety violations in the first 1000 episodes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the results are presented in a convoluted way and specifically mentions that the results disregard the safety violations of the agent in the first 1000 episodes. The comment also states that the reason for this presentation is unclear. However, the comment lacks specific examples or references to support the claim about the convoluted presentation or the omission of safety violations. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results, noting that they are convoluted and that the safety violations of the agent in the first 1000 episodes are disregarded. The comment also points out that the reason for this presentation is unclear. This feedback is 3 as it highlights a potential area for improvement in the clarity and completeness of the results section. However, it lacks detailed guidance on how the authors might address these issues or what specific changes could be made to improve the presentation. The comment provides a clear direction for improvement but could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. While the comment identifies a potential issue with the figure\"s allocation, it does not explicitly instruct the authors on how to improve the space allocation or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, indicating that the authors need to consider how to improve the space allocation. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the allocation is indeed \"too naive\" or why the authors should consider editing the space more wisely. Without concrete examples or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and that the authors could have edited the space of the main paper more wisely. While the comment points out a potential issue, it lacks specific guidance or suggestions on how to address this concern. The feedback is 3 as it highlights an area for improvement, but it does not provide detailed actionable advice or examples to help the authors enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. The comment suggests that the proposed method may be difficult to generalize to a new dataset without ground truth summary. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to improve the method. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitations of the planbased method, specifically noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as suggested by Table 2. The comment further implies that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues with the planbased method, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the planbased method requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also suggests that the learned plan methods are not comparable to methods with predefined plans, as indicated by Table 2. The comment further implies that the proposed method may be difficult to generalize to a new dataset without the ground truth summary. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion. The absence of references or detailed explanations makes it challenging for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient evidence or depth to fully support it.", "helpfulness_rationale": "The review comment identifies a significant limitation of the planbased method, noting that it requires manual design based on ground truth, which is unrealistic in realworld scenarios. It also points out that the learned plan methods are not comparable to methods with predefined plans, as evidenced by Table 2. This observation raises concerns about the generalizability of the proposed method to new datasets without ground truth summaries. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the method. The feedback is 3 as it points out a potential weakness, but it lacks actionable advice, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsalfree continual learning, where featurereplay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue of conclusions not being convincing is discussed, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed by suggesting that the authors explore the impact of different combination methods, particularly in rehearsalfree continual learning, and consider more recent works like [R3]. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point critiques the paper for some conclusions that are not convincing, specifically mentioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" The authors are encouraged to explore the impact of different combination methods, particularly in rehearsalfree continual learning, where featurereplay methods have shown promise. The review suggests considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would benefit from a more detailed explanation of how the suggested methods could address the issue of noise accumulation, providing a clearer path for improvement.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s conclusions, specifically questioning the claim that \"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\" It provides examples and suggests that the results might be due to limited exploration of combination methods. The comment also recommends considering more recent works, such as [R3], which employ feature replay to continually adjust the feature space. However, the feedback lacks detailed guidance on how the authors could address these concerns or what specific actions they should take to strengthen their conclusions. While the comment offers some direction, it could be more helpful with additional suggestions or a more comprehensive critique of the methodology. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results. It does not provide explicit instructions or suggestions on how the authors should address these concerns, such as suggesting alternative methods for validation or providing more detailed analysis. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not specify which part of the paper \"Tab.\" refers to, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its questioning but weakly grounded due to the lack of explicit references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any evidence, reasoning, or references to support these claims. The authors are left to interpret the questions without any guidance on how to address them or what evidence might be relevant. This lack of support makes the comment 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any suggestions or guidance on how the authors might address these concerns. The questions are somewhat vague and leave the authors without actionable steps to improve their work. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. While the comment identifies a specific issue with the writing style, it does not provide explicit guidance on how to revise the conclusion or suggest specific changes to make the word choice less flamboyant. The action is implicit, as the authors would need to infer that they should revise the conclusion to be more concise and less exaggerated. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue of exaggerated wording and suggests that the word choice is a bit flamboyant in multiple places, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. However, the comment does not provide any specific examples or references to support this claim. Without concrete examples or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style in the conclusion, noting that the wording is overly exaggerated and that the word choice is a bit flamboyant in multiple places. This feedback is clear and actionable, as it provides the authors with a specific area to improve the tone and conciseness of their conclusion. However, the comment could be more helpful if it offered suggestions on how to revise the language or provide examples of more appropriate phrasing. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it lacks explicit guidance on how to address them. The comment suggests exploring other bit operations, provides feedback on Figure 5a, asks for clarification on handling DVS input, and suggests analyzing energy consumption as in reference [15]. However, it does not provide concrete steps or detailed explanations on how to implement these suggestions. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises several questions and suggestions for improvement, but it lacks specific references to parts of the paper or sections where these issues are discussed. The questions about \"other bit operations\" and \"Figure 5a\" are somewhat vague, as the authors cannot confidently determine which parts of the paper these issues relate to. However, the comment does specify the need for more explanations and analysis, particularly regarding energy consumption. This makes the comment partially grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises several questions and suggestions for improvement, such as exploring other bit operations, providing more explanations for Figure 5a, and analyzing energy consumption. However, it lacks specific reasoning or references to support these claims, making it difficult for the authors to understand the basis for these suggestions. The comment is 4 as it provides some direction but lacks detailed justification or examples. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises several points for improvement, including suggestions to explore other bit operations, provide more explanations for Figure 5a, and analyze energy consumption, referencing a specific paper [15]. While the comment identifies areas where the paper could be strengthened, it lacks detailed guidance on how to implement these suggestions or specific examples of what additional analysis or discussion might look like. The feedback is 3 as it points out areas for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the novelty of the approach, suggesting that the introduction of multigranularity and multiscale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. However, the comment does not provide explicit guidance on how the authors might address these issues or improve their contribution. The action is implicit and vague, as it does not specify what changes the authors should make to enhance the novelty of their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction of multigranularity and multiscale techniques in the article, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the novelty of the approach in the context of MLMs and critiques the use of algorithms from object detection. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point critiques the novelty of the approach, suggesting that the introduction of multigranularity and multiscale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues effectively. The feedback is 3 as it provides a general critique but lacks the depth needed for actionable improvement.", "helpfulness_rationale": "The review comment critiques the novelty of the approach, suggesting that the introduction of multigranularity and multiscale techniques, while common in convolutional networks, does not represent a significant innovation in the context of MLMs. It also points out that some algorithms used in the article, which enhance information on the input side, are not unique to object detection and can be applied to MLMs. This feedback provides a clear critique of the novelty of the approach and highlights areas where the authors might need to improve their contribution. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors could enhance the novelty of their work. Overall, the comment is 3 as it identifies a key issue but lacks detailed actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not provide explicit guidance on how to conduct these additional experiments or what specific aspects of the model should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer the need for more experiments and the specific areas to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the experiments conducted on the graph classification task. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the concerns and suggestions, the absence of explicit references to the paper\"s sections or figures makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing, specifically questioning whether it might lead to oversmoothing or lower generalization performance. It suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific guidance on how to conduct these additional experiments or what aspects of the model should be evaluated. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is 3, as it highlights important areas for further investigation but does not offer comprehensive guidance for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact area that needs clarification. The comment is specific in its critique but weakly grounded as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations or social norms discussed in the main paper are not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the types of situations or social norms discussed in the main paper. However, it lacks actionable guidance or suggestions on how the authors might address this lack of clarity. Without specific advice on how to improve the clarity or provide more detailed explanations, the authors may find it challenging to effectively respond to the comment. Therefore, the comment is 2, as it points out a problem but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific baselines or domains to include, or how to motivate the design choices. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not specify which baselines or domains should be included, nor does it provide guidance on how to motivate the design choices. The authors may infer that the comment pertains to the experimental section, but without explicit references to specific sections or figures, the grounding is weak. The comment is specific in terms of the suggestions for improvement, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the reasoning behind the suggestions. The absence of detailed justification or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2, as it provides some direction but lacks sufficient support for the claims.", "helpfulness_rationale": "The review comment provides feedback on the need for more baselines and domains to be tested, as well as the lack of strong motivation for certain design choices. It suggests that the authors should include baselines with other design choices and test on more domains to strengthen their empirical results. However, the comment lacks specific guidance on which baselines or domains to include, making it 3. The feedback is actionable but could be more detailed to provide a clearer path for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with Figure 2: the ambiguity of some symbols and the curiosity about information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they should clarify the symbols and explain the redundancy and interference processes. This lack of explicit guidance makes the comment 3, as the authors can deduce the necessary steps but do not have concrete instructions on how to implement them. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the issue of ambiguity in Figure 2, specifically mentioning that some symbols are not explained clearly. It also raises a question about information redundancy and interference in the multisphere icosahedral discretization process. However, the comment does not specify which part of the paper Figure 2 is located in, making it weakly grounded. The comment is specific in identifying the need for clearer explanations and questioning the redundancy and interference processes. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two issues: the ambiguity of symbols in Figure 2 and the curiosity about information redundancy and interference in the multisphere icosahedral discretization process. While the comment identifies these issues, it does not provide specific examples or references to support the claim that the symbols are unclear or that there is redundancy and interference. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that some symbols are ambiguous and raises a question about information redundancy and interference in the multisphere icosahedral discretization process. While the comment highlights areas for improvement, it lacks detailed guidance on how to address these issues or provide additional context. The authors are left to infer that they need to clarify the symbols and explain the redundancy and interference processes, which could be helpful but not fully comprehensive. Therefore, the comment is 3, as it provides some insight but could be more detailed and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the results by pointing out that the authors assume the spectrum of a kernel is subgaussian, which is valid for Gaussian kernels but not for Matern kernels. The authors are suggesting that this assumption might restrict the generality of their results. However, the comment does not provide explicit guidance on how the authors should address this limitation or what steps they should take to include Matern kernels in their analysis. The action is implicit and vague, as it does not specify how the authors can improve their results or what changes are needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitation of the results by pointing out that the authors assume the spectrum of a kernel is subgaussian, which is valid for Gaussian kernels but not for Matern kernels. This provides a specific issue that the authors need to consider. However, the comment does not explicitly mention which part of the paper discusses the results or the assumptions made, making it weakly grounded. The comment is specific in detailing the issue with the assumption regarding the spectrum of the kernel, which could be addressed by including Matern kernels in the analysis. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors assume the spectrum of a kernel is subgaussian, which is valid for Gaussian kernels but not for Matern kernels. The comment suggests that this assumption might restrict the generality of the results. However, the claim lacks specific examples or references to support the assertion that the results could be restrictive due to this assumption. Without detailed reasoning or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results by pointing out that the authors assume the spectrum of a kernel is subgaussian, which is valid for Gaussian kernels but not for Matern kernels. This observation highlights a potential restriction in the generality of the results. However, the comment does not provide actionable guidance on how the authors might address this limitation or what steps they could take to include Matern kernels in their analysis. While it identifies an important area for improvement, the lack of specific suggestions or guidance makes the comment 3, as it provides a clear direction for the authors to consider but does not fully support their potential actions. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the writing is difficult to follow in many places and suggests that it could be simplified. However, it does not provide any specific guidance or suggestions on how to simplify the writing or what aspects of the writing are particularly challenging. The comment lacks concrete actions or detailed feedback on what needs to be improved, leaving the authors with no clear direction on how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the writing is difficult to follow in many places and could be simplified. However, it does not specify which sections or parts of the paper are particularly challenging to understand. Without this information, the authors cannot accurately identify the areas that need improvement. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it lacks detailed guidance on what aspects of the writing are difficult to follow. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand the basis of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the writing, noting that it is difficult to follow in many places and suggests that it could be simplified. However, the comment lacks specific details or actionable suggestions on how to improve the writing. While it highlights a general area for improvement, it does not provide the authors with concrete guidance on what aspects of the writing need to be revised or simplified. This makes the feedback 3, as it points out a critical issue but does not offer detailed advice on how to address it. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. While the comment implies that the authors should conduct more experiments, it does not explicitly instruct them to do so or provide specific guidance on which datasets to use or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to more datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. It is specific in questioning the limited testing of the method, but without clear references to specific sections or figures, the authors may find it challenging to address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. However, the comment does not provide any specific reasoning, examples, or references to support why testing on more datasets would be beneficial or how it would impact the results. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the limited testing of the method on only two datasets, questioning whether the authors have explored more datasets to gain a better understanding of its performance. This feedback is 3 as it highlights a potential area for improvement in the experimental evaluation. However, the comment lacks specific guidance on which additional datasets to consider or how this might impact the results. While it prompts the authors to expand their testing, it does not provide detailed suggestions or examples, which could make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. While the comment highlights a point of confusion for the reviewer, it does not provide explicit guidance or suggestions on how to address this confusion or clarify the issue in the paper. The authors are left to infer that the comment is intended to prompt them to explain the difference more clearly. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the explanation of gradient bias in Batch Normalization and Online Normalization. It highlights a point of confusion for the reviewer, questioning why one is biased and the other is unbiased. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in identifying the confusion and suggesting that the authors clarify the difference between the two methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. The reviewer expresses confusion about this distinction and suggests that the paper should clarify why Online Normalization is unbiased while Batch Normalization is biased. However, the comment lacks specific examples, detailed explanations, or references to support the claim that the paper does not adequately explain this difference. Without additional context or evidence, the reviewer\"s confusion remains unaddressed, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, specifically questioning why one is biased and the other is unbiased. The reviewer expresses confusion about this distinction and suggests that the paper should clarify why Online Normalization is unbiased while Batch Normalization is biased. However, the comment lacks specific guidance or suggestions on how to address this confusion or improve the explanation in the paper. While it identifies an area for improvement, it does not provide actionable feedback or detailed advice on how to enhance the clarity of the explanation. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in addressing it."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the statement about overparametrization leading to overfitting and worse performance, suggesting that overparametrization can be beneficial in practice. It also mentions theoretical work supporting the benefits of overparametrization. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific changes to their draft or addressing the issue. The feedback lacks concrete guidance on how the authors might address this point or incorporate the theoretical work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (4748) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the critique of overparametrization and suggesting that overparametrization can be beneficial in practice, referencing theoretical work. This provides clear guidance on what needs to be addressed and why, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point critiques the statement about overparametrization leading to overfitting and worse performance, suggesting that overparametrization can be beneficial in practice. It references theoretical work supporting the benefits of overparametrization, providing a basis for the critique. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would benefit from a more detailed explanation or examples to fully understand the critique and address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques a statement about overparametrization leading to overfitting and worse performance, suggesting that overparametrization can be beneficial in practice. It references theoretical work supporting the benefits of overparametrization, providing a basis for the critique. However, the comment lacks specific suggestions or actionable feedback on how the authors might address this issue or incorporate the theoretical work into their draft. While it identifies a potential area for improvement, it does not provide detailed guidance or examples, making it 3. The authors would need to infer how to address the critique and incorporate the theoretical work, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiments are only conducted on one game environment and that more experiments are necessary. While the comment implies that additional experiments should be performed, it does not specify which additional environments or types of experiments would be beneficial. The authors are left with a general direction for improvement but lack concrete guidance on how to execute it. Therefore, the comment is 3, as it provides an implicit action but lacks detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the experiments are only conducted on one game environment and that more experiments are necessary. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors cannot confidently determine which section needs revision, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what additional experiments should be conducted or why the current single environment is insufficient. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to infer the validity of the claim, making it difficult to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the experiments are only conducted on one game environment. This feedback is clear and actionable, as it highlights the need for more comprehensive experimentation to strengthen the paper. However, the comment could be more helpful if it suggested specific additional environments or types of experiments that would be beneficial. Despite this, the feedback provides a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues. The action is implicit, as the authors would need to infer that they should consider alternative approaches or provide more detailed explanations to address the concern. The lack of concrete steps or suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment addresses a concern about the implementation and testing of recognition lists, specifically questioning how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the implementation and testing of recognition lists, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practical implementation and testing of recognition lists, specifically questioning how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. While the comment provides a logical explanation of the issue, it lacks specific examples or references to support the claim. The reasoning is clear, but the absence of detailed examples or references makes it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. This feedback highlights a potential gap in the paper\"s discussion of recognition lists and provides a clear area for improvement. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address these issues. Overall, the comment is 3 as it identifies a meaningful area for improvement but lacks depth in terms of actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the fairness of the experimental comparison, suggesting that the proposed method was pretrained before finetuning, while the compared methods might not have been initialized with the same or similar pretrained models. It also points out that the proposed method without SSL performs worse than most compared methods, as shown in Table 1. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experimental setup. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the initialization of the compared methods or provide additional details about the experimental setup. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental comparison with other methods, suggesting that the proposed method was pretrained before finetuning, which may make the comparison unfair. It also points out that the proposed method without SSL performs worse than most compared methods, as shown in Table 1. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental setup and the performance of the proposed method without SSL. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental comparison with other methods is unfair due to the proposed method being pretrained before finetuning, while the compared methods might not have been initialized with the same or similar pretrained models. The comment provides a specific example, referencing Table 1, which shows that the proposed method without SSL performs inferior to most compared methods. This provides a clear basis for the claim, making it 4. However, the comment could be strengthened by explicitly stating the implications of this unfair comparison or suggesting how the authors might address this issue in their revised draft. Overall, the claim is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the experimental comparison, noting that the proposed method was pretrained before finetuning, while the compared methods might not have been initialized with the same or similar pretrained models. This observation is supported by the reference to Table 1, which shows that the proposed method without SSL performs worse than most compared methods. The comment provides a clear and specific example of a potential flaw in the experimental setup, which could help the authors address the issue in their revised draft. However, the comment could be more helpful if it suggested specific steps or considerations for ensuring a fair comparison. Overall, the feedback is 4 as it highlights a critical aspect of the experimental design that needs attention."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should consider using better metadata embeddings for their zeroshot learning results on the CUB dataset. It provides a specific reference to a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which suggests that better metadata embeddings are available. The comment also indicates that the authors should update their paper with this suggestion. This feedback is explicit and provides a clear action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the results of zeroshot learning on CUB dataset\" and \"Table 3 page 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering better metadata embeddings and provides a reference to a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which helps the authors understand the suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the metadata used in the zeroshot learning results on the CUB dataset are \"attribute,\" which is good for fair comparison. However, it suggests that better metadata embeddings options are available and recommends exploring their performance. The comment provides a reference to a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which supports the suggestion. This provides a logical reasoning and specific reference, making the claim 4. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the results of zeroshot learning on the CUB dataset, noting that the metadata used is \"attribute,\" which is good for fair comparison. However, it suggests that better metadata embeddings options are available and recommends exploring their performance. The comment also references a related work, \"Learning Deep Representations of FineGrained Visual Descriptions, Reed et al, CVPR 2016,\" which provides context for the suggestion. This feedback is 4 as it offers actionable insights and a reference for further exploration, guiding the authors to improve their work. However, it could be more comprehensive if it included a detailed discussion of the potential impact of using better metadata embeddings or suggested specific experiments to evaluate this. Overall, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It suggests that the paper should be more explicit about the contribution, noting that the approach involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer expresses confusion about the paper\"s point until this clarification is provided. While the comment identifies a specific issue and suggests a way to address it, it does not provide explicit guidance on how to make the contribution clearer or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the contribution in the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the nature of the contribution with respect to ECE_sweep, specifically mentioning that the contribution involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. This provides a clear reference to a specific part of the paper, allowing the authors to identify the issue. The comment is specific in detailing what needs to be addressed, as it highlights a lack of clarity regarding the contribution. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not clearly describe the nature of the contribution with respect to ECE_sweep, specifically mentioning that the contribution involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that this is not fundamentally different and would prefer the paper to be upfront about the contribution. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the claim, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It highlights that the contribution involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that the paper should be more explicit about this contribution, as it is not clearly described, leading to confusion. While the comment points out a specific area for improvement, it does not provide detailed guidance or suggestions on how to clarify the contribution. The feedback is 3 as it directs the authors to a particular aspect of the paper that needs attention, but it lacks depth and specificity to fully guide the authors in improving their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The suggestion to explore the resilience of the metric to the choice of random projection is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable, as it does not provide clear instructions or specific steps for the authors to follow. The comment is also somewhat vague, as it does not specify how to analyze the variability or what kind of analysis would be helpful. As a result, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not specify which part of the paper it is referring to, making it weakly grounded. The comment is specific in its suggestion to explore the resilience of the metric to the choice of random projection, but without explicit references to the appendix or specific sections, the authors may find it challenging to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors might have missed this in the appendix. However, the comment lacks specific examples or references to support the claim that pathological projection matrices could skew the scores. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. While the comment identifies a potential issue with the robustness of the results, it does not provide specific guidance or suggestions on how to address this concern or what additional analysis might be needed. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the performance should be evaluated. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods. However, it does not specify which part of the paper this evaluation is currently missing or how it should be conducted. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide detailed guidance on how to conduct the evaluation or what aspects of performance should be considered. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the evaluation of FGT is only used to assess the method performance in the ablation study, which should be used to evaluate the performance of the proposed method and comparative methods. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation of the proposed method, noting that the current evaluation of FGT is only used to assess the method\"s performance in the ablation study. It suggests that this evaluation should be extended to include the proposed method and comparative methods. This feedback is clear and actionable, as it provides a specific direction for improvement. However, it could be more helpful if it included suggestions on how to conduct this additional evaluation or what aspects of performance should be considered. Overall, the comment is 4, as it highlights a clear area for improvement and provides a basis for further action."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the originality of the paper, specifically questioning how it contributes novelly to the understanding of the winnertakeall property given that similar findings have been reported in previous works. However, it does not provide explicit or implicit actions for the authors to take to address these concerns. The comment lacks guidance on how to demonstrate the novelty of the paper or how to expand on the findings to differentiate them from previous work. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the originality of the paper by questioning the novelty of the findings in light of previous works that have explored the winnertakeall property. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in that it highlights the concern about the novelty of the findings, but without clear guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s findings are not novel, as similar results have been reported in previous works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is not 5, as it relies on the authors\" interpretation of the existing literature. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning how it contributes novelly to the understanding of the winnertakeall property given that similar findings have been reported in previous works. While the comment identifies a potential issue with the paper\"s novelty, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. The feedback is 3 as it highlights an important aspect of the paper that needs attention, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment does not provide explicit guidance on how the authors should revise their approach to address the problem more directly. The action is implicit and vague, as it does not specify what changes need to be made to the method or how the authors should approach the problem differently. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique refers to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the approach, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. This critique suggests that the approach does not directly address the problem. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment lacks specific guidance or suggestions on how the authors might improve their approach to better address the problem. While it identifies a potential issue, it does not provide actionable steps or alternative methods for the authors to consider. As a result, the comment is 3, as it highlights a potential area for improvement but does not offer detailed guidance on how to address it. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of detail in the experimental description, which makes it difficult for readers to judge the results. It suggests that the authors should provide more clarity to allow readers to better understand the experimental setup. However, the comment does not explicitly instruct the authors on what specific aspects of the description need to be improved or how to enhance clarity. While the authors can infer that they need to add more detail, the action is not concrete and lacks specific guidance on what to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the lack of detail in the experimental description, which is crucial for readers to judge the results. The comment provides clear guidance on what needs to be improved, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the description of experimental details is lacking in clarity, making it difficult for readers to judge the results. However, the comment does not provide specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of detail in the experimental description, which hinders the reader\"s ability to judge the results. It provides a clear and actionable suggestion to improve the clarity of the experimental details, making it 3. However, the comment could be more helpful if it offered specific examples or guidance on how to enhance the clarity of the description. Overall, the feedback is valuable but could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the statement. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not specify which part of the paper this statement is located in, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the statement but lacks grounding as it does not provide clear guidance on how to address the confusion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left to interpret the statement on their own, making it difficult to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. While the comment identifies a potential issue with the statement, it lacks specific guidance or suggestions on how the authors might address this confusion or clarify the statement. The feedback is 3 as it points out a potential area of concern, but it does not provide actionable steps or detailed explanations to help the authors improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper does not provide insight into this, which is important for task domain adaptation. However, the comment does not explicitly instruct the authors to address these questions or provide guidance on how to do so. The action is implicit and vague, as it leaves the authors to infer the need for more detailed explanations and examples. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The comment is specific in its questioning of the assumptions made about morphologic segmentation, but without clear references to the paper, the authors may find it challenging to address the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper does not provide insight into this, which is important for task domain adaptation. However, the comment lacks specific examples or references to support the claim that the paper does not provide insight into this aspect. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is barely verifiable, aligning with a score of 2.", "helpfulness_rationale": "The review comment raises important questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It highlights a potential gap in the paper\"s discussion, noting that the assumption of invariance might not be accurate. This feedback is 3 as it points out a specific area that requires further clarification or discussion. However, the comment could be more helpful if it provided suggestions or guidance on how to address these questions or if it offered examples of how morphologic segmentation might vary across domains. Overall, the comment provides a starting point for improvement but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are explicit and provide clear guidance on what the authors should clarify in their draft. The feedback is concrete, as it directly instructs the authors to address these specific aspects of their method. Therefore, the comment is 5, as it provides explicit and detailed instructions for improvement.", "grounding_specificity_rationale": "The comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. While the questions are specific, the comment does not explicitly mention which part of the paper these questions relate to, such as a particular section or figure. This makes it weakly grounded, as the authors may need to infer the relevant parts. However, the questions are clear and specific, providing detailed guidance on what needs to be clarified. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are factual and do not contain subjective opinions or claims that require verification. The comment is a normal statement, as it does not provide any additional information or reasoning to support the questions. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are clear and actionable, providing the authors with specific areas to clarify in their draft. By addressing these questions, the authors can improve the clarity and completeness of their method description. The feedback is detailed and constructive, offering a clear direction for improvement. Therefore, the comment is 4, as it provides actionable guidance but could be more comprehensive if it suggested specific ways to address the questions or provide additional context."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that utilize summary tokens. While it identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they should include a discussion of these works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about Set Transformer and other related works that use summary tokens. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support this claim. Without additional context or references, the authors are left to question the validity of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that utilize summary tokens. This is a valuable piece of feedback as it highlights an area where the authors could enhance their work by providing a more comprehensive literature review. However, the comment lacks specific guidance on how the authors might address this gap, such as suggesting particular aspects of the related works to discuss or how to integrate them into the paper. While it provides a clear direction for improvement, the feedback could be more helpful if it included actionable suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not provide explicit instructions or suggestions on how the authors should address this concern, such as conducting a statistical significance test or providing justification for the closeness of the numbers. While the comment implies that the authors should consider this aspect, it lacks concrete guidance on how to implement it. Therefore, the comment is 3, as it identifies a potential issue but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. However, it does not specify which part of the paper this comparison is made, nor does it provide any guidance on how to address this issue. The authors cannot confidently determine which section or figure the comment refers to, making it weakly grounded. Additionally, the comment is specific in questioning the statistical significance of the numbers, but it lacks detailed guidance on how to conduct the test or interpret the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not provide any specific evidence, reasoning, or references to support the claim that the numbers are close and whether a statistical significance test was conducted. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the statistical significance of the numbers when comparing the proposed method with baselines. It questions whether the authors have conducted any statistical significance tests to support their claims. This feedback is helpful as it prompts the authors to consider the rigor of their comparisons and to provide evidence to substantiate their findings. However, the comment could be more helpful if it suggested specific statistical tests or provided guidance on how to conduct such tests. Overall, the comment is 3, as it identifies an important aspect of the paper that needs attention, but it lacks detailed suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signedrank test, for comparison between two samples generated from the same input. The comment provides a clear and explicit action for the authors to take, which is to reconsider their choice of statistical test and potentially use a paired test. It also specifies the reason for the recommendation, explaining why a paired test might be more appropriate in this context. This level of detail and specificity makes the comment 5, as it provides a clear direction for improvement. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signedrank test, for comparison between two samples generated from the same input. However, the comment does not specify which part of the paper discusses the significance testing or where the comparison between the two samples is made. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in suggesting a change to the statistical testing approach, the absence of explicit references to the paper\"s sections or content limits the authors\" ability to act on the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors might have incorrectly chosen a significance testing method and recommends using a paired test setting, specifically the Wilcoxon signedrank test, for comparison between two samples generated from the same input. However, the comment does not provide any specific reasoning, examples, or references to support why a paired test would be more appropriate in this context. Without detailed justification or evidence, the claim remains 3, as the authors may need to infer the reasoning behind the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the statistical testing approach used in the paper, specifically suggesting that the choice of test might be incorrect. It recommends using a paired test setting, such as the Wilcoxon signedrank test, for comparison between two samples generated from the same input. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the rigor and validity of the statistical analysis. However, the comment could be more helpful if it included additional context or explanation about why a paired test is more appropriate in this scenario, or if it suggested alternative tests that could be considered. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater depth."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment implies that the authors should consider whether the performance drop is significant enough to support the claim of \"better than random.\" However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to strengthen their argument. The action is implicit and vague, as it leaves the authors to infer the need for further clarification or evidence. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"You write: \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance\"\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the claim that \"better than random\" is a strong demonstration of capability, providing a clear direction for the authors to consider and potentially address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment is 3 as it provides a specific question about the significance of the performance drop, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide additional context or evidence to address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. This feedback is 3 as it highlights a potential area for clarification or further evidence. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or strengthen their argument. The feedback is incomplete and lacks actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. While the comment implies that these actions would enhance the paper, it does not explicitly instruct the authors to do so. The actions are somewhat vague, as the authors are not given specific guidance on how to integrate the background knowledge or where to place the related literature descriptions. Therefore, the comment is 3, as it provides a general direction but lacks concrete details on how to implement the suggested improvements.", "grounding_specificity_rationale": "The comment suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. However, it does not specify which part of the paper this organization issue pertains to, such as the introduction, methodology, or discussion sections. This lack of specificity makes it difficult for the authors to pinpoint exactly where the improvements should be made. The comment is fully grounded in terms of identifying the need for improvement but is not specific in detailing what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the organization of the paper could be improved by providing more background knowledge of the proposed method and bringing the description of related literature forward. However, the comment lacks specific details or examples to support this claim. It does not provide any references or logical reasoning to justify why these changes would be beneficial. As a result, the claim is not verifiable, as the authors are left without a clear understanding of how to address the issue or what specific changes might be necessary. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the organization of the paper, specifically suggesting that more background knowledge of the proposed method and a forward placement of related literature descriptions would enhance the paper. While the comment provides a general direction for improvement, it lacks specific details or examples of how these changes could be implemented. This makes it 3, as it gives the authors a starting point for enhancing their draft, but it could be more helpful with additional guidance or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not included in the comparison. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on whether the authors should include these models in their comparison or provide a rationale for their exclusion. As a result, the authors are left without a clear understanding of what action to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some other representative panoptic segmentation models,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies which models are missing from the comparison, namely \"PanopticFPN\" and \"Mask2Former.\" This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanations or references to justify why these models are not included or why their absence is a significant omission. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the comparison of panoptic segmentation models, noting the absence of models like PanopticFPN and Mask2Former. This feedback is valuable as it highlights an area where the authors could enhance their work by including a broader range of models in their comparison. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what additional models they should consider. While it points out a potential improvement, it does not offer actionable steps or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the paper\"s motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the model to explicitly enforce diversity. The authors are left without guidance on how to proceed, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title of the paper, which includes the word \"diversity.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the concern: the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model, leading to a disappointment. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern about the paper\"s motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the model does not enforce diversity explicitly. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment highlights a significant concern regarding the paper\"s motivation of \"diversity,\" noting that the word is present in the title but the model does not explicitly enforce it. The reviewer expresses disappointment with this discrepancy, suggesting that the authors were initially excited about incorporating diversity into their model but were disappointed to learn that it was not done so explicitly. This feedback is 3 as it identifies a specific area of concern and suggests that the authors might want to reconsider their approach to incorporating diversity into their model. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or improve their model to explicitly enforce diversity. Overall, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on what these missing experiments should include or how they should be conducted. The authors are left without a clear understanding of what additional experiments to add or how to address the issue of missing experiments. Therefore, the comment is 1 as it lacks explicit and detailed instructions for the authors to follow.", "grounding_specificity_rationale": "The comment suggests that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are intended to address or how they relate to the overall content. The authors cannot confidently determine which sections or parts of the paper need additional experiments. While the comment is specific about the type of experiments missing, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any justification or reasoning for why these experiments are missing or how their absence impacts the paper. Without additional context or explanation, the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where experiments are missing, namely contrastive learning and adversarial learning. This feedback is clear and actionable, as it provides the authors with a specific direction to improve their draft by including these additional experiments. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or why they are important. Despite this, the feedback is 4 as it directs the authors towards a clear area for improvement, allowing them to enhance the comprehensiveness of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit, as the authors can infer that they need to test inverse triples in other models, but the lack of concrete details makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in that it identifies a potential area for improvement by suggesting the inclusion of inverse triples in other models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without additional context or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the authors consider introducing inverse triples in other embedding models besides CP, as they did not test such cases in their experiments. This feedback is 3 as it points out a specific area for further exploration and testing, which could enhance the comprehensiveness of the study. However, the comment lacks depth and does not provide detailed guidance on how to implement this suggestion or what specific experiments should be conducted. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the action is implicit, as the authors need to infer that they should provide more details to address the question. The action is vague because it does not specify exactly what additional details are needed or how to provide them. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. It suggests that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment implies that more details are needed to clarify this aspect. However, the authors cannot confidently determine which part of the paper this comment refers to, as it does not explicitly mention a specific section or table. The comment is specific in detailing what needs to be addressed regarding the parameter count in the S2D structure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. This reasoning is clear and logical, making the claim 4. However, the comment could be strengthened by providing specific examples or references to support the claim, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the S2D structure, questioning why the number of parameters does not change when the kernel height and width remain the same. It provides a logical explanation, suggesting that if the kernel height and width stay the same, the depth would increase, resulting in more parameters. The comment acknowledges the potential for efficiency improvement but highlights the need for more details to clarify this aspect. This feedback is clear and actionable, as it directs the authors to provide additional information or details to address the question. However, the comment could be more helpful if it suggested specific ways to provide these details or examples of how to improve the explanation. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the analysis. The comment lacks concrete guidance on what changes could be made to the results or how the authors might enhance their interpretation. As a result, the authors are left without a clear understanding of how to proceed with the feedback, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the Atari game results are discussed in, nor does it provide any context or explanation for why the results are limited to a single game and baseline. The authors cannot confidently determine which section or part of the paper is being addressed, making it difficult to understand the issue being raised. Additionally, the comment is not specific because it does not detail what aspects of the results are difficult to interpret or what suggestions could be made to improve the analysis. Therefore, this comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. While the comment points out a potential issue with the scope of the results, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the analysis. The feedback is 3 as it highlights an area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their draft. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim, leaving the action somewhat vague. The authors are left to infer that they need to provide more evidence or explanation to support the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. However, it does not specify which part of the paper this claim is made or where the authors should provide additional evidence or clarification. The comment lacks grounding as it does not point to a specific section or part of the paper, making it difficult for the authors to identify the exact area that needs attention. Additionally, the comment is specific in its suggestion to quantify and clarify the claim, but without grounding, it remains challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3. The authors are left to infer the basis of the claim, which could be improved with more explicit justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed reasoning or examples to fully support the claim, making it somewhat incomplete. While it offers a direction for improvement, it does not provide specific guidance on how to quantify or clarify the claim, leaving the authors with limited actionable feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for finetuning the extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not provide explicit guidance on how to implement this finetuning or suggest specific methods or techniques to use. The action is implicit, as the authors need to infer that they should finetune the hyperparameters and consider the factors mentioned. While the comment is 3, it lacks concrete details on how to execute the finetuning process, making it 3.", "grounding_specificity_rationale": "The comment addresses the need for finetuning extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not specify which part of the paper this issue is related to, such as a specific section or table where these hyperparameters are introduced or discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion regarding the finetuning process, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the extra hyperparameters k and \u03b7 require finetuning, which depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of extra hyperparameters, k and \u03b7, which require finetuning. It highlights that this finetuning depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any guidance or suggestions on how to address this issue or what specific methods or techniques could be used for finetuning. While it points out a potential area for improvement, it lacks actionable advice or detailed insights that would help the authors enhance their work. Therefore, the comment is 3, as it identifies a problem but does not offer comprehensive guidance for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses confusion about Figure 5 or its labels, but it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this issue, making the comment 1. Therefore, the comment aligns with the lowest score of 1.", "grounding_specificity_rationale": "The comment expresses confusion about Figure 5 or its labels, but it does not specify which part of the paper this issue pertains to, nor does it provide any guidance on how to address it. The authors cannot confidently determine which section or element of the paper is being referred to, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what is wrong with the figure or labels. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about Figure 5 or its labels, but it does not provide any specific reasoning, examples, or references to support the claim. The authors are left to interpret the issue, making the comment 1. Therefore, the comment aligns with a score of 1.", "helpfulness_rationale": "The review comment expresses confusion about Figure 5 or its labels, but it does not provide any specific guidance or suggestions on how to address this issue. The authors are left without actionable feedback, making the comment unhelpful. Therefore, the comment aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two issues with the paper: the minimal performance differences between methods and the use of outdated and saturated benchmarks. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should consider reevaluating their results or selecting more appropriate benchmarks, but it does not offer specific guidance on how to do so. Without concrete steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the performance differences between methods and the use of outdated benchmarks, but it does not specify which part of the paper these issues are discussed in. The authors cannot confidently determine which sections or figures are being referred to, making the comment weakly grounded. However, it provides specific feedback on the minimal performance differences and the need for more appropriate benchmarks, which is clear and specific. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point, potentially due to random variation. It also suggests that the benchmarks used are outdated and likely saturated, referencing a specific paper [1] [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673). The claim is supported by the reference to the paper and the observation about the minimal performance differences, providing a basis for the authors to consider reevaluating their benchmarks. However, the comment could be more verifiable with additional examples or detailed reasoning. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point. This observation suggests that the results may be due to random variation, which is a critical point for the authors to consider. Additionally, the comment highlights that the benchmarks used are outdated and likely saturated, indicating a need for more appropriate benchmarks. The reference to a specific paper [1] [LoRA Learns Less and Forgets Less](https://arxiv.org/abs/2405.09673) provides additional context and support for the claim. While the comment identifies important areas for improvement, it could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the comment is 4, as it provides valuable insights that can guide the authors in enhancing their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the experiments section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to include more detailed interpretations of the results and expand their comparisons to include a broader range of methods. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment addresses the experiments part of the paper, specifically mentioning the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. It also highlights the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or table. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in detailing the issues with the experiments section, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments part lacks interpretive insights into why the proposed gyrostructures outperform existing methods. It also notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. It also highlights the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach is truly superior. This feedback is valuable as it directs the authors to enhance the depth and comprehensiveness of their experimental analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to include additional comparisons or interpretive insights. Overall, the comment is 3, as it directs the authors to areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the claim that improvements are due to distillation rather than regularization effects. It suggests that the finetuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. However, the comment does not explicitly instruct the authors to conduct these ablation studies or provide detailed guidance on how to address the issue. While the action is implied, it is vague and lacks concrete steps, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the claim that improvements are due to distillation rather than regularization effects, suggesting that the finetuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. However, the comment does not specify which part of the paper discusses the finetuning process or the results related to the GLUE dataset. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs revision. While the comment is specific about the issue of regularization effects and the need for ablation studies, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the improvements in the paper could be due to regularization effects rather than distillation, as the finetuning was performed for 10 epochs without early stopping. The reviewer suggests that this could lead to high variances and the need for proper ablation studies. However, the comment lacks specific examples or references to support the claim about the potential impact of regularization effects. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that improvements are due to distillation rather than regularization effects. It points out that the finetuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. This feedback is 3 as it highlights a specific area that requires further investigation and analysis. However, it could be more helpful if it provided more detailed guidance on how to conduct these ablation studies or suggested alternative approaches to address the issue. Overall, the comment offers valuable insights but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper does not provide sufficient insights into why this specific type of data is important for selfsupervised learning. The comment implies that the authors should elaborate on the significance of this data type in the context of selfsupervised learning. However, it does not explicitly instruct the authors to add more details or examples to support this claim. The action is implicit and somewhat vague, as the authors need to infer that they should provide more insights into the importance of the data type. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results and suggests that while the results indicate the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper lacks insights into why this specific type of data is important for selfsupervised learning. However, the comment does not specify which part of the paper discusses the experimental results or the specific section where the authors should provide more insights. This makes it difficult for the authors to identify the exact area that needs improvement. The comment is specific in its critique but weakly grounded as it does not provide explicit references or sections for the authors to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks insights into why selfsupervised learning is necessary for 360 video data with spatial audio. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper lacks insights into why this specific type of data is important for selfsupervised learning. This feedback highlights a need for the authors to elaborate on the significance and importance of this data type in the context of selfsupervised learning. However, the comment does not provide specific suggestions or guidance on how the authors might address this gap, such as suggesting additional experiments or analyses that could provide more insights. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the analysis of the SimCLR approach, specifically mentioning the absence of analysis on the projection head, which is considered important based on recent studies like SimCLRv2. However, the comment does not provide explicit guidance on how the authors should address this gap or what specific aspects of the projection head analysis should be included. While the authors can infer that they need to expand their analysis to include the projection head, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SimCLR case,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of analysis on a seemingly important aspect of the SimCLR approach, namely the projection head, which is a critical component. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that only the SimCLR case is covered and that there is no analysis on a seemingly important part of that approach, specifically the projection head. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the analysis of the SimCLR approach, noting that only the SimCLR case is covered and that there is no analysis on a seemingly important aspect, such as the projection head. This feedback is 3 as it highlights a potential area for improvement in the paper. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this gap, such as suggesting additional experiments or analyses that could be included. Without specific recommendations, the authors may find it challenging to fully understand how to improve their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. While it suggests that these experiments are needed, it does not provide explicit guidance on how to conduct them or what specific aspects of the paper should be compared or analyzed. The action is implicit and somewhat vague, as the authors need to infer that they should perform these experiments to address the lack of additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments are missing from or where they should be conducted. This makes it difficult for the authors to identify the exact areas that need improvement. The comment is 1 as it does not provide specific references or sections of the paper that are missing these experiments. It is also not specific because it does not detail what kind of experiments are needed or how they should be conducted. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why these experiments are necessary or how they could be implemented. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is valuable as it highlights specific areas where the paper could be strengthened to provide a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it provided some guidance on how these experiments could be conducted or what specific aspects of the method should be compared or analyzed. Despite this, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It points out that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results and highlights a concern regarding the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It points out that without prior information, the proposed method does not show an advantage compared to the SOTA, similar to the benchmarks. However, the advantage is only evident when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. While the comment is specific about the issue of fairness and the additional complexity of the proposed method, it does not explicitly mention which part of the paper this issue is discussed in. This makes it weakly grounded, as the authors may need to infer the section being addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it is based on logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It highlights that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer points out that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. This feedback is valuable as it challenges the authors to consider the fairness of their comparisons and the practical implications of their method. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these concerns, such as by including prior information or simplifying the model. Overall, the comment is 3, as it raises important questions about the evaluation process and the practicality of the proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the regularization term appears to be adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific changes should be made to the regularization term. While the authors understand the need for theoretical support and alternative statistics, they are left without clear instructions on how to address these issues. The comment is 3 as it identifies a potential improvement but lacks concrete details on how to achieve it. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, which is a specific part of the paper. It provides feedback on the adhoc nature of the term and suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not specify which part of the paper discusses the regularization term or provide detailed guidance on how to incorporate these alternative statistics. The authors can infer that the comment pertains to the regularization section, but the lack of explicit mention or detailed guidance makes it weakly grounded. The comment is specific in its critique of the adhoc nature and the need for theoretical support, but the lack of grounding makes it 3. Therefore, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, suggesting that other statistics could be used instead of the mean and standard deviation. While the comment provides a rationale for the suggestion, it lacks specific examples or references to support the claim that the current regularization term is adhoc or lacks theoretical backing. The authors would need to infer the basis for this claim, which makes it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, noting that it appears to be adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide specific guidance on how to implement these suggestions or what changes should be made to the regularization term. While it highlights an area for improvement, the lack of detailed feedback limits its helpfulness. The authors would need to infer the need for theoretical support and alternative statistics, making the comment 3 but not fully comprehensive. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. While the comment provides a clear direction for the authors to improve their draft by addressing the computational budget and iteration cost, it does not specify how to discuss this aspect or what specific details to include. The action is explicit but lacks concrete guidance on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to discuss iteration cost and compare it with related methods, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand how to address the issue. Without additional context or examples, the claim is 1, as it does not provide a clear path for the authors to improve their draft. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost of their proposed method and compare it with related methods, including baseline methods. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. However, the comment could be more helpful if it offered additional guidance on how to discuss the iteration cost or what specific aspects of the comparison should be included. Despite this, the comment is 4 as it directs the authors to an important aspect of their work that needs attention. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point questions the authors\" VAD (Visual Attention Descriptor) description, suggesting that it discards TF (TimeFrequency) bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it discards TF bins with zero magnitude, which could lead to division by zero. They also critique the VAD\"s definition, noting that it should look for the presence of speech (not just energy) and is typically defined over time, not frequency. While the comment identifies a potential issue with the VAD description, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification or revision. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the VAD description, explaining that it discards TF bins with a magnitude less than epsilon, which could lead to division by zero. The reviewer critiques the approach, suggesting that it does not align with the typical definition of VADs, which are usually defined over time and look for the presence of speech, not just energy. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the VAD description is puzzling and suggests that the approach of discarding TF bins with a magnitude less than epsilon is problematic. It argues that this method is essentially discarding TF bins with zero magnitude, which could lead to division by zero. The reviewer also critiques the VAD\"s definition, noting that it should look for the presence of speech (not just energy) and is typically defined over time, not frequency. However, the comment lacks specific examples or references to support these claims, making it 3. The reasoning is logical, but the lack of detailed evidence or examples weakens the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the VAD (Visual Attention Descriptor) description in the paper. It points out that the current approach of discarding TF (TimeFrequency) bins with a magnitude less than epsilon is problematic, as it essentially discards TF bins with zero magnitude, which could lead to division by zero. The reviewer also critiques the VAD\"s definition, noting that it should look for the presence of speech (not just energy) and is typically defined over time, not frequency. This feedback is clear and actionable, as it highlights specific issues with the VAD description and suggests areas for improvement. By identifying these weaknesses, the comment provides the authors with a clear understanding of what needs to be addressed to enhance the accuracy and clarity of their work. Therefore, the comment is 5, as it offers detailed and constructive feedback that can significantly improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific guidance or action for the authors to take to achieve this. The comment lacks explicit instructions on how to improve the results or what steps should be taken to make them more convincing. As a result, the authors are left without a clear understanding of how to address this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing of the proposed method. However, it does not specify which part of the paper discusses the results on ImageNet or provide any details on how to make them more convincing. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide guidance on how to improve the results or what aspects need to be considered. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results on ImageNet could be more convincing of the proposed method. While this feedback provides a direction for improvement, it lacks specific guidance or suggestions on how to enhance the results or what aspects of the method could be strengthened to make the results more convincing. The comment is 3 as it identifies a potential area for improvement, but it does not offer detailed or actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the paper\"s contribution, suggesting that it primarily focuses on studying the connection between complementary and model robustness without providing further insights or solutions on how to leverage this connection to improve model robustness. The comment implies that the conclusion could be easily obtained and suggests that the paper lacks insightful findings or possible solutions. However, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the analysis and provide more insightful findings or solutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the paper\"s contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or analysis. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the contribution, the absence of grounding limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the paper\"s contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The comment suggests that the conclusion could be easily and intuitively obtained, implying that the paper lacks insightful findings or possible solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains 3, as the authors are left to infer the basis of the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a significant concern about the sufficiency of the paper\"s contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The comment suggests that the conclusion could be easily and intuitively obtained, implying that the paper lacks insightful findings or possible solutions. This feedback is 3 as it identifies a key area for improvement, prompting the authors to expand on their analysis and provide more substantial insights or solutions. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these concerns. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the method appears to simply adopt the selfattention mechanism from transformers without explaining how it enhances generalization for distant nodes. While the comment identifies a potential issue with the clarity of the connection, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. However, it does not specify which part of the paper this connection is being questioned, making it weakly grounded. The comment is specific in identifying the issue with the proposed method, but the lack of grounding makes it difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method seems to simply adopt the selfattention mechanism from transformers without explaining how it enhances generalization for distant nodes. While the comment raises a valid concern about the lack of clarity in the connection, it does not provide specific examples or references to support the claim. The reasoning is somewhat vague, as it lacks detailed explanations or evidence to substantiate the critique. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by questioning the connection between the theoretical analysis and the proposed method. It highlights that the proposed method appears to simply adopt the selfattention mechanism from transformers without explaining how it enhances generalization for distant nodes. This feedback is 3 as it points out a gap in the paper\"s explanation and suggests that the authors need to clarify the relationship between their theoretical analysis and the proposed method. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors could address this issue. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the authors\" claim about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. It provides a specific correction, indicating that these heads are active at the S2 token but do not primarily attend to it. This feedback is clear and actionable, as it directs the authors to correct their statement and align it with the findings of the cited work. The comment is fully actionable because it provides a direct and concrete instruction for the authors to revise their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the base IOI circuit\" and \"Section 3 of Wang et al., 2023,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is incorrect in the authors\" claim regarding the primary attention of certain heads to the S2 token. The comment provides a detailed explanation of the error, making it highly specific and grounded. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors\" statement about the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token is incorrect, referencing Section 3 of Wang et al., 2023. This claim is 5 as it provides a specific reference to external work that supports the correction. The reasoning is clear and logical, making the comment 5.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific error in the authors\" claim regarding the primary attention of certain heads in the base IOI circuit. It provides a clear correction, referencing Section 3 of Wang et al., 2023, which indicates that these heads are active at the S2 token but do not primarily attend to it. This feedback is actionable and constructive, guiding the authors to revise their draft and align it with the findings of the cited work. The comment is detailed and provides a clear direction for improvement, making it highly beneficial for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the reason for the eta_ri term being a noncentral chisquared distribution. While it identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment lacks concrete suggestions or actionable steps for the authors to clarify or improve their explanation. As a result, the authors are left without a clear direction on how to respond to this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment questions the reason for the eta_ri term being a noncentral chisquared distribution, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, tables, or figures, the authors cannot confidently determine where the issue lies. Additionally, the comment lacks specificity, as it does not provide details on why this clarification is needed or how it would benefit the paper. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the reason for the eta_ri term being a noncentral chisquared distribution. However, it does not provide any supporting evidence, reasoning, or references to justify why this claim is made. Without additional context or explanation, the authors are left without a basis to understand or address the comment. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion regarding the eta_ri term being a noncentral chisquared distribution. While it highlights a potential area of ambiguity, it does not provide any suggestions or guidance on how the authors might address this issue or clarify their explanation. The comment lacks depth and actionable advice, leaving the authors without a clear path to improve their understanding or presentation of this concept. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting the absence of speed analysis and suggesting that comparing inference speed with prior work would be more interesting than reducing FLOPs. However, it does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of inference speed need to be considered. While the comment identifies a gap in the analysis, it lacks concrete instructions on how to address it, making it 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, noting the lack of speed analysis and suggesting that comparing inference speed with prior work would be more interesting than reducing FLOPs. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in its suggestion to include speed analysis, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks speed analysis, specifically noting the absence of comparisons of inference speed between the proposed network and prior work. It suggests that such comparisons would be more interesting than reducing FLOPs. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of where such comparisons could be made or references to similar analyses in other works. Without specific examples or references, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of speed analysis, specifically mentioning the absence of comparisons of inference speed between the proposed network and prior work. It suggests that such comparisons would be more interesting than reducing FLOPs, which implies that the authors should consider including a more comprehensive analysis of inference speed. However, the comment does not provide specific guidance on how to conduct this analysis or what aspects of inference speed should be considered. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it identifies a crucial issue but lacks actionable guidance for the authors."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method is not wellpositioned in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and scoreinterpolation [2]. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the positioning of their method in the literature. The action is implicit and vague, as it does not specify how the authors should conduct a thorough literature review or what specific aspects of their method need to be highlighted. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and suggests a thorough literature review, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and scoreinterpolation [2]. This provides clear guidance on what the authors should consider in their literature review. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not wellpositioned in the literature and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and scoreinterpolation [2]. The comment provides specific examples of related work, which supports the claim and offers a clear rationale for why the method might not be as novel as initially presented. However, it could be more robust if it included a broader range of references or a more detailed explanation of how the proposed method differs from or builds upon these existing works. Overall, the claim is 4, as it is supported by logical reasoning and specific examples, but it could be strengthened with additional evidence.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed method, noting that it is not wellpositioned in the literature. It points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and scoreinterpolation [2]. This feedback is valuable as it highlights a potential gap in the authors\" understanding of the existing literature and suggests that the method might not be as novel as claimed. However, the comment could be more helpful if it provided specific guidance on how the authors could address this issue, such as suggesting a more comprehensive literature review or highlighting the unique aspects of their method that differentiate it from existing approaches. Overall, the comment is 3, as it identifies a critical area for improvement but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it suggests an area for further exploration, it does not provide explicit guidance on how the authors should address this question or incorporate it into their work. The comment lacks concrete actions or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its inquiry about the performance of a particular method, but it lacks detail on how this information could be integrated or utilized. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not provide any specific reasoning, examples, or references to support the claim. The comment lacks detailed justification or evidence to substantiate the inquiry, making it difficult for the authors to understand the basis of the question or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, which could be a valuable area for further exploration. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this question or incorporate it into their work. Without actionable feedback or detailed insights, the authors may find it challenging to understand the implications of the question or how to proceed with it. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance or direction."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. This comment provides an explicit action for the authors to take, which is to expand the related work section. However, it lacks specific guidance on how to achieve this, such as suggesting particular aspects to compare or discuss. The action is clear and direct, but it is somewhat vague in terms of implementation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. However, it does not specify which part of the paper this suggestion is intended for, making it weakly grounded. The comment is specific in its suggestion to enhance the related work section, but without clear guidance on which part of the paper it should be applied to, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed discussion of related work, specifically by not only describing the related works but also discussing the differences to the presented work. This feedback is 3 as it identifies an area for improvement, but it lacks specific guidance on how to achieve this. The authors are left with a general idea of what to do but without detailed suggestions or examples, which limits the actionable value of the comment. Therefore, it aligns with a score of 3, as it provides some insight but could be more comprehensive and detailed."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. While the comment implies that the authors should consider expanding their experiments, it does not provide explicit guidance on which specific architectures or tasks to include. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, it does not specify which other architectures or tasks should be considered, nor does it provide any guidance on how to approach this expansion. The comment lacks grounding as it does not clearly identify the specific part of the paper being addressed, and it is also not specific in its suggestions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments conducted in the paper, noting that they are limited to neural networks and image classification tasks. It suggests that exploring the performance of attacks on other architectures and classification tasks would be interesting. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on which tasks or architectures to consider, nor does it offer any insights into how this could be achieved. The feedback is 3 as it points out a potential avenue for future research but lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the output of the algorithm depends on the order of data processing and suggests that this dependency should be clarified. While the comment explicitly states the issue, it does not provide specific guidance on how to clarify this dependency or what aspects of the algorithm or data processing need to be addressed. The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the output of the algorithm depends on the order of data processing and recommends clarifying this dependency. However, it does not specify which part of the paper discusses the algorithm or the data processing order, making it weakly grounded. The comment is specific in identifying the issue that needs clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the output of the algorithm depends on the order in which the data are processed and suggests that this dependency should be clarified. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this dependency is important or how it should be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the algorithm\"s output, specifically that it depends on the order of data processing. This observation is clear and highlights a potential area for clarification. However, the comment lacks specific guidance on how to address this issue or what aspects of the algorithm or data processing need to be clarified. While it points out a potential problem, it does not provide actionable steps or suggestions for improvement, making it 3. The authors would need to infer how to address the issue, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the impact of mitigation strategies on the model\"s overall performance, suggesting a potential tradeoff between reducing memorization and maintaining utility. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to mitigate the potential impairment. The comment implies that the authors should consider the tradeoff and its implications, but it lacks concrete steps or suggestions on how to implement this consideration. Therefore, the comment is not actionable, as it does not provide clear guidance on how the authors can improve their draft.", "grounding_specificity_rationale": "The comment addresses the mitigation strategies aimed at reducing memorization and their potential impact on the model\"s overall performance. However, it does not specify which part of the paper discusses these mitigation strategies or how they are implemented. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in that it highlights a potential tradeoff between reducing memorization and maintaining performance, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the model\"s overall performance, suggesting a potential tradeoff between reducing memorization and maintaining utility. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 2, as it hints at a concern but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the impact of mitigation strategies on the model\"s overall performance, specifically questioning whether these strategies might significantly impair the model\"s utility. This feedback is valuable as it highlights a potential tradeoff between reducing memorization and maintaining performance, which is a critical consideration for the effectiveness of the mitigation strategies. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to assess the impact of the mitigation strategies. While it identifies a significant area for improvement, the lack of detailed guidance limits its overall helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of using 6fold crossvalidation, noting that other comparable papers did not employ it. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or clarify the reasoning behind their choice. The action is implicit, as the authors would need to infer that they should explain the rationale for using 6fold crossvalidation. The comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment questions the necessity of using 6fold crossvalidation, noting that other comparable papers did not employ it. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it highlights a lack of clarity regarding the use of crossvalidation, but without explicit references to the paper or section, the authors may struggle to pinpoint the exact issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of using 6fold crossvalidation, suggesting that other comparable papers did not employ it. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the reviewer\"s assertion. Without detailed justification or evidence, the claim remains 3, as it lacks the necessary depth and context to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the use of 6fold crossvalidation, questioning its necessity given that other comparable papers did not employ it. This feedback highlights a potential gap in the justification for the chosen methodology, which could impact the clarity and robustness of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or clarify the rationale behind their choice of crossvalidation. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, it does not provide explicit instructions or detailed guidance on how to achieve this clarification. The action is implicit, as the authors need to infer that they should elaborate on the improvements of their method over ODA. While the comment is 3, it lacks concrete details on how to implement the suggested improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" which is a specific method used in the context of solving the MOIP problem. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity on how the presented method improves performance and computation speed compared to using ODA. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs further explanation. However, the comment could be more helpful if it provided additional guidance on how to improve the clarity of this explanation or suggested specific areas where the authors could elaborate. Overall, the comment is 4, as it provides a clear direction for improvement but lacks some depth in terms of actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of the sampling method for convergence to the optimum but notes that this aspect is not experimentally evaluated beyond a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to conduct a more thorough experimental evaluation or what specific aspects of the sampling method should be explored. The action is implicit and somewhat vague, as the authors are left to infer how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the importance of the sampling method for convergence to the optimum, noting that it is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. However, the comment does not specify which part of the paper discusses the sampling method or the benchmarks used, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of experimental evaluation, it lacks grounding as it does not provide clear references or guidance on which sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the sampling performed to obtain different initializations x_0 is important for convergence to the optimum but notes that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. The comment provides some evidence by mentioning the comparison to uniform sampling, but it lacks detailed reasoning or references to support the claim that this aspect is not adequately evaluated. The authors are left to infer the need for a more thorough evaluation, which could be helpful but lacks full verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by highlighting the importance of the sampling method for convergence to the optimum. It points out that while the sampling method is mentioned, it is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison to sampling from a uniform distribution in Table 1 of the supplementary material. This feedback is 3 as it directs the authors to consider a more thorough experimental evaluation of the sampling method. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct this additional evaluation. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should explore how their model works with tabular data, noting that it is another form of multimodal data. However, it does not provide explicit instructions or concrete guidance on how to implement this suggestion. The action is implicit, as the authors would need to infer that they should conduct experiments or analyses to understand the model\"s performance on tabular data. The lack of detailed guidance or specific steps makes the action somewhat vague and challenging to execute. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests exploring the use of tabular data as another form of multimodal data, which is an interesting idea. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide clear guidance on how to implement or address the idea. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that tabular data is another form of multimodal data and proposes exploring how the model works with it. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should explore how their model works with tabular data, noting that it is another form of multimodal data. While the comment identifies an interesting avenue for further investigation, it lacks specific guidance or suggestions on how to approach this exploration. The authors would need to infer that they should conduct additional experiments or analyses to understand the model\"s performance on tabular data, which limits the comment\"s helpfulness. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While it provides a direction for improvement, it does not explicitly instruct the authors to include specific details or examples. The action is implicit, as the authors need to infer that they should expand on the use of attention. However, the comment lacks concrete guidance on what aspects of attention should be detailed or how to present them in the appendix. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not specify which part of the paper discusses attention or where the additional details should be included. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of more details, but it lacks concrete examples or guidance on what those details should include. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on what aspects of attention should be detailed or how to present them. The comment is 3 as it points out a potential enhancement, but it does not offer detailed suggestions or actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of the pseudocode for the proposed method. While it prompts the authors to explain the performance difference, it does not provide explicit guidance on how to address the missing pseudocode or what steps should be taken to include it. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide the pseudocode. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, referencing specific papers. However, it does not specify which part of the paper this comparison is intended for, making it weakly grounded. The comment is specific in its request for clarification and the inclusion of a missing pseudocode, but without clear grounding, the authors may struggle to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of the pseudocode for the proposed method. It references two external papers, [1] and [2], which are relevant to the discussion. However, the comment lacks a detailed explanation or reasoning as to why the explicit methods are superior or how the absence of the pseudocode impacts the paper. While the references provide some context, the claim is 3 as it relies on logical reasoning and references to external work, but it could be strengthened with more detailed explanations or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, referencing specific papers. It also points out the absence of the pseudocode for the proposed method, which is a critical detail for understanding and replicating the work. However, the comment lacks depth and does not provide specific guidance on how the authors might address the performance difference or the missing pseudocode. While it identifies an important area for clarification, it does not offer actionable steps or suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3, as it provides some insight but requires further elaboration to be fully beneficial."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and suggesting that the authors check for differences in figures. However, the comment does not provide explicit guidance on how to simplify the descriptions or what specific changes should be made. The suggestions are somewhat vague and lack concrete details, making it challenging for the authors to implement them effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and suggesting that the authors check for differences in figures. However, the comment does not specify which part of the paper contains these convoluted descriptions or the figures being referenced, making it weakly grounded. The suggestions are specific, as they provide concrete examples of what the authors could do to improve the clarity of their results. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and suggesting that the authors check for differences in figures. However, the comment lacks detailed reasoning or examples to fully support the claim that the descriptions are convoluted or that the suggested references are relevant. The feedback is 3, as it provides some justification but could be more robust with additional details or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions, which is a valuable piece of feedback for improving the clarity and readability of the paper. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication from a teachability perspective and suggesting that the authors check for differences in figures. These suggestions are actionable and provide the authors with concrete directions for improvement. However, the comment could be more helpful if it included more detailed guidance on how to simplify the descriptions or what specific changes should be made. Overall, the feedback is 4 as it offers clear and actionable suggestions for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the experimental validation, including the limited depth of the networks considered (only 2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their experimental validation or positioning, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the experimental validation of the paper, specifically mentioning the limitations of considering only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, and it is specific because it details the issues with the experimental validation and positioning. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, citing the limited depth of the networks considered (2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also mentions a minor issue regarding the positioning of the work with respect to related works, specifically highlighting the consideration of layer redundancy in the context of network pruning. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of specific examples or detailed explanations weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies several weaknesses in the experimental validation of the paper, specifically noting the limited depth of the networks considered (only 2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. However, the comment lacks actionable suggestions or detailed guidance on how the authors might address these issues to improve their experimental validation. While it highlights areas for improvement, it does not provide concrete steps or recommendations for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the testing of the model on other tasks within the bAbI dataset. It does not provide explicit instructions or suggestions on how to address this concern, such as testing on additional tasks or providing a rationale for the choice of Task 1. While the comment implies that the authors should consider expanding their testing, it lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in its request for additional testing but lacks grounding as it does not provide clear guidance on where to find the relevant information or how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not provide any evidence, reasoning, or references to support why testing on other tasks would be beneficial or necessary. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the claim or how it relates to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically noting that it was only tested on Task 1. This feedback highlights a potential area for improvement by suggesting that the authors consider expanding their testing to include other tasks. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this issue or what additional tasks might be relevant. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, as it provides a clear direction but lacks detailed guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that it is difficult for the authors to follow Section 3.2 and suggests that they may improve it by providing more illustrations and examples. While the comment explicitly suggests an action\u2014improving the section and providing additional illustrations and examples\u2014it does not specify how the authors should go about improving the section or what kind of illustrations and examples would be beneficial. The action is clear and direct, but it lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it is difficult for the authors to follow Section 3.2 and recommends providing more illustrations and examples. However, it does not specify which part of Section 3.2 is particularly challenging to follow, nor does it provide any guidance on what kind of illustrations or examples would be helpful. The comment lacks grounding as it does not pinpoint the specific section or part of the paper that needs improvement. It is also not specific because it does not offer detailed suggestions on how to improve the section. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is difficult to follow Section 3.2 and suggests that the authors may improve it by providing more illustrations and examples. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the difficulty or how to address it. Without additional context or evidence, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Section 3.2 is difficult to follow. It suggests that the authors may improve the section by providing more illustrations and examples. While the comment highlights a potential area for improvement, it lacks depth and specificity. It does not offer detailed guidance on what kind of illustrations or examples would be most beneficial, nor does it suggest alternative approaches to improve the clarity of the section. As a result, the feedback is 3, as it provides a general direction for improvement but does not fully address the authors\" needs for enhancing the clarity and accessibility of their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning that GCG could craft adversarial prompts and transfer them to other LLMs. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison into their work. Additionally, the comment highlights a minor point about the low jailbreaking percentage for certain LLMs, which could be addressed by the authors. The feedback is concrete and actionable, giving the authors specific guidance on what to include and what to consider. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including a comparison of the authors\" approach with other LLMs, specifically mentioning that GCG could craft adversarial prompts and transfer them to other LLMs. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison into their work. However, the comment does not specify which part of the paper this comparison should be included in, leaving the authors to infer the section where such a comparison would be most appropriate. While the action is explicit, the lack of specific guidance on where to include the comparison makes it somewhat grounded. Therefore, the comment is categorized as \"Somewhat Grounded and Specific\" because it provides a clear action but lacks detailed guidance on implementation, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors should include a comparison of their approach with other LLMs, specifically mentioning that GCG could craft adversarial prompts and transfer them to other LLMs. This claim is 3 as it suggests a logical extension of the work, but it lacks specific examples or references to support the claim fully. The authors could benefit from additional details or references to substantiate the suggestion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning that GCG could craft adversarial prompts and transfer them to other LLMs. This provides a clear and actionable suggestion for the authors to enhance their work by expanding the scope of their analysis. Additionally, the comment points out a minor observation about the low jailbreaking percentage for certain LLMs, which could be addressed by the authors. While the suggestion is somewhat general, it offers valuable guidance for improving the draft. Therefore, the comment is 4, as it provides actionable feedback and insights that can guide the authors in enhancing their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the parameter S, suggesting that it remains a problem. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps should be taken to resolve it. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the parameter S, suggesting that it remains a problem. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the problem with parameter S. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the parameter S, suggesting that it remains a problem. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the parameter S, suggesting that it remains a problem. However, it does not provide any specific guidance or suggestions on how to address this issue or what steps the authors should take to resolve it. The comment lacks depth and actionable advice, leaving the authors without a clear path forward to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback provides a clear and explicit action for the authors to consider, as it highlights a potential oversight in the introduction. The comment is specific in identifying the issue with the claim and suggests a more nuanced perspective on the constraints. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, the introduction. It is also specific because it clearly specifies what needs to be addressed, namely the potential oversight in the introduction regarding the choice of constraints as a hyperparameter. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is 4 as it provides a logical reasoning for the critique, explaining why the initial claim might be an oversimplification. However, it could be strengthened by providing specific examples or references to support the claim about the nature of these constraints. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment critiques the claim in the introduction that \"these shape constraints do not require tuning a free parameter.\" It argues that while technically true, the choice of employing a convex or concave constraint, or an increasing/decreasing constraint, can be seen as a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it identifies a potential oversight in the introduction and suggests a more nuanced perspective on the constraints. By highlighting this point, the comment provides the authors with a specific area to consider and improve their understanding of the constraints. Therefore, the comment is 5, as it offers valuable insights and guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several limitations in the paper, specifically regarding the limited scope of bias benchmarks and the absence of assessments on stateoftheart generative models. It points out that the current benchmarks only assess gender, race, and religion, and suggests that other important biases and datasets should be included. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific steps they should take to expand their analysis. While the authors can infer that they need to include more diverse biases and datasets, and consider evaluating stateoftheart generative models, the lack of concrete suggestions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the bias benchmarks used in the paper, specifically noting that they only assess gender, race, and religion. It also points out the absence of assessments on other important biases and datasets, as well as the lack of evaluation on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses the bias benchmarks or datasets, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as expanding the scope of bias benchmarks and including evaluations on stateoftheart models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are missing. It also notes the absence of assessments on stateoftheart generative models like GPT. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. Without detailed evidence or examples, the claim remains 3, as the authors may need to conduct further research to confirm the extent of the limitations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the limited scope of bias benchmarks. It points out that the current benchmarks only assess gender, race, and religion, and notes the absence of assessments on other important biases and datasets, as well as the lack of evaluation on stateoftheart generative models like GPT. This feedback is valuable as it highlights areas where the authors could enhance the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these limitations, such as proposing additional datasets or models to include. Without concrete recommendations, the comment is 4, as it provides a clear direction for improvement but lacks detailed actionable advice. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies specific issues with Figure 3, such as the difficulty in understanding the workflow and captions, and the confusion in representing communication modes on the left side. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve the figure, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the difficulty in understanding the workflow and captions, and the confusion in representing communication modes on the left side. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is challenging to understand due to unclear workflow and captions, as well as confusing representation of communication modes on the left side. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues with Figure 3, such as the difficulty in understanding the workflow and captions, as well as the confusion in representing communication modes on the left side. While the comment highlights these areas for improvement, it does not provide detailed suggestions or guidance on how to address these issues. The feedback is 3 as it points out areas that need clarification, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. While it identifies a lack of clarity, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the method need clarification. The action is implicit, as the authors would need to infer that they should provide more details or examples to explain the concept. However, the comment lacks concrete instructions on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SSL pretraining stage of the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the meaning of \"learned [MASK] embedding.\" This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pretraining stage of the proposed method. However, it does not provide any claim, reasoning, or evidence to support the concern. The comment lacks context or justification, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the context of the proposed method\"s SSL pretraining stage. This feedback highlights a lack of clarity in the paper, which could hinder understanding and reproducibility. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the concept. Without actionable advice or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 3, as it points out a critical area for clarification but lacks depth and guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. The comment also suggests that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, it does not explicitly instruct the authors on how to conduct the error analysis or what specific aspects of the model\"s performance should be analyzed. While the action is somewhat inferred, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues, and it encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. However, the comment does not specify which part of the paper should be addressed or how the error analysis should be conducted. This lack of grounding makes it difficult for the authors to understand which sections or aspects of the paper need improvement. Additionally, while the comment is specific about the importance of error analysis, it does not provide detailed guidance on how to conduct it. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that error analysis plays a crucial role in evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment highlights the importance of error analysis in evaluating model performance and suggests that the authors should conduct it to identify potential issues. It encourages the authors to provide detailed explanations of the model\"s performance under different scenarios, which could guide subsequent improvements and expansions of the ERC research. While the comment identifies a key area for improvement, it lacks specific guidance on how to conduct the error analysis or what aspects of the model\"s performance should be analyzed. This makes the feedback 3, as it provides a direction for improvement but could be more comprehensive with detailed suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or explanation of how their approach is NLPspecific. This feedback is implicit, as the authors need to infer that they need to clarify the NLPspecific aspects of their approach. However, the action is vague because it does not provide specific guidance on what aspects of the approach need clarification or how to demonstrate the NLPspecificity. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made or which sections or figures might contain this information. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details about what aspects of the approach are NLPspecific, leaving the authors uncertain about how to address the feedback. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not provide any specific evidence or reasoning to support this claim, nor does it offer examples or references to substantiate the assertion. Without detailed justification or supporting evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment questions the authors\" claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. It points out that the authors do not provide any evidence or explanation of how their approach is NLPspecific. This feedback is 3 as it highlights a potential gap in the authors\" claim and encourages them to clarify the NLPspecific aspects of their approach. However, the comment lacks specific guidance on how to address this issue or what evidence should be provided to support their claim. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the comparison with stateoftheart (SOTA) methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure a fair comparison. The action is implicit and vague, as it does not specify how the authors should adjust their comparison or what additional experiments might be needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison with stateoftheart methods, specifically mentioning the use of a newly collected 209M dataset and the performance of existing methods using smaller datasets, such as GEM with 20M unlabeled data. This provides a clear reference point for the authors to understand the context of the comparison. However, the comment does not specify which part of the paper discusses the comparison with SOTA methods, making it weakly grounded. The comment is specific in detailing the issue of dataset size impacting accuracy, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with stateoftheart methods may be unfair due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides an example of a method, GEM, which uses only 20M unlabeled data, suggesting that the superior performance of the proposed method might be attributed to the larger dataset size. However, the comment lacks specific evidence or references to support this claim, such as detailed comparisons of the datasets used by different methods or a discussion of how dataset size affects accuracy. Without these details, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison with stateoftheart methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer provides a specific example, mentioning that GEM employs only 20M unlabeled data, which highlights the potential impact of dataset size on accuracy. This feedback is 3 as it identifies a potential issue with the comparison and suggests that the superior performance of the proposed method might be attributed to the larger dataset size. However, the comment could be more helpful if it provided additional guidance on how the authors could address this issue, such as conducting experiments with similar dataset sizes or providing a more detailed analysis of the impact of dataset size on performance. Overall, the comment offers a clear point for improvement but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some claims in the paper might be inspired from existing studies and recommends adding supportive references. It provides an example of a section (Lines 5564) where this issue is mentioned. However, the comment does not explicitly instruct the authors to add these references or provide specific guidance on where to find or include them. The action is implicit and somewhat vague, as the authors are left to infer that they need to add references to support the claims made in the specified section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions Lines 5564, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear example of claims that have been discussed in existing studies, suggesting that the authors should add supportive references. This feedback is detailed and provides a clear direction for improvement, making it 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that some claims in the paper may be inspired from existing studies and suggests adding supportive references. It provides an example of a section (Lines 5564) where this issue is mentioned. However, the comment lacks specific references or detailed reasoning to support the claim that the claims are inspired from existing studies. Without additional evidence or examples, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by suggesting that some claims might be inspired from existing studies. It provides an example of a section (Lines 5564) where this concern is raised, specifically mentioning four critical factors that affect the performance of chainofthought prompting. However, the comment does not offer detailed guidance on how to address this issue or provide specific references to existing studies that could be cited. While it highlights an important aspect of the paper, the feedback lacks actionable suggestions and depth, making it 3. The authors would need to infer that they should add references to support the claims, which could be a valuable but incomplete piece of feedback."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the first paragraph of the Introduction is devoted to a general introduction of DNNs and lacks any mention of drift. It suggests that this paragraph is not central to the paper\"s focus on detecting drift types and magnitude, and that it provides little valuable information. This feedback is clear and specific, as it identifies a specific part of the paper that needs revision and provides a clear rationale for why it is not relevant to the paper\"s core focus. The authors can directly infer that they should either remove or reframe this paragraph to align with the paper\"s main contribution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions the first paragraph of the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, noting that the paragraph focuses on a general introduction of DNNs without mentioning drift, which is central to the paper\"s core focus. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of the Introduction is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper\"s focus on detecting drift types and magnitude. The comment suggests that this paragraph provides little valuable information to readers. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to independently assess the relevance of the paragraph to the paper\"s focus to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction section, noting that it focuses on a general introduction of DNNs without mentioning drift, which is central to the paper\"s core focus. This feedback is clear and actionable, as it directs the authors to reconsider the relevance of the introduction to their work. By highlighting the lack of focus on drift, the comment provides a clear direction for improvement, suggesting that the authors should either remove or reframe the paragraph to align with the paper\"s main contribution. This feedback is 4 as it offers a specific and actionable suggestion, though it could be further enhanced by providing additional guidance on how to reframe the introduction. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not provide specific guidance on how to implement these suggestions or what aspects of the prompting technique need to be improved. The action is implicit and vague, as the authors are left to infer that they should explore more sophisticated prompting techniques. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or where the authors should focus their attention. This lack of grounding makes it difficult for the authors to understand which section or aspect of the paper needs improvement. Additionally, the comment is specific in its suggestion to use carefully curated prompts, but without clear guidance on how to implement this suggestion, it remains somewhat specific. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of LLMs. It suggests that carefully curated prompts could yield better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and support to fully substantiate the authors\" concerns.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and does not fully leverage the capabilities of LLMs. It suggests that carefully curated prompts could yield better results in generating systematic reviews. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the prompting technique need improvement. While it highlights an area for potential enhancement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed method, suggesting that it might be easy to improve a relatively small backbone due to its smaller receptive field. It also raises a question about whether the proposed method still works well on larger backbone models like SwinB or SwinL. While the comment identifies a potential issue with the method\"s effectiveness on larger backbones, it does not provide explicit guidance on how to address this concern or what specific experiments or analyses should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they should investigate the performance of the proposed method on larger backbones. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method across different frameworks and tasks, noting that the gains are not very strong. It specifically mentions that the proposed methods achieve only about 1% gain on a relatively small backbone ResNet55. The comment also raises a question about whether the proposed method works well on larger backbone models like SwinB or SwinL. However, the comment does not explicitly mention which part of the paper this issue is related to, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issue with the relative gains and the concern about larger backbones, but it does not provide detailed guidance on how to address these concerns. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed method are not very strong, particularly when compared to the baselines. It suggests that the proposed method might be easy to improve on a relatively small backbone due to its smaller receptive field, and questions whether it still works well on larger backbone models like SwinB or SwinL. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the assertion. The reasoning is somewhat vague, as it does not provide detailed evidence or reasoning to substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail or evidence to fully support it.", "helpfulness_rationale": "The review comment identifies a potential issue with the relative gains of the proposed method, noting that it is not very strong compared to the baselines. It also raises a question about whether the proposed method still works well on larger backbone models like SwinB or SwinL, suggesting that the method might be easily improved on smaller backbones due to their smaller receptive fields. While the comment highlights a concern that could impact the significance of the proposed method, it does not provide specific guidance or suggestions on how to address this issue or what experiments could be conducted to further investigate the method\"s performance. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. It also mentions that the authors have provided an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the comment does not explicitly instruct the authors to add more datasets or provide additional details on their selection process. While the suggestion is clear, it lacks concrete guidance on how to address the issue, such as proposing specific datasets or methods for evaluation. Therefore, the comment is 3, as it identifies a potential improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of dataset size and the number of datasets used for the tasks, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the potential insufficiency of the datasets for rigorous evaluation, particularly when some datasets are too large for all algorithms. The comment further suggests that the authors have addressed this issue by providing an addendum, clarifying the novelty of the datasets and the motivations for their choice. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, especially if some datasets are too large for all algorithms. The comment suggests that the authors have addressed this issue by providing an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the claim lacks specific examples or detailed reasoning to fully support the assertion that the current number of datasets is inadequate. While the authors\" response is acknowledged, the initial claim remains 3 due to the lack of detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the number of datasets used for the tasks, suggesting that it might be insufficient for a rigorous evaluation, especially if some datasets are too large for all algorithms. It acknowledges the authors\" response, which includes an addendum clarifying the novelty of the datasets and the motivations for their choice. This feedback provides a clear point for improvement, suggesting that the authors should consider adding more datasets or providing additional details on their selection process to enhance the rigor of their evaluation. However, the comment could be more helpful by offering specific suggestions or guidance on how to address the issue, such as proposing additional datasets or methods for evaluation. Overall, the comment is 3 as it highlights a potential area for improvement but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to correct the mistakes, discuss the work in detail, or provide new insights. Without specific suggestions or steps, the authors are left without a clear path to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, it does not specify which part of the paper these issues are present in, making it difficult for the authors to pinpoint the exact areas that need attention. The comment is 1 as it does not provide specific references or sections to address. While it is somewhat specific in identifying the issues, the lack of grounding makes it challenging for the authors to understand which parts of the paper need revision. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks detailed discussion and comparison with previous work, and that it does not provide new insights in the field. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it difficult to understand the basis of the criticism and how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the presence of confusing mistakes in the proof of the main results and the lack of detailed discussion and comparison with previous work, as well as the absence of new insights in the field. However, the comment does not provide specific suggestions or guidance on how to address these issues. It lacks actionable advice, such as recommending specific areas for clarification or improvement, or suggesting ways to enhance the discussion and comparison with previous work. Without concrete feedback or constructive suggestions, the authors may find it challenging to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. It also notes that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and that even pretrained models are compared with other models. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to clarify the motivation, ensure fair comparisons, or address the concerns about the model\"s size and the comparison methods. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. However, it does not specify which part of the paper these issues are related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need clarification or improvement. While the comment is specific in identifying the issues, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network and the fairness of the experimental comparisons. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of these concerns and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of clarity in the motivation for using an adversarial network and the unfairness of the experimental comparisons. It also points out that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and that even pretrained models are compared with other models. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the clarity of their motivation or the fairness of their comparisons. While it highlights areas for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the reliability of the experimental results, specifically noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to verify the results, what steps to take to improve the reliability of the findings, or how to address the discrepancy between MSE and MAE. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the experimental results, noting that the MSE is significantly smaller than the MAE, which raises concerns about their validity. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE, raising concerns about their validity. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why the results are considered unreliable or how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. This feedback is clear and actionable, as it highlights a potential problem with the experimental findings. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address or resolve this issue. Without specific advice on improving the reliability of the results, the authors may struggle to make meaningful changes to their draft. Therefore, the comment is 3, as it points out a critical area for improvement but lacks detailed guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the method, specifically the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific changes should be made to the draft. The comment identifies a gap in the methodology but lacks guidance on how to improve it. As a result, the authors are left without a clear understanding of what actions to take to address the identified issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not specify which part of the paper this issue is related to, such as a particular section or methodology. Without this context, the authors cannot confidently determine where the issue lies and how to address it. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the method, specifically the lack of adversarial loss to ensure that perturbed data remains similar to authentic data. However, it does not provide any suggestions or guidance on how to address this issue or what specific changes should be made to the draft. The comment highlights a gap in the methodology but lacks actionable feedback, leaving the authors without a clear understanding of how to improve their work. As a result, the comment is 2, as it points out a problem but does not offer any constructive advice or suggestions for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. While the comment provides explicit guidance on what actions the authors should take\u2014namely, to conduct additional experiments and train baseline models with the correct forecast horizon\u2014it does not specify how to implement these actions or what specific datasets or forecast horizons to use. The actions are concrete but lack detailed guidance, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to put the results in a proper context. However, the comment does not specify which part of the paper discusses the verylongterm forecasting task or which sections or figures need improvement. This lack of grounding makes it difficult for the authors to identify the specific areas that require attention. While the comment is specific about the need for additional experiments and training, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim about the limited practical significance of the task. The suggestion to conduct experiments on more datasets and train baseline models with the correct forecast horizon is clear and actionable, but the overall claim about the task\"s significance is not fully substantiated. Therefore, the comment is 4, as it provides some justification but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task and suggests improvements to the discussion. It recommends conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide a proper context for the results. This feedback is clear and actionable, offering specific suggestions for enhancing the paper\"s discussion and ensuring that the results are properly contextualized. However, the comment could be more helpful if it provided more detailed guidance on which datasets to use or how to define the \"correct\" forecast horizon. Despite this, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific area where the authors lack analysis, namely the security and privacy protection of the proposed framework. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment identifies a gap in the analysis but does not offer guidance on what steps to take to improve the draft. As a result, the authors are left without a clear direction on how to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific area of the paper where the authors lack analysis, namely the security and privacy protection of the proposed framework. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its focus on security and privacy, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors do not analyze the security and privacy protection of the proposed framework. However, the comment lacks specific details or examples to support this claim. Without additional information or references, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the security and privacy protection of the proposed framework. This is a crucial aspect that needs to be addressed for the paper to be considered complete and robust. However, the comment does not provide any suggestions or guidance on how the authors might approach this analysis, such as specific methods or frameworks they could consider. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a critical issue but does not offer detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the claim that \"Memb is apparently the previous stateoftheart,\" but it does not provide any explicit or implicit suggestions on how to address this issue. The comment lacks guidance on whether the authors should include a reference or provide more context to support the claim. Without specific instructions on what needs to be done, the authors are left without actionable steps to take. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or element being discussed. Additionally, the comment is not specific because it does not provide details on what needs to be addressed regarding the claim about \"Memb being the previous stateoftheart.\" Without specific guidance or examples, the authors cannot effectively respond to the comment. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"Memb is apparently the previous stateoftheart,\" but it does not provide any supporting evidence or references to substantiate this claim. Without any justification or references, the authors are left without a basis to verify or challenge the claim. This lack of support makes the comment 1, as it does not offer a clear basis for the authors to address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim that \"Memb is apparently the previous stateoftheart,\" but it does not provide any specific guidance or suggestions on how to address this concern. The comment lacks actionable advice, leaving the authors without a clear path to improve their draft. Without additional context or recommendations, the feedback is minimal and does not offer substantial value to the authors. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and supplement. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the clarity of their examples. The comment lacks concrete guidance on what specific changes could be made to enhance the examples or how the authors might go about finding more illustrative examples. As a result, the authors are left without a clear understanding of how to proceed with improving their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and supplement. However, it does not specify which part of the paper or section contains these examples, making it difficult for the authors to pinpoint the exact issue. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be addressed to improve the clarity of the examples. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and supplement. However, it does not provide any specific reasoning, references, or examples to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding examples that illustrate the loss principles clearly, similar to those presented in the paper and supplement. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve the clarity of their examples. The comment lacks actionable feedback, leaving the authors without a clear understanding of how to enhance their draft. As a result, the comment is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the quality of paraphrases used for training data generation. It points out that the difference between the paraphrases and the original sentences is unclear, which could impact the subsequent steps and the overall quality of the training data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paraphrases. The feedback is somewhat vague and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of generating paraphrases for training data, specifically noting that the difference between the paraphrases and the original sentences is unclear. This provides a clear indication of which part of the paper the comment is focused on, allowing the authors to accurately identify the relevant section. However, the comment does not specify what needs to be addressed in terms of improving the paraphrases or how to ensure the quality of the training data. While the authors can infer that they need to clarify the differences between paraphrases and original sentences, the comment lacks specific guidance on how to achieve this. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrases used for training data generation, specifically noting that the difference between the paraphrases and the original sentences is unclear. This concern is relevant to the paper as it impacts the subsequent steps and the overall quality of the training data. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the difference between the paraphrases and the original sentences is unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the quality of paraphrases used for training data generation. It highlights that the difference between the paraphrases and the original sentences is unclear, which can significantly impact the subsequent steps and the overall quality of the training data. The comment provides a clear and actionable suggestion that the authors should clarify how different the paraphrases are from the original sentences. This feedback is valuable as it directs the authors to address a specific aspect of their methodology that could affect the reliability of their results. However, the comment could be more helpful if it provided additional guidance on how to ensure the quality of the paraphrases or what specific steps could be taken to improve them. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should investigate and clarify the concatenation process. However, the comment lacks concrete details on how to implement this investigation or what specific aspects need clarification. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on how to execute it.", "grounding_specificity_rationale": "The comment raises a question about whether the text input is concatenated by four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on what needs to be addressed or how to clarify the concatenation process. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or reasoning. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about whether the text input is concatenated by four text elements of an object. While it prompts the authors to consider this aspect, it does not provide any specific guidance or suggestions on how to address this question or what changes might be necessary. The comment lacks depth and does not offer actionable feedback that would help the authors improve their draft. Therefore, it is 2, as it identifies a potential area for clarification but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be improved by first motivating the \"why\" behind the research. However, it does not provide explicit guidance on how to motivate the \"why\" or what specific aspects of the paper need to be addressed to achieve this. The action is implicit, as the authors would need to infer that they should add a section or discussion motivating the importance of the research question. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be improved by first motivating the \"why\" behind the research. However, it does not specify which part of the paper this motivation should be included in, making it weakly grounded. The comment is specific in its suggestion to motivate the \"why,\" but without a clear reference to a specific section or aspect of the paper, the authors may find it challenging to understand where to apply the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could be improved by first motivating the \"why\" behind the research. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper could be improved by first motivating the \"why\" behind the research, which is a valuable piece of feedback. It highlights a potential area for improvement by emphasizing the importance of clearly articulating the motivation and significance of the research question. However, the comment lacks specific guidance on how to motivate the \"why\" or what aspects of the paper need to be addressed to achieve this. While it provides a clear direction for improvement, the feedback could be more helpful if it included suggestions on how to structure the motivation or examples of effective motivation strategies. Overall, the comment is 3 as it identifies a meaningful area for enhancement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the fairness of comparisons made in the experiments, specifically noting that the domainspecific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zeroshot singleimage 3D reconstruction models might be unfair. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experiments or comparisons. The action is implicit, as the authors need to infer that they should consider the fairness of their comparisons and potentially adjust their experimental setup or analysis to ensure a more equitable evaluation. While the action is somewhat vague, it is clear that the authors need to address the issue of fairness in their comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pix3D\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, highlighting the unfairness of the comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that comparisons to zeroshot singleimage 3D reconstruction models are unfair because the domainspecific model and the experiments are both conducted on Pix3D. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the comparisons are unfair. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of comparisons made in the experiments, specifically noting that the domainspecific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zeroshot singleimage 3D reconstruction models might be unfair. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to ensure a fairer comparison. While it highlights a concern, it lacks actionable advice or detailed feedback, making it 3. The authors would need to infer that they should consider the fairness of their comparisons and potentially adjust their experimental setup or analysis to address this concern. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D (Contrastive 2D) approach. However, it does not specify which aspects of the C2D approach would benefit from these experiments or how the experiments should be conducted. The comment implies that the authors should consider adding such experiments, but it lacks concrete guidance on what specific experiments to perform or how to integrate them into the draft. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its suggestion regarding the type of experiments, but it lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion or how to implement it. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. This feedback is 3 as it identifies a potential area for improvement by suggesting a specific type of experiment that could enhance the paper\"s support for the C2D approach. However, the comment lacks depth and does not provide detailed guidance on how to conduct these experiments or what specific aspects of the C2D approach would benefit from them. The suggestion is clear but could be more actionable with additional details, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue, it does not provide explicit instructions or suggestions on how to address this concern. The comment lacks concrete guidance on how the authors should verify or correct the issue, leaving them to infer the necessary steps. Therefore, the comment is 3, as it points out a potential problem but does not offer detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its question but lacks grounding as it does not provide context or references to the relevant sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about whether the grid search of the learning rate is performed on the validation set. This is a factual question that does not require any claim or justification. The comment is a normal statement, as it asks for clarification or confirmation about a specific aspect of the methodology. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this concern. The comment lacks actionable feedback, as it does not offer any specific advice or recommendations for improvement. Therefore, it is 2, as it only points out a minor issue without providing any actionable insights or suggestions for the authors to consider."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized ones. It does not provide explicit instructions or suggestions on how to address this issue, such as adding data or discussing the implications of the sample\"s diversity. The action is implicit, as the authors would need to infer that they should consider the diversity of their sample and its impact on generalizability. However, the comment lacks concrete guidance on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (L393) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the question about the diversity of the sample and its generalizability to other groups, especially marginalized groups. This provides clear guidance on what aspect of the paper requires attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized groups. It does not contain a subjective claim or suggestion that requires verification. The comment is factual and descriptive, as it poses a question about the paper\"s content. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a pertinent question about the diversity of the sample and its generalizability to other groups, especially marginalized ones. This is a critical aspect of ensuring the robustness and applicability of the research findings. However, the comment does not provide any suggestions or guidance on how to address this issue, such as adding data or discussing the implications of the sample\"s diversity. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights a significant concern but does not offer constructive feedback for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that nonconvexity may not be an issue for SGD convergence if the function Z has certain properties. However, it does not provide any specific guidance or action for the authors to take in response to this observation. The comment lacks explicit instructions on how the authors might address this point or incorporate it into their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific section of the paper (ln. 182184), allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear observation about the potential issue with nonconvexity and SGD convergence, suggesting that this may not be a problem if the function Z has good properties. This feedback is actionable and provides a clear direction for the authors to consider. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the potential issue of nonconvexity in the context of SGD convergence, suggesting that it may not be a problem if the function Z has good properties. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper regarding the convergence of SGD in the context of nonconvex functions. It suggests that the issue may not be significant if the function Z possesses certain properties. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or incorporate it into their work. It does not provide actionable feedback or detailed insights that would help the authors improve their draft. Therefore, the comment is 2, as it points out a potential area for consideration but does not offer substantial guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. While the comment identifies two separate issues, it does not explicitly instruct the authors to address these by providing detailed experimental settings and the code. The action is implicit and somewhat vague, as the authors need to infer that they should include these details to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of experimental settings and result reproducibility, which are critical aspects of a scientific paper. However, it does not specify which part of the paper discusses the experimental settings or result reproducibility, making it weakly grounded. The comment is specific in identifying the need for proper mention of experimental settings and the provision of code for reproducibility, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental settings are not mentioned properly, which is critical for result reproducibility, and that the authors do not provide the code. This claim is 3 as it highlights a critical issue in the paper, but it lacks specific examples or references to support the claim. The authors would need to infer that they should provide more detailed experimental settings and the code to address this issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the lack of proper mention of experimental settings and the absence of code, which are essential for result reproducibility. It highlights the importance of providing detailed experimental settings and the code to ensure that the results can be replicated by other researchers. This feedback is clear and actionable, as it directs the authors to address these specific areas to improve the reproducibility and reliability of their work. However, the comment could be more helpful if it suggested specific ways to include the experimental settings or code, such as providing a detailed description or a link to the code repository. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify exactly what aspects of the motivation need clarification or how to demonstrate it more explicitly. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the motivation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the need for a clearer explanation, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the motivation is unclear or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the motivation behind applying CMD in federated learning. It suggests that the authors could benefit from a more explicit demonstration or explanation of this motivation. However, the comment lacks specific guidance or examples on how to address this issue, leaving the authors with a general idea of what to improve but without detailed instructions. This makes the feedback 3, as it points out an area for enhancement but does not provide comprehensive suggestions. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the contribution of the CoNO model, specifically whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable and provides references to support the claim. While the comment implies that the authors should compare their model to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to UNets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed CoNO model and questions the source of the performance boost, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This comment is fully grounded as it explicitly mentions the CoNO model and the specific aspect of its performance that is being questioned. It is also specific because it provides clear guidance on what comparisons should be made, namely comparisons to UNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the source of the performance boost in the proposed CoNO model, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This provides a logical reasoning and specific examples to support the claim, making it 4. The comment is clear and provides sufficient evidence for the authors to understand and address the issue.", "helpfulness_rationale": "The review comment raises a critical question about the source of the performance boost in the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This feedback is 4 as it provides a clear direction for the authors to improve their draft by including comparisons to UNets. However, it could be more helpful if it suggested specific ways to conduct these comparisons or provided more detailed guidance on how to evaluate the performance of the CoNO model against UNets. Overall, the comment is 4, as it identifies a significant area for improvement and offers a clear path for the authors to address it."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments described, such as the Brusselator, due to time constraints. While the comment highlights a potential issue with the authors\" engagement with the appendix, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The feedback is implicit and lacks concrete suggestions, making it difficult for the authors to understand how to enhance their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments described, such as the Brusselator, due to time constraints. However, the comment does not specify which part of the Appendix or the paper the authors should focus on, making it weakly grounded. Additionally, the comment does not provide specific guidance on how to address this issue or what actions the authors should take to improve their draft. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses a concern about the authors not carefully reading the additional experiments described in the Appendix, such as the Brusselator, due to time constraints. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to explain why the authors might not have read the appendix thoroughly. Without additional context or reasoning, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments described, such as the Brusselator, due to time constraints. While the comment highlights a potential issue with the authors\" engagement with the appendix, it does not provide specific suggestions or guidance on how to address this concern. The feedback is 3 as it identifies a potential area for improvement, but it lacks actionable advice or detailed suggestions, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While it suggests that these terms likely denote the Encoder and Decoder networks, the comment does not provide explicit guidance on how the authors should define these terms or where they should be defined. The action is implicit, as the authors need to infer that they should define W and V, but it lacks concrete details on how to do so. Therefore, the comment is 3, as it provides a clear indication of what needs to be addressed but does not offer specific guidance on how to implement the action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (p.3, A4, eq.3 and eq.4) where the terms W and V are not defined. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies that the terms W and V are not defined in these sections, and it suggests that these terms likely denote the Encoder and Decoder networks. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While the comment identifies a potential issue with the clarity of the paper, it does not provide any specific examples or references to support this claim. The lack of detailed explanation or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the terms W and V are not defined in equations 3 and 4. This is a clear and actionable feedback that highlights a lack of clarity in the paper. However, the comment does not provide any suggestions or guidance on how the authors might define these terms or improve the clarity of the equations. While it points out a specific area for improvement, it lacks depth and does not offer constructive advice on how to address the issue. Therefore, the comment is 3, as it identifies a problem but does not provide comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per the number of residents. While the comment identifies a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, as the authors are left to infer how to apply the feedback. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and \"the formulation introduced by the authors,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per the number of residents. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the formulation introduced by the authors assumes that observations are obtained by averaging over the support $v$, but it suggests that the data might be aggregated by other procedures, such as simple summation or populationweighted average. The reviewer provides examples of how disease incident data are often available in count or rate per the number of residents. This claim is 3 as it offers specific examples and reasoning to support the assertion that the data aggregation process might differ from the assumed averaging method. However, it could be more robust with additional references or detailed explanations to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per the number of residents. This feedback is 3 as it highlights a potential area for clarification and suggests alternative aggregation methods that might be more appropriate. However, the comment could be more helpful if it provided specific guidance on how the authors could address this issue or what changes they should consider making to their draft. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement this change or what specific aspects of the policy to modify. The suggestion is somewhat vague, as it lacks detailed guidance on how to make the policy nonfixed or how to compare with a reinforcement learning baseline. Therefore, the comment is 3, as it provides a general idea but lacks concrete steps for the authors to follow.", "grounding_specificity_rationale": "The comment suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion, the absence of explicit grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or detailed reasoning to support why this suggestion is beneficial or how it would enhance the paper. Without concrete evidence or references, the claim remains 3, as the authors may find it challenging to fully understand and implement the suggested changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. This feedback provides a clear direction for improving the paper by expanding the scope of the tasks and enhancing the comparison with existing methods. However, the comment lacks specific guidance on how to implement these changes or what aspects of the policy should be modified. While it offers a valuable suggestion, the lack of detailed instructions limits its helpfulness. Therefore, the comment is 3, as it provides a general idea but lacks depth and actionable steps for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might establish this relationship, leaving them without a clear path forward. As a result, the comment is 1, as it does not offer any concrete steps or suggestions for improvement. Therefore, it aligns with the lowest score of 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section or aspect that needs improvement. It mentions \"incomplete study\" and \"the relationship between the top selected patches and the disease,\" but without specific references to sections, tables, or figures, the authors cannot pinpoint the exact issue. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the relationship are missing or how the authors might address this issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the study is incomplete because the relationship between the top selected patches and the disease is not yet established. However, the comment lacks specific details or references to support this claim. It does not provide examples or evidence to substantiate the assertion that the relationship is not yet established. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the study, noting that the relationship between the top selected patches and the disease is not yet established. This feedback is valuable as it highlights a critical gap in the research, suggesting that the authors need to provide more evidence or analysis to support their claims. However, the comment lacks specific guidance on how the authors might address this issue or what additional data or analysis could be included to establish the relationship. While it points out a crucial area for improvement, the feedback could be more helpful if it provided suggestions or examples of how to strengthen the study. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the numerical evaluation: the use of synthetic data and the fairness of the comparison with [5]. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their evaluation or ensure a fair comparison. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation of the paper, specifically mentioning the use of synthetic data and the comparison with [5]. However, it does not specify which part of the paper this evaluation is discussed in, making it weakly grounded. The comment is specific in identifying the issues with the evaluation, such as the use of synthetic data and the fairness of the comparison with [5]. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing because the method is only evaluated on synthetic data, and the comparison with [5] is not fair due to the difference in problem complexity. However, the comment does not provide specific examples or detailed reasoning to support these claims. While the reasoning is somewhat logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key issues with the numerical evaluation of the paper. First, it points out that the method is only evaluated on synthetic data, which may not accurately reflect realworld performance. Second, it notes that the comparison with [5] is not entirely fair because [5] is designed for a more complex problem, specifically lacking knowledge of camera pose parameters. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their evaluation. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two distinct issues. First, it questions the rationale behind using an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q when the latter cannot be computed, asking why the authors did not directly use Importance sampling. This suggests that the authors should clarify their choice of method and provide a rationale for their approach. Second, the comment points out a lack of clarity in Algorithm 1, specifically questioning the difference between QRS and RS and suggesting that the authors should clarify the behavior of these methods for different values of u. While the comment provides some guidance, it does not explicitly instruct the authors on how to address these issues, leaving them to infer the necessary actions. Therefore, the comment is 3, as it provides some direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment addresses two distinct issues related to the methodology and algorithm presented in the paper. It questions the rationale behind using an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, and it also points out a lack of clarity in Algorithm 1 regarding the difference between QRS and RS. However, the comment does not specify which parts of the paper these issues are related to, such as specific sections or algorithms. This makes it difficult for the authors to pinpoint the exact areas that need clarification or improvement. The comment is specific in its questioning of the methodology and algorithm, but it is weakly grounded because it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions about the methodology and algorithm presented in the paper. The first question asks why the authors did not directly use Importance sampling instead of using an arbitrary parameter \u03b2. The second question questions the difference between QRS and RS in Algorithm 1. While the questions are valid and point to potential areas for clarification, they do not provide specific evidence or reasoning to support the claims made. The authors would need to provide additional context or justification to address these questions effectively. Therefore, the comment is considered 2, as it lacks sufficient support for the claims made.", "helpfulness_rationale": "The review comment raises two distinct questions about the methodology and algorithm presented in the paper. The first question challenges the rationale behind using an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q, which could be clarified by providing a more detailed explanation of the choice. The second question points out a lack of clarity in Algorithm 1, specifically questioning the difference between QRS and RS and suggesting that the authors should clarify the behavior of these methods for different values of u. While the comment identifies areas for improvement, it lacks depth and specificity, as it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it highlights areas that need clarification, but it could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the draft to include such a comparison. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison is intended for or how it relates to the content of the draft. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the comparison or what aspects of the paper need to be revised. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any specific claims, opinions, or suggestions. It is a factual question that does not require verification or justification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect for evaluating the efficiency and practicality of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or incorporate such a comparison into their draft. Without specific advice or suggestions, the authors are left without actionable feedback, making the comment unhelpful. Therefore, the comment aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant gap in the paper by noting the absence of a comparison against baselines. It mentions that the functionality similarity comparison study only reports accuracy across optimization levels of binaries but lacks baselines. The comment suggests that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to include or how to conduct the comparison. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the lack of comparison against baselines in the functionality similarity comparison study, specifically mentioning that it only reports accuracy across optimization levels of binaries but lacks baselines. It also notes that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not specify which part of the paper this issue is discussed in, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in detailing the issue of missing baselines and suggesting relevant comparisons, but without explicit grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison against baselines in the functionality similarity comparison study, specifically noting that it only reports accuracy across optimization levels of binaries but does not include baselines. The comment suggests that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not provide specific examples or references to support the claim that these baselines are widely understood or commonly used. This lack of detailed justification makes the claim 3, as the authors may need to infer the relevance of the baselines mentioned. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against baselines in the functionality similarity comparison study. It highlights that the study only reports accuracy across optimization levels of binaries but lacks baselines, which is a crucial aspect for validating the effectiveness of the proposed method. The comment suggests that many papers have developed architectureagnostic similarity comparison or reported it as codesearch, which are similar tasks, providing context for the authors to consider. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this gap, such as suggesting particular baselines to include or how to conduct a more comprehensive comparison. Overall, the comment is 3 as it identifies a critical area for improvement but lacks detailed actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. However, it does not provide any explicit or implicit actions for the authors to take. The comment points out a potential issue but does not guide the authors on how to address it or what changes are needed. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it points out a clear discrepancy between the abstract and the text regarding the requirement of the proposal distribution to upper bound the target everywhere. This provides the authors with a clear understanding of what needs to be corrected or clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract incorrectly states that the proposal distribution must upper bound the target everywhere, which is not true as the authors clarify in the text. This claim is supported by the fact that the authors themselves acknowledge this discrepancy in the text, providing a clear justification for the comment. However, the comment could be more robust by explicitly referencing the specific section or part of the text where this clarification is provided. Despite this, the claim is 4, as it is supported by logical reasoning and a reference to the authors\" own text. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the abstract, noting that it incorrectly states that the proposal distribution must upper bound the target everywhere, which is not accurate as the authors clarify in the text. This feedback is clear and actionable, as it directs the authors to correct the abstract to align with their text. However, the comment could be more helpful if it provided specific guidance on how to revise the abstract or suggested alternative phrasing. Despite this, the comment is 4 as it offers a clear direction for improvement, allowing the authors to address the identified discrepancy effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit suggestions on how the authors should address this question or what changes might be needed. Without further guidance or clarification, the authors are left without a clear understanding of what to do to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the section or figure being referred to. Additionally, the comment is not specific because it does not provide any details on what is intended or how it should be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the intent of Section 5.2 but does not provide any claim, suggestion, or critique that requires verification. It is a factual question that does not offer any guidance or insight into how the authors should improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which could be helpful for the authors to clarify their writing or improve the flow of the paper. However, it does not provide any specific suggestions or guidance on how to address this question or what changes might be needed. The comment lacks actionable feedback, making it 2 as it does not offer any actionable steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that many aspects of the approach need clarification and that the paper quickly delves into technical details without clearly explaining the overall approach or its rationale. However, it does not provide explicit instructions or suggestions on how the authors should clarify these aspects or address the concern about the paper\"s flow. The action is implicit, as the authors are expected to infer that they need to clarify the approach and provide a clearer explanation of the paper\"s overall structure and rationale. The action is somewhat vague, as it lacks concrete guidance on what specific aspects need clarification or how to address the concern about the paper\"s flow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many aspects of the approach need to be clarified,\" allowing the authors to identify the specific part of the paper being addressed. It also specifies what needs to be clarified, particularly regarding the interaction between knowledge about objects and verbs to overcome reporting bias. However, the comment does not provide specific examples or detailed guidance on what aspects need clarification, making it somewhat specific. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the clarity of the approach and the paper\"s flow, specifically questioning how the approach makes knowledge about objects interact with knowledge about verbs to overcome reporting bias. However, the comment lacks specific examples, detailed explanations, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It specifically highlights the concern regarding how the approach makes knowledge about objects interact with knowledge about verbs to overcome reporting bias, which is a critical point for understanding the paper\"s contribution. However, the comment lacks detailed suggestions or guidance on how the authors might address these issues or improve the clarity of their approach. While it points out a crucial area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide specific steps or examples for the authors to follow. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the chatGPT baseline is rudimentary and that fewshot approaches should be tested. It also recommends including discourse relation information in the prompts, possibly using a ChainofThought style, to potentially improve the results. However, the comment does not provide explicit guidance on how to implement these suggestions or actions. The feedback is somewhat vague, as it lacks detailed instructions on how to test the fewshot approach or how to incorporate the discourse relation information into the prompts. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment addresses the chatGPT baseline, noting that it is rudimentary and that fewshot approaches are not tested. It also suggests that including discourse relation information in the prompts, possibly using a ChainofThought style, could yield good results. However, the comment does not specify which part of the paper discusses the chatGPT baseline or the fewshot approach, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as testing fewshot approaches and incorporating discourse relation information. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the chatGPT baseline is rudimentary and that fewshot approaches are not tested. It suggests that including discourse relation information in the prompts, possibly using a ChainofThought style, could yield good results. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general idea but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a weakness in the paper by pointing out that the chatGPT baseline is rudimentary and that fewshot approaches are not tested. It also suggests that including discourse relation information in the prompts, possibly using a ChainofThought style, could yield better results. While the comment provides some actionable feedback, it lacks depth and specificity, as it does not offer detailed guidance on how to implement these suggestions or how to evaluate the results. The feedback is 3, as it directs the authors to areas for improvement but does not fully address the need for comprehensive enhancements. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the authors were unclear about the number of parameters used in each approach, as mentioned in Section B.3. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks guidance on what specific steps the authors should take to clarify the number of parameters or how to present this information effectively. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section B.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a lack of clarity regarding the number of parameters used in each approach, providing a clear direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the clarity of the numbers of parameters used in each approach, as mentioned in Section B.3. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment points out a specific issue in the paper, namely the lack of clarity regarding the number of parameters used in each approach, as mentioned in Section B.3. While it identifies a potential area for improvement, it does not provide any suggestions or guidance on how the authors might address this issue. The comment is clear and highlights a specific aspect of the paper that needs attention, but it lacks actionable advice or suggestions for improvement. Therefore, the comment is 3, as it provides a clear indication of a problem but does not offer comprehensive guidance for resolution."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the statistical significance of the evaluation results reported in Table 1, noting that the results are based on only three trials per case, which is not statistically significant. The comment suggests that the reported deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the statistical significance of their results. The action is implicit and vague, as the authors are left to infer that they need to increase the number of trials or reconsider their claims. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statistical significance of the results, explaining why the reported deviations are not meaningful and why the claims made based on these results are not valid. The comment provides clear guidance on how the authors should address this issue, such as increasing the number of trials or reconsidering their claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials, which is not statistically significant. It argues that this lack of significance makes the reported deviations and claims, such as \"our performance is at least two standard deviation better than the next best baseline,\" unmeaningful. The comment provides a logical reasoning for why the results are not significant and suggests that the authors should reconsider their claims. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the statistical significance of the evaluation results reported in Table 1. It points out that the results are based on only three trials per case, which is not statistically significant, making the reported deviations and claims unmeaningful. The comment provides a clear rationale for why the results are not significant and suggests that the authors should reconsider their claims. However, it does not offer specific guidance on how the authors might address this issue or what steps they should take to improve the statistical significance of their results. While the feedback is valuable, it lacks actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the explanation of the architecture used for the experiments, noting that the authors refer to Jiang et al. (2019) for details. This implies that the authors need to provide a more detailed explanation of the architecture within the paper to make it selfcontained. However, the comment does not specify exactly what aspects of the architecture need clarification or how the authors should elaborate on it. While the action is implied, it is vague and lacks concrete guidance on what needs to be done. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of clarity in the explanation of the architecture used for the experiments, which is a specific part of the paper. It also specifies that the authors refer to Jiang et al. (2019) for details, indicating that the paper is not selfcontained. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the architecture used for the experiments is not clearly explained in the paper, and the authors refer to Jiang et al. (2019) for details. This claim is 3 as it highlights a lack of clarity in the explanation, but it does not provide specific examples or references to support the claim. The authors could improve the paper by providing a more detailed explanation of the architecture or by referencing the specific sections of Jiang et al. (2019) that are relevant. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the architecture used for the experiments is not clearly explained, and the authors rely on Jiang et al. (2019) for details. This makes the paper not selfcontained, which is a critical issue for readers to understand the methodology. The comment is clear and actionable, as it directs the authors to provide a more detailed explanation of the architecture or to include references to their work. However, it could be more helpful if it suggested specific ways to improve the explanation or provided examples of what could be included. Overall, the comment is 4, as it effectively highlights a key area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several specific issues with the presentation quality of the paper, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the presentation. The actions are implicit and vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figs 1&2,\" \"tables with a \"\" for the method,\" \"the \"Dataset\" columns in the tables,\" \"management of Fig 3 and Table 2,\" and a \"*\" in Table 1. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details several issues with the presentation quality, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some aspects of the presentation quality in the paper are weaknesses for a highquality publication, such as NeurIPS. It provides specific examples of issues, including the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. However, the claim lacks detailed reasoning or references to support why these issues are significant or how they impact the paper\"s quality. The comment is 3 as it provides some justification but lacks depth and specific examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several specific weaknesses in the presentation quality of the paper, such as the lack of informativeness in tables, the management of figures and tables, and the meaning of a \"*\" in Table 1. While the comment provides a clear overview of these issues, it lacks detailed guidance on how the authors might address them or what specific improvements could be made. The feedback is 3 as it highlights areas for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be necessary to make the results more idiomspecific. The action is implicit and vague, as it does not offer concrete steps for improvement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed upweighing and KNN methods, referencing Figure 3 to support its claims. However, it does not specify which part of the paper Figure 3 is located in, making it weakly grounded. The comment is specific in detailing the issue with the methods and the interpretation of the results, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the impact of the proposed MT modeling methods on idiomatic vs. random data is similar, suggesting that the results may not be specific to idiomatic translations. The comment provides a logical reasoning based on the observation that the impact is similar across different language and score combinations, as shown in Figure 3. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to infer the basis of the claim, which could be improved with more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed upweighing and KNN methods, suggesting that their impact on idiomatic vs. random data is similar, which implies that the results may not be specific to idiomatic translations. The comment provides a logical reasoning based on the observation that the impact is similar across different language and score combinations, as shown in Figure 3. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve the results to be more idiomspecific. While it identifies a potential weakness in the methodology, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks important references for domain adaptation. It suggests that the authors should cite and discuss these references in the revised manuscript. This feedback is explicit and provides a clear action for the authors to take, which is to include and discuss relevant references. The comment is specific in its suggestion, guiding the authors on what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"domain adaptation,\" allowing the authors to accurately identify the part of the paper that needs improvement. It is also specific because it clearly specifies that the authors should cite and discuss important references for domain adaptation. This provides the authors with a clear understanding of what needs to be addressed in the revised manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss these references. However, the comment does not provide any specific examples of missing references or explain why these references are crucial. Without detailed justification or examples, the claim is 3, as it lacks sufficient evidence to fully support the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of important references for domain adaptation. It provides a clear and actionable suggestion for improvement by recommending that the authors cite and discuss these references in the revised manuscript. This feedback is specific and directly addresses a critical aspect of the paper, offering the authors a clear direction for enhancing their work. However, the comment could be more helpful if it provided examples of missing references or suggested specific areas where these references might be relevant. Despite this, the comment is 4 as it effectively guides the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that the proposed method, PACE, addresses a gap by treating climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts. However, the comment does not provide explicit guidance on how the authors should revise their draft to clarify the distinction between their work and prior efforts. The action is implicit, as the authors need to infer that they should address the overlap with existing work. Additionally, the comment lacks concrete details on how to make the distinction clear, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim being made in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is misleading about the claim, noting that prior work, such as ClimateBench or ClimateSet, has already addressed similar concepts. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim about PACE being a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, has already explored similar concepts. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of how the prior work aligns with the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some basis for the claim but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim made in the paper regarding the novelty of the proposed method, PACE. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts, which could make the claim misleading. However, the comment does not provide specific guidance on how the authors should address this issue or clarify the distinction between their work and prior efforts. While it highlights a potential area for improvement, the feedback lacks actionable advice, making it 3. The authors would need to infer that they should revise their draft to address the overlap with existing work, but the comment does not offer detailed suggestions or examples to facilitate this process. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential confusion in the notation used in the paper, specifically mentioning the use of \"r\" to denote both the risk for minimization problems and primal risk for minimax problems. While the comment identifies a potential issue with the clarity of the notation, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies a specific issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the notation used in the paper, mentioning the potential confusion with the use of \"r\" to denote both the risk for minimization problems and primal risk for minimax problems. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what is confusing and suggests that the authors should clarify the notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using \"r\" to denote both the risk for minimization problems and primal risk for minimax problems is confusing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this confusion arises or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used in the paper, specifically the use of \"r\" to denote both the risk for minimization problems and primal risk for minimax problems. This is a clear and actionable feedback that highlights a potential source of confusion for the readers. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative notations or clarifying the current notation in the paper. While it points out a problem, it lacks depth and could be more helpful with additional suggestions or examples. Therefore, the comment is 3, as it identifies a meaningful issue but does not fully empower the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that making the factors in a table does not help convey more messages than pure text, implying that the table does not add any additional information. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to revise the table or what specific changes could be made to improve its effectiveness in conveying messages. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that making factors in a table does not help convey more messages than pure text, implying that the table does not add any additional information. However, it does not specify which part of the paper this issue is related to, such as a particular table or section. This lack of specificity makes it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, the comment does not provide any suggestions or guidance on how to address this issue, leaving the authors without a clear path forward. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that making factors in a table does not help convey more messages than pure text, suggesting that the table does not add any additional information. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. Without detailed justification or examples, the claim remains somewhat 1. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of information in a table, suggesting that it does not effectively convey more messages than pure text. This feedback is 3 as it highlights a specific area for improvement, but it lacks depth and actionable suggestions. The authors are left without clear guidance on how to revise the table or what specific changes could be made to enhance its effectiveness. While the comment points out a valid concern, it does not provide detailed feedback or examples to help the authors address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the pruning strategy, suggesting that it might not be effective for large networks due to the lack of consideration for global top Q values of the metric over the average of gradients. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment implies that the authors should consider this aspect, but it lacks concrete steps or suggestions on how to implement it. Therefore, the comment is 3, as it identifies a potential problem but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses a specific issue related to pruning strategies, particularly in the context of large networks and distributed training. It highlights a potential problem with the current approach, suggesting that majorly works with large networks but does not mention the necessity of finding global top Q values of the metric over the average of gradients. This provides a clear indication of what part of the paper the comment is addressing, making it fully grounded. The comment is also specific as it specifies the potential issue with pruning strategies and the impact on acceleration techniques like quantization and sparsification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that pruning majorly works with large networks, which are usually trained in distributed settings, but does not mention the necessity of finding global top Q values of the metric over the average of gradients. This claim is 3 as it highlights a potential issue with the pruning strategy but lacks specific examples or references to support the claim. The authors would need to provide more context or evidence to fully understand the implications of this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the pruning strategy, specifically noting that it might not work effectively for large networks due to the lack of consideration for global top Q values of the metric over the average of gradients. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate the necessary considerations into their work. While it points out a critical aspect that needs attention, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear observation but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment raises a concern about the generality of the claim but does not offer guidance on how to address it or what changes might be necessary. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific part of the paper by referencing lines 2627, which allows the authors to accurately identify the section being discussed. It also specifies the issue by pointing out that the claim about the existence of multiple entities in sentences and documents is not limited to documentlevel relation extraction but applies to broader contexts like joint entity and relation extraction. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" This claim is based on a general observation about the nature of entities in text, which is a common understanding in the field. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors could infer that the comment is based on common knowledge, but additional evidence or references would strengthen the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the claim about the existence of multiple entities in sentences and documents is not limited to documentlevel relation extraction but applies to broader contexts like joint entity and relation extraction. This feedback is clear and actionable, as it directs the authors to consider the scope of their claims and potentially expand their discussion to include these broader contexts. However, the comment could be more helpful if it provided specific suggestions or examples of how to address this issue. Overall, the comment is 3, as it offers a clear direction for improvement but lacks depth in terms of actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point asks a question about how the proposed method compares with prior art. While it prompts the authors to consider this comparison, it does not provide explicit instructions or suggestions on how to address this comparison. The authors are left to infer that they need to include a comparison with prior work, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment asks a question about how the proposed method compares with prior art. However, it does not specify which part of the paper this comparison should be made or what aspects of the comparison are relevant. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its request for a comparison, but without grounding, the authors are left to make an educated guess about where to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the proposed method compares with prior art. However, it does not provide any specific details, examples, or references to support this claim. Without additional context or evidence, the authors are left to make their own judgments about the relevance and importance of this comparison. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how the proposed method compares with prior art, which is a relevant and important aspect for evaluating the novelty and contribution of the work. However, the comment lacks specific guidance or suggestions on how to address this comparison. It does not provide any insights into what kind of comparison would be beneficial or how the authors might approach it. Without additional context or suggestions, the authors may struggle to understand the significance of the comparison and how to incorporate it into their work. Therefore, the comment is 2, as it identifies a relevant area for improvement but does not provide actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 tsne plots. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate the suggested analysis. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the redundancy of RQ1 and suggests an interesting point for analysis related to the percentage of explicit hate information in the dataset and its effect on implicit hate speech detection performance. However, it does not specify which part of the paper discusses RQ1 or where the dataset analysis is mentioned. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is specific in suggesting an additional analysis, but without clear grounding, the authors may struggle to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the RQ1 mentioned in the paper is redundant and adds no extra information for the audience. It also suggests an interesting point for analysis regarding the percentage of explicit hate information in the dataset and its effect on implicit hate speech detection performance. However, the comment lacks specific examples or references to support the claim about the redundancy of RQ1. While it provides a suggestion for improvement, the lack of detailed reasoning or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential redundancy in the RQ1 mentioned in the paper, suggesting that it adds no extra information for the audience. It also proposes an interesting point for analysis, such as how the percentage of explicit hate information in the dataset affects implicit hate speech detection performance and vice versa, and its corresponding effect on RQ2 & RQ3 tsne plots. However, the comment lacks specific guidance on how the authors should address this issue or incorporate the suggested analysis. While it provides a clear direction for improvement, the feedback could be more helpful if it included actionable steps or examples of how to implement the suggested analysis. Therefore, the comment is 3, as it offers insights but lacks depth and specificity in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, specifically mentioning the probabilities of actions. It also proposes that the authors may add another head to the network to compute value functions for states during the finetuning stage. This comment provides explicit guidance on what the authors should consider and how they might improve their draft by adding another head to the network. The action is clear and concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides a specific suggestion for improving the LSTM part of the paper, focusing on the objective for pretraining and finetuning. It suggests that the authors may add another head to the network to compute value functions for states during the finetuning stage. This comment is fully grounded as it explicitly mentions the LSTM part, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear and actionable suggestion for improvement. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, specifically mentioning the probabilities of actions. It proposes that the authors may add another head to the network to compute value functions for states during the finetuning stage. This comment is 4 as it provides a clear and logical suggestion for improvement, aligning with the reasoning and common knowledge that additional heads can be used to compute value functions. However, it could be strengthened by providing more detailed reasoning or examples to fully substantiate the claim. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the LSTM part of the paper, noting that the objective for pretraining and finetuning is the same, specifically mentioning the probabilities of actions. It suggests that the authors may add another head to the network to compute value functions for states during the finetuning stage. This feedback is clear and actionable, offering a concrete improvement that the authors can implement to enhance their draft. By providing a specific suggestion, the comment helps the authors focus on a particular aspect of their work that could be further developed. Therefore, the comment is 5, as it guides the authors towards a meaningful enhancement of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works in the related works section. While the comment implies that the authors should include these older works, it does not provide specific guidance on how to identify or incorporate them. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should acknowledge some of the older works in the related works section, specifically mentioning \"a long line of work that use supervised, multilingual systems.\" However, it does not specify which part of the paper this comment refers to, making it weakly grounded. The comment is specific in its suggestion to acknowledge older works, but without clear references to specific sections or parts of the paper, the authors may find it challenging to understand which sections need attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should acknowledge some of the older works in the related works section, specifically mentioning \"a long line of work that use supervised, multilingual systems.\" However, the comment lacks specific examples or references to these older works, making it difficult for the authors to understand which works should be acknowledged. Without detailed examples or references, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge some of the older works in the related works section, specifically mentioning \"a long line of work that use supervised, multilingual systems.\" This feedback is 3 as it points out a potential area for improvement by suggesting that the authors should include a broader range of related works. However, the comment lacks specificity and does not provide detailed guidance on which older works should be acknowledged or how to integrate them into the paper. This leaves the authors with a general idea but without actionable steps to follow, making the comment 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit, as the authors need to infer that they should investigate the results further or consider alternative sampling strategies. While the suggestion is concrete, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, questioning why linear/exponentialdecay sampling underperforms uniform sampling and suggests an alternative approach based on the authors\" argument about the predictor\"s accuracy on the good subregion. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the results are confusing or that the suggested alternative approach is valid. The lack of evidence or justification makes the claim 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. This feedback is 3 as it identifies a potential area for clarification and suggests an alternative approach that could improve the results. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what steps they should take to improve their draft. The suggestion is 3, but it could be more comprehensive and detailed to fully assist the authors in enhancing their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the SE framework can help improve the paper and requests that the authors provide more detailed explanations of the benefits and mechanisms. It also suggests that the authors consider increasing the rating based on their response. However, the comment does not explicitly instruct the authors to provide specific details or actions to address the question. While the authors can infer that they need to elaborate on the benefits of the SE framework, the action is not concrete and lacks specific guidance on how to improve the paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about how the SE framework can help improve the paper, referencing a similar point in the review. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is weakly grounded as it does not provide explicit references to sections or figures. It is also specific in that it asks for clarification on the benefits and mechanisms of the SE framework, but without grounding, the authors cannot confidently determine which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the SE framework can help improve the paper, referencing a similar point in the review. However, it does not provide any specific reasoning, examples, or references to support the claim that the SE framework can help improve the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how the SE framework can help improve the paper, referencing a similar point in the review. It requests that the authors provide more detailed explanations of the benefits and mechanisms of the SE framework, suggesting that the authors consider increasing the rating based on their response. However, the comment lacks specific guidance or actionable suggestions on how to address the question or improve the paper. While it identifies an area for improvement, it does not provide detailed feedback or examples that would help the authors enhance their work. Therefore, the comment is 2, as it offers a general direction but lacks depth and specificity."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or nonexistent. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics that might be more appropriate. The comment lacks concrete actions or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or nonexistent. However, it does not specify which part of the paper discusses these metrics or the datasets used, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the metrics but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or nonexistent. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the metrics used for evaluating continual learning, specifically noting that these metrics are not suitable for settings where task boundaries are unknown or nonexistent. This critique is valuable as it highlights a potential issue with the evaluation methodology, which could affect the validity of the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or consider alternative metrics. While it points out a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment implies that this issue should be discussed in the paper, but it does not provide explicit guidance on how to address it or what specific aspects of the paper need revision. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the issue of bias in the sketch. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not specify which part of the paper discusses the sketch or the ridge regression problem, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of bias, it lacks grounding as it does not provide clear references to the relevant sections or parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It claims that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It points out that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment suggests that this issue should be discussed in the paper, but it does not provide specific guidance on how to address it or what aspects of the paper need revision. While the feedback highlights a potential weakness, it lacks depth and actionable suggestions, making it 3. The authors are left to infer that they need to discuss the issue of bias in the sketch, but without clear direction, the comment is only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the error analysis on the movie dataset, noting that it is missing. It suggests that the authors should provide details on the cases where the model fails to ensure that other researchers can continue on this task. While the comment identifies a clear action\u2014providing details on model failures\u2014it does not specify how the authors should present this information or what kind of details are necessary. The action is explicit but lacks concrete guidance, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014namely, the details of the cases where the model fails. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any reasoning or evidence to support why this is a significant issue or how it impacts the paper. Without additional context or explanation, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the error analysis on the movie dataset is missing. It highlights the importance of providing details on the cases where the model fails to ensure that other researchers can continue on this task. This feedback is clear and actionable, as it directs the authors to address a critical gap in their analysis. However, the comment could be more helpful if it provided additional guidance on how to present the missing error analysis or suggested specific ways to improve the analysis. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. While the comment implies an action, it does not explicitly instruct the authors to include a detailed plan or specify how to address the limitations. The action is somewhat vague, as it lacks concrete guidance on what constitutes a detailed plan or how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, it does not specify which part of the paper discusses the limitations, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion to provide a detailed plan, but it lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. However, the comment lacks specific details or examples of how this detailed plan might be structured or what actions could be taken. Without additional information or guidance, the authors may find it challenging to understand how to implement this suggestion effectively. Therefore, the comment is considered 2, as it provides some indication of the need for a detailed plan but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests that the authors should provide a more detailed plan on how they plan to address the limitations mentioned in the paper. This feedback is 3 as it identifies a specific area for improvement\u2014addressing the limitations\u2014but lacks depth and specificity. The authors are encouraged to elaborate on the nature of the limitations and how they intend to address them in future work. However, the comment does not provide concrete examples or suggestions for how to develop this detailed plan, which limits its overall impact. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not provide explicit instructions or suggestions on how the authors should conduct this comparison or what specific aspects of the computation should be considered. The action is implicit, as the authors need to infer that they should compare the computational cost, but it lacks concrete guidance on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not specify which part of the paper this comparison should be made or which methods are being referred to. The lack of specific grounding makes it difficult for the authors to identify the exact section or aspect of the paper that needs attention. Additionally, the comment does not provide any guidance on how to conduct the comparison or what specific aspects of the computation should be considered. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. It lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. While it identifies a potential area for further analysis, it does not provide specific guidance or suggestions on how the authors might approach this comparison or what aspects of the computation should be considered. The comment lacks actionable advice, making it 3 as it highlights a potential area for improvement but does not offer detailed guidance on how to address it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should use a generic external knowledge base to avoid issues with points 1 and 2, as demonstrated in Figure 3. However, it does not provide explicit guidance on how to implement this suggestion or clarify what specific issues are being addressed. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply the proposed solution. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests using a generic external knowledge base to avoid issues with points 1 and 2, referencing Figure 3. However, it does not specify which part of the paper these points correspond to, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the solution, the lack of grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the writing is too confusing, making it difficult for the authors to understand if the suggested solution is valid. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the writing, specifically mentioning that points 1 and 2 could be avoided by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment lacks specific guidance on how to improve the writing or address the confusion. While it points out a potential area for improvement, it does not provide actionable steps or suggestions for the authors to take. Therefore, the comment is 2, as it offers a vague observation but no concrete advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the definition of perplexity provided in the paper, stating that it is not accurate and that Equation 1 does not represent perplexity but rather crossentropy. While the comment identifies a specific issue with the definition and provides a clear explanation of the discrepancy, it does not explicitly instruct the authors to revise the definition or Equation 1. The action is implicit, as the authors can infer that they need to correct the definition and potentially update the equation. However, the comment lacks concrete guidance on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment critiques the definition of perplexity provided in the paper, specifically mentioning that it is not accurate and that Equation 1 does not represent perplexity but rather crossentropy. However, the comment does not specify which part of the paper contains the definition or the equation being discussed, making it weakly grounded. The comment is specific in identifying the issue with the definition and the nature of Equation 1, but without explicit references, the authors may find it challenging to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the definition of perplexity on line 259 is incorrect and that Equation 1 does not represent perplexity but rather crossentropy. This claim is supported by logical reasoning, as the reviewer provides a clear explanation of the discrepancy between the definition and the equation. However, the comment lacks specific examples or references to external sources that could further substantiate the claim. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of perplexity in the paper, pointing out that it is not accurate and that Equation 1 does not represent perplexity but rather crossentropy. This feedback is clear and actionable, as it directs the authors to reconsider the definition and potentially update Equation 1. However, the comment could be more helpful if it provided additional guidance on how to revise the definition or Equation 1, such as suggesting alternative ways to calculate or represent perplexity. Despite this, the comment offers valuable insights that can guide the authors in improving their draft, making it 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the model has several components with hyperparameters that are not fully provided, suggesting that the authors may need to trace these parameters in the source code. However, it does not specify which components or hyperparameters are missing, nor does it provide guidance on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to trace the hyperparameters in the source code. Without explicit instructions or concrete steps, the authors cannot effectively apply this feedback to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of missing hyperparameter information for several components, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, requiring the authors to trace them in the source code. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without detailed information or guidance, the claim is not 5, as it does not provide a clear path for the authors to improve their work. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has several components with hyperparameters that are not fully provided. This feedback is clear and actionable, as it highlights a potential area for improvement where the authors may need to trace these hyperparameters in the source code. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific steps the authors could take to ensure the completeness of their work. Despite this, the feedback is 4 as it directs the authors to a critical aspect of their draft that needs attention. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a specific claim made in the paper on line 238, which is that the Central Limit Theorem (CLT) implies that a normally distributed random variable can be produced through a finite linear combination of any random variables. The reviewer points out that this statement is incorrect, as the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. The comment provides a clear and explicit action for the authors to take, which is to correct this specific claim in their paper. It also offers detailed reasoning about why the claim is incorrect, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper (line 238), allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies the incorrect claim made about the Central Limit Theorem (CLT) and provides detailed reasoning about why the claim is incorrect. This feedback is precise and actionable, guiding the authors to correct the specific issue. Therefore, this comment is rated as 5, corresponding to category 5.", "verifiability_rationale": "The review point claims that the authors\" statement on line 238, \"According to the Central Limit Theorem (CLT), a normally distributed random variable can be produced through a finite linear combination of any random variables,\" is incorrect. The reviewer provides specific reasoning, explaining that the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by including examples or references to further substantiate the claim, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific claim made in the paper on line 238, which is that the Central Limit Theorem (CLT) implies that a normally distributed random variable can be produced through a finite linear combination of any random variables. The reviewer points out that this statement is incorrect, as the CLT does not guarantee Gaussianity in a nonasymptotic regime and does not hold for a finite linear combination of arbitrary random variables. This feedback is clear and actionable, providing the authors with a specific area to correct in their draft. By identifying the incorrect claim and offering detailed reasoning, the comment helps the authors improve the accuracy and clarity of their paper. Therefore, the comment is 5, as it provides clear guidance on how to address a specific issue in the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arenabased evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arenabased evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in its critique of the evaluation methods, the lack of grounding makes it challenging for the authors to understand where to address the feedback. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arenabased evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arenabased evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique and how it relates to their work. While the feedback highlights potential issues with the evaluation methods, it lacks actionable guidance on how the authors might address these concerns or improve their draft. Therefore, the comment is 2, as it identifies a potential problem but does not offer clear or detailed suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors should use a better encoder, such as RoBERTabase, instead of BERT to improve the results. While it suggests an alternative model, it does not provide explicit guidance on how to implement this change or what specific improvements might be observed. The action is implicit, as the authors need to infer that they should experiment with a different encoder and analyze the results. However, the comment lacks concrete details on how to conduct this experiment or what specific aspects to focus on. Therefore, the comment is 3, as it provides a direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment questions whether a better encoder, such as RoBERTabase, could improve the results instead of using BERT. However, it does not specify which part of the paper this question pertains to, such as the methodology or experimental setup. Without explicit mention of a section or table, the authors cannot confidently determine where to address this feedback. The comment is specific in its suggestion to use a better encoder, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether a better encoder, such as RoBERTabase, could improve the results instead of using BERT. While it suggests an alternative model, it does not provide any specific reasoning or evidence to support why this might be the case. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about whether using a better encoder, such as RoBERTabase, could potentially improve the results compared to using BERT. This is a valuable suggestion that could guide the authors in exploring alternative models and potentially enhancing the performance of their work. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the results might be affected. While it provides a direction for improvement, it does not offer detailed insights or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for enhancement but does not fully support the authors in making informed decisions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without significantly impacting the performance of predictive models. This provides a clear and explicit action for the authors to take, as they need to show the practical application of their method in achieving fair policy learning while maintaining predictive performance. The comment is specific in its request for demonstration and provides a concrete direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without significantly damaging the predictive model performance. However, it does not specify which part of the paper this demonstration should be included in, making it weakly grounded. The comment is specific in its request for a demonstration, but the lack of grounding makes it difficult for the authors to know exactly where to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without significantly damaging the predictive model performance. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to implement the suggested demonstration. Without additional context or guidance, the claim remains 3, as it lacks the necessary depth and specificity to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors demonstrate how their proposed method can achieve fair policy learning without significantly impacting the predictive model performance. This feedback is actionable and offers a clear direction for the authors to enhance their work. By providing a concrete example of how to implement the suggested demonstration, the comment empowers the authors to address a critical aspect of their research. However, the comment could be more helpful if it included additional guidance or examples to further clarify the implementation process. Overall, the comment is 4, as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to improve clarity. The comment lacks concrete guidance on how to revise the text or what specific parts of the paper need to be revised. As a result, the authors are left without a clear understanding of what actions to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, specifically on line 280. This provides full grounding as the authors can accurately pinpoint the part of the paper being addressed. The comment is also specific because it clearly specifies what is problematic, namely the difficulty in understanding the use of \"to meet\" in the context of \"a response candidate can meet each utterace.\" Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of \"to meet\" in the paper is difficult to understand, specifically mentioning line 280. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. While the comment highlights a potential area for improvement, it lacks actionable guidance or suggestions on how the authors might address this issue. The authors are left without a clear understanding of what changes could be made to improve the clarity of the text. Therefore, the comment is 2, as it points out a problem but does not provide sufficient direction for the authors to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment provides a specific action for the authors to take, indicating that they should adjust the connections in the figure to accurately represent the data. The action is explicit and concrete, as it clearly specifies what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and actionable suggestion for improving the figure by adjusting the connections between the Second Inpainted Images, the Inpainted Image, and the Images Masked by Second Masks. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment is specific and provides a clear suggestion for improvement, but it does not offer any reasoning or evidence to support why this adjustment is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, suggesting that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific direction to improve the accuracy and clarity of their figure. By addressing this suggestion, the authors can enhance the visual representation of their data and ensure that the figure accurately reflects the intended connections. This level of detail and specificity makes the comment 5, as it directly guides the authors in making necessary adjustments to their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This observation is clear and explicit, providing a direct action for the authors to take: they should clarify the differences between the two figures and ensure consistency in their presentation. The comment is specific in its request for clarification and actionable in terms of how the authors can address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the inconsistency in the number of encoderdecoders shown in the two figures. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This observation is factual and descriptive, requiring no additional evidence or reasoning to understand. The comment is a normal statement, as it describes a factual observation without making subjective claims or suggestions. Therefore, it should be labeled as \"No\"", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This observation is clear and actionable, providing the authors with a direct point of comparison and highlighting a potential issue in the presentation of their figures. By pointing out this inconsistency, the comment helps the authors ensure that their figures are consistent and accurately represent their findings. However, the comment could be more helpful if it suggested specific ways to address the inconsistency or how to improve the clarity of the figures. Overall, the comment is 3 as it identifies a clear issue that needs attention, but it lacks depth in terms of actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the unclear main contribution, the overstated novelty claims, and the lack of clarity in how the proposed method handles dynamic largescale multitasking and automation. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should clarify the main contribution, provide evidence for the novelty claims, and explain how the method handles dynamic multitasking and automation. While the authors can infer that they need to address these points, the lack of specific guidance on how to do so makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, noting that it is unclear and that the novelty claims are overstated or not wellsupported. It also points out the lack of clarity in how the proposed method handles dynamic largescale multitasking and automation. However, the comment does not specify which part of the paper discusses the main contribution, making it weakly grounded. It is specific in detailing the issues with the novelty claims and the lack of clarity in the method\"s handling of multitasking and automation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the novelty claims are overstated or not wellsupported. It also notes the lack of clarity in how the proposed method handles dynamic largescale multitasking and automation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique, leading to a score of 1.", "helpfulness_rationale": "The review comment identifies several key areas where the paper could be improved, specifically focusing on the clarity of the main contribution and the novelty claims. It highlights that the paper claims the proposed method possesses 8 novel properties, but these claims are either overstated or not wellsupported. Additionally, the comment points out that the main idea of how the proposed method handles dynamic largescale multitasking and automation is unclear. While the comment provides a clear overview of the issues, it lacks specific suggestions or guidance on how the authors might address these weaknesses. The feedback is 3 as it directs the authors to areas needing clarification, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the computational cost of training 3040 models for burnin, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not provide explicit guidance on how to address the computational cost or how to implement the suggested alternative approach. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the computational cost of training 3040 models for burnin, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not specify which part of the paper this issue relates to, such as a specific section or methodology. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestions, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational cost of training 3040 models for burnin, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is appealing or how it could be implemented. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the computational cost of training 3040 models for burnin, which is not particularly appealing. It suggests an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment lacks specific guidance on how to address the computational cost or how to implement the suggested alternative approach. While it identifies a potential area for improvement, it does not provide actionable feedback or detailed suggestions, making it 3. The authors would need to infer the necessary steps to address the issue, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two specific issues with the experiments: the limited types of teacher architectures and the age of the compared methods. While it identifies these areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand the types of teacher architectures and include more recent methods in their comparisons. This lack of explicit and detailed guidance makes the comment 3, as the authors can deduce the necessary changes but do not have a clear roadmap for implementation. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the experiments, such as the limited types of teacher architectures and the age of the compared methods, providing clear guidance on what needs to be addressed. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are not sufficient enough, specifically noting the limited types of teacher architectures and the age of the compared methods. While the comment identifies these issues, it lacks detailed reasoning or references to support why these limitations are significant or how they impact the paper\"s conclusions. The authors are left to infer the importance of these points, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the experiments: the limited types of teacher architectures and the age of the compared methods. It provides specific feedback by suggesting that the authors should include more diverse teacher architectures and compare their methods with more recent studies. This feedback is actionable and constructive, as it guides the authors on what aspects of their experiments need to be expanded or revised to enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it offered additional suggestions or guidance on how to address these issues. Overall, the comment is 4, as it provides clear directions for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. While the comment identifies a potential issue with the comparability of the results, it does not explicitly instruct the authors to address this concern or provide guidance on how to ensure fair comparisons. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the data usage in their comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons in Table 2, particularly regarding the use of different amounts of data in the comparisons. The authors are informed about the specific comparisons that use less data, such as H>N and H>B compared to H>N+B, and H>N>H compared to H>N+B>H. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B compared to H>N+B, and H>N>H compared to H>N+B>H. However, the comment does not offer any justification or reasoning for why this comparability issue is a concern or how it might affect the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B compared to H>N+B, and H>N>H compared to H>N+B>H. This feedback is clear and actionable, as it highlights a specific area where the authors need to ensure fair comparisons. However, the comment could be more helpful if it suggested ways to address this issue, such as standardizing the data usage or providing a rationale for the variations. Overall, the comment is 4 as it points out a critical issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the paper, noting that the use of known causal relationships might not be feasible in practice due to the unavailability or inaccuracy of prior knowledge. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or improve the practicality of their work. The action is implicit and vague, as the authors are left without a clear understanding of what steps they should take to address the concern. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique, it lacks grounding as it does not provide clear references or sections for the authors to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practicality of the paper, specifically questioning the use of known causal relationships due to the unavailability or inaccuracy of prior knowledge. This is a valid point that highlights a potential limitation of the proposed approach. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve the practicality of their work. While it identifies a concern, it does not provide any specific steps or insights for the authors to consider, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the figures and empirical results, such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the figures and empirical results. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses issues with the figures and empirical results, specifically mentioning the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the problems with the empirical results, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of polishing of figures and empirical results, which impedes clarity and confidence in the empirical findings. It provides specific examples such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. These examples offer some level of support for the claim, but the comment could be more detailed by providing references or specific guidance on how to improve the figures and empirical results. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically focusing on the figures and empirical results. It highlights issues such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. These observations provide the authors with specific feedback on what needs to be addressed to enhance the clarity and confidence in their empirical findings. However, the comment could be more helpful if it offered suggestions on how to improve the figures or empirical results, such as providing guidance on how to ensure proper labeling or how to conduct more comprehensive experiments. Overall, the comment is 3 as it points out areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific area in the paper, Section 4.3, where the authors should include comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is explicit and provides a clear action for the authors to take, namely to add these experiments to better showcase the unique advantages or potential shortcomings of the proposed method. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests a specific area for improvement, but it does not provide detailed reasoning or examples to support why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the need for such comparisons to fully understand the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where additional comparative experiments are needed to better showcase the advantages or potential shortcomings of the proposed method. By suggesting the inclusion of experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2, the comment provides a clear and actionable direction for the authors to improve their draft. This feedback is 4 as it offers a specific and constructive suggestion that could significantly enhance the paper\"s impact and comprehensiveness. However, it could be more helpful if it included more detailed reasoning or examples of how these experiments would be conducted or what specific insights they might provide. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the discussion around equation (10) is terse and not clearly explained. While it suggests that the authors should improve the clarity of this discussion, it does not provide specific guidance on how to achieve this. The action is implicit, as the authors need to infer that they should enhance the explanation of the discussion around equation (10). However, the comment lacks concrete details on what aspects of the discussion need to be clarified or expanded. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out that the discussion around this equation is terse and not wellexplained, providing a clear indication of what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion around equation (10) is terse and not clearly explained. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion around equation (10), noting that it is terse and not clearly explained. This feedback is actionable as it provides a clear area for improvement, suggesting that the authors should enhance the clarity and depth of their discussion. However, the comment lacks specific guidance on how to improve the explanation or what aspects of the discussion need clarification. While it offers a valuable suggestion, it could be more helpful if it provided more detailed guidance or examples of how to improve the explanation. Therefore, the comment is 4, as it directs the authors to an area of improvement but does not fully address the need for actionable feedback."}
