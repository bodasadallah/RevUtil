{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap. The comment lacks guidance on what specific aspects of the theory should be investigated or how the convergence properties could be demonstrated. Without concrete actions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a gap in the paper by noting that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, it does not specify which part of the paper this issue is related to, such as a particular section or discussion. This lack of grounding makes it difficult for the authors to pinpoint where the issue lies and how to address it. The comment is specific in identifying the need to explore theoretical properties and convergence, but it is 1 because it does not provide explicit references or sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not explore the theoretical properties of the proposed algorithm, specifically its convergence. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not explore the theoretical properties of the proposed algorithm, specifically its convergence. This is a crucial aspect that could enhance the depth and rigor of the paper. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as suggesting particular theoretical frameworks or methods to analyze convergence. While it highlights an important area for improvement, the absence of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the description of HIERENC, suggesting that the current explanation is unclear and that the method of averaging representations from all possible entity instantiations might introduce noise. However, the comment does not provide explicit guidance on how the authors should revise the description or address the issue of noise. While it identifies a problem, it lacks concrete steps or suggestions for improvement, making it 3.", "grounding_specificity_rationale": "The comment addresses the description of HIERENC, which is a specific part of the paper. It provides a detailed explanation of how the input (h_i) is derived, suggesting that averaging representations from all possible entity instantiations might introduce noise. This allows the authors to accurately identify the section being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies the issue with the description of HIERENC and suggests a potential problem with the method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the description of HIERENC is unclear and suggests that averaging representations from all possible entity instantiations might introduce noise. While the reviewer provides a logical explanation for why this approach could be problematic, the comment lacks specific examples or references to support the claim. The reasoning is present but could be strengthened with more detailed evidence or examples. Therefore, the comment is 4, as it provides a basis for understanding the issue but could benefit from additional support.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of HIERENC, noting that the method of averaging representations from all possible entity instantiations might introduce noise. This feedback is clear and actionable, as it points out a potential problem with the methodology and suggests that only one instantiation is likely correct. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or alternative approaches they could consider. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this selection affects the underestimation of performances. While it prompts the authors to consider the reason for this selection, it does not provide explicit guidance on how to address this issue or what actions should be taken. The action is implicit, as the authors need to infer that they should explain the rationale and discuss the potential impact on performance estimation. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in questioning the rationale and its potential impact, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this affects the underestimation of performances. However, it does not provide any specific reasoning, examples, or references to support the claim that this selection might lead to an underestimation of performances. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this selection might affect the underestimation of performances. While it identifies a potential issue in the methodology, it does not provide any suggestions or guidance on how to address this concern. The comment lacks actionable advice or detailed explanations, making it 3 as it highlights a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors may have selected sentences from raw data sources, which contradicts the claim that the data already contains syntactic information. It implies that the data selected is a subset of Li et al. (2019a)\u2019s dataset. The comment provides a clear action for the authors to take, which is to revise the description to clarify and make it precise. This explicit instruction makes the action clear and concrete, allowing the authors to understand exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (226238 and 242244), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the discrepancy in the description of the data selection process and the suggestion to revise the description to mention Li et al. (2019a) earlier. This provides clear guidance on how to improve the clarity and precision of the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors may have selected sentences from raw data sources, which contradicts the claim that the data already contains syntactic information. It suggests that the data selected is a subset of Li et al. (2019a)\u2019s dataset and recommends revising the description to clarify this. The comment provides a logical reasoning by pointing out the inconsistency in the description of the data selection process. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the description of the data selection process, specifically regarding the use of raw data versus the presence of syntactic information. It suggests that the data selected might be a subset of Li et al. (2019a)\u2019s dataset, which could be clarified by mentioning Li et al. (2019a) earlier in the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and precision of their description. However, the comment could be more helpful if it included additional suggestions or examples to further enhance the authors\" understanding. Overall, the comment is 4, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit, as the authors need to infer that they should provide a clearer explanation of the average duration and its components. However, the lack of concrete instructions on how to implement this suggestion makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. While it is specific in questioning the purpose and components of the average duration, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the purpose of the average duration reported in Table 1 and notes the absence of a supporting explanation. It also asks whether the average duration includes time spent by the user waiting for the model to generate a response. This comment is 4 as it identifies a specific issue in the paper, but it lacks detailed reasoning or references to support the claim. The authors would need to provide additional context or justification to fully address the concern. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the lack of explanation for the purpose of the average duration reported in Table 1. It also raises a question about whether the average duration includes time spent by the user waiting for the model to generate a response. This feedback is clear and actionable, as it prompts the authors to provide a more detailed explanation of the average duration and its components. By addressing this issue, the authors can improve the clarity and completeness of their paper. However, the comment could be more helpful if it suggested specific ways to clarify the purpose or components of the average duration. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these interpretations or what changes might be necessary. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the results in Table 3 are discussed, making it difficult for the authors to identify the relevant section. Additionally, the comment is not specific because it does not provide detailed guidance on how to interpret the results or what actions should be taken. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely descriptive and does not offer any guidance or reasoning to support the interpretation of the results. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison of Chinese MOSQ and Baseline with NVSB and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOSV. However, it does not provide any suggestions or guidance on how the authors might address these interpretations or what changes could be made to improve the clarity or robustness of the results. Without actionable feedback or specific suggestions, the comment is not helpful to the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any explicit or implicit suggestions on how to address this issue, such as recommending a consistent formatting approach or providing guidance on why the inconsistency is problematic. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2 and Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistency in the presentation of data, noting that some items have spaces between accuracy and standard deviation while others do not, which affects the visual appeal and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting that some items have spaces between accuracy and standard deviation while others do not. This inconsistency affects the visual appeal and readability of the tables. However, the comment does not provide any specific reasoning, examples, or references to support why this inconsistency is problematic or how it impacts the overall quality of the paper. Without additional context or justification, the authors may find it challenging to understand the significance of the comment and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of data in Table 2 and Table 3, noting inconsistencies in the formatting of accuracy and standard deviation values. This observation is clear and actionable, as it highlights a potential issue with the visual appeal and readability of the tables. However, the comment does not provide any suggestions or guidance on how to address this inconsistency, such as recommending a consistent formatting approach or explaining why the inconsistency is problematic. While the feedback is 3 in pointing out a potential issue, it lacks depth and actionable advice, making it 3 rather than fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. The comment is explicit in pointing out the missing antecedent and provides concrete guidance on how to address the issue by checking the references for specific formatting details. This allows the authors to directly apply the feedback and improve the formatting of their references. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section of the paper where the issue is located, specifically \"both tasks\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on what needs to be done, namely checking the references for format, capitalization, and bibliographic details. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. While the comment provides a clear instruction for improvement, it lacks specific examples or references to support the claim that the references are missing or need correction. This makes the claim 3, as the authors can infer the need for correction but may require additional guidance to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of references, noting that the antecedent \"both tasks\" is missing and suggesting that the references should be checked for format, such as capitalization and bibliographic details. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the formatting of their references. By addressing this issue, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it provided additional guidance on how to check the references or examples of correct formatting. Overall, the comment is 4 as it offers a clear direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the explanations for lexical features and sentencelevel features in Section 3.2 are somewhat intertwined and confusing. It provides a clear action for improvement: organizing the section with separate paragraphs for each type of feature. This action is concrete and specific, as it directs the authors to reorganize the section in a way that enhances clarity. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the organization of the section by suggesting separate paragraphs for lexical and sentencelevel features. This level of detail helps the authors understand exactly what needs to be done to enhance the clarity of the section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the explanations for features in Section 3.2 are somewhat intertwined and confusing, implying that the section could be more coherently organized. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the confusion or how to address it. Without detailed reasoning or examples, the claim is 3, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of explanations in Section 3.2, noting that the features are somewhat intertwined and confusing. It provides a clear suggestion for improvement by recommending a more organized structure with separate paragraphs for lexical and sentencelevel features. This feedback is actionable and constructive, as it directly addresses a potential weakness in the paper and offers a concrete way to enhance clarity. However, the comment could be more helpful if it included additional suggestions or examples of how to improve the organization. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the comparison of the proposed models with models that consider different senses but not sememes, specifically mentioning the MST baseline as an example. It suggests that the paper would be stronger with the inclusion of more baselines based on related work. However, the comment does not provide explicit guidance on how to address this issue or what specific comparisons should be made. The action is implicit, as the authors need to infer that they should compare their models with those that consider different senses but not sememes and include more baselines. The lack of concrete instructions makes the action somewhat vague, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"It is unclear how the proposed models compare to models that only consider different senses but not sememes,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the comparison with models that consider different senses but not sememes and suggesting the inclusion of more baselines based on related work. This provides clear guidance on what aspects of the paper require attention, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point raises a question about the comparison of the proposed models with models that consider different senses but not sememes, specifically mentioning the MST baseline as an example. It suggests that the paper would be stronger with the inclusion of more baselines based on related work. However, the comment lacks specific examples or detailed reasoning to support the claim that the MST baseline is an example of a model that only considers different senses but not sememes. Without this clarification, the authors may find it challenging to understand the basis of the suggestion. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison of the proposed models with those that consider different senses but not sememes. It questions the relevance of the MST baseline as an example of such a model and suggests that the paper would be stronger with the inclusion of more baselines based on related work. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by expanding the comparison and including additional baselines. However, the comment could be more helpful if it provided more detailed guidance on which specific baselines to include or how to conduct the comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific suggestions or actions that the authors can take to clarify or improve their methodology. As a result, the authors are left without a clear understanding of what steps to take to resolve this ambiguity. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not specify which part of the paper this issue is discussed in. Without knowing the context or location of the discussion, the authors cannot confidently identify the section that needs attention. Additionally, the comment lacks specificity in addressing what aspects of the selection process are unclear, such as the criteria or methods used. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the selection process of frame similarity factors and attributes similarity factors, but it does not provide any specific reasoning, examples, or references to support why this is unclear. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential ambiguity in the selection process of frame similarity factors and attributes similarity factors, which could hinder the clarity and reproducibility of the methodology. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue. While it highlights an area for improvement, it lacks actionable advice or detailed insights that would help the authors clarify their methodology. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of the results. However, the comment does not provide explicit guidance on what specific aspects of the convergence process need to be discussed or how to address the difficulty in understanding the stable points. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the convergence discussion. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include discussions on convergence and stable points, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper that needs improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of the results. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such discussions are necessary. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that additional discussions on the convergence of the proposed joint learning process, particularly in the context of probabilistic metric spaces and stable points, would enhance the clarity and understanding of the paper. It highlights a concern that readers may find it challenging to understand how stable points are obtained, which could hinder the reproducibility of the results. However, the comment does not provide specific guidance on what aspects of the convergence process need to be discussed or how to address the difficulty in understanding the stable points. While it points out a potential weakness, it lacks detailed suggestions or examples, making it 3. The authors would benefit from additional guidance on how to expand the discussion on convergence to improve the paper\u2019s clarity and reproducibility."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific instructions for the authors to address certain aspects of their draft. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using consistent terminology for the model in Tables 1 and 2. The comment also questions why the term \"latent in verbs\" is not mentioned. These instructions are explicit and provide clear guidance on what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. However, the comment does not explicitly mention which part of the paper these instructions refer to, making it weakly grounded. The instructions are specific in detailing what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point provides specific instructions for the authors to address certain aspects of their draft, such as discussing results for the task of inferring knowledge on objects and including results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2 and questions why the term \"latent in verbs\" is not mentioned. However, the comment lacks detailed reasoning or references to support why these changes are necessary or beneficial. The instructions are 3 as they provide a clear direction for improvement, but the absence of specific justification or examples makes it challenging for the authors to fully understand the reasoning behind the suggestions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on areas where the authors could improve their draft. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B), which are important aspects of the paper. Additionally, it suggests using consistent terminology for the model in Tables 1 and 2, which is a practical and helpful suggestion. The comment also questions why the term \"latent in verbs\" is not mentioned, prompting the authors to consider this aspect. Overall, the feedback is clear and provides valuable guidance for the authors to enhance their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. While the comment implies that the authors should consider adding these baselines, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they need to add baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its suggestion to include additional baselines, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. However, the comment does not provide any specific reasoning or evidence to support this claim. It lacks detailed explanations or references to existing literature that could substantiate the assertion about the straightforward nature of the extension or the need for additional baselines. Without this additional context, the claim remains 1, as the authors are left to question the validity of the assertion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the paper is a straightforward extension of existing retrofitting work and recommends including additional baselines, such as character embeddings. This feedback is 3 as it identifies a potential area for improvement by suggesting the inclusion of more diverse baselines. However, the comment lacks specificity in terms of which baselines should be included or how they might impact the results. It does not provide detailed guidance or examples, which could make it more actionable for the authors. While it offers a direction for improvement, the comment could be more helpful if it provided more specific suggestions or examples of how to implement the recommendation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the paper\"s reliance on supplemental space, suggesting that the paper is not truly independent due to references to supplemental figures and model comparisons. However, it does not provide explicit instructions or suggestions on how the authors should address this issue. The comment implies that the authors should consider making the paper more selfcontained, but it lacks concrete guidance on how to achieve this. As a result, the authors are left without a clear understanding of what steps to take to improve the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"supplemental space\" and \"supplemental figures,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the paper is not truly independent due to references to supplemental figures and model comparisons, particularly noting the issue with S3.1 reference to Sup. Fig. 6 and the model comparison and span vs. sentence investigation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper relies on supplemental space, making it not truly independent, and provides specific references to the supplemental figures (S3.1 and Sup. Fig. 6) and model comparisons. However, the comment lacks detailed reasoning or examples to fully substantiate the claim. While it identifies a potential issue, it does not provide a comprehensive explanation or evidence to support the assertion that the paper is not truly independent due to its reliance on supplemental space. Therefore, the claim is 3, as it is partially supported but lacks sufficient detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s reliance on supplemental space, noting that the paper is not truly independent due to references to supplemental figures and model comparisons. This feedback is clear and actionable, as it highlights a potential problem with the paper\"s selfcontainment. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as integrating key information from the supplemental material into the main text or providing a more detailed explanation of the supplemental content. Without specific guidance, the authors may find it challenging to fully address the concern. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies the main weaknesses of the paper as the experiments, specifically noting that they are only conducted in an extremely lowresource regime and for a sentence classification task, which are not representative of realworld applications. The reviewer suggests that the proposed augmentation method has potential for use in more NLP tasks but does not provide explicit guidance on how to address these issues or improve the draft. While the comment highlights areas for improvement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides some direction but does not fully guide the authors on how to address the identified weaknesses.", "grounding_specificity_rationale": "The comment addresses the main weaknesses of the paper, specifically focusing on the experiments conducted in an extremely lowresource regime and for sentence classification tasks. It suggests that the proposed augmentation method has potential for use in more NLP tasks but does not provide specific examples or detailed guidance on how to address these issues. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, and it is specific in identifying the areas where improvements could be made. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the experiments conducted in the paper, specifically noting that they are limited to an extremely lowresource regime and focus on sentence classification, which may not represent realworld applications. The reviewer suggests that the proposed augmentation method could be more broadly applicable to other NLP tasks. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is 3 as it provides a general direction but lacks detailed justification or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies the main weaknesses of the paper, specifically focusing on the experiments conducted in an extremely lowresource regime and for sentence classification tasks. It suggests that the proposed augmentation method has potential for use in more NLP tasks, which is a valuable insight for the authors to consider. However, the comment lacks specific guidance on how to address these weaknesses or improve the draft. While it provides a clear direction for the authors to consider, it does not offer detailed suggestions or actionable steps to enhance the paper\"s impact. Therefore, the comment is 3, as it provides some insights but could be more comprehensive and detailed to fully assist the authors in improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should provide more details about the traits of the experts involved in the annotation process and justify why expert annotation is necessary, beyond its commercial value. It also asks for clarification on whether the experts are linguistic or domain experts, and whether the annotation process differs from what nonexperts would do. This feedback is explicit and provides clear guidance on what additional information and justification the authors should include in their draft. The comment is specific and actionable, as it directly instructs the authors on what needs to be addressed to improve the clarity and robustness of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions and suggestions about the traits of the experts involved in the annotation process, the justification for expert annotation, and the differences between expert and nonexpert annotation. This level of detail helps the authors understand exactly what aspects need to be clarified or expanded upon. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the traits of the experts involved in the annotation process and the justification for expert annotation. It asks for clarification on whether the experts are linguistic or domain experts and whether the annotation process differs from what nonexperts would do. These questions are logical and require the authors to provide detailed information to address them. However, the comment does not provide specific examples or references to support the need for this clarification, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific questions and suggestions for the authors to address regarding the traits of the experts involved in the annotation process and the justification for expert annotation. It asks for clarification on whether the experts are linguistic or domain experts, whether the annotation process differs from what nonexperts would do, and whether it introduces any linguistic challenges. These questions are actionable and provide clear guidance on what additional information the authors should include to enhance the clarity and robustness of their work. By addressing these points, the authors can improve the transparency and rigor of their methodology, making the comment 5. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would benefit from including examples of the system applied to actual texts, as opposed to other components or models. While the comment implies that this would be helpful, it does not explicitly instruct the authors to add such examples or specify how to do so. The action is implicit and somewhat vague, as the authors are left to infer that adding examples would improve the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including examples of the system on actual texts, which implies a specific part of the paper where such examples would be beneficial. However, it does not explicitly mention a particular section, table, or figure, making it weakly grounded. The comment is specific in its suggestion to include examples, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from including examples of the system on actual texts, which implies that the current draft lacks such examples. However, the comment does not provide any specific reasoning or evidence to support this claim, such as explaining why these examples are important or how they would enhance the paper. Without additional context or justification, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from including examples of the system applied to actual texts, which could enhance the understanding and impact of the work. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these examples or what aspects of the system should be illustrated. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more actionable if it included suggestions for specific examples or sections where these examples would be most relevant. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper raises two hypotheses about multilinguality and country/languagespecific bias, but it does not mention these hypotheses again in the draft. The reviewer suggests that the paper should either test these hypotheses as given or explore them in more depth. However, the comment does not provide explicit guidance on how to test the hypotheses or how to delve deeper into them. The action is implicit and vague, as the authors are left to infer that they need to address the lack of testing or deeper exploration of the hypotheses. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper by referencing specific lines (078086) where two hypotheses are raised. This provides full grounding as the authors can accurately identify the part of the paper being discussed. The comment is also specific because it clearly specifies that the paper does not actually study these hypotheses, nor are they mentioned or discussed again. This feedback is clear and actionable, as it directs the authors to address the lack of study and discussion of the hypotheses. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not study the hypotheses mentioned in lines 078086, nor does it discuss them again. This claim is 3 as it highlights a gap in the paper\"s content, but it lacks specific examples or references to support the assertion that the hypotheses are not studied or discussed. The authors would need to provide more detailed evidence to fully substantiate this claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper by pointing out that it raises two hypotheses about multilinguality and country/languagespecific bias, but these hypotheses are not actually studied or discussed in the draft. The reviewer suggests that the paper should either test these hypotheses as given or explore them in more depth. This feedback is clear and actionable, as it provides a specific direction for the authors to improve the depth and rigor of their analysis. However, the comment could be more helpful if it offered additional guidance on how to test or explore the hypotheses, such as suggesting specific methods or analyses. Overall, the comment is 4, as it highlights a critical gap in the paper\"s content and provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper. It asks whether the CS is used for evaluation purposes and also for augmenting the training material. The comment implies that the authors should clarify how the CS is used and what data split is employed. However, it does not provide explicit instructions or detailed guidance on how to address these questions or improve the clarity of the paper. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not specify which part of the paper discusses the CS or the data split, making it difficult for the authors to pinpoint the exact sections that need clarification. While the questions are specific about the content being addressed, the lack of explicit grounding makes it challenging for the authors to fully understand the scope of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not provide any evidence, reasoning, or references to support these questions or claims. The questions are based on the authors\" own understanding, which may not be accurate, and without further clarification or justification, the authors may find it difficult to address these points effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. While the comment identifies an area that needs clarification, it does not provide specific guidance or suggestions on how to improve the clarity or address the questions. The feedback is 3 as it points out a potential area of confusion for the authors, but it lacks depth and actionable advice, making it difficult for the authors to fully address the issue. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the performance of nouns compared to clustering approaches, noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific analyses or improvements to address the performance discrepancy or the contradiction. The authors are left without clear guidance on how to address these issues, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance of nouns and clustering approaches, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the higher oracle GAP for PPDBClus compared to most clustering approaches and the contradiction with the claim of generalizability to all parts of speech. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment lacks specific examples or references to support the claim that the performance is indeed higher or that the contradiction is significant. Without detailed evidence or examples, the claim remains 3, as the authors may need to seek additional information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. This feedback is 3 as it identifies a potential issue with the clustering approach\"s generalizability and highlights an area that needs further investigation or clarification. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this performance discrepancy or the contradiction. Overall, the comment offers some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion in section 5.2 is abstract and lacks clarity, making it difficult for the authors to understand why the new model is better than MH. It suggests providing examples of spurious structures to clarify the discussion. However, the comment does not explicitly instruct the authors to provide these examples or how to incorporate them into the discussion. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies a lack of clarity in the discussion regarding the abstract nature of the insights and suggests providing examples of spurious structures to clarify the comparison between the new model and MH. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the abstract nature of the discussion in section 5.2 and suggests providing examples of spurious structures to clarify the comparison between the new model and MH. However, the comment does not offer any specific reasoning, references, or examples to support why the discussion is abstract or how providing examples would clarify the comparison. Without additional context or justification, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern in the paper, noting that the discussion in section 5.2 is abstract and lacks clarity, making it difficult for the authors to understand why the new model is better than MH. The comment suggests providing examples of spurious structures to clarify the discussion. This feedback is clear and actionable, as it directs the authors to a specific section and suggests a concrete way to improve the clarity of their discussion. However, the comment could be more helpful if it provided additional guidance on how to choose or create these examples effectively. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a clear and explicit action that the authors can readily follow. The comment provides a specific and concrete instruction on what needs to be done to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests including the hard prompt baseline in Table 1 to see the performance increase of each method. However, it does not specify which part of the paper Table 1 is located in, nor does it provide any guidance on how to implement this suggestion. The authors would need to infer that the comment pertains to the results section or a table that presents performance data. Therefore, the comment is weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific because it lacks details on how to incorporate the hard prompt baseline. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a suggestion for improvement, but it lacks specific reasoning or examples to support why this addition would be beneficial. Without additional context or justification, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient evidence or explanation to fully support it.", "helpfulness_rationale": "The review comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a specific and actionable suggestion that could enhance the clarity and comprehensiveness of the results presented in the paper. By adding the hard prompt baseline, the authors can better demonstrate the effectiveness of their methods and provide a more robust comparison. This feedback is clear and constructive, offering a direct way for the authors to improve their draft. Therefore, the comment is rated as 4, as it provides a clear and actionable suggestion that would benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of numerical results in the paper, specifically questioning how the proposed method can be applied to popular algorithms and how its performance compares to existing DP algorithms. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include numerical results and conduct comparisons with existing algorithms. However, the action is implicit and somewhat vague, as it does not specify which algorithms to use or how to perform the comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of numerical results and questions the application of the proposed method to popular algorithms, specifically comparing its performance with existing DP algorithms. However, it does not specify which algorithms are being referred to or provide any details about the numerical results. The authors cannot confidently determine which part of the paper this comment addresses, as it is not explicitly linked to a section or figure. The comment is specific in its request for numerical results and comparisons, but it lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks numerical results and questions how the proposed method can be applied to popular algorithms and compared with existing DP algorithms. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left to infer the validity of the claim, making it difficult to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of numerical results and the absence of comparisons with existing DP algorithms. This feedback is valuable as it highlights a critical area where the authors can enhance the paper by providing empirical evidence and demonstrating the practical applicability of their method. However, the comment could be more helpful if it suggested specific algorithms or methods for comparison or provided guidance on how to conduct these comparisons. Despite this, the feedback is 4 as it directs the authors to an important aspect of their work that needs further development."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experimental comparisons are not sufficient and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so or provide detailed guidance on how to implement these tests. The action is implicit and somewhat vague, as the authors need to infer that they should perform these additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental comparisons are not enough and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, it does not specify which part of the paper these comparisons are made or which sections of the paper need to be revised. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the need for additional experiments, it lacks specificity in terms of how these experiments should be conducted or what results are expected. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experimental comparisons are not enough and suggests testing the proposed method, InvP, with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). However, the comment lacks specific reasoning or examples to support this claim. It does not provide a clear rationale for why these additional comparisons are necessary or how they would enhance the paper\"s contribution. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental comparisons by suggesting that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2\u00d7) and ResNet50 (4\u00d7). This feedback is 3 as it points out an area for improvement in the experimental setup, which could enhance the robustness and comprehensiveness of the results. However, the comment lacks depth and does not provide specific guidance on how to conduct these additional experiments or what results to expect. While it offers a direction for improvement, it does not fully address the authors\" needs for a more thorough evaluation. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for correcting the placement of a callout in Table 5 to Table 3 and for improving the clarity of the callout in Figure 6. These actions are concrete and specific, allowing the authors to directly apply the corrections. The comment is clear and detailed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout in Figure 6, indicating that the authors need to ensure the callout is directing properly. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point consists of factual corrections regarding the placement of callouts in tables and figures. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the placement of callouts in tables and figures, which is a clear and direct way to improve the clarity and accuracy of the paper. By specifying the exact tables and figures that need correction, the authors can easily address these issues. This level of detail and specificity makes the comment 5, as it directly guides the authors in enhancing the presentation of their work. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the experiments in the paper, specifically noting that the paper only reports selfcomparisons and lacks explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. While the comment identifies a specific issue and provides a suggestion for improvement, it does not explicitly instruct the authors to address the lack of explanation for the selfcomparisons or to include comparisons with SketchRNN. The action is implicit and somewhat vague, as the authors need to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section of the paper, specifically mentioning the issue of only reporting selfcomparisons and the lack of explanation for this choice. It also suggests that comparisons with SketchRNN could be performed. However, the comment does not specify which part of the experiments section this issue is discussed, making it weakly grounded. The comment is specific in identifying the problem with the experiments and suggesting an improvement, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only reports selfcomparisons and lacks explanation for this choice, which adds to the poor motivation problem. It suggests that comparisons with SketchRNN could be performed. However, the comment does not provide specific examples or references to support the claim about the lack of explanation or the suggestion to include comparisons with SketchRNN. This makes the claim 3, as it lacks detailed reasoning or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the experiments section of the paper, specifically noting that the paper only reports selfcomparisons and lacks explanation for this choice. This observation highlights a potential weakness in the motivation and depth of the experimental analysis. The comment also suggests that comparisons with SketchRNN could be performed, which provides a concrete direction for improvement. While the comment is clear and identifies a specific area for enhancement, it could be more helpful if it provided additional guidance on how to conduct these comparisons or why SketchRNN is a relevant baseline. However, the feedback is 4 as it directs the authors to address a critical issue in their experimental design. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not provide explicit guidance on what needs to be addressed in those areas or how the authors should improve the clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the confusing parts mentioned in point 3. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not specify which part of the paper these areas of confusion are located in, making it difficult for the authors to pinpoint the exact issues. The comment is weakly grounded because it does not provide explicit references to sections or figures, but it is specific in identifying the need for clarification in certain parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges that the paper is not difficult to follow but identifies several places that may cause confusion, referring to \"point 3.\" However, it does not provide any specific examples or detailed reasoning to support the claim that these areas are indeed confusing. Without concrete examples or references, the authors are left to interpret the comment, making it difficult to understand the specific issues that need addressing. Therefore, the comment is barely verifiable, as it lacks sufficient evidence to support the claim.", "helpfulness_rationale": "The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not provide any detailed feedback or suggestions on how to address these areas of confusion. The comment lacks actionable guidance, leaving the authors without a clear understanding of what needs to be improved. As a result, the feedback is 2, as it does not offer any concrete steps or insights for the authors to enhance their draft. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it contradicts itself by stating that this is false and providing references. While the comment suggests that the authors should acknowledge the existence of such tools, it does not explicitly instruct them to add or discuss these tools in their paper. The action is implicit, as the authors can infer that they need to address the lack of tools, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the reinforcement learning setting, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it claims that there is no corresponding set of tools for this setting, which is a clear and actionable point for the authors to address. The comment provides a specific issue and suggests that the authors should acknowledge the existence of such tools, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that there is no corresponding set of tools for the reinforcement learning setting, but it contradicts itself by stating that this is false and providing references. While the comment acknowledges the existence of such tools, it does not provide specific examples or detailed reasoning to support the claim. The lack of detailed references or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is 3, as it provides some justification but lacks depth and specificity.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the absence of corresponding tools for the reinforcement learning setting. It acknowledges that the claim is false and provides references to support this assertion. While the comment is clear in identifying a gap in the paper, it does not offer specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it highlights an area for improvement, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency to understand. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the results need clarification. The comment implies that the authors should consider making the results more accessible or providing additional context to enhance understanding. While the action is somewhat inferred, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results being based on \"standard\" techniques, which allows the authors to accurately identify the part of the paper being addressed. It also specifies that the results are not obvious a priori and require a degree of technical competency, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results, while based on \"standard\" techniques, are not obvious a priori and require a fair degree of technical competency to understand. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the assertion. Without detailed evidence or examples, the claim remains 3, as it lacks sufficient justification to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the results, noting that they are based on \"standard\" techniques but are not immediately obvious or accessible to a broader audience. This feedback highlights a gap in the clarity or presentation of the results, suggesting that the authors may need to provide additional context or explanation to make the results more understandable. While the comment points out a specific area for improvement, it does not offer detailed guidance on how to address the issue or what specific aspects of the results need clarification. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and actionable suggestions. The authors would need to infer how to enhance the clarity of their results, which limits the comment\"s helpfulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the conclusion that the direct model is clearly the better of the two, given the significant difference in the amount of data used for training. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the impact of data quantity on model performance, but it does not offer specific guidance on how to conduct further analysis or experiments to support their claims. Without concrete steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of data usage in training two different models, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or figure the comment refers to, making it weakly grounded. However, the comment is specific in detailing the concern about the difference in data usage and its impact on the conclusion regarding the models. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the conclusion regarding the performance of two proposed systems based on the amount of data used for training. It suggests that the difference in data usage might impact the conclusion that the direct model is clearly the better of the two. However, the comment does not provide specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the potential impact of the amount of data used to train the text disambiguation model on the conclusion that the direct model is clearly the better of the two. It highlights a discrepancy between the data used for training the two systems and questions whether the conclusion is robust given the small difference in data usage. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their analysis. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to conduct further analysis or experiments to fully address the concern, which limits the comment\"s helpfulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, specifically regarding the recovery of updated parameters from projected gradients. While the comment identifies these areas, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are left to infer that they need to provide a clearer motivation for GaRare and a more detailed explanation of the algorithmic process. This lack of explicit action makes the comment 3, as it provides a general direction but lacks specific details on how to implement the changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. However, it does not specify which part of the paper discusses GaRare or the algorithmic process, making it weakly grounded. The comment is specific in detailing the issues that need to be addressed, such as the motivation for GaRare and the need for a more detailed algorithmic presentation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clear motivation for GaRare and does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes the claim 3, as the authors would need to provide additional information to address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that require attention, but it lacks depth and actionable advice, leaving the authors with a general idea of what needs to be improved rather than detailed steps to follow. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. While the comment provides a clear action\u2014conducting an ablation study\u2014it does not specify how to implement this action or what data to use for the study. The suggestion is somewhat vague, as it lacks detailed guidance on the methodology or expected results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. However, the comment does not specify which part of the paper discusses the visDial dataset or the proposed model, making it difficult for the authors to identify the exact section or figure being referenced. While the comment is specific about the experiment of interest, the lack of grounding makes it challenging for the authors to understand the context and relevance of the suggestion. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. However, the comment lacks detailed reasoning or references to support the claim that this ablation study would provide additional validation. It does not provide specific examples or evidence to justify why this experiment is crucial or how it would enhance the model\"s performance. As a result, the claim is 3, as it lacks sufficient support for the authors to fully understand and address the suggestion.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It specifically mentions one experiment of interest, ATT(+H), and asks for the performance of the model if it did not consider relevant attention retrieval from the attention memory. This feedback is 3 as it identifies a potential area for improvement and provides a clear direction for the authors to explore. However, the comment lacks depth and does not offer detailed guidance on how to conduct the ablation study or what specific results would be expected. The suggestion is actionable but could be more comprehensive, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a belief that the use of reinforcement learning for a static VQA task might be a potential weakness, impacting the data efficiency and training difficulty of the models. However, it does not provide any explicit or implicit suggestions on how the authors might address this concern or improve their approach. The comment lacks concrete guidance on what changes could be made to mitigate the potential weakness or how the authors might strengthen their argument. As a result, the authors are left without a clear understanding of how to proceed with their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less data efficient and harder to train. However, it does not specify which part of the paper this concern relates to, such as a particular section or methodology. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its critique of the approach but lacks detailed suggestions on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less data efficient and harder to train. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting data, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides a subjective opinion but lacks sufficient justification.", "helpfulness_rationale": "The review comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it might make the approach less data efficient and harder to train. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their approach. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete guidance on what needs to be done, making the comment 5. The authors know exactly how to address the issue by adding a table and providing an explanation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to address the distribution of video lengths across the dataset, which is a specific part of the paper. It also specifies what needs to be addressed, including the inclusion of a table and an explanation of the balanced representation of video lengths across the 11 categories. This provides clear guidance for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide relevant explanations regarding the distribution of video lengths within the benchmark, which is crucial for assessing reasoning ability and robustness. The comment suggests that the authors should include a table showing the distribution of video lengths and explain how they ensured a balanced representation across the 11 categories. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. While it provides a general direction for improvement, it does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is 3, as it identifies a potential issue but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding the distribution of video lengths across the benchmark. It provides clear guidance on what the authors should do to address this issue, including the need to include a table showing the distribution and explain how they ensured a balanced representation of different video lengths across the 11 categories. This feedback is actionable and constructive, as it directs the authors to specific steps they can take to enhance the clarity and comprehensiveness of their work. By addressing this feedback, the authors can significantly improve the presentation and robustness of their paper, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should take a cautious approach regarding the contribution until the promised dataset is made publicly available. However, it does not provide any specific guidance or actions on how the authors should proceed with this cautious approach. The comment lacks explicit instructions or concrete steps that the authors can take to address this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the promised dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, taking a cautious approach regarding the contribution until the dataset is publicly available. This provides clear guidance on how the authors should proceed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the promised dataset has not yet been made publicly available, suggesting a cautious approach should be taken. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the availability of a promised dataset, suggesting a cautious approach should be taken regarding the contribution until the dataset is publicly accessible. While the comment highlights a concern that could impact the authors\" work, it lacks specific guidance or suggestions on how to address this issue. The feedback is 3 as it points out a potential limitation, but it does not provide actionable steps or detailed advice on how to proceed. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, it does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider alternative ways to illustrate the results, such as directly showing the latter loss term of Eqn 13. While the comment is 3, it lacks concrete details on how to implement the suggested change, making it 3.", "grounding_specificity_rationale": "The comment refers to \"Fig. 3 e,\" which is a specific figure in the paper. However, it does not explicitly mention which part of the figure or what specific aspect of the figure is being addressed. The comment is specific in its suggestion to illustrate the results of the latter loss term of Eqn 13, but it lacks grounding as the authors cannot confidently determine which part of the paper this refers to. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. However, the comment does not provide any specific reasoning or justification for why cosine similarity is used or why it might be inappropriate in this context. It lacks detailed explanation or examples to support the claim, making it difficult for the authors to understand the reasoning behind the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the rationale behind using cosine similarity to illustrate the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. This raises a valid point about the appropriateness of the chosen method for illustrating the results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their presentation. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors would need to infer that they should consider alternative ways to illustrate the results, such as directly showing the latter loss term of Eqn 13. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning AB. It suggests that these methods aim to adapt to outofdistribution data when the input data is disturbed by noise, and that the paper should compare data processing with model parameter adjustment. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of robustness in video action recognition and highlights the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning AB. It suggests that these TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise, and that the paper should compare data processing with model parameter adjustment. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks comparison with testtime adaptation (TTA) methods, such as AB, which also aim to adapt to outofdistribution data when the input data is disturbed by noise. The comment suggests that the paper should compare data processing with model parameter adjustment and proposes that this comparison should be based on experimental results. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper lacks such a comparison. It lacks detailed justification or references to specific sections where this comparison is missing, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the lack of comparison with testtime adaptation (TTA) methods, specifically mentioning AB. It highlights that these TTA methods aim to adapt to outofdistribution data when the input data is disturbed by noise, and suggests that the paper should compare data processing with model parameter adjustment. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects of the comparison should be addressed. While it identifies an important area for improvement, the lack of detailed suggestions or examples makes it 3. The authors are left to infer the necessary steps, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. This direct feedback allows the authors to identify the specific issue and correct the expression in their draft. The action is explicit and concrete, as it clearly indicates which part of the paper needs revision and what the correct expression should be. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3.2.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the first expression for J(\u03b8) is incorrect and provides the correct expression, making the comment 5. This level of detail enables the authors to understand exactly what needs to be corrected and how to do it. Therefore, the comment is rated as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the first expression for J(\u03b8) in Section 3.2.1 is incorrect and provides the correct expression. However, it does not offer any reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the expression is incorrect or how to correct it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in Section 3.2.1, pointing out that the first expression for J(\u03b8) is incorrect and providing the correct expression. This feedback is clear and actionable, as it directly informs the authors about the need to correct the expression in their draft. By providing the correct expression, the comment offers a concrete solution, making it 5 for improving the accuracy and clarity of the paper. Therefore, this comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific examples of capitalization issues in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. It also mentions specific publications, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020, along with a reference to p. 13, supplement, Fig. This explicit instruction to capitalize specific words in the references provides clear guidance on what needs to be addressed, making the comment 5. The authors know exactly which parts of the references require correction and how to implement the suggested changes. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections and references, such as \"p.8\" and \"p. 13, supplement, Fig.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the issue of capitalization errors in the references, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that various words in the references need capitalization, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies specific issues with the capitalization of words in the references, such as \"ai\" in Amodei et al. (2016), \"bayesian\" in many papers, and \"Advances in neural information processing systems\" in several papers. It also provides specific examples of publications that need correction, such as Dusenberry et al. (2020) in ICML 2020, Osawa et al. (2019) in NeurIPS 2019, and Swiatkowski et al. (2020) in ICML 2020. This feedback is clear and actionable, as it directs the authors to specific areas where capitalization errors need to be addressed. By providing concrete examples and references, the comment helps the authors improve the accuracy and professionalism of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises several questions about the completeness of the paper, specifically regarding the inclusion of parameter values and the rationale behind their selection. It explicitly asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the completeness of the paper, specifically regarding the inclusion of parameter values and the rationale behind their selection. It asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. While the questions are specific about the parameters, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the completeness of the paper, specifically regarding the inclusion of parameter values and the rationale behind their selection. It asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not provide any evidence or reasoning to support these claims, leaving the authors without guidance on how to address the issue. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the concern, rendering the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises specific questions about the completeness of the paper, particularly regarding the inclusion of parameter values and the rationale behind their selection. It asks for the model parameters for task 1 and the lambda value for the Boltzmann policy, and questions how these parameters were chosen, suggesting that maximum likelihood estimates might be relevant. However, the comment does not provide any guidance or suggestions on how the authors might address these issues or improve their draft. While it identifies areas for improvement, it lacks actionable advice, making it 2. The authors are left with a vague understanding of what needs to be addressed but without clear steps to take. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for this observation. While the comment suggests that the authors should consider why the performance deteriorates when CBN is applied to layer 2 in addition to layers 3 and 4, it does not provide explicit guidance on how to address this issue or what actions the authors should take. The action is implicit, as the authors need to infer that they should investigate and explain the performance difference. However, the comment lacks concrete details on how to approach this investigation, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, and it questions why this approach might deteriorate performance compared to applying CBN to layers 4 and 3 only. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It asks the authors to provide some insight or explanation for why applying CBN to layer 2 in addition to layers 3 and 4 might deteriorate performance compared to applying it to layers 4 and 3 only. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this observation might occur. Without additional context or explanation, the authors are left to speculate or make assumptions, which limits the verifiability of the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a specific question about the performance of the GuessWhat?! model when Conditional Batch Norm (CBN) is applied to different layers. It highlights a potential issue where applying CBN to layer 2 in addition to layers 3 and 4 results in a performance deterioration compared to applying it to layers 4 and 3 only. This observation is intriguing and prompts the authors to investigate and understand the underlying reasons for this phenomenon. However, the comment lacks detailed guidance or suggestions on how the authors might approach this investigation or what specific aspects of the model or training process could be contributing to the performance difference. While it identifies a potential area for improvement, the feedback is somewhat limited in its depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, it does not provide explicit instructions or detailed guidance on how to implement this suggestion or address the issue. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of the proposed method not handling headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. However, the comment does not specify which part of the paper discusses the proposed method or headpose handling, making it weakly grounded. It is specific in questioning the authors\" claim and suggesting an alternative approach, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the authors\" claim regarding the proposed method\"s inability to handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it 3. The authors would need to provide more evidence or explanation to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the proposed method\"s inability to handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. This feedback highlights a potential limitation of the proposed method and prompts the authors to consider how to address this issue. However, the comment could be more helpful if it provided specific suggestions or guidance on how to condition headpose parameters in NeRF, similar to the approach in the cited work. Without detailed insights or actionable steps, the authors may find it challenging to fully address the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing only a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel and simple patterns by Gu et al. (2019) 1. However, the comment does not explicitly instruct the authors to address this similarity or provide specific guidance on how to improve their draft based on this observation. While the authors might infer that they should discuss or differentiate their spurious features from existing backdoor triggers, the lack of explicit action or detailed guidance makes the comment 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the similarity between the spurious features and backdoor triggers, providing examples of how these triggers have been used in previous work. This allows the authors to understand the specific issue and how it relates to their own work. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, noting that both are artificial patterns appearing only a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel and simple patterns by Gu et al. (2019) 1. This claim is supported by logical reasoning and references to specific examples, making it 4. The authors can understand the basis of the claim and how it relates to their work, allowing them to address it effectively. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a similarity between the spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing only a few times in the training set. It provides examples of how these triggers have been used in previous work, such as random noise patterns by Chen et al. (2017) and singlepixel and simple patterns by Gu et al. (2019) 1. This observation is insightful and highlights a potential area for further discussion or differentiation in the paper. However, the comment does not offer specific guidance on how the authors might address this similarity or incorporate it into their work. While it provides a valuable observation, it lacks actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a structural optimization component that has been emphasized multiple times, but it points out that the optimization algorithm is directly derived from previous works. This feedback suggests that the authors should clarify the novelty and contribution of their optimization approach. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the algorithm need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the novelty of their optimization algorithm. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the optimization algorithm used in the paper is directly derived from previous works, which reduces the contribution of the paper. However, it does not specify which part of the paper discusses the optimization algorithm or which sections are relevant. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. The comment is specific in that it identifies a potential issue with the novelty of the optimization algorithm, but without clear grounding, the authors may struggle to address it effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the optimization algorithm is directly derived from previous works, which reduces the contribution of the paper. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or references, the authors may find it challenging to verify the claim and address it effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the optimization algorithm used in the paper, noting that it is directly derived from previous works. This feedback is 3 as it highlights a concern that could impact the paper\"s contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without actionable advice or detailed examples, the authors may struggle to fully understand and address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the experimental results, noting that the pipeline method does not yield better average results compared to baseline models. It also points out that the baseline models are not well introduced in the experiments. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes need to be made to the draft. The action is implicit, as the authors can infer that they need to improve the introduction of baseline models and potentially reevaluate the experimental results. The lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results of a pipeline method, specifically noting that it does not yield better average results compared to baseline models on two datasets, XVNLI and MaRVL. However, the comment does not specify which part of the paper discusses these results or the baseline models, making it weakly grounded. The comment is specific in detailing the issue with the results and the lack of introduction of baseline models, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pipeline method does not provide better average results compared to baseline models on two datasets, XVNLI and MaRVL. It also notes that the baseline models are not well introduced in the experiments. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. Without detailed evidence or examples, the claim remains 3, as the authors may need to conduct further investigation to confirm the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the pipeline method does not yield better average results compared to baseline models on two datasets, XVNLI and MaRVL. It also points out that the baseline models are not well introduced in the experiments. This feedback is 3 as it highlights a potential weakness in the experimental setup and suggests that the authors should consider reevaluating their results or providing a more detailed introduction to the baseline models. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as suggesting alternative experimental designs or methods for introducing baseline models. Overall, the comment offers some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the authors\" discussion by noting that they primarily focus on SSC and do not adequately contrast their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they should include a comparison with these methods, but the action is not fully specified. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on SSC and the lack of contrast with other methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue by pointing out the absence of a comparison with these methods, which are computationally efficient and come with similar guarantees. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors primarily focus on SSC and do not contrast their method with other computationally efficient subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it is based on an observation without thorough justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the authors\" discussion by pointing out that they primarily focus on SSC without adequately contrasting their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is 3 as it highlights an area where the authors could enhance their work by providing a more comprehensive comparison with existing methods. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this gap, such as suggesting additional experiments or analyses to compare their method with these alternatives. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the small contributions of the proposed method over previous methods, such as NCNet 6 and Sparse NCNet 21. It also notes that the work is mostly engineeringfocused and suggests that it is challenging to differentiate the proposed method from its predecessors due to similar performance in practice. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the differentiation or to enhance the contribution of the work. As a result, the authors are left without clear directions on how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It mentions \"small contributions over previous methods\" and \"mostly (good) engineering,\" but it does not provide specific details or examples related to these claims. The comment is also not specific because it lacks detailed information about what needs to be addressed or how the contributions should be differentiated. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contributions of the proposed method are small compared to previous methods, such as NCNet 6 and Sparse NCNet 21. It also suggests that the work is mostly engineeringfocused and that it is challenging to differentiate it from its predecessors due to similar performance in practice. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or evidence to substantiate the assertion that the contributions are small or that the differentiation is difficult. As a result, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment acknowledges the small contributions of the proposed method over previous methods, such as NCNet 6 and Sparse NCNet 21. It also notes that the work is mostly engineeringfocused and suggests that it is challenging to differentiate the proposed method from its predecessors due to similar performance in practice. While the comment identifies a potential weakness in the paper\"s contribution, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the differentiation of their method. The feedback is 3 as it highlights an area for improvement, but it lacks actionable advice, making it only partially beneficial for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel. It implies that the statements about semantic segmentation being a lowlevel cue should be removed from the paper. However, the comment does not provide explicit instructions on how to remove these statements or what specific parts of the paper should be revised. The action is implicit and somewhat vague, as the authors need to infer that they should remove the statements and potentially reevaluate the categorization of semantic segmentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the term \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel, implying that the statements about semantic segmentation being a lowlevel cue should be removed from the paper. However, the comment does not specify which part of the paper discusses semantic segmentation or lowlevel cues, making it difficult for the authors to identify the exact section that needs revision. While the comment is specific about the content that should be removed, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"semantic\" segmentation is not lowlevel because the categories are specified for each pixel, suggesting that statements about semantic segmentation being a lowlevel cue should be removed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the argument or how to address it. Without detailed reasoning or evidence, the claim remains 3, as it is based on a logical deduction but lacks sufficient substantiation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the paper, suggesting that \"semantic\" segmentation is not lowlevel due to the pixelspecific categories. This feedback is clear and actionable, as it directs the authors to reconsider the categorization of semantic segmentation and potentially remove statements that imply it is a lowlevel cue. However, the comment could be more helpful if it provided additional context or examples to support the claim, allowing the authors to better understand the implications of this correction. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the ablation experiment results, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or RL is not used. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes need to be made to the draft. The action is implicit, as the authors can infer that they need to clarify the results and include the missing cases in the tables. The action is somewhat vague, as it does not specify how to present the results or what kind of analysis is needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the ablation experiment results, specifically noting a discrepancy in performance without reinforcement learning compared to without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or reinforcement learning is not used. However, the comment does not specify which part of the paper these tables are located in, making it weakly grounded. The comment is specific in detailing the issue with the ablation experiment results, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance without reinforcement learning dropped lower than without the dependency tree in the ablation experiment. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed explanation or examples to substantiate the observation, making it difficult for the authors to understand and address the issue. Therefore, the claim is 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the ablation experiment, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where either the dependency tree or reinforcement learning is not used. This feedback is 3 as it highlights a potential inconsistency in the results and suggests that the authors should clarify the presentation of their findings. However, the comment lacks detailed guidance on how the authors might address this issue or what specific changes are needed to improve the clarity and completeness of their results. The feedback is incomplete and could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their methodology. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not specify which part of the paper discusses the methodology or the results, making it weakly grounded. The comment is specific in detailing the concerns about the methodology and the difficulty in interpreting the results, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It suggests that previous work has considered multiple vulnerabilities simultaneously and reports on the presence of such vulnerabilities. The comment implies that the current approach may not be robust or generalizable, but it does not provide specific examples or references to support these claims. The lack of detailed reasoning or evidence makes the claim 3, as the authors are left to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It suggests that previous work has considered multiple vulnerabilities simultaneously and reports on the presence of such vulnerabilities, implying that the current approach may not be robust or generalizable. The comment also notes that the results are difficult to interpret, which could limit the impact of the study. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their methodology. While it identifies a potential weakness, it lacks actionable advice, making it 3. The feedback is valuable in highlighting areas for improvement but could be more impactful with detailed suggestions or recommendations."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the explanation of how a small degree of bias arises from a clear community structure, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so or specify how to improve the explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the relationship between community structure, degree bias, and the theorems. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the explanation of how a small degree of bias arises from a clear community structure, referencing Theorem 1 and 2. However, it does not specify which part of the paper this explanation is intended for, making it weakly grounded. The comment is specific in its critique of the lack of intuitive understanding of the relationship between community structure, degree bias, and the theorems. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the explanation of how a small degree of bias arises from a clear community structure is insufficient, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The feedback is 3 as it identifies a gap in the explanation but does not provide enough detail to guide the authors in improving their understanding. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by providing more detailed explanations. It points out that while Theorem 1 and 2 prove the relationship between community structure and degree bias, the explanation of how a small degree of bias arises from a clear community structure is not intuitive enough. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation. However, it could be more helpful if it provided specific suggestions or examples for improving the explanation. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It implies that the authors need to clarify how these clean manifolds are constructed, particularly when the exemplar manifolds are not derived from adversarial perturbations or stochasticity. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 182183, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of clean exemplar manifolds for nonstochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the construction of clean exemplar manifolds for nonstochastic networks, specifically in the context of the ResNet50 and ATResNet50 networks. It questions how these manifolds are constructed when the exemplar manifolds are not derived from adversarial perturbations or stochasticity. However, the comment does not provide any evidence, reasoning, or references to support the claim that the construction of these manifolds is unclear or problematic. Without additional context or justification, the authors are left to assume the claim is valid, making the comment 1.", "helpfulness_rationale": "The review comment raises a specific question about the construction of clean exemplar manifolds for nonstochastic networks, particularly in the context of the ResNet50 and ATResNet50 networks. It points out a potential inconsistency in the description of how these manifolds are constructed, as the paper mentions both adversarial perturbations and stochasticity as methods for creating exemplar manifolds. This raises a valid concern about the clarity and consistency of the methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify their methodology. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might enhance the originality of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. Without explicit references or context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment lacks specificity in detailing what aspects of the variable splitting or algorithm could be improved to enhance originality. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the originality of the paper, specifically noting that the main idea of variable splitting and the algorithm are not new. However, it does not provide any suggestions or insights on how the authors might address this issue or enhance the originality of their work. The comment lacks actionable guidance and does not offer any specific advice on how the authors could differentiate their approach from existing methods. As a result, the feedback is not particularly helpful in guiding the authors towards improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment implies that this related work should be discussed and compared against to provide a better understanding of the stateoftheart. However, it does not explicitly instruct the authors to include or discuss this work in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this omission. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors should discuss and compare their work against this related paper to provide a better understanding of the stateoftheart. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment suggests that this related work should be discussed and compared against to provide a better understanding of the stateoftheart. However, the comment lacks specific examples or detailed reasoning to support the claim that this work is indeed relevant and should be discussed. Without additional context or evidence, the authors may find it challenging to understand why this specific paper is important and how it relates to their work. Therefore, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail to fully substantiate it.", "helpfulness_rationale": "The review comment identifies a gap in the related work by pointing out that the authors have missed a relevant paper by Ghoshdastidar and Dukkipati, which deals with spectral clustering using multilinear SVD and hypergraph data. This is a valuable piece of feedback as it suggests that the authors should include and discuss this related work to provide a more comprehensive understanding of the stateoftheart. However, the comment could be more helpful if it provided specific guidance on how to integrate or compare this work with the authors\" own contributions. Overall, the comment is 3 as it highlights an important area for improvement, but it lacks depth and specificity in its suggestions."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper was difficult to follow, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the paper. The comment lacks guidance on how the authors might address these issues, such as suggesting specific sections to clarify or providing examples of how to improve the writing. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not specify which part of the paper is particularly challenging, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment lacks specificity in identifying the sections or aspects of the paper that are hard to follow. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective opinion about the difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without any supporting details or examples, the claim lacks verifiability, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment highlights a significant issue with the paper\"s readability, specifically mentioning the difficulty in following the experimental procedures and evaluations. This feedback is valuable as it points out a critical area that needs improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as providing clearer explanations, additional examples, or a more structured presentation of the experimental details. While the feedback identifies a clear weakness, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that INRs operate on a perdatainstance basis, arguing that this is not an advantage and that such a model would be almost useless. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors might infer that they need to reconsider the framing of their argument or provide a more nuanced perspective on the utility of perdatainstance operations. The comment lacks concrete details on how to implement this feedback, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it critiques the claim about INRs operating on a perdatainstance basis, arguing that this is not an advantage and that such a model would be almost useless. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"Finally, INRs operate on a perdatainstance basis, meaning that one timeseries instance is required to train an INR\" is true but argues that it is not an advantage. The reviewer provides a logical reasoning by suggesting that a model capable of handling only a single timeseries instance is almost useless. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide more detailed reasoning or evidence to fully understand the reviewer\"s point and address it effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim in the paper, stating that INRs operate on a perdatainstance basis, and argues that this is not an advantage. The reviewer provides a logical reasoning by suggesting that such a model would be almost useless. While the comment highlights a potential weakness in the paper\"s argument, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it points out an area for improvement, but it lacks depth and actionable advice, making it a 3 comment."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It provides an example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m, and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is explicit and provides concrete guidance on what needs to be addressed in the paper. The authors know exactly what aspects to consider and how to implement the suggested clarification, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific section of the paper (line 132), allowing the authors to accurately identify the part being addressed. It also provides specific guidance on what needs to be clarified, such as the aspects of the specific model that are specific to this example model and the clarification regarding the bounds of certain parameters. This level of detail ensures that the authors understand exactly what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify specific aspects of the model, such as the bounded nature of certain parameters and the absence of infinite subdivisions. However, it does not provide any evidence or reasoning to support why these clarifications are necessary or how they impact the paper. Without specific examples or references, the claim lacks sufficient justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific feedback on the content of line 132, suggesting that the authors should clarify the aspects of the specific model that are relevant to the example model being discussed. It offers concrete examples, such as clarifying that the authors are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is actionable and provides clear guidance on what needs to be addressed in the paper, making it 5 for the authors to improve their draft. The comment is detailed and specific, offering a clear path for the authors to enhance the clarity and precision of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the experiments are limited to RoBERTabase and raises concerns about the generalizability of the results to other models, such as those with learnable APEs, different model sizes, objective functions, and architectures. It also recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT2. The comment provides clear guidance on what needs to be addressed and how to do it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"most of the experiments\" and \"Section 4.1.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of limited experiments, the need to generalize results to other models with learnable APEs, and suggests including more analysis for GPT2, providing detailed guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to RoBERTabase and suggests that the results may not be generalizable to other models, such as those with learnable APEs, different model sizes, objective functions, and architectures. It recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT2. However, the comment lacks specific examples or references to support the claim about the generalizability of the results. While it provides a logical reasoning for the concern, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experiments conducted, noting that most of the experiments are limited to the RoBERTabase model. It raises concerns about the generalizability of the results to other models, particularly those with learnable APEs, different model sizes, objective functions, and architectures. The comment suggests that the authors should investigate these aspects to ensure the robustness and applicability of their findings. Additionally, it recommends including more analysis and discussion, specifically mentioning the inclusion of results for GPT2, which would provide valuable insights. This feedback is clear, actionable, and constructive, offering specific guidance on how the authors can enhance their experiments and improve the generalizability of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not provide explicit guidance on how to conduct this exploration or what specific steps the authors should take. While the action is implied, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment does not specify which part of the paper discusses the parameters or the experiments, making it weakly grounded. It is specific in suggesting that the authors should consider applying the principles to other areas, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. However, the comment lacks specific examples or references to support the claim that the parameters are only applicable to image data and ViT. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the generalizability of the parameters in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs in the image domain. This feedback is 3 as it points out a potential limitation in the scope of the study and encourages the authors to consider broader applicability. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what additional experiments might be necessary. Overall, the comment offers a valuable insight but lacks detailed actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with largescale datasets. While the comment identifies a potential issue with the learning rate condition, it does not provide explicit guidance on how the authors might address this concern or what specific changes could be made to the draft. The action is implicit, as the authors would need to infer that they should consider alternative learning rate scaling strategies or provide a more realistic justification for the current condition. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the scalability of the required condition on the learning rate, which is a critical aspect of the paper. It highlights a concern that the learning rate scales with the number of samples, a point that is not realistic in practice. The comment is fully grounded as it explicitly mentions the learning rate condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the learning rate condition and its implications for scalability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with largescale datasets. The comment provides a logical reasoning for why the condition might be unrealistic, but it lacks specific examples or references to support the claim. Without additional evidence or references, the claim is 3, as it is based on a reasonable argument but could benefit from more detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the required condition on the learning rate, noting that it scales with the number of samples, which is not realistic in practice. The reviewer points out that in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with largescale datasets. This feedback highlights a critical aspect of the paper that needs further consideration or clarification. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or what alternative approaches could be considered. Without such guidance, the authors may find it challenging to improve their draft based solely on this feedback. Therefore, the comment is 3, as it identifies a significant concern but lacks actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the abstract effectively explains the proposed idea but does not provide details on how the idea was evaluated or what the outcome was. It also mentions minor language issues. While the comment identifies a gap in the abstract\"s content, it does not explicitly instruct the authors to include details about the evaluation process or the outcome. The suggestion to address minor language issues is vague and lacks specific guidance. Therefore, the comment is 3, as it highlights an area for improvement but does not provide clear instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description regarding how the proposed idea was evaluated and what the outcome was, as well as mentioning minor language issues. This provides clear guidance on what needs to be addressed in the abstract. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract effectively explains the proposed idea but lacks details on how it was evaluated and what the outcome was. It also mentions minor language issues. However, the comment does not provide any specific examples or references to support the claim about the lack of detail in the evaluation process or the outcome. The mention of minor language issues is vague and lacks specific examples or references. Therefore, the claim is 1 due to the lack of supporting evidence or justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the abstract, noting that while it effectively explains the proposed idea, it lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it directs the authors to include additional information that would enhance the completeness and clarity of the abstract. However, the comment could be more helpful if it provided specific examples or suggestions for how to include this information. Overall, the comment is 4 as it highlights a significant area for improvement that would benefit the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. It suggests that the experiments section is not useful due to the absence of relevant experiments, even simulated ones. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the experimental section. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results of the paper and the specific examples used to motivate the solution for POMDP problems with nonconvex value functions. It clearly identifies the part of the paper being addressed, allowing the authors to accurately pinpoint the issue. The comment is also specific, as it details the examples used and questions the lack of experiments on the described settings, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern about the experimental results, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. It provides examples of POMDP problems with nonconvex value functions, such as surveillance in museums with thresholded rewards and privacypreserving data collection. However, the comment does not offer any specific reasoning or evidence to support the claim that the experiments are not useful or that the examples are insufficient. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 2, as it lacks sufficient support to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the experimental results of the paper, specifically questioning the motivation for the chosen examples and the lack of experiments on the described settings. The examples provided, such as surveillance in museums with thresholded rewards and privacypreserving data collection, are relevant to the problem being addressed. However, the reviewer points out that there is no experimental evidence to support these examples, which makes the experiments section less useful. While the comment identifies a significant gap in the experimental validation, it does not provide specific suggestions or guidance on how the authors might address this issue or conduct additional experiments. The feedback is 3 as it highlights a critical area for improvement, but it lacks depth and actionable advice, making it only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that epochwise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. Additionally, it suggests that this analysis could be used for comparative studies between deterministic and stochastic methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific aspects of the algorithms to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that epochwise analysis, especially for finite sum settings, could provide insights into the behavior of optimization algorithms. It provides specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. This guidance is clear and specific, as it outlines potential areas for further analysis and comparison between deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be applied to, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that epochwise analysis, particularly in finite sum settings, could provide valuable insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. This claim is 3 as it provides a logical reasoning for why such analysis could be beneficial, but it lacks specific examples or references to support the claim fully. The suggestion to compare deterministic and stochastic methods is also clear but could benefit from more detailed examples or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a suggestion for enhancing the paper by incorporating epochwise analysis, particularly in finite sum settings, to gain insights into the behavior of optimization algorithms. It offers specific examples, such as investigating the effects of batch size and different sampling strategies on the algorithms\" progress after each full pass of the data. This feedback is 3 as it identifies a potential area for improvement and provides a clear direction for the authors to explore. However, the comment could be more helpful if it included additional guidance on how to conduct this analysis or what specific aspects of the algorithms to focus on. Overall, the comment offers valuable insights but could be more comprehensive and actionable to fully assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the issue. It questions the annotators\" consideration of local regulations and their impact on zeroshot crosscountry classification. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the distinction between the two classes. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Paper Summary,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the difficulty in differentiating between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. The comment is specific in detailing what needs to be addressed, including the need for clearer differentiation and clarification regarding the impact of local regulations on annotations and classification. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the distinction between derogatory and exclusionary extreme speech, providing an example from the sample data file to illustrate the confusion. It also questions the role of local regulations in the annotations and their impact on zeroshot crosscountry classification. However, the comment lacks specific examples or references to support the claim that the distinction is difficult to make or that local regulations are not adequately considered. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a specific issue regarding the differentiation between derogatory and exclusionary extreme speech, which is a crucial aspect of the paper. It provides an example from the sample data file to illustrate the confusion, questioning why a particular instance is classified as one type of speech over the other. This feedback is 3 as it highlights a potential area for improvement in the paper\"s clarity and consistency. However, the comment could be more helpful if it provided additional guidance on how the authors might address this issue or suggested specific changes to improve the distinction between the two classes. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement is due to the network design or the nature of ImageNet. This provides clear guidance on what needs to be done and how to address the concern, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to show a graph of T vs the number of images and Expectation(T) over the ImageNet test set, allowing the authors to accurately identify the parts of the paper that need revision. It is also specific because it provides clear guidance on what needs to be addressed, including the purpose of the graph and the question about the source of performance improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement stems from the network design or the nature of ImageNet. However, the comment lacks specific examples or references to support the claim that these visualizations are necessary or how they would address the concern about performance improvement. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by requesting the inclusion of a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a critical question about whether the performance improvement is due to the network design or the nature of ImageNet, which is an important consideration for understanding the results. By addressing these points, the comment offers actionable feedback that helps the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it provided more detailed guidance on how to create the graph or how to address the question about the source of performance improvement. Overall, the feedback is 4 as it directs the authors towards important areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should make the paper mathematically correct, but it acknowledges that this might make other equations messy. It also points out that the notation L_l should be introduced beforehand. While the comment provides some guidance, it does not explicitly instruct the authors on how to make the paper mathematically correct or how to introduce the notation L_l. The action is somewhat vague, as the authors are left to infer the exact steps needed to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig.\" which indicates a figure in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue with the notation L_l, suggesting that it should be introduced beforehand. This provides clear guidance on what needs to be addressed in the figure or the surrounding text. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the mathematical correctness of the paper and the notation used, specifically questioning why the notation L_l is used instead of just L. While the comment suggests that the authors should consider making the paper mathematically correct, it does not provide specific examples or references to support this claim. The reasoning is somewhat vague, as it lacks detailed explanations or evidence to substantiate the claim. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the mathematical correctness of the paper and raises a question about the notation L_l. It suggests that the authors should consider making the paper mathematically correct, but it also acknowledges that this might make other equations messy. The comment also points out that the notation L_l should be introduced beforehand, which is a specific and actionable suggestion. However, the comment could be more helpful if it provided more detailed guidance on how to address the mathematical correctness or introduced the notation L_l. Overall, the comment is 3 as it offers actionable feedback but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, noting that the baseline and timeaware models show similar performance. It suggests that the proposed method might be more effective under different timestep scenarios. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be needed to the draft. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by questioning the effectiveness of the proposed methods when the training and evaluation timesteps are the same, suggesting that the method might be more effective under different scenarios. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, based on the observation that Figure 5 shows similar performance between the baseline and timeaware models. While the comment identifies a potential issue, it does not provide specific examples, detailed reasoning, or references to support the claim that the effectiveness of the proposed methods is questionable under these conditions. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning or seek additional information to fully understand the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation timesteps are the same, as evidenced by the similar performance shown in Figure 5. The comment suggests that the proposed method might be more effective under different timestep scenarios, which is a relevant point for consideration. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to the draft to improve its clarity or effectiveness. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain biases. This feedback is explicit and provides a clear action for the authors to take, which is to elaborate on the mechanisms and guarantees of disentanglement. However, the comment does not specify exactly how this should be done, leaving some room for interpretation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation related to disentangled latent vectors. However, the comment does not specify which part of the paper discusses disentanglement or how it is realized. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the issue of disentanglement, it lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation related to disentangled latent vectors. However, the comment does not provide specific examples, detailed reasoning, or references to support the claim that the disentanglement is not clearly guaranteed. This lack of detailed explanation or evidence makes the claim 3, as the authors may need to infer the reasoning behind the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the clarity of how disentanglement is guaranteed in the paper. It points out that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain biases. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation regarding the disentanglement process. However, the comment could be more helpful if it provided specific examples or suggestions for how to address this issue. Overall, the comment is 4, as it identifies an important area for improvement and encourages the authors to provide more detailed explanations."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison to assess the impact of mean teacher regularization. The comment is specific in its suggestion and provides a concrete action for the authors to implement, making it 5.", "grounding_specificity_rationale": "The comment suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and explicit reference to a specific part of the paper, allowing the authors to accurately identify the section where the comparison should be included. The comment is specific in its suggestion, detailing what needs to be added to the graph to facilitate a comparison. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3 to compare its performance with models that have these regularizations. This claim is 3 as it provides a specific suggestion for comparison, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the reasoning behind this suggestion, which could be improved by providing more context or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by proposing the inclusion of a learning curve for a model without mean teacher or pi regularization in Figure 3. This addition would allow the authors to compare the performance of their model with and without these regularizations, providing valuable insights into the impact of these techniques. The suggestion is clear and actionable, offering a concrete way to enhance the analysis and understanding of the model\"s behavior. However, the comment could be more helpful if it included additional guidance on how to interpret the results or what specific aspects of the learning curve to focus on. Overall, the comment is 4 as it directs the authors towards a meaningful improvement in their analysis."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the handling of different types of inputs and the disordered citation. For the first part, it suggests that the authors should discuss how they deal with various inputs, such as biomedical signals or speech, and present their solutions. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be addressed and how to do it. However, the comment does not specify which part of the paper this discussion should be included in, leaving some ambiguity. For the second part, the comment suggests that the citation is disordered, but it does not provide specific guidance on how to correct it. While the action is somewhat explicit for the first part, the second part lacks detail, making the comment 3 overall.", "grounding_specificity_rationale": "The comment addresses the handling of different types of inputs, such as biomedical signals or speech, suggesting that the authors should discuss this and present their solutions. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting that the authors should discuss how they handle these different types of inputs and present their solutions, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two main concerns: the handling of different types of inputs and the disordered citation. While the comment suggests that the authors should discuss how they deal with various inputs, such as biomedical signals or speech, it does not provide specific examples or references to support this claim. The suggestion to present solutions is clear, but the lack of detailed reasoning or examples makes the claim 3. The comment also mentions that the citation is disordered, but it does not elaborate on why it is disordered or how it should be corrected, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main areas for improvement in the paper. First, it suggests that the authors should discuss how they handle different types of inputs, such as biomedical signals or speech, and present their solutions. This provides a clear direction for the authors to enhance the paper\"s content and address a potential gap in the discussion. Second, the comment points out that the citation is disordered, which could be a minor issue but still suggests a need for attention. While the comment is 3 as it highlights specific areas for improvement, it could be more comprehensive if it provided more detailed guidance or suggestions for addressing the disordered citation. Overall, the comment is rated as 3, as it offers actionable feedback but could be more detailed to fully assist the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relationship between equations 4 and 3, specifically whether the improvement of the designed solutions in Table 5 is significant. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not offer explicit guidance on how the authors should address this issue or what specific actions they should take to improve the significance of their results. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the relationship between equations 4 and 3, specifically questioning whether the improvement of the designed solutions in Table 5 is significant. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. However, the comment does not specify which part of the paper contains the equations or the table, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of marginal improvement, it lacks grounding as it does not clearly identify the relevant parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relationship between equations 4 and 3 and provides an example of marginal improvement in the results presented in Table 5. It questions whether the improvement of the designed solutions is significant, particularly on the OfficeHome dataset. However, the comment lacks detailed reasoning or references to support the claim that the improvement is marginal. It does not provide specific examples or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment raises a question about the relationship between equations 4 and 3, specifically questioning the significance of the improvement in the designed solutions presented in Table 5. It provides an example of marginal improvement on the OfficeHome dataset, where the CSAC achieves 64.35 and the proposed solution achieves 64.71. This feedback highlights a potential area for improvement in the paper, suggesting that the authors should consider whether the observed improvements are substantial enough to warrant further discussion or analysis. However, the comment lacks detailed guidance on how the authors might address this issue or what specific actions they should take to strengthen their results. While it identifies a potential weakness, it does not offer comprehensive suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not \"Whtypes\"/transformable. However, it does not provide any explicit or implicit suggestions on how to address this issue or what changes might be necessary. The comment lacks concrete guidance on how to improve the generalization of the model or what specific modifications could be made to the template mapping. As a result, the authors are left without a clear understanding of how to apply the feedback to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the question answering process, specifically mentioning the template mapping and its potential impact on generalization to questions that are not \"Whtypes\"/transformable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential problem with the template mapping, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the question answering process might cause poor generalization to questions that are not \"Whtypes\"/transformable due to the template mapping. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it difficult to understand or address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not \"Whtypes\"/transformable. This feedback is 3 as it highlights a specific area that could be improved, but it lacks detailed guidance or suggestions on how to address this issue. The authors are left without a clear understanding of what changes might be necessary to enhance the generalization of their model. While the comment points out a potential problem, it does not provide actionable steps or examples to resolve it, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform 1 as an example. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or incorporate the idea into their work. The comment lacks guidance on how to proceed or what changes might be necessary. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VolumeDeform 1\" and provides context by stating that utilizing a volumetric representation in the deformation field is not a novel idea. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what the authors should consider regarding the novelty of their approach, referencing a specific work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that utilizing a volumetric representation in the deformation field is not a novel idea, citing VolumeDeform 1 as an example. This claim is 3 as it provides a specific reference to support the assertion that the idea is not novel. However, it lacks detailed reasoning or examples to fully substantiate the claim, which could leave the authors uncertain about the depth of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the approach, specifically mentioning that utilizing a volumetric representation in the deformation field is not a novel idea and referencing VolumeDeform 1. While the comment highlights a concern, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice or detailed insights that would empower the authors to make meaningful changes. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the ICLHAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit, as the authors need to infer that they should expand the discussion to address the accuracy drop. While the action is somewhat concrete, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ICLHAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the issue of accuracy scores dropping from 70.4 to 55.6 on TRIP. This provides clear guidance on what the authors should discuss or acknowledge in the main text. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ICLHAR, while improving consistency and verifiability, has negatively impacted accuracy scores, dropping from 70.4 to 55.6 on TRIP. This claim is supported by specific numerical data, providing a clear and verifiable basis for the critique. The comment is 4 as it offers a clear explanation of the issue and provides specific data points to support the claim. However, it could be more robust if it included additional context or references to further substantiate the impact of the ICLHAR on accuracy. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the ICLHAR, noting that while it improves consistency and verifiability, it negatively impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This observation is crucial for the authors to address, as it highlights a potential tradeoff between consistency and accuracy. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it provided specific guidance on how to address the accuracy drop or what aspects of the discussion should be included. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the limited nature of the innovations in network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the innovations or the performance of the oracle expert. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It mentions the \"innovations of network architecture design and constraint embedding\" and the \"performance is limited by the performance of the oracle expert,\" but without specific references to sections, tables, or figures, the authors cannot pinpoint the exact areas that need improvement. The comment is also not specific because it does not provide detailed feedback or suggestions on how to address the identified limitations. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the innovations of network architecture design and constraint embedding are \"rather limited\" and that the performance is constrained by the performance of the oracle expert. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of this critique and how it applies to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the innovations in network architecture design and constraint embedding, suggesting that the performance is constrained by the performance of the oracle expert. While this feedback highlights an area for improvement, it lacks specific guidance or suggestions on how the authors might address this limitation or enhance their work. The comment provides a general observation but does not offer actionable advice or detailed insights into potential improvements. As a result, the feedback is 3, as it points out a potential issue but does not fully empower the authors to make meaningful changes to their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not provide explicit guidance on how to implement these suggestions or actions, such as specific steps or examples of how to conduct the calibration curves or discuss the differences. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model AUC\"s ability to assess discriminant ability and suggests that it may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not specify which part of the paper discusses the model AUC or where the calibration curves or feasibility discussion should be included. This makes it weakly grounded, as the authors cannot confidently determine which sections need revision. The comment is specific in detailing the issues and suggestions, such as conducting calibration curves and discussing differences. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It suggests conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it recommends discussing the differences between the traditional method and the proposed method. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the feedback effectively. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the model AUC\"s ability to demonstrate consistency with actual risk, suggesting that calibration curves could be used to show agreement. It also encourages the authors to prove the feasibility of the generated scoring system and to discuss the differences between the traditional method and the proposed method. While the comment provides some guidance on areas for improvement, it lacks specific details or actionable steps for the authors to take. The feedback is 3 as it highlights important aspects that need attention, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues related to the paper\"s content. First, it notes that the range of ID and OOD does not change much with sparsification, as shown in Figure 4. Second, it points out that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment does not explicitly instruct the authors on how to address these issues or provide specific guidance on what changes to make. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the range of ID and OOD does not change much with sparsification, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the range of ID and OOD does not change much with sparsification, as shown in Figure 4, and that Lemma 2 requires approximately identical means, which is crucial for DICE but is not well discussed. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. However, the comment lacks specific examples or references to support the claim that these conditions are crucial for DICE. Without detailed reasoning or evidence, the claim is difficult to verify, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two specific issues in the paper: the lack of change in the range of ID and OOD with sparsification, as shown in Figure 4, and the insufficient discussion of Lemma 2\"s requirements, particularly the need for approximately identical means for DICE. The comment suggests that the authors should provide more discussion on how to ensure DICE meets these conditions. While the feedback highlights areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The comment is 3 as it points out specific weaknesses but does not offer comprehensive advice or detailed steps for improvement, leaving the authors with a clear direction but limited actionable guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several concerns about the strength and fairness of the experiments, including questions about the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to strengthen their experiments, include missing baselines, and discuss limitations and societal impacts. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the strength and fairness of the experiments, questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. However, the comment does not specify which part of the paper these issues are related to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the strength and fairness of the experiments, questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general idea of the issues but does not offer detailed reasoning or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several concerns about the strength and fairness of the experiments, specifically questioning the use of position kernels for baselines and the absence of comparisons with baselines using default settings. It also notes the lack of discussion regarding the limitations and societal impacts of the proposed approach. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it provides a clear direction for the authors to enhance their experiments and discussions, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any explicit or implicit actions for the authors to take or suggest how to address this observation. The comment lacks guidance on what changes might be necessary or how to improve the results. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, it does not specify which part of the paper this observation is related to, such as a particular section, table, or figure. Without this context, the authors cannot confidently determine where the issue lies or how to address it. The comment is 1, as it lacks specific references to the paper, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point describes a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, the comment does not provide any specific evidence, reasoning, or references to support this observation. Without additional context or explanation, the authors are left to interpret the claim, making it difficult to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a phenomenon observed in the paper, noting a drop in correlation after a short period of training, which increases with more training iterations. However, it does not provide any specific suggestions or guidance on how to address this issue or improve the results. The comment lacks actionable insights, leaving the authors without a clear path to enhance their work. As a result, the feedback is not helpful in terms of providing actionable advice or suggestions for improvement. Therefore, the comment is rated as unhelpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the observed results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment does not provide explicit instructions on how the authors should address these issues or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to clarify the results and improve the presentation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the question about the sparsity patterns and the suggestion to clarify the results and improve the presentation of bits in that section. This provides clear guidance on how the authors should respond. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment lacks specific examples or detailed reasoning to support the claim that the sparsity patterns do almost equally well and that there is no insight provided. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the sparsity patterns observed in the results, suggesting that the authors should clarify whether these patterns are specific to the sparsity detection problem or if they generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. While the comment identifies an area for clarification and suggests a potential improvement in presentation, it lacks specific guidance on how the authors should address these issues or what changes might be necessary. The feedback is 3 as it directs the authors to areas that need attention, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown in a rigorous way or mentioned in the paper. This provides a clear and direct action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is specific and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eqn. 3 to Eqn. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the temperature \u03c4 is missing from the derivation and suggests that it should be shown rigorously or mentioned in the paper. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the derivation from Eqn. 3 to Eqn. 4 misses the temperature \u03c4 and suggests that it should be shown rigorously or mentioned in the paper. This claim is 3 as it points out a specific issue in the derivation, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the missing details or provide additional context to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the omission of the temperature parameter \u03c4 in the derivation from Eqn. 3 to Eqn. 4. It suggests that the authors should either show the derivation in a rigorous manner or mention the temperature parameter in the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve the rigor and completeness of their work. By addressing this issue, the authors can enhance the clarity and accuracy of their derivation, making the paper more robust and understandable. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a citation on differential privacy should be added to line 156 to benefit the reader. This is an explicit action, as it directly instructs the authors to include a specific citation. The action is also concrete, as it provides a clear and specific instruction on what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 156,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, which is a clear and actionable recommendation. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests adding a citation on differential privacy to line 156. This is a specific and actionable suggestion that would enhance the clarity and comprehensiveness of the paper. However, the comment does not provide any reasoning or justification for why this citation is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind the suggestion. Therefore, the comment is 3, as it is specific but lacks sufficient justification.", "helpfulness_rationale": "The review comment is specific and actionable, as it suggests adding a citation on differential privacy to line 156. This would enhance the clarity and comprehensiveness of the paper, benefiting the reader by providing additional context and supporting the claims made. However, the comment could be more helpful if it provided more context or explanation about why this citation is necessary or how it would improve the paper. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises two distinct points. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, which is a common assumption in machine learning. This feedback is somewhat explicit but could be more detailed, as it does not provide specific guidance on how to address this concern or what additional assumptions might be considered. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a concrete action that the authors can take to correct the error. However, the first part of the comment is somewhat vague and lacks detailed guidance, making the overall comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first para of Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, questioning the claim about \"significant additional assumptions\" and suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set. Additionally, it points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point contains two claims: one questioning the claim about \"significant additional assumptions\" in the first paragraph of Section 3.2, and another pointing out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. The first claim is 3 as it provides a specific example of a common assumption in machine learning, which partially supports the reviewer\"s argument. However, it lacks detailed reasoning or references to substantiate the claim fully. The second part of the comment is more verifiable as it points out a specific error in the inequality, which can be addressed with a correction. Overall, the comment is 3, as it provides some justification but lacks comprehensive evidence or references for the first claim.", "helpfulness_rationale": "The review comment provides specific feedback on two distinct issues. First, it questions the claim that the methodology requires \"significant additional assumptions,\" suggesting that the only additional assumption is the test set being drawn from the same distribution as the query set, a common assumption in machine learning. This feedback is 3 as it challenges the authors to reconsider the scope of their assumptions and potentially refine their claims. However, it could be more helpful if it provided guidance on how to address this concern or what additional assumptions might be considered. Second, the comment points out an error in the sign of an inequality on line 310, comparing it to the inequality on line 227. This is a clear and actionable suggestion that the authors can easily address by correcting the sign of the inequality. Overall, the comment provides some helpful feedback but could be more comprehensive and actionable to fully assist the authors in improving their draft. Therefore, it is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values. It also recommends including a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space. These suggestions are clear and provide concrete guidance on how the authors can improve their draft. The comment is fully actionable, as it directly instructs the authors on what specific actions to take to strengthen their paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Shapely values\" and \"other methods,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for a comparison with methods like CaCE or raw gradients, as well as a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the authors need to provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument. It also suggests including a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space. While the comment provides a logical reasoning for the need for such comparisons and discussions, it lacks specific examples or references to support the claims. The absence of detailed examples or references makes it 3, as the authors would need to infer the need for these comparisons and discussions. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by recommending a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support the argument for using Shapely values. It also suggests including a discussion on the advantages and disadvantages of transforming highdimensional data to lowdimensional latent space, which could make the methods more or less suitable for certain tasks, datasets, or applications. These suggestions are clear and actionable, offering the authors a clear path to enhance the depth and rigor of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct the comparison or discuss the advantages and disadvantages. Despite this, the feedback is 4 as it directs the authors towards important areas for improvement, making it a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that Appendix A.2 does not illustrate the state space representation of the environment clearly. While it points out a specific area that needs improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the representation in the appendix, but without specific suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment explicitly mentions \"Appendix A.2,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies that the appendix does not illustrate the state space representation of the environment clearly, offering a clear and specific critique. This feedback is 5, allowing the authors to understand exactly what needs to be improved. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the state space representation illustrated in Appendix A.2. This feedback is clear and actionable, as it directs the authors to improve the clarity of their appendix. However, it lacks broader context or suggestions for how to enhance the representation, such as providing more detailed explanations or examples. While the comment is 3, it could be more comprehensive if it offered additional guidance or suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors\" approach is only applicable to small or mediumscale problems and may not be suitable for largescale problems due to the limitations of current LPsolvers. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might adapt their approach or what changes could be made to make it applicable to larger problems. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the authors\" approach is only applicable to small or mediumscale problems, implying that it may not be suitable for largescale problems due to the limitations of current LPsolvers. However, the comment does not specify which part of the paper this issue is discussed or addressed, leaving the authors uncertain about the exact section or aspect that needs attention. The comment is specific in its critique of the approach\"s applicability but lacks grounding as it does not provide clear guidance on which part of the paper to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" approach is only applicable to small or mediumscale problems and may not be suitable for largescale problems due to the limitations of current LPsolvers. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of this critique or how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the authors\" approach, noting that it is only applicable to small or mediumscale problems and may not be suitable for largescale problems due to the limitations of current LPsolvers. This feedback is 3 as it highlights a potential constraint on the applicability of the authors\" method. However, it lacks depth and actionable suggestions for the authors to address this issue. The comment does not provide guidance on how the authors might adapt their approach or what changes could be made to make it applicable to larger problems. As a result, while it points out a limitation, it does not offer a comprehensive or constructive response, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the motivation need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not specify which part of the paper discusses this motivation, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is specific in identifying the issue but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the overall motivation of using characteristic function regularization is not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the motivation is unclear or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the motivation behind using characteristic function regularization. However, it lacks specific details or suggestions on how the authors might address this issue or what aspects of the motivation need clarification. Without actionable guidance or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It claims that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the paper or what specific aspects need to be addressed to enhance the contribution. As a result, the comment is 1, as the authors are left without a clear path forward to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the combination of existing techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a detailed description of the techniques used and suggests that the combination of these techniques is not surprising, implying that the contribution might be incremental. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or evidence to substantiate the assertion that the combination of these techniques is not surprising or that the contribution is incremental. As a result, the claim is 1 due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper by suggesting that the combination of existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets, might not be surprising. This observation implies that the contribution of the paper could be considered incremental. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. While it raises a valid concern, the feedback lacks actionable insights, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits its overall impact."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any specific guidance or suggestions on how the authors should address these issues. The comment lacks explicit actions or concrete steps that the authors can take to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to resolve the identified issues. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies several writing issues, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which part of the paper these issues are present in, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is 1 as it does not provide specific references or sections of the paper that need attention. Additionally, it lacks specificity in detailing the nature of the writing issues, such as examples of unclear sentences or specific grammatical errors. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper contains severe writing issues such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide any specific examples or references to support these claims. Without detailed examples or references, the authors may find it challenging to understand the nature and extent of the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies significant writing issues in the paper, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it lacks specific details or suggestions on how the authors might address these issues. While it highlights areas for improvement, the comment does not provide actionable guidance or examples of how to correct the identified problems. This limits the authors\" ability to effectively improve their draft, making the comment 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit instructions for the authors to address specific issues in their draft. It instructs them to run experiments for untrained networks and add the results to the figures and Table 1. Additionally, it requests clarification on whether the figures show results for networks trained on random data or unaltered data, and whether the nonrandom data is normalized. The comment is clear and provides concrete steps for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3) mentioned above,\" which implies a specific part of the paper being addressed. It also specifies what needs to be addressed, such as running experiments for untrained networks and adding results to figures and Table 1. The request for clarification regarding the use of random data and normalization is also clearly detailed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the importance of figures showing results for untrained networks and requests clarification on the use of random data and normalization. While the comment is clear and specific, it does not provide any evidence or reasoning to support the claim that the figures should include results for untrained networks. The request for clarification is logical but lacks detailed examples or references, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the draft, highlighting the importance of including results for untrained networks in the figures and Table 1. It also requests clarification on the use of random data and normalization, which are crucial for understanding the experimental setup. The comment is clear and detailed, offering concrete suggestions for improvement, making it 5 for the authors to enhance their draft. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The authors are advised to repeat the experiments and conduct statistical significance analysis. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific experiments to repeat or how to perform the statistical analysis. While the action is somewhat inferred, it lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the improvement over previous methods, noting that it is small, about 0.2%1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, and the statistical significance of the results is difficult to determine. The comment suggests repeating the experiments and conducting statistical significance analysis. However, the comment does not specify which parts of the paper these issues are located in, making it weakly grounded. It is specific in detailing the issues with the results and suggesting improvements, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement over previous methods is small, about 0.2%1%, and that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The comment suggests repeating the experiments and conducting statistical significance analysis. However, the claim lacks specific examples or references to support the assertion about the small improvement or the absence of mean and standard deviation in the results. Without detailed evidence or examples, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, noting that the improvement over previous methods is marginal, with a range of 0.2%1%. It also points out that the results presented in Table 1 and Fig. 5 lack crucial information such as mean and standard deviation, making it challenging to assess the statistical significance of the findings. The comment suggests repeating the experiments and conducting statistical significance analysis to address these issues. While the feedback highlights specific areas for improvement, it lacks detailed guidance on how to implement these suggestions or what specific changes should be made to the experiments or analysis. This makes the comment 3, as it provides a clear direction for improvement but could be more comprehensive with additional details. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the approach section is missing in the main paper, which is a clear indication of an action the authors should take. It also suggests that the supplementary material should be used as additional information rather than an extension of the paper. This feedback provides a direct and concrete action for the authors to improve their draft by ensuring all necessary sections are included and appropriately referenced. The comment is fully actionable as it clearly specifies what needs to be addressed and how to do it. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach section\" in the main paper, allowing the authors to accurately identify the part being addressed. It also specifies that the supplementary material should be used as additional information rather than an extension of the paper, providing clear guidance on what needs to be addressed. This level of detail ensures that the authors understand exactly what part of the paper requires revision and how to do it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach section is missing in the main paper, which is a factual observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. The comment lacks detailed reasoning or evidence, which could be improved by providing specific examples or references. Therefore, the claim is considered 2, as it is somewhat supported but lacks key elements for full verification.", "helpfulness_rationale": "The review comment identifies a significant issue with the draft, specifically noting the absence of an \"approach section\" in the main paper. It also suggests that the supplementary material should be treated as additional information rather than an extension of the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, the comment could be more helpful if it included suggestions for how to integrate the supplementary material or clarify its role in the paper. Overall, the comment is 4 as it highlights a critical oversight and offers a clear path for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should revise the statement or what specific changes are needed to make it more robust. While the authors can infer that they should strengthen the statement, the lack of concrete suggestions or examples makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the statement in the introduction regarding the biological plausibility of backpropagation, suggesting that it is too weak and that it is widely accepted that backpropagation is biologically implausible. However, the comment does not specify which part of the introduction contains this statement, making it difficult for the authors to pinpoint the exact area that needs revision. While the authors can infer that the critique applies to the introduction, the lack of explicit grounding makes the comment weakly grounded. The comment is specific in its critique of the statement\"s weakness, but without clear grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is too weak, suggesting that it is widely accepted that backpropagation is biologically implausible. This claim is 3 as it provides a logical reasoning that the statement is weak and lacks depth. However, it does not offer specific examples or references to support the claim, which could enhance its persuasiveness. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction, noting that the statement regarding the biological plausibility of backpropagation is too weak and that it is widely accepted that backpropagation is biologically implausible. This feedback is clear and actionable, as it provides a direct critique of the statement and suggests that it should be strengthened to better reflect the established understanding in the field. By highlighting this discrepancy, the comment offers a clear direction for improvement, allowing the authors to enhance the accuracy and depth of their introduction. Therefore, the comment is 4, as it provides a clear and constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper\"s exploration of the proposed method\"s implications for other NLP tasks is limited, which somewhat limits the generalizability of the results. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to explore the method\"s implications for other NLP tasks. The action is implicit and vague, as it does not specify how the authors can enhance the exploration of the method\"s implications. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"contrastive learning in code search tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a limitation in the paper by pointing out that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is 3 as it highlights a potential area for further exploration and could guide the authors in expanding the scope of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this limitation, such as suggesting additional experiments or analyses that could be conducted to explore the method\"s implications for other NLP tasks. Overall, the comment is 3, as it offers a clear direction for improvement but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used, indicating an interest in demonstrating the method\"s effectiveness in such settings. However, the comment does not provide explicit guidance on how to address this issue or what specific steps the authors should take to incorporate real data into their experiments. While the suggestion is clear, the lack of detailed instructions or examples makes it somewhat vague and leaves the authors with limited actionable information. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments being limited to toy data, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the method\"s performance should be evaluated on real data where barycenters can be used, indicating a clear need for additional experiments. This provides specific guidance on what the authors should consider doing to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests evaluating the method\"s performance on real data where barycenters can be used. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are conducted on toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used, which is an interesting and relevant area for further exploration. While the comment highlights a potential area for improvement, it does not provide specific guidance on how to conduct these additional experiments or what specific aspects of the method should be evaluated on real data. This feedback is 3 as it points out a potential area for enhancement, but it lacks detailed actionable suggestions, making it less comprehensive. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should conduct additional experiments to include these network structures. However, the comment does not specify which experiments should be conducted or how the results should be presented. The action is implicit and somewhat vague, as the authors need to infer the exact nature of the additional experiments. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider including these experiments. However, the comment does not specify which parts of the paper these additional experiments should be conducted on, making it weakly grounded. The comment is specific in suggesting the need for more experiments on specific network structures, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific details on how these experiments should be conducted or what results should be expected. The references provided are relevant, but the comment does not offer a clear rationale or detailed explanation of why these additional experiments are necessary. Therefore, the claim is 3, as it is supported by references but lacks detailed reasoning or examples.", "helpfulness_rationale": "The review comment suggests that more experiments on deeper networks, such as ResNet50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific guidance on how these experiments should be conducted or what results should be expected. While it identifies an area for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. While it highlights a potential area for clarification, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need to be explained. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the mechanism. However, the comment lacks concrete details on how to improve the explanation, making it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or aspect that needs clarification. The comment is specific in its critique but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind the proposed sample selection mechanism and its effectiveness in preserving label distribution. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left to infer the validity of the critique, making it difficult to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed sample selection mechanism, specifically questioning its effectiveness in preserving label distribution. This feedback highlights a critical aspect of the methodology that needs clarification or further explanation. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it points out a potential area for improvement, it does not offer actionable advice or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the evaluation of the results, noting that while the analysis is detailed and comprehensive, it only considers two relatively old and small models. This feedback provides a clear and explicit action for the authors to take, which is to expand the evaluation to include more recent and larger models. The comment is specific in its suggestion, offering concrete guidance on how to enhance the evaluation process. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the results/analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the evaluation is limited to two relatively old and small models, which the authors can address by expanding their evaluation to include more recent and larger models. This provides clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results/analysis, despite being detailed and comprehensive, are limited to the evaluation of only two relatively old and small models. This claim is 3 as it provides a specific observation about the scope of the evaluation. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors could benefit from additional context or examples to understand the limitations of the evaluation more clearly.", "helpfulness_rationale": "The comment identifies a specific limitation in the evaluation of the results, noting that despite being detailed and comprehensive, the analysis is limited to only two relatively old and small models. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors should expand their evaluation to include more recent and larger models. By addressing this limitation, the authors can enhance the comprehensiveness and relevance of their results, making the paper more impactful. Therefore, the comment is 4, as it offers clear guidance on how to improve the evaluation process."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a belief that KD can be viewed as a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting how to incorporate this perspective into their work or providing further clarification. The comment lacks concrete guidance on how the authors might address this point or integrate it into their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It makes a claim about the relationship between KD and LS, but without referencing specific sections or elements of the paper, the authors cannot confidently determine where this comment applies. The comment is also not specific because it does not detail what needs to be addressed or how the authors should respond to this claim. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point makes a claim about the relationship between KD and LS, suggesting that KD can be viewed as a special form of LS under specific conditions. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the claim remains unsubstantiated, making it difficult for the authors to understand or address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a belief that KD can be viewed as a special form of LS under specific conditions, such as when the teacher network is uniformly distributed and the temperature is set at 1. However, the comment does not provide any actionable feedback or suggestions on how the authors might incorporate this perspective into their work or address any potential implications. It lacks depth and does not offer guidance on how the authors could improve their understanding or presentation of the relationship between KD and LS. As a result, the comment is not helpful to the authors in terms of providing meaningful insights or actionable advice. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to provide an explanation for the degradation in performance of the FBN results when additional information is included. While it prompts the authors to address this issue, it does not explicitly instruct them on how to do so or provide specific guidance on what aspects to consider. The action is implicit, as the authors need to infer that they should analyze and explain the performance degradation. However, the lack of concrete details on how to approach this analysis makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FBN results (table 5),\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it asks the authors to provide an explanation for the degradation in performance when additional information is included, which is a clear and actionable request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the degradation in FBN results when additional information is included. However, it does not provide any specific reasoning, examples, or references to support why this degradation might occur. The comment lacks detailed justification or explanation, making it difficult for the authors to understand the basis of the issue or how to address it. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the FBN results, noting that the performance degrades when additional information is included. This observation is clear and highlights a potential area for further investigation or clarification. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what steps they could take to improve the results. While it points out a problem, it does not provide detailed feedback or constructive advice, making it 3. The authors would need to infer that they should analyze the performance degradation and consider potential reasons for it, but the comment does not offer specific guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the paper argues that the proposed method finds flat minima, but the analysis about flatness is missing. It highlights that minimizing the averaged loss across noiseinjected models does not ensure the flatness of the minima. The comment suggests that to claim the minima found by minimizing the loss in Eq (3), an analysis on the losses of the noiseinjected models after training is required. This provides a clear and explicit action for the authors to take, which is to conduct additional analysis on the losses of the noiseinjected models. The action is concrete as it specifies exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the analysis about flatness is missing, allowing the authors to accurately identify the section being addressed. It also specifies what needs to be addressed, namely the lack of analysis on the losses of noiseinjected models after training. This provides clear guidance on how the authors should improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that minimizing the averaged loss across noiseinjected models does not ensure the flatness of the minima, and it suggests that an analysis on the losses of the noiseinjected models after training is required to support the claim that the minima found by minimizing the loss in Eq (3) are flat. The comment provides a logical reasoning by explaining why the current analysis is insufficient and what additional analysis is needed. However, it lacks specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that while the paper argues that the proposed method finds flat minima, the analysis supporting this claim is missing. It highlights that minimizing the averaged loss across noiseinjected models does not guarantee flatness and suggests that an analysis on the losses of these models after training is necessary to substantiate the claim. This feedback is clear, actionable, and provides a specific direction for the authors to improve their draft by conducting additional analysis. The comment is 4 as it offers a detailed and constructive suggestion, though it could be further expanded to include more specific guidance on how to conduct the analysis. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue with the readability of the text within a figure and its labels, suggesting that the text should be of the same size as the manuscript text. This feedback is explicit, as it directly instructs the authors to address the issue by adjusting the size of the text. It is also concrete, as it provides a clear and specific action to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the readability of the text within a figure and its labels, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely that the text should be roughly the same size as the manuscript text. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the text inside the figure and the labels are too small to read without zooming, suggesting that the text should be roughly the same size as the manuscript text. This claim is 3 as it provides a specific observation about the readability of the text, but it lacks detailed reasoning or examples to fully support the suggestion. The authors would need to infer the need for improvement based on the comment, which could be more effective with additional justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of the text within a figure and its labels, noting that the text is too small to read without zooming. It suggests that the text should be roughly the same size as the manuscript text. This feedback is clear and actionable, providing the authors with a direct and specific direction for improvement. By addressing this issue, the authors can enhance the clarity and accessibility of their figures, which is crucial for effective communication of their results. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the use of multiple local prompts, suggesting that while it is intuitive, the features and their positions vary across different categories. However, it does not provide explicit guidance or suggestions on how to address this issue or what specific changes should be made to the draft. The comment lacks concrete actions or detailed instructions for the authors, leaving them uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of using multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or figure that needs attention. The comment is specific in its critique but lacks grounding as it does not provide clear references or guidance on how to address the issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that while it is intuitive that including multiple local prompts helps, the features and their positions are not the same for different categories. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the draft to clarify or improve the presentation of these features. While it points out a valid concern, the feedback could be more helpful if it provided actionable advice or examples of how to improve the clarity of the paper. Therefore, the comment is 3, as it identifies a meaningful issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It also recommends improving the presentation, possibly by referencing the supplement. The comment further suggests replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. These suggestions are explicit and provide concrete guidance on how the authors can improve their draft. The actions are clear and detailed, allowing the authors to understand exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation, possibly by referencing the supplement. The suggestion to replace natural language descriptions with notation and add breakout diagrams to illustrate attention mechanisms is also provided. However, the comment does not specify which part of section 4 is particularly challenging or where the complexity lies, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the suggestions for improvement, the lack of grounding makes it challenging for the authors to fully understand the scope of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the model is somewhat complicated and that its presentation in section 4 requires careful reading. It recommends improving the presentation, possibly by referencing the supplement, and suggests replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment provides some guidance on how to improve the presentation, it lacks specific examples or detailed reasoning to fully substantiate the claim that the model is complicated or that the presentation requires careful reading. The suggestions for improvement are somewhat vague and could benefit from more detailed explanations or examples. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of the model and suggests ways to improve its presentation in section 4. It recommends replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms, which could enhance clarity and understanding. While the comment provides specific suggestions for improvement, it could be more helpful if it included additional guidance on how to effectively implement these changes or if it addressed other potential weaknesses in the paper. Overall, the feedback is 4 as it offers actionable advice, but it could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the paper, noting that the experiments are conducted on a limited number of molecules and only include indistribution testing. The reviewer suggests that the value of the method might be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance on how the authors might address this issue or what steps they should take to improve the method. The action is implicit and vague, as it does not specify how the authors can overcome the limitation or what changes they should make to the method. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of limited experiments on a small number of molecules and the lack of indistribution testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the limitation of the experiments and suggests that the value of the method might be limited if it requires training for each molecule individually. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only conducts experiments on a limited number of molecules and only provides indistribution testing. This is a factual observation about the scope of the experiments. However, the comment does not provide any reasoning, examples, or references to support why this limitation is significant or how it might impact the value of the method. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically that the experiments are conducted on a limited number of molecules and only include indistribution testing. This observation is clear and highlights a potential constraint on the method\"s value. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve the scope of their experiments. While it points out a weakness, it lacks actionable advice, making it 3. The authors would need to infer how to improve their draft based on this feedback, which limits the comment\"s usefulness."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the symbols used in the paper are complicated and timeconsuming to understand. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might simplify the symbols or make them more accessible to readers. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the symbols used in the paper are complicated and timeconsuming to understand. However, it does not specify which part of the paper contains these symbols, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the complexity of the symbols but lacks grounding as it does not provide context or references to specific sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the symbols used in the paper are complicated and timeconsuming to understand. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to verify or address the issue effectively. Without detailed reasoning or evidence, the claim remains unsubstantiated, rendering it 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of symbols used in the paper, which could hinder understanding. However, it lacks specificity and actionable suggestions for improvement. The authors are left without guidance on how to simplify the symbols or make them more accessible to readers. While the feedback points out a potential area for enhancement, it does not provide concrete steps or examples to address the issue, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. While the comment identifies a potential issue with the clarity of the figure, it does not provide explicit guidance on how the authors should address this question or what changes might be needed. The action is implicit, as the authors would need to infer that they should clarify the source of the test data and the presence of a ground truth. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the red line in Figure 3, questioning the source of the test data and the presence of a ground truth. This provides the authors with a clear understanding of what needs to be clarified or addressed. Therefore, the comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the red line in Figure 3, specifically asking where the test data comes from and whether there is a ground truth. This is a factual question that requires clarification but does not contain any subjective opinions, suggestions, or judgments. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, questioning the source of the test data and the presence of a ground truth. This feedback is clear and actionable, as it directs the authors to clarify the figure\"s content and ensure that the data is welldefined and understandable. However, the comment could be more helpful if it provided additional guidance on how to address the issue or suggested specific ways to improve the clarity of the figure. Despite this, the feedback is 4 as it highlights a critical area for improvement, allowing the authors to enhance the clarity and comprehensiveness of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, is used in most experiments, except for Experiment 1b, where the relationships involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. While the comment poses a question that could lead to further exploration, it does not provide explicit guidance on how to address this question or what actions the authors should take to investigate it. The action is implicit and vague, as the authors are left to infer how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It specifically mentions that the comparison model cannot capture periodic relationships and that most experiments, except for Experiment 1b, involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the role of periodicity in the results, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It highlights a specific aspect of the comparison model and questions whether adding periodicity to the spectral kernel could improve its performance. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this question or explore the impact of periodicity on their results. Without actionable advice or a clear path forward, the comment is 2, as it leaves the authors without a clear understanding of how to improve their draft. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions regarding the alignment of results in Table 6 with Table 1 and the inclusion of ablation studies for MCT without adaptive metrics. While the questions highlight areas that need clarification or additional analysis, they do not provide explicit instructions or suggestions on how to address these issues. The authors are left to infer that they should investigate the discrepancies and include the ablation studies, but the lack of concrete guidance makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment raises two questions regarding the alignment of results in Table 6 with Table 1 and the inclusion of ablation studies for MCT without adaptive metrics. However, it does not specify which part of the paper these tables are located in, nor does it provide any guidance on how to address these issues. The authors are left to infer that these questions pertain to specific sections of the paper, but without explicit references, they cannot confidently determine which parts need attention. Additionally, the questions are specific in nature, as they ask for clarification and additional analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the alignment of results in Table 6 with Table 1 and the inclusion of ablation studies for MCT without adaptive metrics. However, it does not provide any specific reasoning, examples, or references to support why these questions are important or how they should be addressed. The comment lacks detailed justification or context, making it difficult for the authors to understand the significance of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two specific questions regarding the alignment of results in Table 6 with Table 1 and the inclusion of ablation studies for MCT without adaptive metrics. While these questions highlight potential areas for clarification or additional analysis, they do not provide actionable guidance or suggestions on how to address these issues. The authors are left to infer that they should investigate the discrepancies and include the ablation studies, but the comment lacks depth and specificity, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the 10 subtasks in the paper are too simplistic for the bAbi task and that the final model could solve all of them. However, it does not provide any explicit or implicit guidance on how the authors should address this issue or what specific changes are needed to make the subtasks more challenging or relevant. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the 10 subtasks are too simplistic for the bAbi task and that the final model could solve all of them. However, it does not specify which part of the paper these subtasks are discussed in, making it difficult for the authors to identify the exact section or figure that needs revision. While the comment is specific about the issue of simplicity in the subtasks, it lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the 10 subtasks are too simplistic for the bAbi task and that the final model could solve all of them. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the complexity of the 10 subtasks used in the bAbi task. It suggests that these subtasks might be too simplistic for the final model, implying that they do not adequately challenge the model\"s capabilities. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or make the subtasks more challenging. Without actionable advice or examples, the authors may find it difficult to improve their draft based on this feedback. Therefore, the comment is 2, as it points out a potential area for improvement but does not provide sufficient direction for the authors to act upon."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is possible. While the comment implies that the authors should consider this limitation, it does not provide explicit guidance on how to address it or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration or discussion. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, it does not specify which part of the paper this restriction is discussed in, making it difficult for the authors to pinpoint the exact section or context. The comment is specific in its inquiry about the limitation but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation or that an extension to longer subsequences is straightforward. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to interpret the question as a potential area for further exploration or discussion, but the claim itself is not substantiated. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the restriction to triplets or a sliding window of length 3, suggesting that it might be a fundamental limitation of the approach or that an extension to longer subsequences is straightforward. This question prompts the authors to consider the implications of this restriction and whether it could be addressed or expanded upon. While the comment does not provide specific guidance or suggestions for improvement, it does highlight a potential area for further exploration or discussion, which could be valuable for the authors to consider. Therefore, the comment is 3, as it identifies a potential area for improvement but lacks detailed guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the term \"sequence of episodes\" used in the paper, specifically asking for clarification on whether \"practice\" and \"evaluation\" are the two types of this sequence. It also mentions that the paper seems related but does not negate its novelty. While the comment explicitly asks for clarification, it does not provide concrete guidance on how the authors should address this question or what specific aspects of the term need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term and its types. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L167,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by asking for clarification on the term \"sequence of episodes\" and whether \"practice\" and \"evaluation\" are the two types of this sequence. Additionally, it mentions that the paper seems related but does not negate its novelty, which provides context for the authors to understand the relevance of the comment. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the term \"sequence of episodes\" and suggests that the paper might be related to existing work. However, it does not provide specific examples or references to support the claim that the paper is related. The lack of detailed reasoning or evidence makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the term \"sequence of episodes\" used in the paper, specifically asking for clarification on whether \"practice\" and \"evaluation\" are the two types of this sequence. It also suggests that the paper might be related to existing work, which could be relevant for the authors to consider. However, the comment lacks detailed guidance or suggestions on how the authors might address this question or explore the related work. While it identifies an area for clarification, it does not provide actionable steps or insights that would significantly enhance the authors\" understanding or improve their work. Therefore, the comment is 3, as it points out a specific area for clarification but does not offer comprehensive guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes might be necessary. The comment lacks concrete guidance on how to revise the study or clarify its nature. As a result, the authors are left without a clear understanding of what action to take to address the concern. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect being discussed. The comment is vague and lacks specificity, as it does not provide any details on what needs to be addressed or how the study should be revised. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the study is not an ablation study. As a result, the claim is not wellsupported, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. This feedback is 3 as it identifies a potential issue with the study\"s categorization, which could be important for the authors to clarify. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. Without actionable advice or examples, the authors may struggle to understand the implications of the comment and how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could potentially improve the model. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the model should be considered. The action is implicit, as the authors need to infer that they should explore the possibility of integrating AccNet into a larger predictor. While the suggestion is concrete in terms of the idea, the lack of detailed guidance on implementation makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 126\" and the section \"Further Questions,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a potential improvement by including and learning AccNet as part of a larger predictor for semantic segmentation, which could enhance the model. This provides clear guidance on what needs to be addressed and how the suggestion could be implemented. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests including and learning AccNet as part of a larger predictor for semantic segmentation. However, it does not provide any specific reasoning, examples, or references to support why this suggestion would be beneficial or how it could be implemented. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the claim is 1.", "helpfulness_rationale": "The review comment suggests including and learning AccNet as part of a larger predictor for semantic segmentation, which could potentially improve the model. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the model should be considered. While it identifies a potential area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a direction for improvement but lacks depth and specificity. The authors would need to infer the exact steps to follow, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the new proposed metric, noting that it is only tested on a single dataset. This feedback suggests that the authors should consider expanding the evaluation to include more datasets to provide a more comprehensive assessment of the metric. However, the comment does not specify which additional datasets should be included or how this expansion would be implemented. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct further testing. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a limitation of the new proposed metric, noting that it is only tested on a single dataset. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in identifying the issue with the metric\"s testing, the absence of explicit references to the paper makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the new proposed metric is only tested on a single dataset. This is a factual observation, as the paper does not provide evidence of testing on multiple datasets. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to verify this claim by examining the experimental setup described in the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the new proposed metric, noting that it is only tested on a single dataset. This feedback is valuable as it highlights a potential area for improvement in the paper, suggesting that the authors should consider expanding their evaluation to include more datasets. However, the comment lacks specific guidance on which additional datasets to include or how this expansion would be implemented. While it provides a clear direction for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It also provides references to support the claim that these issues hinder understanding. The comment explicitly suggests that these issues need to be addressed by defining the abbreviations and clarifying the notation. However, it does not provide detailed guidance on how to define these terms or notation, leaving the authors to infer the necessary actions. The action is explicit but somewhat vague, as it lacks concrete steps on how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as \"L73\" and \"Eq 6,\" allowing the authors to accurately identify the sections being addressed. It also provides references to external works, which are relevant to the issues raised. The comment specifies what needs to be addressed, such as defining abbreviations and clarifying notation, making it specific. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some abbreviations are not defined, specifically mentioning \"NE\" on L73 and the superscript notation in Eq 6, which is only defined later in the paper. The comment also provides references to external works that are relevant to the issues raised. However, the claim lacks detailed reasoning or examples to fully support the assertion that these omissions hinder understanding. While the references provide context, the comment could be more robust with additional examples or detailed explanations to enhance verifiability. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific issues with the paper: the lack of definition for abbreviations like \"NE\" and the delayed definition of superscript notation in Equation 6. It also provides references to relevant works, which could help the authors understand the context and importance of these issues. By highlighting these areas, the comment offers actionable feedback that could guide the authors in improving the clarity and comprehensibility of their paper. However, the comment could be more helpful if it provided more detailed guidance on how to define the abbreviations or clarify the notation. Overall, the feedback is 3, as it points out areas for improvement but lacks depth in suggesting specific solutions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any specific guidance or suggestions on how the authors should address this issue. The comment lacks explicit actions or concrete steps that the authors can take to improve their evaluation methodology. As a result, the authors are left without a clear understanding of what changes are needed to strengthen their evaluation. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the relevant section. Additionally, the comment is not specific because it does not detail what aspects of the evaluation are weak or why the baselines are not suitable for fair classification. Without specific guidance or examples, the authors cannot effectively address the issue. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment lacks specific details or examples to support this claim. It does not provide any references or logical reasoning to substantiate the assertion that the baselines are unsuitable for fair classification. Without such evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the evaluation methodology, specifically that the baselines used are not designed for fair classification. However, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their evaluation. Without specific recommendations or examples, the authors may find it challenging to understand the implications of this critique and how to enhance their work. Therefore, the comment is 2, as it points out a problem but does not provide actionable feedback to improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It also implies that the authors might be overstating the generality of their work, which could muddle the exposition. However, the comment does not provide explicit guidance on how to clarify the setting or address the issue of overstating generality. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first three paragraphs of section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the need to spell out the setting more clearly and the concern about overstating generality. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2, suggesting that the authors might be overstating the generality of their work. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or evidence, the claim is considered 2, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the setting in the first three paragraphs of section 2, suggesting that the authors may be overstating the generality of their work. This feedback is clear and actionable, as it provides a specific area for improvement and highlights a potential issue with the exposition. However, the comment could be more helpful if it offered suggestions on how to clarify the setting or address the concern about overstating generality. Despite this, the feedback is 4 as it directs the authors to a critical area that needs attention, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the choice of using older baselines like R3D and C3D for the experiments, suggesting that more recent 3D CNNs have been proposed to reduce computational complexity. It asks whether the proposed method works on these newer 3D CNNs and what advantages it offers compared to them. While the comment identifies a potential issue with the choice of baselines and suggests further exploration, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of using older baselines like R3D and C3D for the experiments, suggesting that more recent 3D CNNs have been proposed to reduce computational complexity. It asks whether the proposed method works on these newer 3D CNNs and what advantages it offers compared to them. However, the comment does not specify which part of the paper discusses the choice of baselines or the experimental setup, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of using older baselines, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of using older baselines like R3D and C3D for the experiments, suggesting that more recent 3D CNNs have been proposed to reduce computational complexity. It asks whether the proposed method works on these newer 3D CNNs and what advantages it offers compared to them. However, the comment does not provide any specific reasoning, examples, or references to support the claim that the choice of baselines is questionable or that the proposed method is advantageous over newer approaches. Without detailed justification or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid concern about the choice of baselines used in the experiments, specifically questioning the use of older models like R3D and C3D. It suggests that more recent 3D CNNs have been proposed to reduce computational complexity and asks whether the proposed method works on these newer models or what advantages it offers compared to them. This feedback is 3 as it identifies a potential area for improvement and encourages the authors to consider more contemporary baselines. However, the comment could be more helpful if it provided specific examples of recent 3D CNNs or suggested alternative approaches for comparison. Overall, the comment offers a starting point for the authors to enhance their experimental evaluation, but it lacks depth and specificity, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the implementation details of the attention module\"s integration with the ResNet20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed (e.g., after each block or stage). While the comment explicitly asks for clarification, it does not provide any guidance on how the authors should address these questions or what specific changes might be needed. The action is implicit and vague, as the authors are left to infer that they need to clarify these details in their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the implementation details of the attention module\"s integration with the ResNet20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not specify which part of the paper these details are discussed or where the authors should provide this clarification. This makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific about the content it addresses, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the implementation details of the attention module\"s integration with the ResNet20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not provide any evidence or reasoning to support why these details are important or how they impact the paper. It lacks specific examples or references, making it difficult for the authors to understand the basis of the concern. As a result, the claim is not verifiable, and the comment does not provide actionable guidance for improvement. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment raises specific questions about the implementation details of the attention module\"s integration with the ResNet20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed, such as after each block or stage. This feedback is 3 as it points out a lack of clarity in the paper\"s description of the attention module\"s integration, which could hinder understanding and reproducibility. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address these questions or improve the clarity of their explanation. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions: first, it questions the performance of the proposed method at low bitrate compared to baselines, and second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The first part of the comment is explicit, as it directly asks for clarification on the precise bitrate range used for BDrate comparison. However, the second part, while suggesting a related work, does not provide explicit guidance on how to incorporate or discuss this work. The action is somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises two specific questions about the performance of the proposed method at different bitrates and suggests a related work for discussion. However, it does not explicitly mention which part of the paper these questions or suggestions relate to, making it weakly grounded. The questions are specific, as they ask for clarification on the bitrate range and suggest a relevant related work. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: first, it questions the performance of the proposed method at low bitrate compared to baselines, and second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The first part of the comment is a question that requires the authors to clarify the precise bitrate range used for BDrate comparison, which is a logical and verifiable request. The second part suggests a related work, which is a common practice in academic writing to provide context and comparison. However, the comment lacks specific examples or references to support the suggestion, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the performance of the proposed method at different bitrates, noting that it is stronger at high bitrate but close to baselines at low bitrate. This observation is valuable for the authors to understand the limitations of their method. Additionally, the comment suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, which could provide further context and insights. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate or discuss this related work. Overall, the feedback is 3 as it identifies an area for improvement and suggests a relevant comparison, but it lacks depth and actionable suggestions for the authors to fully address the feedback."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point recommends that the authors distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This recommendation provides a clear and explicit action for the authors to take, as they need to clarify the distinction between these two concepts in their paper. The action is concrete, as it specifies exactly what needs to be done to improve the clarity of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction should be made in, nor does it provide any guidance on how to achieve this distinction. The comment lacks grounding as it does not identify a specific section or element of the paper that needs attention. It is also not specific because it does not provide detailed instructions or examples on how to make the distinction. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should distinguish the allornothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This feedback is 3 as it identifies a potential area for clarification that could enhance the paper\"s understanding. However, the comment lacks specificity and does not provide detailed guidance on how to make this distinction or what aspects of the paper need to be addressed. Without more detailed suggestions or examples, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the improvements on three tasks over previous works and selfimplemented baselines are marginal, and that further analysis beyond the main experiments is not sufficient. However, it does not provide explicit or implicit actions for the authors to take. The comment implies that the authors should conduct more analysis, but it does not specify how to do so or what kind of analysis would be beneficial. Without concrete guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"improvements on three tasks over the previous works and selfimplemented baselines,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the issue of marginal improvements and the need for further analysis beyond the main experiments. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the improvements on three tasks over previous works and selfimplemented baselines are marginal, and that further analysis beyond the main experiments is not sufficient. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically noting that the improvements on three tasks over previous works and selfimplemented baselines are marginal. It also points out that the analysis beyond the main experiments is not sufficient. While the comment highlights a concern, it lacks specific suggestions or guidance on how the authors might address these issues or what additional analysis could be conducted to strengthen the paper. Without actionable advice or detailed feedback, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is 3, as it provides a clear area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the proof of Theorem 8 or provide a clearer explanation of how the linear convergence rates are derived. This lack of explicit action makes the comment 3, as it points out a specific area that needs attention but does not offer concrete steps on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 8,\" which is located at the end of the appendix. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a particular issue with the linear convergence rates, noting that the proof of Theorem 8 is not clear enough. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that all linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This claim is 3 as it points out a specific issue with the paper, but it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the basis for this claim, which could be improved by providing more context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the linear convergence rates rely on Theorem 8, which is located at the end of the appendix and whose proof is not clear enough. This feedback is 3 as it highlights a potential area for improvement, specifically the clarity and presentation of the proof of Theorem 8. However, the comment could be more helpful if it provided suggestions on how the authors might improve the clarity or presentation of the proof. Without specific guidance or suggestions, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is explicit and specific, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the reporting of results, suggesting the use of the test set instead of the dev set and the inclusion of average results with error bars. This provides detailed guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the authors should present average results on the test set with clearly defined error bars under different random seeds. This claim is 3 as it suggests a specific improvement to the reporting of results, but it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would need to infer the need for such changes to improve the robustness of their results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on the reporting of results in Tables 1 and 2. It highlights a critical issue with the current presentation, noting that the best results are reported on the dev set for both hyperparameter search and model selection, which is insufficient to be convincing. The suggestion to present average results on the test set with clearly defined error bars under different random seeds is clear and constructive, offering a concrete way to improve the robustness and reliability of the results. This feedback is detailed and actionable, providing the authors with a clear path to enhance their paper."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. While the comment explicitly asks for these details, it does not provide any guidance on how the authors should address these questions or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors without clear instructions on how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. However, the comment does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any additional context, reasoning, or references to support the need for these details. The questions are clear and specific, but the lack of supporting evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the methodology and dataset description, specifically asking for clarification on the number of topics used, how topicword parameters were obtained for the \"real\" dataset, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are factual and require the authors to provide specific details about their methodology and dataset. However, the comment does not offer any suggestions or guidance on how the authors might address these issues or improve their draft. While the questions are clear and specific, the lack of actionable feedback limits the comment\"s helpfulness. Therefore, the comment is rated as 2, as it identifies areas for improvement but does not provide sufficient guidance for the authors to make meaningful changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis on BRPNAS is somewhat barebones, as it only compares against 3 basic alternatives and ignores other NAS approaches like supernets or oneshot methods. While the comment identifies a specific area where the analysis could be improved by including more comparisons, it does not provide explicit guidance on how to conduct these additional comparisons or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their analysis to include more comprehensive comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"BRPNAS\" and specifies the issue with the analysis, which is the limited comparison against only 3 basic alternatives and the omission of other NAS approaches like supernets or oneshot methods. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly identifies the need for a more comprehensive comparison, providing specific examples of what should be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis on BRPNAS is \"somewhat barebones\" because it only compares against 3 basic alternatives and ignores other NAS approaches like supernets or oneshot methods. While the comment provides a specific example of what is missing, it lacks detailed reasoning or references to support the claim. The authors are left to infer that the analysis is indeed limited, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the analysis of BRPNAS, noting that it only compares against 3 basic alternatives and omits other NAS approaches like supernets or oneshot methods. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their analysis by including a more comprehensive comparison. By suggesting the inclusion of additional comparisons, the comment offers valuable guidance on how to strengthen the paper. However, it could be more helpful if it provided specific examples of the NAS approaches that should be included or suggested ways to conduct the additional comparisons. Overall, the comment is 4, as it effectively highlights an area for improvement and encourages the authors to expand their analysis."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a preference for the paper\"s focus on fewshot learning over the inclusion of the zeroshot version and its connection to density estimation. It argues that this is more of an aesthetic argument than a technical one. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the paper. It lacks concrete guidance on what changes could be made to align the paper\"s focus with its main point. As a result, the authors are left without actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment expresses a preference for the paper\"s focus on fewshot learning over the inclusion of the zeroshot version and its connection to density estimation. However, it does not specify which part of the paper this preference pertains to, such as a particular section or figure. The comment is vague in its suggestion, as it does not provide specific guidance on how the authors might address this issue or what changes could be made to align the paper\"s focus with its main point. Therefore, the comment is 1 and lacks specificity, making it ungrounded and not specific. This aligns with category 1.", "verifiability_rationale": "The review point expresses a preference for the paper\"s focus on fewshot learning over the inclusion of the zeroshot version and its connection to density estimation. It argues that this is more of an aesthetic argument than a technical one. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the argument or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a preference for the paper\"s focus on fewshot learning over the inclusion of the zeroshot version and its connection to density estimation. The reviewer argues that this is more of an aesthetic argument than a technical one, suggesting that the inclusion of these elements might distract from the main point of the paper. However, the comment lacks specific suggestions or actionable feedback on how the authors might address this issue or improve the paper\"s focus. While it identifies a potential area for refinement, it does not provide detailed guidance or examples to help the authors make informed decisions. As a result, the comment is 3, as it offers a perspective but lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not provide explicit instructions or concrete guidance on how to implement these suggestions. The authors are left to infer that they need to add more diverse attacks and analyze the impact of thresholds, but without specific steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to understand where to address the feedback. While the comment is specific in its suggestions, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, the comment lacks specific details or examples to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without additional context or references, the claim remains 3, as it is based on logical reasoning but lacks concrete evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the experiment results by suggesting that they could be enriched with attacks of varying strengths and by exploring the influence of different thresholds on detection performance. This feedback is 3 as it points out specific aspects that could enhance the depth and comprehensiveness of the experimental analysis. However, the comment lacks detailed guidance or suggestions on how to implement these enhancements, which limits its impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this is different from Figure 4 due to the coadaptation between the discriminator and the generator, which might lead to a local optimum. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific steps the authors should take to train the discriminator. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the need to train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias. This level of detail provides clear guidance on what the authors should do to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that training a discriminator on generations from the learned model is necessary to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes that this is different from Figure 4 due to the coadaptation between the discriminator and the generator, which might lead to a local optimum. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. The absence of clear justification or references weakens the verifiability of the claim. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the claim of reducing exposure bias requires further validation through training a discriminator on generated data, similar to Figure 1. It also highlights a key difference between this approach and Figure 4, emphasizing the potential for the discriminator to get stuck in a local optimum due to coadaptation between the discriminator and the generator. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by addressing the need for additional validation and clarifying the distinction from Figure 4. However, the comment could be more helpful if it included suggestions on how to implement the discriminator training or provide more detailed guidance on the differences between the approaches. Overall, the comment is 4, as it offers valuable insights and actionable feedback that the authors can use to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the impact of using different image sizes and variations of ResNets on the performance difference. While it suggests that the authors should provide more information on this aspect, it does not explicitly instruct the authors on how to address this issue or what specific data or analysis to include. The action is implicit, as the authors need to infer that they should provide more details on the performance differences. However, the comment lacks concrete guidance on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line in the paper (L170), allowing the authors to accurately identify the part being addressed. It also specifies what the authors should know, namely the impact of using different image sizes and variations of ResNets on the performance difference. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the impact of using different image sizes and variations of ResNets on the performance difference. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The comment raises a question about the impact of using different image sizes and variations of ResNets on the performance difference, which is a relevant concern for the authors to address. However, it does not provide any suggestions or guidance on how to investigate or address this issue. The feedback is 3 as it identifies a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. However, it does not provide explicit instructions on how to implement this suggestion or what specific aspects of the runtime comparison should be included. The action is implicit, as the authors can infer that they need to add a runtime comparison, but the lack of detailed guidance makes it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to include a runtime comparison, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is important or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the paper mentions the possibility of using Chebyshev polynomials to achieve a speedup and recommends including a runtime comparison at test time. This feedback is 3 as it points out a potential area for improvement by suggesting a specific experiment or analysis that could enhance the paper\"s impact. However, the comment lacks depth and does not provide detailed guidance on how to conduct the runtime comparison or what specific aspects of the comparison should be included. While it offers a clear direction for improvement, the lack of actionable advice limits its overall helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. While the comment suggests that the method might be limited to digit and text images, it does not provide any explicit or implicit guidance on how the authors might address this limitation or expand the method\"s applicability. The authors are left without a clear direction on how to improve their draft to accommodate natural images. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion to consider the broader applicability of the method, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. While the comment raises a valid concern about the method\"s potential limitations, it does not provide any specific evidence, examples, or references to support the claim that the method is only applicable to digit and text images. This lack of substantiation makes the claim 3, as the authors may need to conduct further research or experimentation to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the applicability of the proposed method to natural images, such as CIFAR10, given that it has been tested on digit and text images like MNIST and SVHN. This feedback highlights a potential limitation or area for improvement in the paper, suggesting that the method\"s applicability might be restricted to specific types of images. However, the comment does not provide any guidance or suggestions on how the authors might address this limitation or expand the method\"s applicability. Without actionable advice or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 3, as it identifies a potential issue but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights issues with the clarity of the figures, specifically mentioning that Figure 2 is confusing due to the relationship between its subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should clarify the relationships between the subfigures and label the missing modules. This lack of explicit action makes the comment 3, as it provides a clear direction but lacks detailed guidance on implementation. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the clarity of the figures, such as the confusion between subfigures and the lack of labels for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed in the figures. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the figures are not clear, specifically mentioning confusion in Figure 2 due to the relationship between subfigures and the lack of labels for modules like CMAF, L_BT, and VoLTA. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors are left to question the validity of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the figures, particularly in Figure 2, where the relationship between subfigures is confusing and certain modules are not labeled. This feedback is clear and actionable, as it provides the authors with specific areas to improve the presentation of their figures. However, the comment could be more helpful if it offered suggestions on how to enhance the clarity or labeling of the figures, such as proposing specific design changes or providing examples of clearer labeling practices. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It also points out that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. The authors are directed to consider the implications of these factors and how they might be addressed in their work. This feedback is concrete and actionable, as it provides specific guidance on how to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It highlights that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. However, the comment does not specify which part of the paper discusses these design choices or where the authors should address the issue of controlling domain drift. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper it addresses. Despite this, the comment is specific in detailing what needs to be addressed, namely the use of perplexity and the control of domain drift factors. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of perplexity as a measure of semantic information retention after finetuning, questioning its relevance to domain drift. It suggests that perplexity, while related to the original task, may not fully capture the complexities of domain drift. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue raised. Therefore, the comment is considered 2, as it lacks sufficient justification or supporting details to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises concerns about questionable design choices, specifically questioning the use of perplexity as a measure of semantic information retention after finetuning. It highlights that while perplexity relates to the original task, there are other aspects of domain drift that are possible and separate from catastrophic forgetting. The comment asks how such factors are controlled, which provides a clear and explicit action for the authors to take. This feedback is actionable and constructive, as it directs the authors to consider the implications of these factors and how they might be addressed in their work. However, the comment could be more helpful if it provided specific examples or guidance on how to control these factors. Overall, the comment is 4, as it offers valuable insights and actionable feedback that can guide the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks how the number of images impacts the model performance, and second, it suggests explaining the BYOL model in the abstract. While the questions are explicit and direct, they do not provide concrete guidance on how to address these issues. The authors are left to infer that they need to conduct further analysis or provide more context on the impact of image numbers and the BYOL model. The lack of specific instructions or suggestions for improvement makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises two questions about the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. However, it does not specify which part of the paper these questions relate to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in that it asks for clarification and suggests an improvement, but the lack of grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises two questions: \"Since the cluster structure is defined by the identity. How does the number of images impact the model performance?\" and \"Do more training images make the performance worse or better?\" These questions are openended and do not provide specific claims or suggestions that require verification. The comment lacks any supporting evidence or reasoning, making it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is classified as \"1\".", "helpfulness_rationale": "The review comment raises two questions about the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. While these questions are relevant and could provide valuable insights for the authors, they are somewhat vague and lack specific guidance on how to address them. The comment does not offer detailed suggestions or actionable steps for improving the draft, which limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific changes could be made to the dataset. While it identifies a potential problem, the lack of actionable advice makes it difficult for the authors to respond effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also mentions that LLMs are typically trained on trillions of tokens, suggesting that the dataset needs to be massive to cover varied domains. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the dataset size and its implications for capturing diverse user traits and personalities. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. The comment provides a logical reasoning by comparing the dataset size to the typical training data of LLMs, making the claim 3. However, it lacks specific examples or references to support the claim fully, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also highlights the typical scale of training data for LLMs, suggesting that the dataset needs to be massive to cover varied domains. This feedback is 3 as it identifies a potential limitation in the dataset size and its implications for the model\"s ability to generalize across different user characteristics and content topics. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as exploring methods for expanding the dataset or considering alternative approaches to data augmentation. Overall, the comment offers a clear point of concern but lacks actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should use other metrics to evaluate the Results, such as BERTScore. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to improve their draft. The comment is specific in its recommendation, indicating which alternative metrics could be used. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not specify which part of the paper the results are presented in, making it difficult for the authors to identify the exact section that needs revision. While the suggestion is specific in terms of the metrics, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests using other metrics to evaluate the Results, such as BERTScore. However, it does not provide any reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the evaluation. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests using other metrics, such as BERTScore, to evaluate the results. This provides a clear and actionable suggestion for the authors to consider, as it offers a specific alternative to the current evaluation method. However, the comment lacks depth and does not elaborate on why these additional metrics would be beneficial or how they might impact the results. While it offers a starting point for improvement, the feedback could be more comprehensive and helpful if it included more detailed reasoning or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It also highlights the difficulty in understanding under what conditions SynTextBench should be used over other metrics, such as MMLU or Big Bench for language generation. While the comment provides a clear action\u2014comparing the metric with others\u2014it does not offer specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"a large amount of work on LLM evaluation 2\" and suggests comparing the SynTextBench metric with other metrics proposed in the literature. This allows the authors to accurately identify the part of the paper being addressed. Additionally, the comment specifies what needs to be addressed by asking about the conditions under which SynTextBench should be used, such as MMLU or Big Bench for language generation. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not adequately compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It suggests that the authors should compare the metric with others to understand under what conditions SynTextBench should be used. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by noting that while there is a large amount of work on LLM evaluation, the paper does not adequately compare the SynTextBench metric with other metrics proposed in the literature. It suggests that the authors should compare SynTextBench with other metrics to understand under what conditions it should be used, such as MMLU or Big Bench for language generation. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by including a comparative analysis of the metrics. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what aspects to focus on. Overall, the comment is 4, as it highlights an important area for improvement and provides a clear suggestion for action."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the writing and annotations in the paper are difficult to follow. However, it does not provide any specific guidance or suggestions on how the authors might improve the clarity or readability of their writing or annotations. The comment lacks explicit instructions or concrete advice on what needs to be done to address the issue. As a result, the authors are left without a clear understanding of how to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the exact section that needs improvement. Additionally, the comment is not specific, as it does not detail what aspects of the writing or annotations are hard to follow. Without specific examples or guidance, the authors cannot effectively address the issue. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the writing and annotations are \"poor\" and \"hard to follow.\" However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the writing and annotations in the paper, specifically noting that they are \"poor\" and \"hard to follow.\" However, the comment lacks specificity and actionable suggestions. It does not provide any details on what aspects of the writing or annotations are problematic, nor does it offer any guidance on how the authors might improve them. Without concrete examples or recommendations, the authors are left without a clear understanding of how to address the issue, making the comment 2. Therefore, the comment is rated as 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific questions about the results presented in Table 2. The first question asks why only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method. The second question inquires about the discrepancy in F1 scores between the overall setting and individual types in the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. While the comment identifies areas that need clarification, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to respond. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by questioning the performance of the proposed method and the discrepancy in F1 scores. This provides clear guidance on what aspects of the results require further explanation or analysis. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the results presented in Table 2, specifically regarding the number of evaluation metrics achieving SOTA performances and the discrepancy in F1 scores between the overall setting and individual types. While the questions are clear and specific, they do not contain subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies specific areas in the results that require further explanation or clarification. It questions why only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method and why the method achieves the best overall F1 score but not the best F1 score in all single types in the \"Twitter2017 $\rightarrow$ Twitter2015\" setting. This feedback is clear and actionable, as it directs the authors to specific aspects of their results that need further discussion or analysis. However, the comment could be more helpful if it provided suggestions on how to address these issues or what additional analysis might be beneficial. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of including all reports. While the comment is somewhat specific in questioning the rationale, it lacks concrete suggestions on how to implement this change or what experiments might be needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestion about the potential ease of including all reports, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the assertion that including all reports would be easier. As a result, the claim is 1, as it lacks sufficient support for the authors to understand or address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. This feedback is 3 as it prompts the authors to reconsider their approach and potentially explore the impact of including all reports. However, the comment lacks specific guidance or suggestions on how the authors might address this concern or what changes could be made to their methodology. While it identifies an area for improvement, it does not provide detailed actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which figures to revise or how to add the scatter plot. While the action is somewhat inferred, it lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It also proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment does not specify which parts of the paper these figures are located in, making it weakly grounded. The suggestion to highlight best results in tables is also vague and lacks specific guidance on how to implement it. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests improvements to the results presentation, specifically mentioning that the yaxis labels in Figure 2 and 3 are ambiguous and that the runtime is not represented. It proposes a scatter plot with runtime and performance axes as a way to enhance understanding. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The suggestion to highlight best results in tables is also vague and lacks detailed guidance. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or depth to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies areas for improvement in the results presentation, specifically mentioning the ambiguity of the yaxis labels in Figures 2 and 3 and the absence of runtime representation. It suggests a scatter plot with runtime and performance axes as a way to enhance the reader\"s understanding and interpretation of the results. Additionally, it proposes highlighting the best results in tables, which could improve clarity. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific steps or examples. While it provides some actionable feedback, it could be more helpful with additional details or suggestions for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the interpretation of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks for clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment seeks clarification, it does not provide explicit instructions or suggestions on how the authors should address this question or incorporate it into their draft. The action is implicit, as the authors need to infer that they should clarify the statement in their paper. However, the action is vague and lacks concrete guidance on how to implement the clarification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" However, it does not specify which part of the paper this statement is located in, making it difficult for the authors to identify the exact section being addressed. The comment is 1 because it lacks specific references to the paper\"s content. Additionally, it does not provide specific guidance on what needs to be addressed or clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, key nodes for attention, and model performance. However, the comment does not provide any evidence, reasoning, or references to support the claim that this interpretation is incorrect or needs clarification. Without additional context or justification, the authors are left to make their own interpretation, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It asks whether the base node affects the ordering, key nodes for attention, and model performance. This question is valuable as it seeks clarification on a potentially ambiguous statement, which could help the authors better understand and explain their methodology. However, the comment does not provide any suggestions or guidance on how the authors might address this question or incorporate it into their draft. While it identifies an area for clarification, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). While it prompts the authors to consider the rationale behind the arrow\"s direction, it does not provide explicit guidance on how to address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the arrow\"s direction and its impact on n^(i). However, the comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. However, the comment is specific in its request for clarification regarding the arrow\"s direction and its impact on n^(i). This suggests that the authors should provide a detailed explanation of the arrow\"s direction and its relevance to the influence on n^(i). Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It does not contain a claim that requires verification or justification. The comment is a question seeking clarification, which is a normal statement. Therefore, it should be labeled as \"No\".", "helpfulness_rationale": "The review comment raises a specific question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). It challenges the authors to consider the rationale behind the arrow\"s direction, which could be crucial for understanding the model or method being presented. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what changes could be made to the figure. While it identifies a potential area for clarification, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the use of abbreviations in Table 5, noting that they are not defined. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to define the abbreviations, but the comment lacks concrete instructions on which abbreviations need to be defined and how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the abbreviations in Table 5 are not defined, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \u201cAR\u201d in Table 5 stands for domain adaptation tasks and algorithms. While the comment identifies a potential issue with clarity and consistency in the use of abbreviations, it does not provide specific examples or references to support the claim. The authors are left to infer that the lack of definition for abbreviations could hinder understanding, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of abbreviations in Table 5, noting that they are not defined. This is a clear and actionable piece of feedback that could help the authors improve the clarity and readability of their paper. By defining the abbreviations, the authors can ensure that their work is easily understood by readers. However, the comment could be more helpful if it provided guidance on how to define the abbreviations or suggested specific definitions. Overall, the comment is 3 as it highlights a clear area for improvement, but it lacks depth and detail, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not provide explicit guidance or suggestions on how the authors should address this question or what aspects of the analysis might need to be reconsidered. The action is implicit, as the authors are left to infer that they should explore other technical considerations related to the use of advantage instead of qvalue. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on what aspects of the analysis might need to be reconsidered, leaving the authors with no clear direction on how to address the question. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of using advantage instead of qvalue in the analysis, suggesting that there might be other technical considerations. This feedback is 3 as it prompts the authors to consider alternative approaches or technical factors that might influence their choice. However, the comment lacks depth and specificity, as it does not provide detailed guidance or suggestions on how the authors might explore these considerations. Without concrete advice or examples, the authors may find it challenging to address the question effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the setting, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the \"Unsupervised Online Adaptation\" setting, suggesting that the training set, which includes documents, quires, and labels, might not align with the definition of unsupervised learning. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique, leaving them uncertain about how to address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the \"Unsupervised Online Adaptation\" setting, specifically questioning whether the inclusion of labels in the training set aligns with the definition of unsupervised learning. This critique is clear and provides a specific point of concern that the authors should consider. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what changes could be made to the setting. While it highlights a potential weakness, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the fairness of the performance comparison in Table 1 due to the use of different sample weights in the training process for VINS compared to the baselines. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the impact of different sample weights on the comparison, but it does not offer specific guidance on how to adjust the comparison or what steps to take to ensure fairness. As a result, the authors are left without clear instructions on how to address the issue, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the fairness of the performance comparison in Table 1, specifically pointing out that VINS uses different sample weights during training compared to the baselines. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential issue with the comparison, but without clear references to the table or section, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance comparison in Table 1 is unfair due to the use of different sample weights in the training process for VINS compared to the baselines. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the comparison is unfair or how to address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights during training compared to the baselines. This observation raises concerns about the validity of the comparison, as the use of different sample weights could significantly impact the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or ensure a fair comparison. While it highlights a potential problem, it lacks actionable advice or constructive feedback, making it 3. The authors would need to infer how to improve the comparison, which limits the comment\"s usefulness."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the time complexity of the method might be too high if the reply buffer is too large, referencing a specific paper. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the method need to be improved to mitigate the high time complexity. The comment lacks concrete actions or suggestions for the authors to take, making it difficult for them to understand how to apply the feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the time complexity issue related to a large reply buffer, referencing a specific paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear issue and suggests a potential solution by referencing a related work. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper. However, it does not provide any reasoning, examples, or detailed explanation to support this claim. The reference to the paper alone is insufficient to verify the claim, as it does not elaborate on the specific issues or provide evidence of the high time complexity. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the time complexity of the method when the reply buffer is too large, referencing a specific paper. While it points out a potential problem, it does not provide detailed guidance or suggestions on how to address this issue or improve the method\"s efficiency. The comment lacks actionable advice, such as specific techniques or strategies that could be employed to mitigate the high time complexity. Without concrete recommendations or a clear path forward, the feedback is 3 but could be more comprehensive and actionable to fully assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include the performance of accelerating SGMs by involving additional baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement this suggestion. The comment lacks concrete details on which baselines are relevant or how the authors should integrate them into their draft. As a result, the authors are left without a clear understanding of how to proceed with this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the authors should display the performance of accelerating SGMs by involving additional baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include additional baselines and perspectives, but without a clear reference to a specific section or figure, the authors may struggle to identify the exact area where this feedback is intended. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include the performance of accelerating SGMs by involving additional baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment lacks specific examples or references to support the claim that these additional baselines would provide valuable insights or improve the paper. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion and how to incorporate it into their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include the performance of accelerating SGMs by involving additional baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback is 3 as it provides a direction for the authors to enhance their work by considering alternative approaches and baselines. However, the comment lacks specific guidance on which baselines to include or how to integrate them into the draft, which limits its effectiveness. The suggestion is clear but could be more actionable with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions should be included. While it provides a clear indication of what needs to be added, it does not specify how to write the conclusion or summary, nor does it offer any guidance on the content or structure. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that a brief conclusion and a summary of the paper\"s contributions should be included. However, it does not specify which part of the paper this comment is referring to, such as a particular section or paragraph. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. Additionally, the comment is specific in its suggestion to include a conclusion and summary, but without grounding, it is challenging for the authors to understand where to make these additions. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a brief conclusion and a summary of the paper\"s contributions should be included. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as \"1.\"", "helpfulness_rationale": "The review comment suggests that a brief conclusion and a summary of the paper\"s contributions should be included. This feedback is clear and actionable, as it provides a specific direction for improvement. However, it lacks depth or guidance on how to write the conclusion or summary effectively. While it identifies a necessary element for the paper, it does not offer detailed suggestions or examples to enhance the quality of the conclusion and summary. Therefore, the comment is 3, as it provides a clear starting point for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment does not specify which method should be used for comparison or how this comparison should be presented in the paper. The action is implicit, as the authors need to infer that they should include this comparison, but it lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed framework with a method designed to defend against multiple attacks, implying that the authors should include this comparison in their paper. However, it does not specify which method should be used for comparison or how this comparison should be presented. The comment lacks specific guidance on which part of the paper should address this comparison, making it weakly grounded. It is also specific in suggesting the need for a comparison with a method defending against multiple attacks, but the lack of grounding makes it difficult for the authors to pinpoint the exact area to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without additional context or references, the claim is not 5, as it relies on the authors\" interpretation of the need for such a comparison. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific guidance on which method to use for comparison or how to present this comparison in the paper. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, making it 3. The feedback is clear but could be more comprehensive if it provided more actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to define the bounds for \tau_i^l, which is crucial for understanding the timewarp function. This provides a clear and direct action for the authors to take, as they need to ensure that the bounds are clearly defined in their draft. The comment is specific and concrete, giving the authors a precise task to accomplish. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, indicated by the line number (l111), allowing the authors to accurately identify the section where the bounds for \tau_i^l need to be defined. It is also specific because it clearly specifies what needs to be addressed, which is the definition of the bounds for \tau_i^l to understand the timewarp function. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and a specific instruction regarding the definition of \tau_i^l, which is important for understanding the timewarp function. It does not contain a subjective claim or opinion, but rather a suggestion for improvement. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment is specific and actionable, as it requests the authors to define the bounds for \tau_i^l, which is crucial for understanding the timewarp function. This feedback provides a clear and direct instruction for the authors to improve their draft by ensuring that all necessary definitions are included. The comment is helpful because it directly addresses a specific aspect of the paper that needs clarification, guiding the authors to enhance the comprehensibility of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies specific instances of writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment highlights these errors, it does not provide explicit guidance on how the authors should correct them or what specific changes need to be made. The action is implicit, as the authors can infer that they need to revise the text to eliminate the writing errors. However, the lack of detailed instructions on how to correct these errors makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. However, it does not specify which sections or parts of the paper these errors are located in, making it difficult for the authors to pinpoint the exact areas that need correction. While the comment is specific about the nature of the errors, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point highlights specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment identifies these errors, it does not provide any reasoning, examples, or references to support why these errors are problematic or how they impact the paper. The lack of detailed explanation or justification makes it difficult for the authors to understand the significance of these errors and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific writing errors in the paper, such as \"informative informative\" on page 5 and \"performance\" on page 1, which lacks a title. While the comment points out these issues, it does not provide any suggestions or guidance on how the authors might address or correct these errors. The feedback is limited in scope and lacks actionable advice, making it difficult for the authors to improve their draft based on this comment alone. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the first sentence of the abstract should be rewritten. This is an explicit action that the authors can directly implement by revising the sentence. However, the comment does not provide specific guidance on what aspects of the sentence need to be changed or how to improve it. While the action is clear, the lack of detail makes it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the first sentence of the abstract needs to be rewritten. However, it does not specify which part of the abstract this refers to, making it difficult for the authors to pinpoint the exact section that requires revision. Additionally, the comment lacks specificity, as it does not provide details on what aspects of the sentence need to be rewritten or why it needs to be revised. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the first sentence of the abstract needs to be rewritten. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this change is necessary or how to approach it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the first sentence of the abstract needs to be rewritten. While this provides a clear direction for improvement, it lacks specific guidance on what aspects of the sentence should be revised or why it needs to be rewritten. The comment is 3 as it identifies a specific area for improvement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how to simplify the method or identify the underlying principle. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact issue. The comment is vague and lacks specificity, as it does not provide detailed guidance on how to simplify the method or identify the underlying principle. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without additional context or evidence, the claim remains 3, as it is based on an observation without clear justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the method described in the paper is more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. While the comment identifies a potential area for simplification, it lacks specific guidance or suggestions on how to achieve this simplification. The feedback is 3 as it points out a potential issue with the method\"s complexity, but it does not provide actionable steps or detailed insights to address the concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the hGRU architecture is adhoc and not wellmotivated. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to improve the motivation or justification of the architecture. As a result, the authors are left without a clear understanding of how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the hGRU architecture is adhoc and not wellmotivated. However, it does not specify which part of the paper this comment is referring to, such as a particular section or figure. Without this context, the authors cannot accurately identify where the issue lies, making it difficult to address the feedback effectively. The comment is specific in its critique of the architecture but lacks grounding, as it does not provide clear references or sections to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the hGRU architecture is \"adhoc and not very well motivated.\" However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the architecture is considered adhoc or poorly motivated. This lack of supporting evidence makes the claim 3, as it lacks the necessary details to fully substantiate the assertion.", "helpfulness_rationale": "The comment identifies a potential issue with the hGRU architecture, suggesting that it is adhoc and not wellmotivated. While this feedback highlights a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address this concern. The comment does not provide any actionable steps or examples of how the authors could enhance the motivation or justification of the architecture. As a result, the feedback is 3, as it points out a potential area for improvement but does not offer comprehensive guidance for the authors to address it effectively. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies specific areas for clarification and improvement, it does not provide explicit instructions on how to address these points. The authors would need to infer that they should correct the potential error in the algorithm, discuss the asymptotic performance, and provide additional experimental results. The action is somewhat explicit but could be more concrete. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to Algorithm 1, Line 8, suggesting a potential error in using s_t instead of s_n. It also raises questions about the asymptotic performance of the proposed method and requests additional results with more environment steps. However, the comment does not explicitly mention which part of the paper Algorithm 1 is located in, making it weakly grounded. The comment is specific in detailing the issues and requests, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about a specific line in Algorithm 1, suggesting a potential error in using s_t instead of s_n. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies areas for clarification and improvement, it lacks specific reasoning or references to support the claims. The authors would need to infer the basis for these suggestions, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about a potential error in Algorithm 1, Line 8, suggesting that s_n should be used instead of s_t. It also asks for clarification on the asymptotic performance of the proposed method and requests additional results with more environment steps. While the comment identifies an area for improvement and provides a link to a GitHub repository, it lacks detailed guidance on how to address these issues or what specific changes might be necessary. The feedback is 3 as it points out a potential error and suggests additional experiments, but it could be more comprehensive with detailed instructions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the challenges in analyzing Adam under the (L0,L1)smoothness condition and suggests that it might be possible to directly apply standard analysis. It also recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not provide explicit guidance on how to address these challenges or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the challenges in analyzing Adam under the (L0,L1)smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not specify which part of the paper discusses the analysis of Adam under the (L0,L1)smoothness condition, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the issue of challenges and differences, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the challenges in analyzing Adam under the (L0,L1)smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment lacks specific examples or detailed reasoning to support the claim that standard analysis might be directly applicable. Without further elaboration or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of Adam under the (L0,L1)smoothness condition. It questions whether the challenges are significant enough to warrant detailed explanation and suggests that the analysis might be directly applicable to standard methods, as seen in the work of Zhang et al. This feedback is 3 as it highlights a potential gap in the paper\"s analysis and points towards a relevant comparison. However, the comment could be more helpful if it provided more detailed guidance on how to address the challenges or what specific aspects of the analysis need clarification. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights that most person reID methods build on pedestrian detectors and mentions the existence of endtoend methods. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or incorporate these methods into their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general overview of person reID methods, categorizing them as building on pedestrian detectors or being endtoend. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section or aspect that needs attention. Additionally, the comment lacks specificity in detailing what aspects of the methods or the paper could be improved. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that most person reID methods build on pedestrian detectors and mentions the existence of endtoend methods. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to verify the accuracy of the statement. The lack of detailed evidence or examples weakens the claim, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment provides a brief overview of person reID methods, categorizing them as building on pedestrian detectors or being endtoend. While this observation is accurate, it does not offer specific suggestions or guidance on how the authors might address this issue or improve their work. The comment lacks actionable insights or detailed feedback that would help the authors enhance their draft. Therefore, it is 2, as it identifies a relevant aspect but does not provide substantial guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests adding a first sentence to introduce Section 3.2. This is an explicit action that the authors can directly implement by adding a sentence at the beginning of the section. The comment is specific and provides clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce the section, providing clear guidance on what needs to be done. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point suggests adding a first sentence to introduce Section 3.2. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the label \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it suggests adding a first sentence to introduce Section 3.2. This is a clear and direct feedback that provides the authors with a concrete step to improve their draft. By adding this sentence, the authors can enhance the clarity and coherence of their paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment implies that the authors should clarify the term \"perfect,\" it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the term. However, the comment lacks concrete details on what specific clarification is needed, making it 3. Therefore, this comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This is a subjective claim that requires the authors to interpret the term \"perfect\" in the context of the paper. However, the comment does not provide any specific examples or references to support the claim, making it difficult for the authors to understand the reasoning behind it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the phrase \"perfect\" in the context of the initial rationale selector. It questions the meaning of \"perfect\" and suggests that if it were perfect, no additional work would be needed. This feedback is 3 as it highlights a potential ambiguity in the writing, which could be clarified to improve the paper\"s clarity. However, the comment could be more helpful if it provided additional context or suggestions for how to clarify the term. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zeroshot intent classifier. While it does not explicitly instruct the authors to address these questions, it implies that they should provide more clarity on these aspects. The action is implicit, as the authors need to infer that they should clarify these points in their draft. However, the questions are specific and direct, giving the authors a clear idea of what needs to be addressed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zeroshot intent classifier. It references a specific line (211) in the paper, which helps the authors identify the part of the paper being addressed. However, the questions themselves are specific and provide clear guidance on what needs to be clarified or addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zeroshot intent classifier. While the questions are clear and specific, they do not contain any subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\".", "helpfulness_rationale": "The review comment raises two specific questions about the experimental setup, particularly concerning the use of domain ontologies and the details of the zeroshot intent classifier. It points out a lack of clarity in the description of the experimental setup, which is crucial for understanding the methodology and results. By highlighting these areas of ambiguity, the comment provides the authors with actionable feedback that can help them improve the clarity and completeness of their draft. However, the comment could be more helpful if it suggested specific ways to address these issues or provided additional context. Overall, the feedback is 3 as it identifies important areas for improvement but lacks depth in terms of actionable suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their method with other selfsupervised learning methods that are not based on contrastive learning. This provides a clear and explicit action for the authors to take, as they can directly compare their method with relevant baselines. The comment is specific in its suggestion, guiding the authors on what kind of comparisons would be beneficial. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the authors\" method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not specify which part of the paper this comparison should be made or where these methods are discussed. The authors cannot confidently determine which section or part of the paper this suggestion relates to, making it weakly grounded. Additionally, while the suggestion is specific in terms of the type of comparison, it lacks detail on how to implement or execute this comparison. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the authors\" method with other selfsupervised learning methods that are not based on contrastive learning. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this comparison is necessary or how it would benefit their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the authors\" method with other selfsupervised learning methods that are not based on contrastive learning. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their work by including additional comparisons. By comparing their method with other relevant approaches, the authors can better position their work within the existing literature and demonstrate its unique contributions. This feedback is 4 as it offers a clear and constructive suggestion for improvement, though it could be further expanded to include specific examples or guidance on how to conduct the comparison effectively. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by models. It does not provide explicit instructions or suggestions on how the authors should address this question or clarify the distinction. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to respond. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the abstention process and its relation to decision thresholds, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its request for clarification regarding the difference between the abstention process and decision thresholds. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the abstention process and its relation to decision thresholds, but it does not contain a claim or suggestion that requires verification. It is a request for clarification and does not provide any evidence or reasoning to support a claim. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the abstention process and its relation to decision thresholds, specifically asking how the abstention process differs from a decision threshold used by models. This question is clear and identifies a potential area for clarification in the paper. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a specific area that needs attention, the comment lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of meaningful baselines in the authors\" comparisons, suggesting that they should include more sophisticated baselines such as a chainofthought prompting approach. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific baselines to consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more meaningful baselines. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue of lacking meaningful baselines and suggests a specific alternative baseline, the chainofthought prompting approach. This provides the authors with clear guidance on what needs to be addressed and how to improve their comparisons. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors limit their comparisons to simple naive baselines, suggesting that they should include more meaningful baselines such as a chainofthought prompting approach. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed justification or examples, the claim remains 3, as the authors may need to infer the basis of the criticism themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of meaningful baselines used for comparison. It suggests that the authors should include more sophisticated baselines, such as a chainofthought prompting approach, to provide a more comprehensive evaluation of their model. This feedback is clear and actionable, as it directs the authors to enhance the depth and rigor of their comparisons. However, the comment could be more helpful if it provided specific examples of how to implement these baselines or suggested additional baselines that could be considered. Overall, the comment is 4, as it offers valuable guidance for improving the paper but could be more detailed in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment prompts the authors to clarify their methodology, it does not provide explicit instructions or suggestions on how to address the question or what changes might be needed. The action is implicit, as the authors need to infer that they should clarify their pretraining approach and its generalization capabilities. However, the comment lacks concrete guidance on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set, and it also asks about the generalization of this approach to scenarios where labels are not available. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area they need to address. While the comment is specific in its inquiry about the model\"s pretraining and generalization, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the pretraining of the cardiac signal representation learning model and its generalization to scenarios without labels. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is purely factual and descriptive, aligning with the classification of \"No\".", "helpfulness_rationale": "The review comment raises a question about the pretraining of the cardiac signal representation learning model, specifically whether it is trained on the entire dataset or just the training set. It also inquires about the model\"s generalization capabilities in scenarios where labels are not available. While the comment identifies an area that requires clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their work. The feedback is 3 as it highlights a potential area for further discussion or exploration, but it lacks actionable advice or detailed suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results. It does not provide explicit instructions or suggestions on how the authors should address these concerns, such as suggesting alternative methods for evaluating the ground truth or providing more detailed analysis of the ablation study. The feedback is implicit and lacks concrete guidance, making it difficult for the authors to understand what actions to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not specify which part of the paper \"Tab.\" refers to, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its questioning, the lack of grounding makes it challenging for the authors to fully understand and address the issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any evidence, reasoning, or references to support these claims. The comment lacks specific details or justifications, making it difficult for the authors to understand the basis of the concerns or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any suggestions or guidance on how the authors might address these concerns. The feedback is primarily critical and lacks actionable advice, leaving the authors without a clear path forward for improving their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues: the lack of new evaluation metrics and the need for an indepth exploration of the reasons behind the experimental results. However, it does not provide explicit or implicit actions for the authors to take. The authors are left without guidance on how to address these issues, such as suggesting the development of new metrics or the inclusion of a detailed analysis of the experimental results. The comment lacks concrete details on how to implement these suggestions, making it 1.", "grounding_specificity_rationale": "The comment addresses the lack of new evaluation metrics and the need for an indepth exploration of experimental results, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which sections or aspects of the paper are being discussed, making the comment weakly grounded. However, it is specific in detailing the issues that need to be addressed, such as the absence of new metrics and the need for deeper analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks new evaluation metrics and that only existing metrics are linearly combined. It also suggests that the experimental analysis section needs an indepth exploration of the reasons behind the results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of new evaluation metrics and the need for a more indepth exploration of the reasons behind the experimental results. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that require attention, but it lacks actionable advice or detailed examples, which could have been more beneficial for the authors to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit action that the authors should take to avoid confusion and ensure consistency in their notation. The comment provides a direct and concrete instruction, making it 5. The authors know exactly what needs to be addressed and how to implement the suggested change. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit reference to specific parts of the paper, such as L166 and L176, which allows the authors to accurately pinpoint the issue. The comment is fully grounded as it provides specific references to the sections where the notation is used. It is also specific because it clearly specifies the problem with the notation, making it easy for the authors to understand and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a factual observation that requires no additional evidence or reasoning to be understood. The comment is clear and specific, making it verifiable. Therefore, it is classified as \"3\" as it is clear but lacks some depth in terms of suggesting potential consequences or implications of the issue.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion for the readers. By pointing out this inconsistency, the comment provides the authors with a concrete suggestion to improve the clarity and consistency of their notation. This feedback is valuable as it helps the authors enhance the readability and understanding of their work. Therefore, the comment is 4, as it offers a clear and actionable piece of advice that can significantly improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practical impact of the weak recovery problem studied, suggesting that it may be primarily of theoretical interest and that the AMP algorithm\"s usefulness for nonGaussian problems is unclear. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the practical relevance of their work. The action is implicit and vague, as it does not specify what changes or improvements the authors should make to enhance the paper. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the practical impact of the weak recovery problem studied, suggesting that it is primarily of theoretical interest and that the AMP algorithm\"s usefulness for nonGaussian problems is unclear. However, the comment does not specify which part of the paper discusses the weak recovery problem or the AMP algorithm, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of practical impact, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and that the AMP algorithm\"s usefulness for nonGaussian problems is unclear, limiting practical impact. However, the comment does not provide specific evidence, examples, or references to support these claims. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical impact of the weak recovery problem studied, suggesting that it is primarily of theoretical interest and that the AMP algorithm may not be useful for nonGaussian problems. This feedback highlights a gap in the paper\"s discussion of the algorithm\"s applicability and suggests that the authors should consider expanding their analysis to address this concern. However, the comment lacks specific guidance on how the authors might improve the practical relevance of their work or what additional experiments or analyses could be conducted to address the identified issue. While it points out a potential area for improvement, the feedback is somewhat limited in its actionable value, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the paper\"s focus on a reductionist problem. It suggests that the authors should clarify their claims and provide more context or citations to support their arguments. However, the comment does not explicitly instruct the authors on how to address this issue or what specific changes to make. The action is implicit, as the authors need to infer that they should clarify their claims and provide more context or citations. The action is somewhat vague, as it does not specify the exact nature of the clarification or the type of citations needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the relevance of connections to human cognition in the context of the paper, specifically questioning whether such connections are meaningful given the reductionist nature of the problem. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its critique of the authors\" claims regarding the impact of cognitively basic adaptation mechanisms and the structure of the CPR on selforganization. It suggests that the authors need to provide more context or citations to support their claims, which is a clear and specific request. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the relevance of connections to human cognition in the context of the paper, specifically questioning whether such connections are meaningful given the reductionist nature of the problem. The authors themselves state that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation that humans use, which makes the claim about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR somewhat unclear. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors need to clarify their reasoning and provide more context or evidence to support their claims, which would enhance the verifiability of the comment.", "helpfulness_rationale": "The review comment raises a question about the relevance of connections to human cognition in the context of the paper, specifically questioning whether such connections are meaningful given the reductionist nature of the problem. The authors themselves state that the problem is fairly reductionist and does not allow for mechanisms like bargaining and negotiation that humans use, which makes the claim about the interaction between cognitively basic adaptation mechanisms and the structure of the CPR somewhat unclear. The comment suggests that the authors need to clarify their claims and provide more context or citations to support their arguments. This feedback is 3 as it identifies a potential area of confusion and encourages the authors to provide more context or evidence to support their claims. However, it could be more helpful if it provided specific examples or references to support the claim, making it more actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. While the comment identifies a specific issue with the writing style, it does not provide explicit guidance on how to revise the conclusion or suggest specific changes to make the word choice less flamboyant. The action is implicit, as the authors would need to infer that they should revise the conclusion to be more concise and less flamboyant. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the conclusion section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue of exaggerated wording and suggests that the word choice is a bit flamboyant in multiple places, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. However, the comment does not provide any specific examples or references to support this claim. Without concrete examples or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the writing style in the conclusion, noting that the wording is overly exaggerated and that the word choice is a bit flamboyant in multiple places. This feedback is clear and actionable, as it provides the authors with a specific area to improve the tone and conciseness of their conclusion. However, the comment could be more helpful if it offered suggestions on how to revise the language or provide examples of more appropriate phrasing. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and explicit action for the authors to take, as they know exactly what experiments to conduct and what metrics to compare. The comment is specific in its suggestion, detailing the methods and metrics to be used. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this comparison should be made or which sections of the paper contain the relevant information. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the metrics for comparison, it lacks specific guidance on how to conduct the ablation experiments or what specific aspects of the comparison are crucial. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This claim is 3 as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the choice of methods or metrics. The authors would benefit from additional context or justification to fully understand the rationale behind the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their experimental evaluation. By conducting these ablation studies, the authors can better understand the effectiveness and efficiency of their proposed method compared to existing approaches. However, the comment could be more helpful if it included additional guidance on how to conduct the ablation experiments or what specific aspects of the comparison are crucial. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks concrete guidance on what kind of baselines to include or how to demonstrate the effectiveness of the proposed approach. Without specific actions or detailed instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a significant weakness in the paper, which is the lack of comparison to simple feature acquisition baselines. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. This makes it difficult for the authors to pinpoint where the comparison should be made. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on which sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks comparison to simple feature acquisition baselines, which is a significant issue. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of comparison to simple feature acquisition baselines. This is a crucial point because it affects the ability to demonstrate the effectiveness of the proposed approach. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as which baselines to include or how to conduct the comparison. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it provides a clear weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement, but it lacks explicit guidance on how to address them. The comment suggests exploring other bit operations, providing more explanations for Figure 5a, and dealing with DVS input when the input is in aer format. It also suggests analyzing energy consumption as reference 15 did to strengthen the paper. However, the authors are left without clear instructions on how to implement these suggestions or what specific actions to take. The feedback is somewhat vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment raises several questions and suggestions for improvement, but it does not specify which part of the paper these issues relate to. The references to \"11,\" \"Fig. 5 a,\" and \"aer format\" are vague and do not allow the authors to pinpoint the exact sections or figures being discussed. While the suggestions are relevant, the lack of grounding makes it difficult for the authors to understand which parts of the paper need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises several questions and suggestions for improvement, such as exploring other bit operations, providing more explanations for Figure 5a, and dealing with DVS input when the input is in aer format. It also suggests analyzing energy consumption as reference 15 did to strengthen the paper. However, the comment lacks specific reasoning, examples, or references to support these suggestions, making it difficult for the authors to understand the basis of the claims. The feedback is 4 as it provides some direction but lacks detailed justification or evidence. Therefore, it aligns with a score of 4.", "helpfulness_rationale": "The review comment raises several questions and suggestions for improvement, such as exploring other bit operations, providing more explanations for Figure 5a, and dealing with DVS input when the input is in aer format. It also suggests analyzing energy consumption as reference 15 did to strengthen the paper. However, the comment lacks specific guidance on how to address these points or what actions the authors should take to improve their draft. While it identifies areas for enhancement, it does not provide detailed feedback or actionable steps, making it 3. The feedback is 3 as it offers some direction but could be more comprehensive and detailed to fully assist the authors in improving their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not provide explicit guidance on how to conduct these additional experiments or what specific aspects of the model should be evaluated. The action is implicit and somewhat vague, as the authors are left to infer the need for more experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarityaware positive sample selection or the experiments conducted on the graph classification task. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the concerns and suggestions, the absence of explicit references to the paper\"s sections or content makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The comment suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the similarityaware positive sample selection and its potential impact on GNNbased encoder oversmoothing, specifically questioning whether it might lead to oversmoothing or lower generalization performance. It suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific guidance on how to conduct these additional experiments or what aspects of the model should be evaluated. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is 3, as it highlights important areas for further investigation but does not offer comprehensive guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to discuss the power of different architectures. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for more discussion but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not contain any subjective opinions, claims, or suggestions that require verification. The comment is purely factual and descriptive, lacking any reasoning or evidence to support it. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue or what aspects of the architectures should be discussed. The comment is 3 as it points out a potential area for further exploration, but it does not provide detailed feedback or actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment is specific in its critique but weakly grounded as it does not provide clear guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the types of situations or social norms discussed in the main paper are not clear. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the types of situations or social norms discussed in the main paper. However, it lacks actionable guidance or suggestions on how the authors might address this lack of clarity. Without specific advice on how to improve the clarity or provide more detailed explanations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a problem but does not provide sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point requests the authors to define the dashed lines in figures 2AB and 4B. This is a clear and explicit action that the authors can readily take to improve their draft. The comment provides specific guidance on what needs to be addressed, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment requests the authors to define the dashed lines in figures 2AB and 4B. While it does not explicitly mention which part of the paper these figures are located in, the authors can infer that they are referring to specific sections of the paper where these figures are presented. This makes the comment weakly grounded, as the authors can make an educated guess but cannot precisely identify the referenced part. However, the comment is specific in its request to define the dashed lines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point requests the authors to define the dashed lines in figures 2AB and 4B. This is a factual request for clarification, as it does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment requests the authors to define the dashed lines in figures 2AB and 4B. This is a clear and actionable suggestion that directly addresses a specific aspect of the paper that needs clarification. By defining these lines, the authors can improve the readability and understanding of their figures, which is crucial for effective communication of their results. The comment is specific and provides a clear direction for improvement, making it 5 for the authors. Therefore, it is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the comparability of their results. The comment lacks concrete guidance on what specific steps the authors should take to make their results more comparable or to enhance the significance of their proposed methods. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, it does not specify which part of the paper this issue is related to, such as the results section, the discussion, or the methodology. Without clear grounding, the authors cannot confidently identify where the issue lies, making it difficult to address the concern effectively. Additionally, the comment lacks specificity in detailing what aspects of the results need to be improved to enhance comparability or significance. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern regarding the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, the comment lacks specific details or suggestions on how the authors might address this issue or improve the significance of their methods. It does not provide actionable guidance or insights into potential improvements, leaving the authors with limited information to enhance their draft. As a result, the comment is 2, as it points out a problem but does not offer a comprehensive or constructive response to guide the authors in improving their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a limitation in the results of the paper, specifically regarding the assumption that the spectrum of a kernel is subgaussian. It notes that while Gaussian kernels are in this class, other popular kernels like Matern kernels, which have polynomial decay spectra, are not included. The comment suggests that this limitation could restrict the results of the paper. However, it does not provide explicit guidance on how the authors might address this limitation or what steps they should take to improve their draft. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific limitation in the results of the paper, focusing on the assumption that the spectrum of a kernel is subgaussian. It highlights that while Gaussian kernels are included, other popular kernels like Matern kernels, which have polynomial decay spectra, are not considered. This provides a clear and specific reference to the part of the paper being discussed, allowing the authors to accurately identify the issue. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific because it clearly specifies the limitation regarding the inclusion of Matern kernels. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is subgaussian. It argues that while Gaussian kernels are included, other popular kernels like Matern kernels, which have polynomial decay spectra, are not considered. The comment provides a logical reasoning by explaining why the inclusion of Matern kernels could be beneficial, but it lacks specific examples or references to support the claim. Without detailed examples or references, the claim is 3, as it provides a basis for understanding the limitation but does not fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the results of the paper, specifically regarding the assumption that the spectrum of a kernel is subgaussian. It points out that while Gaussian kernels are included, other popular kernels like Matern kernels, which have polynomial decay spectra, are not considered. This observation suggests that the results of the paper could be more comprehensive if these kernels were included. However, the comment does not provide specific guidance on how the authors might address this limitation or what steps they should take to improve their draft. While it highlights an important area for consideration, the feedback lacks depth and actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but could be more comprehensive and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it is a key factor in performance gain compared to other modules. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the unsupervised pretraining should be discussed. The suggestion is implicit and lacks concrete details, making it difficult for the authors to know exactly what to do. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining in the main paper and suggests that it is more important than other modules. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4. However, it lacks detailed discussion on this topic in the main paper, which could be a problem. The comment suggests that the unsupervised pretraining is more important than other modules, as shown in the ablation study of Table 5. While the claim is supported by the data in the tables, the reasoning could be more explicit and detailed, providing a clearer justification for the suggestion. Therefore, the comment is 4, as it provides some support but could be strengthened with more detailed reasoning or references.", "helpfulness_rationale": "The review comment identifies a key issue in the paper, specifically the lack of detailed discussion on unsupervised pretraining despite its importance in performance gains. It provides a clear suggestion to focus more on this aspect in the main paper, which is a valuable piece of feedback. However, the comment could be more helpful if it offered additional guidance on how to address the lack of discussion or suggested specific areas where the discussion could be expanded. Overall, the comment is 4 as it highlights a significant area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker\"s gender beforehand, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors should choose the ELM or how they should calculate the accuracy. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker\"s gender beforehand, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table discussing the selection of ELMs. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of ELM choice and its potential drawbacks, it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker\"s gender beforehand, which could be a drawback. The comment implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed explanation or evidence makes the claim 3, as it is based on logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the choice of ELM (male or female) and suggests that this choice might require knowing the speaker\"s gender beforehand, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. This feedback highlights a potential issue with the methodology and suggests that the authors should consider the implications of gender detection in their pipeline. However, the comment lacks specific guidance on how the authors might address this issue or what changes could be made to improve their draft. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to 31. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how to improve the paper\"s technical depth or relevance. As a result, the authors are left without a clear path to enhance their draft, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to 31. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. Additionally, the comment is specific in its critique of the paper\"s incremental nature and the addition of a new loss, but without clear guidance on how to address these issues, the comment is 3. Therefore, it aligns with category 3.", "verifiability_rationale": "The review point claims that the paper is incremental and lacks technical substance, primarily adding a new loss to 31. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that it is incremental and lacks technical substance, primarily adding a new loss to 31. This feedback is clear and actionable, as it highlights a critical area for improvement. However, the comment could be more helpful if it provided suggestions on how to enhance the paper\"s technical depth or relevance. Despite this, the feedback is 4 as it directs the authors to address a key weakness in their work, providing a clear starting point for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the use of different variables in equations (7) and (10), questioning why they are not analogous. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the equations. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the use of different variables in equations (7) and (10), specifically asking why they are not analogous. However, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The authors are left without a clear understanding of what part of the paper needs revision or how to improve the consistency of the equations. As a result, the comment is 1, as the authors cannot confidently determine which part of the paper is being addressed, and it is not specific because it does not provide any actionable feedback. Therefore, this comment aligns with category 1 and Not Specific.", "verifiability_rationale": "The review point raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. However, it does not provide any claim, suggestion, or judgment that requires verification. The comment is purely analytical and does not offer any evidence or reasoning to support the observation. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. While it identifies a potential inconsistency or area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to the equations. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but does not offer any constructive advice or suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in realworld scenarios. However, the comment does not specify how the authors should go about providing this evidence, such as suggesting specific datasets or methods for empirical validation. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment does not specify which part of the paper discusses the model\"s applicability or where the empirical evidence should be provided. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific in its suggestion to provide empirical evidence, the absence of explicit references or sections makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the applicability of the model to realworld diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment lacks specific details or examples to substantiate this concern, making it difficult for the authors to understand the basis of the claim. Without additional context or references, the claim remains 3, as it is based on a general observation without clear justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the applicability of the model to realworld diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in realworld scenarios. This feedback is valuable as it highlights a crucial aspect of the paper that needs further substantiation. However, the comment could be more helpful if it provided specific guidance on how the authors might conduct this empirical validation, such as suggesting particular datasets or methods. Despite this, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. While the comment implies that the authors should conduct more experiments, it does not provide specific guidance on which datasets to use or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer that they should expand their testing to more datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. It is specific in suggesting that the authors should try more datasets, but without a clear reference to a specific section or figure, the authors may find it challenging to address the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether the method has been tested on more than two datasets, suggesting that the authors should try additional datasets to gain a better understanding of its performance. However, the comment does not provide any specific reasoning, examples, or references to support why testing on more datasets would be beneficial or how it would impact the results. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the limited testing of the method on only two datasets, questioning whether the authors have explored a broader range of datasets to gain a more comprehensive understanding of the method\"s performance. This feedback is 3 as it highlights a potential area for improvement, suggesting that the authors should consider expanding their testing to more datasets. However, the comment lacks specific guidance on which datasets to use or how to analyze the results, making it 3. The authors would need to infer the need for more extensive testing, which could be a bit challenging. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper itself. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section being discussed. Additionally, the comment is not specific because it does not detail what aspects of the contribution are not novel or how the authors might address this issue. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the main contribution of combining attention with other linear mechanisms is not novel, referencing the paper itself. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the contribution is not novel or that alternatives exist. Without this additional information, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the paper\"s main contribution, specifically the combination of attention with other linear mechanisms. However, it lacks depth and actionable suggestions, as it does not provide specific examples or guidance on how the authors might address this concern or enhance the novelty of their work. The comment is vague and does not offer a clear path for improvement, making it 3 but not fully supportive. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a plot showing how different weights of the model change after unlearning, specifically focusing on which layers are most affected. This feedback is explicit and concrete, as it directly instructs the authors on what action to take and how to implement it. The comment provides a clear and detailed action, making it 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. The comment is specific in its suggestion to include a plot and analyze weight changes, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. This claim is 3 as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors would need to infer the need for such a plot to address the issue of understanding how different layers are affected by unlearning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors include a plot illustrating how different weights of the model change after unlearning. This feedback is actionable and directly addresses a potential area for clarification or further analysis in the paper. By suggesting a visual representation of weight changes across layers, the comment helps the authors enhance the interpretability of their results. However, the comment could be more helpful if it provided additional guidance on how to create or interpret the plot effectively. Overall, the feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional details. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete guidance on how to address the issue. The action is implicit, as the authors need to infer that they should discuss the domain of the inputs and why it is not mentioned. However, the comment lacks detail on how to implement this action, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not mentioned in the paper. However, it does not specify which part of the paper this issue relates to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion to clarify the domain of the inputs, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not mentioned in the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the domain of the inputs, suggesting that they appear to be in the same sphere but are not explicitly mentioned in the paper. This feedback highlights a potential gap in the clarity of the paper, as it leaves the reader questioning the scope and nature of the inputs. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as clarifying the domain or providing additional context. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. While the comment highlights a specific issue, it does not provide explicit guidance on how the authors should address this conflict or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to resolve the conflict. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lemma 2\" and \"Eq (7),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the definition of minimal conditional dependence and the equations, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically mentioning equations (7) and the definition of minimal conditional dependence. It suggests that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. The comment provides a clear logical reasoning by pointing out the inconsistency between the definition and the equation. However, it lacks specific examples or references to support the claim, which could make it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. It highlights a discrepancy between the theoretical expectation and the equation presented, suggesting that taking Z\u00e2\u0080\u0099 as the empty set should result in x and y being independent given W, but equation (7) contradicts this. This feedback is clear and actionable, as it points out a specific area where the authors need to address a potential inconsistency. However, the comment could be more helpful if it provided guidance on how to resolve the conflict or what changes might be necessary. Overall, the comment is 4, as it directs the authors to a critical issue that needs to be addressed for the paper to be accurate and consistent."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to improve the subscripts or what specific enhancements could be made. Without concrete suggestions or instructions, the authors are left without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, and suggests enhancing readability and aesthetic appeal. This provides the authors with a clear understanding of what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the visual presentation of data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to improve the presentation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. While the comment highlights a potential improvement, it lacks detailed guidance or suggestions on how to achieve this enhancement. The authors are left with a general idea of what needs to be improved but without specific steps or examples to follow. This feedback is 3 as it points out a potential area for improvement, but it could be more helpful with additional guidance or suggestions. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete guidance on how to update the archetypes. The comment is vague and lacks actionable steps for the authors to take. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the update mechanism of archetype positions after initialisation, providing a clear direction for the authors to address the concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It does not contain a claim or assertion that requires verification. The comment is factual and descriptive, as it seeks clarification on a specific aspect of the algorithm. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the update mechanism of archetype positions in Algorithm 2, specifically after initialisation. It points out a lack of clarity regarding how these positions are updated, which could hinder the understanding and implementation of the algorithm. However, the comment does not provide any suggestions or guidance on how to address this issue or improve the clarity of the algorithm. As a result, the feedback is 3, as it identifies a potential area for improvement but lacks actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the timeconsuming nature of the training process and the lack of description and comparison of processing efficiency with existing work. While the comment identifies the problems, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to improve the efficiency of their model and compare it with existing methods, but the comment lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is 3, as it points out areas for improvement but does not provide detailed guidance on implementation. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the timeconsuming nature of the training process and the lack of description and comparison of processing efficiency with existing work. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for a comparison with existing work, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas that require attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper is timeconsuming due to the shape model being trained at the pixel level and the independent training on all font images and characters. It also mentions that the parsing model is a highorder factor graph with four types of factors, and the processing efficiency of training and testing should be described and compared with existing work. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or comparisons, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the timeconsuming nature of the training process due to the shape model being trained at the pixel level and the independent training on all font images and characters. It also points out the complexity of the parsing model, which is a highorder factor graph with four types of factors. The comment suggests that the processing efficiency of training and testing should be described and compared with existing work. However, the feedback lacks specific details or suggestions on how the authors might address these issues or what improvements could be made to enhance the efficiency of their model. While it highlights areas for improvement, the comment does not provide actionable guidance or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors can address these issues. The comment lacks explicit actions or concrete steps that the authors can take to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to enhance the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not specify which part of the paper is challenging to follow or provide any details on what aspects of the motivation are unclear. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide any suggestions or guidance on how to improve the motivation or address the concern about being an incremental engineering paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper is difficult to follow and suggests it might be an incremental engineering paper. However, it does not provide any specific evidence, reasoning, or references to support these claims. Without detailed justification or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: difficulty in following the motivation and the perception that it might be an incremental engineering paper. However, it lacks specific suggestions or guidance on how the authors can address these concerns. While it points out areas for improvement, the feedback is somewhat vague and does not provide actionable steps for the authors to take. This limits the comment\"s helpfulness, as it does not offer a comprehensive roadmap for enhancing the paper. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a critical weakness in the paper, stating that it lacks novelty and is incremental in nature. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit suggestions on how the authors might address these issues or improve the paper. The authors are left without guidance on how to enhance the novelty or the approach to dataset design. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper discusses the dataset design or the approach to benchmarking, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks novelty and is incremental in nature, citing the design of a new dataset as a different train/test split of an existing dataset, SQUALL, and another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of substantiation makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any actionable suggestions or insights on how the authors might address these issues or improve the paper. Without specific guidance or recommendations, the authors are left without a clear path forward to enhance their work. Therefore, the comment is 2, as it highlights a significant issue but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and MPHATE in Figure 3. Additionally, the comment questions the purpose of examining the learning curves, asks about the accuracy of the models, and whether worseperforming models always lead to structural collapse. While the comment provides several specific actions, it lacks a clear and explicit instruction on how to implement these suggestions. The authors are left to infer the exact steps needed to address each point, making the feedback 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests adding more sentences to explain the experimental setting for continual learning, specifically in section 2. It also requests a detailed explanation of the correspondence between the learning curves and MPHATE in Figure 3. Additionally, it questions the purpose of examining the learning curves, asks about the accuracy of the models, and whether worseperforming models always lead to structural collapse. However, the comment does not specify which part of the paper these suggestions pertain to, making it weakly grounded. It is specific in detailing what needs to be addressed, such as adding explanations and clarifying the correspondence between learning curves and MPHATE. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point contains several claims that require justification. For instance, it questions the purpose of examining learning curves and asks about the accuracy of the models, suggesting that worseperforming models might lead to structural collapse. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The request for a detailed explanation of the correspondence between learning curves and MPHATE is logical but lacks sufficient evidence. Overall, the comment is 3, as it provides some reasoning but lacks depth and specific examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment provides several suggestions for improving the draft, such as adding more sentences to explain the experimental setting for continual learning and clarifying the correspondence between learning curves and MPHATE in Figure 3. It also raises questions about the purpose of examining the learning curves and the accuracy of the models. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to address these issues or what specific aspects of the draft need improvement. While the feedback is 3, it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, it does not provide explicit or implicit actions for the authors to take, such as conducting experiments or providing detailed reasoning. The comment lacks concrete guidance on how the authors might address this question or incorporate it into their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it does not provide explicit references to sections, tables, or figures. While it is specific in its suggestion about the potential benefits of labeled data, the lack of grounding makes it challenging for the authors to understand the context and relevance of the comment. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. However, the comment does not provide any specific reasoning, examples, or references to support the claim that labeled data could be beneficial. Without detailed justification or evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that labeled data could provide effective information for the task. It provides a specific example of how labeled data might be beneficial, referencing two relevant papers on graph contrastive learning. However, the comment lacks actionable guidance or suggestions on how the authors might explore this idea further or incorporate it into their work. While it identifies an interesting area for potential improvement, it does not provide detailed feedback or concrete steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experimental part needs to be reorganized and further improved. It highlights that the current experimental content in the main text does not effectively showcase the superiority of the method. The comment implies that the authors should reorganize the experimental section to better highlight the method\"s advantages. However, it does not provide specific guidance on how to reorganize the content or what aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental part needs to be reorganized and further improved, indicating that the authors should reorganize the experimental section to better highlight the method\"s superiority. However, the comment does not specify which part of the paper the experimental section is located in, making it weakly grounded. It is specific in suggesting that the experimental content should include certain suggestions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experimental part needs to be reorganized and further improved, indicating that the current content does not effectively showcase the superiority of the method. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact issues or how to address them. Without additional information or guidance, the claim remains 3, as it is based on an observation without clear justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a need for reorganization and improvement in the experimental part of the paper. It highlights that the current content in the main text does not effectively showcase the superiority of the method, suggesting that the experimental section should be restructured to better emphasize this aspect. However, the comment lacks specific guidance or suggestions on how to reorganize the content or what specific improvements should be made. While it points out a critical area for improvement, the lack of detailed feedback limits its helpfulness for the authors. Therefore, the comment is rated as 3, as it provides a clear direction but lacks depth and actionable advice."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should include a plot comparing the flexibility of SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. This provides a clear and concrete action for the authors to take, as it specifies exactly what needs to be added to the paper. The comment is explicit and detailed, guiding the authors on how to implement the suggested improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"SGC\" and \"LoRA,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a concrete action: including a plot with sparsity on the xaxis and performance on the yaxis to compare the flexibility of SGC with LoRA. This provides clear guidance on what needs to be addressed, making the comment highly specific and grounded. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point claims that PEFT methods typically target computeconstrained scenarios, where finegrained control may require extra tuning, thus reducing practicality. It suggests including a plot comparing SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. While the claim about PEFT methods is generally accepted, the suggestion to include a plot is specific and provides a clear direction for the authors to improve their paper. However, the comment lacks detailed reasoning or references to support the claim about PEFT methods, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim regarding the applicability of SGC, suggesting that PEFT methods, such as LoRA, are more practical in computeconstrained scenarios. It provides a specific suggestion to include a plot comparing SGC with LoRA, using sparsity on the xaxis and performance on the yaxis. This feedback is clear and actionable, offering a concrete way for the authors to address the identified issue and enhance the paper\"s clarity and practical relevance. The comment is 4 as it provides a detailed and constructive suggestion, though it could be further expanded to include additional comparisons or context. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time, and it recommends publishing the code. However, the comment does not provide explicit guidance on how to address the question or what specific actions the authors should take to improve their draft. The suggestion to publish the code is vague and lacks detail on how this would benefit the authors or the paper. Therefore, the comment is not actionable, as it does not provide clear instructions or concrete steps for the authors to follow. The comment is rated as 1.", "grounding_specificity_rationale": "The comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment does not provide specific guidance or suggestions on how to address this issue or what changes might be necessary. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time and recommends publishing the code. However, the comment does not provide any evidence, reasoning, or references to support the claim that the training time is reasonable or that publishing the code would be beneficial. The lack of justification makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the reasonableness of the training time for the German and Law school datasets in the context of the Gerrymandering experiment compared to the Independent experiment. It also suggests that the main advantage of the method is its computational time and recommends publishing the code. However, the comment lacks depth and specificity, as it does not provide detailed reasoning or suggestions on how to address the question or what changes might be necessary to improve the draft. The feedback is 3 as it identifies an area for clarification and suggests a potential improvement, but it does not offer comprehensive guidance or actionable steps for the authors. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the human baseline\"s performance and the claim made in the abstract. It points out that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to the draft. The action is implicit, as the authors need to infer that they should clarify the discrepancy in the human baseline\"s performance and the abstract\"s claim. The action is somewhat vague, as it does not specify how to address the issue or what changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the human baseline, specifically mentioning that it is based on a 1hour recording compared to the 15hour recording used for the model baseline. This provides a clear reference point for the authors to understand which part of the paper is being discussed. However, the comment does not specify what needs to be addressed in this part, such as how to improve the human baseline or clarify the discrepancy in the abstract. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the human baseline is based on a 1hour recording, which is less than the 15hour recording used for the model baseline. This makes the human baseline weaker than the model baseline. The comment also notes that the abstract mentions a human baseline achieving certain performance metrics, which is misleading given the discrepancy in recording lengths. However, the comment lacks specific examples or references to support the claim about the human baseline\"s performance. While the reasoning is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the human baseline in the paper, noting that it is based on a 1hour recording compared to the 15hour recording used for the model baseline. This discrepancy makes the human baseline weaker than the model baseline, apart from other factors mentioned in Section 4.1. The comment also points out that the abstract claims the human baseline \"already beating the 34.2% CER and 4.51 BLEU achieved by a human who learned Kalamang from the same resources,\" which is misleading given the 1hour vs. 15hour recording difference. This feedback is 3 as it highlights a potential inconsistency in the paper\"s claims and suggests that the authors should clarify the discrepancy in the human baseline\"s performance and the abstract\"s claim. However, the comment could be more helpful if it provided specific guidance on how to address this issue or what changes should be made to the draft. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is explicit and provides a clear action for the authors to take: they should consider incorporating these methods as baselines in their experiments. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a gap in the related work by noting that while other methods for training NMT models beyond MLE are discussed, none of them are used as baselines. This provides a clear and specific direction for the authors to improve their draft by including these methods as baselines. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work section discusses other methods for training NMT models beyond MLE but does not include any of these methods as baselines. This claim is 3 as it highlights a gap in the related work section, but it lacks specific examples or references to support the claim. The authors would need to infer that the omission of these methods as baselines is a significant gap, which could be addressed by providing more detailed evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the related work section by noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is clear and actionable, as it provides a specific suggestion for improvement: the authors should consider incorporating these methods as baselines in their experiments. By doing so, the authors can provide a more comprehensive comparison and better contextualize their work. This feedback is 4 as it offers a clear direction for improvement, but it could be more comprehensive if it suggested specific methods or baselines to include. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of the term \"efficient proxy\" used in the paper. It suggests that the authors might be referring to a particular proxy or a family of efficient proxies, but the paper does not provide a clear definition or context. While the comment implies that the authors need to clarify this term, it does not explicitly instruct them to do so or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the term. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. However, the comment does not specify which part of the paper this issue is discussed, making it difficult for the authors to pinpoint the exact location. Additionally, the comment does not provide specific guidance on how to clarify the term or address the potential ambiguity. As a result, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left to interpret the ambiguity themselves, making the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the clarity of the term \"efficient proxy\" used in the paper, suggesting that it might refer to a particular proxy or a family of efficient proxies. This raises a potential ambiguity that could affect the understanding of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the term. Without actionable feedback or specific advice, the authors are left to interpret the ambiguity themselves, which limits the helpfulness of the comment. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Grouplearning setting, and then using DBSCAN for clustering. However, it does not provide any explicit or implicit suggestions for improvement or action. The authors are left without guidance on how to address this combination of methods or why it might be problematic. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Grouplearning setting, and then using DBSCAN for clustering. However, it does not specify which part of the paper this combination is discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in detailing the methods used, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Grouplearning setting, and then using DBSCAN for clustering. However, it does not provide any claim, suggestion, or judgment about the paper. It is a factual description of the methods used, without any critical analysis or critique. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Grouplearning setting, and then using DBSCAN for clustering. However, it does not provide any critical analysis, suggestions, or insights into why this combination might be problematic or how it could be improved. The comment lacks depth and does not offer actionable feedback that would help the authors enhance their work. As a result, it is 2, as it does not provide any meaningful guidance or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The suggestion to explore the resilience of the metric to the choice of random projection is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable, as it does not provide clear instructions or guidance on how to address the identified issue.", "grounding_specificity_rationale": "The comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not specify which part of the paper discusses the results or the appendix, making it weakly grounded. The comment is specific in its suggestion to explore the resilience of the metric to the choice of random projection, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors might have missed this in the appendix. However, the comment lacks specific examples or references to support the claim that pathological projection matrices could skew the scores. Without detailed reasoning or evidence, the claim is difficult to verify, making the comment 2. The authors would need to provide more context or examples to fully understand and address the concern raised in the comment.", "helpfulness_rationale": "The review comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. While the comment identifies a potential area for further exploration and suggests a specific aspect to consider, it lacks detailed guidance or actionable advice on how to address this issue or what specific steps the authors should take to improve their draft. The feedback is 3 as it points out a potential area for improvement, but it does not provide comprehensive or detailed suggestions, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides several specific questions and suggestions for the authors to address. It asks for an example of synthetic data, clarifies the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggests explicitly writing down the model used in the appendix. These actions are clear and direct, allowing the authors to understand exactly what needs to be done to improve their draft. The comment is fully actionable as it provides concrete guidance on how to address the issues raised. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"synthetic data,\" \"Figure 1,\" and \"predicted training count data,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear questions and suggestions for the authors to clarify and improve their work, such as asking for an example of synthetic data and clarifying the meaning of \"support data\" and \"predicted training count data.\" This level of detail and specificity makes the comment 5 and informative for the authors. Therefore, this comment is rated as 5.", "verifiability_rationale": "The review point consists of questions and suggestions for the authors to clarify and improve their paper. It does not contain any subjective opinions or claims that require verification. The questions are logical and straightforward, and the suggestions are actionable. Therefore, this comment is classified as \"No\".", "helpfulness_rationale": "The review comment provides specific questions and suggestions for the authors to address, such as asking for an example of synthetic data, clarifying the meaning of \"support data\" and \"predicted training count data\" in Figure 1, and suggesting explicitly writing down the model used in the appendix. These actions are clear and actionable, offering the authors concrete guidance on how to improve their draft. The feedback is detailed and addresses specific areas of concern, making it 5 for the authors. Therefore, this comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit actions or concrete details on how to improve the model\"s complexity or address the identified issue. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the model is overly simple, which is both a feature and a bug. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. Without this context, the authors cannot accurately identify where the issue lies, making the comment weakly grounded. Additionally, the comment is specific in identifying the issue as the model being overly simple, but it does not provide guidance on how to address this issue. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the model is overly simple, which is both a feature and a bug. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s complexity, suggesting that it is overly simple. While this observation is noted, the comment lacks specific guidance or suggestions on how the authors might address this issue. It does not provide actionable steps or insights into how to improve the model\"s complexity or address the identified problem. As a result, the feedback is 3, as it highlights a potential area for improvement but does not offer detailed guidance for the authors to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the work\"s narrow focus on a specific task and language might limit its broader impact. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might broaden the scope or impact of their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It provides a general observation about the narrow focus of the work, but without referencing specific sections or elements, the authors cannot confidently identify the area that needs attention. The comment is also not specific, as it does not detail what aspects of the work could be broadened or how the impact might be limited. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the work\"s narrow focus on a specific task and language might limit its broader impact. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation of the work, specifically that its narrow focus on a specific task and language might limit its broader impact. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or broaden the scope of their work. Without actionable feedback or suggestions, the authors may find it difficult to improve their draft based on this comment alone. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the originality of the paper, suggesting that the findings are similar to those reported in previous works, particularly in the context of NNbased clustering algorithms. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of their work could be improved to demonstrate novelty. The comment implies that the authors should consider expanding their analysis or providing a more detailed comparison to highlight the unique contributions of their work. While the action is somewhat inferred, it lacks concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the originality of the paper by questioning the novelty of the findings in the context of previous works, particularly NNbased clustering algorithms. It mentions that the findings have been reported in previous works, which suggests that the paper does not contribute novelly to the understanding of the winnertakeall property. However, the comment does not specify which part of the paper discusses these findings or how the authors might address this issue. The lack of specific references or sections makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the findings are similar to those reported in previous works, particularly in the context of NNbased clustering algorithms, and that the paper does not contribute novelly to the understanding of the winnertakeall property. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains 3, as the authors may need to seek additional information to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the originality of the paper, specifically questioning whether the findings are similar to those reported in previous works, particularly in the context of NNbased clustering algorithms. It suggests that the paper does not contribute novelly to the understanding of the winnertakeall property, especially given the simplified settings used. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of their work could be improved to demonstrate novelty. While it identifies a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer how to address the concern, which limits the comment\"s usefulness."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of runtimes in the experiments to aid readers in applying the method. While the comment provides explicit actions\u2014mentioning the computational cost and including runtime examples\u2014it does not specify how to integrate these elements into the main paper or experiments. The actions are clear and concrete, but the lack of detailed guidance on implementation makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of runtimes in the experiments to aid readers in applying the method. However, the comment does not specify which part of the paper this should be included in, making it weakly grounded. It is specific in suggesting what needs to be addressed\u2014mentioning the computational cost and providing runtime examples. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method and include a rough example of runtimes in the experiments. This claim is 3 as it provides a logical suggestion for improving the paper\"s clarity and motivation. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the paper by mentioning the negligible computational cost of CHR and suggesting the inclusion of runtime examples in the experiments. This feedback is actionable and offers concrete guidance on how the authors can enhance the motivation and clarity of their work. By highlighting these aspects, the comment helps the authors address potential weaknesses and improve the overall impact of their research. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. The comment is explicit in its request for clarification and provides a specific direction for improvement. It instructs the authors to explain how the spatial arrangement of sensors might influence the process, which is a concrete action they can take to enhance the clarity of their paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests the authors to elucidate the EEG token quantization process and to understand the role of the spatial arrangement of EEG sensors in this process. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should elucidate the EEG token quantization process in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This is a constructive suggestion that provides a clear direction for improvement. However, the comment lacks specific examples or references to support the claim that the spatial arrangement of sensors plays a role in the process. While the suggestion is logical and actionable, the lack of detailed examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of ambiguity in the paper, namely the interpretation of Figure 3, which presents EEG topography plots for both input and output during the EEG token quantization process. The authors are advised to elucidate this procedure in greater detail, particularly focusing on the role of the spatial arrangement of EEG sensors. This feedback is clear and actionable, providing a specific direction for improvement that could enhance the clarity and understanding of the paper. By addressing this suggestion, the authors can significantly improve the interpretability of their results and strengthen the overall presentation of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment does not provide explicit guidance on how the authors should revise their approach to address the problem more directly. The action is implicit and vague, as it does not specify what changes need to be made to align with the reviewer\"s critique. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, it does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the approach but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. However, the comment does not provide any specific reasoning, examples, or references to support why this approach is problematic or how it fails to address the problem directly. Without additional context or justification, the claim remains 1, as the authors cannot understand the basis for the critique. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment critiques the authors for using the complexity of checking on the Witness oracle, which is described as \"polynomial time\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment lacks specific guidance or suggestions on how the authors might improve their approach to better address the problem. While it identifies a potential issue, it does not provide actionable feedback or alternative strategies for the authors to consider. As a result, the comment is 2, as it offers limited insight into how the authors can enhance their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. The comment is explicit in its suggestion and provides concrete details on how the authors can address the issue by including these comparisons. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. However, the comment lacks detailed reasoning or references to support why these comparisons are necessary or how they would enhance the paper. Without additional context or justification, the claim is 3, as it provides a suggestion but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a concrete example of a baseline to consider, which is testing on a smaller subset of RepoEval. This feedback is actionable and offers a clear direction for the authors to enhance their work by incorporating additional baselines. However, the comment could be more helpful if it provided more detailed guidance on how to implement these comparisons or why they are essential. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria used for this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detail and consider additional tasks or datasets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in that it highlights a potential issue with the scope of the evaluation, but without clear references, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not provide any specific reasoning, examples, or references to support why this choice might limit generalizability or what alternative approaches could be considered. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It questions the criteria behind this selection and suggests that the authors should provide more insight into why this specific subset was chosen. This feedback is 3 as it highlights a potential limitation in the scope of the evaluation and encourages the authors to consider the broader applicability of their findings. However, the comment could be more helpful if it provided specific examples or criteria for the selection process, or suggested alternative tasks or datasets that might yield different insights. Overall, the comment offers a starting point for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions regarding the use of shiftedMNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies that the authors should clarify the rationale behind this choice. The second question suggests showing performance on test samples from the observational (in) distribution, indicating that the authors should provide this information to better understand the model\"s performance. While the comment provides explicit questions that guide the authors to clarify and provide additional information, it lacks concrete instructions on how to address these questions or what specific actions to take. Therefore, the comment is 3, as it provides a clear direction but does not offer detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses two specific issues related to the use of shiftedMNIST and the performance of the model and baselines on test samples from the observational (in) distribution. It explicitly mentions \"shiftedMNIST\" and \"test samples from the observational (in) distribution,\" providing clear grounding for the parts of the paper being discussed. The comment is specific in its suggestions, as it requests clarification on the rationale behind the choice of shift values and the inclusion of performance metrics on test samples from the observational (in) distribution. This allows the authors to understand exactly what needs to be addressed and why. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises two questions about the use of shiftedMNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies a need for clarification on the rationale behind this choice. The second question suggests showing performance on test samples from the observational (in) distribution, indicating a need for additional information to better understand the model\"s performance. However, the comment does not provide any specific reasoning, examples, or references to support these claims, making it difficult for the authors to understand the basis of the questions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises two important questions regarding the use of shiftedMNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies that the authors should clarify the rationale behind this choice. The second question suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, indicating that the authors should provide this information to better understand the model\"s performance. While the comment identifies areas for improvement and provides specific questions for clarification, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it directs the authors to areas that need further explanation and analysis, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of the algorithm should be examined. The action is implicit, as the authors need to infer that they should analyze the quality of the local minima, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides a direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of local minima, particularly the approximation ratio, under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of local minima found by Algorithm 1, specifically focusing on the approximation ratio under certain assumptions. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggested improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that while the paper analyzes the convergence of Algorithm 1 to permutations as local minima, it lacks an analysis of the quality of these local minima. The comment suggests that the authors should consider analyzing the approximation ratio of these local minima under certain assumptions, which is a valuable and actionable suggestion. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this analysis. Overall, the feedback is 4 as it points out a clear area for improvement and offers a constructive suggestion, but it could be more comprehensive with additional details. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, specifically referencing a sentence in the paper. It also questions the robustness of the Cans model, suggesting that it largely comes from the information redundancy implemented in the weight pool. However, the comment does not provide explicit guidance on how to address these questions or what specific actions the authors should take to clarify or improve their draft. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. However, it does not provide any evidence, reasoning, or references to support the claim that the robustness of the Cans model largely comes from the information redundancy implemented in the weight pool. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about how information redundancy is built into the Fill, Propagate, and Decode algorithms, referencing a specific sentence in the paper. It also questions the robustness of the Cans model, suggesting that it largely comes from the information redundancy implemented in the weight pool. However, the comment does not provide any suggestions or guidance on how the authors might address these questions or improve their draft. It lacks actionable feedback, leaving the authors without a clear path forward. Therefore, the comment is 2, as it identifies a potential area for clarification but does not offer constructive advice or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of the added complexity of using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice is not ablated, and the authors should consider whether one IN would suffice. However, the comment does not provide explicit guidance on how to address this question or what actions the authors should take to clarify or resolve it. The action is implicit and vague, as it leaves the authors to infer the need for further analysis or experimentation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in questioning the design choice, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. However, it does not provide any evidence, reasoning, or references to support the claim that this design choice is important or how it impacts the model. Without specific justification or examples, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. It prompts the authors to consider whether one IN would suffice, which is a relevant and important question for understanding the model\"s complexity and efficiency. However, the comment does not provide any guidance or suggestions on how to address this question or what experiments might be needed to substantiate the claim. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This provides a clear and explicit action for the authors to take, as they can directly apply this suggestion to their draft. The comment is specific in its request for additional experiments, which helps the authors understand exactly what needs to be done to strengthen their claims. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for experimental results that exclude the mixup technique to demonstrate the pure contribution of the proposed method. This provides the authors with a clear understanding of what additional experiments are required to support their claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include experimental results of excluding the mixup technique from the proposed method to demonstrate its pure contribution. This claim is 3 as it provides a clear direction for the authors to take, but it lacks specific examples or references to support the need for such experiments. While the suggestion is logical, the comment could be more robust with additional evidence or references to substantiate the claim. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include experimental results of excluding the mixup technique from their proposed method. This is a clear and actionable suggestion that directly addresses a potential gap in the paper\"s claims regarding the pure contribution of the proposed method. By providing a specific direction for additional experiments, the comment helps the authors strengthen their claims and demonstrate the necessity of the mixup technique. This feedback is 4 as it offers a clear and constructive suggestion for improvement, though it could be further enhanced with more detailed guidance or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. While the questions are explicit and direct, they do not provide any guidance on how the authors should address these questions or what changes might be necessary. The authors are left without any actionable steps to take, making the comment 1. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. However, it does not specify which part of the paper these questions relate to, making it weakly grounded. The questions are specific in nature, as they seek clarification on the implementation details of the attention mechanism. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are factual and seek clarification rather than making subjective claims. The comment does not contain any claims that require verification or justification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are clear and direct, providing the authors with specific areas to clarify in their draft. However, the comment does not offer any suggestions or guidance on how to address these questions or what changes might be necessary. While it identifies a potential area for improvement, it lacks depth and actionable feedback, making it 3. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to their draft. The comment lacks concrete guidance on how to improve the paper, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its request for details, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the inputoutput mapping. However, it does not provide any claim, suggestion, or critique that requires verification. The comment is purely factual and descriptive, lacking any opinions or assertions that need to be substantiated. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the methodology, noting that the authors do not provide details on how the network is trained to fit the residual instead of directly learning the inputoutput mapping. This feedback is valuable as it highlights a potential gap in the clarity of the methodology section. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their draft. Without specific advice or examples, the authors may find it challenging to incorporate the necessary details. Therefore, the comment is 3, as it identifies an area for improvement but does not provide comprehensive guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not explicitly instruct the authors to provide more details about the experiment setup or how it relates to the BadNets paper. While the authors can infer that they need to clarify the experimental setup, the action is implicit and somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not specify which part of Section 3.3 is being referred to, making it weakly grounded. The comment is specific in asking for details about the experiment setup, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not contain a claim or assertion that requires verification. It is a request for clarification and additional information, which is helpful but does not involve making a claim that needs to be substantiated. Therefore, this comment is classified as \"No\".", "helpfulness_rationale": "The review comment requests clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment lacks specificity and does not provide detailed guidance on how the authors should address this request. While it identifies an area for improvement, it does not offer actionable steps or suggestions for the authors to take. Therefore, the comment is 2, as it provides a vague indication of what needs clarification but does not offer concrete advice or direction for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether an error in the initial calibration steps of the algorithm might explain the speed disparities observed between the RSPs and FDs. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to investigate or correct the error. The comment lacks concrete guidance on how to proceed, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"Section III of \u201cRecognition and Velocity Computation of Large Moving Objects in Images\u201d,\" which provides full grounding as the authors can accurately identify the section being addressed. It also specifies the issue by questioning whether an error in the initial calibration steps might explain the speed disparities observed between the RSPs and FDs. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between RSPs and FDs. This feedback is 3 as it identifies a potential issue that could impact the results, prompting the authors to investigate and address it. However, the comment lacks specific guidance on how to identify or correct the error, making it incomplete. Without actionable suggestions or detailed reasoning, the authors may struggle to fully address the concern. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, arguing that this is not a significant issue compared to other techniques like backprop. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve their draft. It lacks actionable steps or concrete advice, leaving the authors without a clear understanding of what to do to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ASAP (and similar methods)\" and \"artificial networks,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the concern regarding the resemblance of these networks to biological networks compared to other techniques like backprop. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, arguing that this is not a significant issue compared to other techniques like backprop. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to substantiate the assertion that the resemblance is not significant. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the claim that artificial networks trained using ASAP (and similar methods) do not necessarily resemble biological networks, suggesting that this is not a significant issue compared to other techniques like backprop. However, the comment does not provide any specific guidance or suggestions on how the authors might address this concern or improve their draft. It lacks actionable feedback, leaving the authors without a clear understanding of what to do to address the issue. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer constructive advice or actionable steps for the authors to take. The score aligns with a rating of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not provide explicit instructions or suggestions on how the authors should address this concern, such as conducting a statistical significance test or providing justification for the closeness of the numbers. While the comment implies that the authors should consider this aspect, it lacks concrete guidance on how to implement it. Therefore, the comment is 3, as it identifies a potential issue but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. However, it does not specify which part of the paper this comparison is made, nor does it provide any guidance on how to address this issue. The authors cannot confidently determine which section or part of the paper is being referenced, making the comment weakly grounded. Additionally, the comment is specific in questioning the statistical significance of the numbers, but it lacks detailed guidance on how to conduct the test or interpret the results. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not provide any specific examples, references, or detailed reasoning to support the claim that the numbers are close. Without additional context or justification, the reviewer\"s question remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the statistical significance of the numbers when comparing the proposed method with baselines. This is a crucial aspect for ensuring the robustness and reliability of the results. However, the comment does not provide any guidance or suggestions on how the authors might address this issue, such as conducting a statistical significance test or providing justification for the closeness of the numbers. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically focusing on common inference tasks. It asks which tasks can be computed exactly or approximately with an NPSPECHMM. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on learning HMMs with nonparametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the impact of these distributions on inference and asks about common inference tasks in discrete HMMs, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically asking which common inference tasks can be computed exactly or approximately with an NPSPECHMM. While the question is clear and directly relates to the paper\"s focus, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks depth and does not offer any guidance or justification for the question, making it difficult for the authors to understand the basis of the inquiry. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of nonparametric emission distributions on inference in HMMs, specifically focusing on common inference tasks such as filtering, smoothing, and marginal observation likelihood. It asks which of these tasks can be computed exactly or approximately with an NPSPECHMM. While the comment identifies a potential area for clarification and exploration, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The feedback is 3 as it points out a gap in the paper\"s discussion but lacks depth and actionable advice. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a deficiency in the analysis of experimental results, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. While the comment identifies a gap in the analysis, it does not offer explicit guidance on how the authors should address this issue or what specific aspects of the results need further exploration. The action is implicit, as the authors are expected to infer that they should provide a more detailed analysis of the results. However, the lack of concrete suggestions or examples makes the comment somewhat vague and challenging for the authors to act upon. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, providing a clear indication of what needs to be addressed. This level of detail helps the authors understand the specific issue and how to improve their analysis. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a gap in the analysis but lacks specific examples or references to support the claim. The authors are expected to infer that they should provide a more detailed analysis to address this issue, but the comment does not offer detailed guidance or examples to enhance the analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the analysis of experimental results, specifically noting that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is valuable as it highlights a gap in the depth of the analysis, suggesting that the authors should delve deeper into the reasons behind the observed results. However, the comment could be more helpful if it provided specific examples or guidance on how the authors might analyze the results further. While it prompts the authors to enhance their analysis, the lack of detailed suggestions limits its impact. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. While the comment implies an action\u2014namely, to provide a justification for the selection of datasets\u2014it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to explain their dataset selection process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the dataset selection process, but without explicit grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. However, the comment does not provide any justification or reasoning for this choice, nor does it offer any references or examples to support the claim. Without additional context or explanation, the authors are left to infer the reasoning behind the dataset selection, making the claim 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind considering only 10 out of 120 datasets for comparison, specifically asking why the authors did not compare batch and greedy methods in the remaining 110 datasets. This question highlights a potential gap in the analysis or justification of the dataset selection process. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for improvement, it lacks actionable advice or detailed feedback, making it 3. The authors are left to infer the need for clarification and improvement, but without specific suggestions, the feedback is limited in its impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the motivation in the introduction regarding lowrank factorization, suggesting that it is unnecessary given the main result focuses on polytopes. It also implies that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the motivation in the introduction regarding lowrank factorization, suggesting it is unnecessary given the focus on polytopes. It also implies that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. However, the comment does not specify which part of the introduction or the paper this issue pertains to, making it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific about the content of the concern, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the motivation in the introduction regarding lowrank factorization, suggesting it is unnecessary given the focus on polytopes. It also implies that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. However, the comment lacks specific examples or detailed reasoning to support the claim that the motivation is unnecessary or to explain why the implications for lowrank matrix factorization should be discussed. Without concrete evidence or references, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the motivation in the introduction, specifically questioning the relevance of lowrank factorization given that the main result focuses on polytopes. It suggests that if the result has implications for lowrank matrix factorization, these should be explicitly discussed. This feedback is 3 as it points out a potential gap in the motivation and encourages the authors to consider the broader implications of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to address this issue, making it actionable for the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point asks the authors to explicitly specify the labels for each dataset in section 4.1, including their source. It questions whether the labels are derived from the dataset itself or from additional information, particularly for caspealr1 and mugshot. While the comment implies that the authors should provide this information, it does not explicitly instruct them to do so or offer guidance on how to present the labels. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the labels and their sources. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions section 4.1, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is needed: the labels for each dataset in section 4.1, including their source (from the dataset itself or from additional information). This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point asks the authors to clarify the labels for each dataset in section 4.1, specifically questioning the source of these labels for caspealr1 and mugshot. While the comment is clear and specific, it does not provide any additional context, reasoning, or references to support the request. The authors are left to infer that clarification is needed, but without explicit guidance or examples, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area of confusion regarding the labels used in section 4.1. It prompts the authors to clarify the source of these labels, particularly for caspealr1 and mugshot, which are not explicitly addressed. This feedback is clear and actionable, as it directs the authors to provide additional information that would enhance the clarity and completeness of their paper. However, the comment could be more helpful if it offered specific examples or guidance on how to present the labels. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit guidance or suggestions on how to address these issues or improve the clarity of the explanation. The authors are left to infer that they need to clarify the calculation of \u03bb and provide a more detailed explanation of the ELLA\"s performance in COMBO environments. This lack of explicit and concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (Page 9, lines 310313 and Page 8, lines 281285), allowing the authors to accurately identify the parts being addressed. It also specifies what the authors need to understand, namely the process of calculating \u03bb and the explanation of why ELLA does not increase sample efficiency in a COMBO environment. Additionally, the comment references specific papers 1, 2, and 3, which provides context and suggests further reading. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the sensitivity of performance and sample efficiency to \u03bb parameters and the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment lacks specific details or references to support these claims, making it difficult for the authors to understand the basis of the concern. The absence of detailed reasoning or examples makes the claim 3, as the authors may need to infer the basis of the concern themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the sensitivity of performance and sample efficiency to \u03bb parameters and questions the process of calculating \u03bb. It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment, referencing specific papers to provide context. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the clarity of the explanation. While it identifies areas for improvement, it does not provide actionable steps or specific advice, making it 3. The authors would need to infer the need for clarification and additional explanation, which limits the comment\"s overall impact."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point mentions that an alternating direction method is used to solve a minmin problem but does not specify which method is being referred to. This lack of specificity makes it difficult for the authors to understand which method is being discussed and how it relates to the minmin problem. Without this information, the authors are left without a clear action to take, as they cannot identify the specific method or understand its relevance. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what is being mentioned or how it relates to the minmin problem. The authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity in explaining what needs to be clarified or addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a factual statement, as it mentions the use of an alternating direction method to solve a minmin problem. It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is brief and lacks specificity, as it only mentions that an alternating direction method is used to solve a minmin problem without specifying which method is being referred to. This lack of detail makes it difficult for the authors to understand the context or how to address the issue. The comment does not provide any actionable feedback or suggestions for improvement, leaving the authors with no guidance on how to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to expand the experiments or what additional baselines should be included. The authors know that they need to address these limitations but lack detailed instructions on how to do so. Therefore, the comment is 3, as it provides a clear action but lacks concrete details on implementation.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not specify which parts of the paper these issues are related to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues with the experiments, it lacks grounding as it does not provide clear references to the relevant sections of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments should be more comprehensive and general, specifically noting that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of these suggestions or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experiments section, noting that they should be more comprehensive and general. It highlights the limitations of the current experiments, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. This feedback provides a clear direction for the authors to enhance their experiments, but it lacks detailed guidance on how to achieve this comprehensiveness or generalization. While the comment is 3 as it points out areas for improvement, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should elaborate on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. It provides a specific example of how the bound is guaranteed to hold due to conditioning on the previous iterate. However, the comment does not explicitly instruct the authors on how to elaborate on this point, such as by providing additional explanations, examples, or references. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the explanation of the conditions for Hoeffding\"s bound. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific lines of the paper (124125), allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear request for elaboration on the conditions under which Hoeffding\"s bound holds, particularly in the context of stochastic algorithms. This guidance is detailed and specific, enabling the authors to understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should elaborate on the conditions under which Hoeffding\"s bound holds, specifically mentioning the role of independent samples and conditioning on the previous iterate. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the elaboration of the conditions under which Hoeffding\"s bound holds. It provides a clear example of how stochastic algorithms guarantee the validity of the bound due to conditioning on the previous iterate. However, the comment lacks actionable guidance on how the authors might elaborate on this point, such as by providing additional explanations, examples, or references. While it points out a potential area for improvement, it does not offer detailed suggestions or a clear path for the authors to follow. Therefore, the comment is 3, as it highlights a specific area for enhancement but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. While it implies that this addition would be beneficial, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the table would benefit from such an addition. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to incorporate the suggested approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not specify which part of Table1 would benefit from this addition or what specific issues the authors are addressing. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also specific in suggesting a particular approach, but without context, it is difficult for the authors to understand how to apply this suggestion. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. However, it does not provide any justification or reasoning for why this addition would be beneficial or how it would improve the paper. Without specific examples or references, the claim lacks support and is therefore 1. The comment is purely speculative and does not offer any actionable guidance for the authors to follow.", "helpfulness_rationale": "The review comment suggests adding an optimizationbased metalearning approach, such as MAML or implicitMAML, to Table1. This feedback is 3 as it points out a potential area for improvement by suggesting a specific technique that could enhance the paper. However, the comment lacks depth and does not provide detailed reasoning or guidance on why this addition would be beneficial or how it would impact the overall contribution of the paper. The authors are left to infer the exact steps needed to incorporate this suggestion, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, it does not provide explicit guidance on how the authors should revise the text to address this concern. The comment implies that the authors need to clarify their use of the term, but it lacks concrete instructions on how to do so. Therefore, the comment is 3, as it identifies a potential issue but does not provide detailed guidance on how to implement the suggested change.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" recommending careful consideration of its distinction from temporal relationships. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment on page 1 points out a potential issue with the use of the term \"causal mechanisms,\" suggesting that it should be used carefully as it is distinct from a temporal relationship. This feedback is clear and identifies a specific area for improvement, but it lacks detailed guidance on how the authors might address this concern. While it provides a starting point for revision, it does not offer comprehensive suggestions or examples, making it 3. The comment is valuable in highlighting a potential issue but could be more helpful with additional guidance or examples to assist the authors in making the necessary revisions."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment implies that the authors should consider whether the performance drop is significant enough to support the claim of \"better than random.\" However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to strengthen their argument. The action is implicit and vague, as it leaves the authors to infer the need for further clarification or evidence. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"You write: \"Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance\" I\"m unsure that \"better than random\" is a strong demonstration of capability.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the strength of the demonstration of capability, providing a clear direction for the authors to consider and potentially address. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment is 3 as it provides a specific question about the significance of the performance drop, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to provide additional context or evidence to address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment is 3 as it identifies a potential area for clarification or further evidence. However, it does not provide specific suggestions or guidance on how the authors might address this concern or strengthen their argument. The feedback is clear but lacks depth and actionable advice, making it 3 rather than fully helpful. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the results in section 4 are limited to shallow fullyconnected ReLU networks. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might extend their results to deeper networks or how they could improve the applicability of their findings. Without specific suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results in section 4 apply only to shallow fullyconnected ReLU networks, providing a clear understanding of the limitation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in section 4 apply only to shallow fullyconnected ReLU networks. This is a factual statement that is supported by the content of section 4, which likely discusses the limitations of the results to such networks. However, the comment does not provide additional context, examples, or references to support this claim beyond what is already present in the paper. While the claim is verifiable, it lacks depth and could be strengthened with more detailed reasoning or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the results presented in section 4, noting that they apply only to shallow fullyconnected ReLU networks. This feedback is clear and actionable, as it highlights a constraint on the scope of the results. However, it does not provide suggestions on how the authors might address this limitation or extend their findings to more complex networks. While the comment is 3 in pointing out a specific issue, it lacks depth and guidance on potential improvements, making it a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide results for the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not specify how the authors should present these results or what aspects of the results are important to highlight. The comment implies that the authors should include results, but it lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more information about what was observed in this discussion, indicating that the authors need to provide results or detailed observations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the discussion of using sequential MCB vs a single MCT layers for the decision head, noting that no results were shown. However, it does not provide any specific reasoning, examples, or references to support why this observation is important or how it impacts the paper. The comment lacks detailed justification or context, making it difficult for the authors to understand the significance of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires further clarification, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It notes that no results were shown, which is a significant gap in the analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what results they should include. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is 3, as it points out a critical gap but does not offer concrete suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several minor language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). It also suggests that the authors should proofread the paper and fix all language problems. While the comment identifies specific instances of language issues, it does not provide explicit guidance on how to address these issues or what specific language problems need to be corrected. The action is implicit, as the authors can infer that they need to revise the language in these instances, but the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific instances of language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the exact language problems that need to be corrected. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of minor comments on language usage, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). These comments are factual observations about language issues, and the reviewer suggests proofreading the paper to address these problems. However, the comment lacks specific examples or detailed reasoning to support the need for proofreading or to clarify the language issues. Without additional context or justification, the claim is 3, as it provides a general suggestion but lacks depth and specificity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several minor language issues in the paper, such as \"we typically considers\" in the context of (7), \"two permutation\" in the context of Theorem 1, and \"until converge\" in the context of (14). It also suggests that the authors should proofread the paper and fix all language problems. While the comment points out specific areas that need attention, it lacks detailed guidance on how to address these issues or what specific language problems need correction. The feedback is 3 as it directs the authors to areas for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. While it implies that the authors should consider this aspect, it does not provide explicit guidance on how to control the number of distribution sets or what specific actions should be taken. The comment is somewhat vague, as it leaves the authors to infer the need for further exploration and experimentation. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its question about the number of distribution sets, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not provide any specific reasoning, examples, or references to support why this choice is questionable or what impact it might have. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. This feedback is 3 as it identifies a potential area for further investigation or clarification. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment could be more helpful if it offered actionable advice or examples of how to control the number of distribution sets or what implications this choice might have. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the perplexity experiments should be conducted using transformerbased language models, which are more current and relevant to the field. While the comment provides a clear direction for improvement by recommending the use of transformer models, it does not specify which transformer models should be used or how the experiments should be conducted. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the perplexity experiments should be conducted using transformerbased language models, which are more current and relevant to the field. However, it does not specify which transformer models should be used or how the experiments should be conducted. The comment is fully grounded as it mentions the type of models being used, but it is not specific because it does not provide detailed guidance on which models to use or how to conduct the experiments. Therefore, this comment is 4, aligning with category 4.", "verifiability_rationale": "The review point suggests that the perplexity experiments should be conducted using transformerbased language models, which are more current and relevant to the field. This claim is 3 as it provides a logical reasoning for why transformer models are more appropriate, aligning with current NLP trends. However, it lacks specific examples or references to support the claim, which could enhance its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the perplexity experiments, noting that they are conducted on obsolete language models that are rarely used in current NLP research. The comment suggests that the authors should consider using transformerbased language models, which are more relevant and widely adopted in the field. This feedback is clear and actionable, providing a specific direction for improvement. However, it could be more helpful if it included suggestions for which transformer models to use or how to adapt the experiments to align with current trends. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear path forward."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. While the comment provides a clear direction for improvement, it lacks specific guidance on which aspects of the experiments need to be expanded or what specific types of additional experiments would be beneficial. The action is explicit but somewhat vague, as it does not detail the exact nature of the additional experiments or how they should be conducted. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the experiments are not sufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment does not specify which part of the paper the experiments are related to, making it weakly grounded. It is specific in suggesting the need for more experiments, but without clear references to specific sections or figures, the authors may find it challenging to identify the exact areas that require improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are not sufficient and suggests that more empirical or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. However, the comment lacks specific details or examples to support the claim that the current experiments are insufficient. It does not provide a clear rationale for why more experiments are necessary or how they would address the identified gaps. Without additional context or justification, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the experiments are not sufficient to fully validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that additional empirical or toy experiments should be conducted to address this gap. While the comment provides a clear direction for improvement, it lacks specific guidance on the types of experiments that would be beneficial or how they should be designed. This leaves the authors with a general idea of what needs to be done but without detailed instructions, making the feedback 3. Therefore, the comment aligns with a score of 3, as it offers actionable feedback but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the estimation process. The comment lacks concrete guidance on what needs to be done to clarify or address the issue of misestimation. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its critique of the estimation process but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific reasoning, examples, or references to support the claim that the estimation of mu is unclear or problematic. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific guidance or suggestions on how to address this issue or improve the estimation process. The comment lacks actionable insights and detailed feedback, leaving the authors without a clear understanding of how to proceed. As a result, the comment is 2, as it does not offer any meaningful improvements or suggestions for the authors to consider. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests a specific way to present the sensitivity of the performance to initialization by varying the distance of the initialization matrix M^0 from the groundtruth matrix M^*. It provides a clear and concrete action for the authors to take, which is to include this analysis in their draft. The comment is explicit and provides detailed guidance on how to implement the suggested action, making it 5.", "grounding_specificity_rationale": "The comment suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the groundtruth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in detailing the proposed analysis, but the lack of explicit grounding makes it 3. Therefore, it aligns with category 3.", "verifiability_rationale": "The review point suggests a specific way to present the sensitivity of performance to initialization by varying the distance of the initialization matrix M^0 from the groundtruth matrix M^*. It provides a clear and detailed explanation of how this analysis should be conducted, including the range of distances to be considered and the expected impact on mean error and variance. However, it does not offer any specific examples or references to support the claim that this analysis would be beneficial or how it aligns with existing literature. The lack of detailed reasoning or evidence makes the claim 3, as it provides a direction for improvement but lacks comprehensive support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the presentation of the paper by analyzing the sensitivity of performance to initialization. It proposes a method to vary the distance of the initialization matrix M^0 from the groundtruth matrix M^* and reports the performance accordingly. This feedback is actionable and offers a clear direction for the authors to enhance their draft by including this analysis. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or discussed the expected outcomes in more detail. Overall, the comment is 4 as it directs the authors towards a specific improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This comment provides a specific and explicit action for the authors to consider, as they can evaluate whether the absolute value is necessary given that tensor entries are real. The action is concrete, as it clearly specifies which part of the paper needs to be examined and what consideration should be made. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 77,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue with the definition of the Frobenius norm, suggesting that the absolute value operation is not needed since tensor entries are real numbers. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the absolute value operation in the definition of the Frobenius norm in line 77 is not needed because tensor entries are real numbers. This claim is 3 as it provides a logical reasoning based on the nature of tensor entries. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a minor point regarding the Frobenius norm definition, specifically questioning the necessity of the absolute value operation given that tensor entries are real numbers. This feedback is clear and actionable, as it directs the authors to reconsider the mathematical formulation in line 77. By suggesting that the absolute value might not be needed, the comment provides a specific and constructive suggestion for improvement. However, the comment could be more helpful if it offered additional context or examples to support the claim. Overall, the feedback is 4, as it guides the authors towards a more refined understanding of the mathematical formulation. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper only provides bounds in expectation and recommends exploring the possibility of obtaining highprobability bounds, similar to those used in the experiments. It also suggests adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement these suggestions. The action is implicit, as the authors can infer that they need to explore highprobability bounds and add robustness measures. However, the comment lacks concrete guidance on how to achieve these improvements, such as specific methods or techniques to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of bounds in the paper, specifically noting that only bounds in expectation are provided. It suggests exploring the possibility of obtaining highprobability bounds, similar to those used in the experiments, and recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not specify which part of the paper discusses the bounds or where these measures are currently presented. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the type of bounds and measures to be added, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only provides bounds in expectation and suggests exploring the possibility of obtaining highprobability bounds, similar to those used in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment lacks specific examples or references to support the claim about the absence of highprobability bounds or the effectiveness of ensemble methods in achieving them. While the suggestion to add robustness measures is logical, the lack of detailed reasoning or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that only bounds in expectation are provided and suggesting the inclusion of highprobability bounds, similar to those used in the experiments. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is clear and actionable, providing the authors with specific directions for enhancing the rigor and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance on how to implement these suggestions or provided examples of how to achieve highprobability bounds. Overall, the comment is 4 as it highlights important areas for improvement and encourages the authors to consider these enhancements."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the paper\"s motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the model to explicitly enforce diversity. The authors are left without guidance on how to proceed, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title of the paper, which includes the word \"diversity.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the concern: the paper motivates \"diversity\" extensively but does not enforce it explicitly in the model, leading to a disappointment. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses a concern about the paper\"s motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the model does not enforce diversity explicitly. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises a valid concern about the paper\"s motivation of \"diversity,\" noting that the word is present in the title but the model does not explicitly enforce it. The reviewer expresses disappointment with this discrepancy, which could leave the authors questioning the depth of their model\"s approach to diversity. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their model to better incorporate diversity. While it identifies a potential area for improvement, the feedback is somewhat limited in its actionable value, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that some experiments are missing, specifically mentioning \"contrastive learning\" and \"adversarial learning.\" However, it does not provide any guidance on which experiments are missing or how the authors should address this issue. The comment lacks explicit instructions or suggestions for improvement, leaving the authors uncertain about what specific experiments to include or how to enhance their draft. As a result, the comment is 1 because it does not provide any concrete steps for the authors to take. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that some experiments are missing, specifically mentioning \"contrastive learning\" and \"adversarial learning.\" However, it does not specify which parts of the paper these experiments are intended to address or how they relate to the overall content. The authors cannot confidently determine which sections or aspects of the paper need to be revised or expanded. Additionally, the comment lacks specificity in detailing what is missing or how these experiments should be included. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some experiments are missing, specifically mentioning \"contrastive learning\" and \"adversarial learning.\" However, it does not provide any supporting evidence or reasoning to justify why these experiments are missing or why they are important. Without specific examples or references, the claim lacks verifiability, making it difficult for the authors to understand the basis for the criticism. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of certain experiments, namely \"contrastive learning\" and \"adversarial learning.\" This feedback is clear and actionable, as it directs the authors to include these experiments in their draft to enhance its comprehensiveness and depth. By highlighting specific areas that are missing, the comment provides a clear path for the authors to improve their work. However, the comment could be more helpful if it suggested alternative approaches or provided guidance on how to conduct these experiments. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, making it a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while FIDs are still used, there are flaws associated with them and the Inception network. It recommends using DinoV2 Frechet Distances for comparisons, in addition to FID. However, the comment does not provide explicit guidance on how the authors should implement this suggestion or what specific aspects of their draft need to be addressed. The action is implicit and vague, as it does not specify which parts of the paper should be revised or how the authors should incorporate the suggested changes. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"FIDs\" and \"Inception network,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear recommendation to use DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This guidance is detailed and actionable, as it specifies what needs to be done to improve the evaluation process. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there have been clear flaws associated with FIDs and the Inception network, suggesting the use of DinoV2 Frechet Distances for comparisons. However, the comment lacks specific examples or references to support the claim about the flaws of FIDs and the Inception network. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it provides a general suggestion but lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of FIDs and the Inception network, suggesting that there are flaws associated with them. It recommends using DinoV2 Frechet Distances for comparisons, in addition to the widely used FID metric. This feedback is 3 as it points out a specific area for improvement and provides a clear suggestion for alternative evaluation methods. However, the comment could be more helpful if it included more detailed reasoning or examples of the flaws associated with FIDs and the Inception network, or if it suggested specific ways to incorporate the new metric into the draft. Overall, the comment provides a starting point for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include an experiment where the image is occluded, similar to a previous suggestion. It provides two reasons for this suggestion: (a) to simulate irregularity in neural/behavioral data and (b) to inspect the longrange inference capacity of the model. The comment is explicit in its request for additional experiments and provides clear reasoning for why these experiments would be beneficial. It also suggests that these experiments should be reasonably easy to run, which gives the authors a concrete idea of how to implement the suggestion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for an experiment where the image is occluded, similar to a previous suggestion. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides two clear reasons for including this experiment: (a) to simulate irregularity in neural/behavioral data and ((b) to inspect the longrange inference capacity of the model. This detailed explanation helps the authors understand the rationale behind the suggested experiment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should include an experiment where the image is occluded, similar to a previous suggestion. It provides two reasons for this suggestion: (a) to simulate irregularity in neural/behavioral data and (b) to inspect the longrange inference capacity of the model. While the reasoning is logical and provides a clear rationale for the suggested experiment, it lacks specific examples or references to similar experiments in the literature. This makes the claim 3, as the authors can infer the need for such an experiment but may require additional justification or examples to fully understand the reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by including an experiment where the image is occluded. This is a valuable addition as it simulates irregularity in neural/behavioral data and allows for the inspection of the model\"s longrange inference capacity, which is not possible with a nearlysupervised reconstruction task. The comment is specific and provides a clear rationale for why this experiment would be beneficial, making it 4. However, it could be further enhanced by suggesting specific implementation details or providing examples of how this experiment could be conducted. Overall, the feedback is 4 as it offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the clarity of a specific statement in the abstract, suggesting that it is unclear and that the abstract should be more highlevel, omitting technical details. While the comment implies that the authors should revise the abstract to make it clearer, it does not provide explicit guidance on how to achieve this. The action is implicit, as the authors need to infer that they should clarify the statement. However, the comment lacks concrete details on how to make the abstract clearer, such as suggesting specific ways to rephrase the sentence or what aspects of the statement need clarification. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, namely that the statement is unclear and contains technical details that are not necessary for a highlevel abstract. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of a specific statement in the abstract, suggesting that it is unclear and contains technical details that are not necessary for a highlevel abstract. However, the comment does not provide any evidence or reasoning to support why the statement is unclear or why the technical details are unnecessary. Without specific examples or references, the authors may find it difficult to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that the statement is unclear and contains technical details that are not necessary for a highlevel abstract. This feedback is clear and actionable, as it provides the authors with a specific area to improve the clarity and conciseness of their abstract. However, the comment could be more helpful if it offered suggestions on how to rephrase the statement or what aspects of the statement need clarification. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement, allowing them to enhance the overall quality of their paper."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement, it does not explicitly instruct the authors on which modalities to include or how to present the results. The suggestion is somewhat vague, as it lacks specific guidance on which tasks or modalities to focus on. Therefore, the comment is 3, as it gives a general idea of what needs to be done but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss. However, it does not specify which modalities or tasks should be included, nor does it provide any guidance on how to present or analyze the results. The comment is 1 as it does not reference specific parts of the paper, and it is not specific because it lacks detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss. However, it does not provide any specific reasoning, examples, or references to support why these suggestions are important or how they would impact the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestions. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including results in other modalities, such as languagerelated tasks, and questions the significance of expected test loss. While this feedback provides a direction for improvement, it lacks specificity and depth. The comment does not specify which modalities or tasks should be included, nor does it offer detailed guidance on how to present or analyze the results. Additionally, it does not address the broader implications of the suggestions or provide actionable steps for the authors to take. As a result, the comment is 3, as it identifies an area for improvement but does not fully support the authors in enhancing their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. While the comment identifies a specific area needing clarification, it does not provide explicit guidance on how to address this issue or what actions the authors should take to improve their draft. The action is implicit and vague, as the authors are left to infer how to enhance the motivation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/f few training steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue, as it clearly explains the gap in the motivation and the need for the authors to address how the method effectively leverages fewshot learning and ensures generalization. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the work should be further justified, specifically regarding how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"fewshot\" aspect and guarantees generalization to new tasks with 0/few training steps. This feedback is valuable as it highlights a critical area that needs further clarification and justification. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, which limits its helpfulness. While it points out an important area for improvement, the lack of actionable advice makes it 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that some ablations mentioned in previous sections are difficult to find in the subsequent content, suggesting that the writing in this part could be improved. However, it does not provide explicit guidance on what specific aspects need improvement or how the authors should address this issue. The action is implicit and vague, as it leaves the authors to infer that the writing needs improvement but does not specify what needs to be improved or how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that some ablations mentioned in previous sections are difficult to locate in the following content, implying that the writing in this part could be improved. However, it does not specify which sections or parts of the paper contain these ablations, making it weakly grounded. The comment is specific in identifying the issue of difficulty in locating ablations, but without explicit references, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some ablations mentioned in previous sections are difficult to locate in the following content, suggesting that the writing in this part could be improved. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some ablations mentioned in previous sections are difficult to locate in the subsequent content, suggesting that the writing in this part could be improved. However, the comment lacks specific details or suggestions on how the authors might address this issue. It identifies a potential area for improvement but does not provide actionable guidance or examples, making it 3. The authors may gain some insight into the need for better organization or clarity, but the feedback is incomplete and could be more comprehensive to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the differential privacy application is \"halfbaked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The actions are implicit and vague, leaving the authors without clear direction on how to improve their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"given2)5)\" and \"differential privacy application,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the authors should \"think through it more clearly\" and \"move the experimental results from the appendix to the main paper,\" providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the differential privacy application is \"halfbaked\" and recommends moving experimental results from the appendix to the main paper. However, it does not provide specific reasoning or examples to support why the application is considered halfbaked or why the results should be moved. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a potential issue with the differential privacy application, suggesting that it is \"halfbaked\" and could benefit from more clarity. It also recommends moving the experimental results from the appendix to the main paper, which could enhance the paper\"s impact. However, the comment lacks specific guidance on how to address the \"halfbaked\" nature of the application or what specific improvements could be made. While it provides some direction, the feedback could be more actionable and detailed to fully assist the authors in improving their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it critiques the contribution of multilingual chainofthought as being incremental compared to villa chainofthought. However, without grounding, the authors cannot confidently determine which part of the paper needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution of multilingual chainofthought is incremental compared to the villa chainofthought. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the incremental nature of the contribution of multilingual chainofthought compared to the villa chainofthought. While it identifies a potential weakness in the paper\"s contribution, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance their work. The comment lacks actionable advice, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation. It suggests that using robotic manipulation in general could be more appropriate. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the methodology. The action is implicit, as the authors need to infer that they should provide more detail on the methodology\"s specificity. The comment is vague and lacks concrete steps on how to implement the suggested clarification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the clarity of the proposed methodology\"s specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. This feedback highlights a potential ambiguity in the paper, as it does not clearly define the scope or application of the methodology. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or clarify the methodology\"s focus. While it identifies an area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the consistency of the advantage of the UNIFORM procedure over other methods, particularly in the 1shot setting. It suggests that the authors should provide a theory to explain why the method is not as effective in this setting. However, the comment does not offer explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly what to do. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the consistency of the UNIFORM procedure\"s advantage over other methods, specifically noting that the results are not always clear, especially in the 1shot setting. However, it does not specify which part of the paper this issue is discussed in, such as a particular table or section. The comment is specific in its critique of the results but lacks grounding as it does not provide clear references to the sections or figures where the issue is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the consistency of the UNIFORM procedure\"s advantage over other methods, particularly in the 1shot setting, based on the results presented in the tables. However, it does not provide any specific examples, references, or detailed reasoning to support the claim that the results are not always clear or that the authors should provide a theory for the 1shot setting. The comment lacks sufficient evidence and justification to be considered verifiable. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of the UNIFORM procedure\"s advantage over other methods, particularly in the 1shot setting, based on the results presented in the tables. It questions whether the authors have a theory to explain why the method is not as effective in this setting. While the comment highlights a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments could be conducted to clarify the results. The feedback is 3 as it points out a critical area for further investigation, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this, implying that adding such theory would strengthen the paper. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it lacks specific guidance on how to conduct this exploration or what linguistic theories might be relevant. The action is explicit but somewhat vague, as it does not provide detailed steps or examples for the authors to follow. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. This provides full grounding as the authors can accurately identify the sections where the discussion takes place. The comment is also specific, as it asks the authors to consider existing linguistic theories that could explain the phenomenon, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically referencing pages 7 or 8. It also asks if there is any existing linguistic theory that could explain this phenomenon. While the comment provides a clear direction for the authors to explore and potentially enhance their work, it lacks specific examples or references to support the claim that information value is a stronger predictor. The suggestion to consider existing linguistic theories is vague and does not provide detailed guidance on which theories might be relevant or how they could be integrated into the paper. Therefore, the comment is 3, as it provides a general direction but lacks the necessary depth and specificity to fully support the claim.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by questioning the reason why information value is a stronger predictor for dialogue, referencing specific sections of the paper (pages 7 or 8). It also prompts the authors to consider existing linguistic theories that could explain this phenomenon, suggesting that incorporating such theories would strengthen the paper. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their work. However, it could be more helpful if it provided more detailed guidance on which theories might be relevant or how to integrate them into the discussion. Overall, the comment is 4 as it identifies a specific area for improvement and offers a clear suggestion for action."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the authors for not adequately commenting on the use of AutoML approaches beyond improving raw performances, specifically mentioning the extraction of hints for future network architecture design. It suggests that the authors should provide more insight into what the biggest takeaways from the found architecture might be. However, the comment does not explicitly instruct the authors on how to address this issue or what specific actions they should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the authors for not adequately commenting on the use of AutoML approaches beyond improving raw performances, specifically mentioning the extraction of hints for future network architecture design. However, it does not specify which part of the paper this critique refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the use of AutoML approaches, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the authors for not adequately commenting on the use of AutoML approaches beyond improving raw performances, specifically mentioning the extraction of hints for future network architecture design. It suggests that the authors should provide more insight into what the biggest takeaways from the found architecture might be. However, the comment lacks specific examples or references to support the claim that the authors did not spend much time commenting on these aspects. Without detailed examples or references, the authors may find it challenging to understand and address the feedback effectively. Therefore, the comment is considered 2, as it provides some basis for the critique but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by providing more detailed commentary on the use of AutoML approaches beyond just improving raw performances. It highlights the importance of extracting hints that can be reused in the design of new network architectures, which is a valuable insight. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as providing examples or detailed explanations of the takeaways from the found architecture. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the definition of T_a(t), noting that it is used in Section 3.1 but only defined in Section 4. This suggests that the authors may need to ensure that all terms are defined before they are used in the paper. However, the comment does not provide explicit guidance on how to address this issue, such as suggesting where the definition should be placed or how to clarify its usage. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the issue of defining T_a(t) before using it in Section 3.1. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1\" and \"Section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out that the term T_a(t) is used in Section 3.1 but only defined in Section 4, highlighting a clear issue that needs to be addressed. This provides the authors with a clear understanding of what part of the paper requires attention and what specific problem is being pointed out. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a potential issue with the definition of T_a(t), noting that it is used in Section 3.1 but only defined in Section 4. This observation is factual and requires no additional evidence or reasoning to be understood. The comment is a normal statement, as it describes a factual observation about the paper\"s structure and content. Therefore, it does not contain a claim that needs verification, and it should be labeled as \"No\".", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the term T_a(t) is used in Section 3.1 but is only defined in Section 4. This observation highlights a potential inconsistency or lack of clarity in the paper\"s structure and content. While the comment points out a specific area that needs attention, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is 3 as it directs the authors to a particular area of concern, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises two main concerns: the confusion regarding the empirical analysis in Figure 3 and the large spacing in Equations (9) and (10). For the first concern, the authors are asked to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This action is explicit and concrete, as it clearly instructs the authors to provide detailed explanations. However, the comment does not specify how to address the confusion, leaving the authors to infer the necessary steps. For the second concern, the authors are asked to explain why the adjustments are effective in enhancing the model\"s performance, which is also an explicit and concrete action. The comment is 4 as it provides clear guidance on what needs to be addressed, but it could be more helpful if it included specific suggestions or examples of how to clarify the analysis or improve the presentation of the equations. Overall, the comment is 4, aligning with a score of 4.", "grounding_specificity_rationale": "The comment addresses the confusion regarding the empirical analysis in Figure 3, specifically asking for clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This part of the comment is weakly grounded as the authors cannot confidently determine which part of the paper is being addressed. However, it is specific in detailing what needs to be clarified, which is the impact of the adjustments on model prediction accuracy. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises two questions: one about the confusion regarding the empirical analysis in Figure 3 and another about the large spacing in Equations (9) and (10). The first question prompts the authors to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This is a request for explanation and clarification, which is a subjective opinion or judgment. The second part of the comment questions the large spacing in Equations (9) and (10), which is a factual observation. However, the comment does not provide any evidence or reasoning to support the claim about the spacing, making it difficult for the authors to address the issue. Therefore, the comment is 4, as it contains a claim that is partially supported by factual observation but lacks detailed reasoning or references. The score is 4.", "helpfulness_rationale": "The review comment raises two main concerns: the confusion regarding the empirical analysis in Figure 3 and the large spacing in Equations (9) and (10). The authors are asked to provide additional clarification on how the adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. This request for clarification is clear and actionable, as it directs the authors to provide detailed explanations that would help them understand the impact of these adjustments. Additionally, the comment questions the large spacing in Equations (9) and (10), which is a factual observation that could be improved by addressing the formatting issue. While the comment is 4, it could be more comprehensive if it provided specific suggestions or examples of how to clarify the analysis or improve the presentation of the equations. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should compare their work with the recent related work CoCoOp 1 in the experiments. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to include it in their draft. The action is implicit, as the authors can infer that they need to add a comparison with CoCoOp. However, the comment lacks specific guidance on how to implement this comparison, such as which aspects of the work should be compared or what data should be used. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment explicitly mentions \"the recent related work CoCoOp 1\" and suggests that it should be compared in the experiments. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies the need to compare with CoCoOp, which is a detailed and specific request. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the recent related work CoCoOp 1 should be compared in the experiments. However, the comment lacks specific reasoning or evidence to support this claim. It does not provide a detailed explanation of why CoCoOp is relevant or how its comparison would enhance the paper. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should compare their work with the recent related work CoCoOp 1 in the experiments. This is a valuable suggestion as it highlights the importance of contextualizing the authors\" contributions within the existing literature. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison, such as which aspects of the work should be compared or what data should be used. Despite this, the comment offers a clear direction for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not provide explicit instructions or detailed guidance on how to enhance the figure. The authors are left to infer that they need to improve the figure, but the comment lacks concrete steps on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests improvements to Figure 1, specifically mentioning the need to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what aspects of the figure need improvement, providing clear guidance on how to enhance the figure. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Figure 1 could be improved to better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring. However, the comment does not provide any specific examples, references, or detailed reasoning to support why these improvements are necessary or how they would enhance the figure. The lack of detailed justification makes it difficult for the authors to understand the basis of the suggestion, resulting in an 1 claim.", "helpfulness_rationale": "The review comment provides specific suggestions for improving Figure 1, which could enhance the clarity and effectiveness of the paper. By suggesting that the figure should better illustrate the processing pipeline, including prompt generation, manual checks, demonstration selection with ground truth scores, and automatic scoring, the comment offers actionable feedback that could help the authors improve the presentation of their work. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or provided examples of how the figure could be improved. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This comment provides a clear and explicit action for the authors to take: they should remove or define the abbreviations in the section header. The action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 136,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that abbreviations like \"MoCo\" should not appear in the section header, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that abbreviations like \"MoCo\" should not appear in the section header because a reader might not understand them. This claim is 3 as it provides a logical reasoning for why the inclusion of such abbreviations could be problematic. However, it lacks specific examples or references to support the claim, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of abbreviations in the section header, noting that readers might not understand them. This feedback is clear and actionable, as it provides a direct suggestion for improvement. By recommending that abbreviations like \"MoCo\" should not appear in the section header, the comment helps the authors enhance the clarity and accessibility of their paper. However, the comment could be more helpful if it provided additional guidance on how to define or remove abbreviations effectively. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited. It also notes that many previous works focus on this topic and that adding topic entities seems incremental. However, the comment does not provide specific guidance or suggestions on how to address these issues or improve the paper. The authors are left without a clear understanding of what needs to be done to enhance their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what is trivial or incremental about the improvements or suggest specific ways to enhance the novelty of the paper. The comment lacks both grounding and specificity, making it unsuitable for guiding the authors effectively. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that many previous works focus on this topic. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains 3, as it is based on general observations without strong justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the trivial nature of improvements on different datasets and the limited novelty of the work. It suggests that many previous works have focused on similar topics, and that adding topic entities seems incremental. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or enhance the novelty of their work. While it points out areas for improvement, it does not provide actionable steps or detailed feedback that would help the authors significantly improve their draft. Therefore, the comment is 3, as it highlights important areas for consideration but does not offer comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the authors claim their method performs better than baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors can address this issue or improve their method. It lacks concrete actions or detailed feedback on what specific aspects of the method or experiments need to be revised to demonstrate a more substantial improvement. As a result, the authors are left without clear direction on how to enhance their draft, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of marginal improvements over baselines and the high error range, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern regarding the performance differences between methods and the need for more significant improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" method only shows marginal improvements over baselines, mostly within the error bar range. It suggests that the performance differences between some methods are not very significant. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a key issue with the authors\" claims of marginal improvements over baselines, noting that the error range is high, suggesting that the performance differences are not significant. This feedback is valuable as it highlights a potential overstatement in the authors\" claims and encourages them to reevaluate their results. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue, such as conducting additional experiments or refining their analysis. While it points out a critical area for improvement, the lack of detailed actionable advice limits its overall impact. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method. It also asks for clarification on how to select representative images. However, the comment does not provide explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the action is not concrete or detailed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method and how to select representative images. However, it does not provide any specific reasoning, examples, or references to support why this is an issue or how it could be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. This feedback highlights a potential gap in the paper\"s methodology or experimental design, suggesting that the authors need to clarify how their new evaluation set differs from existing methods and how they ensure the selection of representative images. However, the comment lacks specific guidance or suggestions on how to address these issues, leaving the authors with a general idea of what needs improvement but without actionable steps. Therefore, the comment is 3, as it identifies an area for clarification but does not provide detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These suggestions are clear and direct, allowing the authors to understand exactly what needs to be added to their draft. The comment is fully actionable as it provides concrete guidance on how to improve the paper. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment suggests that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. While it provides some specificity by mentioning the need for a background section and a brief overview of the DPO algorithm, it does not detail how these additions would enhance the paper. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the authors should include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also suggests providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment provides a logical reasoning for the need for these additions, it lacks specific examples or references to support the claim fully. The authors would need to infer the importance of these additions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This would help readers understand the context of the paper. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This feedback is detailed and constructive, offering specific guidance on how to improve the clarity and comprehensibility of the paper. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). While it raises a valid point about the need to clarify the connection between the term and the cited work, it does not provide explicit guidance on how the authors should address this question or incorporate it into their draft. The action is implicit, as the authors need to infer that they should clarify the relevance of the term in the context of the cited work. However, the lack of concrete instructions on how to do so makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider by questioning the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). While it does not contain a subjective claim or suggestion, it prompts the authors to consider the connection between the term and the cited work. However, without further elaboration or context, the comment lacks sufficient detail to be considered verifiable. Therefore, it is classified as \"1.\"", "helpfulness_rationale": "The review comment raises a question about the relevance of the term \"interpretable\" program to the work of DoshiVelez and Kim (2017). This question prompts the authors to consider the connection between the term and the cited work, which could help them clarify their terminology and ensure consistency in their use of terms. However, the comment does not provide specific guidance or suggestions on how the authors might address this question or incorporate it into their draft. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. While this feedback identifies a potential area for improvement, it does not provide explicit guidance on how the authors should expand their experiments to include more datasets or address this limitation. The action is implicit, as the authors can infer that they need to consider adding more datasets to enhance the comprehensiveness of their experiments. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments being limited to MNIST and a single realworld dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the limitation in the experiments, indicating that the authors should consider expanding their experiments to include more datasets. This provides clear guidance on what needs to be addressed to improve the comprehensiveness of the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. This feedback is 3 as it points out a potential area for improvement in the experimental design, but it lacks specific examples or references to support the claim. The authors may infer that expanding the experiments to include more datasets would enhance the comprehensiveness of the study, but the comment does not provide detailed guidance or evidence to support this suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experiments, noting that they are restricted to MNIST and a single realworld dataset. This feedback is valuable as it highlights a potential area for improvement in the comprehensiveness of the experiments. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation, such as expanding the experiments to include more datasets or realworld scenarios. While it points out a clear weakness, it does not provide actionable advice to enhance the draft, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer suggests that if the kernel dimensions are constant, the depth would increase, leading to more parameters. While the comment implies that more details are needed, it does not explicitly instruct the authors to provide additional information or clarify the parameter count. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the parameter count. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the S2D structure and questions why the number of parameters does not change when the kernel height and width remain the same. It suggests that if the kernel dimensions are constant, the depth would increase, resulting in more parameters. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the issue with the parameter count, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change when the kernel height and width remain the same. The reviewer provides a logical explanation, suggesting that if the kernel dimensions are constant, the depth would increase, leading to more parameters. This reasoning is clear and wellsupported, making the claim 4. The comment also acknowledges the potential for efficiency improvement, further substantiating the point. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in the S2D structure, questioning why the number of parameters does not change when the kernel height and width remain the same. It provides a logical explanation, suggesting that if the kernel dimensions are constant, the depth would increase, resulting in more parameters. The reviewer acknowledges the potential for efficiency improvement, which is a valuable insight for the authors. However, the comment could be more helpful by providing specific guidance on how to address this issue or by suggesting additional details that could be included in the paper. Overall, the comment is 3 as it highlights a potential area for improvement and offers a clear rationale, but it lacks depth and actionable suggestions for the authors to fully address the issue."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in 10, suggesting that 10 could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider whether 10 could benefit from these side information. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, as it does not specify how the authors should explore or implement the suggestions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the similarity between the proposed method and the approach in 10, suggesting that 10 could also be equipped with scoring causal predictions and interventional data. However, it does not specify which part of the paper this comparison is intended to address, making it weakly grounded. The comment is specific in its suggestion to consider why 10 cannot use side information, but without clear grounding, the authors may struggle to identify the exact section or part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the similarity between the proposed method and the approach in 10, suggesting that 10 could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why 10 cannot use side information. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the suggestion. Without clear justification or references, the claim is barely verifiable, as it relies on the authors\" interpretation and understanding of the existing work. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about the similarity between the proposed method and the approach in 10, suggesting that 10 could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why 10 cannot use side information. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to differentiate their method from 10. While it identifies a potential area for improvement, it does not provide actionable advice or detailed reasoning, making it 3. The authors would need to infer the need for further exploration and comparison, which limits the comment\"s effectiveness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This absence could lead to the model using more factors as the number of tasks increases, resulting in increased computation. However, the comment does not provide explicit guidance on how the authors might address this issue or suggest any specific actions to improve the model. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to understand how to implement the suggested improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the proposed method, noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This allows the authors to accurately identify the part of the paper being discussed, making the comment fully grounded. The comment is also specific, as it clearly explains the issue and its potential consequences, providing guidance on how the model might be incentivized to use more factors. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint, which could lead to an increase in the number of factors and computation as the number of tasks increases. However, the comment does not provide specific evidence or references to support this claim, such as examples of how the absence of a sparsity constraint might manifest or why it is a significant issue. Without detailed reasoning or supporting evidence, the claim remains 3, as it lacks the necessary depth to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically noting the absence of a sparsity constraint in the number of factors used by subsequent tasks. This lack of constraint could lead to an increase in the number of factors and computation as the number of tasks increases, potentially impacting the model\"s efficiency. While the comment highlights a potential weakness, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the model. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the presentation of the simulation study is not effective in supporting the authors. It specifically notes that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to the bandit feedback and not the use of information about the form of the cost function. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their presentation. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"presentation of the simulation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comment on why the GPC (benchmark) performs better than BPC (the authors\" method) and suggests that this difference is due to bandit feedback and not the use of information about the cost function form. This provides a clear direction for the authors to improve their presentation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the presentation of the simulation study is not effective in supporting the authors, specifically noting that the authors do not comment on why the GPC (benchmark) performs better than BPC (their method). The comment suggests that it would be beneficial to reiterate that this difference is due to bandit feedback and not the use of information about the cost function form. However, the comment lacks specific examples or detailed reasoning to substantiate this claim, making it 3. The authors would need to infer the basis for the claim, which limits its verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) performs better than BPC (their method). It suggests that the difference is due to bandit feedback and not the use of information about the cost function form. This feedback is clear and actionable, as it provides a specific area for improvement and a clear rationale for why the authors should address this issue. However, the comment could be more helpful if it offered suggestions on how to reiterate this point or provide additional context. Overall, the comment is 4, as it guides the authors to improve their presentation but could be more comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment does not explicitly instruct the authors on how to quantify or clarify the claim, leaving the action somewhat vague. The authors are left to infer that they need to provide more evidence or explanation to support the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment does not explicitly mention which part of the paper this claim is being addressed, making it weakly grounded. The comment is specific in suggesting that the authors should provide more evidence or explanation to support the claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed reasoning or examples to fully support the claim, making it 3. The authors are left to infer the basis of the claim, which could be improved with more explicit justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors might be helpful in quantifying and clarifying the claim that ReLU does not work well in deep or convolutional networks. It provides a specific example by mentioning the use of ReLUs in the AlexNet paper, which was considered deep and convolutional. However, the comment lacks detailed guidance on how to quantify or clarify the claim, leaving the authors with limited actionable feedback. While it points out a potential area for improvement, it does not offer specific suggestions or detailed reasoning, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. While the comment implies that these additions are necessary, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their evaluation to include these aspects. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is related to, such as the methodology or results sections. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the type of experiments needed, the absence of explicit references to the paper\"s sections or content makes it weakly grounded. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. This feedback is 3 as it identifies specific areas where the evaluation could be strengthened. However, the comment lacks depth and does not provide detailed guidance on how to conduct these additional experiments or what specific aspects of the evaluation would benefit from these additions. Without more detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors define rooted patterns in a similar way to orbit counting in GSN but do not elaborate on the importance of rooted patterns or how the roots are chosen. It suggests that a brief discussion is expected or that the discussion of nonrooted patterns could be moved to the supplementary material. While the comment implies that the authors should provide more context and explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on what to include in the discussion or how to address the issue of root selection. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concept of rooted patterns and their definition, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the importance of rooted patterns and the lack of explanation on how the roots are chosen. This provides clear guidance on what the authors should do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors define rooted patterns in a similar way to orbit counting in GSN but do not elaborate on the importance of rooted patterns or how they choose the roots. The comment suggests that a brief discussion is expected or that the discussion of nonrooted patterns could be moved to the supplementary material. However, the comment lacks specific examples or references to support the claim that the authors do not elaborate on the importance or root selection. This makes the claim 3, as it provides a general idea but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their paper by providing more context and explanation. It points out that the definition of rooted patterns is similar to orbit counting in GSN but does not elaborate on the importance of rooted patterns or how the roots are chosen. The comment suggests that a brief discussion is expected or that the discussion of nonrooted patterns could be moved to the supplementary material. This feedback is clear and actionable, as it provides specific areas for improvement and guidance on how the authors might address these issues. However, it could be more helpful if it included suggestions for specific content or examples to include in the discussion. Overall, the comment is 4, as it offers valuable insights and direction for the authors to enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, it does not provide explicit guidance on what specific aspects of the paper need further explanation or elaboration. The suggestion to give more explanations is clear and concrete, as it directs the authors to expand on this particular point. Therefore, the comment is 4, as it provides a clear direction for improvement but lacks some detail on how to implement the suggestion. This aligns with a score of 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (9597 and 308310) where the issue of consistency between training and inference is discussed. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly suggests that the authors should provide more explanations on this topic, indicating what needs to be addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the paper addresses the consistency between training and inference, noting that it can be easily satisfied due to the smoothness of neural models. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how it relates to the paper\"s content. Therefore, the comment is considered 1, as it lacks sufficient evidence to support the claim.", "helpfulness_rationale": "The review comment identifies a specific area in the paper where the consistency between training and inference is discussed, noting that it can be easily satisfied due to the smoothness of neural models. The reviewer suggests that the paper should provide more detailed explanations on this topic. This feedback is clear and actionable, as it directs the authors to expand on a particular aspect of their work that could enhance its clarity and depth. By offering a specific suggestion for improvement, the comment is 4, as it provides a clear direction for the authors to enhance their draft. However, it could be more helpful if it included additional suggestions or examples to further guide the authors in improving their explanation."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the need for finetuning the extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not provide explicit guidance on how to implement this finetuning process or suggest specific methods for determining the optimal values of k and \u03b7. The action is implicit, as the authors need to infer that they should finetune these hyperparameters and consider the factors mentioned. While the comment is 3, it lacks concrete details on how to execute the suggested action. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the need for finetuning extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not specify which part of the paper this issue is related to, such as a specific section or table where these hyperparameters are introduced or discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion regarding the finetuning process, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the extra hyperparameters k and \u03b7 require finetuning, which depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the introduction of extra hyperparameters, k and \u03b7, which require finetuning. It highlights that this finetuning depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any guidance or suggestions on how to address this issue or what steps the authors should take to ensure the proper finetuning of these hyperparameters. While it points out a potential area for improvement, it lacks actionable advice or detailed explanations, making it 3. The authors would need to infer the need for finetuning and consider the factors mentioned, but the comment does not fully support their understanding or provide comprehensive guidance. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. While the comment implies that the authors should conduct an ablation study, it does not provide explicit guidance on how to perform it or what specific aspects of the encoding should be examined. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an ablation study to address the question. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. While the comment is specific in suggesting an ablation study, the absence of explicit grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of the base layer GNN encoding in the proposed method, suggesting that an ablation study would be helpful. However, the comment does not provide any specific reasoning, examples, or references to support why the base layer GNN encoding is unclear or why an ablation study is necessary. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically questioning the necessity of the base layer GNN encoding. It suggests that an ablation study could be conducted to determine the importance of this component. While the comment highlights a specific area for further investigation, it does not provide detailed guidance on how to conduct the ablation study or what specific aspects of the encoding should be examined. This feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the discussion of computational complexity, specifically the lack of detailed explanation or explicit mention of upper bounds for counting homomorphomorphisms. It suggests that the authors should consider adding this information and potentially elaborating on empirical runtimes. While the comment implies that the authors should address this issue, it does not provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve the draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the issue of computational complexity is discussed, specifically referencing line 145. This allows the authors to accurately identify the section being addressed. The comment is also specific because it clearly specifies the issue of computational complexity and suggests that the authors should explicitly add the upper bounds of counting homomorphisms and elaborate on empirical runtimes. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, noting that the paper makes brief statements but lacks detailed explanation or explicit mention of upper bounds. The comment suggests that it would be beneficial for the paper to include this information and potentially elaborate on empirical runtimes. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the discussion is inadequate. This lack of substantiation makes the claim 3, as the authors would need to infer the basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved by discussing the computational complexity of counting homomorphisms. It points out that the paper makes brief statements about the topic but lacks a detailed discussion or explicit mention of upper bounds. The suggestion to include this information and potentially elaborate on empirical runtimes is clear and actionable, providing the authors with a concrete direction for enhancing their draft. This feedback is 4 as it offers a specific and constructive suggestion for improvement, though it could be further detailed to be even more comprehensive. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on a potential error in the text, noting that the first \"f\" should be \"g\" and that there is an extra \".\" in the middle of a sentence. It also raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While the comment explicitly points out the error and raises a question, it does not provide explicit guidance on how to correct the error or address the question. The action is implicit, as the authors would need to infer that they should correct the error and consider the impact of early learner cutting. However, the feedback is 3 as it provides clear guidance on what needs to be addressed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (108 and 115) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be corrected, such as the error in the text and the question about the convergence of networks in a baseline MCL with deep learning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the concern, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies specific issues in the text, such as a potential error in line 108 and an extra punctuation mark in line 115. It also raises a question about the convergence of networks in a baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While the comment points out these issues, it does not provide detailed guidance on how to address them or offer suggestions for improvement. The feedback is 3 as it highlights areas that need attention, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the study, specifically the lack of analysis of inference time. It suggests that since the method is direct and does not require detection or keypoint grouping, it would be beneficial to compare its inference speed to previous topdown and bottomup pose estimation methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific metrics to use. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of study of inference time, which is a specific aspect of the paper. It also suggests comparing the inference speed to previous topdown and bottomup pose estimation methods, providing clear guidance on what needs to be addressed. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issue that needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a study of inference time, which is a significant aspect for evaluating the practical applicability of a pose estimation method. It suggests comparing the inference speed to previous topdown and bottomup methods, implying that this comparison would provide valuable insights. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the lack of inference time study is a critical omission. While the suggestion is logical, the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the study by pointing out the absence of an analysis of inference time. It suggests that since the method is direct and does not require detection or keypoint grouping, it would be beneficial to compare its inference speed to previous topdown and bottomup pose estimation methods. This feedback is valuable as it highlights a crucial aspect that could enhance the practical applicability and comprehensiveness of the research. However, the comment could be more helpful if it provided specific guidance on how to conduct the inference time analysis or suggested particular metrics for comparison. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not provide explicit instructions or suggestions on how to address these issues, such as suggesting alternative indexing or revisiting the calculation. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem A.3 proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions about the indexing of the input x and the calculation of the sum of squares of the second layer weights, guiding the authors on what needs to be clarified or corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises specific questions about the proof of Theorem A.3, particularly regarding the indexing of the input x and the calculation of the sum of squares of the second layer weights. It does not contain any subjective opinions or claims that require verification. The questions are factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment identifies specific issues in the proof of Theorem A.3, particularly questioning the indexing of the input x and the calculation of the sum of squares of the second layer weights. It points out that the input is a vector, not a matrix, and suggests that the sum of squares should be 1/d, not d. While the comment highlights areas that need clarification, it does not provide detailed guidance or suggestions on how to address these issues. The feedback is 3 as it directs the authors to specific areas of concern, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the use of terms like \"somewhat\" and \"good generative ability\" in the description of results, specifically questioning the accuracy of the generated logical forms. It highlights a concern that even with beam search, only 77% of the results list contains the ground truth logical forms. The comment requests clarification on how the authors ensure the correctness of the entities and relationships when they are replaced, and specifically asks for the percentage of correct entities/relationships plugged in when no ground truth is available. This feedback is explicit and provides a clear action for the authors to take, which is to address the concerns about the accuracy of the generated logical forms and the reliability of the entities and relationships. The comment is detailed and specific, guiding the authors on what needs to be clarified or addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the accuracy of the generated logical forms, questioning the reliability of the entities and relationships when they are replaced. The comment requests clarification on the percentage of correct entities/relationships plugged in when no ground truth is available, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the accuracy of the generated logical forms, specifically questioning the reliability of the entities and relationships when they are replaced. It provides a specific example, noting that only 77% of the results list contains the ground truth logical forms. However, the comment lacks detailed reasoning or references to support the claim that the generated results are not accurate or reliable. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a specific concern about the accuracy of the generated logical forms, particularly questioning the reliability of the entities and relationships when they are replaced. It highlights that only 77% of the results list contains the ground truth logical forms, which is a significant concern. The comment requests clarification on how the authors ensure the correctness of the entities and relationships and asks for the percentage of correct entities/relationships plugged in when no ground truth is available. This feedback is clear and actionable, providing the authors with specific areas to address and improve their work. However, the comment could be more helpful if it offered additional guidance or suggestions on how to address the issue of entity and relationship accuracy. Overall, the comment is 4 as it identifies a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the dependence of FedPCL\"s performance on the selection of pretrained models, noting that this limits its applicability to a broader range of areas. It also mentions that the model accuracy is sensitive to the choice of pretrained models, as shown in Table 4. The comment suggests that the authors have adequately addressed the limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the comment does not provide explicit guidance on how the authors should address these limitations or what specific actions they should take to improve the framework. While the authors are informed of the issue, they are not given clear instructions on how to resolve it, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is by stating that the performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications to more wide areas. The comment further highlights that the model accuracy is sensitive to the choice of pretrained models, as shown in Table 4. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of FedPCL heavily relies on the selection of different pretrained models, limiting its applications to a broader range of areas. It also notes that the model accuracy is sensitive to the choice of pretrained models, as evidenced by the results in Table 4. The comment suggests that the authors have adequately addressed these limitations and developed a lightweight federated learning framework to reduce computation and communication costs. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion about the sensitivity of model accuracy to pretrained models. While the comment provides a general idea, it does not offer a comprehensive explanation or evidence to support the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a limitation in the performance of FedPCL, which is heavily dependent on the selection of pretrained models. This limits its applicability to a broader range of areas. The comment also notes that the model accuracy is sensitive to the choice of pretrained models, as shown in Table 4. While the comment acknowledges that the authors have adequately addressed these limitations, it does not provide specific suggestions or guidance on how the authors might improve the framework or address the identified issues. The feedback is 3 as it highlights a key area for improvement but lacks actionable advice, leaving the authors with a general understanding of the problem without clear steps to resolve it."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include not only the retrieved and final attention maps but also the tentative attention maps in the qualitative figures. This provides a clear and explicit action for the authors to take, as they know exactly what additional information they should include in their figures. The comment is specific in its request, detailing what needs to be added to the qualitative figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including tentative attention maps in the qualitative figures, which implies that the authors should consider adding this information. However, it does not specify which part of the paper the authors should focus on or provide any guidance on how to incorporate these maps. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. Additionally, it lacks specificity in detailing what exactly needs to be added or how it should be presented. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests including \"tentative attention maps\" in the qualitative figures, which implies that the authors should consider adding this information. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks sufficient support, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including \"tentative attention maps\" in the qualitative figures, which could enhance the paper by providing additional insights into the model\"s attention mechanisms. However, the comment lacks specificity, as it does not explain why these maps are important or how they would contribute to the overall understanding of the paper. Additionally, it does not provide any guidance on how to present or interpret these maps, leaving the authors with limited actionable feedback. While the suggestion is relevant, the lack of detailed guidance makes it 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific suggestions for improving the organization of the paper by suggesting that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. It also suggests that tricks like normalization or feature scaling could be referenced in a separate section. However, the comment does not explicitly instruct the authors on how to implement these suggestions, such as where to add these sections or how to integrate the tricks. While the suggestions are clear, the lack of explicit guidance on implementation makes the comment 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the organization of the paper, such as separating the description of the main contributions and the generative/inference models, and referencing tricks like normalization or feature scaling in a separate section. However, it does not explicitly mention which sections or parts of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point consists of minor comments and suggestions regarding the organization and structure of the paper. It suggests that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. However, the comment does not provide any specific reasoning, examples, or references to support these suggestions, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the organization and structure of the paper. It suggests that the main contributions, particularly the introduction of two types of attention for deep VAEs, should be described in a separate section before discussing the generative and inference models. This would help improve the clarity and flow of the paper. Additionally, the comment recommends referencing tricks like normalization or feature scaling in a separate section, which could enhance the paper\"s clarity and completeness. However, the comment lacks depth and does not provide detailed guidance on how to implement these suggestions, making it 3. The feedback is actionable but could be more comprehensive to fully assist the authors in improving their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses confusion about Figure 5 or the labels, but it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this issue, making the comment 1. Therefore, this comment aligns with the lowest score of 1.", "grounding_specificity_rationale": "The comment expresses confusion about Figure 5 or the labels, but it does not specify which part of the paper this issue pertains to, nor does it provide any guidance on how to address it. The authors cannot confidently determine which section or element is being referred to, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what is unclear or incorrect about the figure or labels. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about Figure 5 or the labels, but it does not provide any specific reasoning, examples, or references to support the claim. Without additional context or explanation, the authors are left to interpret the issue, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment expresses confusion about Figure 5 or the labels, but it does not provide any specific guidance or suggestions on how to address this issue. The authors are left without actionable feedback, making the comment unhelpful. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include supervised baselines in their experiments, particularly for datasets of a certain scale. It provides a rationale for why this is important, explaining that full annotation is often available for datasets of this size and that it would be informative to compare selfsupervised methods to fully supervised pretrained networks. However, the comment does not explicitly instruct the authors on how to implement this suggestion, such as which specific baselines to include or how to compare the results. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for supervised baselines in the experiments, which is a specific part of the paper. It provides a clear rationale for why these baselines are important, explaining that they are relevant for datasets of a certain scale and that comparing selfsupervised methods to fully supervised pretrained networks would be informative. This level of detail helps the authors understand what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks supervised baselines, which is a reasonable suggestion given the scale of the datasets used in the experiments. The comment provides a rationale for why these baselines are important, explaining that full annotation is often available for datasets of this scale and that comparing selfsupervised methods to fully supervised pretrained networks would be informative. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the need for these baselines and understand the reasoning behind the suggestion, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why these baselines are important, particularly for datasets of a certain scale where full annotation is often available. The suggestion to include supervised baselines and compare selfsupervised methods to fully supervised pretrained networks is actionable and would help the authors contextualize their findings. However, the comment could be more helpful if it provided specific examples of what these baselines might be or suggested particular datasets for comparison. Overall, the feedback is 4 as it highlights a crucial aspect of the paper that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for the authors to consider. It questions the effectiveness of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. Additionally, it asks why BEAR is missing from the baselines. While the comment provides some guidance, it lacks explicit instructions on how to address these points or what specific actions the authors should take. The suggestions are somewhat vague and do not offer detailed guidance on how to conduct the additional evaluations or why BEAR is missing from the baselines. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment raises questions about the method\"s effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment does not specify which part of the paper discusses the method\"s application or evaluation on Hopper, making it weakly grounded. While it provides some specificity by questioning the method\"s effectiveness and suggesting additional evaluations, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the method\"s effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment lacks specific reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The questions are openended and do not provide clear guidance or evidence, leaving the authors uncertain about the validity of the concerns. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions for the authors to consider, which could help them improve their draft. It questions the method\"s effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with nondeterministic dynamics to assess its empirical efficacy. This provides a clear direction for further experimentation and analysis. Additionally, the comment asks why BEAR is missing from the baselines, which could highlight a gap in the evaluation and encourage the authors to include it. However, the comment lacks detailed guidance on how to conduct these evaluations or why BEAR is missing from the baselines, making it 3. The feedback is valuable but could be more comprehensive if it provided specific suggestions or examples for addressing the concerns. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation of the proposed method in detecting hallucinations in openended responses, providing a specific example to illustrate the issue. It suggests that the method might struggle with prompts like \"introduce a sports celebrity to me,\" where sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific improvements could be made to the method. The action is implicit and somewhat vague, as it leaves the authors to infer the need for further investigation or modification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the proposed method, noting its potential struggle to detect hallucinations in openended responses. It provides a concrete example, such as the prompt \"introduce a sports celebrity to me,\" to illustrate the challenge. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The specificity of the comment is high as it clearly identifies the problem and provides an example, guiding the authors on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method might struggle to detect hallucinations in openended responses, providing an example of a prompt that could lead to this issue. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or examples, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a potential limitation of the proposed method in detecting hallucinations in openended responses, using a specific example to illustrate the issue. It highlights that the method might struggle with prompts like \"introduce a sports celebrity to me,\" where sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. While the comment points out a specific area of concern, it does not provide detailed guidance or suggestions on how the authors might address this issue or improve the method. The feedback is 3 as it identifies a potential weakness, but it lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of how theoretical findings relate to realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"theoretical findings\" and suggests verifying the conclusion about \"label noise and model size on MNIST and CNN.\" This provides clear guidance on which parts of the paper need attention. However, the comment lacks specificity in detailing what aspects of the findings need verification or how the authors should approach this verification. It does not provide specific examples or detailed instructions on what needs to be verified, making it weakly specific. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the clarity of how theoretical findings relate to realworld deep learning models. It suggests verifying the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand and address the issue. The feedback is 3 as it points out a potential area for clarification but does not provide sufficient evidence or guidance to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by questioning the connection between theoretical findings and realworld deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific guidance on how to conduct this verification or what aspects of the findings need to be examined. While it points out an area for improvement, the feedback is 3 as it directs the authors to a specific area that requires further attention. However, it could be more helpful with additional details or suggestions on how to approach the verification process. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing could be improved and provides specific feedback on the clarity of the paper. It recommends drawing a table to compare different CoT prompting methods across different dimensions, which is a concrete action for the authors to take. However, the comment does not explicitly instruct the authors to make assumptions about the frequency of errors or to justify the selection criteria in section 4.2. While the action is somewhat explicit, it lacks detailed guidance on how to implement the suggestions, such as how to draw the table or why the specific token and step limits were chosen. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"weaknesses/feedback\" and provides specific suggestions for improvement, such as drawing a table to compare CoT prompting methods and questioning the assumption about error clusters. It also asks for justification regarding the selection criteria in section 4.2, which is specific to the content of the paper. This level of detail allows the authors to accurately identify the parts of the paper that need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity of the paper and suggests improvements, such as drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks for justification regarding the selection criteria in section 4.2. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The feedback is 3 as it offers suggestions for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies areas for improvement in the paper, specifically suggesting that the writing could be enhanced by drawing a table to compare different CoT prompting methods across various dimensions. It also questions the assumption that \"questions of all the wrong demonstrations fall into the same frequenterror cluster\" and asks for justification regarding the selection criteria in section 4.2. While the comment provides specific suggestions for improvement, it lacks detailed guidance on how to implement these suggestions or why the specific criteria were chosen. This makes the feedback 3, as it offers actionable insights but could be more comprehensive with additional details. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the application of weight decay, suggesting that the authors should expect suboptimal cosine similarities for large weight decay parameters. It also notes that the plots do not extend to these large weight decay strengths, where cosine similarities are still close to optimal. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer that they should consider reporting cosine similarities for larger weight decay values or extend their plots to include these values. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the application of weight decay, noting that the authors might expect suboptimal cosine similarities for large weight decay parameters. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. The comment is specific in detailing the expected outcome and the observation about the plots, but it lacks grounding as the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors would expect suboptimal cosine similarities for large weight decay parameters, which is a logical deduction based on the understanding of how weight decay affects model training. However, the comment does not provide specific examples or references to support this claim, making it 3. The authors are left to infer the reasoning, which could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the application of weight decay, suggesting that the authors might expect suboptimal cosine similarities for large weight decay parameters. It also notes that the plots do not extend to these large weight decay strengths, where cosine similarities are still close to optimal. This feedback is 3 as it highlights a potential area for improvement in the analysis of the plots. However, it lacks specific guidance on how the authors might address this issue or what changes could be made to the plots to better illustrate the expected behavior. The comment could be more helpful if it provided suggestions or examples of how to extend the analysis or present the data differently. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the experiments section: the lack of interpretive insights into why the proposed gyrostructures outperform existing methods and the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The authors are left to infer that they need to include more detailed discussions and comparisons to strengthen their experimental analysis. Therefore, the comment is 3, as it provides a clear direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment addresses the experiments part of the paper, specifically mentioning the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. It also highlights the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifoldbased learning. However, the comment does not specify which part of the experiments section this issue is related to, such as specific sections or figures. This makes it weakly grounded, as the authors may need to infer which part of the paper is being addressed. The comment is specific in detailing the issues with the experiments, such as the lack of interpretive insights and the absence of comparisons with other stateoftheart methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments part lacks interpretive insights into why the proposed gyrostructures outperform existing methods. It also notes the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of interpretive insights into why the proposed gyrostructures outperform existing methods. It also highlights the absence of comparisons with other stateoftheart methods that do not rely on gyrostructures, making it unclear whether the proposed approach is truly superior. This feedback is valuable as it directs the authors to enhance the depth and comprehensiveness of their experimental analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to include additional comparisons or interpretive insights. Overall, the comment is 3, as it directs the authors to areas for improvement but lacks detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Figure 5 is difficult to comprehend and suggests that the authors should provide more details about the two baselines presented in the figure. It also notes that the study is limited to Englishcentric datasets and suggests that the authors could extend CATER to other languages in the future. While the comment explicitly mentions the need for more details about the baselines and suggests a potential future direction, it does not provide specific guidance on how to enhance the comprehensibility of Figure 5 or how to extend CATER to other languages. The action is somewhat vague, as the authors are left to infer the exact steps needed to address these issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: the comprehensibility of Figure 5 and the need for more details about the two baselines. Additionally, the comment suggests extending CATER to other languages, which is a specific and actionable suggestion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 5 is hard to comprehend and suggests providing more details about the two baselines presented in the figure. It also notes that the study is limited to Englishcentric datasets and suggests extending CATER to other languages. While the comment identifies a potential issue with the comprehensibility of Figure 5 and suggests a future direction for the study, it lacks specific examples or detailed reasoning to fully substantiate these claims. The suggestion to extend CATER to other languages is somewhat vague, as it does not provide concrete guidance on how to achieve this. Therefore, the claim is 3, as it provides some basis for the feedback but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and lacks details about the two baselines presented. It also points out that the study is limited to Englishcentric datasets, which is a relevant observation given the widespread use of text generation APIs for translation. The comment suggests extending CATER to other languages, which could be a valuable direction for future work. While the feedback is clear and actionable, it could be more helpful if it provided specific suggestions on how to improve the comprehensibility of Figure 5 or how to extend CATER to other languages. Overall, the comment is 4 as it highlights important areas for improvement and provides a clear direction for future work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for improvement in the literature review, specifically mentioning that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. While the comment suggests that the paper should provide a more explicit and comparative analysis of related work, it does not provide specific guidance on what aspects of the literature review need to be improved or how the authors should address these issues. The action is implicit and vague, as the authors are left to infer that they need to expand the literature review to include a clearer comparison with existing work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for improvement in the literature review, allowing the authors to accurately identify the part of the paper being addressed. It specifies what needs to be addressed, namely, the clarity of the main contribution and the distinction from existing work, particularly in relation to GFlowNet for sequence generation. This provides clear guidance on how the authors should enhance their literature review. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the literature review is unclear and needs improvement, specifically regarding the main contribution of the proposed method and its distinction from existing work, particularly in relation to GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact areas that need improvement. Without detailed examples or references, the claim is 3, as it provides a general direction but lacks the necessary depth to guide the authors effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper\"s literature review, specifically noting that it lacks clarity regarding the main contribution of the proposed method and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how the authors could improve the literature review. Despite this, the feedback is 4 as it directs the authors to a critical area for improvement, allowing them to enhance the depth and clarity of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that section 3.2 can be eliminated, implying that readers are likely to be familiar with the GumbelSoftmax/Concrete distribution. However, it does not provide any explicit guidance on how the authors should eliminate this section or what specific content should be removed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that section 3.2 can be eliminated, implying that readers are likely familiar with the GumbelSoftmax/Concrete distribution. However, it does not specify which part of the paper section 3.2 corresponds to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its suggestion to eliminate the section, but the lack of grounding makes it challenging for the authors to understand which part of the paper needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that section 3.2 can be eliminated because readers are likely familiar with the GumbelSoftmax/Concrete distribution. However, the comment does not provide any specific reasoning or evidence to support this claim, such as examples or references to similar sections in other papers. Without detailed justification, the authors may find it challenging to understand why this section is unnecessary. Therefore, the comment is considered 2, as it lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment suggests that section 3.2 can be eliminated because readers are likely familiar with the GumbelSoftmax/Concrete distribution. This feedback is 3 as it points out a potential area for simplification in the paper. However, it lacks specific guidance on which parts of section 3.2 could be removed or what content might be redundant. The comment does not provide actionable advice on how the authors can address this issue, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests adding performance on word similarity and sentence translation tasks, referencing the MUSE paper, to enhance the credibility of the framework. It also mentions the inclusion of morphologically rich and lowresource languages in the experiments as additional points. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific steps or considerations for adding these tasks and languages. The actions are implicit and somewhat vague, as the authors need to infer how to apply the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding performance on word similarity and sentence translation tasks, referencing the MUSE paper, to enhance the credibility of the framework. It also mentions the inclusion of morphologically rich and lowresource languages in the experiments as additional points. However, the comment does not specify which part of the paper these suggestions relate to, such as specific sections or tables. This makes it difficult for the authors to identify the exact areas where these additions should be made. While the suggestions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding performance on word similarity and sentence translation tasks, referencing the MUSE paper, to enhance the credibility of the framework. It also recommends including morphologically rich and lowresource languages in the experiments. However, the comment lacks specific examples or detailed reasoning to support these suggestions. While the authors might infer that these additions would improve the robustness and effectiveness of the framework, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the experiments section by adding performance on word similarity and sentence translation tasks, referencing the MUSE paper. This addition would enhance the credibility and robustness of the framework. Additionally, the comment suggests including morphologically rich and lowresource languages in the experiments, which would broaden the scope and applicability of the research. However, the comment lacks detailed guidance on how to implement these suggestions, such as specific steps or considerations for adding these tasks and languages. While the feedback is 3, it could be more comprehensive if it provided more detailed instructions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper does not provide sufficient insights into why this specific type of data is important for selfsupervised learning. The comment implies that the authors should elaborate on the significance of this data type in the context of selfsupervised learning. However, it does not explicitly instruct the authors to add more details or examples to support this claim. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or insights about the importance of the data type. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of insights into why selfsupervised learning is needed for 360 video data with spatial audio. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for more insights but lacks detail on what those insights should include or how they should be presented. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not provide sufficient insights into why selfsupervised learning is needed for 360 video data with spatial audio. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the paper does not offer sufficient insights. As a result, the claim is not wellsupported, making the comment 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while the experimental results suggest the value of the proposed approach for selfsupervised learning on 360 video data with spatial audio, the paper lacks insights into why this specific type of data is important for selfsupervised learning. This feedback highlights a need for the authors to provide more context or explanation regarding the significance of this data type in the context of selfsupervised learning. However, the comment does not offer specific suggestions or guidance on how to address this gap, leaving the authors with a clear understanding of the issue but without actionable steps to improve their draft. Therefore, the comment is 3, as it identifies a meaningful area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This provides a clear and explicit action for the authors to take, as they need to average their results over multiple runs to ensure the statistical significance of their findings. The comment is specific in its suggestion, detailing exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion, the absence of grounding limits its usefulness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This is a logical and straightforward recommendation that aligns with standard practices in statistical analysis. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the need for averaging results based on common knowledge in statistical analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that directly addresses a potential issue with the statistical analysis of the results. By averaging results over multiple runs, the authors can ensure that their findings are robust and statistically significant, which is crucial for the validity of their conclusions. This feedback provides a specific and constructive suggestion that the authors can easily implement to improve the quality of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" While the first question prompts the authors to explore the relationship between model capacity and FID, it does not provide explicit guidance on how to address this. The second part acknowledges the presence of unexpected artifacts but does not offer specific suggestions or actions for the authors to take. The comment lacks explicit and concrete actions or suggestions for the authors to address these issues, making it 1.", "grounding_specificity_rationale": "The comment raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to identify the exact areas that need attention. While the questions are specific about the issues, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" These questions are openended and do not contain any subjective opinions, judgments, or suggestions. They are factual inquiries that require the authors to provide their own analysis or findings. Therefore, the comment is classified as \"No\" because it does not contain a claim that needs verification.", "helpfulness_rationale": "The review comment raises two questions about the impact of the SR model\"s capacity on the FID and the unexpected artifacts introduced by the pipelining method. While these questions highlight potential areas for further investigation and clarification, they do not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it identifies areas that require attention, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the content and purpose of Appendix A and Appendix B, specifically questioning the clarity of Proposition B.1 and the absence of a \"proof.\" It suggests that the authors should clarify the purpose of these appendices and provide a more detailed explanation or proof. However, the comment does not explicitly instruct the authors to add content or provide a specific action to take, such as expanding the appendices or clarifying the purpose of Proposition B.1. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the content of Appendix A and Appendix B, specifically questioning the purpose of Proposition B.1 and the absence of a \"proof.\" It does not explicitly mention specific sections or parts of the paper, making it weakly grounded. However, it provides clear guidance on what needs to be addressed, such as clarifying the purpose of Proposition B.1 and providing a detailed explanation or proof. This makes the comment specific in its suggestions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the content and purpose of Appendix A and Appendix B, specifically questioning the clarity of Proposition B.1 and the absence of a \"proof.\" It suggests that the authors should clarify the purpose of these appendices and provide a more detailed explanation or proof. However, the comment lacks specific examples or references to support the claim that the purpose of Proposition B.1 is unclear or that the \"proof\" is missing. Without detailed reasoning or examples, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies specific issues with the content and purpose of Appendix A and Appendix B, particularly questioning the clarity of Proposition B.1 and the absence of a \"proof.\" It suggests that the authors should clarify the purpose of these appendices and provide a more detailed explanation or proof. This feedback is 3 as it points out areas where the authors need to improve the clarity and completeness of their paper. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as suggesting additional content or a more detailed explanation of the concepts. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. While it suggests that these experiments are needed, it does not provide explicit guidance on how to conduct them or what specific aspects of the paper should be compared or analyzed. The action is implicit and somewhat vague, as the authors need to infer that they should perform these experiments to address the lack of additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments are missing from or where they should be added. This makes it difficult for the authors to identify the exact areas that need improvement. The comment is fully grounded in terms of identifying the need for additional experiments but is not specific in detailing what is missing. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or references to similar studies, the authors may find it challenging to understand why these experiments are necessary or how they would enhance the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is valuable as it highlights specific areas where the paper could be strengthened to provide a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it suggested specific ways to conduct these experiments or provided examples of how they could be implemented. Overall, the comment is 3 as it directs the authors to areas that need improvement, but it lacks depth and actionable guidance, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores. However, it points out that more careful analysis is needed, particularly for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment implies that the authors should provide more details about the evaluation procedures to address this concern. While the action is clear and explicit, it lacks concrete guidance on how to conduct this additional analysis or what specific aspects of the evaluation procedures need to be detailed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but it highlights the need for more careful analysis, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. It also mentions the need for more details about the evaluation procedures. However, the comment does not specify which part of the paper discusses the evaluation procedures or the \"old\" benchmarks, making it difficult for the authors to pinpoint the exact areas that require attention. While the comment is specific about the need for more detailed analysis, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed model demonstrates impressive performance on many benchmarks, setting new SoTA scores, but suggests that more careful analysis is needed, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment also requests more details about the evaluation procedures. However, the claim lacks specific examples or references to support the assertion about the need for more careful analysis, particularly for the \"old\" benchmarks. Without detailed reasoning or examples, the claim is 3, as it provides a general direction but lacks the depth needed for full understanding and action.", "helpfulness_rationale": "The review comment highlights a potential issue with the evaluation of the proposed model, noting that while it achieves impressive performance on many benchmarks, it lacks careful analysis, especially for \"old\" benchmarks where the data might have been indirectly seen by the model through \"data curation\" processes. The comment requests more details about the evaluation procedures, which could help the authors address this concern. However, the feedback is somewhat limited as it does not provide specific suggestions or guidance on how to conduct this additional analysis or what aspects of the evaluation procedures need to be detailed. While it points out a potential area for improvement, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the experimental setup, noting that the different methods in the two sets of benchmarks proposed in the paper are quite different in their OPE methods. The reviewer hopes for some comments on these differences. While the comment identifies a potential issue with the experimental design, it does not provide explicit guidance on how the authors should address this discrepancy or what specific aspects need to be clarified. The action is implicit, as the authors would need to infer that they should discuss the differences between the two sets of evaluation methods. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental part of the paper, specifically mentioning Figure 4 and Figure 5, which contain different evaluation methods. However, it does not specify which sections of the paper these figures are located in, making it weakly grounded. The comment is specific in that it highlights a discrepancy in the experimental setup and requests comments on the differences between the two sets of evaluation methods. This provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between two sets of evaluation methods in the experimental part, specifically mentioning Figure 4 and Figure 5. However, it does not provide any specific reasoning, examples, or references to support why these differences are significant or how they impact the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue in the experimental part of the paper, specifically noting that the different methods in the two sets of benchmarks proposed are quite different in their OPE methods. This observation raises a question about the consistency and comparability of the results across different evaluation methods. While the comment highlights a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this discrepancy. The feedback is 3 as it points out a potential issue that needs attention, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It points out that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental results and highlights a concern regarding the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It points out that without prior information, the proposed method does not show an advantage compared to the SOTA, similar to the benchmarks. However, the advantage is only evident when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. While the comment is specific about the issue of fairness and the additional complexity of the proposed method, it does not explicitly mention which part of the paper this issue is discussed in. This makes it weakly grounded, as the authors may need to infer the section where the comparison is made. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as the authors may need to infer the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the fairness of the comparison between the proposed method and the stateoftheart (SOTA). It highlights that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer points out that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. This feedback is valuable as it challenges the authors to consider the fairness of their comparisons and the practical implications of their method. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these concerns, such as by including prior information or simplifying the model. Overall, the comment is 3, as it raises important questions about the evaluation process and the practicality of the proposed method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not provide explicit guidance on how to incorporate these games into the experiments or what specific aspects of the methods should be analyzed in this context. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including collaborative games in the experiments, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this suggestion relates to, such as the experimental setup or results section. This makes it weakly grounded, as the authors may need to infer the specific part being addressed. The comment is specific in its suggestion to include collaborative games, but the lack of explicit grounding makes it 3. Therefore, the comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is valuable or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. This feedback provides a clear direction for improving the experimental design and analysis, offering a specific area for the authors to consider. However, the comment lacks depth and does not provide detailed guidance on how to incorporate these games or what specific aspects of the methods should be analyzed. While it offers a valuable suggestion, the feedback could be more helpful if it included additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, making it difficult for the authors to be convinced of the results. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue. It lacks concrete guidance on what specific information should be included or how the authors should present the experimental settings to make the figures more convincing. Without actionable steps or detailed guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures 1 to 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly identifies the issue as the missing experimental settings for these figures, which makes them hard to be convincing. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental settings for Figures 1 to 9 are missing, making them hard to be convincing. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the experimental settings are missing or how this impacts the persuasiveness of the figures. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, which makes it difficult for the authors to be convinced of the results. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided some guidance on how the authors might include or present the experimental settings to make the figures more convincing. Despite this, the comment is 4 as it directs the authors to a specific area that requires improvement, allowing them to enhance the clarity and persuasiveness of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the regularization term appears to be adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide explicit guidance on how to implement these suggestions or how to address the issue of the adhoc nature of the regularization term. While it identifies a potential area for improvement, the lack of detailed instructions or concrete steps makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term, which is a specific part of the paper. It provides feedback on the adhoc nature of the regularization and suggests that other statistics could be used instead of the mean and standard deviation. However, the comment does not explicitly mention which section or part of the paper discusses the regularization term, making it weakly grounded. It is specific in detailing the issue with the regularization term and suggesting alternative approaches. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term is adhoc and lacks theoretical support, suggesting that other statistics could be used instead of the mean and standard deviation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence to substantiate the assertion that the regularization term is adhoc or lacks theoretical support. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, suggesting that it may be adhoc and lacks theoretical support. It provides an intuitive explanation of the regularization but does not offer a detailed analysis or justification for why it is adhoc. The comment also suggests alternative statistics, such as the median, that could be used instead of the mean and standard deviation. However, it does not provide specific guidance on how to implement these suggestions or how to address the issue of the adhoc nature of the regularization term. While the comment highlights a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides several specific suggestions for improvement in the experimental section. It suggests that the authors should report average results over multiple runs to make the results more robust and easier to compare. It also asks for a discussion on why the decision boundaries look as they do in Section 3.1 and what information is present in Figure 9. These suggestions are explicit and provide clear guidance on what needs to be done, making the comment 5. The feedback is detailed and actionable, allowing the authors to understand exactly how to improve their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improvement in the experimental section, including the need to report average results over multiple runs, a discussion on decision boundaries, and clarification on the information presented in Figure 9. However, it does not explicitly mention which sections or parts of the paper these suggestions relate to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as reporting averages and discussing decision boundaries. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of three parts, each providing specific suggestions for improvement in the experimental section. The first part suggests reporting average results over multiple runs, which is a standard practice in experimental evaluations. The second part recommends discussing the decision boundaries in Section 3.1, which would provide valuable insights into the model\"s behavior. The third part asks for clarification on the information presented in Figure 9, which is a request for additional detail. While the suggestions are logical and common, they lack specific examples or references, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement in the experimental section, such as reporting average results over multiple runs to enhance the robustness and comparability of the results. It also suggests discussing the decision boundaries in Section 3.1, which could offer valuable insights into the model\"s behavior. Additionally, the comment requests clarification on the information presented in Figure 9, which is a request for additional detail. These suggestions are clear and actionable, providing the authors with concrete guidance on how to improve their draft. However, the comment could be more helpful if it included more detailed reasoning or examples to support the suggestions. Overall, the feedback is 4, as it offers actionable insights but could be expanded for better guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the authors\" reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 8082. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and then determine how to address it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 8082, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors are questioning, namely the use of the center correlation in Figure 4 A&B despite its stated lack of insight for discriminating model defenses. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point raises a question about the authors\" reasoning for using the center correlation in Figure 4 A&B, despite stating on lines 8082 that it was not insightful for discriminating model defenses. The comment implies that the authors should clarify why they found the metric useful in the figure and what they meant by the statement on lines 8082. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the center correlation is useful in this context. This lack of detailed explanation or justification makes the claim 3, as the authors would need to infer the reasoning behind the use of the metric. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid question about the use of the center correlation in Figure 4 A&B, despite the authors\" claim that it was not insightful for discriminating model defenses. This feedback highlights a potential inconsistency or lack of clarity in the paper, prompting the authors to reconsider their approach and provide a more detailed explanation of why they chose to use this metric. By addressing this issue, the authors can improve the clarity and coherence of their paper, ensuring that their claims are wellsupported and their methodology is transparent. The comment is 4 as it identifies a specific area for improvement and encourages the authors to provide additional context or justification for their choices."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not provide explicit guidance on how the authors should implement this change or any other specific actions they should take. The comment is vague and lacks concrete instructions, leaving the authors uncertain about how to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, it does not specify which part of the paper this critique refers to, such as a particular figure or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the labeling method, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the use of \"above/below diagonal\" versus \"above/below 45 degree\" for labeling elements in a plot, suggesting that the former is easier to interpret. This feedback is specific and identifies a potential improvement in the clarity of the plot labeling. However, the comment does not provide any suggestions or guidance on how the authors might implement this change or what other aspects of the plot could be improved. While it offers a clear observation, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the phrase, but it lacks concrete details on how to achieve this clarification. Therefore, the comment is 3, as it identifies a need for clarification but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should clarify, namely the meaning of the phrase \"is sufficient\" in the context of the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide any specific examples, reasoning, or references to support the claim that the phrase is unclear or requires clarification. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the phrase \"is sufficient\" at lines 240 and 428. It suggests that the authors should clarify the meaning of this phrase in the context of the sum of \"optimistic\" hopedfor rewards and the expected actual rewards. This feedback is 3 as it points out a potential area of ambiguity that could affect the clarity and understanding of the paper. However, the comment lacks detailed guidance on how to clarify the phrase or what specific aspects of the explanation need to be addressed. Without more detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically asks for clarification on whether the model, as described in Section 2.3, serves as a prototype approximation for nonlinear RNN models that exhibit emergent behavior. The reviewer also questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. While the comment identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address these questions or clarify the scientific insight. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity regarding the scientific insight gained from the model and formalism compared to prior taskoptimized approaches, and it questions the model\"s role as a prototype approximation for nonlinear RNN models. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It questions whether the model, as formulated in Section 2.3, serves as a prototype approximation for nonlinear RNN models that exhibit emergent behavior. The reviewer also questions whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. While the comment identifies a potential area of confusion, it lacks specific examples or detailed reasoning to fully substantiate the claims. The authors are left to infer the basis of the critique, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a critical question about the scientific insight gained from the proposed model and formalism compared to prior taskoptimized approaches. It specifically points out that the model, as described in Section 2.3, is not shown to be a prototype approximation for nonlinear RNN models that exhibit emergent behavior. This raises concerns about whether the work provides any further explanation of how these nonlinear models attain solutions through optimization on a task. The comment is clear and identifies a significant gap in the paper\"s explanation, prompting the authors to clarify the scientific contribution and provide a more detailed explanation of the model\"s role. However, it could be more helpful if it suggested specific ways to address this issue or provide additional context. Overall, the comment is 3 as it highlights a crucial area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are explicit and concrete, as they clearly indicate what changes need to be made to the paper. The authors can directly apply these actions to improve the visual presentation of their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are fully grounded as they explicitly mention specific parts of the paper, such as legends, axis labels, and captions, which allows the authors to accurately identify the sections that need improvement. The comment is also specific as it details what needs to be changed in these parts, such as increasing the font size and aligning it with the text size. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific suggestions for improving the readability of the paper by recommending that the text in legends and axis labels should be larger. It also suggests that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are based on common practices in academic writing and are logical and verifiable. However, the comment lacks specific examples or references to support these claims, which could make it slightly less robust. Overall, the comment is 4, as it provides a clear rationale for the suggestions but could benefit from additional evidence or references to enhance its persuasiveness.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the readability of the paper, particularly focusing on the font size in legends and axis labels. It suggests that the text in these elements should be larger and that the font size in captions and legends should be similar to the text size in Figures 2 and 3. These suggestions are actionable and directly address potential issues with the visual presentation of the paper, which can enhance its clarity and impact. However, the comment could be more helpful if it included additional guidance on how to implement these changes or provided examples of how the revised figures would look. Overall, the feedback is 4, as it offers clear and actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments, specifically mentioning Figure 2 of 1 which demonstrates a larger effect of removing highscoring images. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"counterfactual experiments\" and \"Journey TRAK,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests a comparison against Journey TRAK, particularly referencing Figure 2 of 1, which highlights a significant effect of removing highscoring images. This provides clear guidance on what needs to be addressed in the counterfactual experiments. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a comparison against Journey TRAK in the counterfactual experiments, referencing Figure 2 of 1. However, it does not provide specific examples or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. The claim is 3 as it offers a suggestion for improvement but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending a comparison against Journey TRAK in the counterfactual experiments. It highlights a particular aspect of the comparison, referencing Figure 2 of 1, which demonstrates a larger effect of removing highscoring images. This feedback is actionable and constructive, as it guides the authors to include a relevant comparison that could strengthen their analysis. However, the comment could be more helpful if it provided additional context or suggested specific ways to implement the comparison. Overall, the comment is 4, as it offers clear guidance on an important aspect of the research."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF, such as the sufficient amount of training data points needed. However, it does not explicitly instruct the authors to include these results or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should add these results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results related to not returning NSF. However, it does not specify which part of the paper these discussions are located in, making it weakly grounded. The comment is specific in its suggestion to include additional results, but the lack of grounding makes it difficult for the authors to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered 5. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could be enhanced by including sample complexitytype results for not returning NSF. This feedback is actionable, as it provides a clear direction for the authors to consider adding additional results to strengthen their theoretical analysis. However, the comment could be more helpful if it offered more detailed guidance on how to derive or incorporate these results. Overall, the comment is 4, as it provides a valuable suggestion for improvement but lacks some depth in terms of actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the authors\" VAD (Visual Attention Descriptor) description, suggesting that it discards TF (TimeFrequency) bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it discards TF bins with zero magnitude, which could lead to division by zero. The comment implies that a VAD should look for the presence of speech (not just energy) and is typically defined over time, not frequency. However, the comment does not explicitly instruct the authors to revise their VAD description or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider their VAD description and potentially address the issue of division by zero. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the VAD description, explaining that it discards TF bins with a magnitude less than epsilon, which is problematic as it could lead to division by zero. The comment further critiques the approach, suggesting that a VAD should look for the presence of speech (not just energy) and is typically defined over time, not frequency. This provides clear guidance on what needs to be addressed in the VAD description. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors\" VAD description is puzzling and suggests that it discards TF bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it discards TF bins with zero magnitude, which could lead to division by zero. The comment also critiques the approach, suggesting that a VAD should look for the presence of speech (not just energy) and is typically defined over time, not frequency. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to infer the reasoning and provide their own justification to address the feedback effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the authors\" VAD (Visual Attention Descriptor) description, highlighting a specific issue where the authors discard TF bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it could lead to division by zero and does not align with the typical definition of a VAD, which focuses on the presence of speech over time rather than frequency. This feedback is clear and actionable, as it directs the authors to reconsider their VAD description and address the issue of division by zero. However, the comment could be more helpful if it provided specific guidance on how to revise the VAD description or suggested alternative approaches. Overall, the comment is 4, as it offers valuable insights for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the discussion section could benefit from including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach as in Section 4.2. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is explicit and concrete, as it clearly indicates what additional discussion should be included and what aspects of it should be explored. The authors are given a clear direction on how to enhance the discussion section, making the comment 5.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. However, the comment does not explicitly mention which part of the paper this discussion should be included in, leaving the authors to infer that it should be in the discussion section. This makes the comment weakly grounded but specific, as it clearly specifies what needs to be addressed. Therefore, it aligns with the label 3.", "verifiability_rationale": "The review point suggests including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach. It provides specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. However, the comment lacks detailed reasoning or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or evidence, the claim is 3, as it provides a suggestion but lacks depth and clarity. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by suggesting that the discussion section could benefit from including a brief discussion on the empirical motivation for using timevarying Q^t and S_t, as opposed to a fixed approach. It offers specific examples, such as the effect on the volatility of \u03b1_t and the average lengths of predictive intervals when Q^t and S_t vary with time. This feedback is clear and actionable, as it guides the authors on what additional content to include in their discussion section. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the suggestion. Overall, the comment is 4, as it offers a clear direction for improvement but could be expanded for greater depth and impact."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses concerns about the paper\"s readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not explicitly suggest specific actions or provide detailed guidance on how to improve the paper. The authors are left to infer that they need to enhance the clarity of the presentation and provide more context for the experiments. While the comment identifies a general issue, it lacks concrete suggestions or detailed guidance on how to address it, making it 3.", "grounding_specificity_rationale": "The comment expresses concerns about the paper\"s readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not specify which part of the paper is difficult to follow or lacks context. The authors cannot confidently determine which sections or aspects of the paper are being referred to, making the comment weakly grounded. Additionally, the comment is somewhat specific in that it identifies the issues with clarity and context, but without pointing to specific sections or examples, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point expresses concerns about the paper\"s readability and the lack of clear intuition connecting the pieces, as well as the limited context provided by the experiments. However, it does not provide specific examples, reasoning, or references to support these claims. The authors are left to infer the validity of the feedback, which makes the comment 3. The comment is 3 because it identifies issues but lacks detailed justification or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s readability, noting that it is not particularly easy to follow and lacks a clear intuition for how the pieces fit together. Additionally, the reviewer points out that the experiments have little context, which can make it difficult for readers to understand their relevance. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how to enhance the clarity or provide more context for the experiments. The feedback is 3 as it directs the authors to areas that need attention, but it lacks depth and actionable advice, making it a 3 out of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of comparing the student and refinement networks, which are trained simultaneously. It suggests that the comparison might be unfair and requests the authors to provide KID/FID metrics for their teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics to address the concern about fairness. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the request for metrics, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, the comment does not provide any justification or reasoning for why this comparison might be unfair or why the inclusion of KID/FID metrics would address this concern. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. This feedback is 3 as it identifies a potential issue with the experimental setup and suggests a specific metric to include, which could enhance the rigor and comparability of the results. However, the comment lacks depth and does not provide detailed guidance on how to address the fairness issue or why the inclusion of KID/FID metrics is necessary. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to implement or explore this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider regarding the scaling of the refined region vector and suggests an alternative approach. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment provides a specific question and suggestion, it lacks detailed reasoning or examples to fully substantiate the claim. The authors are left to infer the implications and potential benefits of the alternative approach, which could be more effective with additional explanation or evidence. Therefore, the comment is considered 2, as it provides some justification but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific aspect of the paper that could be improved by questioning the scaling of the refined region vector. It suggests an alternative approach by introducing a scaling variable before the attention weight, which could potentially enhance the model\"s performance. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, leaving the authors with a somewhat vague understanding of the issue. While it provides a direction for improvement, the feedback could be more helpful if it included additional context or suggestions for exploration. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve their draft to address this problem, such as suggesting specific changes or improvements to the methodology or experimental setup. Without actionable steps or suggestions, the authors are left without a clear path to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to goal misspecification in the ALFRED benchmark, noting that failures occurred due to the LLM\"s inability to accurately recover the formal goal predicate, especially with ambiguities in human language. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in detailing the problem, the absence of grounding information makes it challenging for the authors to understand where to focus their improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This claim is 3 as it provides a specific example of a problem that can occur in the ALFRED benchmark. However, it lacks detailed reasoning or references to support the claim fully, making it 3. The authors could benefit from additional evidence or examples to strengthen the claim.", "helpfulness_rationale": "The review comment identifies a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM often fails to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. This feedback is 3 as it highlights a potential area for improvement in the draft, suggesting that the authors should consider refining their methodology or experimental setup to address this issue. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might improve their draft to address this problem. Without actionable advice, the authors may struggle to effectively incorporate this feedback into their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the significance of the improvement of the proposed method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV compared to other baselines. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment provides a clear direction for the authors to address the issue, it lacks specific guidance on how to analyze the distribution or why it might be difficult for SamplingGaussian to improve such frameworks. The action is explicit but somewhat vague, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the improvement of the proposed method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV compared to other baselines. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. However, the comment does not specify which part of the paper addresses these issues, making it difficult for the authors to pinpoint the exact sections that need attention. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the significance of the improvement of the proposed method over SOTA methods like IGEV and suggests that the authors analyze the distribution of disparities produced by IGEV compared to other baselines. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. However, the comment lacks specific examples, detailed reasoning, or references to support the claims made. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it provides some basis for understanding but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a question about the significance of the improvement of the proposed method over SOTA methods like IGEV, suggesting that the authors analyze the distribution of disparities produced by IGEV compared to other baselines. It also raises a concern about the difficulty of SamplingGaussian to significantly improve iterative frameworks similar to IGEV. While the comment identifies areas for further analysis and consideration, it lacks specific guidance or suggestions on how to address these concerns. The feedback is 3 as it prompts the authors to explore additional aspects of their method and its performance, but it could be more comprehensive with detailed recommendations or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should delve deeper into how specific models behave differently when ReGuide is applied, providing a more nuanced understanding of the conclusions. It gives an example of comparing false positive rates (FPR) between models with and without ReGuide. However, the comment does not explicitly instruct the authors to conduct this analysis or present the results in a specific way. While the action is implied, it lacks concrete guidance on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment suggests a deeper investigation into how specific models behave differently when ReGuide is applied, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this investigation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare false positive rates (FPR) between models with and without ReGuide, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should provide a deeper investigation into how specific models behave differently when ReGuide is applied, particularly focusing on differences in false positive rates (FPR). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand and address the suggestion effectively. The lack of detailed guidance or evidence weakens the verifiability of the claim, aligning it with a score of 2.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting a deeper investigation into how specific models behave differently when ReGuide is applied. It provides a specific example of comparing false positive rates (FPR) between models with and without ReGuide, which could enhance the nuance of the conclusions. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or presented preliminary results to illustrate the point. Overall, the feedback is 3 as it points out a valuable area for further exploration, but it lacks detailed actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that it is unclear how much performance gain is attributed to the task formulation versus the use of pretrained language models. It suggests including results using the GCPG model without pretrained initializations to address this ambiguity. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these additional experiments or present the results. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and then decide how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"missing ablations,\" which allows the authors to accurately identify the part of the paper being addressed. It specifies what is missing by suggesting the inclusion of results using the GCPG model without pretrained initializations. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that it is unclear how much performance gain is attributed to the task formulation versus the use of pretrained language models. It suggests including results using the GCPG model without pretrained initializations to address this ambiguity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains 3, as it is based on a logical inference but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by highlighting the lack of clarity regarding the source of performance gains. It points out that it is unclear how much of the performance improvement is due to the task formulation versus the use of pretrained language models. The suggestion to include results using the GCPG model without pretrained initializations is a specific and actionable step that would help the authors address this ambiguity. By providing a clear direction for additional experiments, the comment offers valuable guidance for improving the paper. However, it could be more helpful if it included more detailed reasoning or examples to support the claim. Overall, the comment is 4 as it directs the authors to a specific area for improvement and provides a clear action to take."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific guidance or action on how to achieve this. The authors are left without a clear understanding of what steps they should take to enhance the results on ImageNet, making the comment somewhat vague and lacking in actionable details. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that results on ImageNet could be more convincing of the proposed method. However, it does not specify which part of the paper discusses the results on ImageNet or provide any details on how to improve the results. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting that the results could be more convincing, but it lacks detailed guidance on how to achieve this. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that results on ImageNet could be more convincing of the proposed method. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to interpret the comment, making it difficult to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the results on ImageNet could be more convincing of the proposed method. While this feedback provides a direction for improvement, it lacks specific guidance or suggestions on how to enhance the results or what aspects of the ImageNet results might need attention. The comment is 3 as it identifies a potential area for improvement, but it does not offer detailed actionable advice, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of the paper\"s contribution, suggesting that it primarily focuses on studying the connection between complementary and model robustness without providing further insights or solutions on how to leverage this connection to improve model robustness. The comment implies that the conclusion could be easily obtained and suggests that the paper lacks insightful findings or possible solutions. However, it does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the paper. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the analysis and provide more insightful findings or solutions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of the paper\"s contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. However, the comment does not specify which part of the paper this concern relates to, such as a particular section or analysis. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the contribution, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of the paper\"s contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The comment suggests that the conclusion could be easily and intuitively obtained, implying that the paper lacks insightful findings or possible solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or context, the authors may find it challenging to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a significant concern about the sufficiency of the paper\"s contribution, specifically questioning whether the authors have adequately explored how to leverage the connection between complementary and model robustness to improve model robustness. The reviewer suggests that the conclusion could be easily and intuitively obtained, implying that the paper lacks insightful findings or possible solutions. This feedback is 3 as it identifies a key area for improvement, prompting the authors to expand on their analysis and provide more substantial insights or solutions. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these concerns, such as proposing additional experiments or analyses that could strengthen the paper. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\"s motivation. While it raises a valid concern about the focus, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors would need to infer that they should consider the differences in representation and potentially adjust their focus. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\"s motivation. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the focus, the absence of grounding information limits its effectiveness. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the choice of focusing on which clusters are \"best\" rather than the differences in representation between them, given the paper\"s motivation. This is a subjective opinion that raises a valid concern about the focus of the paper. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment raises a valid concern about the focus of the paper, specifically questioning why the authors chose to focus on which clusters are \"best\" rather than the differences in representation between them. This critique is based on the paper\"s motivation, suggesting that the current focus might be misaligned with the intended goals. While the comment identifies a potential issue with the paper\"s focus, it does not provide specific suggestions or guidance on how the authors might address this concern. The feedback is 3 as it highlights an area for improvement, but it lacks actionable advice, making it only 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics\". This provides a clear and direct action for the authors to take, which is to correct the caption. The comment is specific and concrete, as it identifies the exact figure and the correct caption, allowing the authors to know exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the caption from \"Node Dynamics\" to \"Edge Dynamics\". This provides the authors with precise guidance on how to improve the figure caption. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the caption for Figure 7 is incorrect and should be corrected to \"Edge Dynamics\" from \"Node Dynamics.\" This is a factual correction based on the content of the figure caption. However, the comment does not provide any reasoning or evidence to support why the caption is incorrect or why the suggested correction is appropriate. Without additional context or justification, the claim is difficult for the authors to verify or address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific error in the caption of Figure 7, which is a factual mistake. It provides a clear and actionable suggestion to correct the caption from \"Node Dynamics\" to \"Edge Dynamics.\" This feedback is precise and directly addresses a minor but important detail that could improve the clarity and accuracy of the paper. By correcting this error, the authors can enhance the overall quality and readability of their work. Therefore, the comment is 4, as it offers a clear and actionable improvement that the authors can easily implement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment does not explicitly instruct the authors to address this clarification or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for clarification and the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the traditional DCI framework and its consideration of explicitness (E) and size (S). It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, suggesting that these aspects may already be considered implicit. However, the comment does not specify which part of the paper discusses the DCI framework or where the authors can find the relevant information. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the issue of explicitness and size, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the explicitness (E) and size (S) of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment lacks specific examples or references to support the claim that the DCI framework is already considered explicit or sizerelated. Without detailed reasoning or evidence, the claim is 3, as it provides a basis for discussion but lacks the depth needed for full understanding. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the explicitness and size of the traditional DCI framework, suggesting that these aspects may already be considered implicit. It provides an example of how the capacity of probing and latent size can affect the DCI evaluation, implying that the authors need to clarify the motivation for considering explicitness and size as extra evaluation. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to the framework. While it identifies a potential area for improvement, it does not provide actionable steps or detailed reasoning to help the authors enhance their work. Therefore, the comment is 3, as it highlights a relevant concern but does not offer comprehensive guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also points out that the improvement brought by SoRA compared to the baseline might be due to random fluctuations. The comment suggests that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are actual improvements due to the SoRA method. This feedback is explicit and provides a clear action for the authors to take, namely to clarify the experimental results and provide a more detailed analysis of the improvements. The action is concrete, as it specifies exactly what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section of the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it details the issue of not providing standard deviation after multiple experiments and suggests that the authors should clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides clear guidance on what needs to be addressed in the experimental section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation after multiple experiments is not provided, which may lead to the conclusion that the improvement brought by SoRA compared to the baseline is due to random fluctuations. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional evidence or context, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a specific issue in the experimental section, noting that the standard deviation after multiple experiments is not provided. It also suggests that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are actual improvements brought by the SoRA method. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft. By addressing this issue, the authors can enhance the rigor and clarity of their experimental results, making the paper more robust and understandable. Therefore, the comment is 5, as it offers detailed guidance on how to improve the presentation of the experimental findings."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment identifies specific areas that need improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to make the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific issues with the organization and presentation of the paper, such as the font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the exact issues and provides examples, such as the small font size and the incorrect placement of figures and tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not well organized and the layout is rushed. It provides specific examples, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. These examples offer some support for the claim, but the comment lacks a broader context or references to similar issues in other papers. While the examples are specific, the overall claim could be strengthened with more detailed reasoning or references. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies several issues with the organization and presentation of the paper, such as the small font size of annotations in Figure 1 and Figure 2, the lack of explicitness in the figures, the incorrect placement of Table 2, and the incorrect format of the top two lines on page 6. While the comment provides specific examples of these problems, it does not offer detailed guidance on how the authors might address these issues or suggest improvements to the layout. The feedback is 3 as it highlights areas for enhancement, but it lacks depth and actionable suggestions, making it only partially beneficial for the authors to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for realworld querying. However, it does not provide explicit guidance on how the authors should address this concern or what specific aspects of the interventions need to be evaluated for practicality and safety. The action is implicit and vague, as it leaves the authors to infer the necessary steps without clear direction. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that while the computational types of interventions are reasonable, it is important to consider their practicality and safety for realworld querying. However, it does not specify which part of the paper discusses the types of interventions or where the authors should address the practicality and safety concerns. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is somewhat specific in that it highlights the importance of considering practicality and safety, but it lacks detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that while the types of interventions are reasonable computationally, they need to be considered for practicality and safety in realworld querying. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 2, as it offers a suggestion but lacks the necessary depth and support for the authors to fully understand and address the issue.", "helpfulness_rationale": "The review comment raises a valid concern about the practicality and safety of the interventions discussed in the paper. It suggests that while the computational types are reasonable, they need to be considered in terms of their realworld applicability and safety. However, the comment lacks specific guidance or suggestions on how the authors might address this concern, such as providing examples of realworld scenarios or discussing potential risks. While it identifies an important area for improvement, the feedback is somewhat limited in its actionable nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what changes they should consider making to their draft. Without specific suggestions or instructions, the authors are left without a clear path forward, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this concern or what changes might be necessary. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1, as it lacks sufficient evidence or explanation to be fully understood and actionable.", "helpfulness_rationale": "The review comment raises a concern about the separate treatment of images and their augmentations, suggesting that they might be interchangeable. However, the comment does not provide specific examples, reasoning, or suggestions for how the authors might address this concern or improve their draft. It lacks actionable guidance and depth, making it difficult for the authors to understand the implications of the comment and how to respond effectively. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the method separately on baseline detection and parsing techniques to better support their claim. While the comment identifies a specific issue and provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this evaluation or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should perform the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, which consists of two major components: a generative shape model and a word parsing model. It highlights the lack of clarity regarding which component contributes to the performance gain. The reviewer suggests evaluating the method separately on baseline detection and parsing techniques to better support the claim. However, the comment does not specify which part of the paper discusses the proposed method or the evaluation of the components. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of evaluating the components separately, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the contribution of each component to the performance gain of the proposed method. It suggests that the authors should evaluate the method separately on baseline detection and parsing techniques to better support their claim. However, the comment does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would strengthen the claim. The lack of detailed justification or evidence makes the claim 3, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key issue with the proposed method, specifically the lack of clarity regarding which component contributes to the performance gain. It suggests that the authors should evaluate the method separately on baseline detection and parsing techniques to better support their claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their analysis and strengthen their claims. However, the comment could be more helpful if it included suggestions on how to conduct the evaluation or what specific metrics to use. Overall, the comment is 4, as it offers valuable guidance for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption. While it highlights a potential area of concern, it does not provide explicit guidance on how the authors should address this issue or what steps they should take to clarify the method\"s behavior. The comment lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying a potential area of concern, as it questions the method\"s behavior without a key assumption. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the behavior of the method without the Lipschitz Hessian assumption, but it does not provide any specific reasoning, examples, or references to support why this is a concern. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area of concern regarding the method\"s behavior without the Lipschitz Hessian assumption. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue. Without additional context or recommendations, the authors may struggle to understand the implications of this concern or how to improve their work. Therefore, the comment is 2, as it highlights a potential weakness but does not offer actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it does not provide explicit guidance on how the authors should improve the presentation or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the presentation of these methods. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some pieces\" and \"equation (12),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies that the presentation of these methods is vague and requires checking the original paper for understanding. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it lacks specific examples or references to support the claim. The authors are left to infer that the presentation is vague, but without detailed examples or references, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of certain pieces of the paper, noting that some methods are described using existing methods, such as equation (12), and that the presentation of these methods is vague, requiring the authors to consult the original paper to understand them. This feedback is 3 as it highlights a potential area for improvement in the clarity and presentation of the paper. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might improve the presentation of these methods. Overall, the comment offers a clear indication of an area for improvement, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point indicates that Table 4 is incomplete and should include results for all four datasets. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to the table. The comment is specific in its suggestion, detailing which part of the paper needs improvement and what should be included. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the table should include results for all four datasets, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 4 is incomplete and should include results for all four datasets. While the comment identifies a specific issue with the table, it does not provide any reasoning or evidence to support why this is a necessary or important addition. The authors are left to infer the importance of this addition, which makes the claim 3. However, without further justification or examples, the claim is not 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, providing the authors with a direct instruction on what needs to be addressed to improve the completeness and accuracy of their results. By specifying the exact issue and the necessary addition, the comment offers a clear path for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the work, suggesting that it is incremental and not impressive or novel. However, it does not specify which part of the paper this critique refers to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment applies and what specific issues need to be addressed. Additionally, the comment is somewhat specific in its critique of the pipeline, but without clear references, it remains challenging for the authors to fully grasp the feedback. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the contribution of the work is incremental and that the proposed pipeline is not impressive or novel, consisting of a pack of tricks to improve defense evaluation. However, the comment lacks specific evidence or references to support this claim. Without detailed examples or comparisons to existing work, the authors may find it challenging to understand the basis of the critique. This makes the claim 3, as it is based on subjective assessment without strong supporting evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the technical contribution of the work, suggesting that it is incremental and not impressive or novel, consisting of a pack of tricks to improve defense evaluation. While the comment identifies a potential weakness in the novelty of the contribution, it lacks specific suggestions or guidance on how the authors might address this issue or enhance their work. The feedback is 3 as it points out a critical area for improvement, but it does not provide actionable steps or detailed advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuplelike structure instead of sets. This provides a specific and explicit action for the authors to take, as they can directly address this suggestion by revising the notation to better reflect the tuple structure. The comment is clear and concrete, offering a direct and actionable improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 122,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement by recommending that triples denoted as $(e_1, r, e_2)$ should be represented to show their tuplelike structure instead of sets. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that triples denoted as $(e_1, r, e_2)$ would clearly show their tuplelike structure instead of sets. This is a specific and actionable suggestion that could enhance the clarity of the paper. However, the comment does not provide any reasoning or examples to support why this change would be beneficial or how it would improve the understanding of the triples. Without additional context or justification, the claim is 3, as it lacks sufficient evidence to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that triples denoted as $(e_1, r, e_2)$ would be clearer if they were represented to show their tuplelike structure instead of sets. This feedback is actionable and directly addresses a potential area for enhancing the clarity of the paper. By suggesting a specific change, the comment empowers the authors to improve the presentation of their work. However, the comment could be more helpful if it included additional context or examples to illustrate why this change would be beneficial. Overall, the comment is 4 as it offers a clear and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the scalability of optimal quantization, suggesting that it is costly even with clustering. It also points out that the paper aims to speed up variational inference (VI) through fast convergence, but quantization is a bottleneck in this process, making the method less effective for big data and big model settings. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the method or what specific changes might be necessary. As a result, the authors are left without clear direction on how to respond or improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the scalability of optimal quantization, a topic mentioned in the abstract and introduction. It highlights the cost of quantization even with clustering, which is a relevant issue for big data and big model settings. However, the comment does not specify which part of the paper discusses this issue or provide detailed guidance on how to address it. The authors can infer that the issue is related to the abstract and introduction, but the lack of specific guidance makes the comment weakly grounded. The comment is specific in identifying the problem with quantization, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that optimal quantization is not scalable, even with clustering, and that it is a bottleneck for variational inference (VI) in big data and big model settings. The comment provides a logical reasoning by explaining the cost of quantization in terms of the number of data points (N) and the dimension (M). However, it lacks specific examples or references to support the claim about the cost of quantization. While the reasoning is somewhat clear, the absence of detailed evidence or references makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the scalability of optimal quantization, which is a significant concern for big data and big model settings. It highlights that even with clustering, quantization remains costly, making it a bottleneck for variational inference (VI). This critique is important as it points out a potential weakness in the method\"s applicability to largescale problems. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve the method. Without specific recommendations or strategies, the authors are left without a clear path forward, making the comment 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is explicit and provides a clear action for the authors to take, which is to include a gradient comparison between KL and PCC. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC)\" as key components of the paper. It also specifies the issue with the assumption that PCC is a more relaxed constraint compared to KL divergence, suggesting that the constraint strength should be defined by the gradient distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is 4 as it provides a logical reasoning and an example to support the claim, but it lacks specific references or detailed explanations of how the gradient comparison would be conducted. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence. It provides a logical argument based on the concept of constraint strength being defined by the gradient distribution, and it offers an example comparing KL divergence and MSE loss to illustrate the point. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim, which is a clear and actionable feedback for the authors. This feedback is 4 as it guides the authors to address a specific aspect of their work and improve its rigor. However, it could be more helpful if it included more detailed guidance on how to conduct the gradient comparison or provided additional examples. Overall, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the analysis presented in Figure 4. It asks whether GPI with noise added could reproduce the data similarly well, suggesting that additional measures should be considered to show that GPI cannot have as good a fit with behavioral data. The reviewer also suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the possibility of GPI with noise added reproducing the data similarly well and the need for additional measures to show that GPI cannot have as good a fit with behavioral data. Furthermore, the comment suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. This provides clear guidance on what aspects of the analysis need further exploration or discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the analysis presented in Figure 4, specifically regarding the reproducibility of data with GPI and noise, and suggests considering additional measures to show that GPI cannot have as good a fit with behavioral data. It also proposes discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The authors are left to interpret the suggestions, which may make it difficult to fully understand and address the issues. Therefore, the comment is considered 2, as it provides some basis for the claims but lacks sufficient detail or evidence to fully substantiate them.", "helpfulness_rationale": "The review comment raises several important points that could enhance the paper\"s analysis and discussion. It questions the reproducibility of data with GPI and noise, suggesting that additional measures should be considered to demonstrate that GPI cannot have as good a fit with behavioral data. The comment also proposes discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. However, the comment lacks specific guidance on how to address these points or what additional analyses might be necessary. While it identifies areas for improvement, the feedback could be more helpful if it provided more detailed suggestions or examples of how to strengthen the analysis. Therefore, the comment is 3, as it offers insights but could be more comprehensive and actionable."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the authors should compare their proposed approach with a \"small learning rate for attention parameters\" benchmark. However, it does not provide explicit instructions on how to conduct this comparison or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors need to infer that they should perform the comparison, but it lacks concrete guidance on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the proposed approach with a \"small learning rate for attention parameters\" benchmark, but it does not specify which part of the paper this comparison should be made or where the \"small learning rate for attention parameters\" benchmark is described. This makes it difficult for the authors to understand which section or part of the paper needs to be addressed. Additionally, the comment does not provide specific guidance on what aspects of the comparison should be highlighted or how the comparison should be conducted. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests comparing the proposed approach with a \"small learning rate for attention parameters\" benchmark, but it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or beneficial. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis for the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests comparing the proposed approach with a \"small learning rate for attention parameters\" benchmark, which could provide valuable insights into the effectiveness of the proposed method. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects of the comparison should be highlighted. Without additional context or suggestions, the authors may find it challenging to understand the significance of the comparison or how to implement it. Therefore, the comment is 2, as it offers a general idea but lacks actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be more appropriate to reproduce the results of the compared methods using the same setting to ensure a fair comparison. However, the comment does not provide explicit guidance on how to reproduce the results or what specific steps should be taken to achieve this. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of AdamW with cosine learning rate for training the proposed method, while comparing it with methods that use Adam with fixed learning rate. This provides a specific point of comparison and highlights a potential issue with the fairness of the comparison. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the discrepancy in the training methods used, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison between the proposed method and other methods is unfair because the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be better to reproduce the results of the compared methods using the same setting to ensure a fair comparison. However, the comment lacks specific examples or references to support the claim that most recent methods have their code released, making it difficult for the authors to verify the suggestion. The reasoning is logical but lacks detailed evidence, making the claim 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It highlights that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that it would be more appropriate to reproduce the results of the compared methods using the same setting to ensure a fair comparison. This feedback is clear and actionable, as it provides a specific suggestion for improvement. However, it could be more helpful if it included details on how to reproduce the results or what specific steps should be taken. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric. While it suggests an area for further exploration, it does not provide explicit guidance on how the authors should address this question or incorporate it into their work. The comment lacks concrete actions or suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its inquiry about the performance of a particular method, but it lacks detail on how this information could be integrated or utilized. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, but it does not provide any specific reasoning, examples, or references to support the claim. The comment lacks detailed justification or evidence to substantiate the suggestion, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the SOTA method (e.g., LST) combined with the adaptive metric, which could be a valuable area for further exploration. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might approach this question or what aspects of their work could be improved. Without actionable feedback or detailed insights, the authors may find it challenging to address the comment effectively. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance or direction."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point critiques the quality of the plots, specifically mentioning that they are too small, have hardtodistinguish colors, poorly labeled axes, and visually similar labels. It suggests that these issues are the reason for the substandard clarity. However, the comment does not provide explicit guidance on how the authors should improve the plots or what specific changes to make. The actions are implicit and vague, leaving the authors without clear steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the plots,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the plots, such as their size, color distinguishability, poor labeling, and visually similar labels. This provides clear guidance on what needs to be addressed to improve the clarity of the presentation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the quality of the plots, detailing specific issues such as their size, color distinguishability, poor labeling, and visually similar labels. These claims are supported by examples and logical reasoning, providing clear evidence for the issues. However, the comment lacks references to external sources or detailed explanations of why these issues are significant. While the feedback is 4, it could be strengthened with additional references or examples to fully substantiate the claims. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it provides specific feedback on the quality of the plots, which are a crucial part of the paper. It identifies several issues, such as the small size, hardtodistinguish colors, poorly labeled axes, and visually similar labels, all of which impact the clarity of the presentation. The comment also explains why these issues are significant, as they contribute to a substandard rating of clarity. By highlighting these specific problems, the reviewer offers actionable guidance for the authors to improve the visual presentation of their experimental results. This detailed feedback is valuable and empowers the authors to make meaningful enhancements to their draft, making the comment 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a concern regarding the performance gains of the proposed approach, noting that the difference between the baseline and the best approach is less than 1% on most metrics. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the performance. The comment lacks concrete guidance on what actions the authors should take to enhance their results. Without specific advice or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It only mentions the performance gains and the comparison between different approaches, without referencing any specific section, table, or figure. Therefore, the authors cannot confidently determine which part of the paper the comment pertains to, making it weakly grounded. Additionally, the comment is specific in that it highlights a concern about the performance gains being less than 1%, which could be useful for the authors to address. However, without grounding, the authors are left without a clear understanding of where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance gains are not very high, as the difference between the baseline and the best approach is less than 1% on most metrics. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to fully understand or address the concern raised. Therefore, the claim is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment highlights a concern regarding the performance gains of the proposed approach, noting that the difference between the baseline and the best approach is less than 1% on most metrics. This observation is important as it suggests that the proposed method may not be significantly better than the baseline, which could impact the overall significance of the work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or specific suggestions, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 2, as it identifies a potential weakness but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. While it prompts the authors to consider the value of this information, it does not provide explicit guidance on how to address this question or what actions should be taken. The comment is somewhat vague, as it does not specify how the authors should analyze the performance or what kind of analysis would be beneficial. Therefore, the comment is 3, as it provides a direction but lacks concrete steps for implementation.", "grounding_specificity_rationale": "The comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to analyze the performance or what kind of analysis would be beneficial. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, asking for clarification or further analysis rather than making assertions. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the impact of specific information on the feedback network, specifically asking about the performance with and without certain types of information. This question is relevant as it seeks to understand the value of the information provided in the draft. However, the comment does not offer any suggestions or guidance on how to address this question or what actions the authors should take to improve their draft. While it identifies an area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Table 1 should include standard deviations and that the experiments should be more extensive to make the submission stronger. However, it does not provide explicit instructions on how to add standard deviations to the table or how to make the experiments more extensive. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of standard deviations and the need for more extensive experiments. This provides clear guidance on how to improve the submission. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 does not show standard deviations and suggests that including them would make the submission stronger. However, the comment lacks specific examples or references to support the claim about the importance of standard deviations in strengthening the submission. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 1, noting that it does not include standard deviations. It also suggests that the experiments should be more extensive to strengthen the submission. While the comment points out a clear area for improvement, it lacks detailed guidance on how to address these issues or what specific changes should be made to the experiments. The feedback is 3 as it highlights important aspects that need attention, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. While the comment implies that the authors should consider expanding their experiments, it does not provide explicit guidance on which specific architectures or tasks to include. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, it does not specify which other architectures or tasks should be considered, nor does it provide any guidance on how to approach this expansion. The comment lacks grounding as it does not clearly identify the specific part of the paper being addressed, and it is also not specific in its suggestions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments conducted in the paper, noting that they are limited to neural networks and image classification tasks. It suggests that exploring the performance of attacks on other architectures and classification tasks would be interesting. While the comment highlights a potential area for future research and improvement, it does not provide specific guidance or suggestions on which tasks or architectures to consider. This feedback is 3 as it points out a potential avenue for expansion, but it lacks depth and specificity, leaving the authors with limited actionable insights. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the impact of mitigation strategies on the model\"s overall performance, suggesting a potential tradeoff between reducing memorization and maintaining utility. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to mitigate the potential impairment. The comment implies that the authors should consider the impact of these strategies on performance, but it lacks concrete suggestions or detailed instructions on how to implement this consideration. Therefore, the comment is 3, as it identifies a potential issue but does not provide clear guidance on how to address it.", "grounding_specificity_rationale": "The comment addresses the impact of mitigation strategies on the model\"s overall performance, suggesting a potential tradeoff between reducing memorization and maintaining utility. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its critique of the potential impairment of the model\"s utility, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas that need attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the impact of mitigation strategies on the model\"s overall performance, suggesting a potential tradeoff between reducing memorization and maintaining utility. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered 5. Therefore, the comment is rated as 2, as it hints at a concern but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the impact of mitigation strategies on the model\"s overall performance, suggesting a potential tradeoff between reducing memorization and maintaining utility. It highlights that if these strategies significantly impair the model\"s utility, it might deter their adoption. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the mitigation strategies. The feedback is 3 as it points out a critical area for consideration, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the proposed approaches only outperform the baselines in one out of three setups, and there is no consistent trend in the results. It suggests that the results are insufficient to prove the benefits of the proposed methods and recommends additional experiments or more indepth analysis. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments or perform more detailed analysis to strengthen the paper. The comment is concrete, as it specifies exactly what needs to be done to improve the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the results, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend, making the results insufficient to justify the claims. The comment suggests that additional experiments or more indepth analysis are necessary to address these issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results presented in Table 2 are insufficient to prove the benefits of the proposed methods. It provides specific evidence, such as the fact that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This detailed explanation supports the claim, making it 4. However, the comment could be strengthened by providing additional context or examples to further substantiate the claim. Overall, the feedback is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This observation is crucial as it questions the effectiveness and generalizability of the proposed methods. The comment suggests that additional experiments or more indepth analysis are necessary to better justify the claims made in the paper. This feedback is clear, actionable, and provides a clear direction for the authors to improve their draft by addressing the limitations in their experimental results. Therefore, the comment is 5, as it offers specific and constructive guidance for enhancing the paper."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. However, it does not provide explicit guidance on how to achieve this detailed comparison or what specific aspects of the comparison should be emphasized. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. However, it does not specify which part of the paper this comparison should be made or which sections of the related work should be discussed. This lack of grounding makes it difficult for the authors to understand where to focus their efforts. The comment is specific in its suggestion to compare time complexity and competitiveness, but the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a more detailed comparison with related work, particularly in terms of time complexity and competitiveness. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to incorporate it into their work. Therefore, the comment is considered 2, as it provides some indication of the need for a more detailed comparison but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests that the paper would benefit from a more detailed comparison with related work, specifically focusing on the time complexity and competitiveness of prior art. This feedback is 3 as it identifies a potential area for improvement, but it lacks specific guidance on how to conduct this comparison or what aspects of prior work should be discussed. The comment provides a clear direction for enhancing the paper, but it could be more helpful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, it does not provide explicit instructions or detailed guidance on how to achieve this clarification. The action is implicit, as the authors need to infer that they should elaborate on the improvements of their method over ODA. While the comment is 3, it lacks concrete details on how to implement the suggested improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ODA,\" which is a specific method used in the context of solving the MOIP problem. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the lack of clarity on how the presented method improves performance and computation speed compared to using ODA. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs further explanation. However, the comment could be more helpful if it provided additional guidance on how to improve the clarity of this explanation or suggested specific areas where the authors could elaborate. Overall, the comment is 4, as it provides a clear direction for improvement but lacks some depth in terms of actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to 9 and 16. It questions the rationale behind the order of comparisons and the focus on computational cost with 9 while omitting 16. The comment implies that the authors should provide a clearer explanation of the logic and comparisons, but it does not offer specific guidance on how to address these issues. The feedback is 3 as it identifies areas for improvement, but it lacks concrete suggestions or detailed guidance on how to implement the changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the logic and comparisons between the proposed method and specific references 9 and 16. It also questions the rationale behind the order of comparisons and the focus on computational cost with 9 while omitting 16. However, the comment does not specify which part of the paper these questions pertain to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need clarification or improvement. While the comment is specific about the content of the questions, it lacks grounding as it does not provide clear references to the paper sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to 9 and 16. It questions the rationale behind the order of comparisons and the focus on computational cost with 9 while omitting 16. However, the comment does not provide any specific reasoning, examples, or references to support these claims. The questions are presented as logical inquiries but lack detailed justification or evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its relation to 9 and 16. It questions the rationale behind the order of comparisons and the focus on computational cost with 9 while omitting 16. This feedback highlights areas where the authors could improve the clarity and coherence of their comparisons, making it 3. However, the comment lacks detailed guidance or suggestions on how to address these issues, which limits its impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it prompts the authors to consider this comparison, it does not provide explicit guidance on how to address it or what specific aspects of the comparison should be explored. The action is implicit, as the authors need to infer that they should compare their PL condition with the one mentioned in the reference. However, the lack of detailed guidance on how to conduct this comparison makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific reference, \"\u00e2\u0080\u009cGlobal Convergence of ArbitraryBlock Gradient Methods for Generalized Polyak\u00c5\u0081ojasiewicz Functions\u00e2\u0080\u009d, arXiv:1709.03014,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for a comparison of the PL condition used in the paper with the PL conditions proposed in the mentioned reference, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it prompts the authors to consider this comparison, it does not provide any specific reasoning, examples, or references to support the claim that such a comparison is necessary or beneficial. The lack of detailed justification or guidance makes it difficult for the authors to understand the basis for the comparison and how it might impact their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the comparison of the PL condition used in the paper with the PL conditions proposed in a specific reference. While it prompts the authors to consider this comparison, it does not provide any guidance on how to approach it or what aspects of the comparison might be relevant. The comment lacks depth and specificity, as it does not offer any suggestions or insights on how to address the comparison effectively. Without additional context or direction, the authors may find it challenging to understand the significance of the comparison or how to incorporate it into their work. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline 31, 33, *. However, the comment does not specify how the authors should conduct this analysis or what specific aspects of the computational effort need to be addressed. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide this analysis for a fair comparison with the baseline, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a complete lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. This is a crucial aspect that needs to be addressed for a fair comparison with the baseline. However, the comment lacks specific guidance on how the authors should conduct this analysis or what specific aspects of the computational effort need to be considered. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction but could be more comprehensive with actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the analysis. While the authors can infer that they need to clarify the analysis and provide theoretical evidence, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, but it does not specify which part of the paper this analysis is discussed. The authors cannot confidently determine which section or figure this analysis is related to, making the comment weakly grounded. However, the comment is specific in detailing the issue of the lack of clarity in the analysis and the absence of theoretical evidence. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, noting that the trend is not clear across different model architectures and that no theoretical evidence is provided. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is 3, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific area of concern in the paper, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It highlights that the trend is not clear across different model architectures and that no theoretical evidence is provided to support the correlation. This feedback is valuable as it points out a gap in the analysis and suggests that the authors should consider expanding their discussion to include theoretical evidence or clarify the analysis. However, the comment could be more helpful if it provided specific guidance on how to address these issues or suggested alternative approaches. Overall, the comment is 3, as it directs the authors to areas that need improvement but lacks detailed actionable suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It also questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for selfsupervised learning (SSL) algorithms. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to mitigate the potential trap or clarify the implications for SSL algorithms. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the experiments conducted in Section 4.2, particularly the use of AutoAugment as a stronger augmentation strategy. It raises a concern about potential information leakage due to the supervised training on ImageNet, which is a specific aspect of the paper. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about information leakage and its implications for the conclusions drawn in the paper, particularly regarding the pretraining dataset matching the target dataset for linear classification and its relevance to SSL algorithms. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for selfsupervised learning (SSL) algorithms. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that this is a significant issue. The lack of detailed justification makes it difficult for the authors to understand the basis of the concern and how it might affect their results. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about a potential trap in the experiments conducted with AutoAugment, specifically regarding the possibility of information leakage due to the supervised training on ImageNet. It questions the conclusion drawn in the paper regarding the pretraining dataset matching the target dataset for linear classification and its implications for selfsupervised learning (SSL) algorithms. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or clarify the implications for SSL algorithms. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it offers some insight but lacks depth and practical guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper has weak analysis on the alignment of entity representations, particularly for languageagnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from lowresourced languages with highresourced ones. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the additional analysis or what specific aspects of the alignment should be explored. The authors know that they need to expand their analysis, but the comment does not offer concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper has weak analysis on the alignment of entity representations, particularly for languageagnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from lowresourced languages with highresourced ones. However, the comment does not specify which part of the paper discusses entity representations or where the analysis is currently lacking. This makes it difficult for the authors to pinpoint the exact section that needs improvement. While the comment is specific about the type of analysis and the languages to consider, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper has weak analysis on the alignment of entity representations, particularly for languageagnostic characters. It suggests that the authors should add more analysis, visualizations, or case studies for different languages, including language families, and specifically mention the alignment of entities from lowresourced languages with highresourced ones. However, the comment lacks specific examples or references to support the claim that the analysis is weak. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the analysis of entity representations, particularly for languageagnostic characters. It suggests that the authors should provide more analysis, visualizations, or case studies to enhance the understanding of multilingual alignment. Additionally, the comment raises an interesting question about the alignment of entities from lowresourced languages with highresourced ones, which could be a valuable addition to the paper. However, the comment lacks specific guidance on how to conduct the additional analysis or what aspects of the alignment should be explored. While it provides a clear direction for improvement, the feedback could be more helpful if it included concrete suggestions or examples. Therefore, the comment is 3, as it offers a clear idea of what needs to be addressed but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While the comment implies that additional information is needed, it does not explicitly instruct the authors to provide these details or specify how they should be presented. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the use of attention. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not specify which part of the paper discusses the use of attention, making it difficult for the authors to identify the exact section or element that needs more detail. The comment is specific in its suggestion to add more details, but it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details on using attention would be useful, potentially as an extra appendix. However, it does not provide any specific reasoning or examples to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that more details on using attention would be beneficial, potentially as an extra appendix. While it identifies a potential area for improvement, it lacks specificity and does not provide concrete guidance on how to enhance the paper with additional details on attention. The comment is 3 as it points out a potential area for improvement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues or what steps the authors should take to address them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the references list, including the presence of duplicates and the absence of publication venues and years. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the references list contains duplicates and that publication venues and years are missing. However, it does not provide any specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to verify the accuracy of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two specific issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it points out these problems, it does not provide any suggestions or guidance on how the authors might address these issues. The feedback is clear and identifies areas for improvement, but it lacks actionable advice or detailed suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what additional experiments could be conducted. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is 1 as it does not provide specific guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. However, it does not provide any specific reasoning or evidence to support this claim or question. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale behind showing results only on images corrupted with Gaussian noise, despite the claim that the model can work well for various image noise types. This question prompts the authors to consider whether the choice of noise type limits the generalizability of their findings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to strengthen the paper. While it identifies an area for improvement, the lack of actionable feedback makes it 3, as it highlights a potential gap in the analysis but does not offer concrete steps for the authors to take. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication and the importance of checking for useful communication. However, the comment does not provide explicit guidance on how to simplify the descriptions or what specific changes should be made. The suggestions are somewhat vague and lack concrete details, making it challenging for the authors to implement them effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication and the importance of checking for useful communication. However, the comment does not specify which part of the paper contains these convoluted descriptions, making it difficult for the authors to pinpoint the exact areas that need improvement. While the suggestions are somewhat specific, the lack of grounding makes it challenging for the authors to fully understand the feedback. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication and the importance of checking for useful communication. However, the comment lacks detailed reasoning or examples to fully support the claim that the descriptions are convoluted. While the suggestions are somewhat specific, the overall critique lacks a comprehensive explanation, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions, which is a valuable piece of feedback. The comment also offers specific suggestions, such as referencing related work on speakerlistener communication and the importance of checking for useful communication. However, the feedback could be more helpful if it provided more detailed guidance on how to simplify the descriptions or what specific changes should be made. Overall, the comment is 3 as it identifies an area for improvement and offers some suggestions, but it lacks depth and specificity to fully assist the authors in enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should provide details about the division of the dataset into training and testing sets, including the numbers used and the method of division. It specifies that the division should be explained, whether it was random or based on other considerations. This provides clear and concrete guidance on what information is missing and how it should be addressed. The authors know exactly what additional details they need to include to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for details about the division of the dataset into training and testing sets, including the numbers and the method of division. This allows the authors to accurately identify the part of the paper that requires attention. The comment is also specific because it clearly specifies what information is missing and how it should be addressed, such as whether the division was random or based on other considerations. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information regarding the division of the dataset into training and testing sets. It does not contain a claim that requires verification or justification. The comment is factual and descriptive, as it requests specific details about the dataset division. Therefore, it is classified as \"No\"", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their draft by providing more details about the division of the dataset into training and testing sets. It requests the inclusion of numbers and the method of division, which are crucial for reproducibility and understanding the experimental setup. By addressing this feedback, the authors can enhance the clarity and completeness of their paper. The comment is clear, actionable, and provides a specific direction for improvement, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing guidance on how to address the scalability issue. The feedback lacks concrete details on how the authors might improve their draft, making it 1.", "grounding_specificity_rationale": "The comment addresses concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment does not specify which part of the paper these issues are related to, making it difficult for the authors to pinpoint the exact sections that need revision. The lack of specific references or grounding makes the comment weakly grounded. Additionally, the comment is specific in its critique of the need for human labor and the scalability issue, but without clear guidance on how to address these concerns, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The absence of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the longtext input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. While it identifies potential areas for improvement, it does not provide actionable steps or detailed insights that would be helpful for the authors to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the experimental validation, including the limited depth of the networks considered (only 2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, specifically mentioning the consideration of layer redundancy in the context of network pruning. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their experimental validation or positioning, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the experimental validation of the paper, specifically mentioning the limitation of considering only shallow networks (2 or 3 layers) and the lack of description of the optimization strategy, including the grid search for hyperparameter selection. It also points out a minor issue regarding the positioning of the work with respect to related works, such as the consideration of layer redundancy in the context of network pruning, providing a specific example. The comment is fully grounded as it explicitly mentions the parts of the paper being addressed, and it is specific because it details the issues with the experimental validation and positioning. Therefore, this comment is labeled as 5, corresponding to a score of 5.", "verifiability_rationale": "The review point claims that the experimental validation is not convincing, citing the limited depth of the networks considered (2 or 3 layers) and the lack of description of the optimization strategy, such as the grid search for hyperparameter selection. It also mentions a minor issue regarding the positioning of the work with respect to related works, specifically highlighting the consideration of layer redundancy in the context of network pruning. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of specific examples or detailed explanations weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically focusing on the experimental validation. It points out that the experiments are limited to shallow networks (2 or 3 layers) and lack a detailed description of the optimization strategy, including the grid search for hyperparameter selection. Additionally, the positioning of the work with respect to related works is noted as limited, with a specific example provided regarding the consideration of layer redundancy in network pruning. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address these limitations in their revised draft. The feedback is 3 as it directs the authors to areas that need improvement, but it lacks actionable advice, making it a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any evidence or reasoning to support this claim. It also does not suggest any actions or improvements that the authors should take to address this issue. The comment lacks explicit guidance on how the authors might address the absence of new theoretical results, making it 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this work,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies what needs to be addressed by stating that the work does not prove any new theoretical results. This provides clear guidance on what the authors should consider or address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work does not prove any new theoretical results, despite the use of a specific type of loss in a particular setting. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 2, as it provides a claim but lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically that it does not provide new theoretical results despite using a specific type of loss in a particular setting. This feedback is clear and actionable, as it highlights a gap in the paper\"s contribution. However, the comment could be more helpful if it suggested specific areas where the authors could address this issue or provide additional theoretical analysis. Overall, the comment is 3 as it points out a significant aspect that needs attention, but it lacks depth and guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the data and proposes that human test results might support it. However, it does not provide explicit guidance on how the authors should test this hypothesis or what evidence they should present to either prove or disprove it. The action is implicit, as the authors need to infer that they should provide more evidence to support or disprove the hypothesis. The comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the relevant section. It also lacks specificity, as it does not provide detailed guidance on what evidence should be presented to support or disprove the hypothesis. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data and suggests that human test results might support it. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains speculative and difficult to verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data, suggesting that the \"trivial\" part might be highly consistent with the training set, while the \"impossible\" part might involve ambiguous labels or atypical object poses. The comment questions whether the authors could provide more evidence to support or disprove this hypothesis, which is a valuable suggestion for improving the paper. However, the comment lacks specific guidance on how to test this hypothesis or what kind of evidence would be most effective. While it provides a direction for improvement, it could be more helpful with additional details on how to implement the suggestion. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the testing of the model on other tasks within the bAbI dataset. It does not provide explicit instructions or suggestions on how to address this concern, such as testing on additional tasks or providing a rationale for the choice of Task 1. While the comment implies that the authors should consider expanding their testing, it lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in its suggestion to consider other tasks, but the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not provide any evidence, reasoning, or references to support why testing on other tasks would be beneficial or necessary. The comment lacks specific details or justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically noting that it was only tested on Task 1. This feedback highlights a potential area for improvement, as testing on additional tasks could provide a more comprehensive evaluation of the model\"s capabilities. However, the comment lacks specific suggestions or guidance on how to address this issue, such as proposing additional tasks or explaining the rationale for focusing solely on Task 1. While it identifies a potential weakness, it does not provide actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide explicit guidance or suggestions on how to address this issue, such as proposing alternative methods or optimizations. The action is implicit and vague, as the authors are left to infer that they need to consider the time complexity and potential improvements. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the time complexity of the proposed algorithm, specifically mentioning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not specify which part of the paper discusses the algorithm or the hypervolume calculation, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue of time complexity, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the repeated calculation of hypervolume is timeconsuming. Without additional context or justification, the authors may find it challenging to understand the basis of the claim and how it relates to the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be timeconsuming, especially for problems with many objectives, potentially making the algorithm impractical. While the comment identifies a potential issue with the algorithm\"s efficiency, it does not provide specific suggestions or guidance on how to address this concern. The feedback is 3 as it points out a potential limitation that the authors should consider, but it lacks actionable advice or detailed insights into how to mitigate the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should delve deeper into the limitations of evolutionary methods, specifically mentioning the importance of leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and suggests that the authors should be more precise when being critical. The comment further asks for clarification on the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago. While the comment provides several suggestions for improvement, it lacks explicit guidance on how to implement these suggestions or what specific actions the authors should take. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the paper should explore deeper aspects of evolutionary methods, such as leveraging state, reactiveness, and learning during an episode. It critiques the title as being too generic and suggests that the authors should be more precise when being critical. The comment also asks for clarification on the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance on what aspects to explore but lacks detailed instructions on how to do so. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the paper for being too generic and vague, particularly in its title. It suggests that the authors should be more precise when being critical and provides examples of specific areas that could be explored further, such as the importance of leveraging state, reactiveness, and learning during an episode. However, the comment lacks detailed reasoning or references to support these claims, making it 3. The authors would need to infer the need for more specific feedback and detailed suggestions to improve the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the paper for being too generic and suggests that the authors should be more precise in their critical feedback. It provides specific examples, such as the importance of leveraging state, reactiveness, and learning during an episode, and questions the title\"s vagueness. The comment also asks for clarification on the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods and the landscape of research 10 years ago. While the feedback is 3 in identifying areas for improvement, it lacks depth and actionable suggestions, making it 4. The authors would need to infer the need for more detailed feedback to fully address the concerns raised."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at image edges. While the questions are explicit and direct, they do not provide concrete guidance on how the authors should address these issues. The authors are left with a clear understanding of what needs to be clarified but lack specific steps or suggestions on how to improve the description. Therefore, the comment is 3, as it identifies areas for improvement but does not offer detailed guidance on implementation. This aligns with a score of 3.", "grounding_specificity_rationale": "The comment raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at image edges. However, it does not specify which part of the paper these questions pertain to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the questions are specific about the methodology, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at image edges. However, it does not provide any claims, opinions, or suggestions that require verification. The comment is purely descriptive, asking for clarification on specific aspects of the methodology. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at image edges. While these questions highlight areas where the authors could improve their methodology, they do not provide specific suggestions or guidance on how to address these issues. The feedback is 3 as it identifies potential weaknesses in the methodology, but it lacks actionable advice or detailed explanations of how the authors might improve their approach. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide empirical justification for their claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. However, the comment does not specify how this justification should be presented or what kind of empirical evidence would be most effective. While it implies a need for additional support, the action is implicit and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"first claimed contribution of the paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the claim, suggesting that there should be empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical justification for its claim regarding the proposed algorithm. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this claim is important or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the lack of empirical justification for the claim that the proposed algorithm does not take as many points or does not need apriori knowledge about dimensions of subspaces. This feedback is clear and actionable, as it directs the authors to strengthen their claims by providing empirical evidence. However, the comment could be more helpful if it suggested specific types of empirical evidence or methods for gathering such evidence. Despite this, the feedback is 4 as it provides a clear direction for improvement, allowing the authors to enhance the rigor and persuasiveness of their claims."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors do not provide a comprehensive discussion of previous work on the topic. However, it does not specify which aspects of the discussion are missing or what specific areas need to be addressed. The comment lacks explicit guidance on how the authors should expand their discussion or what specific details are missing. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of comprehensive discussion of previous work on the topic, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which section or aspect of the paper requires a more thorough discussion of prior work. This lack of specificity makes it difficult for the authors to address the feedback effectively. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors do not provide a comprehensive discussion of previous work on the topic. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the extent of the issue or how to address it. Without detailed examples or references, the claim is 1, as the authors cannot determine the basis for the criticism. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The comment identifies a significant gap in the paper by pointing out the lack of a comprehensive discussion of previous work on the topic. This feedback is valuable as it highlights an area where the authors could enhance the depth and context of their research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending specific areas of prior work to include or how to frame the discussion. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for improvement regarding the OT sample selection process described in section 2.4.3. It asks whether the process runs once or iteratively, whether the optimization of the loss in equation (10) and the solving of OT in equation (3) are conducted by turns iteratively, and suggests that adding more details and a flow chart would make it easier for readers to understand the process. Additionally, the comment questions the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment provides explicit questions and suggestions for improvement, it lacks concrete guidance on how to address these points or what specific actions the authors should take. The actions are implicit and require the authors to infer the necessary steps, making the comment 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses the OT sample selection process in section 2.4.3, making it fully grounded as it explicitly mentions the section being discussed. It also specifies what needs to be addressed, such as whether the process runs once or iteratively, the iterative nature of optimization and OT solving, and the runtime for solving the entropic regularized discrete OT problem and OT sample selection. This level of detail provides clear guidance on what the authors should consider and address, making the comment 5. Therefore, the comment aligns with a score of 5.", "verifiability_rationale": "The review point raises questions about the OT sample selection process, specifically whether it runs once or iteratively, and whether the optimization of the loss in equation (10) and the solving of OT in equation (3) are conducted by turns iteratively. It also asks for the runtime of solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment does not contain subjective opinions or claims, it poses questions that require clarification and detailed explanations. However, it lacks specific references or logical reasoning to support the need for these clarifications. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully substantiate the need for clarification.", "helpfulness_rationale": "The review comment raises several important questions and suggestions regarding the OT sample selection process described in section 2.4.3. It asks whether the process runs once or iteratively, whether the optimization of the loss in equation (10) and the solving of OT in equation (3) are conducted by turns iteratively, and suggests that adding more details and a flow chart would enhance the clarity of the process for readers. Additionally, it questions the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. These questions and suggestions provide valuable feedback that could help the authors improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided specific guidance on how to address these points or suggested additional details that would make the process easier to understand. Overall, the comment is 4 as it identifies areas for improvement and encourages the authors to enhance the clarity of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the experimental evaluation of the proposed method, specifically noting that while the authors discuss how KG handles continuous tasks, there are no experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7 of the appendix, and asks why these are not included in the experiments. The comment requests a comparison of the empirical performance of these methods with ConBO. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to include experiments with continuous tasks and compare the performance of entropy methods. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental evaluation of the proposed method, specifically noting the absence of experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7 of the appendix, and asks for a comparison of their empirical performance with ConBO. However, the comment does not specify which part of the paper discusses continuous tasks or entropy methods, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, the lack of grounding makes it challenging for the authors to understand which parts of the paper need revision. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the absence of experiments with continuous tasks and the lack of comparison of entropy methods for conditional optimization with ConBO. While the comment suggests that the authors should include these experiments and comparisons, it does not provide specific examples or references to support the claim that these elements are missing. The reasoning is somewhat vague, as it lacks detailed explanations or evidence to fully substantiate the claim. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a gap in the experimental evaluation of the proposed method, specifically noting the absence of experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization, derived in Section 7 of the appendix, and asks for a comparison of their empirical performance with ConBO. This feedback is 3 as it highlights specific areas where the authors could enhance their experiments and provide a clearer understanding of the method\"s performance. However, the comment could be more helpful if it offered suggestions on how to conduct these additional experiments or compare the methods. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment highlights a potential area of confusion for the authors, it does not provide explicit guidance on how to address this issue or what specific aspects need clarification. The action is implicit, as the authors are expected to infer that they need to provide a more detailed explanation of the difference between similarity and exit times. However, the comment lacks concrete details on how to achieve this clarification, making it 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not mention the specific section or part of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not provide any specific evidence, reasoning, or references to support the claim or the need for clarification. The comment lacks depth and does not offer a clear path for the authors to address the issue, making it 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the authors\" claim regarding unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment identifies a potential area of confusion for the authors, it does not provide specific guidance or suggestions on how to address this issue. The feedback is 3 as it highlights a point that needs clarification, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the limitations of the unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. It does not provide explicit instructions or suggestions on how the authors should address this question or what changes might be needed in their draft. The comment implies that the authors should consider discussing the limitations of their framework, but it lacks concrete guidance on how to do so. Therefore, the comment is not actionable, as it does not provide the authors with a clear path forward for improving their draft.", "grounding_specificity_rationale": "The comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its inquiry about the limitations of the framework, but the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not provide any specific reasoning, examples, or references to support the claim that the framework might not be applicable to these broader formulations. Without additional context or evidence, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. This question highlights a potential area for further exploration and clarification in the paper. However, the comment does not provide any specific suggestions or guidance on how the authors might address this limitation or expand their discussion. While it identifies an important aspect that could be improved, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, as it points out a potential area for improvement but does not offer detailed guidance on how to enhance the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider conducting experiments on other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a clear and explicit action for the authors to take, which is to expand their experiments to include more types of sentence pair tasks. This guidance is concrete and specific, allowing the authors to understand exactly what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitation in the experiments conducted by the authors, specifically noting that they only evaluate sentence similarity and open domain QA tasks. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the need for additional experiments on other sentence pair tasks, such as MNLI and RTE, which are common in the NLP field. This provides a clear direction for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited, as the authors only conduct evaluations on sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a logical reasoning by identifying the limitation in the scope of the experiments and suggesting specific tasks that could be included. However, it lacks specific examples or references to support the claim fully. Therefore, the comment is 3, as it provides a basis for improvement but could be strengthened with additional evidence or references.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experiments conducted by the authors, noting that they only evaluate sentence similarity and open domain QA tasks. It suggests that the authors should consider expanding their experiments to include other sentence pair tasks, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by conducting additional experiments. However, the comment could be more helpful if it included suggestions on how to implement these additional experiments or provided examples of relevant datasets. Overall, the comment is 4 as it offers valuable guidance for enhancing the scope and depth of the experiments."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the parameter S, suggesting that its setting is a problem. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps should be taken to resolve it. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the parameter S, suggesting that its setting is a problem. However, it does not specify which part of the paper discusses the parameter S or provide any context for why this is a concern. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what needs to be addressed or how the issue can be resolved. Therefore, this comment is 2, aligning with category 2.", "verifiability_rationale": "The review point raises a question about the parameter S, suggesting that its setting is a problem. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why setting the parameter S is problematic. This lack of support makes the comment difficult to verify and does not provide actionable guidance for the authors. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the parameter S, suggesting that its setting is a problem. However, it lacks specificity and does not provide any guidance or suggestions on how to address this issue. Without additional context or details, the authors are left without a clear understanding of what needs to be done to resolve the problem with parameter S. This comment is 2 as it points out a potential area for improvement but does not offer actionable advice or suggestions for the authors to consider. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While it implies that human evaluation is a good idea, it does not provide explicit instructions or guidance on how to conduct such an evaluation. The authors are left to infer that they should perform a human evaluation, but the comment lacks concrete details on how to implement this suggestion. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The comment is vague in terms of grounding, as the authors cannot confidently determine which part of the paper it addresses. Additionally, the comment is specific in its suggestion to use human evaluation, but without grounding, the authors are left to make an educated guess about where to apply this feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While the comment implies that human evaluation is a better approach, it does not provide specific reasoning or examples to support this claim. The lack of detailed justification or references makes it difficult for the authors to understand why this suggestion is valid. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. This feedback is valuable as it highlights a potential limitation of the current evaluation approach and suggests an alternative method that could provide more reliable results. However, the comment lacks specific guidance on how to conduct a human evaluation or what criteria should be used. While it identifies an important area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers a clear direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the triviality of the convergence proof, suggesting that it lacks substantial novelty and rigor. It provides a specific example of how the proof could be adapted by referencing a modification in the appendix. However, the comment does not explicitly instruct the authors to address this issue or provide detailed guidance on how to improve the proof. The action is implicit and somewhat vague, as the authors need to infer that they should consider revising the proof to enhance its novelty and rigor. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Triviality of Convergence Proof\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proof, explaining that it lacks substantial novelty and rigor due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The comment provides clear guidance on how the authors might address this issue by referencing a modification in the appendix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical proof for convergence is trivial, as it relies on the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The reviewer suggests that the proof lacks substantial novelty and rigor, and that it could be adapted with straightforward modifications. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it 3. The authors would need to infer the basis for the claim and seek additional evidence to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical proof of convergence, noting that it appears trivial due to the assumption that $X$ is i.i.d., which contradicts the claim that $Z$ is noni.i.d. The reviewer suggests that the proof lacks substantial novelty and rigor, and that it could be adapted with straightforward modifications. This feedback is clear and actionable, providing the authors with a specific area to address and improve their work. However, it could be more helpful if it included suggestions for enhancing the novelty or rigor of the proof. Overall, the comment is 4 as it highlights a critical issue and offers a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. The comment suggests that this should be mentioned clearly. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit, as the authors can infer that they need to clarify the experimental setup in the paper. The comment is 3 because it identifies a specific area that needs attention, but it lacks concrete details on how to implement the suggested change. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"The experimental setup borrowed from 2 is only semireal,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that multinode seed cascades are artificially created by merging singlenode seed cascades. This provides clear guidance on how the authors should improve their paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental setup is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This claim is supported by the statement itself, as it provides a clear explanation of the issue. However, the comment does not offer additional evidence or references to substantiate this claim further. While the reasoning is logical, the lack of detailed examples or external references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that it is only semireal because multinode seed cascades are artificially created by merging singlenode seed cascades. This observation is clear and provides a specific point for the authors to address in their paper. By highlighting this detail, the comment offers a constructive suggestion for improving the transparency and rigor of the experimental setup description. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific ways to enhance the clarity of the experimental setup. Overall, the comment is 4 as it identifies a meaningful aspect of the paper that needs attention, but it could be more comprehensive with additional suggestions or guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights specific limitations in the paper, such as the limited scope of bias benchmarks (gender, race, and religion) and the absence of assessments on stateoftheart generative models like GPT. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these limitations or suggest specific actions to take. The authors are left to infer that they need to expand their dataset and model evaluations to include more diverse biases and stateoftheart models. This lack of explicit and concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the limitations of the bias benchmarks used in the paper, specifically noting that they only assess gender, race, and religion. It also points out the absence of assessments on other important biases and datasets, as well as the lack of evaluation on stateoftheart generative models like GPT. However, the comment does not specify which part of the paper discusses the bias benchmarks or the models used, making it weakly grounded. The comment is specific in detailing the issues with the current evaluation, but without explicit references to sections or figures, the authors may need to infer the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are missing. It also notes the absence of assessments on stateoftheart generative models like GPT. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. Without detailed evidence or examples, the claim remains 3, as the authors may need to conduct further research to confirm the extent of the limitations. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, specifically the limited scope of bias benchmarks. It highlights that the current evaluation only considers gender, race, and religion, while other important biases and datasets are missing. Additionally, it points out the absence of assessments on stateoftheart generative models like GPT. This feedback is valuable as it directs the authors to expand the scope of their evaluation to include a more comprehensive set of biases and models. However, the comment could be more helpful if it provided specific examples of other biases or datasets that could be included, or suggested particular models to assess. Overall, the comment is 4 as it directs the authors to areas for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the description of the metrics used in the paper is limited and recommends providing an explanation of the metrics or citing the metrics. While the comment implies that the authors should include more details about the metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on how to expand the description or where to find the necessary information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the description of the metrics used in the paper is limited and recommends providing an explanation or citing the metrics. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific about the need for more detail on the metrics, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the description of the metrics is limited and suggests that the authors should provide an explanation or cite the metrics. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed examples or references, the claim is 3, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the description of the metrics used is limited. It suggests that the authors should provide an explanation of the metrics or cite the metrics to enhance the clarity and comprehensiveness of the paper. This feedback is actionable and provides a clear direction for the authors to improve their draft. However, the comment could be more helpful if it offered specific examples of how to explain or cite the metrics, making it more comprehensive. Overall, the comment is 4 as it highlights an important aspect of the paper that needs attention."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two main issues with the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment identifies these areas, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to motivate the applications and consider using streaming datasets. However, the lack of specific suggestions or examples makes the action vague and difficult to implement. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the paper\"s objective of designing fast label aggregation algorithms for a streaming setting, noting that it lacks motivation for the applications. It also points out that the empirical analysis uses static datasets, which limits the paper\"s usefulness. However, the comment does not specify which part of the paper discusses the motivation or the datasets used, making it weakly grounded. The comment is specific in identifying the issues with motivation and the use of static datasets, but without explicit references to sections or figures, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of fast label aggregation algorithms in a streaming setting and that the empirical analysis uses static datasets, limiting the paper\"s usefulness. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper: the lack of motivation for the applications of fast label aggregation algorithms in a streaming setting and the use of static datasets in the empirical analysis. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is 3 as it points out areas that need attention, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any explicit or implicit suggestions on how the authors might address this connection or incorporate it into their work. The comment lacks concrete guidance on how to improve the draft, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it questions the connection between the statement about the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. This provides clear guidance on what needs to be addressed in the introduction. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \"nice\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order4 tensors. While the comment identifies a potential area for clarification or further discussion, it does not provide specific suggestions or guidance on how the authors might address this connection. The feedback is 3 as it prompts the authors to consider the relevance of recent findings to their work, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. The comment also suggests that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, it does not specify which part of the paper should be revised or how the error analysis should be conducted. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues, and it encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. It also mentions that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, the comment does not specify which part of the paper should be revised or how the error analysis should be conducted, making it weakly grounded. The comment is specific in its suggestion to conduct error analysis and provide detailed explanations, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\"s performance under different scenarios. The comment implies that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, the claim lacks specific examples or references to support the assertion that error analysis is crucial or how it should be conducted. The reasoning is somewhat vague, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to enhance their paper by conducting error analysis. It emphasizes the importance of error analysis in evaluating model performance and identifying potential issues, which can guide subsequent improvements and expansions of the ERC research. The comment encourages the authors to provide detailed explanations of the model\"s performance under different scenarios, which is a valuable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to conduct the error analysis or what aspects of the model should be analyzed. Despite this, the feedback is 4 as it directs the authors towards a significant area for improvement, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue and suggests a direction for improvement, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 (a)\" and discusses the performance of the method with an increasing number of identities, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of performance degradation and suggests a potential solution by presetting the capacity to a small number. The comment provides clear guidance on how the authors might address the scalability issue, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the scalability of the method, noting that performance degrades as the number of identities increases. It suggests that the capacity should be preset to a small number, such as 10, and questions whether the authors have considered how to scale up without compromising performance. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that performance degrades with an increasing number of identities. The reasoning is somewhat vague, as it does not provide detailed evidence or guidance on how to address the scalability issue. Therefore, the claim is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a critical concern about the scalability of the method, noting that performance degrades as the number of identities increases. It provides a specific example from Table 3 (a) to illustrate this issue, suggesting that the capacity should be preset to a small number, such as 10. The comment also questions whether the authors have considered how to scale up without compromising performance, which is a valuable point for improvement. However, the comment could be more helpful by offering specific suggestions or guidance on how to address the scalability issue, such as exploring alternative methods or strategies for handling a larger number of identities. Overall, the comment is 3 as it identifies a significant weakness and prompts the authors to consider it, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a critical issue regarding the proposed method, which includes several complicated modules and more parameters than the baselines. It questions whether the main performance gain is due to a specific module or simply the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, it does not offer any explicit or implicit actions for the authors to take to address this issue. The authors are left without guidance on how to conduct a more thorough ablation study or what specific experiments to perform to clarify the source of the performance gain. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It highlights a critical issue regarding the source of the main performance gain, questioning whether it originates from a particular module or is merely due to the increased number of parameters. The comment also notes that the current ablation study does not provide definitive answers to these questions. However, the comment does not specify which part of the paper discusses the proposed method or the ablation study, making it weakly grounded. The comment is specific in identifying the issue with the ablation study, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the source of performance gains in the proposed method, specifically questioning whether the gains are due to a particular module or simply the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support the claim that the ablation study is insufficient. Without detailed reasoning or evidence, the claim remains 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed method, which includes several complicated modules and more parameters than the baselines. It questions whether the main performance gain is due to a specific module or simply the increased number of parameters, noting that the current ablation study does not provide definitive answers. This feedback is valuable as it highlights a critical gap in the analysis and encourages the authors to conduct a more thorough investigation into the source of the performance gains. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct the additional experiments or analysis needed to address this issue. Overall, the comment is 4, as it points out a crucial area for improvement but lacks detailed actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the robustness of MIA testing for privacy guarantees and recommends using ULiRA. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The comment suggests that the authors should consider using ULiRA, but it lacks detailed instructions or examples on how to implement this recommendation. As a result, the authors are left without a clear understanding of how to improve their draft based on this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of MIA (Membership Inference Attack) testing in the paper, specifically mentioning the robustness of MIA testing for privacy guarantees and recommending the use of ULiRA. However, it does not specify which part of the paper discusses MIA testing or how it is used. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. The comment is specific in detailing the issue with MIA testing and recommending the use of ULiRA, but without explicit grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effectiveness of MIA testing is not sufficiently robust for privacy guarantees and recommends using ULiRA. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to substantiate the assertion about the limitations of MIA testing. Without additional context or justification, the claim remains unsubstantiated, making the comment 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of MIA (Membership Inference Attack) testing as a metric for evaluating unlearning effectiveness, suggesting that it may not be sufficiently robust for privacy guarantees. It recommends using ULiRA, a specific tool, to address this concern. However, the comment lacks detailed guidance on how the authors should implement this recommendation or what specific changes they should make to their draft. While it points out a potential area for improvement, it does not provide actionable steps or examples, leaving the authors with limited direction on how to address the issue. Therefore, the comment is 3, as it highlights a concern but does not fully support the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the qualitative nature of explanations, minimal or missing descriptions of procedures in simulation or experimentbased evidence, confusing figures (e.g., \"sample count\" in Figure 2), and the lack of error bars or pvalues in statistical inferences. While the comment identifies these areas for improvement, it does not provide explicit instructions on how to address them. The authors are left to infer that they need to add more details, figures, and statistical measures, but the lack of concrete guidance makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses issues with the qualitative nature of explanations and the lack of detail in simulation or experimentbased evidence, specifically mentioning figures and statistical inferences. However, it does not specify which parts of the paper these issues are present in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as adding more details to the figures and including error bars or pvalues. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the explanations are qualitative and that the procedures for simulation or experimentbased evidence are minimally described. It also notes that some figures are confusing, specifically mentioning \"sample count\" in Figure 2, and suggests adding more details to the paper or supplementary information. The comment also criticizes the lack of error bars or pvalues in statistical inferences. While the comment identifies specific issues, it lacks detailed reasoning or references to support these claims, making it 3. The authors would need to infer the basis for these claims, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the qualitative nature of explanations, minimal or missing descriptions of procedures in simulation or experimentbased evidence, confusing figures, and the lack of error bars or pvalues in statistical inferences. While the comment provides a clear overview of these issues, it lacks specific guidance on how to address them. The authors are left to infer that they need to add more details, clarify figures, and include statistical measures, but the feedback is somewhat vague and could be more actionable. Therefore, the comment is 3, as it offers insights but requires further elaboration to be fully beneficial."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the generalizability of the specific examples of biases and prediction shifts presented in the paper. It points out that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment does not provide explicit guidance on how the authors should address this issue or what actions they should take to clarify the generalizability of their findings. The action is implicit and vague, as it does not specify how the authors can improve the clarity or provide more context on the generalizability of the examples. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific issues related to the clarity of the paper, particularly regarding the generalizability of the examples of biases and prediction shifts presented in section 3.2 and Theorem 1. It highlights that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment does not specify which part of the paper these examples are located in, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the generalizability of the examples, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the generalizability of the specific examples of biases and prediction shifts presented in the paper. It notes that while the paper demonstrates these biases, it does not explain how common or general these situations are. However, the comment does not provide any specific evidence, examples, or references to support the claim that the authors are unsure about the generalizability of these situations. Without additional context or justification, the claim remains 3, as it lacks detailed reasoning or supporting evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the generalizability of the examples of biases and prediction shifts presented in section 3.2 and Theorem 1. It points out that while the paper demonstrates these biases, it does not explain how common or general these situations are, leaving the authors unsure about the scope of these findings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the generalizability of their examples. Without actionable advice or additional context, the comment is 3 as it highlights a potential area for improvement but lacks depth and direction. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would have appreciated more datasets, particularly for the crosstask transferability aspect. However, it does not provide explicit guidance on which datasets to include or how to incorporate them into the paper. The action is implicit, as the authors need to infer that they should add more datasets to address the crosstask transferability. While the comment is 3, it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the authors would have appreciated more datasets, especially concerning the crosstask transferability aspect. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. The authors cannot confidently determine which part of the paper needs to be addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting the inclusion of more datasets for crosstask transferability, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors would have appreciated more datasets, particularly concerning the crosstask transferability aspect. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how it might impact their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors would have appreciated more datasets, especially concerning the crosstask transferability aspect. While this feedback provides a clear direction for improvement, it lacks specific guidance on which datasets to include or how to incorporate them into the paper. The comment is 3 as it identifies a potential area for enhancement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors have made any additional novel effort in the Sec. 3.1 for 3D Gaussians generation, noting that it seems to follow the previous work, Luciddreamer. While the comment implies that the authors should clarify the novelty of their approach, it does not explicitly instruct them to provide evidence or details about any additional contributions. The action is implicit and somewhat vague, as the authors are left to infer that they need to address the novelty of their work. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. However, it does not specify which part of the paper Sec. 3.1 corresponds to, making it weakly grounded. The comment is specific in its request for clarification regarding the novelty of the approach, but without explicit grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the Sec. 3.1 for 3D Gaussians generation follows the previous work, Luciddreamer, and asks for clarification on any additional novel effort. While the comment implies that the authors should address the novelty of their approach, it does not provide specific examples, references, or detailed reasoning to support the claim. The lack of explicit evidence or justification makes the claim 3, as the authors are left to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the novelty of the Sec. 3.1 for 3D Gaussians generation, noting that it appears to follow the previous work, Luciddreamer. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their approach. The feedback is 3 as it prompts the authors to consider the novelty of their work, but it lacks actionable advice or detailed suggestions, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks specific guidance on how to improve the tractability of MMD DRO or how to refine the upper bound. Therefore, the comment is 1, as it does not offer actionable steps for the authors to improve their draft.", "grounding_specificity_rationale": "The comment addresses the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1, specifically mentioning that MMD DRO does not have a tractable exact equivalent reformulation. It also highlights the crude nature of the upper bound due to the omission of the nonnegative constraint on the distribution and the need for further approximation. Additionally, the comment points out the restrictive assumption of the loss function belonging to the RKHS. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of explicit references to specific sections or parts of the paper makes the comment weakly grounded. While it provides some specificity by detailing the issues with the tractability and the upper bound, the absence of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises several concerns about the tractability of MMD DRO and the limitations of the upper bound in Theorem 3.1. It claims that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises several valid concerns about the tractability of MMD DRO and the limitations of the upper bound presented in Theorem 3.1. It highlights that MMD DRO does not have a tractable exact equivalent reformulation, which is a significant drawback. The comment also points out that the upper bound is crude due to the omission of the nonnegative constraint on the distribution and that further approximation is needed even for simple kernel ridge regression problems. Additionally, it notes that assuming the loss function belongs to the RKHS is restrictive, as the authors themselves pointed out. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve the tractability of MMD DRO or the upper bound. While it identifies important areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it provides some insight but lacks depth and guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the relevance of the framework in the context of nonconvex losses and nonnorm type defenses, as well as its applicability to binary classification scenarios where the true mean is known. It questions whether the framework remains relevant given the challenges of nonvanishing duality gaps and the difficulty of maximization over nonnorm type constraints. Additionally, it asks whether the framework can provide intuitions on the risk upper bound. The comment also suggests exploring the use of covariance or other statistics to design a better defense. However, it does not provide explicit guidance on how the authors should address these questions or incorporate them into their draft. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require attention and how to address them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the relevance of the framework in the context of nonconvex losses and nonnorm type defenses, specifically questioning its applicability given the challenges of nonvanishing duality gaps and the difficulty of maximization over nonnorm type constraints. It also asks about the relevance of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not specify which part of the paper these questions relate to, making it weakly grounded. The questions are specific and provide clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the relevance of the framework in the context of nonconvex losses and nonnorm type defenses, specifically questioning whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant. It also asks about the applicability of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The questions are openended and lack sufficient justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions about the relevance of the framework in the context of nonconvex losses and nonnorm type defenses, as well as its applicability to binary classification scenarios where the true mean is known. It questions whether the nonvanishing duality gap and the difficulty of maximization over nonnorm type constraints make the algorithm irrelevant, or if it could still provide some intuition on the risk upper bound. Additionally, it suggests exploring the use of covariance or other statistics to design a better defense. However, the comment lacks specific guidance on how the authors should address these questions or incorporate them into their draft. While it identifies areas for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it offers some insight but requires further elaboration to be fully beneficial."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about an action that could be taken with the baselines in Figure 3. It suggests sparsifying the trained models to reduce the number of selected features and comparing the accuracy to the proposed model. However, the comment does not provide explicit guidance on how to implement this action or what specific steps the authors should take. While the suggestion is clear and concrete, the lack of explicit instructions on how to execute it leaves the authors with a general idea of what to do but no detailed guidance. Therefore, the comment is 4, as it provides a clear direction but lacks specific implementation details.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests an action to be taken with the baselines on the lefthand side of the figure, specifically sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about an action that could be taken with the baselines in Figure 3, specifically suggesting sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, the comment does not provide any justification or reasoning for why this action is relevant or beneficial. It lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about an action that could be taken with the baselines in Figure 3. It suggests sparsifying the trained models to reduce the number of selected features and comparing accuracy to the proposed model. This feedback is actionable as it provides a clear direction for the authors to consider and potentially implement. However, the comment lacks depth and does not offer additional insights or suggestions on how to approach this action or what specific results might be expected. While it is 3, it could be more beneficial with additional guidance or context. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the paper\"s clarity and reproducibility. It suggests that while the paper provides an intuitive understanding, it lacks the necessary technical details for reproduction, such as specifics about the RNN implementation. However, the comment does not explicitly instruct the authors to include these details or provide guidance on how to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the need for additional details. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper being written to provide an intuitive understanding but lacking details for reproduction, specifically mentioning the need for technical details like RNN implementation parameters. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what is missing in terms of technical details required for reproducibility. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is written to provide an intuitive understanding but lacks details for reproduction, such as specific technical details like RNN implementation parameters. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it is based on an observation but lacks sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s clarity and reproducibility. It points out that while the paper provides an intuitive understanding, it lacks the necessary technical details for reproduction, such as specifics about the RNN implementation, including the number of units. This feedback is clear and actionable, as it directs the authors to include additional details to enhance the paper\"s reproducibility. However, the comment could be more helpful if it provided specific examples or guidance on what kind of technical details are needed. Overall, the comment is 4, as it effectively highlights a critical area for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Figure 1 would be stronger if it included error bars and more random trials to potentially eliminate random fluctuations in the results. While the comment provides explicit guidance on what should be added to the figure, it does not specify how to implement these changes or where to add them. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests improvements to Figure 1, specifically mentioning the need for error bars and more random trials to address potential random fluctuations. However, it does not specify which part of the paper Figure 1 is located in, making it weakly grounded. The comment is specific in detailing what needs to be addressed to enhance the figure, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that Figure 1 would be stronger with error bars and more random trials to address potential random fluctuations. However, it does not provide any specific reasoning or evidence to support why these changes would be beneficial or how they would impact the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific suggestions for improving Figure 1, such as adding error bars and conducting more random trials to address potential random fluctuations in the results. These suggestions are actionable and directly address a potential weakness in the presentation of the data. By offering concrete improvements, the comment empowers the authors to enhance the clarity and robustness of their findings. However, the comment could be more helpful if it included additional guidance on how to implement these suggestions or why these changes are expected to improve the results. Overall, the comment is 4 as it provides clear directions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. It also points out that Figure 1 lacks clarity regarding the correspondence of different learning rates and steps to the points in the graph. This feedback provides clear guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment suggests providing a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. However, it does not specify which part of the related work section this introduction should be included in, making it weakly grounded. The comment also points out a lack of clarity in Figure 1, but it does not specify which part of the figure is unclear, making it weakly grounded. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should provide a brief introduction to energy models in the related work section, which is a specific and actionable suggestion. However, it does not provide any reasoning or evidence to support why this suggestion is necessary or beneficial. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient support.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the draft, such as adding a brief introduction to energy models in the related work section and clarifying the correspondence of different learning rates and steps in Figure 1. These suggestions are actionable and directly address potential weaknesses in the paper, offering clear guidance for the authors to enhance their work. However, the comment could be more helpful if it included additional details or examples to further clarify the issues. Overall, the feedback is 4, as it provides a solid foundation for improvement but could be more comprehensive."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the model need to be clarified. The comment lacks concrete guidance on how the authors can improve the draft to address this concern. As a result, the authors are left without a clear understanding of what actions to take to enhance the paper. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment does not provide specific guidance or suggestions on how to address the issue of novelty or testability. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any specific evidence, reasoning, or references to support the claim that the model could generate novel knowledge or testable hypotheses. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. This is a valid concern that could impact the paper\"s contribution and impact. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what aspects of the model need clarification. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is 3, as it identifies a potential weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, it does not provide explicit guidance on how to simplify the theorem or what aspects should be emphasized. The action is implicit, as the authors would need to infer that they should simplify the theorem, but it lacks concrete details on how to achieve this. Therefore, the comment is 3, as it provides a direction but not a detailed path for implementation.", "grounding_specificity_rationale": "The comment suggests presenting a simplified version of Theorem 2 for the general audience, implying that the authors should consider making it more accessible. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. The comment is specific in its suggestion but lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, the comment does not provide any specific reasoning, examples, or references to support why this simplification would be beneficial or how it could be achieved. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of Theorem 2, suggesting that it might be difficult for the general audience to understand. It proposes an idea to present a simplified version of the theorem, which could enhance its accessibility. However, the comment lacks specific guidance on how to simplify the theorem or what aspects should be emphasized. While it provides a direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a potential area for enhancement but does not fully address the authors\" needs for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide explicit guidance on how the authors should revise their method or what specific changes to make. The action is implicit, as the authors need to infer that they should reconsider their approach and potentially implement the suggested alternative. While the action is somewhat concrete, it lacks detailed instructions on how to apply it, making the comment 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"KeyQN section\" and the specific question about the calculation of the averaged feature vector. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what the authors should consider regarding the calculation of the averaged feature vector, questioning the current approach and suggesting an alternative. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the approach used in the KeyQN section regarding the calculation of the averaged feature vector, specifically questioning whether it is correct to just multiply each feature map elementwise by H_psi. While the comment raises a valid concern about the method\"s accuracy, it does not provide any supporting evidence, examples, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a specific question about the calculation of the averaged feature vector in the KeyQN section, questioning whether it is correct to simply multiply each feature map elementwise by H_psi. This feedback is 3 as it identifies a potential issue with the methodology and prompts the authors to reconsider their approach. However, the comment lacks detailed guidance or suggestions on how the authors might address this concern or what alternative methods they could consider. Without more specific advice or examples, the authors may find it challenging to fully understand and address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should make the different curves in Figure 2 more distinguishable by using styles like dashed lines or adding color. This provides a clear and explicit action for the authors to take, as they know exactly how to improve the figure. The comment is specific and concrete, giving detailed guidance on how to implement the suggested changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2 right,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the figure by suggesting the use of styles like dashed lines or adding color. This feedback is detailed and actionable, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Figure 2 right is difficult to distinguish between different curves and recommends using styles like dashed lines or adding color. This is a subjective observation and suggestion for improvement, but it lacks specific reasoning or examples to support why these changes would be beneficial. Without additional context or evidence, the claim is 3, as it provides a suggestion but does not fully explain its relevance or impact. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that it is difficult to distinguish between different curves. It provides a clear suggestion for improvement by recommending the use of styles like dashed lines or adding color to enhance the figure\"s clarity. This feedback is actionable and directly addresses a potential weakness in the presentation of the data, offering a concrete way for the authors to improve the figure. However, the comment could be more helpful if it included additional suggestions or considerations for other aspects of the figure. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. It recommends toning down the introduction and suggesting that the task is more accurately described as a feedbackdriven QA in the form of a dialog. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to tone down the introduction or provide specific examples of what should be included. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the claims made in the introduction, suggesting that they are not aligned with the tasks and models described. It recommends toning down the introduction and suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment does not specify which part of the introduction is being referred to, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the claims made in the introduction are not aligned with the tasks and models described, specifically noting that the authors call the task \"language learning\" while evaluating on question answering. The comment suggests that the task is more accurately described as a feedbackdriven QA in the form of a dialog. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the claims made in the introduction, noting that they are not aligned with the tasks and models described. The authors are called to tone down the introduction and suggest that the task is more accurately described as a feedbackdriven questionanswering in the form of a dialog. This feedback is clear and actionable, providing the authors with a specific direction for revising their introduction to better reflect the actual content of the paper. However, the comment could be more helpful if it included suggestions for specific changes or examples of how to revise the introduction. Overall, the comment is 4, as it provides a clear and actionable critique that guides the authors in improving their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper by suggesting that the lower bound results for round complexity in batched ranking problems are not novel, as they follow easily from existing collaborative ranking results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to make the results more impactful. The action is implicit, as the authors are left to infer that they should consider expanding the discussion or providing a more detailed analysis to differentiate their work from existing results. The comment is 3 because it identifies a potential area for improvement, but it lacks concrete steps or suggestions on how to achieve this. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"proving lower bounds for round complexity\" and \"batched ranking problems,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper exploits an easy reduction from collaborative ranking, making the lower bound results follow as an easy corollary. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that proving lower bounds for round complexity is a major part of work in batched ranking problems, but the paper exploits an easy reduction from collaborative ranking, making the lower bound results follow as an easy corollary. This claim is 3 as it provides a logical reasoning for why the results might not be novel. However, it lacks specific examples or references to support the claim fully, which could make it difficult for the authors to understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by suggesting that the lower bound results for round complexity in batched ranking problems are not novel, as they follow easily from existing collaborative ranking results. This observation highlights a gap in the paper\"s contribution and provides a clear direction for the authors to consider expanding their discussion or providing a more detailed analysis to differentiate their work from existing results. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue, such as suggesting additional experiments or analyses to strengthen the novelty of their findings. Overall, the comment is 3 as it points out a potential area for improvement but lacks detailed actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not provide specific guidance on how to implement these suggestions or what aspects of the prompting technique need to be improved. The action is implicit and vague, as the authors are left to infer that they should explore more sophisticated prompting techniques. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or where the authors should focus their attention. This lack of grounding makes it difficult for the authors to understand which section or aspect of the paper needs improvement. Additionally, the comment is specific in its suggestion to use carefully curated prompts, but without clear guidance on how to implement this suggestion, it remains somewhat specific. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of LLMs. It suggests that carefully curated prompts could yield better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is considered 2, as it provides a general observation but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and does not fully leverage the capabilities of LLMs. It suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the prompting technique need improvement. While it highlights an area for potential enhancement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial, but acknowledges that computational resources might be a constraint. It also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. The comment is explicit in suggesting additional experiments, which provides a clear action for the authors to take. However, it lacks specific guidance on which datasets or types of experiments to conduct, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests additional experiments on larger datasets, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper these experiments relate to, making it weakly grounded. The comment is specific in suggesting that maintaining probabilities might become an issue at large batch sizes, but it does not provide detailed guidance on how to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional experiments on larger datasets would be beneficial, but acknowledges the potential issue of computational resources. It also expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. The comment is 3 as it provides a rationale for the suggestion, but it lacks specific examples or references to support the claim about the potential issues with maintaining probabilities at large batch sizes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that additional experiments on larger datasets would be beneficial, which is a valuable piece of feedback for improving the paper. However, the comment also acknowledges the potential issue of computational resources, which is a practical consideration for the authors. The reviewer expresses a preference for maintaining probabilities, particularly at large batch sizes, but deems this aspect not critical. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific suggestions or guidance on how to conduct these additional experiments or address the computational concerns. Overall, the comment is 3 as it identifies an area for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific examples of how the performance of the models in Table 4 is behind more recent models, citing GLaMM and UNINEXT. However, it does not offer any explicit or implicit suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of how the performance of the models in Table 4 is behind more recent models, citing specific models and their performance metrics. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of how these models perform compared to the current models. The claim is supported by the inclusion of references to GLaMM and UNINEXT, which provide specific performance metrics. This level of detail and evidence makes the claim 5, as it provides a clear basis for comparison and highlights areas for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of the models in Table 4, noting that they are behind more recent models. It provides concrete examples of how these models perform, referencing GLaMM and UNINEXT, which achieve higher performance metrics. This feedback is valuable as it highlights a clear area for improvement and provides specific examples for the authors to consider. However, the comment could be more helpful if it offered suggestions on how the authors might address this performance gap or what steps they could take to improve their models. Despite this, the comment is 4 as it directs the authors to areas that need attention and provides a basis for further discussion. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on framewise SDSA, similar to ConsiStory, with the main difference being the mask source. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or enhance the novelty of their approach. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning that it relies on framewise SDSA, similar to ConsiStory, with the main difference being the mask source. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure being addressed. The comment is specific in detailing the issue of limited novelty but lacks grounding as it does not provide explicit references to the paper sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the innovation of the proposed video storyboarding approach is limited, as it primarily relies on framewise SDSA, similar to ConsiStory, with the main difference being the mask source. The comment provides a specific example of a similar approach, suggesting that the novelty is limited. However, it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the basis of the claim, which makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on framewise SDSA, similar to ConsiStory, with the main difference being the mask source. While the comment highlights this limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it points out a weakness but lacks depth and direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the method\"s weakness might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on fewshot classification using such a dataset. However, the comment does not provide explicit guidance on how the authors should address this weakness or what specific steps they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors should conduct the comparison or what data they should use. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or figure that needs attention. Additionally, the comment does not provide specific guidance on how to address this issue or what changes should be made to the method. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the weakness of the method might be more prominent in images with multiple objects or cluttered scenes. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method, suggesting that it might be more prominent in images with multiple objects or cluttered scenes. It proposes an interesting comparison to previous approaches on fewshot classification using such a dataset. However, the comment lacks specific guidance on how the authors should address this weakness or what steps they should take to improve their draft. While it provides a direction for further exploration, it does not offer detailed suggestions or actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, it does not provide explicit guidance on how the authors should address this point or what changes might be needed in their draft. The action is implicit, as the authors would need to infer that they should consider the efficiency of their implementation or provide a rationale for their choice of framework. The comment lacks concrete details on how to implement or address this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Kernels are implemented with OpenAI\"s Triton, not CUDA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, noting that a fullpage explanation is unnecessary due to wellknown engineering improvements. This provides the authors with a clear understanding of what needs to be addressed in the draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. However, the comment lacks specific references or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this is a valid point or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the implementation of kernels using OpenAI\"s Triton, rather than CUDA, is unnecessary due to wellknown engineering improvements. This feedback is 3 as it identifies a potential area for simplification or clarification in the draft. However, it lacks specific guidance on how the authors might address this issue or what changes could be made to improve the draft. The comment provides a clear observation but does not offer actionable suggestions or detailed reasoning, which limits its overall impact on the authors. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the zeroshot nature of the experiment and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides examples of tasks that could be used to provide more information about the target task. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the zeroshot nature of the experiment and the transferability of the policy. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the zeroshot nature of the experiment and questions the transferability of the policy due to the difficulty of the source and target tasks. It provides examples of tasks that could be used to provide more information about the target task, such as the 3prong and 4prong tasks. However, the comment does not explicitly mention specific sections or parts of the paper that need to be addressed, making it weakly grounded. The comment is specific in detailing the issues with the zeroshot nature and the potential limitations of policy transfer, but without explicit references, the authors may need to infer which parts of the paper to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the zeroshot nature of the experiment and suggests that the transferability of the policy might be limited due to the difficulty of the source and target tasks. It provides examples of tasks, such as the 3prong and 4prong tasks, to illustrate the potential limitations. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. The authors are left to infer the basis for these claims, which makes the comment 3. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the zeroshot nature of the experiment and questions the transferability of the policy due to the difficulty of the source and target tasks. It provides examples of tasks, such as the 3prong and 4prong tasks, to illustrate the potential limitations. However, the comment lacks specific guidance on how the authors might address these issues or what additional experiments could be conducted to clarify the transferability. While it identifies a potential weakness, it does not offer detailed suggestions or actionable steps for improvement, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the relative gains of the proposed method, suggesting that it might be easy to improve a relatively small backbone due to its smaller receptive field. It also raises a question about whether the proposed method still works well on larger backbone models like SwinB or SwinL. While the comment identifies a potential issue with the method\"s effectiveness on larger backbones, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to investigate or improve the method. The suggestion is implicit and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the relative gains of the proposed method across different frameworks and tasks, noting that the gains are not very strong. It specifically mentions that the proposed methods achieve only about 1% gain on a relatively small backbone ResNet50. The comment also raises a question about whether the proposed method works well on larger backbone models like SwinB or SwinL. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issue with the relative gains and the question about larger backbones. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the relative gains of the proposed method are not very strong, particularly when compared to the baselines. It suggests that the proposed method might be easier to improve on smaller backbones due to their smaller receptive field, and questions whether it still works well on larger backbone models like SwinB or SwinL. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the reasoning or understand the basis of the critique. The absence of detailed evidence or logical reasoning weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the relative gains of the proposed method, noting that it is not very strong compared to the baselines. It also raises a question about the method\"s effectiveness on larger backbone models like SwinB or SwinL, suggesting that the smaller receptive field of these backbones might make it easier to improve. While the comment highlights an area for further investigation, it does not provide specific guidance or suggestions on how to address this issue or what experiments could be conducted to explore the method\"s performance on larger backbones. The feedback is 3 as it points out a potential limitation and encourages further exploration, but it lacks detailed actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the analysis of neural networks, suggesting that it contributes less due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. It mentions specific sections (3.2 and 3.3) where this issue is discussed. However, the comment does not provide explicit guidance on how the authors might address this issue or improve their analysis. While it identifies a potential area for enhancement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it highlights a specific area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the analysis of neural networks, noting that the extension from linear models to wide fullyconnected neural networks is trivial due to the existing NTK theorem. This provides a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of neural networks contributes less due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. While the comment provides a logical reasoning based on the existing theorem, it lacks specific examples or references to support the claim fully. The authors could benefit from additional evidence or examples to strengthen the argument. Therefore, the comment is 3, as it provides a basis for the claim but requires more detailed support to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific area of the paper where the analysis of neural networks is considered less significant due to the triviality of extending from linear models to wide fullyconnected neural networks, given the existing NTK theorem. It points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fullyconnected neural networks. This feedback is 3 as it highlights a potential limitation in the analysis and suggests that the authors might need to reconsider the scope or depth of their analysis to address this issue. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors could enhance their analysis to address this concern. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. It also mentions that the authors have provided an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the comment does not explicitly instruct the authors to add more datasets or provide additional details on their selection process. While the suggestion is clear, it lacks concrete guidance on how to address the issue, such as proposing specific datasets or methods for evaluation. Therefore, the comment is 3, as it identifies a potential improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of dataset size and the number of datasets used for the tasks, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern about the sufficiency of the datasets for rigorous evaluation, particularly when some datasets are too large for all algorithms. The comment provides clear guidance on the issue and suggests that the authors have addressed it by providing an addendum clarifying the novelty of the datasets and the motivations for their choice. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, especially if some datasets are too large for all algorithms. The comment suggests that the authors have addressed this concern by providing an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion about the sufficiency of the datasets. While the authors\" response is acknowledged, the initial claim remains 3 due to the lack of detailed justification or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the number of datasets used for the tasks, suggesting that it might be insufficient for a rigorous evaluation, especially if some datasets are too large for all algorithms. It acknowledges the authors\" response, which includes an addendum clarifying the novelty of the datasets and the motivations for their choice. This feedback provides a clear point for improvement, suggesting that the authors should consider adding more datasets or providing additional details on their selection process to enhance the rigor of their evaluation. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address the issue, such as proposing additional datasets or methods for evaluation. Overall, the comment is 3 as it highlights a potential area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework. It points out a discrepancy in the terminology used (\"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction). However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the terminology used in these sections. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the multifidelity framework and sequential design for learning quantities of interest, referencing a specific paper (Stroh et al. 2017). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework, pointing out a discrepancy in terminology. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract and introduction use inconsistent terminology regarding the cost of the multifidelity framework, specifically mentioning \"relatively inexpensive\" in the abstract and \"expensive to evaluate\" in the introduction. While the comment identifies a potential issue with clarity, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the inconsistency, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the abstract and introduction regarding the cost of the multifidelity framework. It points out a discrepancy in terminology, noting that the abstract uses \"relatively inexpensive\" while the introduction uses \"expensive to evaluate.\" This feedback highlights a need for the authors to clarify their terminology to avoid confusion. However, the comment lacks specific suggestions or guidance on how to address this issue, such as providing examples or rephrasing the terms to ensure consistency. While it points out a potential area for improvement, the feedback is 3 as it directs the authors\" attention to a specific issue that could impact the clarity of their work. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment does not provide explicit guidance on how the authors should address these questions or improve their method. The action is implicit and vague, as it does not specify what changes or actions the authors should take to clarify or improve their work. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about how the proposed method addresses sparse reward problems, suggesting that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to identify the exact section being addressed. While the comment is specific about the issue of sparse rewards, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the proposed method is similar to dense reward signals or that Qmix could solve sparsereward tasks. Without these elements, the claim is difficult to verify, making the comment 2.", "helpfulness_rationale": "The review comment raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparsereward tasks. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their method. It does not provide actionable feedback or detailed insights that would help the authors enhance their work. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer concrete steps or advice for the authors to take."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. While the comment identifies a potential issue and suggests a clarification, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the dataset usage and compare training conditions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. However, the comment does not specify which part of the paper discusses the dataset or the training process, making it difficult for the authors to pinpoint the exact section that needs clarification. While the comment is specific about the issue of dataset usage and comparison, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. However, the comment does not provide any evidence, reasoning, or references to support the claim that the dataset usage is unclear or that the comparison is unfair. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the clarity of the use of the curated AH36M dataset for training. It questions whether the dataset is used for training and whether other methods, such as HMR and SPIN, have access to the same data during training, which could affect the fairness of the comparison. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or what changes could be made to ensure a fair comparison. The feedback is 3 as it highlights an important aspect of the methodology that needs clarification, but it lacks actionable advice for the authors to improve their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network in the model, the fairness of the experimental comparisons, and the size of the proposed model compared to others. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how to clarify the motivation, ensure fair comparisons, or justify the model\"s size. As a result, the authors are left without a clear path to improve their draft, making the comment 1.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the motivation for using an adversarial network, the fairness of experimental comparisons, and the size of the proposed model. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to identify the exact sections that need attention. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not detail what needs to be addressed to improve the motivation, fairness, or model size. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the clarity of the motivation for using an adversarial network, the fairness of experimental comparisons, and the size of the proposed model. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of these concerns and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically regarding the clarity of the motivation for using an adversarial network, the fairness of the experimental comparisons, and the size of the proposed model. However, the comment lacks specific suggestions or guidance on how to address these issues. While it points out potential weaknesses, it does not provide actionable steps or detailed feedback that would help the authors enhance their work. As a result, the comment is 3, as it highlights areas for improvement but does not offer comprehensive guidance for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the reliability of the experimental results, specifically noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to verify the results, what steps to take to improve the reliability of the findings, or how to address the discrepancy between MSE and MAE. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the experimental results, noting that the MSE is significantly smaller than the MAE, which raises concerns about their validity. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are unreliable, particularly in Table 1, where the MSE is significantly smaller than the MAE, raising concerns about their validity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand why the results are considered unreliable or how to address the discrepancy between MSE and MAE. Therefore, the comment is 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. This feedback is clear and actionable, as it highlights a potential problem with the experimental findings that the authors should investigate and address. However, the comment could be more helpful if it provided suggestions on how to verify the results or what steps to take to improve the reliability of the findings. Despite this, the comment offers valuable insight into an area that needs attention, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of novelty in the methodology, suggesting that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their methodology or what specific aspects need to be improved to differentiate their approach from existing methods. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It is also not specific because it does not detail what aspects of the methodology lack novelty or how the proposed metaalgorithm is a direct extension of existing methods. Without specific references or detailed explanations, the authors cannot effectively address the feedback. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that there is not much novelty in the methodology, suggesting that the proposed metaalgorithm is a direct extension of existing methods. However, the comment lacks specific examples or references to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out the lack of novelty in the methodology, specifically noting that the proposed metaalgorithm is a direct extension of existing methods. While this feedback highlights an area for improvement, it does not provide specific suggestions or guidance on how the authors might enhance the novelty of their approach. The comment is 3 as it directs the authors to consider the novelty of their methodology, but it lacks actionable advice on how to address this issue. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to others. It suggests that the authors should provide an analysis for the inferior results, as they contradict the motivation. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it lacks concrete guidance, making it 3.", "grounding_specificity_rationale": "The comment addresses the issue of limited comparisons and inconsistent performance, suggesting that the authors should provide an analysis for the inferior results. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the results section. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the performance comparison, the absence of grounding information makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. This claim is supported by the observation that the results violate the motivation. However, the comment lacks specific examples or detailed reasoning to substantiate the claim fully. While it provides a general observation, it does not offer detailed evidence or references to support the claim comprehensively. Therefore, the comment is 3, as it provides some justification but lacks depth and specificity.", "helpfulness_rationale": "The review comment identifies a significant issue with the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to other methods. It highlights that the results do not align with the motivation, suggesting that the authors should provide an analysis for the inferior results. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work. However, the comment could be more helpful if it provided specific guidance on how to conduct the analysis or what aspects of the results to focus on. Overall, the comment is 4, as it offers valuable insights and directions for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, especially concerning occupant comfort and energy efficiency. While the comment identifies a specific area that needs more attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they need to expand on this aspect, but the comment lacks concrete suggestions or detailed instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be covered, namely the types of activities and their importance in smart homes. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a gap in the paper by noting that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. This feedback is 3 as it highlights a specific area that needs improvement, but it lacks detailed guidance on how the authors might address this gap. The comment provides a clear direction for the authors to expand their discussion, but it does not offer specific suggestions or examples of how to incorporate this information into the paper. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. It recommends using different notation to avoid this ambiguity. The comment is explicit in identifying the issue and provides a clear suggestion for improvement. However, it does not specify which parts of the paper use \"D\" for both purposes or how the authors should implement the change. While the action is clear, the lack of specific guidance on implementation makes it 3.", "grounding_specificity_rationale": "The comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, it does not specify which part of the paper uses \"D\" for both purposes, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its suggestion to use different notation, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this confusion could arise or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the symbol \"D\" in the paper, suggesting that it might be confusing as it represents both the dimensionality of points and the dilation factor. This feedback is clear and actionable, as it points out a specific area where clarity could be improved. However, the comment does not provide detailed guidance on how the authors might address this issue or suggest alternative notations. While it offers a valuable suggestion, the lack of comprehensive guidance limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the clarity of the concept of \"state\" in the paper, suggesting that it is represented by the \"grid status\" and obtained after applying an action. It also asks whether the term \"elements\" is equivalent to \"states\" or \"actions,\" implying that more elaboration is needed. While the comment explicitly states the need for clarification, it does not provide specific guidance on how the authors should elaborate on the concept or the relationship between \"elements,\" \"states,\" and \"actions.\" The action is clear but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the concept of \"state\" in the paper, specifically questioning its clarity and providing examples of how it is represented. It references specific lines (186187) to pinpoint the part of the paper being discussed. However, it does not specify what needs to be addressed in terms of elaborating on the concept or providing more context. The comment is fully grounded as it mentions specific lines, but it is underspecific because it does not detail what needs to be addressed. Therefore, this comment is categorized as 4, aligning with category 4.", "verifiability_rationale": "The review point questions the clarity of the concept of \"state\" in the paper, specifically asking whether \"elements\" are equivalent to \"states\" or \"actions.\" This is a subjective question that requires clarification and does not present a claim that needs verification. The comment is factual and descriptive, aligning with the classification of \"X.\"", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the concept of \"state\" in the paper, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" This feedback is 3 as it highlights a specific area that needs clarification, which can guide the authors in improving the consistency and understanding of their terminology. However, the comment lacks depth and does not provide detailed suggestions or guidance on how to elaborate on the concept or address the ambiguity. As a result, it is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be clarified or improved. As a result, the authors are left without a clear understanding of how to proceed with the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its critique, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the theoretical comparisons to adaptive learning of GPRGNN are not clear. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a lack of clarity in the theoretical comparisons to adaptive learning of GPRGNN. However, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it identifies a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\"s comprehension of object presence. However, it does not provide explicit guidance on how the authors should address this issue or what alternative methods could be used. The comment implies that the authors should consider expanding their evaluation to include more nuanced measures, but it lacks concrete suggestions or detailed instructions on how to implement this. As a result, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\"s comprehension of object presence. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the measurement method, the absence of explicit grounding limits its effectiveness. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the sufficiency of measuring object hallucination through only yes/no responses, suggesting that this approach may not accurately reflect the model\"s comprehension of object presence. The comment implies that a yes response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects when undertaking other tasks. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to provide more detailed reasoning or evidence to fully understand the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the sufficiency of measuring object hallucination through only yes/no responses. It points out that a positive response does not necessarily indicate that the model comprehends the presence of the object in the image, as it may still produce incorrect objects in other tasks. This feedback is 3 as it highlights a potential limitation in the evaluation method, suggesting that the authors should consider expanding their evaluation to include more nuanced measures. However, the comment could be more helpful if it provided specific suggestions or examples of alternative evaluation methods that could address this issue. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to provide context for the results. While the comment provides explicit guidance on what actions to take\u2014improving the discussion and conducting additional experiments\u2014the instructions for implementation are somewhat vague. The authors know that they need to improve the discussion and conduct more experiments, but they may not be entirely clear on the specific steps to take to achieve this. Therefore, the comment is 4, as it provides a clear direction but lacks detailed guidance on how to implement the suggestions.", "grounding_specificity_rationale": "The comment suggests that the verylongterm forecasting task is of limited practical significance and recommends improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon to put the results in a proper context. However, the comment does not specify which part of the paper discusses the verylongterm forecasting task or which sections or figures are being referred to. This lack of grounding makes it difficult for the authors to identify the specific part of the paper that needs improvement. While the comment is specific about the actions to be taken, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the verylongterm forecasting task is of limited practical significance and suggests improving the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the limited practical significance of the task. The suggestion to conduct experiments on more datasets and train baseline models with the correct forecast horizon is 3, as it offers a clear direction for improvement. However, the lack of detailed examples or references makes the claim 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the practical significance of the verylongterm forecasting task and suggests improvements to the discussion by conducting experiments on more datasets and training baseline models with the \"correct\" forecast horizon. This feedback is 3 as it provides a clear direction for enhancing the paper\"s discussion and context. However, it lacks depth and specificity, as it does not elaborate on the specific datasets or the rationale for choosing the \"correct\" forecast horizon. The comment could be more helpful if it provided more detailed guidance or examples to help the authors improve their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific area where the authors should provide more detail, namely the experiments and explanation regarding the different queries used in spatiotemporal representation. It explicitly mentions the need for experiments and explanations for spatial, temporal, and summary queries, as well as the comparison with VideoChatGPT and other works. However, it does not provide any guidance on how to conduct these experiments or what specific aspects of the queries should be explored. The action is implicit, as the authors need to infer that they should add these components to their draft. While the action is somewhat vague, it is clear that the authors need to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments  Ablation,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of experiments and explanation regarding the different queries used in spatiotemporal representation, including spatial, temporal, and summary queries. The comment also poses a question about what would happen if only spatial, temporal, or summary queries were used, which provides a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments and explanation regarding the different queries used in spatiotemporal representation are missing. It suggests that the authors should include experiments and explanations for spatial, temporal, and summary queries, as these are key differences to VideoChatGPT and other works. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. While the authors can infer that the claim is valid, the lack of detailed justification makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors\" draft could be improved by including experiments and explanations regarding the different queries used in spatiotemporal representation. It highlights the importance of these queries, particularly spatial, temporal, and summary ones, in comparison to works like VideoChatGPT. The comment poses a question about what would happen if only one type of query were used, which encourages the authors to explore the impact of each query type. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects of the queries should be explored. Despite this, the feedback is clear and actionable, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not provide explicit guidance on how to detail the innovative aspects or what specific aspects need to be elaborated upon. The action is implicit and vague, as the authors are left to infer that they need to provide more details on the innovative aspects of the FRM. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not specify which part of the paper this comment is addressing, such as a specific section or figure. The comment is vague and does not provide detailed guidance on what needs to be detailed or how to elaborate on the innovative aspects. As a result, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity in terms of what aspects of the FRM are innovative and require detailed explanation. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspects should be detailed. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the FRM is a simple combination of these attention mechanisms. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed FRM, suggesting that it is a simple combination of channel attention and spatial attention. It implies that the innovative aspects of the FRM should be detailed. However, the comment lacks specificity and does not provide concrete suggestions or guidance on how to elaborate on the innovative aspects. Without additional details or examples, the authors may struggle to understand what specific aspects need to be detailed or how to improve the presentation of the FRM. Therefore, the comment is 2, as it provides a general observation but lacks actionable feedback."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the authors\" claim regarding the lack of negative social impact of their work. It suggests that the authors might not be reviewing this aspect correctly and recommends mentioning the social impact of increased automation or the risks from the dual use of their method. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the societal impact of the work, specifically questioning the authors\" claim that there are no negative social impacts. It suggests that the authors might not be reviewing this aspect correctly and recommends discussing the social impact of increased automation or the risks from the dual use of their method. However, the comment does not specify which part of the paper discusses the societal impact, making it weakly grounded. It is specific in suggesting what the authors could include, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the authors\" claim regarding the lack of negative social impact of their work. It suggests that the authors might not be reviewing this aspect correctly and recommends mentioning the social impact of increased automation or the risks from the dual use of their method. However, the comment lacks specific examples or references to support the claim that the authors are overlooking these potential impacts. Without detailed reasoning or evidence, the claim remains 3, as it is based on the authors\" own assertion without further substantiation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the authors\" claim regarding the lack of negative social impact of their work, specifically questioning the assertion that there are no negative social impacts. It suggests that the authors might not be reviewing this aspect correctly and recommends discussing the social impact of increased automation or the risks from the dual use of their method. While the comment identifies a potential area for improvement, it lacks specific guidance on how the authors should address this concern or what actions they should take to incorporate this feedback into their work. The suggestion is 3 as it points out a potential oversight, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clear connection between two concepts: \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It suggests that the authors should clarify this connection, but it does not provide specific guidance on how to do so. The comment is explicit in identifying the issue but lacks detail on how to address it, making it 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of poor clarity in connecting these concepts. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that there is a lack of clear connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness,\" suggesting that the authors should clarify this connection. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the connection between \"improved variance control of prediction y^ or the smoothness of loss landscape\" and \"zeroshot learning effectiveness.\" It points out that the authors should clarify this connection, which is crucial for understanding the paper\"s main argument. However, the comment lacks specific guidance on how to improve the clarity or what aspects of the connection need to be addressed. While it highlights an important area for improvement, the feedback is somewhat limited in its actionable value, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not provide explicit guidance on how to conduct these analyses or experiments, nor does it offer concrete steps for the authors to take. The comment is 3 as it identifies a potential area for improvement but lacks detailed instructions on how to implement it. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not specify which part of the paper these analyses or experiments should be conducted in, making it weakly grounded. The comment is specific in its suggestions for improvement, but without clear references to specific sections or parts of the paper, it is difficult for the authors to pinpoint where to address these points. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that such analyses are missing. This lack of evidence makes the claim 3, as the authors would need to infer the need for these analyses based on the existing content. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that it could be more novel and interesting if it included theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. This feedback is 3 as it points out a specific direction for enhancing the paper\"s contribution. However, it lacks detailed guidance on how to conduct these analyses or experiments, which could make it less impactful. The comment provides a clear suggestion for improvement but does not offer comprehensive advice or detailed steps for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks the authors to provide a citation for the kmax problem, implying that it has been discussed elsewhere in the paper. However, it does not explicitly instruct the authors to include a citation or specify where the discussion can be found. The action is implicit, as the authors need to infer that they should add a citation. The comment is vague because it does not provide guidance on how to find or include the citation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment asks the authors to provide a citation for the kmax problem, implying that it has been discussed elsewhere in the paper. However, it does not specify which part of the paper or section contains the discussion, making it weakly grounded. The comment is specific in that it requests a citation, which is a clear and actionable request. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking for clarification or additional information regarding the kmax problem. It does not contain a subjective claim, assertion, or suggestion that requires verification. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment is a question asking for clarification or additional information regarding the kmax problem, specifically requesting a citation. While it identifies a potential area for improvement by prompting the authors to provide context, it does not offer any suggestions or guidance on how to address the issue. The comment is vague and lacks actionable advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it points out a missing detail, it does not provide explicit guidance on how to address this issue or what steps the authors should take to clarify or improve the explanation. The action is implicit and vague, as the authors are left to infer that they need to provide more information on the estimation process and the model\"s reliability. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. While it identifies a gap in the paper, it does not provide any specific examples, references, or reasoning to support the claim that this information is missing or critical. The authors are left to infer the importance of this information, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of information on how the function for the optimal sequence length was estimated (Equation 1) and the reliability of the model. This feedback is clear and actionable, as it directs the authors to provide additional details or clarification regarding the estimation process and the model\"s reliability. By addressing this issue, the authors can improve the transparency and robustness of their methodology, making the paper more comprehensive and understandable. The comment is 4 as it provides a clear direction for improvement, though it could be more detailed by suggesting specific ways to enhance the explanation or provide additional context. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the use of \"thousands\" in the context of the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. The comment is explicit in identifying a specific issue with the text and provides a clear action for improvement by suggesting a more precise term. This allows the authors to directly address the inaccuracy and enhance the clarity of their writing. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L006\" in the main text, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding \"on the subword level\" to clarify the use of \"thousands,\" providing a clear direction for improvement. This feedback is detailed and actionable, making it 5.", "verifiability_rationale": "The review point critiques the use of \"thousands\" in the context of the main text, suggesting that it is not accurate and recommending the addition of \"on the subword level\" for clarity. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for improvement is clear, but the absence of additional context or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the text, noting that the use of \"thousands\" is not accurate and suggests adding \"on the subword level\" for clarity. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. However, the comment could be more helpful if it offered additional context or examples to illustrate the inaccuracy. Despite this, the feedback is 4 as it guides the authors in enhancing the precision of their writing. Therefore, the comment is rated as 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several points that could be actionable for the authors. First, it notes that certain hyperparameters, such as regularization, are not specified, which could be clarified by explicitly listing them. Second, it questions the yvalue at x=0 in the latent path figures, asking if it is normalized and seeking clarification. Third, it suggests that the authors consider further analysis using interpolations. However, the comment does not provide specific guidance on how to address these issues or what kind of analysis to conduct. While the actions are somewhat explicit, they lack concrete details, making the comment 4.", "grounding_specificity_rationale": "The comment addresses specific issues related to hyperparameters, latent path figures, and suggests further analysis using interpolations. It mentions specific elements like \"regularization\" and \"latent path figures\" (e.g., Fig 3), which allows the authors to identify the parts of the paper being addressed. However, it does not specify which sections or figures are being referred to, making it weakly grounded. The comment is specific in detailing what needs to be clarified or addressed, such as the yvalue at x=0 in the figures and the suggestion for further analysis. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and suggestions regarding the clarity and completeness of the paper. It questions the absence of specified hyperparameters, such as regularization, and asks for clarification on the yvalue at x=0 in the latent path figures. The comment also suggests further analysis using interpolations. However, the reviewer does not provide any specific reasoning or evidence to support these claims, making them difficult for the authors to address effectively. The lack of detailed justification or examples makes the claims 3, as the authors would need to infer the basis for the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides several specific points for improvement, which could be helpful for the authors. It highlights the absence of specified hyperparameters, such as regularization, which could be clarified by explicitly listing them. Additionally, it questions the yvalue at x=0 in the latent path figures, asking for clarification on whether it is normalized. This feedback is 3 as it identifies areas where the paper could be more clear and detailed. However, the comment could be more helpful if it provided specific guidance on how to address these issues or suggested additional analyses that could be conducted. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also notes that the material supporting the main contributions, such as the deeprag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. While the comment explicitly mentions these issues, it does not provide specific guidance on how the authors should address them. The authors are left to infer that they need to clarify the forward referencing, provide more detailed explanations of the contributions in the introduction, and ensure that the supporting material is moved to the main sections. This lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"the Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. Additionally, it points out that the material supporting the main contributions, including the deeprag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point claims that there is forward referencing in the paper, which is not properly explained, and that the contributions are unclear in the introduction. It also notes that the material supporting the main contributions, such as the deeprag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. The comment provides specific examples of issues, such as Figure 1 and the introduction, and suggests that the authors should clarify the forward referencing and provide more detailed explanations of the contributions. However, it lacks detailed reasoning or references to support these claims, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deeprag algorithm and discussion on high concurrency, is located in the appendix rather than the main sections. While the comment highlights these areas for improvement, it does not provide specific guidance on how the authors should address these issues or suggest concrete changes to the paper. The feedback is 3 as it directs the authors to areas that need clarification and improvement, but it lacks depth and actionable suggestions, making it a 3 out of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor, specifically in terms of epsilon. It does not provide explicit instructions or suggestions on how the authors should address this issue, such as whether they should explore theoretical bounds or provide empirical evidence. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its inquiry about the theoretical effect and error bounds, but it lacks grounding as it does not mention a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. However, it does not provide any evidence, reasoning, or references to support the claim that the authors should explore this issue. The comment lacks specific details or examples, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the effect of rounding core tensors on the approximation error in the full tensor, specifically in terms of epsilon. It highlights a potential area for further exploration or clarification, which could be valuable for the authors to address. However, the comment lacks specific guidance or suggestions on how the authors might approach this issue, such as whether they should explore theoretical bounds or provide empirical evidence. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the two test settings in visual dialog and the results presented in Table 1, which only shows the result for the discriminative setting. The reviewer questions the applicability of the discriminative setting to realworld applications and asks for the result on the generative setting. This comment implies that the authors should provide results for the generative setting to address the gap in the evaluation. However, it does not explicitly instruct the authors to include the generative setting results or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the generative setting results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to realworld applications and asks for the result on the generative setting. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what is missing in the evaluation and what additional results are needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the applicability of the discriminative setting in realworld applications and requests results for the generative setting. While the comment identifies a potential gap in the evaluation, it does not provide specific reasoning or evidence to support why the discriminative setting is not suitable for realworld applications or why the generative setting is important. The lack of detailed justification or references makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some context but lacks sufficient support for a clear claim.", "helpfulness_rationale": "The review comment identifies a specific issue in the evaluation of visual dialog, noting that Table 1 only presents results for the discriminative setting, while there are two test settings in visual dialog. It questions the applicability of the discriminative setting to realworld applications and asks for the result on the generative setting. This feedback is clear and actionable, as it directs the authors to provide results for the generative setting to address the gap in the evaluation. However, the comment could be more helpful by suggesting specific ways to present or analyze the generative setting results, such as comparing performance metrics or discussing the implications of the findings. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed approach, noting that its effectiveness is not known for other language families. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or demonstrate the effectiveness of their approach across different language families. Without specific suggestions or guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed approach, noting that its effectiveness is unknown for other language families. However, it does not specify which part of the paper this issue is related to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to understand where the issue lies and how to address it. Additionally, the comment is specific in identifying the need for further investigation into the effectiveness of the approach across different language families. However, without explicit references to sections or figures, the comment is weakly grounded but specific. Therefore, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed approach is unknown for other language families. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant limitation in the paper, noting that the effectiveness of the proposed approach is unknown for other language families. This observation highlights a critical gap in the research, as it suggests that the findings may not be generalizable to a broader range of language families. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or explore the effectiveness of their approach across different language families. While it points out an important area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or insights for the authors to take. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This provides a clear and explicit action for the authors to take, as they need to either explicitly state the form of p or provide a reference to where it is discussed. The comment is specific and concrete, giving the authors a clear direction on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the form of p should be described near line 135, implying that the authors should provide more context or clarification regarding this aspect of their work. However, the comment does not specify which part of the paper line 135 refers to, making it weakly grounded. It is specific in suggesting that the form of p should be described, but without a clear reference to the section or table, the authors may find it challenging to locate the relevant part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the form of p should be described near line 135, as the authors assume it is a Gaussian distribution but do not explicitly state it. This claim is 3 as it points out a specific area where the paper could be improved by providing more context or clarification. However, it lacks detailed reasoning or examples to fully support the suggestion, making it 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by pointing out that the form of p should be described near line 135. It acknowledges that the authors assume p is a Gaussian distribution but do not explicitly state it, which could lead to confusion. By suggesting that the form of p should be described, the comment offers a clear and actionable direction for the authors to enhance the clarity and completeness of their paper. This feedback is 4 as it provides a specific and actionable suggestion, though it could be more comprehensive if it included additional guidance on how to describe the form of p. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which parts of the related work section need improvement or how the authors should address this issue. The comment lacks explicit guidance on what specific aspects of the related work need to be clarified or expanded upon. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, it does not specify which part of the paper this comment is addressing, making it weakly grounded. The comment is specific in its suggestion to improve the description of differences in related works, but without a clear reference to the section, the authors may find it challenging to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the related work section could be improved by providing more detailed descriptions of the differences between the related works. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed examples or references, the claim is not 5, as it does not provide a clear path for improvement. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the related work section, noting that while some related works are named, their differences are not adequately described. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the related work section by offering suggestions for more detailed descriptions of the differences between the related works. However, the comment could be more helpful if it provided examples of how to describe these differences or suggested specific areas where the descriptions could be improved. Overall, the comment is 4, as it guides the authors toward a specific improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It suggests that the authors should provide a clearer explanation of the significance of these maps in understanding PPP effects. However, the comment does not offer specific guidance on how to improve the explanation or what aspects of the understanding should be emphasized. The action is implicit, as the authors need to infer that they should provide a more detailed explanation of the PPP maps. The action is vague because it lacks concrete details on how to achieve this clarification. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It does not specify which part of the paper this explanation should be included in, making it weakly grounded. However, the comment is specific in its request for clarification regarding the significance of PPP maps in understanding PPP effects. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It suggests that the explanation is intriguing but not explicitly given in the article. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the explanation is missing or important. Without additional context or evidence, the claim remains 3, as the authors are left to infer the need for a more detailed explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while the authors mention the importance of reliable PPP metrics for understanding PPP effects, they do not explicitly explain what kind of understanding one reaches by examining the PPP maps. This feedback is 3 as it highlights a specific area where the authors could enhance their explanation and provide more context for their findings. However, the comment could be more helpful if it offered suggestions on how to clarify this understanding or provide additional context. Overall, the comment provides a clear direction for improvement, but it lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of comparison with stateoftheart methods, such as SpanBERT, which could impact the credibility of the authors\" work. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons they should include. The action is implicit, as the authors need to infer that they should compare their methods with stateoftheart approaches to strengthen their credibility. While the action is somewhat vague, it is clear that the authors need to make comparisons to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of comparison with stateoftheart methods, such as SpanBERT, which is a specific aspect of the paper. It clearly specifies what needs to be addressed, namely the absence of such comparisons, which could impact the credibility of the authors\" work. This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not compare their methods with other stateoftheart methods for spanrelated tasks, such as SpanBERT, which could impact the credibility of their work. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism or how to address it. Without detailed reasoning or evidence, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out the lack of comparison with stateoftheart methods, specifically mentioning SpanBERT. This is a crucial oversight as it affects the credibility and impact of the authors\" work. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as which additional methods to compare with or how to strengthen their evaluation. While it highlights an important area for improvement, the feedback is somewhat limited in its actionable value, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The suggestion to provide a stronger baseline is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable, as it identifies a potential issue but does not offer clear or detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its critique of the training data, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment lacks specific examples or references to support the claim that such supervision is ignored. It does not provide detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 2, as it provides some basis for concern but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer suggests that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments or analyses could be conducted to strengthen their claims. While it identifies a potential area for improvement, the feedback lacks actionable advice and detailed guidance, making it 3. The authors would need to infer how to address the concern, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to clarify the statement. The action is implicit and vague, as it does not specify how the authors should revise the statement or what specific aspects need to be addressed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. However, it does not specify which part of the paper this concern pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the multiscale statement, but it lacks grounding as it does not provide explicit references or sections within the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. The reviewer provides a logical argument to support this claim, explaining that the stacks are sequentialized in the graph, indicating logical time scales. However, the comment lacks specific examples or references to substantiate the claim fully. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the multiscale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. This observation is insightful and could help the authors clarify their explanation of the model\"s operation. However, the comment does not provide specific guidance on how the authors might address this issue or what changes could be made to improve the clarity of the statement. While it offers a valuable point for consideration, the feedback lacks actionable suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the evaluation methodology, suggesting that the use of expected performance under observation noise might not be representative of the decisionmaker\"s true interests. It proposes that the paper\"s formulation, where the decisionmaker cares about the noise, should be clarified upfront. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to clarify the distinction or what specific changes should be made to the paper. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and understand the specific changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the evaluation methodology, suggesting that the use of expected performance under observation noise might not be representative of the decisionmaker\"s true interests. It highlights a potential inconsistency in the paper\"s formulation, where the decisionmaker is assumed to care about the noise, rather than the objective function of interest being a stochastic noisy function. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the inconsistency and suggesting that this distinction should be clarified upfront, providing clear guidance for the authors. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of expected performance under observation noise might not be representative of the decisionmaker\"s true interests, as the paper formulation suggests the decisionmaker cares about the noise. The comment suggests that this distinction should be clarified upfront. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed evidence or guidance on how to clarify the distinction. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation methodology, specifically suggesting that the use of expected performance under observation noise might not be representative of the decisionmaker\"s true interests. It points out that the paper\"s formulation implies the decisionmaker cares about the noise, rather than the objective function of interest being a stochastic noisy function. This feedback is 3 as it highlights a potential inconsistency in the paper\"s approach and suggests that this distinction should be clarified upfront. However, the comment could be more helpful if it provided specific guidance on how to clarify this distinction or what changes might be necessary in the paper. Overall, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment does not explicitly instruct the authors to run the suggested experiment or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance but lacks detailed instructions on how to implement the suggestions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks specific examples or references to support the claim that this approach would be effective or how it would impact the results. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about whether running VGAE with a vamp prior could better match the doubly stochastic construction in the work, suggesting it could help determine if the benefits are from a better generative model or better inference. It also provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. However, the comment lacks specific guidance or detailed suggestions on how to implement these ideas, making it 3. The authors are given a direction to explore, but without concrete steps or examples, the feedback is limited in its impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the model collapsing less than other methods is a common occurrence and whether the authors have observed it in their experiments. While it prompts the authors to consider this aspect, it does not explicitly instruct them to provide evidence or address it in their draft. The action is implicit, as the authors need to infer that they should investigate and potentially include this information. However, the comment lacks concrete guidance on how to address this issue, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in that it asks for clarification on whether this phenomenon is commonly encountered and if the authors have observed it in their experiments. This provides a clear direction for the authors to address the issue, but the lack of explicit grounding makes it challenging for them to pinpoint the exact section to focus on. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. However, it does not provide any evidence, reasoning, or references to support the claim that this phenomenon is commonly encountered or observed in the authors\" experiments. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model collapsing less than other methods, specifically referencing line 159 where gradients become 0 and collapse. It prompts the authors to consider whether this phenomenon is commonly encountered and if they have observed it in their experiments. While the comment identifies an area that could be explored further, it lacks detailed guidance or suggestions on how to address this issue or what specific aspects of the model\"s behavior might be contributing to the collapse. The feedback is 3 as it highlights a potential area for improvement, but it does not provide actionable steps or insights to help the authors enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and explicit action for the authors to take, as they can directly implement the suggestion by adding experiments with these models. The comment is specific in its recommendation, detailing which models should be used and how this would enhance the paper\"s applicability and generalizability. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in its suggestion to include experiments with different LLM families, which would enhance the paper\"s applicability and generalizability. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is 3 as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors could benefit from additional context or references to strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It provides a clear and actionable suggestion to conduct trials with models like OPT, BLOOM, or other alternatives, which could enhance the paper\"s applicability and generalizability. This feedback is specific and constructive, offering a direct path for the authors to improve their draft. However, the comment could be more helpful if it included additional guidance on how to select or compare these models, or if it suggested specific metrics for evaluating the results. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer suggests that the current presentation does not align with the initial understanding of the first part, which involves taking random weights, learning curves between weights, and finding nice weights to be mixed into the final ensemble. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the connection between the two parts. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. However, it does not specify which sections or parts of the paper these connections are discussed, making it weakly grounded. The comment is specific in identifying the issue with the weak connection between the two parts, but it lacks detailed guidance on how to improve this connection. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the initial understanding of the first part and contrasts it with the actual content of the paper, suggesting that the current presentation does not align with the initial understanding. However, the comment lacks specific examples or references to support the claim that the connection is weak. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out a lack of connection between the first part, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the initial understanding of the first part and contrasts it with the actual content of the paper, suggesting that the current presentation does not align with the initial understanding. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connection between the two parts. While it highlights an area for improvement, the feedback is somewhat vague and could be more helpful if it provided actionable advice or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between the performance of learningbased and heuristicbased solvers, noting that heuristicbased solvers, specifically the SOTA heuristicsolver (e.g., Concorde), usually perform better for singleobjective TSP. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This provides a clear and explicit action for the authors to take, which is to include the results for linear scalarization + Concorde in their analysis. The action is concrete, as it specifies exactly what needs to be done to improve the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"competitive baselines\" and \"heuristicbased solvers,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the performance of the SOTA heuristicsolver (e.g., Concorde) for singleobjective TSP and suggests including results for linear scalarization + Concorde for a better comparison. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the learningbased solvers are much better than the heuristicbased solvers according to the experimental results. However, it highlights that for singleobjective TSP, the SOTA heuristicsolver (e.g., Concorde) usually performs better. The comment suggests that the results for linear scalarization + Concorde should be included for a better comparison. This claim is 3 as it provides a logical reasoning for why the inclusion of linear scalarization + Concorde is necessary for a comprehensive comparison. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the learningbased solvers outperform heuristicbased solvers, but it highlights a potential gap in the comparison by suggesting the inclusion of results for linear scalarization with the SOTA heuristicsolver (e.g., Concorde). This feedback is actionable and provides a clear direction for the authors to improve their analysis by including additional comparisons. By addressing this suggestion, the authors can enhance the comprehensiveness and robustness of their experimental evaluation. Therefore, the comment is 4, as it offers a specific and actionable suggestion to improve the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use longterm storage through pose graphs in SLAM, like those discussed in the appendix. However, the comment does not provide explicit guidance on how to incorporate this discussion into the paper or what specific aspects of the proposed method should be compared. The action is implicit and somewhat vague, as the authors are left to infer how to implement the suggested discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"general ideas\" and provides specific examples of existing methods that are relevant to the proposed approach, such as those using topological reasoning, generalized Voronoi graphs, semantic maps, pose graphs in SLAM, and curiositydriven exploration. It also references the appendix section on graphbased SLAM, which provides additional context. The comment is specific because it clearly specifies what needs to be addressed by discussing the proposed method in relation to these existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some general ideas are already present in other methods for exploration, specifically mentioning topological reasoning and methods using generalized Voronoi graphs or semantic maps, as well as longterm storage through pose graphs in SLAM. The comment provides specific examples of these methods, such as those discussed in the appendix section on graphbased SLAM. This level of detail and specificity allows the authors to understand the basis of the claim and how it relates to their work, making the comment 4. However, it could be strengthened by providing more explicit references or examples within the main body of the paper, rather than just referencing the appendix. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use longterm storage through pose graphs in SLAM. This feedback is 3 as it provides a clear direction for the authors to enhance their paper by contextualizing their work within existing literature. However, the comment could be more helpful if it offered specific guidance on how to integrate these discussions into the paper or what aspects of the proposed method should be compared. Overall, the comment provides a valuable suggestion but lacks depth and specificity, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part. It asks whether the combination of these two architectures is a reason for the improvements observed. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The authors are left without guidance on how to address this concern or what changes might be necessary. Therefore, the comment is 1 as it does not offer any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address the question or improve the paper. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, but it does not provide any specific reasoning, examples, or references to support the claim. The authors are left to infer the reasoning, which makes the comment difficult to understand and verify. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using GRU for the Pyramid and LSTM for the sequential part, which is a valid concern for the authors to address. However, the comment does not provide any specific suggestions or guidance on how to improve the paper or address this concern. It lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, the comment is 2, as it identifies a potential issue but does not offer substantial assistance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the definition of \"active vertices\" in line 135, which is a specific part of the paper. It implies that the authors need to clarify this term to ensure the reader understands the context. However, the comment does not provide explicit guidance on how to define \"active vertices\" or suggest alternative definitions. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the term. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 135,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the definition of \"active vertices.\" This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the definition of \"active vertices\" in line 135, which is a factual question about the paper\"s content. It does not contain a subjective claim, suggestion, or judgment that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the definition of \"active vertices\" in line 135. By pointing out this ambiguity, the comment provides the authors with a clear area to clarify, which is essential for improving the readability and understanding of the paper. However, the comment lacks broader suggestions or guidance on how to address this issue effectively. While it is helpful in identifying a specific area for improvement, it could be more helpful if it offered additional advice or strategies for clarifying the term. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the paper, noting that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. It also points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The comment suggests that the authors might be underestimating the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies a gap in the paper\"s discussion and suggests an area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The feedback is 3 as it points out areas for improvement but lacks detailed instructions on how to implement them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"limitations\" section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by pointing out the lack of mention of the theory\"s inapplicability to the used model and the vagueness of \"structural assumptions.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section, which is a valid observation. It also highlights the vagueness of \"structural assumptions,\" which are only detailed in the appendix, making this limitation difficult to understand. The comment suggests that the authors might be underestimating the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. However, the comment lacks specific examples or references to support these claims, making it 3. The authors would need to provide more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically noting that the authors do not explicitly mention the inapplicability of their theory to the used model in the limitations section. This oversight is a critical gap that needs to be addressed. Additionally, the comment points out the vagueness of the term \"structural assumptions,\" which are only detailed in the appendix, making it difficult for the authors to understand this limitation. The reviewer also suggests that the authors might be underestimating the current use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. This feedback is 4 as it provides clear guidance on areas for improvement, such as explicitly mentioning the limitations and elaborating on the societal impact of graph neural networks. However, it could be more helpful if it included specific suggestions or examples to guide the authors in addressing these issues. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific aspect of the paper, noting that only the projection head (CNN layers) are affected, while the classification head (FCN layer) is not. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what changes could be made to the paper. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"projection head (CNN layers)\" and \"classification head (FCN layer),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a particular aspect of the paper, noting that only the projection head is affected, while the classification head is not. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is factual and descriptive, stating that only the projection head (CNN layers) are affected but not the classification head (FCN layer). It does not contain any subjective opinions, suggestions, or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is factual and descriptive, noting that only the projection head (CNN layers) are affected but not the classification head (FCN layer). While this observation is accurate, the comment does not provide any suggestions or insights on how this might impact the paper or what actions the authors could take to address this finding. Without actionable feedback or guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the generalization of the model\"s performance across different focusing distances, specifically those not present in the training data. It suggests that the authors should consider including images with other focusing distances to assess the model\"s generalization ability. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific distances to include or how to analyze the results. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and generalize the findings. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 8,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the generalization of the model\"s performance across different focusing distances, particularly those not included in the training data. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the generalization of the model\"s performance across different focusing distances, specifically those not present in the training data. It does not contain a subjective claim or opinion but rather poses a question that requires the authors to consider additional experiments or analysis. The comment is factual and does not require external references or logical reasoning to be understood. Therefore, it aligns with the label \"X.\"", "helpfulness_rationale": "The review comment raises a valid concern about the generalization of the model\"s performance across different focusing distances, specifically those not included in the training data. It questions whether the model generalizes well to unseen focusing distances, which is a crucial aspect of evaluating the robustness of the model. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as proposing additional experiments or analysis methods. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider defining content and style more broadly, particularly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic.\" However, the comment does not provide explicit guidance on how to define content and style, nor does it offer concrete suggestions on how to address the ambiguity surrounding the meaning of \"style.\" The action is implicit and vague, leaving the authors uncertain about how to implement the suggested changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should consider defining content and style more broadly, particularly in the context of their specific neural application, referencing Gabbay & Hosehn (2018). It also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic.\" However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. While the suggestion is specific about the need for broader definitions, the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the definitions of content and style in the context of a specific neural application, referencing Gabbay & Hosehn (2018). It suggests that style should be instancespecific and that content includes information transferable among groups. However, the comment does not provide specific examples or detailed reasoning to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed explanation or references to relevant literature makes the claim 3, as it leaves room for interpretation and requires further clarification from the authors. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises important questions about the definitions of content and style in the context of the authors\" specific neural application, referencing Gabbay & Hosehn (2018). It highlights the need for a broader understanding of these concepts, particularly in relation to instancespecific style and the transferability of content across groups. The comment also questions the meaning of \"style\" in the context of a nonsequential model and its relation to \"movement dynamic,\" which could help the authors clarify their terminology and improve the clarity of their work. However, the comment could be more helpful if it provided specific examples or suggestions for how to address these issues. Overall, the feedback is 3 as it identifies areas for improvement but lacks detailed guidance, making it partially beneficial for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific examples and comparisons to support the claim that the analysis of vit quantification could be explained in depth. It highlights discrepancies in the variance difference between the proposed approach and the baseline, and mentions that the quantization of MHSA introduces a large loss of precision, a finding already established in transformer quantization in NLP. However, the comment does not offer explicit guidance on how the authors should improve the explanation or address these issues. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as Line 45 and Figures 1(b) and 5(b), allowing the authors to accurately identify the parts being addressed. It also specifies the issue with the analysis of vit quantification, highlighting the discrepancies in variance difference and the loss of precision in MHSA quantization. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the analysis of vit quantification could be explained in depth, providing specific examples and comparisons to support this claim. It highlights discrepancies in variance differences and mentions that the quantization of MHSA introduces a large loss of precision, a finding already established in transformer quantization in NLP. However, the comment lacks detailed reasoning or references to substantiate these claims, making it 3. The authors would need to infer the basis for the claims, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the analysis of vit quantification, highlighting discrepancies in variance differences and the loss of precision in MHSA quantization. It references similar findings in NLP, such as QBERT, Q8BERT, BinaryBERT, FullyBinaryBert, and QBERT, which suggests that the issue is not unique to the ViT model. However, the comment lacks actionable guidance on how the authors might address these issues or improve their analysis. While it identifies a significant area for improvement, it does not offer detailed suggestions or steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It points out that the proposed Xtransformation is similar to STN, applied locally, and notes that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions that there are no empirical or conceptual comparisons to STN in the work, which is a significant gap. While the comment identifies a key issue and suggests that the authors should address the lack of comparison, it does not provide explicit guidance on how to improve the draft or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to STN and other relevant works. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a main weakness of the work regarding its technical novelty, specifically in comparison to spatial transformer networks (STN). It highlights the similarity between the proposed Xtransformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also points out the absence of empirical or conceptual comparisons to STN in the work, which is a significant gap. However, the comment does not specify which part of the paper discusses the technical novelty or the comparison to STN, making it weakly grounded. The specificity of the comment is high as it clearly identifies the issue and suggests improvements, such as including comparisons to STN and other relevant works. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and does not provide a comparison to STN. It highlights the similarity between the proposed Xtransformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also mentions the absence of empirical or conceptual comparisons to STN in the work, which is a significant gap. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. The claim is 3 as it provides some reasoning but lacks detailed evidence or references to substantiate the assertion of limited technical novelty and missing comparisons. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper, specifically the lack of technical novelty compared to spatial transformer networks (STN). It highlights the similarity between the proposed Xtransformation and STN, noting that existing works have already explored applying STN in a local pixel neighborhood. The comment also points out the absence of empirical or conceptual comparisons to STN, which is a critical gap in the work. While the comment provides a clear and actionable suggestion for improvement, it could be more helpful if it offered specific guidance on how to address the lack of comparison or how to demonstrate the novelty of the proposed method. Overall, the comment is 4 as it directs the authors to a key area for improvement, but it could be more comprehensive with additional suggestions or examples."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on a potential error in the referencing of figures in the supplementary material, suggesting that \"Fig.7\" should be \"Fig.12\". It also offers a suggestion to attach proofs to theorems and corollaries in the main paper to improve readability. However, the comment does not explicitly instruct the authors to correct the figure reference or to implement the suggestion about proof links. While the actions are implied, they are vague and lack concrete details on how to execute them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 821 in Supp. Page 31,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure reference, suggesting that \"Fig.7\" should be \"Fig.12.\" Additionally, the comment provides a clear suggestion to attach proofs to theorems and corollaries in the main paper, enhancing the paper\"s readability. However, the comment lacks specificity in terms of what aspects of the methodology or experiments need to be improved to address the concerns about motivation, methodology soundness, and experiment persuasion. While the authors can infer that these concerns relate to the content of the paper, the comment does not provide detailed guidance on how to address them. Therefore, the comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point contains a claim about the correctness of a figure reference (\"Fig.7\" should be \"Fig.12\") and suggests improving the paper\"s readability by attaching proofs to theorems and corollaries. However, the comment lacks specific examples or detailed reasoning to support the claim about the figure reference. While the suggestion to improve readability is logical, the overall comment is 3 due to the lack of detailed justification for the figure reference claim. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on a potential error in the referencing of figures in the supplementary material, suggesting that \"Fig.7\" should be \"Fig.12\". It also offers a suggestion to attach proofs to theorems and corollaries in the main paper to improve readability. However, the comment lacks depth and does not address the concerns about motivation, methodology soundness, and experiment persuasion, which are mentioned but not elaborated upon. While the feedback is 3 in identifying a minor error and suggesting an improvement, it does not provide comprehensive guidance on how to address the broader concerns raised. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about specific sections of the paper, such as the missing determiner in the definition above Section 3, the selection and tagging of action verbs, and the concept of \"action frames.\" While the comment explicitly asks for clarification on these points, it does not provide explicit instructions or suggestions on how the authors should address these issues. The actions are implicit, as the authors need to infer that they should clarify these aspects in their draft. However, the lack of concrete guidance on how to implement these clarifications makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses specific sections of the paper, such as \"Above definition\" and \"Section 3,\" which allows the authors to accurately identify the parts being discussed. It also asks for clarification on the selection of 50 classes and the tagging of action verbs, as well as the concept of \"action frames.\" This provides clear guidance on what needs to be addressed in these sections. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises questions about specific sections of the paper, such as the missing determiner in the definition above Section 3 and the selection of action verbs. It also asks for clarification on the concept of \"action frames.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify the claims made. Without additional context or explanation, the authors may find it challenging to understand the basis of these questions or how to address them. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies specific areas in the paper that require clarification, such as the missing determiner in the definition above Section 3 and the selection of action verbs. It also questions the tagging of action verbs by Levin and asks for clarification on the concept of \"action frames.\" While the comment points out these areas of confusion, it does not provide detailed guidance or suggestions on how the authors might address these issues. The feedback is 3 as it highlights specific areas that need attention, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\". This is an explicit action that the authors can directly apply to improve the accuracy of the paper. The comment is clear and provides a specific instruction, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Ln 32 on Page 1,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly identifies a grammatical error (\"Empiically\" should be \"Empirically\"). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a minor grammatical error in the text, specifically suggesting that \"Empiically\" should be corrected to \"Empirically\". This is a factual correction and does not require any additional reasoning or references to be understood. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a minor grammatical error in the text, specifically pointing out that \"Empiically\" should be corrected to \"Empirically\". This is a straightforward and actionable suggestion that the authors can easily implement to improve the accuracy of their paper. While the comment is brief, it provides a clear and direct piece of feedback that is helpful for enhancing the draft. Therefore, it aligns with a score of 3, as it is 3, as it offers a clear and actionable suggestion but lacks depth or additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, it does not provide explicit guidance on how to implement this improvement or what specific aspects of the feature selection should be considered. The action is implicit and vague, as it leaves the authors to infer the necessary steps to enhance their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed invariant learning module in Section 4.2, specifically mentioning mask selection and rawlevel features. It also refers to the discussion of representation learning in the appendix, suggesting that the feature selection could be improved by considering representation learning. However, the comment does not specify which part of the paper the authors should focus on for improvement, making it weakly grounded. The comment is specific in suggesting that the feature selection could be enhanced by considering representation learning, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why considering representation learning would enhance the feature selection process or how it could be implemented. Without these details, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it provides some basis for improvement but lacks sufficient depth and clarity to be 5.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the paper by suggesting that the feature selection presented in Section 4.2 could be further enhanced by considering representation learning, which is discussed in the appendix. This feedback is 3 as it points out a specific aspect of the paper that could be improved, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of representation learning should be considered. The comment provides a clear direction for improvement but does not offer a comprehensive or actionable plan, leaving the authors with a general idea of what to work on. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on what specific information is missing or how the authors should clarify the design of rewards. Without concrete suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper is missing details or lacks understanding regarding the design of rewards. However, it is specific in identifying the issue of missing details and the lack of understanding about the reward design. This allows the authors to infer that the feedback pertains to a specific section or part of the paper where these details are discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the missing details or how to address them. Without additional context or evidence, the claim is 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, noting that some details are missing and that the design of rewards is not fully understandable. This feedback is clear and actionable, as it points out a gap in the paper\"s explanation, allowing the authors to improve the clarity and completeness of their work. However, the comment could be more helpful if it provided specific examples or suggestions for how the authors might address these missing details. Despite this, the feedback is 4 as it directs the authors to areas that need attention, making it a valuable piece of guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the computational efficiency of Prithvi WxC, suggesting that its runtime should be discussed as a limitation. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the draft. The comment implies that the authors should consider discussing the runtime, but it lacks concrete instructions or suggestions on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide detailed guidance on implementation.", "grounding_specificity_rationale": "The comment addresses the computational efficiency of Prithvi WxC, specifically mentioning its large parameter count and suggesting that its runtime should be discussed as a limitation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to discuss the runtime, but without clear references to the paper, the authors may find it challenging to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the computational efficiency of Prithvi WxC should be discussed due to its large parameter count. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or examples, the claim remains 3, as it lacks sufficient justification to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the computational efficiency of Prithvi WxC, specifically mentioning its large parameter count. It suggests that the runtime of this model should be discussed as a limitation for applications involving climate model parametrizations. While the comment highlights a relevant aspect of the model\"s performance, it does not provide specific guidance on how to address this issue or what actions the authors should take to improve the draft. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what changes could be made to the framing or how the contribution could be clarified. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the framing of the paper oversells the method, making the contribution less clear. However, it does not specify which part of the paper is being referred to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to identify the specific issue and address it effectively. Additionally, the comment does not provide specific guidance on how to revise the framing or clarify the contribution. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the framing of the paper oversells the method, making the contribution less clear. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or context, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the framing of the paper, suggesting that it oversells the method, thereby making the contribution less clear. While the comment highlights a concern that could impact the perceived clarity and impact of the paper, it lacks specific guidance or suggestions on how the authors might address this issue. Without actionable advice or examples of how to revise the framing, the authors may find it challenging to improve their draft. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the quality of paraphrases used for training data generation. It points out that the difference between the paraphrases and the original sentences is unclear, which could impact the subsequent steps and the overall quality of the training data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paraphrases. The feedback is somewhat vague and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of generating paraphrases for training data, specifically noting that the difference between the paraphrases and the original sentences is unclear. This provides a clear indication of which part of the paper the comment is focused on, allowing the authors to accurately identify the relevant section. However, the comment does not specify what needs to be addressed in terms of improving the paraphrases or how to ensure the quality of the training data. While the authors can infer that they need to clarify the differences between paraphrases and original sentences, the comment lacks specific guidance on how to achieve this. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the quality of paraphrases used for training data generation, specifically noting that the difference between the paraphrases and the original sentences is unclear. This concern is relevant to the paper as it impacts the subsequent steps and the overall quality of the training data. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the difference between the paraphrases and the original sentences is unclear. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a critical issue regarding the quality of paraphrases used for training data generation. It highlights that the difference between the paraphrases and the original sentences is unclear, which can significantly impact the subsequent steps and the overall quality of the training data. The comment provides a clear and actionable suggestion that the authors should clarify the differences between the paraphrases and the original sentences to ensure the quality of the training data. This feedback is 4 as it directs the authors to a specific area of concern and offers a clear path for improvement. However, it could be more helpful if it provided additional guidance on how to measure or address the differences between the paraphrases and the original sentences. Overall, the comment is 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with the clarity of the \"bold\" text in Figure 2, suggesting that it might be difficult to see. However, it does not provide explicit guidance on how to address this issue, such as recommending a different color or font size. The comment is somewhat vague and lacks concrete details on how to improve the figure. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear feedback on the issue of the \"bold\" text being hard to see, suggesting improvements such as using another color or a bigger font. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that identifying rationales is not a simple problem, particularly for complex NLP tasks like machine translation. It also notes that the paper is wellorganized and easy to follow, but points out that Figure 2 is cluttered and the \"bold\" text is difficult to see. While the comment provides some context, it lacks specific examples or references to support the claim about the difficulty of identifying rationales. The feedback is 3 as it offers a general observation but could be strengthened with more detailed reasoning or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the \"bold\" text in Figure 2, suggesting that it might be difficult to see. While the comment acknowledges that the paper is wellorganized and easy to follow, it provides specific feedback on a minor issue that could impact the readability of the figure. This feedback is actionable, as it suggests a simple improvement that could enhance the clarity of the presentation. However, the comment could be more helpful if it offered additional suggestions or guidance on how to address similar issues in other parts of the paper. Overall, the comment is 4, as it provides a clear and actionable piece of feedback that could improve the draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, indicating that the writing could be improved. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the writing or what aspects need clarification. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment expresses the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment is somewhat specific in that it highlights the difficulty in understanding the main idea and theoretical analysis, but without further guidance on what specific aspects are unclear, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point expresses the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or suggestions, the claim is not 5, as it does not provide a clear basis for improvement. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment acknowledges the authors\" difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it lacks specific suggestions or guidance on how the authors might address this issue. While it identifies a potential area for improvement, the comment does not provide actionable advice or examples of how the authors could enhance the clarity or coherence of their writing. This limits the comment\"s helpfulness, as it leaves the authors without a clear path to improve their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the proposed method primarily builds upon existing methods, such as ClopperPearson intervals and Gaussian elimination, and that it lacks significant theoretical novelty. The comment also expresses a willingness to improve the score if the authors address these concerns. However, it does not provide specific guidance on how to address these issues or what aspects of the method need to be improved to enhance its theoretical novelty. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of existing methods, such as ClopperPearson intervals and Gaussian elimination, which allows the authors to accurately identify the part of the paper being addressed. It also specifies the concern regarding the lack of significant theoretical novelty, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method primarily builds upon existing methods and lacks significant theoretical novelty. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or references to substantiate the assertion about the method\"s novelty. As a result, the claim is 1 due to the absence of supporting details or examples. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a key weakness in the paper, noting that the proposed method primarily builds upon existing methods, such as ClopperPearson intervals and Gaussian elimination, and lacks significant theoretical novelty. This feedback is clear and actionable, as it highlights a specific area where the authors could improve their work. However, the comment could be more helpful if it provided suggestions on how to address the lack of theoretical novelty or how to differentiate the proposed method from existing approaches. Despite this, the comment offers valuable insight into the need for further development and enhancement of the paper, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should investigate and clarify the concatenation process. However, the comment lacks concrete details on how to implement this investigation or what specific issues might arise. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment raises a question about whether the text input is concatenated by four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment lacks specificity in addressing the issue, as it does not provide details on what needs to be clarified or how the concatenation process might be relevant. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether the text input is concatenated by four text elements of an object. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely factual and descriptive, lacking any critical analysis or reasoning. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about whether the text input is concatenated by four text elements of an object. While this question prompts the authors to consider a specific aspect of their work, it does not provide any guidance or suggestions on how to address this issue or what changes might be necessary. The comment lacks depth and actionable feedback, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is 2, as it identifies a potential area for clarification but does not offer constructive guidance or suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide specific guidance on how to make the sentence clearer or what aspects of the sentence need improvement. The authors are left with an implicit action to revise the sentence, but without concrete details on how to do so. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides a clear suggestion to make the sentence in lines 1217 clearer. This feedback is actionable and provides a clear direction for improvement, making it a 5 comment.", "verifiability_rationale": "The review point suggests that the abstract sentence is cumbersome and could be made clearer. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the sentence is cumbersome or how to make it clearer. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the abstract, noting that the sentence describing the number of questions is cumbersome and could be clearer. This feedback is actionable as it provides a clear suggestion for improvement, guiding the authors to refine the sentence for better readability and comprehension. However, the comment could be more helpful if it offered additional guidance on how to make the sentence clearer, such as suggesting specific ways to rephrase it or provide more context. Overall, the comment is 4 as it highlights an area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the fairness of comparisons made in the experiments, specifically noting that the domainspecific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zeroshot singleimage 3D reconstruction models might be unfair. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experiments or comparisons. The action is implicit, as the authors need to infer that they should consider alternative datasets or methods to ensure fair comparisons. While the action is somewhat vague, it is clear that the authors need to address the issue of fairness in their comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pix3D\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons to zeroshot singleimage 3D reconstruction models, highlighting the unfairness of the comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that comparisons to zeroshot singleimage 3D reconstruction models are unfair because the domainspecific model and experiments are both conducted on Pix3D. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the comparisons are unfair. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of comparisons made in the experiments, specifically noting that the domainspecific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zeroshot singleimage 3D reconstruction models might be unfair. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to ensure fair comparisons. While it highlights a concern, it lacks actionable advice or detailed recommendations, making it 3. The authors would need to infer that they should consider alternative datasets or methods to ensure fair comparisons, but the comment does not provide explicit guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the evaluation is limited, primarily relying on 4 OCR QA datasets. It acknowledges that this evaluation may be unreliable, as the authors themselves admit in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. However, the comment does not provide explicit guidance on how the authors should incorporate these additional scenarios or how to conduct the ablation studies. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4(5)\" in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the evaluation, noting that it is limited to 4 OCR QA datasets and that the authors themselves acknowledge this limitation. The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is limited, primarily relying on 4 OCR QA datasets, and that this evaluation may be unreliable, as acknowledged in Fig 4(5). The comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. However, the comment lacks specific examples or detailed reasoning to support the claim that the evaluation is unreliable or why the LLaVA benchmark would be more appropriate. Without concrete evidence or references, the claim is 3, as it provides a basis for improvement but lacks detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the paper, noting that it primarily relies on 4 OCR QA datasets. The authors themselves acknowledge this limitation in Figure 4(5), suggesting that the evaluation may be unreliable. The comment proposes that more scenarios, such as the LLaVA benchmark, would be expected, particularly in ablation studies. This feedback is 3 as it highlights a specific area for improvement and suggests additional scenarios that could enhance the robustness of the evaluation. However, the comment could be more helpful if it provided more detailed guidance on how to incorporate these additional scenarios or how to conduct the ablation studies. Overall, the comment offers valuable insights but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions about the notation and assumptions in the paper. It suggests that the authors should clarify the function pi and explain why the dimensions do not match in equation (2) due to the removal of the noop action. The comment implies that the authors should address these issues to improve the clarity and consistency of their paper. However, it does not provide explicit instructions on how to implement these changes, such as suggesting specific edits or providing examples. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issues. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the notation and assumptions in the paper, particularly concerning the function pi and the dimensions in equation (2). It provides a clear reference to line 75, allowing the authors to accurately identify the part of the paper being discussed. The comment is fully grounded as it explicitly mentions a specific section of the paper. Additionally, it specifies what needs to be addressed, namely the clarification of the function pi and the explanation of the dimension mismatch. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the notation and assumptions in the paper, specifically regarding the function pi and the dimensions in equation (2). It suggests that the authors should clarify the function pi and explain why the dimensions do not match due to the removal of the noop action. However, the comment does not provide any supporting evidence, reasoning, or references to justify these claims. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas for improvement in the paper, particularly concerning the notation and assumptions. It points out a potential issue with the function pi and the dimensions in equation (2), suggesting that the authors should clarify these aspects. However, the comment lacks depth and does not provide detailed guidance or suggestions on how to address these issues. While it highlights areas that need attention, it does not offer actionable steps or specific advice, making it 3. The feedback is clear but could be more comprehensive to fully assist the authors in improving their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to the tasks. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. However, the comment does not specify which part of the paper discusses these tasks, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the tasks, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it provides a general concern but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions the complexity of the tasks and whether simpler alternatives might be more effective. The comment provides a specific question about the formulation in the paper, prompting the authors to consider simpler tasks. However, the feedback lacks detailed suggestions or guidance on how to address these concerns or what specific changes could be made to the tasks. While it identifies an area for improvement, the comment could be more helpful if it offered concrete suggestions or examples of how to simplify the tasks or improve their clarity. Therefore, the comment is 3, as it provides a starting point for the authors to consider but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of visualization in the paper, specifically mentioning the absence of intermediate processes and comparisons. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. The comment lacks concrete guidance on what kind of visualizations would be beneficial or how the comparisons should be made. Without specific advice on what to visualize or how to compare, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which sections or figures might be missing these visualizations. This lack of specific grounding makes it difficult for the authors to address the issue effectively. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that there is a lack of essential visualization of intermediate processes and comparisons in the paper. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the specific areas where the visualization is lacking. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to focus on enhancing the visual representation of their work. However, the comment could be more helpful if it provided suggestions on what kind of visualizations would be beneficial or how the comparisons should be made. Despite this, the comment offers a clear direction for improvement, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. This is a clear and explicit action that the authors can take to improve their draft. By including these results, the authors can provide a more comprehensive evaluation of their work, allowing readers to better understand the significance of their findings. The comment is specific and concrete, as it directly instructs the authors on what needs to be added to their experiments section. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that keypoint detection results should be included in the experiments section. However, it does not specify which part of the experiments section this should be included in, making it weakly grounded. The comment is specific in its suggestion to include keypoint detection results, but the lack of grounding makes it difficult for the authors to know exactly where to add this information. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any reasoning, examples, or references to support why this is necessary or beneficial. Without additional context or justification, the claim lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that keypoint detection results should be included in the experiments section. This is a specific and actionable piece of feedback that provides the authors with a clear direction for improving their draft. By including these results, the authors can enhance the comprehensiveness and depth of their experimental evaluation, allowing readers to better understand the significance of their findings. The comment is clear, concise, and directly addresses a specific area for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue, it does not provide explicit instructions or suggestions on how to address this concern. The authors are left to infer that they need to clarify this aspect in their draft. The action is implicit and somewhat vague, as it does not specify what needs to be done to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is 1 as it lacks specific references or context. Additionally, it does not provide any specific guidance or suggestions on how to address the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about whether the grid search of the learning rate is performed on the validation set. This is a factual question that does not require any subjective opinions or claims. The comment is purely descriptive and does not provide any evidence or reasoning to support or refute the question. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While this is a valid concern, the comment does not provide any specific guidance or suggestions on how the authors might address this issue. It lacks actionable advice or detailed feedback that would help the authors improve their draft. As a result, the comment is 2, as it identifies a potential area for improvement but does not offer substantial assistance to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The comment implies that the authors should investigate the nature of these relations and consider whether they are appropriate for the dataset or if they should be categorized differently. While the action is implicit, it is somewhat vague, as the authors are left to infer the specific steps needed to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment refers to \"Table A2\" and questions the presence of a large number of dobj relations, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, it does not specify which part of the paper or section contains this table, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the relations but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the observation, making the comment 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the presence of a large number of dobj relations in Table A2, suggesting that it might be an artifact of colloquial language or a specific choice in the UD dataset. While the comment identifies a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern. The feedback is 3 as it points out a potential area for further investigation, but it lacks actionable advice or detailed insights that would guide the authors in improving their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized ones. It does not provide explicit instructions or suggestions on how to address this issue, such as adding data or discussing the implications of the sample\"s diversity. The action is implicit, as the authors would need to infer that they should consider the diversity of their sample and its impact on generalizability. However, the comment lacks concrete guidance on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (L393), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the question about the diversity of the sample and its generalizability to other groups, especially marginalized groups. This provides clear guidance on what aspect of the paper requires attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized groups. It does not contain a subjective claim or suggestion but rather poses a question that could be addressed by the authors. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a pertinent question about the diversity of the sample and its generalizability to other groups, especially marginalized ones. This is a critical aspect of ensuring the robustness and applicability of the research findings. However, the comment does not provide any suggestions or guidance on how to address this issue, such as adding data or discussing the implications of the sample\"s diversity. While it identifies an important area for consideration, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the output quality of the paper is reasonable but still far from realistic, citing recent GAN works that achieve highquality synthesized results. It implies that there is room for improvement in the result quality. However, the comment does not provide specific guidance on how to improve the output quality or what aspects of the paper need to be addressed to achieve higher quality results. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know exactly what steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with output quality, referencing recent GAN works that have shown highquality synthesized results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with output quality and suggests that there is room for improvement. However, it does not provide detailed guidance on how to improve the output quality or what specific aspects of the paper need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the output quality is reasonable but still far from realistic, citing recent GAN works that have shown highquality synthesized results. This claim is 3 as it provides a general reference to recent advancements in GANs, which could be expanded with specific examples or citations to support the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the output quality of the paper, noting that it is reasonable but still far from realistic, especially considering recent advancements in GANs. It suggests that there is room for improvement in the result quality, which is a valuable feedback point for the authors. However, the comment lacks specific guidance on how to improve the output quality or what aspects of the paper need to be addressed to achieve higher quality results. While it provides a clear direction for improvement, the feedback could be more helpful if it included actionable suggestions or examples of how to enhance the output quality. Overall, the comment is 3, as it highlights a critical area for improvement but does not provide detailed guidance for the authors to address it effectively."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This feedback is explicit, as it directly instructs the authors to include additional evaluations and specific elements in their draft. The action is also concrete, as it provides clear guidance on how to implement the suggestion by adding translations to Figure 6. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to add translations to Figure 6, which would help clarify the evaluation process for unseen words. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide more evaluation on classifying unseen words, particularly by adding translations to Figure 6. This claim is 3 as it implies the need for additional evaluation, but it lacks specific examples or references to support the suggestion. The authors would need to infer the need for more detailed evaluation and the rationale behind it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the presentation of the simple/traditional experiment for unseen characters, suggesting that it is presented as an afterthought. The reviewer recommends adding more evaluation, particularly on classifying unseen words, and suggests including translations in Figure 6 to aid understanding for those who do not speak Chinese. This feedback is actionable and provides clear guidance on how the authors can improve the presentation and clarity of their work. However, the comment could be more comprehensive by suggesting additional ways to enhance the evaluation or addressing other aspects of the paper that could benefit from more detailed explanations. Overall, the comment is 4 as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the discussion of computational aspects, noting that the authors do not provide a detailed analysis of how their proposed methods can be practically useful for highdimensional data. It also points out that the algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for their experiments being conducted on smallscale datasets, which does not reflect the practical applicability of the methods. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer how to improve the discussion and experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of detailed discussion on computational aspects, particularly in high dimensions, and highlights the challenges associated with solving LPs in such settings. It also points out that the experiments are performed on smallscale datasets, which does not reflect the practical applicability of the methods. However, the comment does not specify which part of the paper discusses computational aspects or which sections should be expanded. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not adequately discuss computational aspects, particularly in high dimensions, and that their algorithm requires solving several linear programs (LPs) in high dimensions, where a key parameter is not easily calculable. The authors are also criticized for conducting experiments on smallscale datasets, which does not reflect the practical applicability of the methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, as the authors may struggle to address the concerns effectively. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a gap in the discussion of computational aspects, particularly in high dimensions, and highlights the challenges associated with solving linear programs (LPs) in such settings. It points out that the algorithm requires solving several LPs in high dimensions, where a key parameter is not easily calculable, and notes that the experiments are conducted on smallscale datasets, which does not reflect the practical applicability of the methods. While the comment raises important concerns about the practical utility of the proposed methods, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific feedback on the equations in the paper, suggesting that the signs should be changed. It also mentions a minor comment about a specific line. However, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to implement them. The actions are implicit and somewhat vague, as the authors need to infer that they should correct the signs in the equations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines in the paper (Line 502, 503, and 504), allowing the authors to accurately identify the parts being addressed. It is also specific because it provides clear feedback on the equations, detailing the necessary corrections to the signs. This level of detail helps the authors understand exactly what needs to be changed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point provides specific feedback on the equations in the paper, suggesting that the signs should be changed. However, it lacks detailed reasoning or examples to support why these changes are necessary or how they impact the overall understanding of the paper. The feedback is 3 as it points out specific errors, but it does not provide a comprehensive explanation or justification for the suggested changes. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the equations in the paper, pointing out inconsistencies in the signs used. It suggests that the \"+\" sign after \nu_j should be a \"\" sign, and similarly for other parts of the equations. This feedback is actionable and detailed, as it offers clear guidance on how the authors should correct the equations. However, the comment could be more helpful if it included a brief explanation of why these sign changes are necessary or how they affect the overall understanding of the paper. Despite this, the feedback is 4 as it directs the authors to specific areas for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the motivation of the paper, suggesting that the crossencoder architecture is not \"ignoring crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to respond or enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the motivation of the paper, specifically questioning the claim that the crossencoder architecture \"ignores crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment does not specify which part of the paper discusses the crossencoder architecture or the motivation, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the claims made about the architecture, the lack of grounding makes it challenging for the authors to understand the context and address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the crossencoder architecture is not \"ignoring crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. Without detailed reasoning or evidence, the claim remains unsubstantiated, and the authors may struggle to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the motivation of the paper, specifically questioning the claim that the crossencoder architecture \"ignores crossentity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. While the comment highlights a potential misinterpretation or lack of clarity in the paper\"s claims, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it points out a critical area for improvement, but it lacks actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the use of an \"antiquated GNN model and method\" and suggests that this impacts the performance of the framework. It also mentions that the baseline algorithms/methods are \"antiquated.\" However, the comment does not provide any specific guidance or suggestions on how the authors should address this issue. The authors are left without a clear understanding of what changes or improvements are needed to make the framework more effective or uptodate. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the use of an antiquated GNN model and method. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific because it does not detail what aspects of the model or methods are considered \"antiquated\" or how this impacts the framework. Therefore, the comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point claims that the work uses an \"antiquated GNN model and method,\" which seriously impacts the performance of the framework. It also states that the baseline algorithms/methods are \"antiquated.\" However, the comment lacks specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a significant issue with the use of an \"antiquated GNN model and method,\" which could impact the performance of the framework. It also points out that the baseline algorithms/methods are \"antiquated.\" However, the comment lacks specific details or suggestions on how the authors might address this issue or improve their approach. While it highlights a potential weakness, it does not provide actionable guidance or insights that would help the authors enhance their work. Therefore, the comment is 3, as it points out a critical area for improvement but does not offer comprehensive feedback or suggestions for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides two explicit actions for the authors to take: first, to clarify the experiment and its implications, and second, to strengthen the experiment by considering additional factors. The first action is clear and concrete, as it instructs the authors to clarify the experiment and its implications. The second action is also explicit and concrete, as it suggests strengthening the experiment by considering additional factors. The comment is fully actionable because it provides clear guidance on how the authors can improve their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"one experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the use of pseudo feature importance and the reliance on Prop 3.2 and a large enough perturbation value. This provides clear guidance on how to improve the experiment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiment uses pseudo feature importance because no true feature importance is available, and the correctness of this approach relies on Prop 3.2 and a large perturbation value. The comment suggests that this makes it difficult to judge the trustworthiness of the experiment due to the small difference between the tested method and the pseudo feature importance. However, the comment lacks specific examples or references to support the claim about the difficulty in judging trustworthiness. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the experimental setup, specifically addressing the use of pseudo feature importance to estimate uncertainty. It highlights a potential issue with the experiment\"s trustworthiness due to the reliance on Prop 3.2 and a large perturbation value, noting that the difference between the tested method and the pseudo feature importance is minimal. The comment suggests two ways to strengthen the experiment, which are actionable and constructive. By identifying a specific area of concern and offering concrete suggestions, the comment is 5 in guiding the authors to improve their draft. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not provide specific guidance on how to achieve this. The comment lacks explicit instructions or concrete steps for the authors to take to enhance their analysis. As a result, the authors are left without a clear understanding of what actions to undertake to address the feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not specify which part of the paper this analysis should be applied to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what kind of analysis would be more comprehensive or dataintensive. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not provide specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that a more comprehensive and dataintensive analysis would improve the paper, but it does not provide specific guidance on how to achieve this. While it identifies a potential area for improvement, the lack of detailed suggestions or examples makes it difficult for the authors to understand how to enhance their analysis. The comment is 3 as it points out a direction for improvement, but it could be more actionable with additional guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation and how retraining costs are addressed. It suggests that the authors should clarify these aspects to provide a more comprehensive comparison. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the comparison and the challenges of including online learning in the evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other instances where the authors discuss the limitations of online learning formulations. It also specifies the need for a comparison against online learning approaches and RL, highlighting the importance of considering retraining costs and incremental updates. This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation and how retraining costs are addressed. It suggests that the authors should clarify these aspects to provide a more comprehensive comparison. However, the comment lacks specific examples or references to support the claims, making it difficult for the authors to understand the reasoning behind the suggestions. The questions posed are logical and require the authors to provide detailed explanations, but without additional context or evidence, the claim is 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important questions about the comparison of online learning approaches, specifically questioning why they are not considered in the evaluation and how retraining costs are addressed. It highlights the need for a more comprehensive comparison, including a discussion of the challenges and considerations of including online learning in the evaluation. This feedback is valuable as it prompts the authors to clarify and expand their analysis, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these questions, such as suggesting additional experiments or analyses. Overall, the comment is 4, as it identifies key areas for improvement and encourages the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should cite and discuss works related to metalearning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not provide explicit guidance on how to implement these suggestions, such as specific examples of metalearning approaches or how to effectively link the cited works to the current work. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should cite and discuss works related to metalearning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment does not specify which part of the paper these connections should be made, leaving the authors to infer the relevant sections. The comment is specific in its suggestions but lacks grounding as it does not explicitly mention sections or parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cite and discuss works related to metalearning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the suggestions. The reasoning is somewhat vague, and the claim is not 5 without additional context or evidence. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment provides valuable feedback by suggesting that the authors should cite and discuss works related to metalearning, particularly those that, while not directly targeting continual learning, are relevant. It also recommends strengthening the connection to works on RL for architecture search and optimization in the context of continual learning. This feedback is clear and actionable, as it guides the authors to include additional relevant literature and enhance the discussion of their work\"s relationship to existing research. However, the comment could be more helpful if it provided specific examples of metalearning approaches or detailed guidance on how to effectively link the cited works to the current work. Overall, the comment is 4, as it offers clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different feedback. However, it does not provide explicit instructions or guidance on how to implement this suggestion. The action is implicit, as the authors need to infer that they should explore methods to increase the diversity of feedback. While the suggestion is concrete in terms of exploring different feedback types, the lack of explicit guidance on how to do so makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to explore different feedback types, but without a clear reference to the paper, it is difficult for the authors to understand where to apply this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. However, it does not provide any specific reasoning, examples, or references to support why this is a concern or how it might impact the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback. This is a relevant point, as it could enhance the comprehensiveness and depth of the feedback provided. However, the comment lacks specific guidance or suggestions on how to implement this idea, such as exploring different methods for generating diverse feedback or providing examples of how to do so. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This recommendation provides a clear and explicit action for the authors to take, as they can compare their results with these specific works to better understand their performance relative to existing methods. The comment is concrete, as it specifies exactly which papers to compare with, and it provides a clear direction for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This recommendation is fully grounded as it explicitly mentions the papers to be compared, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies which papers to compare with, providing a clear direction for the authors to follow. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This recommendation is 3 as it provides a clear suggestion for comparison, but it lacks specific details or examples of how the comparison should be conducted or what aspects of the performance should be evaluated. Without additional guidance, the authors may find it challenging to fully understand the implications of the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MADX: An AdapterBased Framework for MultiTask CrossLingual Transfer\". This recommendation provides a clear and actionable direction for the authors to improve their draft by benchmarking their results against existing work. By comparing their performance with these specific papers, the authors can better understand the strengths and weaknesses of their approach and identify areas for further improvement. The comment is 4 as it offers a concrete suggestion for comparison, but it could be more comprehensive if it included additional guidance on how to conduct the comparison or what aspects of the performance to focus on. Overall, the feedback is valuable and constructive, making it a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests that the approach should be extended to more general settings. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to extend the approach or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific setting of the paper, including the requirements for the model and the episodic nature of the problem. It also specifies the need to extend the approach to more general settings, providing clear guidance on what needs to be addressed. This allows the authors to accurately identify the part of the paper being discussed and understand the specific issue being raised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a specific question about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. While the comment does not provide a claim or assertion, it raises a question that could be addressed by the authors. However, without further elaboration or justification, the comment lacks sufficient detail to be considered 5. Therefore, it is categorized as \"2.\"", "helpfulness_rationale": "The review comment raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. This feedback is clear and actionable, as it provides a direction for improvement by identifying a potential area where the approach could be broadened. However, the comment could be more helpful if it offered specific examples or guidance on how to extend the approach to more general settings. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. While the comment identifies a specific detail that needs clarification, it does not provide explicit guidance on how the authors should address this question or what information they should include in their response. The action is implicit, as the authors need to infer that they should clarify the feature extractor used. However, the comment lacks concrete details on how to implement this clarification, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This provides a clear direction for the authors to address the question. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This is a factual question that requires the authors to provide additional information or context. However, the comment does not contain any subjective opinions, judgments, or suggestions that would require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific detail in the paper, namely the dimensionality of each region being 512, and asks for clarification on which feature extractor is used. This is a clear and actionable piece of feedback that helps the authors understand a potential gap in their explanation or methodology. By prompting the authors to clarify this aspect, the comment provides a direct path for improvement, making it 3. However, it could be more helpful if it suggested specific ways to address the question or provided examples of how to clarify the feature extractor. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the choice of p < 0.4 in Algorithm 1, but it does not provide any guidance or suggestions on how the authors might have made this choice. The comment lacks explicit instructions or concrete advice on how to address the question or improve the algorithm. As a result, the authors are left without any actionable steps to take, making the comment 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper Algorithm 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it questions the choice of p < 0.4, but without the context of where Algorithm 1 is located, the authors cannot fully understand the scope of the question. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of p < 0.4 in Algorithm 1, but it does not provide any justification or reasoning for why this specific value was chosen. Without additional context or explanation, the authors are left without guidance on how to address this question or improve the algorithm. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of p < 0.4 in Algorithm 1, which could be a point of confusion for the authors. However, the comment does not provide any guidance or suggestions on how the authors might have made this choice or how to address it. Without additional context or explanation, the authors are left without actionable feedback to improve their draft. Therefore, the comment is 2, as it identifies a potential issue but lacks depth and guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. While the comment implies that the authors should provide a clearer explanation, it does not specify exactly what aspects of the motivation need clarification or how to demonstrate it more explicitly. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, it does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the motivation behind applying CMD in federated learning is unclear and could benefit from a more explicit demonstration or explanation. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the motivation behind applying CMD in federated learning. It suggests that the authors could benefit from a more explicit demonstration or explanation of this motivation. However, the comment lacks specific details or examples, making it somewhat vague and challenging for the authors to fully understand and address the feedback. While it points out an area for improvement, it does not provide actionable guidance on how to enhance the clarity of the motivation. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the analysis or what specific aspects of the methods should be examined. The suggestion to compare with other methods is clear, but the lack of detailed instructions on how to perform the analysis makes the action somewhat vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. However, it does not specify which part of the paper this analysis should be conducted or which sections of the paper discuss the methods being compared. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the type of analysis and comparison suggested, the lack of grounding makes it challenging for the authors to understand which parts of the paper are relevant. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing. The comment provides specific references to support the suggestion, which helps the authors understand the basis for comparison. However, the claim about the lack of analysis is somewhat vague and lacks detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is 4, as it provides some support but could be more robust with additional details or examples.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLMbased paraphrasing, to clarify the unique advantages of the proposed method. The inclusion of references to specific works further supports the suggestion, providing a clear direction for the authors to enhance their analysis. This feedback is 4 as it offers actionable insights and guidance on how to improve the paper\"s analysis and comparison, though it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the performance of a model that assigns all negative samples to a distractor class. While it raises a relevant question, it does not provide explicit guidance or suggestions on how the authors should address this issue or what actions they should take to improve their draft. The comment lacks concrete steps or detailed feedback, leaving the authors uncertain about how to respond or what changes are needed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it does not provide explicit references to specific sections, tables, or figures. Additionally, it lacks specificity because it does not detail what the authors should do to address this question or how it relates to the overall content of the paper. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the performance of a model that assigns all negative samples to a distractor class. However, it does not provide any context, explanation, or justification for why this question is important or how it relates to the paper\"s content. Without additional information or reasoning, the authors are left without guidance on how to address this question or what it implies for their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of a model that assigns all negative samples to a distractor class. While this question is relevant to understanding the model\"s behavior, it does not provide specific guidance or suggestions on how the authors might address this issue or what improvements could be made to their draft. The comment lacks actionable feedback, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of quantitative analysis regarding computational gains from replacing the MAE model with a CNNbased data augmentation strategy. It suggests that the authors should provide specific measurements, such as GPU hours, memory usage, or training time, to substantiate these claims. The comment is explicit in its request for quantitative data and provides clear guidance on how the authors should address this issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"computational gains\" and suggests providing specific measurements like \"GPU hours, memory usage, or training time.\" This allows the authors to accurately identify the part of the paper where the issue lies. The comment is also specific because it clearly specifies what needs to be addressed\u2014quantitative analysis of computational gains. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks quantitative analysis on computational gains, specifically mentioning the absence of measurements like GPU hours, memory usage, or training time. This claim is 3 as it provides a clear suggestion for improvement but lacks specific examples or references to support the assertion that these metrics are missing. The authors would need to provide additional evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis on computational gains. It suggests that the authors should provide specific measurements, such as GPU hours, memory usage, or training time, to substantiate the claims of efficiency improvements. This feedback is clear, actionable, and directly addresses a critical aspect of the paper that needs further support. By providing quantitative data, the authors can strengthen the evidence for their claims and enhance the credibility of their work. Therefore, the comment is 5, as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. However, the comment does not specify which part of the paper discusses the FMN, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the questions are specific, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The questions are openended and lack depth, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. These questions highlight potential gaps in the paper\"s analysis and provide specific areas for improvement. However, the comment lacks detailed guidance or suggestions on how the authors might address these issues or what specific experiments could be conducted to strengthen the analysis. While it identifies key areas for improvement, the feedback could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions the contribution of the CoNO model, specifically whether the performance boost is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable and provides references to support the claim. While the comment implies that the authors should compare their model to UNets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons to UNets. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed CoNO model and questions the source of its performance boost, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This comment is fully grounded as it explicitly mentions the CoNO model and the specific aspect of its performance that is being questioned. It is also specific because it provides clear guidance on what comparisons should be made, namely comparisons to UNets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the source of the performance boost in the proposed CoNO model, specifically whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially given the strong performance of UNets on regular gridded domains, referencing works by Raonic et al. and Gupta et al. This provides a logical reasoning and specific examples to support the claim, making it 4. However, the comment could be more robust if it included a detailed explanation of why these comparisons are necessary or how they would be conducted. Overall, the claim is 4.", "helpfulness_rationale": "The review comment raises a critical question about the source of the performance boost in the proposed CoNO model, specifically questioning whether it is due to the fractional transform or the UNet operation in the fractional Fourier domain. It suggests that comparisons to UNets are inevitable, especially considering the strong performance of UNets on regular gridded domains, as evidenced by references to works by Raonic et al. and Gupta et al. This feedback is valuable as it prompts the authors to provide a more detailed analysis of their model\"s performance and to include comparisons to relevant baselines. However, the comment could be more helpful if it provided specific guidance on how to conduct these comparisons or what aspects of the model should be compared. Overall, the comment is 3, as it identifies a significant area for improvement but lacks detailed instructions for action."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly asks the authors to rewrite a specific sentence in the paper, indicating that the original phrasing is unclear. This provides a clear and direct action for the authors to take, making the comment 5. The comment also specifies the location of the sentence, further aiding the authors in understanding where to make the change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the location of the sentence in the paper (P. 5, p. 3, l.), allowing the authors to accurately identify the part being addressed. It is also specific because it requests a rewrite of the sentence to clarify its meaning, providing clear guidance on what needs to be done. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the meaning of a specific sentence in the paper. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The comment is 5 as it directly identifies a specific issue with the clarity of a sentence in the paper. By requesting a rewrite, it provides a clear and actionable suggestion for improvement, enabling the authors to enhance the readability and understanding of their work. The comment is specific and actionable, offering a clear path for the authors to address the identified weakness. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions. It suggests that the authors should consider these aspects and provide details on how they are addressed in the manuscript. While the comment implies that the authors should include this information, it does not explicitly instruct them to add it or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include details about these aspects in their manuscript. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"DocRED\" and \"multiple entity mentions,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with how the authors handle documents as an entire sentence and how they deal with multiple entity mentions, which are important aspects of the manuscript. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the handling of documents in DocRED and the treatment of multiple entity mentions, which are specific concerns related to the methodology or experimental setup. However, it does not provide any claims or suggestions that require verification or justification. The comment is purely descriptive and does not offer any new information or insights that would help the authors improve their work. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions, which are important aspects of the manuscript. It highlights a potential gap in the current manuscript by noting that these details are missing. However, the comment does not provide any suggestions or guidance on how the authors might address these issues or improve their manuscript. While it identifies an area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not provide explicit guidance on how to implement this suggestion or what specific aspects of the lowresolution stream should be emphasized. The action is implicit and vague, as the authors are left to infer that they should consider adding a lowresolution stream. However, the comment lacks concrete details on how to approach this addition, making it 3.", "grounding_specificity_rationale": "The comment expresses an opinion about the marginal contribution of the paper, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but does not specify which part of the paper this suggestion relates to. The comment lacks grounding as it does not mention specific sections, tables, or figures, making it difficult for the authors to identify the exact area where the suggestion should be addressed. However, the comment is specific in its critique of the contribution, suggesting that adding a lowresolution stream might not be a major contribution for a toptier venue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution but does not provide specific examples or references to support this claim. The comment lacks detailed reasoning or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are welldesigned and demonstrated. It proposes adding another stream for lowresolution as a potential contribution, but it does not provide specific guidance on how to implement this suggestion or what aspects of the lowresolution stream should be emphasized. The comment lacks actionable feedback, as it does not offer concrete steps or suggestions for improving the paper. While it identifies a potential area for enhancement, it does not provide detailed guidance on how to achieve it, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implications of providing a tester for the spread parameter, specifically whether it can be extended to yield an (\u03f5, \u03b4)identity tester. It also asks for clarification on how the tester handles pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment implies that the authors should consider these aspects, it does not provide explicit instructions or concrete guidance on how to address them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2 gives a tester for the spread parameter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the implication of this tester for yielding an (\u03f5, \u03b4)identity tester and seeks clarification on how the tester handles specific pairs of (\u03c0, \u03d5). This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the implications of providing a tester for the spread parameter, specifically whether it can be extended to yield an (\u03f5, \u03b4)identity tester. It also asks for clarification on how the tester handles pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment is clear and specific, it does not provide any additional reasoning or references to support the claim that the reviewer is questioning the implications of the provided information. The authors are left to interpret the question themselves, which limits the verifiability of the comment. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises a question about the implications of providing a tester for the spread parameter, specifically whether it can be extended to yield an (\u03f5, \u03b4)identity tester. It also seeks clarification on how the tester handles pairs (\u03c0, \u03d5) where \u03d5 = \u03d5_0 but d_K(\u03c0_0, \u03c0) is large. While the comment identifies a potential area for clarification and exploration, it does not provide specific guidance or suggestions on how the authors might address these questions or improve their draft. The feedback is 3 as it points out a specific area that requires further consideration, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the detailed distribution of the proposed dataset is unclear, but it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the dataset distribution. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper discusses the detailed distribution of the proposed dataset. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is specific in that it points out a lack of clarity in the dataset distribution, but without grounding, the authors are left to guess which part needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point states that the detailed distribution of the proposed dataset is unclear. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the criticism or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the detailed distribution of the proposed dataset is unclear. However, it lacks actionable guidance or suggestions on how the authors might address this issue. Without specific advice or examples, the authors are left without a clear path to improve their draft. The comment is vague and does not provide any constructive feedback, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It proposes that a selfsupervised pretraining approach without annotations could be more appealing. While the comment identifies a potential limitation and suggests an alternative approach, it does not provide explicit guidance on how to implement or address this issue. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration of selfsupervised methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method\"s reliance on annotated labels for learning semantic tokens, which limits its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment does not specify which part of the paper discusses the proposed method or the limitations of supervised training. The authors may need to infer the section where this issue is discussed, making the comment weakly grounded. The comment is specific in detailing the issue and suggesting an alternative approach, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method necessitates annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains 3, as it is based on a logical deduction but lacks sufficient substantiation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, noting that it requires annotated labels for learning semantic tokens, which restricts its applicability to supervised training. It suggests that a selfsupervised pretraining approach without annotations could be more appealing. This feedback is 3 as it highlights a potential area for improvement and offers an alternative approach. However, the comment could be more helpful if it provided specific guidance on how to implement or explore the selfsupervised pretraining approach. Overall, the comment offers valuable insights but lacks detailed actionable suggestions, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate LFF\"s scalability on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. However, the comment does not provide explicit guidance on how the authors should conduct these experiments or what specific aspects of the tasks need to be addressed. The action is implicit and vague, as it does not specify how the authors should demonstrate the scalability of LFF or what kind of experiments would be most effective. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"continuous control experiments\" and provides examples of simple and lowdimensional tasks like \"cartpole or mountain car.\" It also specifies the need to demonstrate LFF\"s scalability on more challenging tasks with higher input dimensionality, such as \"locomotion of ants or humanoids.\" This provides clear guidance on which parts of the paper need attention and what specific issues need to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car, and that it is important to demonstrate LFF\"s scalability on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This claim is 3 as it provides a logical reasoning for why demonstrating scalability on more complex tasks is important. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that most continuous control experiments are performed on simple and lowdimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of LFF, the authors should consider showing its effectiveness on more challenging tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the scope and impact of their work. By addressing this suggestion, the authors can strengthen the paper and provide a more comprehensive evaluation of LFF. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific suggestions for improving the abstract and the inclusion of learning curves in the appendix. It explicitly states that the abstract should mention the expressivity of the model in terms of the change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments, at least in an appendix. These suggestions are clear and concrete, providing the authors with specific actions to take to enhance their draft. The comment is fully actionable as it directly instructs the authors on what changes to make, making it a 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, providing a clear reference point for the authors to understand where the feedback is being applied. It also specifies the suggestion to include a citation and learning curves for all experiments, which are specific and actionable. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the abstract should include a citation to support the claim about expressivity and that learning curves should be included for all experiments. While the suggestion to include a citation is logical and would strengthen the claim, the comment lacks specific examples or references to support the need for learning curves. The absence of detailed reasoning or references makes the claim 3, as it provides a basis for improvement but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the abstract by suggesting a more detailed description of the model\"s expressivity, referencing a specific citation. It also recommends including learning curves for all experiments, which would enhance the paper\"s comprehensiveness. These suggestions are clear and actionable, offering the authors concrete guidance on how to improve their draft. However, the comment could be more helpful if it provided additional context or examples of how to incorporate the suggested changes. Overall, the feedback is 4, as it directs the authors towards specific improvements that would strengthen their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the clarity of the paper\"s motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. While the comment implies that the authors should provide more context and examples to clarify the motivation and application, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the motivation and provide examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the clarity of the paper\"s motivation and the lack of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not specify which part of the paper discusses the motivation or the application of the proposed method, making it weakly grounded. It is specific in detailing what needs to be addressed, such as clarifying the motivation and providing examples of domain adaptation tasks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a claim about the lack of clarity in the paper\"s motivation and the absence of a clear application for the proposed method. It questions the relevance of the domain adaptation demonstrated, suggesting that the paper would be more impactful if it included examples of how the methodology could be used in actual tasks involving domain adaptation. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors are left to infer the need for clarification and examples, which could be addressed with additional information or feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s motivation and application, specifically questioning the relevance of the domain adaptation demonstrated. It suggests that the paper would be more impactful if it included examples of how the methodology could be applied to actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. This feedback is clear and actionable, providing the authors with a specific direction for improving the paper\"s clarity and relevance. However, the comment could be more helpful if it included suggestions for demonstrating the methodology\"s use in specific tasks or provided examples of such applications. Overall, the comment is 4 as it highlights an important area for improvement and guides the authors toward enhancing the paper\"s impact."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the paper for considering only one deep learningbased baseline, MULT, which was proposed in 2019 and is no longer considered stateoftheart. However, the comment does not provide any explicit or implicit suggestions for improvement or additional baselines that could be considered. The authors are left without guidance on how to address this issue or what other baselines might be relevant. As a result, the comment lacks actionable information, making it 1.", "grounding_specificity_rationale": "The comment provides a list of references related to multimodal sentiment analysis and emotion recognition, but it does not specify which part of the paper these references are relevant to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not specify what needs to be addressed in relation to these references, such as how they might improve the paper or what aspects of the paper are lacking in comparison to these works. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper regards MULT as the only deep learningbased baseline that considers crosssensory interaction but notes that MULT was proposed in 2019 and is thus out of fashion. This claim is 3 as it provides a specific example of a baseline and its publication year, allowing the authors to understand the context of the criticism. However, it lacks detailed reasoning or references to support the claim fully, which could make it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by suggesting that the authors should consider more recent baselines for comparison, as the current baseline, MULT, was proposed in 2019 and may no longer be considered stateoftheart. This feedback is 3 as it points out a potential gap in the literature review and suggests an area for improvement. However, the comment could be more helpful if it provided specific examples of more recent baselines or suggested how the authors might address this issue in their work. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should compare the tensor completion results for all models, including TW, TT, and TR, while ensuring that the models have the same number of model parameters. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue of unclear comparisons. The comment is fully actionable because it specifies the exact steps required to improve the fairness of the comparison. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a comparison against other models in the experiments, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on how to address the issue, including the omission of model ranks and the suggestion to compare tensor completion results with the same number of model parameters. This level of detail helps the authors understand exactly what needs to be done to improve the fairness of the comparison. Therefore, this comment is rated as 5, corresponding to category 5.", "verifiability_rationale": "The review point claims that the comparison against other models in the experiments is unclear and that the omission of model ranks makes it difficult to ensure a fair comparison. The comment suggests that the authors should compare tensor completion results for all models, including TW, TT, and TR, while having the same number of model parameters. This claim is 3 as it provides a logical reasoning for why the comparison is unclear and suggests a specific way to address the issue. However, it lacks detailed examples or references to support the claim fully, which could make it somewhat challenging for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it identifies a significant issue with the experimental comparison, specifically the lack of clarity and the omission of model ranks, which hinders a fair comparison between the models. The comment provides clear and actionable suggestions for improvement, such as comparing tensor completion results for all models while ensuring they have the same number of model parameters. This guidance is detailed and constructive, enabling the authors to address the identified weakness effectively. The feedback is comprehensive and provides a clear path for the authors to enhance the rigor and fairness of their experiments. Therefore, this comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It highlights a gap in the theoretical part of the paper, as the authors did not provide details on how the algorithm removes subdivision splines. The comment implies that the authors should clarify the algorithm\"s details and address the computational cost. However, it does not explicitly instruct the authors to provide these details or address the cost, making the action implicit and somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment questions the authors\" claim about the utility of subdivision splines and the computational cost of the proposed algorithm. It does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its critique of the claim but lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the authors\" claim regarding the utility of subdivision splines and the computational cost of the proposed algorithm. It does not provide any specific evidence, reasoning, or references to support the claim that the authors did not detail how the algorithm removes subdivision splines or address the computational cost. Without explicit evidence or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the utility of subdivision splines and the computational cost of their proposed algorithm. It questions whether the theoretical part of the paper provides details on how the algorithm removes subdivision splines and whether it introduces extra computational costs. This feedback is 3 as it highlights a gap in the paper\"s explanation and encourages the authors to provide more detailed information. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While it suggests that these terms likely denote the Encoder and Decoder networks, the comment does not provide explicit guidance on how the authors should define these terms or where they should be defined. The action is implicit, as the authors need to infer that they should define W and V, but it lacks concrete details on how to do so. Therefore, the comment is 3, as it provides a clear indication of what needs to be addressed but does not offer specific guidance on how to implement the action.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper (p.3, A4, eq.3 and eq.4) where the terms W and V are not defined. This allows the authors to accurately identify the parts of the paper that need attention. The comment is also specific because it clearly specifies that the terms W and V are not defined in these sections, and it suggests that these terms likely denote the Encoder and Decoder networks. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While the comment identifies a potential issue with the clarity of the paper, it does not provide any specific examples or references to support the claim. The authors are left to infer that the terms are likely undefined, but without further explanation or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the terms W and V are not defined, particularly in equations 3 and 4. This feedback is clear and actionable, as it points out a lack of clarity in the paper that could hinder understanding. However, the comment could be more helpful if it provided suggestions on how the authors might define these terms or where they should be defined for clarity. While it identifies a significant issue, it lacks depth in terms of actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the comparison with some baselines is unfair because these baselines lack prior knowledge of users or language embedding computation. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the comparison. The action is implicit, as the authors need to infer that they should consider a more fair comparison by incorporating prior knowledge or language embedding computation into the baselines. While the action is clear, it lacks concrete details on how to implement it, making it 3.", "grounding_specificity_rationale": "The comment suggests that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with the comparison, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas that need improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair because they lack prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 3, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed method with some baselines, specifically noting that these baselines lack prior knowledge of users or language embedding computation. This observation raises concerns about the fairness of the comparison. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparison. While it highlights a potential weakness, it lacks actionable advice or detailed recommendations, making it 3. The authors would need to infer that they should consider incorporating prior knowledge or language embedding computation into the baselines to ensure a fairer comparison. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including why the outputside layers do not benefit from the proposed method, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions and concerns about specific aspects of the paper, such as the benefits of outputside layers, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. However, it does not explicitly mention which sections or parts of the paper these issues relate to, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its questions, the lack of explicit grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including why the outputside layers do not benefit from the proposed method, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. Additionally, it questions the limitations and potential negative societal impact of the work. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The questions are openended and do not provide clear guidance on how the authors might address these issues. As a result, the comment is considered 1, as it does not offer sufficient evidence or justification for the claims made.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, such as why the outputside layers do not benefit from the proposed method, the clarity of Figure 4, the details of the Pixelshuffle operation, and the dimensionality of upsampling in Figure 2. It also questions the limitations and potential negative societal impact of the work. While the comment identifies areas that need clarification or improvement, it lacks specific guidance or suggestions on how the authors might address these issues. The feedback is 3 as it points out areas for improvement, but it could be more actionable with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the process of generating negative chips and training the RPN, specifically whether the negative chips are fixed or updated during training. It also asks whether alternating between generating negative chips and training the network would help improve performance. While the comment poses a question that could guide the authors to consider certain aspects of their methodology, it does not provide explicit instructions or suggestions on how to address the question or incorporate the feedback into the draft. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the process of generating negative chips and training the RPN, specifically whether the negative chips are fixed or updated during training. It also asks whether alternating between generating negative chips and training the network would help improve performance. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area that needs clarification or discussion. While the question is specific about the process, the lack of grounding makes it challenging for the authors to address it effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the process of generating negative chips and training the RPN, specifically whether the negative chips are fixed or updated during training. It also asks whether alternating between generating negative chips and training the network would help improve performance. However, the comment does not provide any evidence, reasoning, or references to support the claim that this process is critical or beneficial. Without specific justification or examples, the authors may find it challenging to understand the basis of the question or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the process of generating negative chips and training the RPN, specifically whether the negative chips are fixed or updated during training. It also asks whether alternating between generating negative chips and training the network would help improve performance. While the comment identifies a potential area for clarification and exploration, it does not provide specific guidance or suggestions on how the authors might address this question or incorporate it into their work. The feedback is 3 as it prompts the authors to consider an important aspect of their methodology, but it lacks depth and actionable advice. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide explicit guidance on how to conduct this evaluation or what specific aspects of the approach should be considered. The action is implicit, as the authors need to infer that they should perform this evaluation, but it lacks concrete details on how to implement it. Therefore, the comment is 3, as it provides a clear direction but lacks specific guidance on execution.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion to evaluate the approach on new and old patients, the absence of grounding information makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would impact the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. This feedback highlights a potential area for further analysis and could guide the authors in refining their methodology or experimental design. However, the comment lacks specific guidance on how to conduct this evaluation or what aspects of the approach should be considered. While it identifies a relevant area for improvement, the lack of detailed suggestions or examples limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction but lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the algorithm need to be revised. Without further clarification or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not specify which part of the paper these techniques are discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its critique of the novelty of the techniques but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some techniques behind the algorithm may not be novel, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, the comment lacks specific evidence or references to support this claim. Without detailed examples or citations, the authors may find it challenging to understand the basis of the critique or how to address it. The comment is 3 as it provides a general observation but lacks the necessary depth and support to be fully convincing. Therefore, it is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of some techniques used in the algorithm, specifically mentioning \"computation offloading\" and \"gradient augmentation.\" However, it does not provide any suggestions or guidance on how the authors might address this issue or improve the novelty of their approach. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per the number of residents. While the comment identifies a potential inconsistency in the formulation, it does not explicitly instruct the authors to revise the formulation or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider alternative aggregation methods or data types. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1)\" and refers to specific works, Law et al., NeurIPS\"18 and 4, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support $v$, while the data might be aggregated by other procedures, such as simple summation or populationweighted average. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the formulation introduced by the authors assumes that observations are obtained by averaging over the support $v$, but it suggests that the data might be aggregated by other procedures, such as simple summation or populationweighted average. The reviewer provides examples of how disease incident data are often available in count or rate per the number of residents, which supports the claim. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the formulation of the integral in Equation (1), suggesting that the authors assume observations are obtained by averaging over the support $v$. However, it points out that the data might be aggregated by other procedures, such as simple summation or populationweighted average, and notes that disease incident data are often available in count or rate per the number of residents. This feedback highlights a potential gap in the paper\"s methodology and suggests that the authors should consider alternative aggregation methods or data types. While the comment provides a clear direction for improvement, it could be more helpful if it offered specific guidance on how to address the issue or suggested alternative approaches. Overall, the comment is 3 as it identifies a potential area for clarification and improvement, but it lacks depth and specificity in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks indepth analysis, specifically regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. While the comment implies that the authors should conduct a more detailed analysis, it does not explicitly instruct them to do so or provide specific guidance on how to analyze the training dynamics. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct a more thorough analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks indepth analysis, specifically regarding the inverse scaling observed over compute. It implies that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. It is specific in suggesting that the authors should provide an analysis explaining the training dynamics, but without a clear reference to a specific section or figure, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis, specifically regarding the inverse scaling observed over compute, and suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper: the lack of indepth analysis regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to strengthen the paper. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work. However, the comment could be more helpful if it provided some guidance on how to conduct this analysis or suggested specific methods for investigating the training dynamics. Despite this, the comment is 4 as it highlights a crucial aspect of the paper that needs attention, providing the authors with a clear direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on how to implement this change or what specific aspects of the policy to modify. The suggestion is somewhat vague, as it lacks concrete details on how to make the policy nonfixed or how to compare with a reinforcement learning baseline. Therefore, the comment is 3, as it provides a general idea but lacks specific guidance on implementation.", "grounding_specificity_rationale": "The comment suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment applies. While the comment is specific in its suggestion, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or detailed reasoning to support this suggestion. It does not provide any references or logical arguments to justify why this change would be beneficial or how it aligns with the paper\"s goals. Without concrete evidence or detailed explanations, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should consider making the policy nonfixed to increase the complexity of the tasks and compare their approach with a reinforcement learning algorithm baseline. This feedback provides a clear direction for improving the paper by expanding the scope of the tasks and enhancing the comparison with existing methods. However, the comment lacks specific details on how to implement this change or what aspects of the policy should be modified. While it offers a valuable suggestion, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides a general direction but requires further elaboration to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the paper\"s focus on explaining multitask models limits its applicability. However, it does not provide any specific guidance or suggestions on how the authors might address this limitation or enhance the applicability of their work. The comment lacks explicit actions or concrete steps that the authors could take to improve their draft. As a result, the authors are left without a clear understanding of what changes are needed to make the paper more applicable. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper mainly focuses on explaining multitask models, which limits its applicability. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the issue of limited applicability but lacks grounding as it does not provide guidance on how to address this issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper mainly focuses on explaining multitask models, which limits its applicability. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique and how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s focus on explaining multitask models, suggesting that this limits the applicability of the work. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance the applicability of their research. Without actionable guidance or examples, the authors may find it challenging to understand the implications of this feedback and how to improve their draft. Therefore, the comment is 2, as it provides a general observation but lacks depth and specificity to guide the authors effectively."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the literature review should include several papers that seem relevant, specifically mentioning 1 and 2. It also notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. The action is implicit and vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the literature review should include several papers that seem relevant, specifically mentioning 1 and 2. It also notes that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not specify which section of the paper the literature review is located, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the inclusion of relevant papers and the comparison with QSGD. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the literature review ignores several relevant papers, specifically mentioning 1 and 2. It suggests that VRMARINA and DASHAMVR satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issue. The absence of references or detailed explanations weakens the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the literature review, noting that it may be overlooking several relevant papers. It provides specific examples, such as 1 and 2, which seem to satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks detailed guidance on how to incorporate these papers into the literature review or how to address the comparison with QSGD. While it points out a potential gap in the literature review, it does not offer actionable steps or suggestions for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not provide explicit or implicit actions for the authors to take, such as conducting additional experiments or providing detailed analysis. The comment lacks concrete guidance on how the authors should address these questions or what specific actions they should take to improve their draft. As a result, the comment is 1, as it does not provide the authors with a clear path forward for addressing the concerns raised.", "grounding_specificity_rationale": "The comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections or content being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not provide detailed guidance on how to address the performance concerns or what additional experiments might be needed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. However, it does not provide any specific evidence, reasoning, or references to support these claims or questions. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other realworld datasets like WebVision, evaluated by DivideMix. While it identifies an area for further investigation, it does not provide specific guidance or suggestions on how the authors might address these concerns or what additional experiments could be conducted. The comment lacks actionable insights and detailed feedback, making it 3 as it highlights potential areas for improvement but does not offer a comprehensive roadmap for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the level of detail provided about the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should provide more information about the computation requirements of these models, particularly in relation to the timedependent LGSSM parameters \u03b3. While the comment implies that the authors should elaborate on these aspects, it does not explicitly instruct them to add more details or clarify the computation requirements. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more information about the computation requirements of the models. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a more detailed presentation of the compared models, specifically DMM, DVBF, and KVAE. It also references Table 1, allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it requests more information about the computation requirements of the models, which is a clear and actionable request for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the level of detail provided regarding the compared models, specifically DMM, DVBF, and KVAE. It suggests that the authors should comment on the computation requirements of these models, particularly in relation to the timedependent LGSSM parameters \u03b3. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the models are not wellpresented. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed presentation of the compared models, particularly DMM, DVBF, and KVAE. It highlights a specific aspect of the models, such as the computation requirements, which could be beneficial for the authors to clarify and improve their paper. However, the comment could be more helpful if it provided additional guidance on how to present the models in more detail or suggested specific areas where the presentation could be improved. Overall, the comment is 3 as it points out a need for more detail but lacks depth in its suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the theoretical results lack immediate practical implications and recommends that the authors provide more takeaway points for practitioners. It also notes that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not explicitly instruct the authors to provide these takeaway points or clarify the novelty of the finding. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the theoretical results and their lack of immediate practical implications, suggesting that the authors should provide more takeaway points for practitioners. It also mentions that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not specify which part of the paper discusses the theoretical results or the takeaway points, making it weakly grounded. The comment is specific in detailing the issue with the theoretical results and the lack of clarity regarding the novelty of the finding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the theoretical results lack immediate practical implications and suggests that the authors should provide more takeaway points for practitioners. It also notes that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a key weakness in the paper, specifically the lack of immediate practical implications for the theoretical results. It suggests that the authors should provide more takeaway points for practitioners, which could enhance the paper\"s impact and relevance. Additionally, the comment points out that the main takeaway point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty, which is a valuable feedback for the authors to consider. However, the comment could be more helpful if it provided specific guidance on how to address these issues, such as suggesting additional experiments or analyses to demonstrate the practical implications or providing a clearer explanation of the novelty of the finding. Overall, the comment is 3 as it highlights important areas for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point questions the necessity of introducing separators in Section 4, asking for clarification on their purpose beyond T/I/O. While it prompts the authors to explain the role of separators, it does not provide explicit guidance on how to address this issue or what specific changes might be needed. The action is implicit, as the authors need to infer that they should clarify the purpose of separators. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of introducing separators and asks for clarification on their purpose beyond T/I/O, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the necessity of introducing separators in Section 4, specifically asking for clarification on their purpose beyond T/I/O. While it does not contain a subjective claim or opinion, it prompts the authors to provide additional context or justification for the introduction of separators. The comment is factual and descriptive, as it requests clarification rather than making a claim that needs verification. Therefore, it aligns with the \"No\" category.", "helpfulness_rationale": "The comment identifies a specific area in the paper, section 4, where the introduction of separators is questioned. It prompts the authors to clarify the purpose of these separators beyond T/I/O, which is a valuable piece of feedback. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it highlights an area for improvement, it does not offer actionable advice or detailed insights, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This provides a clear and explicit action for the authors to take, as they know exactly what additional information to include in their table. The comment is specific and concrete, giving the authors a precise direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a concrete improvement by comparing the real search cost in terms of GPU days, which provides clear guidance on what needs to be added to the table. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This is a specific and actionable suggestion that provides a clear direction for improvement. However, the comment does not offer any reasoning or justification for why this comparison is important or how it would enhance the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of this suggestion. Therefore, the comment is 3, as it provides a specific action but lacks detailed reasoning or references to support its importance.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors compare the real search cost in terms of GPU days in addition to the number of queries in Table 3. This feedback is actionable and directly addresses a potential area for enhancing the clarity and comprehensiveness of the paper. By offering a concrete suggestion, the comment empowers the authors to make a meaningful improvement to their draft, making it 4. However, it could be more helpful if it included additional context or reasoning for why this comparison is important. Overall, the comment is 4 as it provides a clear direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to include them in the paper. The action is implicit, as the authors can infer that they need to clarify these training details. However, the comment lacks concrete guidance on how to address this issue, such as suggesting where to add the information or what specific details to include. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment raises a question about the training details of the VQGAN, specifically whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this information is relevant to, making it weakly grounded. The comment is specific in that it identifies a missing detail that needs clarification, but the lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that requires attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the training details of the VQGAN, specifically whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This is a factual question that requires the authors to provide specific details about their methodology. However, the comment does not offer any additional context, reasoning, or references to support the need for this clarification. As a result, the claim is 3, as it lacks sufficient justification or evidence to fully substantiate the need for the authors to address this question. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the training details of the VQGAN, asking whether it is pretrained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This question highlights a potential gap in the clarity of the methodology section, as it is crucial for understanding the experimental setup. By pointing out this ambiguity, the comment provides the authors with a clear direction to improve their draft by including these details. However, the comment could be more helpful if it suggested where to add this information or what specific details to include. Overall, the feedback is 3 as it identifies a specific area for improvement but lacks depth in terms of actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some crossmodel retrieval tasks, particularly in the MSVD task, where performance shows minor improvements. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the methods. The authors are left without guidance on what steps to take to enhance the generality of the methods or to address the observed performance limitations. Therefore, the comment is 1 as it lacks any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed methods, DualIS and DualDIS, and refers to specific results in Table 3, particularly the performance on the MSVD task. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the methods, noting that they are not generic on some crossmodel retrieval tasks and that the performance in MSVD shows minor improvements. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some crossmodel retrieval tasks, specifically noting that the performance in MSVD (Table 3) shows minor improvements. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to fully understand or address the issue raised. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some crossmodel retrieval tasks, particularly in the MSVD task, where performance shows minor improvements. While the comment highlights a limitation in the methods\" applicability, it does not provide any suggestions or guidance on how to address this issue or improve the methods. The feedback is 3 as it points out a specific area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for enhancing their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point expresses a concern about the experimental strengths of the proposed approach, suggesting that running the algorithm on 40 different networks from the training phase might be unnecessary. It proposes an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts would reach the global minimum. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their experimental setup. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts would reach the global minimum. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the concern about the experimental setup and suggesting an alternative approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts would reach the global minimum. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the proposed approach is unnecessary or that the suggested alternative is more effective. The lack of evidence or justification makes the claim 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts would reach the global minimum. This feedback provides a clear and actionable suggestion for the authors to consider, offering an alternative approach that could potentially simplify their experimental setup. However, the comment could be more helpful if it provided more detailed reasoning or examples to support the claim about the inefficiency of the current approach. Overall, the comment is 4 as it offers a specific and actionable suggestion, but it could be enhanced with additional context or evidence to strengthen its impact."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to correct a typographical error in the phrase \"for \"inbetween\" uncertainty,\" specifically mentioning that the first quotation mark should be a forward mark rather than a backward mark. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be corrected and how to implement the suggestion. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the phrase \"for \"inbetween\" uncertainty\" and provides a specific correction regarding the quotation mark. It clearly specifies what needs to be addressed, making it fully grounded. The comment is also specific as it details the exact issue with the quotation mark, providing clear guidance for the authors. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction regarding a typographical error in the phrase \"for \"inbetween\" uncertainty.\" It specifies that the first quotation mark should be a forward mark rather than a backward mark. While the comment is accurate, it does not provide any additional reasoning, references, or context to support the claim. However, it is clear and specific, making it 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment is specific and actionable, pointing out a minor typographical error in the phrase \"for \"inbetween\" uncertainty.\" It clearly instructs the authors to correct the quotation mark, which is a straightforward and easily implementable suggestion. This feedback is valuable as it helps the authors improve the accuracy and clarity of their writing. However, the comment could be more helpful if it provided additional context or suggestions for similar issues throughout the paper. Despite this, the comment is 4 as it offers a clear and direct improvement for the authors to address. Therefore, it is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the clarity and specificity of certain aspects of the paper. It asks the authors to clarify the meaning of \"Omega\" in line 178, to be more explicit about the OMD family of algorithms, and to specify the link function and theorem in reference to the regret guarantee. While the comment provides explicit questions and suggestions, it lacks concrete guidance on how the authors should address these points. The authors are left to infer the necessary actions, which makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses specific questions and suggestions related to the content of the paper, particularly around line 178. It asks for clarification on the meaning of \"Omega,\" the OMD family of algorithms, the link function, and the specific theorem in reference to the regret guarantee. However, the comment does not explicitly mention the section or part of the paper where these questions are relevant, making it weakly grounded. The questions are specific and provide clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the clarity and specificity of certain aspects of the paper, such as the meaning of \"Omega\" in line 178, the OMD family of algorithms, the link function, and the specific theorem referenced for the regret guarantee. While the questions are logical and seek clarification, they do not provide explicit evidence or references to support the claims made. The comment lacks detailed reasoning or examples to substantiate the need for clarification or more explicitness. Therefore, the claim is considered 2, as it is somewhat supported but lacks sufficient detail or references.", "helpfulness_rationale": "The review comment raises specific questions and suggestions regarding the clarity and specificity of certain aspects of the paper, particularly around line 178. It asks for clarification on the meaning of \"Omega,\" the OMD family of algorithms, the link function, and the specific theorem referenced for the regret guarantee. While the comment identifies areas where the paper could be more explicit, it lacks detailed guidance on how the authors should address these issues. The feedback is 3 as it provides a clear direction for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific aspect of the models being learned directly from pixels without a Markovian state. While it points out a potential issue with the approach, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The comment lacks concrete suggestions or actionable steps for the authors to take, leaving them uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the models are learned directly from pixels without a Markovian state,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular aspect of the models that may need clarification or further discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the models are learned directly from pixels without a Markovian state. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is 1.", "helpfulness_rationale": "The review comment identifies a specific aspect of the models being learned directly from pixels without a Markovian state. While it points out a potential issue, it does not provide any suggestions or guidance on how the authors might address this concern or what changes could be made to the models. The comment lacks actionable feedback, leaving the authors without a clear path forward for improvement. Therefore, the comment is 2, as it identifies a problem but does not offer any constructive advice or suggestions for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before and are only aware of works reporting nodewise Hamming loss. The comment suggests that the authors should point out some references to clarify this aspect. While the comment implies that the authors should provide references, it does not explicitly instruct them to do so or provide specific guidance on how to find or include these references. The action is implicit and somewhat vague, as the authors need to infer that they should add references to support their claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Example 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the Hamming distance over entire parts of the sequence, questioning its common practice and contrasting it with nodewise Hamming loss. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of the Hamming distance over entire parts of the sequence as a common practice in the context of CRF, noting that the authors have not seen this approach before and are only aware of works reporting nodewise Hamming loss. The comment suggests that the authors should point out some references to clarify this aspect. However, the comment lacks specific references or detailed reasoning to support the claim that this approach is uncommon or that the authors are unaware of it. Without additional context or references, the claim is difficult to verify, making it 2.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the use of the Hamming distance over entire parts of the sequence in the context of CRF, which is presented as a \"common\" practice. The reviewer questions the authors\" claim that this approach is common, noting that they have not seen it before and are only aware of works reporting nodewise Hamming loss. This feedback is 3 as it highlights a potential inconsistency or lack of clarity in the paper\"s approach, prompting the authors to consider the validity of their claim and provide references to support their understanding of \"common\" practices. However, the comment could be more helpful if it provided specific references or examples to clarify the reviewer\"s point, allowing the authors to address the issue more effectively. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing the corresponding sections, instead offering to briefly mention the metrics along with the datasets or in the captions of the tables. This provides a clear and explicit action for the authors to take, as they know exactly what changes to make to improve their draft. The comment is specific in its suggestions, detailing the exact alterations needed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing corresponding sections, instead offering to briefly mention the metrics along with the datasets or in the captions of the tables. This provides clear guidance on what needs to be addressed, but it does not specify which part of the paper the \"Evaluation\" element is located in, making it weakly grounded. However, the comment is specific in its suggestions regarding the name change and the presentation of metrics. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests changing the name of the \"Evaluation\" element to \"Metrics\" and recommends removing corresponding sections, instead offering to briefly mention the metrics along with the datasets or in the captions of the tables. This comment is 4 as it provides a clear suggestion for improvement, aligning with the reasoning that the change would enhance clarity and conciseness. However, it lacks specific examples or references to support the claim fully, which could make it slightly less verifiable. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the clarity and conciseness of the paper by recommending a change in terminology from \"Evaluation\" to \"Metrics\" and suggesting a more streamlined presentation of the metrics. It offers actionable advice on how the authors can enhance the draft by aligning with standard practices and improving readability. While the comment is clear and provides a direct path for improvement, it could be more helpful if it included additional guidance on how to implement the suggestions or examples of how the metrics are used. Overall, the feedback is 4, as it offers valuable insights and actionable advice for the authors to consider."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific guidance or suggestions on how the authors might explore the dataset further. The comment lacks explicit instructions or concrete details on what aspects of the dataset should be investigated or how it could enhance the paper. As a result, the authors are left without a clear understanding of how to address this feedback, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this exploration should occur, leaving the authors uncertain about the exact location or scope of the suggestion. Additionally, the comment lacks specificity in terms of what aspects of the dataset should be explored or how it could enhance the paper. Without these details, the authors cannot confidently determine how to address the feedback. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why this suggestion is important or how it could be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on how the authors might explore the dataset further or what aspects of the dataset should be investigated. Without detailed suggestions or examples, the authors are left without actionable feedback on how to enhance their work. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance for the authors to address it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement, noting that the improvement is evident but difficult to characterize as remarkable. It implies that the authors should consider using more precise language to describe the results. However, the comment does not provide explicit guidance on how to implement this suggestion, such as specific examples of more objective terms or how to revise the text to achieve this. The action is implicit and somewhat vague, as the authors need to infer the need for more objective terms and how to apply it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section number 218, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting the use of more objective terms instead of \"remarkable\" to describe the accuracy improvement. This provides clear guidance on how to revise the text, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests using more objective terms instead of \"remarkable\" to describe the accuracy improvement, noting that the improvement is evident but difficult to characterize as remarkable. This claim is 3 as it provides a specific suggestion for improvement but lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the reasoning behind the suggestion and understand why \"remarkable\" is inappropriate in this context. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the use of the term \"remarkable\" in the paper, suggesting that it is subjective and could be replaced with more objective terms. It also points out that the improvement in accuracy is evident but difficult to characterize as remarkable, which is a valuable observation for the authors to consider. However, the comment could be more helpful if it provided examples of more objective terms or suggested how to revise the text to achieve this. While it offers a clear direction for improvement, the feedback is somewhat limited in its depth and specificity, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors consider using longer video sequences to better capture motion, color, and object changes. It also acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the previous stateoftheart. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"short video sequences\" and provides examples, such as \"16 frames,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, suggesting the use of longer video sequences to capture motion, color, and object changes. This provides clear guidance on how to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is interesting and extensive in its experiments, noting that the results are still not perfect but show improvement over the previous stateoftheart. However, the comment lacks specific evidence or references to support these claims, making it difficult for the authors to verify the accuracy or significance of the feedback. The reasoning is vague and does not provide detailed examples or justifications, which weakens the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides feedback on the use of short video sequences, suggesting that longer sequences might better capture motion, color, and object changes. It acknowledges the paper\"s interesting idea and extensive experiments, noting that the results are still not perfect but show improvement over the previous stateoftheart. However, the comment lacks specific guidance on how to implement the suggestion of using longer video sequences or what additional experiments could be conducted to address the identified weaknesses. While it offers some insight into potential improvements, the feedback is somewhat limited in its depth and actionable nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the current work, stating that it is not yet possible to realize efficiency gains on GPU, as is common in other work on pruning. However, it does not provide any specific guidance or suggestions on how the authors might address this limitation or improve their work. The comment lacks explicit actions or concrete details on how the authors can enhance their draft to overcome this issue. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It makes a general statement about the difficulty of realizing efficiency gains on GPU, which is a common issue in pruning work. However, it does not provide specific guidance or suggestions on how to address this limitation or improve the paper. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is not yet possible to realize efficiency gains on GPU, as is common in other work on pruning. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to substantiate the assertion, making it difficult for the authors to understand the basis of the claim or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the current work, noting that it is not yet possible to realize efficiency gains on GPU, a common issue in pruning research. However, the comment lacks specific guidance or suggestions on how the authors might address this limitation or improve their work. It does not provide actionable feedback or detailed insights into potential solutions or areas for enhancement. As a result, the comment is 2, as it offers a general observation without actionable advice for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two issues with the numerical evaluation: the use of synthetic data and the fairness of the comparison with a specific method. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to improve their evaluation or ensure a fair comparison. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the numerical evaluation of the paper, specifically mentioning the use of synthetic data and the comparison with a method from 5. It highlights that the evaluation is not fully convincing due to the use of synthetic data and that the comparison with 5 is not fair because 5 is designed for a more complex problem. However, the comment does not specify which part of the paper discusses the numerical evaluation or the comparison with 5. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to the parts of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the numerical evaluation is not fully convincing because it is based on synthetic data, and the comparison with 5 is not fair due to the different problem complexity. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide references or logical arguments to substantiate the assertion that the evaluation is not convincing or that the comparison is unfair. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment identifies two key issues with the numerical evaluation of the paper. First, it points out that the evaluation is based on synthetic data, which may not accurately reflect realworld scenarios. Second, it notes that the comparison with a specific method from 5 is not entirely fair because 5 is designed for a more complex problem, lacking knowledge of camera pose parameters. While the comment highlights these weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their evaluation. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment implies that the authors should consider the relevance of this experiment, it does not provide explicit guidance on how to address this question or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer the need for further analysis or discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion about the experiment\"s relevance, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. However, the comment lacks specific evidence or reasoning to support the claim that the experiment is unnecessary or how it might strengthen the paper. The authors are left to infer the relevance of the experiment, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the necessity of studying the impact of the number of bits in logits on robustness against a larger epsilon in a PGD attack. It suggests that this experiment might not be absolutely necessary but could strengthen the paper. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this concern or what additional experiments could be conducted to strengthen the paper. The feedback is 3 as it points out a potential area for further exploration, but it does not provide detailed actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the cost of insurance for men and women after the method is applied. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to provide a comprehensive analysis. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the cost of insurance for men and women after a method is applied, but it does not specify which part of the paper this question pertains to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity as it does not provide any details or context about the method or the insurance cost, leaving the authors without a clear understanding of what needs to be addressed. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the cost of insurance for men and women after a method is applied. However, it does not provide any context, reasoning, or references to support the question or its relevance to the paper. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the question or how it relates to the content of the paper. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the cost of insurance for men and women after a method is applied, but it does not provide any context, reasoning, or suggestions for how the authors might address this question. The comment lacks depth and specificity, leaving the authors without actionable guidance on how to improve their draft. Without additional information or direction, the feedback is minimal and does not significantly enhance the authors\" understanding or ability to revise their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the paper\"s categorization method, noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the practice of posting papers on arXiv earlier. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their categorization method. The action is implicit, as the authors would need to infer that they should consider the arXiv publication dates when categorizing the papers. The lack of concrete instructions or suggestions makes the action vague and difficult to implement. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the categorization of papers based on publication years on the ACL anthology, noting that many papers are posted on arXiv earlier. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in its critique, the lack of grounding makes it challenging for the authors to fully understand and address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s categorization method, which splits papers based on publication years on the ACL anthology, is inaccurate because many papers are posted on arXiv earlier. The reviewer provides an example, such as the BERT paper being available on arXiv before the ACL anthology. However, the comment lacks detailed reasoning or references to support the claim comprehensively. While the example provides some context, it does not fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s categorization method, specifically noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the practice of posting papers on arXiv earlier. The reviewer provides an example, such as the BERT paper being available on arXiv before the ACL anthology, which highlights the inconsistency in the categorization. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their categorization method. While it points out a potential problem, it lacks actionable advice, making it 3. The authors would need to infer that they should consider the arXiv publication dates when categorizing the papers, but the comment does not provide detailed guidance on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises two distinct points regarding the relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. For the first point, the comment questions the rationale behind not using importance sampling and suggests that the authors should clarify why they chose to use an arbitrary parameter \u03b2 instead of the true upper bound of the ratio p/q. This provides a clear and explicit action for the authors to take, as they need to explain their reasoning and potentially provide examples to support their choice. For the second point, the comment highlights a lack of clarity in the differences between QRS and RS, specifically questioning how the algorithm behaves differently for certain values of u. This is also an explicit action, as the authors need to clarify the distinction between these two methods. Both points are concrete and provide clear guidance on how the authors can improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment addresses two distinct issues: the relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. However, it does not specify which sections or parts of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues and asking for clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two questions about the methodology and algorithm used in the paper. The first question asks why the authors did not directly use importance sampling instead of relaxing rejection sampling with an arbitrary parameter \u03b2. The second question questions the differences between QRS and RS in Algorithm 1, specifically asking for a value of u where they behave differently. While the questions are clear and specific, they do not provide any supporting evidence or reasoning to justify the authors\" choices or to clarify the differences between the methods. The lack of detailed explanation or references makes it difficult for the authors to address these questions effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises two distinct points that could be helpful for the authors to address. First, it questions the rationale behind using an arbitrary parameter \u03b2 in the relaxation of rejection sampling instead of directly using importance sampling. This raises a valid concern that could help the authors clarify their methodological choices and potentially strengthen their argument. Second, the comment points out a lack of clarity regarding the differences between QRS and RS in Algorithm 1, specifically questioning how the algorithm behaves differently for certain values of u. This feedback is valuable as it highlights an area where the authors could provide more detailed explanations or examples to improve the clarity and understanding of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and specificity in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment lacks specific guidance on how to refine the performance or what aspects of the future work need improvement. Without concrete suggestions or actionable steps, the authors are left without a clear path to follow. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not specify which part of the paper this observation pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment is somewhat specific in that it suggests future refinement, but without detailed guidance on what aspects to focus on, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest, suggesting room for further refinement in the future. However, the comment lacks specific evidence or examples to support this claim. It does not provide any references or detailed reasoning to substantiate the assertion that the enhancements are modest. Without such evidence, the claim remains unsubstantiated and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how to achieve this refinement or what aspects of the work could be improved. The comment lacks actionable advice, leaving the authors without a clear path to enhance their draft. As a result, the feedback is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230234 and 234235. It also points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. These instructions are clear and direct, allowing the authors to know exactly what needs to be addressed. The comment is fully actionable as it provides specific guidance on where to add references and clarify terminology. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2, lines 230234 and 234235,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed: providing references for two passages and clarifying the term \"MLP\" in Figure 2. This level of detail ensures that the authors understand exactly what revisions are required. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point contains claims that require verification. It suggests that the authors should provide references for specific passages in Section 3.2, lines 230234 and 234235, and clarify the term \"MLP\" in Figure 2. However, the comment lacks specific examples or detailed reasoning to support these claims, making it 3. The authors would need to infer the need for references and clarification, which could be improved with more detailed guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback by requesting references for two passages in Section 3.2, lines 230234 and 234235. It also points out that the term \"MLP\" is not described in the paper, specifically in Figure 2. This feedback is clear and actionable, as it directs the authors to specific areas where they need to provide additional context or clarification. By addressing these points, the authors can improve the completeness and accuracy of their paper. The comment is 4 as it offers clear guidance but could be more comprehensive if it suggested specific ways to find or include the references. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the experimental setup. The action is implicit, as the authors are left to infer that they need to investigate the similarity in performance and potentially refine their experiments. The lack of concrete steps or detailed guidance makes the comment 3.", "grounding_specificity_rationale": "The comment addresses the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment does not specify which part of the paper these datasets are associated with, making it weakly grounded. The comment is specific in identifying the issue with the experimental results, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental results on the last two datasets are not convincing enough to validate the effectiveness of the proposed method, as the performance is similar to IRM. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it difficult to understand why the results are not convincing or how the similarity to IRM impacts the effectiveness of the proposed method. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a concern regarding the experimental results on the last two datasets, noting that the performance is similar to IRM, which raises questions about the effectiveness of the proposed method. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their experimental setup. While it points out a potential weakness, it does not provide actionable steps or detailed insights to help the authors enhance their work. Therefore, the comment is 3, as it highlights an area for improvement but does not offer comprehensive guidance. The score aligns with a rating of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long entity is known. However, it does not provide explicit guidance on how the authors should address this question or what changes might be necessary in their draft. The action is implicit, as the authors need to infer that they should consider the implications of detecting both entities and compare it to a simpler scenario. The comment lacks concrete details on how to implement this suggestion, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. Additionally, it does not provide specific guidance on what needs to be addressed or how the authors should respond to the question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. This is a question that seeks clarification and understanding, rather than making a claim that requires verification. The comment does not contain any subjective opinions, suggestions, or judgments, aligning with the classification of \"No\". Therefore, the comment is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the rationale behind detecting both entities in Figure 2 and asks for a comparison with a scenario where only the long entity is known. This question prompts the authors to consider the implications of their detection method and its potential differences from simpler scenarios. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or improve their draft. While it identifies an area for clarification, it does not offer actionable feedback that would significantly enhance the authors\" understanding or the quality of their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of empirical validation in the paper and suggests that the authors would like to see experiments where the bounds are validated. However, the comment does not provide explicit guidance on how to conduct these experiments or what specific aspects of the bounds need to be validated. The action is implicit, as the authors can infer that they need to add empirical validation, but the lack of detail makes it vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of empirical validation, which is a specific aspect of the paper. It also suggests that the authors would like to see experiments where the bounds are validated, providing a clear direction for improvement. However, the comment does not specify which part of the paper lacks empirical validation or what specific aspects of the bounds need to be validated. This makes the comment specific but not fully specific. Therefore, it aligns with category 4.", "verifiability_rationale": "The review point claims that the paper lacks empirical validation, suggesting that the authors would like to see experiments where the bounds are validated. However, the comment does not provide any specific examples, references, or reasoning to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of empirical validation. It suggests that the authors would benefit from including experiments that validate the bounds discussed in the paper. This feedback is clear and actionable, as it provides a specific direction for improvement. However, the comment could be more helpful if it offered guidance on how to conduct these experiments or what specific aspects of the bounds need validation. Despite this, the comment is 4 as it highlights a crucial area for improvement that would enhance the paper\"s credibility and impact."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about a specific aspect of Theorem 1, questioning the validity of an assumption regarding a node with 0 neighbors. While the reviewer identifies a potential issue with the theorem, the comment does not provide explicit guidance or suggestions on how to address this concern. The authors are left to infer that they need to clarify or correct the theorem, but the lack of concrete steps or detailed explanations makes the action implicit and vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about a specific aspect of Theorem 1, focusing on a potential issue with an assumption regarding a node with 0 neighbors. However, it does not specify which part of the paper this theorem is located in, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its critique of the theorem but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the validity of Theorem 1, specifically questioning the assumption that a node with 0 neighbors results in an upper bound of 0. While the reviewer expresses a concern, the comment lacks detailed reasoning or examples to substantiate the claim. It does not provide specific references or logical arguments to support the assertion that this assumption is incorrect or needs clarification. As a result, the claim is 3, as it is based on a subjective observation without sufficient evidence or justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about a potential issue with Theorem 1, particularly concerning the assumption that a node with 0 neighbors results in an upper bound of 0. This question highlights a potential area of confusion or error in the theorem, which could hinder the authors\" understanding or the validity of their results. However, the comment does not provide any suggestions or guidance on how to address this issue or clarify the theorem. Without actionable feedback or detailed explanations, the authors are left without a clear path to improve their work. Therefore, the comment is 2, as it identifies a problem but lacks the necessary depth and guidance to be fully beneficial."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the Discussion section of the paper, noting that the training time reduction is less drastic than the parameter reduction due to the computation of gradients for early downsampling layers. However, it does not provide explicit guidance on how the authors should address this issue or what changes need to be made to the Discussion section. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Pg.5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that the training time reduction is less drastic than the parameter reduction due to the computation of gradients for early downsampling layers. This provides clear guidance on what aspect of the Discussion section requires attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training time reduction is less drastic than the parameter reduction because most gradients are still computed for early downsampling layers. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the Discussion section, noting that the training time reduction is less drastic than the parameter reduction due to the computation of gradients for early downsampling layers. While the comment points out a potential inconsistency or area for clarification, it does not provide actionable guidance on how the authors might address this issue or what changes could be made to the Discussion section. The feedback is 3 as it highlights a specific area that needs attention, but it lacks depth and does not offer suggestions for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. While it prompts the authors to consider this aspect, it does not provide explicit guidance on how to address it or what changes might be necessary. The action is implicit, as the authors need to infer that they should explore the broader applicability of their work. However, the comment lacks concrete details on how to implement this exploration, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it lacks specific references or context. Additionally, it does not provide detailed guidance on how to address the question or what changes might be necessary. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors understand or address the issue. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment raises a question about the applicability of the problem to other downstream tasks or if it is specific to binding affinity prediction. This question prompts the authors to consider the broader context and potential applications of their work. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address this question or what changes might be necessary. While it identifies an area for improvement, it does not offer actionable feedback that would empower the authors to enhance their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper by noting that while it mentions the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions. The comment suggests that the paper should explore why GPTgenerated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not specify how the authors should address this issue or what kind of analysis or solutions they should propose. The action is implicit and vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the handling of rumors generated by GPT, specifically noting that the paper mentions the challenges of detecting such rumors but lacks further analysis or solutions. It questions why GPTgenerated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the issue of the difficulty in detecting GPTgenerated rumors compared to natural ones, but without explicit references to sections or figures, the authors may need to infer the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difficulty of detecting GPTgenerated rumors compared to natural rumors, suggesting that the paper does not provide a clear analysis or explanation for this phenomenon. It implies that the experimental results might be counterintuitive, as artificial rumors, being written by humans, should be as difficult to detect as natural rumors. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the paper does not address this issue. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern raised. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that while it acknowledges the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions. The comment questions why GPTgenerated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. This raises a valid concern that the paper does not address, and it suggests that the authors should explore this issue further. However, the comment lacks specific guidance or suggestions on how to analyze or address this concern, making it 3. The feedback is clear and identifies an area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. While the comment identifies a potential issue with the technical contribution, it does not provide explicit guidance on how the authors should address this limitation or what specific aspects of the section need improvement. The action is implicit, as the authors would need to infer that they should consider a more formal and principled approach to enhance the technical contribution. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This claim is 3 as it provides a specific example of a limitation in the technical contribution, but it lacks detailed reasoning or references to support the claim. The authors would need to infer the basis of this claim, which could be improved by providing more context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the technical contribution of the paper, specifically pointing out that Section 4 focuses on heuristics rather than a formal and principled solution. This feedback is clear and actionable, as it highlights a specific area where the authors could enhance the rigor and depth of their work. By emphasizing the need for a more formal approach, the comment provides a clear direction for improvement, allowing the authors to address the identified weakness. However, the comment could be more helpful if it suggested specific ways to incorporate a formal solution or provided examples of how to achieve this. Overall, the comment is 4, as it offers a clear and actionable critique that guides the authors toward enhancing their technical contribution."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that the font size in Figure 6 is small, which could be a minor issue. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the font size or what specific changes are needed. Without actionable steps, the authors are left without a clear path to resolve the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies an issue with the font size in Figure 6, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the font size in Figure 6 is small. While this is a factual observation, the comment does not provide any reasoning or justification for why this is an issue or how it affects the paper. Without additional context or explanation, the authors may find it difficult to understand the significance of this observation or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a minor issue with the font size in Figure 6, which could affect the readability of the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve the figure. Without actionable advice or detailed feedback, the comment is 3 as it highlights a potential area for improvement, but it does not provide substantial assistance for the authors to enhance their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a regret about the limited exploration of the probability mass function in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the context of Boosted Decision Trees (BDT) of different depths. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to incorporate different probability mass functions into their experiments. The suggestion is vague and lacks concrete details, making it difficult for the authors to understand how to implement it. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MixBoost\" and \"probability mass function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the probability mass function is practically unexploited and suggests considering various distributions to add depth to the experimental setting. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, it aligns with category 5.", "verifiability_rationale": "The review point expresses a regret about the limited exploration of the probability mass function in the paper, specifically mentioning that it is practically unexploited. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the context of Boosted Decision Trees (BDT) of different depths. However, the comment lacks specific examples or references to support the claim that the quasiuniform distribution is wellsuited or why exploring other distributions would be beneficial. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the probability mass function is practically unexploited in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the context of Boosted Decision Trees (BDT) of different depths. However, the comment does not provide specific guidance on how the authors might explore different probability mass functions or what specific experiments could be conducted to address this issue. While it offers a direction for improvement, the lack of detailed suggestions or examples makes it 3. The authors would need to infer how to implement the suggested changes, which limits the comment\"s full impact. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include missing references, specifically mentioning a relevant work a that discusses supervised learning in QBF solving. It also provides a brief explanation of the relevance of this work, stating that it generalizes SMT. The comment is clear and direct, providing the authors with a specific action to take: include the suggested reference and discuss its connections to their work. This level of detail makes the comment 5, as it clearly outlines what needs to be done and how to implement it. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the relevance of a specific work a to the topic of the paper, allowing the authors to accurately identify the part of the paper that needs attention. It also specifies what needs to be addressed by discussing the connections between the suggested work and the authors\" topic. This provides clear guidance on how to incorporate the missing references and improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is missing relevant references, specifically mentioning a work a that discusses supervised learning in QBF solving. The comment provides a brief explanation of the relevance of this work, suggesting that it generalizes SMT. However, it does not offer detailed reasoning or examples to support why this specific reference is crucial for the paper. The lack of detailed justification or examples makes the claim 3, as the authors may need to infer the importance of the missing reference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of relevant references, specifically mentioning a work a that discusses supervised learning in QBF solving. This is a crucial area for the paper to address, as it generalizes SMT, a concept central to the authors\" topic. The comment provides a clear and actionable suggestion for the authors to include this reference and discuss its connections to their work. By doing so, the authors can strengthen the paper\"s relevance and comprehensiveness. The feedback is specific and constructive, offering a clear direction for improvement, making it 5 for the authors. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the draft to include such a comparison. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison is intended for or how it relates to the content of the draft. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the comparison or what aspects of the paper need to be revised. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the comparison of computation cost or running time, but it does not provide any specific claims, opinions, or suggestions. It is a factual question that does not require verification or justification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect for evaluating the efficiency and practicality of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or incorporate such a comparison into their draft. Without specific advice or suggestions, the authors are left without actionable feedback, making the comment unhelpful. Therefore, the comment aligns with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This provides a clear and specific action for the authors to take, guiding them on how to improve the paper by focusing on different types of problems. The comment is explicit and concrete, as it directly instructs the authors on what to address and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on what the authors should focus on, suggesting alternative examples of problems that require interprocess communication. The comment specifies the need to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This provides a clear direction for the authors to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the paper\"s goal in the introduction, suggesting that the examples provided do not effectively convey the need for interprocess communication. The reviewer offers an alternative suggestion for focusing on problems where the loss function does not decompose as the sum of sample losses, which is a specific and actionable suggestion. However, the comment lacks detailed reasoning or examples to fully support the claim that the current examples are insufficient. While the suggestion is logical, the lack of detailed justification makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a lack of clarity in the paper\"s goal in the introduction and provides specific suggestions for improvement. The reviewer points out that the examples chosen do not effectively convey the need for interprocess communication, particularly in the context of samplingbased Bayesian methods. The suggestion to focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms, such as Hogwild, is clear and actionable. This feedback provides the authors with a concrete direction to enhance the paper\"s clarity and relevance. However, the comment could be more helpful if it included additional examples or a more detailed explanation of why the current examples are insufficient. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the privacypreserving nature of the proposed approach compared to other federated learning methods and suggests that privacy preservation might be an issue in traffic signal control. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address these questions or improve their draft. As a result, the authors are left without a clear understanding of what steps to follow to enhance their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the privacypreserving nature of the proposed approach compared to other federated learning methods and suggests that privacy preservation might be an issue in traffic signal control. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact sections being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. It is also not specific because it does not detail what needs to be addressed or how the authors might respond to these questions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the privacypreserving nature of the proposed approach compared to other federated learning methods and suggests that privacy preservation might be an issue in traffic signal control. However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples to substantiate the concerns raised, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises questions about the privacypreserving nature of the proposed approach compared to other federated learning methods and suggests that privacy preservation might be an issue in traffic signal control. It questions whether one traffic signal should not know the color of the next one, implying a potential issue with privacy. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their draft. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. The authors are left with a general idea of what to consider but without concrete steps to take, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point indicates that the hyperlinks for footnote 3 and 4 are not working. This is a clear and explicit action that the authors can take to address the issue. The comment provides a direct instruction on what needs to be done, making it 5. The authors know exactly where the problem lies and how to fix it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the hyperlink functionality, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point states that the hyperlink for footnote 3 and 4 does not work. This is a factual observation that requires no further verification or explanation. The comment is purely descriptive and does not contain any subjective opinions or suggestions. Therefore, it is classified as \"No\"", "helpfulness_rationale": "The review comment points out a specific issue with the formatting of the paper, noting that the hyperlinks for footnote 3 and 4 are not working. This is a clear and actionable feedback that the authors can easily address by ensuring the links are functional. The comment is concise and provides a direct suggestion for improvement, making it 5 for the authors. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests revising the discussion, particularly in the modeling section, as it is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is explicit in its suggestions and provides concrete details on how the authors can improve the discussion. It instructs the authors to revise the section and clarify the role of Label Embeddings, which are described as external parameters but seem to be the output of the encoder in the figure. This level of detail allows the authors to understand exactly what needs to be addressed and how to implement the changes. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is fully grounded as it explicitly mentions the modeling section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what needs to be addressed, such as the formalization of the architecture and the clarification of the Label Embeddings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests revising the discussion, particularly in the modeling section, which is not clear enough. It provides specific examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is 4 as it offers clear reasoning and examples of what needs to be addressed, such as the formalization of the architecture and the clarification of the Label Embeddings. However, it could be more robust with additional references or detailed explanations to fully substantiate the claims. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and organization of the discussion, particularly in the modeling section. It suggests revising the section to enhance its clarity and provides concrete examples, such as the need for a better formalization of the architecture in section 2 and a clarification regarding the Label Embeddings. The comment is 4 as it offers actionable suggestions and detailed examples that guide the authors on how to improve their draft. However, it could be more comprehensive if it included additional feedback on other sections or aspects of the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. While it implies that the authors should consider this possibility, it does not provide explicit guidance on how to implement or explore this suggestion. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the comment. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is relevant or beneficial. The comment lacks depth and does not offer a clear justification for the proposed change, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the model\"s limitation to CTC loss and suggests exploring attentionbased encdec training. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement or explore this idea. The comment is 3 as it points out a potential limitation and encourages the authors to consider alternative approaches, but it does not provide detailed feedback or actionable steps to address the issue. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the mitigation methods or how they could ensure that the image generation capabilities are not negatively impacted. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it is addressing. It mentions \"mitigation methods affect the image generation capabilities of diffusion models,\" but it does not provide context or references to specific sections, tables, or figures. The comment is also not specific because it does not detail what needs to be addressed or how the authors should approach the issue. Therefore, this comment is 1 and not specific, aligning with category 1.", "verifiability_rationale": "The review point claims that the mitigation methods affect the image generation capabilities of diffusion models, potentially leading to lower image quality. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the mitigation methods affecting the image generation capabilities of diffusion models, which could lead to lower image quality. However, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The comment lacks actionable advice, leaving the authors without a clear path to enhance their work. As a result, the feedback is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure fair comparisons. The action is implicit and vague, as it does not specify how the authors can mitigate the risk of information leakage or how they should adjust their experimental setup. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the comparisons with existing SSL methods. This lack of grounding makes it difficult for the authors to identify the exact sections that need attention. While the comment is specific in its critique, the absence of explicit references to the paper\"s sections limits its effectiveness. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the concerns raised. Therefore, the comment is considered 2, as it lacks sufficient justification to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential risk that the pretrained visual model and target dataset might leak additional information, skewing results and leading to unfair comparisons. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or ensure fair comparisons. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as 2, as it offers some insight but lacks depth and practical guidance for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit suggestions for improvement or clarification. The authors are left without guidance on how to address this observation or what might be causing it. As a result, the comment lacks actionable feedback, making it 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the reviewer is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what is surprising or how the dominance of function words over content words might be addressed. Without this information, the authors cannot confidently understand the basis of the comment or how to respond to it. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which is followed by a question about the reviewer\"s understanding. While the observation is based on a subjective interpretation of the content, the comment lacks specific evidence or reasoning to support the claim. The authors are left without a clear understanding of why this observation is surprising or what it implies. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which is followed by a question about the reviewer\"s understanding. While the comment highlights an interesting aspect of the content, it does not provide specific feedback or suggestions on how this observation might be addressed or improved. The authors are left without actionable guidance on how to respond to this comment or what changes might be necessary. Therefore, the comment is 2, as it lacks depth and direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is explicit and provides a clear action for the authors to take, which is to define the FLOT cost matrix in the algorithm. The comment is concrete as it specifies exactly what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of definition for the FLOT cost matrix in Algorithm 1. This provides the authors with a clear understanding of what needs to be addressed to improve the paper.", "verifiability_rationale": "The review point claims that the FLOT cost matrix in Algorithm 1 is not defined. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the FLOT cost matrix in Algorithm 1 is not defined. This feedback is clear and actionable, as it directly points out a missing element that needs to be addressed. By defining the FLOT cost matrix, the authors can improve the clarity and completeness of their algorithm description. However, the comment could be more helpful if it provided additional context or suggestions on how to define the cost matrix effectively. Overall, the comment is 3 as it highlights a crucial aspect that needs attention, but it lacks depth in terms of guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the convergence of a bound in Theorem 2, specifically concerning the second term in Eq. (30). It notes that a similar bound in Grunewalder et al, 2010, Eq. (27), does converge to 0, but it is not trivial to prove that the second term in Eq. (30) also converges to 0. The comment suggests that the authors prove this, but it does not provide explicit guidance on how to approach the proof or what specific steps to take. While the action is implied, it is vague and lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 2, Eq. (30)\" and \"Eq. (27)\" from Grunewalder et al, 2010, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the bound in Theorem 2, Eq. (30), particularly regarding the convergence of the second term as T approaches infinity. The comment requests proof of this convergence, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the convergence of a bound in Theorem 2, specifically concerning the second term in Eq. (30). It notes that a similar bound in Grunewalder et al, 2010, Eq. (27), does converge to 0, but it is not trivial to prove that the second term in Eq. (30) also converges to 0. The comment suggests that the authors prove this, but it does not provide specific examples or references to support the claim that the second term does not converge to 0. While the reasoning is logical, the lack of detailed justification or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the convergence of a bound in Theorem 2, Eq. (30), noting that a similar bound in Grunewalder et al, 2010, Eq. (27), does converge to 0. It highlights that the second term in Eq. (30) does not trivially converge to 0 and requests the authors to prove this. The comment is clear and actionable, providing a specific area for the authors to address and improve their work. However, it could be more helpful if it offered additional guidance or suggestions on how to approach the proof. Overall, the comment is 4, as it effectively directs the authors to a critical aspect of their work that needs further attention."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the specific definition of the sparsity of the residual term in the paper, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. While the comment explicitly asks for clarification and provides a clear direction for the authors to address the issue, it lacks concrete guidance on how to demonstrate the advantages of the proposed method or how to provide evidence for the sparsity assumption. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the specific issue of the sparsity of the residual term in the paper, which is a clear and specific concern. It questions the definition of sparsity and requests evidence to support the assumption across various noisy cases. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the specific definition of the sparsity of the residual term, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. While the comment raises a valid point about the need for clarification and evidence, it lacks specific examples or references to support the claim that the sparsity assumption is not welljustified. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the definition of the sparsity of the residual term in the paper. It questions whether the term implies the inclusion of many zero elements and requests evidence to support the sparsity assumption across various noisy cases. Additionally, the comment suggests that the authors should demonstrate the advantages of their proposed method compared to existing methods. This feedback is clear and actionable, providing the authors with specific areas to address and improve their work. However, it could be more helpful if it included more detailed guidance on how to demonstrate the advantages of the proposed method or provide examples of noisy cases where the sparsity assumption holds. Overall, the comment is 4, as it offers valuable insights and directions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of the term \"connectivity\" in the paper, arguing that it is misleading because it does not reflect the structural connections between the brain and body. However, the comment does not provide any specific guidance or suggestions on how the authors should revise or clarify their use of the term. The action is implicit, as the authors would need to infer that they should reconsider the terminology to accurately represent the content of their work. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the use of the term \"connectivity\" in the paper, arguing that it is misleading because it does not reflect the structural connections between the brain and body. However, the comment does not specify which part of the paper uses the term \"connectivity\" or provide any examples of how it is used. This makes it difficult for the authors to identify the specific section or parts of the paper that need revision. Additionally, the comment does not specify what should be done to address the issue of misleading terminology. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the term \"connectivity\" is misleading because it does not reflect the structural connections between the brain and body. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains 3, as it is based on a subjective interpretation of the term. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"connectivity\" in the paper, suggesting that it is misleading because it does not reflect the structural connections between the brain and body. While the comment highlights a specific concern, it does not provide detailed guidance or suggestions on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It also directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which implies that this section contains more detailed feedback. However, the comment does not explicitly instruct the authors on what specific aspects of the paper need improvement or how to address the issues mentioned. The action is implicit and somewhat vague, as the authors need to infer that they should focus on the missing details and improve the polish of the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which provides a clear indication of the areas needing attention. However, the comment does not specify which parts of the paper are missing details or require improvement, making it weakly grounded. The comment is specific in identifying the need for polish and addressing issues in related work, experiments, and writing, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that this section contains more detailed feedback. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is not polished or lacks details. Without concrete examples or references, the authors may find it challenging to understand the specific issues that need to be addressed. Therefore, the claim is 3, as it provides a general direction but lacks sufficient detail to fully support the feedback.", "helpfulness_rationale": "The review comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which implies that this section contains more detailed feedback. However, the comment does not provide specific examples or actionable suggestions for improvement, such as what aspects of the paper need clarification or how the authors can enhance the polish. While it identifies a general area for improvement, the lack of detailed guidance makes it 3, as the authors may need to infer the specific areas that require attention. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the methodology, suggesting that the authors should study the importance of orthogonal matrix weights in their model. It implies that the current approach might be unnecessary and that a deeper analysis of the necessity of orthogonal matrices is needed. However, the comment does not provide explicit guidance on how to conduct this study or what specific aspects of the model should be examined. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the methodology of the paper, specifically mentioning the use of orthogonal matrix weights and the potential redundancy of steps 2 and 3. It suggests that the authors should study the importance of orthogonal matrix weights, implying that the current approach might be unnecessary. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact area of concern. The comment is specific in its suggestion to study the importance of orthogonal matrix weights, but without clear grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a claim about the potential redundancy of steps 2 and 3 in the methodology, suggesting that the importance of orthogonal matrix weights might be overstated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the current approach might be unnecessary. Without concrete evidence or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically suggesting that steps 2 and 3 might be redundant and that the importance of orthogonal matrix weights could be overstated. It implies that the authors should study the necessity of orthogonal matrix weights to validate their use. However, the comment lacks specific guidance on how to conduct this study or what aspects of the model should be examined. While it points out a potential area for improvement, the feedback is somewhat vague and could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the accuracy drop observed in Figure 5 after a certain order of around 45, specifically questioning whether it is due to overfitting. While the comment prompts the authors to consider this possibility, it does not provide explicit guidance on how to address the issue or what steps to take to improve the draft. The action is implicit, as the authors need to infer that they should investigate the cause of the accuracy drop and consider whether it is due to overfitting. However, the comment lacks concrete details on how to conduct this investigation or what specific actions to take. Therefore, the comment is 3, as it provides a clear direction but lacks detailed guidance on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for the accuracy drop observed in the figure, specifically asking whether it is due to overfitting. This provides clear guidance on what needs to be addressed in the figure or the discussion related to it. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically questioning whether it is due to overfitting. While the comment prompts the authors to consider this possibility, it does not provide any evidence, reasoning, or references to support the claim that overfitting might be the cause. Without additional context or justification, the authors are left to make their own judgments or seek further clarification. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the accuracy drop observed in Figure 5 after a certain order, specifically questioning whether it is due to overfitting. This feedback is 3 as it prompts the authors to consider the potential reasons for the observed behavior and to investigate the issue further. However, the comment lacks detailed guidance or suggestions on how to address the problem or what steps to take to improve the draft. While it identifies a potential area for improvement, it does not provide actionable advice or specific recommendations, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the toylike nature of the models and datasets used in the paper, suggesting that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small should be considered. The comment also questions the feasibility of experimenting on language tasks. While the comment implies that the authors should address these issues, it does not provide explicit instructions or detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises concerns about the models and datasets used in the paper, suggesting that they are too toylike. It specifically mentions the need to include more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small. However, the comment does not specify which part of the paper discusses the models and datasets, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the types of datasets that should be included, it lacks full grounding as it does not provide explicit references to sections or figures. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toylike and that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViTtiny or small should be considered. However, the comment does not provide specific reasoning or examples to support why these datasets are necessary or how they would improve the paper. Without detailed justification or references, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper by pointing out that the models and datasets used are too simplistic. It suggests that the authors should consider using more challenging datasets, such as CIFAR100, ResNet 34 or 50, and ViTtiny or small, to better evaluate their models. Additionally, the comment raises a question about the feasibility of experimenting on language tasks, which could be a valuable point for discussion. However, the comment lacks depth and does not provide specific guidance or suggestions on how to address these issues. While it highlights an important area for improvement, the feedback is somewhat limited in its scope and actionable, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises two main concerns: the absence of consideration for Vision Transformer in the experiment and the uncertainty of its effectiveness on larger datasets like ImageNet. It also questions whether the pruning strategy might differ in selfattention layers. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to incorporate Vision Transformer into their experiments or explore its performance on larger datasets. The suggestions are vague and lack concrete details, making it difficult for the authors to understand how to implement them. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also inquires about the potential differences in pruning strategies for selfattention layers. However, the comment does not specify which part of the paper discusses the experimental setup or the results related to image classification, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific about the concerns regarding Vision Transformer and larger datasets, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the absence of consideration for Vision Transformer in the experiment and questions its effectiveness on larger datasets like ImageNet. It also asks about the potential differences in pruning strategies for selfattention layers. However, the comment lacks specific evidence, examples, or references to support these claims. Without detailed reasoning or references, the authors may find it challenging to understand the basis of these concerns and how to address them. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental setup by noting the absence of consideration for Vision Transformer, a stateoftheart model in image classification. It also raises questions about the effectiveness of the pruning strategy on larger datasets like ImageNet, which is crucial for understanding the scalability of the proposed method. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or what experiments could be conducted to explore the effectiveness of Vision Transformer and the pruning strategy. While it highlights important areas for improvement, the feedback is somewhat limited in its actionable and detailed nature, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. The comment implies that the authors should include such metrics to substantiate their claims of efficiency. However, the action is implicit, as the authors need to infer that they should report metrics to demonstrate efficiency. The action is also somewhat vague, as it does not specify which metrics should be reported or how they should be presented. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the advantages of their proposed method over previous work in terms of efficiency. This allows the authors to accurately identify the section being addressed. The comment is also specific because it points out a lack of reporting of metrics that would demonstrate the efficiency of the proposed method. This provides clear guidance on what needs to be addressed to strengthen the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not report any metric that shows the proposed method is more efficient to train compared to previous work. This claim is 3 as it highlights a gap in the paper\"s reporting of efficiency metrics. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand exactly what metrics are missing or how to address this issue. The lack of detailed reasoning or examples makes the claim 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. This feedback is valuable as it directs the authors to include quantitative evidence that substantiates their claims of efficiency. By highlighting this omission, the comment encourages the authors to enhance the rigor and persuasiveness of their paper. However, the comment could be more helpful if it suggested specific metrics or types of metrics that would be appropriate to include. Overall, the feedback is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point requests the authors to provide more details about the statespace, actions, and the space of theta. While the authors can infer that they need to clarify these aspects, the comment does not explicitly instruct them to do so. The request for more details is clear, but the action of providing these details is implicit, making the comment 3. The lack of explicit guidance on how to present these details leaves some ambiguity, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific part of the paper, L81, allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the details regarding the statespace, actions, and the space of theta. The request for more details and clarification is clear and actionable, providing the authors with a precise understanding of what needs to be addressed. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point requests more details about specific aspects of the paper, such as the statespace, actions, and the space of theta. While the request is clear and specific, it does not contain any subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with a score of \"No\".", "helpfulness_rationale": "The review comment is 4 as it identifies specific areas where the authors could provide more details, such as the nature of the statespace, actions, and the space of theta. By requesting these details, the comment encourages the authors to clarify their methodology and assumptions, which is crucial for improving the clarity and rigor of their work. However, the comment could be more helpful if it provided additional guidance on how to present these details or suggested specific ways to enhance the clarity of the paper. Overall, the feedback is actionable and constructive, making it a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the method\"s performance on general reasoning tasks or what changes could be made to enhance its effectiveness. As a result, the authors are left without a clear understanding of what steps to undertake to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, it does not specify which part of the paper this claim is based on, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its critique of the method\"s performance but lacks grounding as it does not provide explicit references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method does not work very effectively on general reasoning tasks compared to mathematical reasoning. However, the comment lacks specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the method\"s performance on general reasoning tasks compared to mathematical reasoning. While it highlights an area for improvement, it lacks specific details or suggestions on how the authors might address this issue. The comment is 3 as it points out a limitation that could be addressed, but it does not provide actionable guidance or examples of how to enhance the method\"s effectiveness on general reasoning tasks. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The authors acknowledge this in Section 3, where they mention the inapplicability of Theorem 1 due to normalization. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. While the authors are aware of the problem, the comment lacks actionable steps or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the reliance on a special case where a contradiction arises as matrix norms approach infinity. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. However, the comment does not provide specific examples or detailed reasoning to support this claim. While the authors mention the inapplicability of Theorem 1 due to normalization, the comment lacks a thorough explanation of how this affects the proof technique. Without additional context or examples, the claim is 3, as it is based on logical reasoning but lacks sufficient detail to fully substantiate the assertion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The authors acknowledge this in Section 3, where they mention the inapplicability of Theorem 1 due to normalization. However, the comment does not provide actionable guidance or suggestions on how the authors might address this issue or improve their proof technique. While it highlights a potential weakness, it lacks depth and does not offer constructive feedback to help the authors enhance their work. Therefore, the comment is 2, as it identifies a problem but does not provide sufficient direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. It also expresses a concern that allowing \"t\" to be arbitrary does not add value. While the comment provides a specific suggestion for improvement, it does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment addresses the histogram intersection kernel and suggests replacing \"t\" with the size of T for clarity. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion regarding the clarity of the notation, but without explicit references to the paper, the authors may find it challenging to pinpoint the exact section. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests replacing \"t\" with the size of T in the histogram intersection kernel for clarity. However, it does not provide any reasoning, examples, or references to support why this change would be beneficial or how it would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion and whether it is a valid improvement. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the clarity of the histogram intersection kernel by replacing \"t\" with the size of T. This feedback is actionable and directly addresses a potential area of confusion for the authors. However, the comment lacks broader context or suggestions for other areas that could be improved, which limits its overall impact. While it offers a clear and constructive suggestion, it does not provide a comprehensive guide for enhancing the draft, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, particularly when class labels correlate more with semantics than geometry. It suggests that the image encoder may struggle to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or what specific aspects of their model could be improved. The action is implicit and vague, as it does not offer concrete steps for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, particularly when class labels correlate more with semantics than geometry. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being discussed. The comment is specific in its questioning of the model\"s ability to handle semantic concepts, but it lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, particularly when class labels correlate more with semantics than geometry. It questions whether the image encoder can produce meaningful embeddings for new concepts in such cases, especially for concepts where class labels correlate more with semantics rather than geometry. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the image encoder may struggle with this issue. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the adaptation capacity of the proposed visual memory to accommodate evergrowing concepts, particularly when class labels correlate more with semantics than geometry. It specifically questions whether the image encoder can produce meaningful embeddings for new concepts in such cases, especially for concepts where class labels correlate more with semantics rather than geometry. This feedback highlights a potential limitation or area for improvement in the model\"s ability to handle semantic concepts. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or what specific aspects of their model could be improved. While it identifies a potential weakness, it does not provide concrete steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the paper, including confusion due to the use of undefined notation (M and N), suggesting that the authors spell out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be crossreferenced. The actions are explicit and concrete, as the authors know exactly what needs to be done to address each issue. For example, the suggestion to spell out F.L.T.R in Figure 4 is clear and actionable, and the recommendation to crossreference notation and figures provides a specific direction for improvement. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses issues with notation in the paper, specifically mentioning that M and N are used without definition. It also suggests improvements such as spelling out F.L.T.R in Figure 4, noting that the text in Figure 1 is too small to see, and recommending that notation and figures be crossreferenced. However, the comment does not specify which part of the paper these issues are located in, making it weakly grounded. The suggestions are specific and provide clear guidance on how to improve the paper, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of notation in the paper, specifically mentioning that M and N are used without definition. It also suggests improvements such as spelling out F.L.T.R in Figure 4 and noting that the text in Figure 1 is too small to see. Additionally, the comment recommends crossreferencing notation and figures. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is 3 as it provides some guidance but lacks detailed evidence or examples to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, including the confusion caused by undefined notation (M and N) and suggestions for enhancing the clarity of figures and text. It provides specific recommendations, such as spelling out F.L.T.R in Figure 4 and noting that the text in Figure 1 is too small to see. Additionally, the comment suggests that notation and figures should be crossreferenced, which is a clear and actionable piece of feedback. While the comment could be more detailed, it offers valuable insights and guidance that would help the authors improve their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this issue, such as suggesting alternative notations or clarifying the usage of $p$. The action is implicit and vague, as the authors are left to infer that they need to make the notation clearer. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using $p$ to denote both the phase mixing probability and a dummy variable in Algorithm 1 could be confusing. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this confusion might arise or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the notation used in Algorithm 1, specifically the use of $p$ to denote both the phase mixing probability and a dummy variable in the inner loop of Phase 2. This could lead to confusion for readers, as the same symbol is used for two distinct concepts. While the comment highlights a specific area that needs clarification, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is 3 as it points out a potential area for improvement, but it lacks actionable advice, making it incomplete. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding of the approach. It also critiques the figure, noting that it is too abstract and that sentiment analysis does not align with the paper\"s main contribution, the WiC task. The comment implies that the authors should consider adding a mathematical formulation and improving the figure\"s clarity and relevance. However, it does not provide explicit instructions on how to implement these suggestions, such as which specific aspects of the mathematical formulation to include or how to improve the figure\"s clarity. The action is somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the highlevel description and the figure, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed in these parts, such as the need for a more detailed mathematical formulation and the confusion with the figure. The feedback is specific, as it provides clear guidance on how to improve the understanding of the approach and the clarity of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the highlevel description as intuitive but suggests that a more detailed mathematical formulation, potentially in the appendix, would be beneficial. It also critiques the figure, noting that it is too abstract and confusing, and that sentiment analysis does not align with the paper\"s main contribution, the WiC task. The comment provides specific suggestions for improvement, such as adding a mathematical formulation and improving the figure\"s clarity and relevance. However, it lacks detailed reasoning or references to support these claims, making the feedback 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on areas where the paper could be improved. It suggests that a more detailed mathematical formulation, potentially in the appendix, would enhance the understanding of the approach. Additionally, it critiques the figure, noting that it is too abstract and confusing, and that sentiment analysis does not align with the paper\"s main contribution, the WiC task. The comment offers suggestions for improvement, such as adding a mathematical formulation and improving the figure\"s clarity and relevance. However, the feedback could be more comprehensive by providing specific examples or guidance on how to implement these suggestions. Overall, the comment is 4 as it identifies areas for improvement and offers actionable feedback, but it could be more detailed to fully assist the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include additional benchmarking tasks outside of AitW. While it implies that the authors should consider adding these tasks, it does not provide explicit guidance on how to implement this suggestion or what specific tasks should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including additional benchmarking tasks outside of AitW, but it does not specify which tasks should be included or how they might enhance the paper. The authors cannot confidently determine which part of the paper this comment addresses, as it is not explicitly linked to a specific section or figure. However, the comment is specific in its suggestion to include additional benchmarking tasks. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include additional benchmarking tasks outside of AitW. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would improve the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, this comment is rated as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include additional benchmarking tasks outside of AitW. While this feedback provides a clear direction for improvement, it lacks specific guidance on which tasks to include or how they might enhance the paper. The comment is 3 as it identifies a potential area for expansion, but it does not offer detailed suggestions or examples, which could make it more actionable for the authors. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and requests for additional information regarding the experiments conducted. It asks for the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST2. While the comment explicitly asks for these details, it does not provide explicit guidance on how to incorporate them into the draft or suggest specific actions to take. The actions are implicit and somewhat vague, as the authors need to infer how to address these requests. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experiments\" and \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what information is missing, such as the steps vs ppl of linformer with YOSO, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the experimental setup and results, specifically regarding the steps vs ppl of linformer with YOSO in Figure 4, the comparison result of YOSO with linformer on iterationwise convergence, and an explanation for the better accuracy of linformer in downstream tasks like SST2. While the comment does not provide explicit reasoning or references to support these claims, it implies that the authors should address these aspects to improve the paper. However, without detailed justification or examples, the claim is 3, as it highlights areas where the authors might need to provide additional information or analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the authors could improve their experimental section. It points out the absence of steps vs ppl data for linformer with YOSO in Figure 4, the lack of comparison results on iterationwise convergence, and the need for an explanation regarding the better accuracy of linformer in downstream tasks like SST2. While the comment highlights these issues, it does not provide detailed guidance on how to address them or suggest specific actions to take. The feedback is 3 as it directs the authors to areas needing improvement, but it lacks depth and actionable suggestions, making it a 3 out of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and its ability to solve the optimal problem, specifically questioning whether the converged solution will be optimal for Eq. 5. This suggests that the authors should clarify the relationship between the equations. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the equations need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the equations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the policy gradient in Eq. 6 and its ability to solve the optimal problem, specifically questioning whether the converged solution will be optimal for Eq. 5. This question is specific to the equations mentioned, allowing the authors to identify the relevant part of the paper. However, the comment does not specify what needs to be addressed in terms of clarification or improvement. While the authors can infer that they need to clarify the relationship between the equations, the comment lacks specificity in terms of what aspects of the equations or the convergence process need clarification. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the policy gradient in Eq. 6 and its ability to solve the optimal problem, specifically questioning whether the converged solution will be optimal for Eq. 5. This is a subjective opinion or critique of the paper\"s approach. However, the comment does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the policy gradient in Eq. 6 and its ability to solve the optimal problem, specifically questioning whether the converged solution will be optimal for Eq. 5. This feedback highlights a potential area of confusion or concern regarding the theoretical underpinnings of the paper. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue or what aspects of the equations need clarification. While it identifies a potential area for improvement, the lack of detailed suggestions or guidance makes it 3. Therefore, the comment aligns with a score of 3, as it provides some insight but could be more comprehensive and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption of the general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not provide any explicit guidance or suggestions on how the authors should address this question or what changes might be necessary. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the assumption of a general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its inquiry about the distribution assumption, the absence of explicit grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the assumption of a general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. However, it does not provide any specific reasoning, examples, or references to support this claim or question. The comment lacks depth and does not offer any guidance or justification for why this assumption might be made or what the implications could be. As a result, the claim is 1, making the comment unsuitable for providing actionable feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the assumption of a general Gaussian distribution in the proposed algorithm, suggesting that it might be possible to assume an isotropic Gaussian instead. This question is relevant as it challenges the authors to consider alternative assumptions that could potentially simplify or improve their algorithm. However, the comment does not provide any guidance or suggestions on how the authors might approach this question or what changes could be made to their algorithm. Without specific advice or examples, the authors may find it difficult to address the question effectively. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide explicit guidance on how to implement this discussion or what specific aspects of the partitioning strategy should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 192,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed by suggesting that the authors discuss the limitations of freezing the partitioning in the first iteration. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point suggests that freezing the partitioning in the first iteration is a risky choice that makes strong assumptions about the coverage of the initial data. It implies that the authors should discuss the limitations of this approach. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification to fully support the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology, specifically the assumption of coverage in the first iteration of partitioning. It suggests that this choice is risky and implies that the authors should discuss the limitations of this approach. This feedback is clear and actionable, as it provides a specific area for improvement and encourages the authors to address a potential weakness in their methodology. However, the comment could be more helpful if it offered additional guidance on how to discuss the limitations or what specific aspects of the partitioning strategy should be addressed. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit suggestions on how the authors should address this question or what changes might be needed. Without further guidance or clarification, the authors are left without a clear understanding of what to do to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the section or figure being referred to. Additionally, the comment is not specific because it does not provide any details on what is intended or how it should be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the intent of Section 5.2 but does not provide any claim, suggestion, or critique that requires verification. It is a factual question that does not offer any guidance or insight into how the authors should improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the intent of Section 5.2, which could be helpful for the authors to clarify their writing or improve the flow of the paper. However, it does not provide any specific suggestions or guidance on how to address this question or what changes might be needed. The comment lacks actionable feedback, making it 2 as it does not offer any actionable steps for the authors to take. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that many aspects of the approach need clarification and questions are raised about the interaction between knowledge about objects and verbs to overcome reporting bias. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how to clarify the approach or why it is a good idea, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that many aspects of the approach need clarification, but it does not specify which parts of the paper these aspects relate to. The reviewer expresses concern about the interaction between knowledge about objects and verbs to overcome reporting bias, but the comment does not provide specific guidance on which sections or figures might be relevant. This lack of grounding makes it difficult for the authors to pinpoint the areas that need clarification. Additionally, the comment is somewhat specific in that it highlights a particular concern about the interaction between knowledge about objects and verbs, but without explicit references, it remains challenging to address fully. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the clarity of the approach and the interaction between knowledge about objects and verbs to overcome reporting bias. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence to substantiate the concerns, making it difficult for the authors to understand the basis of the feedback. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that many aspects of the approach need clarification. It raises a specific concern about the interaction between knowledge about objects and verbs in overcoming reporting bias, which is a critical point for understanding the paper\"s contribution. However, the comment lacks detailed guidance or suggestions on how to address these issues or improve the clarity of the approach. While it highlights an important area for improvement, the feedback is somewhat vague and could be more helpful if it provided specific examples or actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the threat model needs further clarification and proposes defining it more explicitly, specifying the attacker\u2019s level of access, capabilities, and the defender\"s available resources. It also recommends including this information in a dedicated section to enhance clarity. The comment provides a clear and explicit action for the authors to take, which is to define the threat model more explicitly and include it in a dedicated section. This action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the threat model needs further clarification and proposes defining it more explicitly, specifying the attacker\u2019s level of access, capabilities, and the defender\"s available resources. It recommends including this information in a dedicated section to enhance clarity. This feedback is fully grounded as it explicitly mentions the part of the paper that needs clarification, allowing the authors to accurately identify the section. The comment is also specific, as it provides clear guidance on what needs to be addressed in the threat model section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the threat model needs further clarification and proposes defining it more explicitly, specifying the attacker\u2019s level of access, capabilities, and the defender\"s available resources. It recommends including this information in a dedicated section to enhance clarity. While the comment provides a clear rationale for the need for clarification, it lacks specific examples or references to support the claim. The authors would need to infer the importance of this clarification based on the reasoning provided. Therefore, the comment is 3, as it offers a logical basis for the suggestion but could benefit from additional evidence or examples to strengthen its persuasiveness.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the clarity of the threat model. It suggests that the authors should define the threat model more explicitly by specifying the attacker\"s level of access, capabilities, and the defender\"s available resources. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and comprehensiveness of their work. By including this information in a dedicated section, the authors can improve the overall understanding and robustness of their analysis. The comment is 4 as it offers a specific and constructive suggestion for improvement, though it could be further expanded to provide additional guidance or examples. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the authors on how to set a reasonable classimbalanced task in the context of fewshot learning, given that each class has only a few examples. It does not provide explicit instructions or suggestions on how to address this issue, nor does it offer concrete details or examples to guide the authors. The comment implies that the authors should clarify this aspect, but it lacks specific guidance on how to do so. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment questions the authors on how to set a reasonable classimbalanced task in the context of fewshot learning, specifically noting that each class has only a few examples. However, it does not specify which part of the paper this issue is discussed or addressed. The authors cannot confidently determine which section or aspect of the paper is being referred to, making the comment weakly grounded. Additionally, the comment is specific in its request for clarification and explanation regarding the setting of classimbalanced tasks, but it lacks detailed guidance on how to achieve this. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how to set a reasonable classimbalanced task in the context of fewshot learning, given that each class has only a few examples. However, it does not provide any specific reasoning, examples, or references to support the claim that this is a significant issue or how it might affect the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how to set a reasonable classimbalanced task in the context of fewshot learning, given that each class has only a few examples. This is a relevant concern, as it highlights a potential issue with the experimental setup or methodology. However, the comment does not provide any suggestions or guidance on how to address this issue, nor does it offer any concrete examples or detailed explanations to help the authors clarify their approach. Without actionable advice or further elaboration, the comment is 3 as it identifies a potential area for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a lack of detail in the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide details on how the actual pruning was performed. This feedback is explicit, as it directly instructs the authors to include more information about the pruning process. However, the action is somewhat vague because it does not specify exactly what details need to be added or how the pruning process should be described. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 238239, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the lack of detail in explaining how the ground truth of sensitivity is achieved, specifically mentioning the absence of information on the pruning process. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors do not explain how the ground truth of sensitivity is achieved, specifically noting that lines 238239 mention estimating sensitivity by pruning but lack details on the actual pruning process. This claim is 3 as it identifies a gap in the explanation but does not provide specific examples or references to support the assertion. The authors would need to infer the missing details, making the comment 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors lack detail, namely the explanation of how the ground truth of sensitivity is achieved. It points out that the paper mentions estimating sensitivity by pruning but does not provide sufficient information on the actual pruning process. This feedback is clear and actionable, as it directs the authors to include more details about the methodology used to determine the ground truth of sensitivity. By addressing this feedback, the authors can improve the clarity and completeness of their paper, making the comment 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that some parts of the text could be written more clearly, specifically mentioning lines 97, 105106, and the concept of a proper rotation matrix and the issue of a nonpositive semidefinite matrix. However, it does not provide explicit instructions or suggestions on how the authors should improve the clarity of these sections. The feedback is somewhat vague, as it implies that the authors should clarify these points but does not offer concrete guidance on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but lacks detailed instructions on how to implement them.", "grounding_specificity_rationale": "The comment suggests that some parts of the text could be written more clearly, specifically mentioning lines 97, 105106, and the concept of a proper rotation matrix and the issue of a nonpositive semidefinite matrix. However, it does not provide explicit references to sections, tables, or figures, making it difficult for the authors to pinpoint the exact parts of the paper being addressed. While the comment is specific about the issues needing clarification, the lack of grounding makes it challenging for the authors to focus their revisions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some parts of the text could be written more clearly, specifically mentioning lines 97, 105106, and the concept of a proper rotation matrix and the issue of a nonpositive semidefinite matrix. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without additional context or justification, the authors may find it difficult to understand why these parts need clarification. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies areas where the text could be written more clearly, specifically mentioning lines 97, 105106, and the concepts of a proper rotation matrix and a nonpositive semidefinite matrix. By pointing out these specific instances, the comment provides the authors with clear feedback on areas that need improvement. However, the comment lacks detailed suggestions or examples of how to clarify these points, which limits its helpfulness. The feedback is 3 as it directs the authors to specific areas for revision, but it could be more comprehensive with additional guidance on how to improve the clarity of these sections. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This comment provides a specific suggestion for improvement, indicating that the authors should consider a different term for the function. The action is explicit and concrete, as it clearly directs the authors to make a change to the terminology. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 111,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the suggestion to consider renaming the function g as a binary operator, similar to the approach in Cohen and Shashua, 2016. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This comment provides a specific suggestion based on a reference to external work, which supports the claim. However, it lacks detailed reasoning or examples to fully substantiate the suggestion. The authors would benefit from additional context or explanation to understand why this change might be beneficial. Therefore, the comment is 4, as it provides some justification but could be more comprehensive.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by suggesting that the authors might consider renaming the function g as a binary operator, similar to the approach taken in Cohen and Shashua, 2016. This feedback is actionable and offers a clear direction for enhancing the clarity and consistency of the paper. By aligning the terminology with existing literature, the authors can improve the readability and understanding of their work. However, the comment could be more helpful if it included additional context or examples to further clarify the reasoning behind the suggestion. Overall, the comment is 4, as it provides a clear and actionable piece of feedback that the authors can readily implement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors\" content and recommends shrinking the captions to provide more space for the methods or related work sections. This feedback is explicit and provides a clear action for the authors to take, which is to adjust the captions. The comment is specific in its suggestion and offers a concrete way to improve the presentation of the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 1 and Fig. 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides a clear suggestion to shrink the captions to make space for the methods or related work sections. This feedback is detailed and actionable, providing the authors with a clear understanding of what needs to be done. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the captions of Figure 1 and Figure 2 have large overlaps with the authors\" content and recommends shrinking them to provide more space for the methods or related work sections. While the comment identifies a potential issue with the presentation of the figures, it does not provide specific examples or references to support the claim that the captions overlap significantly. The suggestion is logical and actionable, but the lack of detailed evidence or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the captions of Figure 1 and Figure 2, noting that they have large overlaps with the authors\" content. It suggests shrinking the captions to make space for the methods or related work sections. This feedback is clear and actionable, providing the authors with a concrete step to take to improve the presentation and organization of their paper. By addressing this issue, the authors can enhance the readability and clarity of their work. Therefore, the comment is 5, as it offers a direct and constructive suggestion for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. It implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to include or exclude the dataset. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work and why it is not used as a potential benchmark for evaluation. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the inclusion of Vidgen et al., 2021, in Table 2, suggesting that it might be similar to the dataset presented in the current work despite the size difference. The comment implies that this dataset could be a potential benchmark for evaluation, specifically for investigating the role of context in detecting hate. However, the comment lacks specific reasoning or examples to support why this dataset should or should not be included. It does not provide references or detailed explanations to justify the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 2, as it provides some context but lacks sufficient evidence to fully support the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the inclusion of Vidgen et al., 2021, in Table 2, questioning its relevance as a benchmark for evaluating the role of context in detecting hate. It suggests that despite the size difference, the dataset might be similar to the one presented in the current work and could potentially be used as a benchmark. However, the comment does not provide specific guidance on how the authors might address this issue or what steps they should take to include or exclude the dataset. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights a relevant concern but does not offer detailed guidance for the authors to address it."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide explicit or implicit suggestions on how the authors might address these issues or improve their approach. The feedback lacks concrete guidance on potential modifications or strategies to enhance the proposed method, leaving the authors without clear direction on how to proceed. As a result, the comment is 1, as it does not offer actionable steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not specify which part of the paper this critique is directed towards, making it difficult for the authors to identify the exact section being addressed. While the critique provides some specificity regarding the issues raised, the lack of explicit grounding makes it challenging for the authors to understand which parts of the paper need revision. Therefore, the comment is weakly grounded and somewhat specific, aligning with category 3.", "verifiability_rationale": "The review point critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims, making it 3. The authors may find it challenging to fully understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the proposed approach, suggesting that it is merely learning a surrogate model for solving linear/linearized systems of equations arising in FEM. It highlights the need for careful selection of basis functions and meshes, as well as the assembly of stiffness matrices, particularly in the context of the current work, which heavily relies on FEniCS. The comment also notes that while current operator learning methods may not yet achieve the same accuracies as specialized numerical solvers, they are more universal and do not require adaptation to specific PDEs. However, the comment does not provide specific suggestions or actionable feedback on how the authors might address these issues or improve their approach. While it identifies a potential area for improvement, it lacks detailed guidance or concrete suggestions, making it 3. The authors may gain some insights into the limitations of their approach but would need to seek further clarification or guidance to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. It also acknowledges the authors\" judgment regarding the lack of immediate societal impact. However, the comment does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative datasets or methods to address the issue. Without specific guidance on how to improve the draft, the authors are left without actionable feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. Additionally, the comment does not provide specific guidance on how to address this issue or what aspects of variation need to be controlled. As a result, the authors cannot confidently determine which part of the paper is being addressed, and the comment lacks specificity. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the use of fully realistic datasets, suggesting that it might be challenging to control multiple aspects of variation with precision. While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how to address this concern or improve the draft. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited insights on how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should mention the evaluation metric used in the paper to improve clarity and understanding of the results. It provides a specific example of where this information is missing, namely lines 078079 and line 08. However, the comment does not explicitly instruct the authors on how to incorporate this information or what specific metric should be mentioned. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines of the paper (078079 and 08), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of the evaluation metric for clarity and comparability. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the evaluation metric should be mentioned for clarity and comparability, providing a specific example of where this information is missing. However, the comment lacks detailed reasoning or examples to fully support the claim. It does not provide references or logical reasoning to justify why mentioning the evaluation metric is crucial for understanding the results. As a result, the claim is 3, as it is partially supported but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the evaluation metric should be mentioned in the paper to enhance clarity and comparability. It provides a concrete example of where this information is missing, specifically in lines 078079 and line 08. By highlighting the importance of including the evaluation metric, the comment offers a clear and actionable suggestion for the authors to improve the presentation and understanding of their results. However, the comment could be more helpful if it provided additional guidance on which specific metric should be included or how it should be presented. Overall, the feedback is 4 as it directs the authors towards a specific improvement that would enhance the paper\"s clarity and comparability."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should study the behavior of the model under higher noise, given that the current noise level is not very high based on the observations. This comment provides a clear and explicit action for the authors to take, which is to conduct additional experiments with higher noise levels. The suggestion is concrete and detailed, as it specifies the type of experiments to be conducted. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"simulation study\" and the \"standard deviation of the noise\" being 3. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests studying the behavior of the model under higher noise, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the standard deviation of the noise being 3 is not a very high noise value based on the observations in the plot compared to the true trajectories. This claim is 3 as it provides a basis for the suggestion to study the model\"s behavior under higher noise. However, it lacks specific examples or references to support the claim, making it 3. The authors could benefit from additional evidence or examples to strengthen the claim.", "helpfulness_rationale": "The review comment identifies a specific issue in the simulation study, noting that the standard deviation of the noise is stated as 3, but the reviewer argues that this is not a very high noise value based on the observations. The comment suggests studying the model\"s behavior under higher noise, which is a constructive and actionable suggestion for improvement. By providing a clear direction for further experimentation, the comment helps the authors enhance the robustness and comprehensiveness of their study. Therefore, the comment is 4, as it offers valuable guidance but could be more detailed in its suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to resolve the issue or enhance the applicability of the approach. As a result, the authors are left without a clear understanding of how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the bounds, the absence of explicit grounding makes it challenging for the authors to understand where to address the issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the bounds of a certain approach have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer\"s assertion remains unsubstantiated, making the comment 1. The authors are left without a basis to understand or address the issue raised in the comment.", "helpfulness_rationale": "The review comment identifies a potential issue with the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide specific guidance or suggestions on how to address this concern or enhance the applicability of the approach. The comment lacks actionable insights or detailed feedback that would help the authors improve their draft. As a result, the feedback is not particularly helpful, as it does not offer a clear path for the authors to resolve the issue or enhance their work. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises an interesting question about the performance of DVP on video with varying lengths. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to improve their draft. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises an interesting question about the performance of DVP on video with different lengths, but it does not specify which part of the paper this question relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this question or what needs to be improved in the paper. Therefore, the comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point raises an interesting question about the performance of DVP on video with different lengths. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insight that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises an interesting question about the performance of DVP on video with different lengths, which could be a valuable point for discussion or further exploration. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this question or what improvements could be made to their draft. Without actionable insights or constructive feedback, the comment is not particularly helpful in guiding the authors to enhance their work. Therefore, it aligns with a score of 1, indicating that it is 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion or clarify the distinction in their draft. The action is implicit, as the authors would need to infer that they should clarify the target queries in the introduction or methodology sections. However, the lack of specific guidance on how to clarify the distinction makes the action vague and less actionable. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until reading the conclusion. However, it does not specify which part of the paper this confusion pertains to, making it weakly grounded. The comment is specific in identifying the issue of clarity regarding the type of cloze queries targeted, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses confusion about whether the paper targets singletoken or multitoken cloze queries, noting that this distinction is not clear until reading the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support why this distinction is important or how it affects the paper\"s content. Without additional context or justification, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment highlights a potential confusion regarding the paper\"s focus on singletoken or multitoken cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential area of ambiguity, it does not provide specific suggestions or guidance on how the authors might clarify this distinction in their draft. The feedback is 3 as it points out a potential issue that could affect the clarity of the paper, but it lacks actionable advice on how to address it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should evaluate the approximation error of the proposed training objective by calculating the actual KLdivergence and checking whether it approaches zero. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be done to address the issue. The comment is fully actionable because it specifies the exact steps required to implement the suggested improvement. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment explicitly mentions \"Section 3.3,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the proposed training objective has ignored the KLdivergence term in equation (3) and suggests evaluating this approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This level of detail makes the comment specific, as it clearly identifies what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a specific concern about the proposed training objective in Section 3.3, noting that it has ignored the KLdivergence term in equation (3). The comment suggests evaluating this approximation error by calculating the actual KLdivergence and checking whether it approaches zero. However, the comment does not provide any supporting evidence, examples, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in Section 3.3, where the proposed training objective has ignored the KLdivergence term in equation (3). It suggests that the authors evaluate this approximation error by calculating the actual KLdivergence and checking whether it approaches zero. This feedback is actionable and provides a clear direction for the authors to improve their draft by addressing the identified gap in their analysis. However, the comment could be more helpful if it included additional guidance on how to calculate the KLdivergence or suggested specific experiments to validate the approximation. Despite this, the comment is 4 as it offers a concrete and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work 1. While the comment identifies areas that need improvement, it does not provide explicit guidance on how to address these issues or what specific changes should be made. The authors are left to infer the actions needed, such as strengthening the connection between Section 2 and the methodology or expanding the theoretical analysis. The lack of concrete suggestions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2\" and \"the methodology section,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the limited connection between these sections and the concern about the theoretical analysis being simplistic and closely related to a specific work 1. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the label is 5.", "verifiability_rationale": "The review point claims that Section 2 has a limited connection with the methodology section and that the theoretical analysis is somewhat simplistic and closely related to a specific work 1. While the comment provides a general assessment, it lacks specific examples or detailed reasoning to substantiate these claims. The authors are left to infer the basis of these claims, which makes the comment 3. To enhance the comment\"s verifiability, it would be beneficial to include specific examples or references that support the claims about the limited connection and the simplicity of the theoretical analysis. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the connection between Section 2 and the methodology section, suggesting that the paper could benefit from strengthening this link. It also points out that the theoretical analysis is somewhat simplistic and closely related to a specific work 1, which implies that the authors should consider expanding or contextualizing their analysis. While the comment highlights areas for improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is 3 as it provides a direction for improvement but does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. While the comment implies an action, it does not explicitly instruct the authors to provide a detailed discussion or analysis of these situations. The action is somewhat vague, as it leaves the authors to infer that they need to expand on the discussion of the losses. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests further discussion or exploration of which situations the losses help, specifically mentioning specular areas. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its focus on the relationship between losses and specular areas, providing a clear direction for the authors to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should further discuss or explore which situations the losses help in particular, such as for specular areas. This feedback is 3 as it points out a potential area for additional discussion that could enhance the paper\"s depth and clarity. However, the comment lacks specificity and does not provide detailed guidance on how to address this suggestion, leaving the authors with limited actionable advice. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the major contributions of the paper and criticizes the approach of analyzing previous work as a contribution. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should clarify their contributions and reconsider their approach to analyzing previous work, but it does not offer specific guidance on how to do so. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper is unclear regarding its major contributions or critique the approach of analyzing previous work as a contribution. The authors cannot confidently determine which section or aspect of the paper is being addressed, making it difficult to understand the feedback and apply it effectively. Additionally, the comment is not specific because it does not provide detailed guidance on what needs to be clarified or how the critique should be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is unclear what the major contributions of the paper are and criticizes the approach of analyzing previous work as a contribution. However, the comment lacks specific examples or detailed reasoning to support these claims. It does not provide any references or logical arguments to substantiate the assertion that analyzing previous work does not constitute a contribution. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of clarity regarding the major contributions. It also critiques the approach of analyzing previous work as a contribution, which is a valuable piece of feedback. However, the comment lacks specific suggestions or guidance on how the authors might address these issues. While it highlights a critical area for improvement, the absence of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out important weaknesses but does not provide sufficient direction for the authors to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the reproducibility of the results, questioning whether the code will be publicly available. While it identifies a potential issue, it does not provide any explicit or implicit suggestions on how the authors might address this concern. The comment lacks concrete guidance on what steps the authors should take to ensure reproducibility, such as suggesting specific practices for sharing code or providing detailed documentation. As a result, the authors are left without a clear understanding of how to improve their draft to address this issue. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the reproducibility issue, such as recommending specific practices for sharing code or providing detailed documentation. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. However, it does not provide any claim or suggestion that requires verification or justification. The comment is purely a question, which does not offer any guidance or insight into how the authors might address the issue. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the results, specifically questioning whether the code will be publicly available. This is a valid concern that could impact the ability of others to replicate the findings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as recommending specific practices for sharing code or providing detailed documentation. Without actionable advice or suggestions, the comment is not particularly helpful in guiding the authors to improve their draft. Therefore, it aligns with a score of 1, indicating that it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. It implies that the authors should consider this extension, but it does not explicitly instruct them to do so or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should extend the feature and understand the implications of such an extension. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or context. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not offer any justification or reasoning for why this extension is necessary or beneficial. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. This feedback is specific and actionable, as it offers a clear direction for improvement by suggesting a potential enhancement to the feature representation. However, the comment could be more helpful if it included additional context or explanation about why this extension is beneficial or how it might impact the overall performance of the model. Despite this, the comment provides valuable guidance for the authors to consider, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the clarity and detail of the paper. It suggests that the authors denote the vector representations of words in the equation, clarify whether the vectors are L2normalized, and specify the method used for computing nearest neighbor examples (cosine or dot product). These suggestions are explicit and concrete, as they directly instruct the authors on what needs to be done to enhance the paper. The comment is fully actionable, as it provides clear guidance on how to address the identified issues. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improving the clarity of the notation, the normalization of vectors, and the method used for computing nearest neighbor examples. The authors are guided on what specific aspects need attention, making the comment both 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises questions about the notation, normalization, and computation of nearest neighbor examples in the paper. It suggests that the authors should clarify these aspects, but it does not provide any specific reasoning or references to support why these details are important or how they impact the paper. The comment lacks detailed justification or examples, making it difficult for the authors to fully understand and address the issues. Therefore, the comment is considered 2, as it provides some guidance but lacks sufficient evidence to fully support the claims.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the clarity and detail of the paper. It requests that the authors clarify the notation used for vector representations, whether the vectors are L2normalized, and the method used for computing nearest neighbor examples (cosine or dot product). These suggestions are actionable and detailed, offering clear guidance on how the authors can enhance the paper. By addressing these points, the authors can improve the clarity and completeness of their work. Therefore, the comment is 4, as it provides valuable feedback that is 4 and constructive."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with the formatting of equations in the paper, noting that some end with a period while others end with a comma. It provides explicit instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. This feedback is clear and actionable, as it directly instructs the authors on what needs to be corrected. The comment is specific in its instructions, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as Figure 2, Line 433, and Line 468, allowing the authors to accurately identify the sections being addressed. It is also specific because it clearly specifies the issue with the formatting of equations, noting that some end with a period while others end with a comma. This provides clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the inconsistency in punctuation marks used at the end of equations in specific parts of the paper (Figure 2, Line 433, and Line 468). It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a minor issue with the formatting of equations in the paper, specifically noting that some equations end with a period while others end with a comma. This feedback is clear and actionable, as it provides specific instructions for the authors to check Figure 2, Line 433, and Line 468, and to ensure consistency in the ending punctuation of equations. While the comment is concise, it effectively highlights a detail that needs attention, making it 3. However, it could be more helpful if it suggested specific ways to achieve consistency or provided examples of how to do so. Overall, the comment is 4 as it offers clear guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the technical contribution or what specific aspects need to be revised. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, it does not specify which part of the paper this comparison is made or where the similarity is discussed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying a potential issue with the technical contribution, but it lacks detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is limited because $kNNECD$ is very similar to $kNNMT$. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of this claim or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the technical contribution of the paper, suggesting that the similarity between $kNNECD$ and $kNNMT$ might limit the novelty of the work. However, the comment lacks specific details or suggestions on how the authors might address this issue or enhance their contribution. Without actionable feedback or guidance, the authors may find it challenging to understand the implications of this critique or how to improve their draft. Therefore, the comment is 2, as it points out a potential weakness but does not provide substantial assistance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point questions whether the figures in Figure 1 are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback provides a clear and explicit action for the authors to take, namely to verify the nature of the figures and potentially conduct additional experiments. The comment is specific in its request for clarification and suggests a concrete way to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors should determine if the figures are generated by real experiments or artificially and, if artificially generated, conduct realworld experiments to support the phenomenon. This provides a clear and actionable direction for the authors to improve their draft. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This comment is 3 as it provides a clear question and a suggestion for further investigation, but it lacks specific examples or references to support the claim. The authors would need to conduct additional research or experiments to fully address the suggestion, making the comment 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the nature of the figures in Figure 1, specifically whether they are generated by real experiments or artificially. It suggests that if the figures are artificially generated, the authors should conduct realworld experiments to support the phenomenon occurring in these figures. This feedback is valuable as it prompts the authors to consider the validity and reliability of their experimental results. By addressing this question, the authors can strengthen the credibility of their findings and provide a more robust evaluation of their proposed method. The comment is clear, actionable, and constructive, making it 5 for improving the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the assumption among classes is not practical and suggests that the formulation or definition in the manuscript is somewhat trivial. It highlights the importance of optimization and theoretical property analysis, indicating that some conclusions or insights can be gained. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to make the assumption more practical or to enhance the manuscript. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the assumption among classes, suggesting it is not practical. However, it does not specify which part of the manuscript discusses this assumption, making it difficult for the authors to identify the exact section or content being addressed. The comment is specific in its critique of the assumption but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the assumption among classes, suggesting it is not practical. However, it does not provide specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the assumption is not practical. Without additional context or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption among classes, suggesting that it is not practical. It also notes that the formulation or definition in the manuscript is somewhat trivial, but highlights the importance of optimization and theoretical property analysis, which can lead to some conclusions or insights. While the comment points out a specific area for improvement, it lacks detailed guidance or suggestions on how the authors might address the issue or enhance the manuscript. The feedback is 3 as it directs the authors to consider the practicality of their assumptions and the potential for further analysis, but it could be more comprehensive with additional actionable advice. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the statistical significance of the evaluation results reported in Table 1, noting that the results are based on only three trials per case, which is not statistically significant. The comment suggests that the reported deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to improve the statistical significance of their results. The action is implicit and vague, as the authors are left to infer that they need to increase the number of trials or reconsider their claims. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statistical significance of the results reported in the table, explaining why the deviations are not meaningful and why the claims made based on these results are not valid. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation results in Table 1 are based on only three trials, which is not statistically significant. It suggests that the reported deviations are not meaningful and that the claims made based on these results are not valid. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of supporting evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the statistical significance of the evaluation results reported in Table 1. It points out that the results are based on only three trials per case, which is not statistically significant, making the reported deviations and claims about performance improvements unmeaningful. The comment provides a clear critique of the statistical rigor of the evaluation, which is a significant concern for the validity of the paper. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue, such as increasing the number of trials or using alternative statistical methods. Despite this, the feedback is 4 as it highlights a crucial area for improvement, guiding the authors to enhance the robustness of their evaluation."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any explicit or implicit actions for the authors to take. The comment suggests that the authors should include these two relevant papers in their comparison, but it does not specify how to do so or what aspects of the comparison should be addressed. Without concrete guidance, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not specify which part of the paper this comparison is located in, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the issue of a shallow comparison, it lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the feature comparison with prior work is shallow and lacks two relevant papers. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the feature comparison section, noting that it is shallow and lacks two relevant papers. This feedback is clear and actionable, as it directs the authors to include these missing references in their comparison. However, the comment could be more helpful if it provided suggestions on how to integrate these references or what aspects of the comparison should be addressed. Despite this, the feedback is 4 as it offers a clear direction for improvement, allowing the authors to enhance the depth and comprehensiveness of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of the multiview clustering approach, specifically questioning why other views are useful if the paraphrase similarity view performs significantly better. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform a detailed analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. It is specific in detailing what the authors need to address, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment lacks specific examples or references to support the claim that the other views are not useful. It does not provide a clear rationale or evidence to justify the need for a detailed analysis of the differences between the views. Therefore, the claim is not verifiable, as it lacks sufficient evidence or reasoning to support the assertion.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of the multiview clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It points out that while the paraphrase similarity view performs significantly better, the authors do not provide a detailed analysis of how the different views differ or how they contribute to the clustering task. This lack of analysis makes it difficult for the authors to draw solid conclusions about the usefulness of the other views. The comment suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to better understand their contributions. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or suggested additional empirical examples to support the claim. Overall, the comment is 3 as it identifies a gap in the analysis but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment does not explicitly instruct the authors to provide these results or specify how to do so, leaving the action somewhat vague. The authors can infer that they need to include more detailed results, but the lack of concrete guidance makes the action 3.", "grounding_specificity_rationale": "The comment questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment does not explicitly mention which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of model size affecting performance, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment lacks specific examples or detailed reasoning to substantiate the claim, making it difficult for the authors to understand and address the issue effectively. The absence of clear evidence or references makes the claim 3, as it relies on the authors\" interpretation and the provided reference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the unexpected impact of increasing model size on performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. This observation highlights a potential inconsistency in the authors\" findings and suggests that providing more detailed preliminary experimental results on Wikipedia would strengthen the paper. However, the comment lacks specific guidance on how to address this issue or what additional experiments might be necessary. While it identifies a potential area for improvement, the feedback could be more helpful if it included suggestions for further analysis or additional experiments. Therefore, the comment is 3, as it points out a significant issue but does not provide detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper uses analysis to justify the use of the information axis as a tool. It also points out that the conclusion mentions the need for related experiments to demonstrate the tool\"s effectiveness. However, the comment does not provide explicit guidance on what specific experiments should be conducted or how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they need to add experiments to support the claim. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper uses much analysis to justify the use of the information axis as a tool. It also mentions that the conclusion points out the need for related experiments to demonstrate the tool\"s effectiveness. However, the comment does not specify which part of the paper this analysis or justification is located in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment does not provide specific guidance on what experiments should be conducted or how they should be designed. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper uses much analysis to justify the use of the information axis as a tool. It also mentions that the conclusion points out the need for related experiments to demonstrate the tool\"s effectiveness. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the analysis is thorough or that the conclusion accurately identifies the need for additional experiments. Without these elements, the claim remains 3, as the authors are left to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper could benefit from additional experiments to demonstrate the effectiveness of the information axis tool. It points out that the conclusion mentions the need for related experiments, which implies that the current analysis might be insufficient. However, the comment lacks specific guidance on what kind of experiments should be conducted or how they should be designed to effectively showcase the tool\"s utility. While it provides a direction for improvement, the feedback is somewhat vague and could be more helpful if it included suggestions for specific experiments or analyses. Therefore, the comment is rated as 3, as it offers a clear direction but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. While the comment implies that this extension would be more interesting and practical, it does not provide explicit guidance on how to implement this extension or what specific aspects of the current study need to be addressed to make this extension feasible. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is specific in its suggestion to extend the study, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical suggestion that aligns with the idea of making the study more interesting and practical. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim is considered 2, as it lacks sufficient evidence to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment raises a question about the scope of the study, suggesting that the current approach of considering only one truck and one drone could be extended to multiple trucks and drones. This is a logical and interesting suggestion that could enhance the practicality and applicability of the study. However, the comment does not provide specific guidance on how to extend the study or what aspects of the current work need to be addressed to make this extension feasible. While it offers a valuable direction for future work, the lack of detailed suggestions or actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides a clear direction but lacks depth and specificity in its recommendations."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might enhance the novelty of their approach or what specific aspects need to be improved. Without concrete suggestions or actions, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment suggests that the proposed approach to pretraining has limited novelty because it follows the strategies used in ELECTRA. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect that needs improvement. The comment is specific in its critique of novelty but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed approach to pretraining has limited novelty because it more or less follows the strategies used in ELECTRA. This claim is 3 as it provides a basis for comparison with a wellknown approach, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors could benefit from additional context or references to support the assertion of limited novelty. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the proposed approach to pretraining, noting that it closely resembles the strategies used in ELECTRA. While the comment highlights a specific concern, it does not provide detailed suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the motivation for the Newton algorithm in section 4 is lacking, as it is essentially a 1dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm\"s runtime and suggests that experiments could help motivate the need for the analysis/algorithm. While the comment implies that the authors should consider adding experiments to address this concern, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments to demonstrate the impact of the Newton algorithm. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the motivation for the Newton algorithm, suggesting that it is essentially a 1dimensional line search on a convex function and questioning the impact of this on the algorithm\"s runtime. The comment provides a clear and specific request for additional experiments to motivate the need for the analysis/algorithm. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the motivation for the Newton algorithm in section 4 is lacking, as it is essentially a 1dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm\"s runtime and suggests that experiments could help motivate the need for the analysis/algorithm. However, the comment lacks specific examples or references to support the claim that the Newton algorithm is merely a linearly convergent 1dimensional line search. Without detailed reasoning or evidence, the claim is difficult to verify, making it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential weakness in the motivation for the Newton algorithm in section 4, suggesting that it is essentially a 1dimensional line search on a convex function, which converges linearly. The reviewer questions the impact of this on the algorithm\"s runtime and recommends that experiments be conducted to demonstrate the need for the analysis/algorithm. This feedback is 3 as it points out a specific area for improvement and suggests a potential experiment to address the concern. However, the comment could be more helpful by providing more detailed guidance on how to conduct these experiments or by elaborating on the specific aspects of the Newton algorithm that need to be motivated. Overall, the comment provides a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that subtracting dynamic factors from dynamic information in Equation 8 might lead to the loss of some dynamic information, which could hinder the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the equation. The action is implicit and vague, as it does not specify how to modify the equation or what steps should be taken to mitigate the potential loss of dynamic information. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to Equation 8, which is a part of the paper. It provides a clear and specific explanation of a potential problem with the equation, suggesting that subtracting dynamic factors might lead to the loss of dynamic information, thereby affecting the LSTM module\"s ability to capture complete dynamic changes. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that subtracting dynamic factors from dynamic information in Equation 8 might result in the loss of some dynamic information, which could hinder the LSTM module\"s ability to capture complete dynamic changes. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with Equation 8, specifically suggesting that subtracting dynamic factors might lead to the loss of dynamic information, which could affect the LSTM module\"s ability to capture complete dynamic changes. While the comment highlights a specific area that requires attention, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is 3 as it points out a potential problem, but it lacks actionable advice or examples of how to resolve it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how to address these questions or what experiments to conduct to explore these effects. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to identify the exact areas that need attention. While the questions are specific, the absence of grounding information limits the authors\" ability to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. However, it does not provide any specific claims, opinions, or suggestions that require verification or justification. The comment is purely descriptive and does not offer any guidance or insights that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises questions about the empirical impact of the number of Monte Carlo (MC) samples on performance and how the network structure affects this. While it identifies areas for further exploration, it does not provide specific guidance or suggestions on how to address these questions or what experiments to conduct. The feedback is 3 as it highlights important aspects that need further investigation, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It specifically asks about the selection of 21 event types from Freebase and the coverage of 33 event types in the ACE data. While the comment identifies areas that need clarification, it does not provide explicit instructions or suggestions on how to address these concerns. The authors are left to infer that they need to provide more details on the selection process and coverage, but the action is not concrete. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It specifically mentions Section 2 line 262, which indicates that 21 event types are selected from Freebase. However, the comment does not specify which part of the paper discusses the selection process or the coverage of the 33 event types in the ACE data. This makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the concerns raised, it lacks full grounding as it does not provide clear guidance on which parts of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It specifically mentions Section 2 line 262, which states that 21 event types are selected from Freebase. However, the comment does not provide any justification or reasoning for why this selection is made or how it relates to the 33 event types in the ACE data. Without additional context or explanation, the claim that the authors need to clarify the selection process and coverage is not 5. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment raises concerns about the generalizability of the method to other domains and questions the selection process of event types. It specifically mentions that 21 event types are selected from Freebase in Section 2, line 262, and asks about the coverage of the 33 event types in the ACE data. This feedback highlights a potential gap in the paper\"s discussion and suggests that the authors need to provide more details on the selection process and the coverage of event types. However, the comment does not offer specific guidance or suggestions on how to address these concerns, leaving the authors with a general idea of what needs improvement but without concrete steps to take. Therefore, the comment is 3, as it identifies an area for improvement but lacks depth and actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point indicates that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or how the authors should address these issues. The comment lacks concrete actions or suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not specify which parts of the paper these issues relate to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the comment is specific about the nature of the issues, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what specific issues need to be addressed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity and motivation of the experimental setup, specifically mentioning corpora and datasets. However, it lacks detailed guidance or suggestions on how to address these issues. The comment is 3 as it points out a specific area that needs improvement, but it does not provide actionable steps or examples to help the authors enhance their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters compared to competing approaches. It also notes that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is explicit and provides a clear action for the authors to take: they should provide more detailed information about the size of each hourglass module. However, the comment lacks specific guidance on how to determine or measure the size of each module, making it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This provides a clear reference to a specific part of the paper, allowing the authors to identify the relevant section. However, the comment does not specify what needs to be addressed in this part, such as how the size of the model compares to competing approaches or why the size is important. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the size of the model in terms of depth or number of parameters, specifically mentioning that the model consists of 4 hourglass modules but does not specify the size of each module. This feedback is clear and provides a specific question that the authors should address to improve the clarity and completeness of their paper. However, it does not offer any additional context or justification for why this information is important or how it relates to the overall work. Therefore, the comment is 3, as it provides a clear question but lacks detailed reasoning or references to support the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters, particularly noting that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the model\"s architecture, which is crucial for understanding and replicating their work. However, the comment could be more helpful if it suggested specific ways to determine or measure the size of each module or how this information is relevant to the study. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the claim that the proposed method, PACE, addresses a gap by treating climate emulation as a diagnostictype prediction. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts. However, the comment does not provide explicit guidance on how the authors should revise their draft to clarify the distinction between their work and prior efforts. The action is implicit, as the authors need to infer that they should address the overlap with existing work. Additionally, the comment lacks concrete details on how to make the distinction clear, making it 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim being made in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what is misleading about the claim, noting that prior work, such as ClimateBench or ClimateSet, has already addressed similar concepts. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper\"s claim about PACE being a diagnostictype prediction is misleading because prior work, such as ClimateBench or ClimateSet, has already addressed similar concepts. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks references or detailed explanations of how the prior work differs from the proposed method. Without this additional information, the claim remains 3, as the authors may need to infer the basis for the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the claim made in the paper regarding the novelty of the proposed method, PACE. It points out that prior work, such as ClimateBench or ClimateSet, has already explored similar concepts, which could make the claim misleading. However, the comment does not provide specific guidance on how the authors should address this issue or clarify the distinction between their work and prior efforts. While it highlights a potential area for improvement, it lacks actionable advice on how to revise the paper to make the claim more accurate and less misleading. Therefore, the comment is 3, as it raises a valid concern but does not offer detailed suggestions for improvement. The score is consistent with the label 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the metric learning theory in the paper, suggesting that it is not novel or better than existing theoretical results. It implies that the authors should consider how to improve the metric learning aspect of their work. However, the comment does not provide specific guidance on what changes or improvements could be made to address the identified issue. The action is implicit and vague, as the authors are left to infer that they need to enhance the metric learning section. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the metric learning theory in the paper, referencing the generalization theory of neural networks and suggesting that the proposed metric perspective analysis does not offer better results compared to previous theoretical findings. It implies that the part of metric learning in the paper does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment is specific in its critique of the metric learning theory, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the metric learning theory in the paper is not novel or better than existing theoretical results, referencing the generalization theory of neural networks. It suggests that the proposed metric perspective analysis does not yield better results compared to previous findings. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of references or detailed explanations weakens the verifiability of the claim, aligning with a score of 2.", "helpfulness_rationale": "The review comment critiques the metric learning theory in the paper, noting that it is not novel or better than existing theoretical results. It suggests that the proposed metric perspective analysis does not yield better results compared to previous findings. This feedback provides a clear direction for the authors to consider how to enhance the metric learning aspect of their work. However, the comment lacks specific suggestions or guidance on how to improve the metric learning section, leaving the authors with a general idea but without actionable steps. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a central experiment. It also recommends condensing the current figures to make space for these visual results. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors on which figures to move or how to condense them. The action is somewhat vague, as the authors need to infer which figures to move and how to condense them to effectively utilize the space. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a central experiment. It also recommends condensing the current figures to make space for these visual results. However, the comment does not specify which figures are being referred to or how they should be condensed, making it weakly grounded. The comment is specific in its suggestion to include visual results on crowd density estimation, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests moving visual results from the supplementary material to the main paper, specifically noting the lack of visual results on crowd density estimation, which is a central experiment. It recommends condensing the current figures to make space for these visual results. However, the comment lacks specific examples or references to support the claim that the current figures are insufficient or how they should be condensed. Without detailed reasoning or examples, the claim is 3, as the authors may need to infer the basis for the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the organization of the paper, suggesting that visual results from the supplementary material should be moved to the main paper to enhance the presentation of crowd density estimation, a central experiment. It also recommends condensing the current figures to make space for these visual results. This feedback is actionable and constructive, as it directly addresses a specific area of the paper that could improve its clarity and impact. By providing clear guidance on where to move visual results and how to condense figures, the comment empowers the authors to make meaningful improvements to their draft. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. However, it does not provide explicit guidance on how to address this issue or what actions the authors should take to improve their draft. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. However, it does not specify which part of the paper this issue is related to, such as a particular section or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its inquiry about the importance of test examples and the potential use of corpus residual value, but it lacks detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. However, it does not provide any specific reasoning, examples, or references to support the claim that this is a significant issue or how it might be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. This inquiry is valuable as it prompts the authors to consider the robustness of their experimental setup and the potential impact of corpusspecific biases. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or what steps they could take to improve their draft. While it identifies a potential area for improvement, it does not provide detailed feedback or concrete advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not explicitly instruct the authors to change their dataset or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the WebQuestions benchmark set. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not specify which part of the paper discusses the choice of the testbed dataset or the rationale behind it. The authors would need to infer that the comment relates to the methodology or experimental setup section. This lack of explicit grounding makes it weakly grounded. The comment is specific in its suggestion to use a more popular benchmark set, but the lack of grounding makes it difficult for the authors to pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. The rationale provided in the comment explains that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions is more intuitive or straightforward. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the choice of the testbed dataset, specifically questioning the use of WebQuestionsSP and suggesting the more popular WebQuestions benchmark set instead. The rationale provided explains that WebQuestions is more intuitive and straightforward for weak supervision tasks, which would facilitate direct comparison with mainstream QA research. This feedback is 3 as it points out a potential area for improvement and provides a rationale for why the authors might consider using a different benchmark set. However, the comment could be more helpful if it offered specific guidance on how to implement this suggestion or provided additional context on why the WebQuestions benchmark set is more suitable. Overall, the comment is 3, as it offers a clear direction for improvement but lacks detailed actionable advice."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It also implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The action is implicit and vague, as it does not specify how to demonstrate the benefits of sparsity or how to make the claims more convincing. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not specify which part of the paper discusses sparsity or training, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of sparsity and its relevance, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide specific examples, references, or detailed reasoning to support its claim. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some basis for questioning the claims but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide specific guidance or suggestions on how to address this issue or what additional evidence might be needed to support the claims. While it raises a valid point about the need for demonstration, it lacks actionable advice or detailed feedback on how to improve the draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance for the authors to enhance their work."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, it does not provide any specific suggestions or actions for the authors to take to address this issue or enhance the novelty of their work. The comment lacks explicit guidance on how the authors might improve their design or what specific aspects need to be revised to make it more novel. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, it does not specify which part of the paper this claim is related to, such as the introduction, methodology, or results sections. Without this context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the novelty of the design. Therefore, the comment is 1 and lacks specificity, making it ungrounded and not specific.", "verifiability_rationale": "The review point claims that the novelty of the design is limited because it is based on the use of attention for motion learning, which has been widely used in video understanding. However, the comment does not provide any specific evidence or references to support this claim, such as examples of similar work or detailed explanations of how the design aligns with existing approaches. Without this additional context, the authors may find it difficult to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the design, suggesting that it is based on the use of attention for motion learning, which has been widely used in video understanding. This feedback highlights a concern that the authors may need to address to enhance the originality of their work. However, the comment lacks specific suggestions or guidance on how the authors might improve the novelty of their design or address the identified limitation. Without actionable advice or detailed examples, the authors may find it challenging to understand how to respond to this feedback effectively. Therefore, the comment is 3, as it points out a potential issue but does not provide comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy between the use of BigFive and MBTI as models in the Abstract and Introduction sections and their use as datasets in the Experiments section. It suggests that the authors should either consistently treat them as datasets or provide an extended explanation for their use as models. While the comment identifies a specific issue and suggests a course of action, it does not provide explicit guidance on how to implement the change or what specific aspects of the paper need to be revised. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the use of BigFive and MBTI as models in the Abstract and Introduction sections but inconsistently as datasets in the Experiments section. It suggests that the authors should either consistently treat them as datasets or provide an extended explanation for their use as models. However, the comment does not specify which parts of the paper need to be revised or what specific changes should be made. The authors cannot confidently determine which sections are being referred to, making the comment weakly grounded. While it is specific in identifying the inconsistency, the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that Big Five and MBTI are used inconsistently as models and datasets throughout the paper. The comment suggests that the authors should either consistently treat them as datasets or provide an extended explanation for their use as models. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the issue or how to address it. Without detailed reasoning or evidence, the claim is considered 2, as it provides some basis but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a significant inconsistency in the use of Big Five and MBTI, which are initially presented as models in the Abstract and Introduction but are later used as datasets in the Experiments section. This inconsistency raises concerns about the clarity and coherence of the paper. The comment suggests that the authors should either consistently treat these terms as datasets or provide a detailed explanation for their use as models. While the comment highlights a specific issue, it does not offer detailed guidance on how to address it or what specific changes should be made to the paper. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. While the comment provides a clear action\u2014either to include rejection rates or to consider misclassifications as rejections\u2014it does not specify how to implement this action. The authors are left with a general direction but lack concrete guidance on how to incorporate rejection rates into their results or how to justify viewing misclassifications as rejections. Therefore, the comment is 3, as it provides an explicit action but lacks detailed guidance on execution.", "grounding_specificity_rationale": "The comment suggests that the rejection rate is not shown in any experiments and recommends including it or viewing misclassifications as rejections. However, it does not specify which part of the paper this issue pertains to, such as the results section or a specific table. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the rejection rate is not shown in any experiments, which is a factual observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to verify the claim independently. The comment suggests that misclassifications could be viewed as rejections, but it lacks detailed reasoning or evidence to substantiate this claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the rejection rate is not shown in any experiments. It suggests that misclassifications could be viewed as rejections, which is a valuable insight for the authors to consider. However, the comment lacks detailed guidance on how to incorporate rejection rates into the results or how to justify viewing misclassifications as rejections. While it provides a clear direction for improvement, the feedback could be more helpful if it included specific steps or examples for the authors to follow. Therefore, the comment is 3, as it offers a clear area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. While the comment explicitly requests information about the thresholds and hyperparameters, it does not provide specific guidance on how to obtain or present this information. The authors are left to infer that they need to provide these details, but the action is not concrete. Therefore, the comment is 3, as it provides an implicit action but lacks detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment requests clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. However, it does not specify which part of the paper contains this information, making it difficult for the authors to identify the exact section or table that needs attention. The comment is specific in its request for information but lacks grounding as it does not provide clear references or guidance on where to find the relevant details. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point asks for clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. This is a request for additional information and clarification, which does not contain a subjective claim or opinion. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment requests clarification on the final thresholds used in the results and suggests that sharing the full set of hyperparameters would enhance reproducibility. While the comment identifies an area for improvement, it lacks specificity and actionable guidance on how to address the issue. The authors are left to infer that they need to provide these details, but the comment does not offer concrete steps or examples to enhance the clarity and reproducibility of their work. Therefore, the comment is 3, as it provides a general direction for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential nuance in the original claim, it does not provide explicit guidance on how the authors should address this issue or what specific features they should consider. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of different features on question difficulty. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. However, the comment does not specify which part of the paper this critique refers to, making it weakly grounded. It is specific in detailing what the authors should consider regarding the impact of different features on question difficulty, but without explicit references to sections or figures, the authors may struggle to identify the exact area of concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment provides a specific example of a potential factor that could influence the conclusion, it lacks detailed reasoning or references to support the claim. The authors are left to infer the basis of the critique, which makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques a specific claim made in the paper, pointing out that the conclusion about the relationship between RC dataset readability and question difficulty might be influenced by the method or features used for answer detection. This feedback is 3 as it identifies a potential nuance in the original claim and suggests a direction for further consideration. However, it could be more helpful if it provided specific guidance on how the authors might explore this influence or what additional experiments or analyses could be conducted to address this concern. Overall, the comment offers a valuable critique but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. This is a specific and actionable suggestion, as it provides a clear direction for improvement. The authors know exactly what aspect of the figure needs attention and what kind of optimization is being suggested. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests optimizing Figure 1 to use less whitespace, but it does not specify which part of the paper Figure 1 corresponds to or provide any context for why this optimization is necessary. Without this information, the authors cannot confidently determine which section or figure is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the figure could be optimized or why less whitespace is beneficial. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that Figure 1 could be optimized to use less whitespace. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 1 could be optimized to use less whitespace. While this is a specific suggestion, it lacks broader context or detailed reasoning on why optimizing the figure is beneficial or how it could be achieved. The comment provides a clear direction for improvement but does not offer comprehensive guidance or insights into the implications of the suggestion. As a result, the feedback is 3, as it identifies an area for enhancement but does not fully address the authors\" needs for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how to improve the writing quality or address the issue of missing related work. The authors are left to infer that they need to revise the paper to enhance its clarity and comprehensiveness, but the lack of concrete suggestions makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks. However, the comment does not specify which part of the paper discusses memory networks or the forward model, nor does it indicate which sections of the related work are missing. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the writing quality of the paper should be improved, specifically noting that the authors spend the same space on explaining basic memory networks and the forward model. It also mentions that the related work section has missing pieces on more reinforcement learning tasks. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the writing quality of the paper and the comprehensiveness of the related work section. It points out that the authors spend the same space on explaining basic memory networks and the forward model, which could be streamlined for better clarity. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is 3 as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking for improvements in accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment does not explicitly instruct the authors on how to implement this suggestion or what specific aspects to focus on. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that if the authors did not find improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties. It provides an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in suggesting what to look for, but without clear references, the authors may struggle to identify the exact sections or parts of the paper that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that if the authors did not see improvements in FLOPs or inference time, they should consider looking at accuracy or specific properties, with an example related to recurrent models. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the reasoning behind it. Without clear justification or references, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides a suggestion for the authors to consider if they did not see improvements in FLOPs or inference time, suggesting they should look at accuracy or specific properties. It offers an example, such as the potential for easier modeling of sequential relationships in a recurrent model. However, the comment lacks depth and does not provide specific guidance on which aspects to focus on or how to approach this exploration. While it offers a starting point, it does not fully address the authors\" needs for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. While it implies that the authors should have tested this assumption, the comment does not explicitly instruct or suggest how to conduct the test. The action is implicit, as the authors need to infer that they should test the assumption. However, the comment lacks concrete guidance on how to perform the test or what specific aspects to consider. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not specify which part of the paper this assumption is made or where it is discussed. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the testing of the assumption, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the assumption that d_e are good replacements for entity embeddings has been tested. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the assumption made regarding the use of d_e as replacements for entity embeddings. It questions whether this assumption has been tested, which is a crucial aspect of ensuring the validity of the research. However, the comment does not provide any specific guidance or suggestions on how the authors might test this assumption or what aspects they should consider. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it highlights a potential issue but does not offer detailed guidance on how to address it."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not provide any guidance or suggestions on how to address this question or what aspects of the simulation might benefit from such an analysis. The comment lacks explicit instructions or concrete advice, leaving the authors without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. Without this context, the authors cannot accurately identify the area that needs clarification or discussion. The comment is 1, as it lacks specific references to the paper, making it difficult for the authors to understand which part of the paper is being addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. It does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, aligning with the classification of \"No\".", "helpfulness_rationale": "The review comment poses a question about the number of different kinds of physical interactions that can be included in a simulation. While it highlights an area that might require further clarification or discussion, it does not provide any specific guidance or suggestions on how to address this question or what aspects of the paper might benefit from such an analysis. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. While the comment identifies specific issues with the dataset selection and suggests that the authors should consider the importance of categorical features and onehot encoding, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, which is the model comparison section. It provides detailed feedback on the dataset selection, noting that only one dataset contains categorical features while the others are exclusively numerical. This feedback is specific, as it clearly specifies what needs to be addressed in the model comparison section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. The comment provides a clear and logical explanation of why the dataset selection is inadequate and suggests that the authors should consider the importance of categorical features and onehot encoding. However, it lacks specific examples or references to support the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the model comparison section, highlighting a significant limitation in the dataset selection. It points out that only one dataset contains categorical features, while the others are exclusively numerical, which may affect the conclusions drawn from the comparison. Additionally, it notes the absence of onehot encoding for the categorical dataset, which could negatively impact model performance. This feedback is clear and actionable, as it identifies specific areas where the authors need to improve their draft. However, it could be more helpful if it suggested specific ways to address these issues, such as recommending the inclusion of additional datasets with categorical features or the use of onehot encoding. Overall, the comment is 4, as it provides valuable insights for improvement but could be more comprehensive with detailed suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the choice of IoT datasets, specifically FlatCam Face 26 and Headpose detection 11, is unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might have been more appropriate. While the comment identifies a potential issue with the dataset selection, it does not provide explicit guidance on how the authors should address this concern or what specific datasets they should consider. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative datasets and potentially reevaluate their benchmarking results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the choice of IoT datasets, namely that they are unpopular and outdated, and suggests better options for benchmarking. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of IoT datasets, specifically FlatCam Face 26 and Headpose detection 11, is unpopular and outdated, making the benchmarking results difficult to sense and evaluate. The comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. However, the comment lacks specific examples or references to support the claim about the datasets being unpopular or outdated. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of IoT datasets used in the paper, noting that the selected datasets, FlatCam Face 26 and Headpose detection 11, are unpopular and outdated. The authors are questioned about why these datasets were chosen, and the comment suggests that better options, such as wearable health or mobile activity recognition data, or data from UCI, might be more appropriate. This feedback is 3 as it highlights a potential weakness in the dataset selection and provides suggestions for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct a more comprehensive benchmarking or suggested alternative datasets in detail. Overall, the comment provides a clear direction for improvement, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a clear and explicit action that the authors can easily understand and implement. The comment provides a specific and concrete instruction on how to improve the figure, making it 5.", "grounding_specificity_rationale": "The comment suggests that the annotations in Figure 4 can be further enlarged for better visibility. However, it does not specify which part of the paper Figure 4 is located in, nor does it provide any context or explanation for why this is necessary. The authors may infer that it refers to a specific section or figure, but the lack of explicit mention makes it difficult to pinpoint the exact area. The comment is specific in its suggestion but weakly grounded as it does not provide clear guidance on which part of the paper needs attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a factual observation about the presentation of the figure, but it does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is descriptive and does not provide any reasoning or evidence to support the claim. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment suggests that the annotations in Figure 4 can be further enlarged for better visibility. This is a specific and actionable piece of feedback that the authors can easily implement. By making the annotations more visible, the authors can improve the readability and understanding of the figure, which is crucial for the clarity of the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to achieve this enlargement effectively. Overall, the comment is 3 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment raises a concern about the generality of the claim but does not offer guidance on how to address it or what changes might be necessary. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific as it clearly specifies what the issue is, questioning the generality of the claim. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this critique. Without additional context or justification, the claim remains unsubstantiated, making the comment 1. Therefore, the comment is labeled as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim that \"Multiple entities typically exist in both sentences and documents and this is the case even for relation classification, not only documentlevel RE or joint entity and relation extraction.\" However, it does not provide any suggestions or guidance on how to address this issue or improve the draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse\". This is a specific and actionable suggestion that the authors can easily address by revising the label. The comment provides clear guidance on what needs to be changed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that one of the labels on the color bar should be \"worse,\" providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that one of the labels on the color bar of Fig. 4 should be \"worse.\" This is a specific and actionable suggestion that is clear and verifiable. The authors can easily address this by revising the label, making the comment 5. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is specific and actionable, pointing out a potential error in the labeling of a color bar in Figure 4. It suggests that one of the labels should be \"worse,\" which is a clear and direct feedback that the authors can easily address. This feedback provides a specific direction for improvement, making it 5 for the authors to enhance the accuracy and clarity of their work. Therefore, the comment is rated as 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point identifies a specific issue in the text, pointing out that the phrase \"training/validation/test\" should be \"training/validation/test sets\". This is an explicit action that the authors can take to correct the text. The comment is clear and provides a concrete instruction on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Row 757 in Supp. Page 29,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the correction needed, which is to change \"training/validation/test\" to \"training/validation/test sets\". This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual correction, stating that the phrase \"training/validation/test\" should be \"training/validation/test sets\" in the specified location. This is a straightforward factual correction and does not require any additional reasoning, common knowledge, or external references to be understood or verified. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is specific and actionable, pointing out a minor error in the text where the phrase \"training/validation/test\" should be corrected to \"training/validation/test sets\". This feedback is clear and provides a direct instruction for the authors to make the necessary change, which is essential for improving the accuracy and clarity of the paper. Therefore, the comment is 5, as it offers a clear and concise suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit, as the authors would need to infer how to provide the requested information or improve the writing. Therefore, the comment is 3, as it provides some guidance but lacks concrete details on how to implement the suggestions.", "grounding_specificity_rationale": "The comment raises several questions and concerns about specific aspects of the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment does not explicitly mention specific sections or parts of the paper that need attention, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues that need to be addressed, such as the coefficient and hyperparameter details. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several questions and concerns about the paper, including the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment lacks specific examples, detailed reasoning, or references to support the claims made. The questions raised are openended and do not provide clear guidance or evidence for the authors to address the issues. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several important questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies areas that need clarification or improvement, it lacks specific guidance on how to address these issues or provide additional details. The feedback is 3 as it points out potential weaknesses and areas for improvement, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a \"very high performing model\" or a similar phrase. This provides a clear and explicit action for the authors to take, as they can directly address the issue by considering alternative models or updating their references. The comment is specific in its suggestion, offering concrete guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 152,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion to replace the model by Dozat and Manning (2016) with a \"very high performing model\" or a similar phrase. This guidance is concrete and directly addresses the issue, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the model by Dozat and Manning (2016) is no longer stateoftheart and recommends replacing it with a \"very high performing model\" or a similar phrase. While the comment provides a suggestion, it lacks specific reasoning or evidence to support why the model is no longer stateoftheart. Without additional context or references, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the model used in the paper, suggesting that the model by Dozat and Manning (2016) is no longer stateoftheart. It provides a clear recommendation to replace it with a \"very high performing model\" or a similar phrase. This feedback is actionable and offers a concrete suggestion for improvement, helping the authors enhance the relevance and accuracy of their work. However, the comment could be more helpful if it provided additional context or guidance on how to select an appropriate alternative model. Overall, the comment is 4 as it directs the authors towards a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation identifies a key weakness of the method. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the method. The authors are left without guidance on what steps to take to enhance their work, making the comment 1. Therefore, this comment aligns with a score of 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the proposed compression\" and \"PQ,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed compression performs worse than PQ when a small code length is allowed, which is a clear and specific critique. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the proposed compression performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation highlights a key area for improvement, as it points out a limitation of the method that could impact its practical application. However, the comment does not provide any suggestions or guidance on how to address this issue or enhance the method. While it identifies a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point identifies several areas where the paper could be improved, such as the inclusion of subjective statements, the need for proofs and references to support claims, and the lack of detailed explanation for certain statements. It also suggests that the paper should provide a detailed explanation to verify these claims. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to do so. The actions are implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses issues with subjective statements and the need for proofs and references to support claims. It also mentions specific areas, such as the laborintensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, it does not specify which part of the paper these issues are present in, making it weakly grounded. The comment is specific in detailing the need for additional evidence and detailed explanations, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about subjective statements and the need for proofs and references to support claims. It also mentions the laborintensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. However, the comment lacks specific examples or references to substantiate these claims, making it difficult for the authors to understand and address the issues. The feedback is 3 as it provides a general direction but lacks detailed support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, such as the inclusion of subjective statements and the need for proofs and references to support claims. It also highlights the laborintensive nature of seeking an effective architecture and the sensitivity of image recovery performance to neural architecture choices. The comment suggests that the paper should provide a detailed explanation to verify these statements, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the feedback is 3 as it points out areas for improvement but lacks depth and detail, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point asks a question about how the proposed method compares with prior art. While it prompts the authors to consider this comparison, it does not provide explicit instructions or suggestions on how to address this comparison. The authors are left to infer that they need to include a comparison with prior work, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment asks a question about how the proposed method compares with prior art. However, it does not specify which part of the paper this comparison should be made or what aspects of the comparison are relevant. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its request for a comparison, but without grounding, the authors are left to make an educated guess about where to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the proposed method compares with prior art. However, it does not provide any specific details, examples, or references to support this claim. Without additional context or evidence, the authors are left to make their own judgments about the relevance and importance of this comparison. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how the proposed method compares with prior art, which is a relevant and important aspect for evaluating the novelty and contribution of the work. However, the comment lacks specific guidance or suggestions on how to address this comparison. It does not provide any insights into what kind of comparison would be beneficial or how the authors might approach it. Without actionable advice or examples, the comment is 3 as it identifies an important area for improvement but does not provide sufficient direction for the authors to address it effectively. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not explicitly instruct the authors to add more detailed analyses or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the need for more detailed analysis and the specific areas where it should be expanded. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more detailed analyses and to compare different languages/nationalities, but without explicit references to sections or figures, the authors may need to infer the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment lacks specific examples or references to support the claim that the current analyses are insufficient or that there are interesting observations that could be made. Without detailed reasoning or examples, the claim is 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. This feedback is 3 as it identifies an area for improvement by suggesting more detailed analysis and prompting the authors to consider interesting comparisons. However, the comment could be more helpful if it provided specific guidance on how to conduct these analyses or examples of interesting observations that could be made. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether there are other properties of features that could be used in the approach design. While it suggests that exploring additional properties might be beneficial, it does not provide explicit guidance on how to identify or utilize these properties. The comment is somewhat vague, as it lacks specific examples or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a direction but not a detailed path for implementation.", "grounding_specificity_rationale": "The comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide context or references to specific sections or parts of the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about whether there are other properties of features that could be used in the approach design, suggesting that exploring additional properties might be beneficial. This feedback is 3 as it prompts the authors to consider expanding their approach and potentially enhancing its effectiveness. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how to explore these additional properties. Without concrete examples or actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where the proposed method (PE) is important. However, it does not provide any specific guidance or suggestions on how to achieve this, such as which tasks to include or how to demonstrate the importance of PE in those tasks. The comment lacks explicit instructions or concrete details, making it difficult for the authors to understand what actions they should take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not specify which tasks or sections of the paper should be addressed to achieve this. The authors cannot confidently determine which part of the paper needs revision based on this comment alone. Therefore, the comment is 1, as it does not provide specific guidance on which sections or parts of the paper to address. It is also not specific because it does not detail what needs to be added or improved. As a result, this comment is rated as \"1\".", "verifiability_rationale": "The review point suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to incorporate it into their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it lacks specific guidance or examples on how to achieve this, making it difficult for the authors to understand the implications of the comment or how to improve their draft. The feedback is 3 as it points out a potential area for expansion, but it does not provide actionable steps or detailed suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the inclusion of fewshot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not provide explicit guidance on how to implement this suggestion, such as which specific demonstrations to include or how they should be structured. The comment is somewhat vague, as it leaves the authors to infer the exact action needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the inclusion of fewshot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. The comment is vague in terms of specificity, as it does not detail what aspects of the fewshot demonstrations would be beneficial or how they should be presented. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the inclusion of zeroshot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. The comment does not provide specific examples or references to support the claim that the inclusion of zeroshot results is problematic or unnecessary. As a result, the claim is considered 2, as it lacks sufficient evidence to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of zeroshot generation results, suggesting that it might not be necessary or relevant to the paper\"s main focus. While the comment raises a valid point about the relevance of zeroshot results, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the draft. The feedback is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a minor issue regarding Figure 3, noting that the label \"OAA\" is not referenced in the body text. It also suggests that there might be additional content in the appendix that is missing or that the caption is out of date. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how to address the issue, such as suggesting where the additional content might be or how to update the caption. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that the label \"OAA\" is not referenced in the body text and suggesting that there might be additional content in the appendix or an outofdate caption. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a minor issue regarding Figure 3, specifically noting that the label \"OAA\" is not referenced in the body text. It also suggests that there might be additional content in the appendix or that the caption is out of date. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that \"OAA\" is not referenced. The authors would need to independently verify this claim by checking the body text, which could be timeconsuming. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the label \"OAA\" is not referenced in the body text. It also suggests that there might be additional content in the appendix or that the caption is out of date. While the comment points out a potential oversight, it does not provide detailed guidance on how to address the issue or what specific steps the authors should take to resolve it. The feedback is 3 as it highlights a minor but important detail that could improve the clarity and completeness of the paper, but it lacks actionable suggestions for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference 2. While the comment implies that the authors should investigate this aspect, it does not provide explicit instructions or detailed guidance on how to conduct the analysis or present the findings. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the impact of the GS module on the effective receptive field. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of the GS module and its impact on the effective receptive field, referencing a specific paper 2. It does not explicitly mention a specific part of the paper where this issue is discussed, making it weakly grounded. However, the comment is specific in its focus on the effective receptive field and its relevance to the GS module. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the effective receptive field is improved after applying the GS module and suggests that this can be computed from a reference 2. While the comment implies that the authors should investigate this aspect, it lacks specific details or examples to support the claim. The suggestion to compute the effective receptive field from 2 is a starting point, but the comment does not provide a clear methodology or reasoning for why this is important or how it would be implemented. Therefore, the claim is 3, as it provides a basis for further exploration but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises a question about the effectiveness of the GS module in improving the effective receptive field, suggesting that this can be computed from a reference 2. This feedback is 3 as it points out a potential area for further analysis and exploration, which could enhance the understanding of the module\"s impact. However, the comment lacks detailed guidance on how to conduct this analysis or present the findings, leaving the authors with limited actionable steps. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, specifically mentioning the probabilities of actions. It also proposes that the authors may add another head to the network to compute value functions for states during the finetuning stage. This comment provides explicit guidance on what the authors should consider and how they might improve their draft by adding another head to the network. The action is clear and concrete, as it specifies exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides a specific suggestion for improving the LSTM part of the paper, focusing on the objective for pretraining and finetuning. It suggests that the authors may add another head to the network to compute value functions for states during the finetuning stage. This comment is fully grounded as it explicitly mentions the LSTM part, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear and actionable suggestion for improvement. Therefore, this comment is classified as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the objective for the LSTM part is the same for pretraining and finetuning, specifically mentioning the probabilities of actions. It proposes that the authors may add another head to the network to compute value functions for the states during the finetuning stage. This comment is 4 as it provides a clear and logical suggestion for improvement, aligning with the reasoning and common knowledge of the field. However, it could be strengthened by providing more detailed justification or examples to fully substantiate the claim. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improving the LSTM part of the paper, noting that the objective for pretraining and finetuning is the same, specifically mentioning the probabilities of actions. It suggests that the authors may add another head to the network to compute value functions for the states during the finetuning stage. This feedback is clear and actionable, offering a concrete improvement that the authors can implement to enhance their draft. By providing a specific suggestion, the comment helps the authors address a potential area for improvement in their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should acknowledge some of the older works in the related works section. While the comment implies that the authors should include these older works, it does not provide specific guidance on which works to acknowledge or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should acknowledge some of the older works in the related works section. However, it does not specify which part of the paper this comment refers to, making it weakly grounded. The comment is specific in its suggestion to acknowledge older works, but without a clear reference to the section, the authors may find it challenging to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should acknowledge some of the older works in the related works section. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should acknowledge some of the older works in the related works section. While this feedback is relevant and provides a direction for improvement, it lacks specific guidance on which works to acknowledge or how to integrate them into the paper. The comment is 3 as it identifies a potential area for enhancement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit, as the authors need to infer that they should investigate the results further or consider alternative sampling strategies. While the suggestion is concrete, the lack of explicit guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, questioning why linear/exponentialdecay sampling underperforms uniform sampling and suggests an alternative approach based on the authors\" argument about the predictor\"s accuracy on the good subregion. This provides a clear direction for the authors to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the results are confusing or that the suggested alternative approach is valid. The lack of evidence or justification makes the claim 3, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the results presented in Table 2, specifically regarding the underperformance of linear/exponentialdecay sampling compared to uniform sampling. It suggests that if the predictor is accurate on the good subregion, increasing the sampling probability for topperforming predicted architectures could lead to better performance. This feedback is 3 as it identifies a potential area for clarification and suggests an alternative approach that could improve the results. However, the comment could be more helpful if it provided more detailed guidance on how to investigate the results or what specific steps the authors should take to address the issue. Overall, the comment offers a valuable insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights potential issues with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, it does not provide explicit or implicit actions for the authors to take to address these concerns. The comment identifies potential areas for improvement but lacks guidance on how to implement these suggestions or what specific changes might be made to mitigate the high time complexity. As a result, the authors are left without a clear path forward, making the comment 1.", "grounding_specificity_rationale": "The comment addresses the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. However, it does not specify which part of the paper these issues are discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in detailing the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the time complexity of the proposed method is high, citing the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment does not provide specific evidence, examples, or references to support these claims. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies potential issues with the time complexity of the proposed method, specifically mentioning the use of an itemoriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorizationbased methods. While the comment highlights these concerns, it does not provide specific suggestions or guidance on how the authors might address these issues or improve the efficiency of their method. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. This comment provides a clear and explicit action for the authors to take, which is to label the figures more precisely. The suggestion is concrete, as it specifies exactly what needs to be done to improve the clarity of the figures. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, it does not explicitly mention which figures are being referred to, making it weakly grounded. The comment is specific in its suggestion to improve the clarity of the figures by providing more detailed labels. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the figures would be clearer if they specified \"pretrained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification or examples to fully substantiate the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the figures, suggesting that labeling them as \"pretrained solution encoders & solution decoders\" would improve their readability. This feedback is clear and actionable, providing the authors with a direct and specific direction for enhancing the presentation of their figures. By addressing this suggestion, the authors can significantly improve the clarity and understanding of their work. Therefore, the comment is 5, as it offers a clear and constructive improvement that directly addresses a specific aspect of the paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. While the comment explicitly suggests that a brief explanation of \"multiaspect\" would be helpful, it does not provide guidance on how to implement this suggestion, such as what kind of explanation would be beneficial or how to integrate it into the paper. Similarly, the question about the subscripts in Figure 1 is specific but lacks guidance on how to address it. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on how to achieve them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line numbers (14 and 47) and a figure (Figure 1), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed: a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. This level of detail provides clear guidance on what the authors should do to improve their draft. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. The first part is a suggestion for improvement, but it lacks specific guidance on how to provide the explanation or what aspects to cover. The second part is a question that requires clarification but does not provide any evidence or reasoning to support it. Therefore, the comment is 4, as it provides some basis for improvement but lacks detailed justification or references. The score is 4.", "helpfulness_rationale": "The review comment provides specific feedback on two aspects of the paper: the need for a brief explanation of \"multiaspect\" and a question about the subscripts in Figure 1. While the comment identifies areas for improvement, it lacks detailed guidance on how to address these issues. For instance, it does not suggest specific ways to clarify the \"multiaspect\" concept or provide examples to enhance understanding. Similarly, the question about the subscripts in Figure 1 is openended and does not offer actionable advice on how to resolve it. Therefore, the comment is 3, as it highlights important areas for improvement but does not provide comprehensive or detailed guidance for the authors to follow. The feedback is valuable but could be more impactful with additional suggestions or examples."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment explicitly asks for clarification and suggests a more detailed analysis, it does not provide explicit instructions on how to conduct the analysis or what specific aspects need to be detailed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on the extraction process and its impact on the experiment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how parts of sentences and documents are extracted and whether the extraction rules have an effect on the experiment, along with a request for a more detailed analysis. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. However, the comment does not provide any specific reasoning, examples, or references to support the need for clarification or detailed analysis. The authors are left to infer the importance of these questions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment identifies a potential area for clarification and suggests a more thorough analysis, it lacks specific guidance on what aspects of the extraction process need to be detailed or how the analysis should be conducted. This provides the authors with a general direction for improvement but could be more helpful with additional suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point asks for information about the computational requirements of the experiments, specifically the time taken and the hardware used. While it prompts the authors to provide this information, it does not explicitly instruct them to include it in the paper or suggest where to add it. The action is implicit, as the authors can infer that they need to provide this information, but it lacks concrete guidance on how to present or discuss it. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests information about the computational requirements, including the time taken and the hardware used, which are key details for understanding the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the computational requirements of the experiments, specifically the time taken and the hardware used. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is 3 as it prompts the authors to provide information about the computational requirements of their experiments, specifically the time taken and the hardware used. This is a relevant piece of information for understanding the practical aspects of the experiments and their reproducibility. However, the comment lacks depth and does not provide specific guidance on how to present or discuss this information in the paper. While it identifies an important area for improvement, it does not offer detailed suggestions or examples, making it 3 rather than fully helpful."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. While it prompts the authors to provide more discussion, it does not explicitly instruct them to do so or provide detailed guidance on how to address this concern. The action is implicit, as the authors need to infer that they should discuss the application of the meta sampler and the specific epoch it is applied. However, the lack of concrete instructions or examples makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its request for more discussion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not provide any evidence, reasoning, or references to support the claim that the authors only apply the meta sampler in a decoupled way or when specific epochs are used. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the application of the meta sampler, asking whether it is used in a decoupled way and when it is applied. This feedback is 3 as it prompts the authors to provide more discussion on the methodology and its application. However, the comment lacks depth and does not offer suggestions or guidance on how to address the concern, leaving the authors with limited actionable feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the content on lines 107114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment 5. The explicit suggestion to either rephrase, include in a discussion, or remove the content gives the authors a direct path to improvement.", "grounding_specificity_rationale": "The comment suggests that the content on lines 107114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment 5. However, the comment does not specify which part of the paper this refers to, leaving the authors to infer that it is the content on lines 107114. Therefore, the comment is fully grounded but lacks specificity, aligning with a score of 4.", "verifiability_rationale": "The review point suggests that the content on lines 107114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. While the comment provides a clear recommendation, it lacks specific examples or references to support the claim that the content is speculative or overly opinionated. This makes the claim 3, as the authors would need to independently assess the content to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific section of the paper (lines 107114) as being speculative or overly opinionated, suggesting that it should be rephrased, included in a discussion section, or removed. This feedback is clear and actionable, providing the authors with a direct path to improve the clarity and objectivity of their work. By offering specific suggestions for how to address the issue, the comment is 4, as it guides the authors in making necessary revisions. However, it could be more helpful if it provided additional context or examples to support the claim about the content being speculative or opinionated. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement achieved by the changes suggested in the paper. While the comment implies that these baselines should be included, it does not explicitly instruct the authors to add them or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate these baselines into their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include these baselines, but without clear grounding, the authors may struggle to identify the exact section or part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, the comment lacks specific examples or references to support the claim that these baselines are necessary or would provide additional insights. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered 2, as it provides some indication of the need for additional baselines but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. This feedback is 3 as it identifies a potential area for further validation and provides a specific suggestion for improvement. However, the comment lacks depth and does not offer detailed guidance on how to implement this suggestion or why these baselines are particularly relevant. As a result, the authors may gain some insight but may need additional clarification to fully understand and address the feedback. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights two key issues that need addressing: the lack of analysis regarding the value of the neighborhood size h and its influence on the model\"s performance, and the inconsistent use of hyperparameter sets across different datasets. The comment suggests that providing readers with intuitive knowledge of the value of h to use and demonstrating the robustness of the method with respect to varying neighborhood sizes is essential. It also questions whether the authors can provide insights into how performance varies with a constant set of parameters. While the comment identifies the areas that need improvement, it does not explicitly instruct the authors on how to conduct the analysis or provide specific guidance on how to address these issues. The action is somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the missing element of the value of neighborhood size h and its influence on the model\"s performance, which is a key parameter of the proposed strategy. It also mentions the inconsistent use of hyperparameter sets across different datasets, which is not ideal. However, the comment does not specify which part of the paper discusses the neighborhood size or the hyperparameter sets, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the issues, it lacks grounding as it does not provide clear references to the relevant sections. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two main concerns: the lack of analysis regarding the value of neighborhood size h and its influence on the model\"s performance, and the inconsistent use of hyperparameter sets across different datasets. The comment suggests that providing readers with intuitive knowledge of the value of h to use and demonstrating the robustness of the method with respect to varying neighborhood sizes is essential. It also questions whether the authors can provide insights into how performance varies with a constant set of parameters. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims, making it 3. The authors would need to infer the basis for the claims, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant areas for improvement in the paper: the lack of analysis regarding the value of the neighborhood size h and its influence on the model\"s performance, and the inconsistent use of hyperparameter sets across different datasets. The comment highlights the importance of neighborhood size h as a key parameter of the proposed strategy and suggests that providing readers with intuitive knowledge of the value of h to use, along with demonstrating the robustness of the method with respect to varying neighborhood sizes, is essential. Additionally, the comment points out that different hyperparameter sets are used per dataset, which is not ideal and questions whether the authors can provide insights into how performance varies with a constant set of parameters. This feedback is 4 as it provides clear directions for improvement, but it could be more comprehensive if it included specific suggestions or guidance on how to address these issues. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. While the comment prompts the authors to consider these aspects, it does not provide explicit instructions or suggestions on how to address these questions or incorporate them into the paper. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not specify which part of the paper addresses this issue, making it weakly grounded. It is specific in detailing the question about the model\"s behavior with imperfect multimodal data, but without explicit references to sections or figures, the authors cannot confidently identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not provide any evidence, reasoning, or references to support these claims or questions. The authors are left to interpret the questions without any guidance or justification, making the comment 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises important questions about the model\"s performance when multimodal data is imperfect, specifically when certain modalities are missing. It prompts the authors to consider the impact on the model and whether it can leverage additional modalities to infer missing ones. This feedback is valuable as it highlights a potential area for further exploration and analysis, which could enhance the robustness and applicability of the model. However, the comment lacks specific suggestions or guidance on how to address these questions or incorporate them into the paper, making it 3. The authors would need to infer the necessary steps to improve their draft, which limits the comment\"s impact. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment suggests an analysis, it does not provide explicit guidance on how to conduct this analysis or what specific actions the authors should take. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"General Discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear question and suggestion for analysis, asking for statistics on the effectiveness of negation or intensity words in the SST dataset. This guidance is detailed and specific, making the comment 5.", "verifiability_rationale": "The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment does not contain a subjective claim, it suggests a specific analysis that could be beneficial for the authors. However, it lacks detailed reasoning or references to support why this analysis is important or how it would enhance the paper. The comment is 3 as it provides a clear suggestion but lacks depth and justification. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a specific question about the effectiveness of negation or intensity words in the SST dataset, particularly focusing on how often these words change the polarity of the context. It suggests that the authors should provide statistics on the frequency of these words and their impact on the dataset. This feedback is actionable and provides a clear direction for the authors to improve their analysis or discussion. However, the comment could be more helpful if it offered additional guidance on how to conduct this analysis or presented examples of how such statistics could be presented. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear suggestion, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors consider additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. While the comment provides a direction for improvement by suggesting specific methods to explore, it does not explicitly instruct the authors on how to implement these suggestions or what specific aspects of the draft should be addressed. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and consider how to integrate these methods into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore alternative methods, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. This is a suggestion for improvement, but it lacks specific examples or references to support why these methods are relevant or beneficial. The comment does not provide detailed reasoning or evidence to justify the suggestion, making it difficult for the authors to understand the basis for the recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests considering additional methods for parameterefficient finetuning, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. This feedback is 3 as it provides a direction for the authors to explore alternative approaches that could enhance the efficiency and effectiveness of their model. However, the comment lacks specific guidance on how to implement these suggestions or what aspects of the draft should be addressed. While it offers a valuable insight, the feedback could be more impactful with additional details or examples. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide specific guidance on which baselines to include or how to structure the comparison. The action is implicit, as the authors need to infer that they should expand the related work section and compare their work to baselines using coordinates. While the comment is 3, it lacks concrete details on how to implement the suggested action, making it 3.", "grounding_specificity_rationale": "The comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not specify which baselines are relevant or how this comparison should be structured. The authors cannot confidently determine which part of the paper this comment addresses, as it is not explicitly linked to a specific section or element. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide specific examples of these baselines or explain why such a comparison is necessary or beneficial. Without detailed references or reasoning, the claim lacks sufficient support, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 2, as it provides some indication of the need for expansion but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for a more comprehensive comparison with existing baselines. However, the comment lacks specific guidance on which baselines to include or how to structure the comparison, which limits its actionable value. The authors would benefit from additional details on the selection of baselines and the expected structure of the comparison. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment implies that multiple seed experiments would provide a more robust evaluation. However, it does not explicitly instruct the authors to conduct multiple seed experiments or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should perform multiple seed experiments to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments being conducted on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This lack of grounding makes it challenging for the authors to identify the exact area that needs improvement. While the comment is specific in its critique of the experimental setup, the absence of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to training on a single seed, making it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or examples, the claim is 3, as it provides a logical argument but lacks the necessary depth to fully substantiate the point. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experimental setup, noting that the experiments are conducted using a single seed, which makes it challenging to assess the true impact of the proposed cycle consistency loss on convergence. The comment suggests that using multiple seed experiments would provide a more robust evaluation, enhancing the reliability and significance of the results. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it included additional guidance on how to conduct or analyze the results of multiple seed experiments. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. It suggests that this requirement might limit the potential users who can access or implement the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific guidance on how to make the method more accessible or how to justify the need for a multiGPU setup. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"optimizations in the proposed method\" and the \"requirement of a multiGPU setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains the issue of accessibility due to the need for a multiGPU setup, which could limit potential users. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the requirement of a multiGPU setup for the proposed method makes it inaccessible to many potential users. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the accessibility of the proposed method due to the requirement of a multiGPU setup for optimizations. This is a valid concern that could limit the potential users who can access or implement the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the method more accessible. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is 3, as it highlights a potential weakness but does not provide comprehensive guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a missing citation for the public skipgram data set mentioned in line 425. While it points out the absence of a citation, it does not provide any explicit or implicit guidance on how the authors should address this issue. The authors are left without any direction on how to include the missing citation, making the comment 1. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L425,\" allowing the authors to accurately identify the section of the paper where the issue lies. It is also specific because it clearly identifies the missing citation for the public skipgram data set, providing a clear direction for the authors to address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a missing citation for the public skipgram data set in L425. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors are left without a basis to understand why this is a significant issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the draft, namely the missing citation for the public skipgram data set mentioned in line 425. This feedback is clear and actionable, as it directs the authors to a specific part of the paper where a citation is required. However, the comment does not provide any suggestions or guidance on how the authors might address this issue beyond simply adding the citation. While it highlights a necessary correction, it lacks depth and could be more helpful if it offered additional insights or suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the current system captures semantics through RNNbased models and recommends comparing it with another system that also captures semantics. It also suggests using Ref2 as a strong baseline for comparison. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific aspects of the comparison should be highlighted or how the performance of the current system should be evaluated against the baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current system with another system that captures semantics, implying a need for comparison. However, it does not specify which part of the paper this comparison should be made or which sections are relevant. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting a comparison with Ref2 as a strong baseline, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests comparing the current system with another system that captures semantics, recommending Ref2 as a strong baseline. However, it lacks specific details or references to support the claim that Ref2 is indeed a strong baseline. The comment does not provide a clear rationale or evidence to justify why this comparison is necessary or how it would enhance the paper. As a result, the claim is not verifiable, making the comment 1.", "helpfulness_rationale": "The review comment suggests comparing the current system with another system that captures semantics, recommending Ref2 as a strong baseline. However, it lacks specific guidance on how to conduct this comparison or what aspects of the performance should be evaluated. The comment identifies a potential area for improvement but does not provide detailed suggestions or actionable steps for the authors to take. As a result, the feedback is 3, as it points out a relevant area for comparison but does not fully address the authors\" needs for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the model or assumptions need to be investigated. Without concrete suggestions or a clear path forward, the authors are left without actionable steps to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is vague and lacks specificity, as it does not provide detailed guidance on what needs to be addressed or how to approach the issue. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve their model or assumptions. It does not provide actionable advice or insights that would help the authors enhance their draft. As a result, the comment is 2, as it identifies a potential problem but does not offer a clear path forward for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how the SE framework can help improve the paper, specifically asking for clarification on the mechanism of improvement. It also suggests that the authors should provide more detailed explanations of their actions and achievements, similar to a previous comment. The comment is explicit in its request for clarification and provides a reference to a similar point, making it 3. However, it lacks concrete guidance on what specific aspects of the SE framework need clarification or how the authors should elaborate on their actions. As a result, the action is somewhat vague and could be more actionable with additional details. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment raises a question about how the SE framework can help improve the paper, specifically asking for clarification on the mechanism of improvement. It also suggests that the authors should provide more detailed explanations of their actions and achievements, similar to a previous comment. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. It is specific in its request for clarification and detailed explanations, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about how the SE framework can help improve the paper and suggests that the authors should provide more detailed explanations of their actions and achievements. It references a previous comment, indicating a need for similar depth in the current draft. However, the comment lacks specific examples or detailed reasoning to support the claim that the SE framework can improve the paper. It does not provide any references or logical reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about how the SE framework can help improve the paper, specifically asking for clarification on the mechanism of improvement. It also suggests that the authors should provide more detailed explanations of their actions and achievements, similar to a previous comment. The reference to a previous comment indicates a need for similar depth in the current draft. However, the comment lacks specific guidance on what aspects of the SE framework need clarification or how the authors should elaborate on their actions. While it provides a clear direction for improvement, the lack of detailed suggestions or examples makes it 3. Therefore, the comment is rated as 4, as it offers a clear direction but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their draft. As a result, the authors are left without a clear understanding of what to do next, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. While the comment is specific in its question, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any claim, suggestion, or reasoning to support this question. The comment lacks any evidence or justification, making it 1. Therefore, it does not provide any guidance or insight for the authors to address the question or improve their draft.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. This question highlights a potential area for clarification or improvement in the methodology section of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to their approach. Without specific advice or examples, the authors are left without actionable feedback, making the comment 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that a section on synonym identification is missing under the similarity measurement section, which describes how the multiplechoice task is approached. This provides a clear and direct action for the authors to take, namely to include this section in their draft. The comment is explicit and concrete, as it specifies exactly what is missing and where it should be added. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on similarity measurement, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing section, which is a section on synonym identification. This provides the authors with a clear understanding of what needs to be added to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that a section on synonym identification is missing under the similarity measurement section, which describes how the multiplechoice task is approached. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this section is missing or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of a section on synonym identification under the similarity measurement section. This is a clear and actionable piece of feedback that would help the authors improve their draft by ensuring that all relevant aspects are addressed. The comment is specific and provides a clear direction for the authors to take, making it 5. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific guidance on how to create this overview or what aspects of the workflow and model should be included. The action is implicit, as the authors need to infer that they should provide a detailed overview, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not specify which part of the paper this overview should be included in or how it should be structured. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to include an overview, but it lacks details on what aspects of the workflow and model should be covered. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is beneficial or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. While this feedback is relevant and provides a clear direction for improvement, it lacks specific guidance on how to create such an overview or what aspects of the workflow and model should be included. The comment is 3 as it identifies a potential area for enhancement, but it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment implies that this issue should be discussed in the paper, but it does not provide explicit guidance on how to address it or what specific aspects of the paper need revision. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the issue of bias in the sketch. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not specify which part of the paper discusses the sketch or the ridge regression problem, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of bias, it lacks grounding as it does not provide clear references to the relevant sections or parts of the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It claims that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It points out that this cannot be computed accurately without a significant runtime, which could lead to bias that defeats the purpose of the approach. The comment suggests that this issue should be discussed in the paper, but it does not provide specific guidance on how to address it or what aspects of the paper need revision. While the feedback highlights a potential weakness, it lacks detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it provides a clear area for improvement but does not offer comprehensive guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the authors should redefine Figure 3 to show scalar quantities instead of vectors. This is an explicit action that provides clear guidance on how the authors should modify their draft. The comment is specific in its request, detailing exactly what needs to be changed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be done: redefine the figure to show scalar quantities instead of vectors. This provides the authors with a clear understanding of the issue and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should redefine Figure 3 to show scalar quantities instead of vectors. While the comment identifies a specific issue with the figure, it does not provide any reasoning or justification for why this change is necessary or how it would improve the clarity or accuracy of the paper. Without additional context or explanation, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, noting that the expected quantities are scalars but are shown as vectors. This feedback is clear and actionable, providing the authors with a direct instruction on how to improve the accuracy and clarity of their figure. By redefining the figure to accurately represent scalar quantities, the authors can enhance the precision and effectiveness of their presentation. This level of detail and specificity makes the comment 5, as it directly addresses a potential error and guides the authors on how to correct it. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific guidance or suggestions on how the authors should improve the experiment setup or address these questions. The comment lacks explicit actions or concrete details, leaving the authors uncertain about what changes to make. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not specify which part of the paper the ablations are discussed in, nor does it provide any guidance on how to address these questions. The lack of specific information about the sections or content being referred to makes it difficult for the authors to understand the exact issue being raised. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment expresses concern about the ablations in the paper, noting that they seem to raise many questions. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address these concerns. Without detailed guidance or examples, the authors may find it challenging to understand the issues or how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a weakness in the paper by noting that while a reasonable argument is made about the usefulness of the proposed models for learning representations of lowfrequency words, no empirical evidence is provided to support this claim. The comment suggests that the authors could explore this aspect further, but it does not offer specific guidance on how to conduct the empirical testing or what data to use. The action is implicit, as the authors need to infer that they should provide empirical evidence to test the hypothesis. However, the lack of concrete suggestions or detailed guidance on how to implement this action makes the comment 3. Therefore, the comment aligns with a score of 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper by discussing the usefulness of the proposed models for learning representations of lowfrequency words. It highlights a reasonable argument but notes the absence of empirical evidence to support this claim. The comment is fully grounded as it explicitly mentions the aspect of the paper being discussed, allowing the authors to accurately identify the section being addressed. However, the comment is somewhat specific as it does not provide detailed guidance on what empirical evidence could be used or how to conduct the analysis. Therefore, the comment is fully grounded and somewhat specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that no empirical evidence is provided to test the hypothesis about the usefulness of the proposed models for learning representations of lowfrequency words. However, the comment does not offer any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand why the claim is valid or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of empirical evidence to support the claim that the proposed models are particularly useful for learning representations of lowfrequency words. It highlights the importance of testing this hypothesis and suggests that the authors could explore this aspect further. However, the comment does not provide specific guidance on how to conduct the empirical testing or what data could be used to validate the claim. While it points out a critical area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the resolution of the 3D voxel and its impact on computational cost. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct this comparison or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the study of global features and specifically mentions methods like PiFu that avoid voxellike features due to computational and memory costs. It questions the resolution of the 3D voxel and whether it introduces unnecessary overhead. The comment suggests studying the importance of global features in Section 4.2 by comparing different resolutions of voxel features, noting that a 1x1x1 resolution is equivalent to using a single global feature. This provides a clear and specific direction for the authors to address the issue, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxellike features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that different resolutions of voxel features could offer more insights into the importance of global features. The authors would need to infer the basis for this claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the resolution of the 3D voxel and its impact on computational cost, particularly in the context of methods like PiFu that avoid voxellike features due to high computational and memory costs. It suggests that the importance of global features could be better studied by comparing different resolutions of voxel features, specifically mentioning the case of a 1x1x1 resolution, which is equivalent to using a single global feature. This feedback is clear and actionable, providing a specific direction for the authors to improve their study by exploring the impact of different voxel resolutions on the importance of global features. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or what specific analyses would be most informative. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement, but it could be further enhanced with more detailed guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the error analysis on the movie dataset, noting that it is missing. It suggests that the authors should provide information on the cases where the model fails to help other researchers continue with the task. However, the comment does not offer explicit guidance on how to address this issue or what specific information should be included in the error analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a detailed error analysis section. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing error analysis, and suggests that the authors should provide information on the cases where the model fails to help other researchers continue with the task. This provides a clear direction for improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any reasoning or evidence to support why this is a significant issue or how it impacts the paper. Without additional context or explanation, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the error analysis on the movie dataset is missing. It highlights the importance of this analysis for other researchers to continue with the task. However, the comment lacks actionable guidance on how the authors might address this issue or what specific information should be included in the error analysis. While it points out a critical gap, it does not provide detailed suggestions or examples, making it 3. The authors would need to infer that they should add a detailed error analysis section to address the issue, which limits the comment\"s helpfulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that it is difficult to discern trends in Table 3, particularly regarding the behavior of PM+CL compared to PM or CL alone. It proposes that the authors would find it interesting to explore development set trends with respect to hyperparameters. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve the clarity of the table or the analysis of the trends. The suggestion is somewhat vague and lacks concrete details on how to implement the proposed exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a particular issue with the table, namely the difficulty in discerning trends and suggests exploring development set trends with respect to hyperparameters. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a suggestion for improvement, specifically regarding the clarity of trends in Table 3. It does not contain a subjective claim or opinion, but rather a request for clarification or further analysis. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting that it is difficult to discern trends, particularly the behavior of PM+CL compared to PM or CL alone. It suggests exploring development set trends with respect to hyperparameters, which is a valuable insight for improving the clarity and interpretability of the results. However, the comment could be more helpful if it provided additional guidance on how to analyze or visualize the data to better understand these trends. While it offers a direction for improvement, the feedback is somewhat limited in its depth and actionable suggestions. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a difficulty in understanding Figure 5 due to overlapping lines, suggesting that the authors could report additional metrics such as FLOPs or model size to make the figure more concrete. While the comment provides a clear action\u2014improving the clarity of Figure 5 by adding more metrics\u2014it does not specify how to implement this action, such as which metrics to include or how to present them. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue with the figure, namely the difficulty in understanding due to overlapping lines, and suggests a concrete improvement by reporting additional metrics like FLOPs or model size. This provides clear guidance on what needs to be addressed to enhance the clarity and comprehensiveness of the figure. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that it is difficult to understand Figure 5 due to overlapping lines, and suggests that reporting additional metrics like FLOPs or model size would make the figure more concrete. While the comment identifies a specific issue with the figure\"s clarity, it lacks detailed reasoning or examples to fully support the claim. The suggestion to include additional metrics is logical but could be more robust with specific examples or references to similar practices in the field. Therefore, the comment is 3, as it provides a basis for improvement but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 5, noting that the overlapping lines make it difficult to understand. It suggests that the authors could enhance the figure\"s clarity by reporting additional metrics such as FLOPs or model size. This feedback is actionable and provides a clear direction for improvement, as it guides the authors on what additional information to include to make the figure more informative and easier to interpret. However, the comment could be more helpful if it offered specific examples of how to report these metrics or suggested alternative ways to present the data. Overall, the comment is 4, as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on what those details should include. The authors are left without a clear understanding of what information is needed to address the issue, making the comment somewhat vague and lacking in actionable guidance. Therefore, this comment is rated as 2.", "grounding_specificity_rationale": "The comment indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which part of the paper contains these missing details, making it difficult for the authors to identify the exact section or part that needs attention. Additionally, the comment lacks specificity, as it does not provide any guidance on what these missing details are or how they should be addressed. Therefore, this comment is 2, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the nature of the missing details or how to address them. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, this comment is rated as 1.", "helpfulness_rationale": "The review comment points out that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on how to address this issue. The feedback is vague and lacks actionable suggestions, leaving the authors without a clear understanding of what information is needed to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the performance of EIGNN with respect to oversmoothing on realworld datasets, particularly in comparison to variants like GCNII. However, it does not provide explicit instructions on how to conduct this evaluation or what specific aspects of the evaluation should be considered. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the evaluation on oversmoothing,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating EIGNN\"s performance on realworld datasets, especially in comparison to variants like GCNII, which provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests evaluating the performance of EIGNN with respect to oversmoothing on realworld datasets, particularly in comparison to variants like GCNII. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is important or how it would enhance the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending an evaluation of EIGNN\"s performance with respect to oversmoothing on realworld datasets, particularly in comparison to variants like GCNII. This feedback is actionable as it directs the authors to a concrete area for further investigation and analysis, which could enhance the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it included additional guidance on how to conduct this evaluation or what specific aspects of the evaluation should be considered. Overall, the comment is 4, as it offers a clear direction for improvement but lacks some depth in terms of actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of a separate part or subsection dedicated to introducing the inference strategy. While it points out the missing element, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to include this information. The comment is somewhat vague, as it leaves the authors to infer the need for a detailed explanation of the inference strategy. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the approach method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue: the lack of a separate part or subsection to introduce the inference strategy, particularly how multiple prompts are used in the test stage. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point claims that the paper lacks a separate part or subsection to introduce the inference strategy, specifically mentioning the use of multiple prompts in the test stage. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of a detailed explanation of the inference strategy, particularly how multiple prompts are used in the test stage. This feedback is clear and actionable, as it directs the authors to include a separate part or subsection that elaborates on this aspect. By addressing this gap, the authors can enhance the clarity and completeness of their paper, making it more informative and easier to understand. The comment is 4 as it provides a clear direction for improvement, though it could be further enhanced by suggesting specific ways to elaborate on the inference strategy. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clear, specifically mentioning sorting and ranking. The comment questions the complexity of the procedure to find upper bounds on gaps and its implications for solving a ranking problem. However, the comment does not provide explicit guidance on how to improve the discussion of the results or how to clarify the realworld applications. The suggestions are somewhat vague and lack concrete details, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the experiment results could be discussed more, providing an example of how to conclude from the Streetview experiment. It also points out that the realworld applications of the new problem setting are not clear, specifically mentioning sorting and ranking. However, the comment does not specify which part of the paper these discussions or applications are related to, making it difficult for the authors to identify the exact sections that need improvement. The comment is specific in its suggestions but lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two main concerns: the need for a more detailed discussion of the experiment results and the lack of clarity regarding the realworld applications of the new problem setting. The first part suggests that the authors should provide a more comprehensive analysis of the results, particularly in the context of the Streetview experiment, and question the conclusion that MaxGapTop2UCB is better than other methods. This claim is 3 as it provides a specific example of what the authors should consider discussing further. However, it lacks detailed reasoning or references to support the suggestion, making it 3. The second part of the comment questions the clarity of the realworld applications, particularly regarding the complexity of the procedure to find upper bounds on gaps and its implications for solving a ranking problem. This part is also 3 as it raises a logical question but lacks specific examples or references to substantiate the claim. Overall, the comment is 3, as it provides some basis for the claims but lacks sufficient detail or evidence to fully support the suggestions.", "helpfulness_rationale": "The review comment identifies two main areas for improvement: the discussion of experiment results and the clarity of realworld applications. It suggests that the authors should provide a more detailed analysis of the Streetview experiment results, questioning whether MaxGapTop2UCB is indeed better than other methods. This feedback is 3 as it prompts the authors to expand on their findings and consider alternative interpretations. However, the comment could be more helpful if it provided specific guidance on how to enhance the discussion or suggested additional analyses that could strengthen the results. The second part of the comment highlights the lack of clarity regarding the realworld applications of the new problem setting, particularly in the context of sorting and ranking. It questions the complexity of the procedure to find upper bounds on gaps and its implications for solving a ranking problem. While this feedback is relevant, it lacks detailed suggestions or examples to guide the authors in clarifying these aspects. Overall, the comment is 3, as it identifies important areas for improvement but could be more comprehensive and actionable."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or improve their results, leaving them without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental results sections. The lack of specific referencing makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the results, it is 1 because it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the low results obtained using only ML in the ablation experiments, noting that these results are even lower than those of some simple early methods. While the comment identifies a potential issue with the experimental setup or results, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is 3 as it points out a potential area for improvement, but it does not provide actionable steps or detailed explanations to help the authors enhance their work. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to include an ablation study. The comment identifies a gap in the analysis but does not offer guidance on how to fill that gap, leaving the authors without a clear path forward. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of a small performance gain. However, it does not specify which part of the paper lacks ablation analysis or provide any guidance on how to address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the need for ablation analysis but lacks detailed suggestions on how to implement it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of ablation analysis in the main paper makes it difficult to determine the source of a small performance gain. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. This feedback is clear and actionable, as it highlights a critical gap in the analysis that could impact the paper\"s conclusions. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as suggesting specific ablation studies or analyses that could be included. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a concern regarding the verification of the hypothesis through the designed experiment. It points out that the base model is trained on the adversarial set only, while conventional methods are trained on the original training set in addition to the generated adversarial examples. The comment suggests that it would be better to compare the model trained on the original dataset with that trained on the mixture to highlight the impact of the augmented adversarial examples. This feedback provides a clear and explicit action for the authors to take, which is to conduct an additional experiment to strengthen the motivation of the work. The action is concrete, as it specifies exactly what needs to be done to improve the paper. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the comparison between models trained on the original dataset and the mixture of original and adversarial examples to better verify the hypothesis. This provides clear guidance on how to improve the paper, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the hypothesis is not well verified by the designed experiment, specifically noting a discrepancy in how models are trained in conventional methods versus the base model. The comment suggests an additional experiment to compare models trained on the original dataset versus the mixture of original and adversarial examples. This claim is 3 as it provides a logical reasoning for why the experiment might not be sufficient, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the verification of the hypothesis through the designed experiment. It points out that the base model is trained on the adversarial set only, while conventional methods are trained on the original training set in addition to the generated adversarial examples. This discrepancy makes it difficult to assess the impact of the augmented adversarial examples. The comment suggests a more convincing experiment by comparing the model trained on the original dataset with that trained on the mixture of original and adversarial examples. This feedback is clear, actionable, and provides a specific direction for the authors to improve their experimental design. By addressing this concern, the authors can strengthen the motivation and credibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point indicates that the CNN experiments are not fully convincing, but it does not provide any specific details or suggestions on how to improve the experiments or address the lack of convincingness. The comment lacks explicit guidance on what aspects of the experiments need to be revised or how the authors should enhance the results. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the CNN experiments are discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is not specific because it does not provide details on what aspects of the experiments are not convincing or what improvements could be made. Without specific guidance or examples, the authors cannot effectively address the issue. Therefore, this comment is rated as 1 and Not Specific, corresponding to a score of 1.", "verifiability_rationale": "The review point claims that the CNN experiments are not fully convincing, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors cannot determine why the experiments are not convincing or how to address this issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses concern about the CNN experiments, stating they are not fully convincing. However, it lacks specific details or suggestions on how to improve the experiments or address the lack of convincingness. Without actionable feedback or guidance, the authors are left without a clear understanding of what aspects of the experiments need to be revised or enhanced. This comment is 2 as it identifies a potential issue but does not provide sufficient information for the authors to make improvements. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to mention that the results for model (3) in Table 1 were computed by themselves, as they are not reported in the original paper. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be added to their draft to address this issue. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the results for model (3) were not taken from the original paper and suggests that the authors should mention if they computed these results themselves. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the results for model (3) in Table 1 were not taken from the original paper but were computed by the authors. This claim is 3 as it provides a specific example of a discrepancy between the paper\"s content and the original source. However, it lacks detailed reasoning or references to support the claim fully, which could make it challenging for the authors to understand and address the issue comprehensively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the results for model (3) in Table 1 were not taken from the original paper but were computed by the authors. This observation is clear and actionable, as it highlights a potential inconsistency or lack of transparency in the reporting of results. The comment suggests that the authors should mention this discrepancy to ensure the integrity and accuracy of their work. By addressing this feedback, the authors can improve the clarity and credibility of their paper. Therefore, the comment is 4, as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the authors\" results with SoTA approaches, specifically mentioning HateXplain models as an example. This provides a clear and explicit action for the authors to take, as they can compare their results with these models to demonstrate their effectiveness or novelty. The comment is specific in its suggestion and provides a concrete direction for improvement, allowing the authors to understand exactly what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests comparing the authors\" results with SoTA approaches, specifically mentioning HateXplain models as an example. However, it does not specify which part of the paper this comparison should be made or where the results are discussed. This makes it difficult for the authors to identify the exact section or part of the paper that needs to be addressed. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests comparing the authors\" results with SoTA approaches, specifically mentioning HateXplain models as an example. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or beneficial. Without additional context or justification, the claim lacks sufficient evidence to be 5. Therefore, the comment is rated as 2, as it provides a suggestion but lacks detailed support.", "helpfulness_rationale": "The review comment suggests comparing the authors\" results with stateoftheart (SoTA) approaches, specifically mentioning HateXplain models as an example. This feedback is 3 as it provides a clear direction for the authors to enhance their work by benchmarking their results against established models. However, the comment lacks depth and specificity, as it does not elaborate on why such a comparison is necessary or how it would impact the paper\"s contributions. While it offers a starting point for improvement, the feedback could be more comprehensive and actionable to fully guide the authors in enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. While the comment implies that the use of freezing is not welljustified, it does not explicitly instruct the authors to remove or modify the use of freezing. The action is implicit, as the authors would need to infer that they should provide a clearer explanation for their choice of using freezing. However, the comment lacks concrete guidance on how to address this issue, making it 3.", "grounding_specificity_rationale": "The comment questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. However, it does not specify which part of the paper discusses the use of freezing or provide any context for the question. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in questioning the choice of methods, but without grounding, the authors are left to infer which part of the paper needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. However, the comment does not provide any specific reasoning, examples, or references to support why freezing is used or why adaptive methods might be preferred. Without additional context or justification, the claim is difficult to verify, making it 1.", "helpfulness_rationale": "The review comment raises a valid question about the rationale behind using freezing in MLS selection, suggesting that if adaptive methods are effective, they should be used instead. This feedback is 3 as it prompts the authors to consider alternative methods and provide a clearer explanation for their choice of using freezing. However, the comment lacks depth and does not offer specific suggestions or guidance on how to address the issue, leaving the authors with limited actionable feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It also proposes an interesting idea for the authors to perform a similar analysis on their proposed model. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects of the model should be examined. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. However, the comment does not explicitly mention which part of the paper it is addressing, making it weakly grounded. It is specific in suggesting an analysis that could be performed on the proposed model, but without clear guidance on how to implement it. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. However, the comment does not offer a detailed explanation or justification for why this analysis is important or how it would enhance the paper. The lack of specific reasoning or examples makes it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a question about whether the proposed knowledgeCLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It provides a link to an external resource, which is helpful for context. The comment also proposes an interesting idea for the authors to perform a similar analysis on their proposed model, which could enhance its robustness. However, the comment lacks detailed guidance on how to conduct this analysis or what specific aspects of the model should be examined. While it offers a valuable suggestion, the feedback could be more helpful if it included concrete steps or examples. Therefore, the comment is 3, as it provides some insight but requires further elaboration to fully assist the authors."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is an explicit action that the authors can directly implement by adding a brief explanation in the relevant section of the paper. The comment is specific and provides a clear direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific line number (l.97) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: explaining how novel values in the test set are handled for clarity. This provides the authors with a clear and precise direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it suggests that the authors should clarify how novel values in the test set are handled for better understanding. This feedback provides a clear direction for improvement, helping the authors enhance the clarity and comprehensibility of their paper. However, the comment could be more helpful if it offered additional guidance on how to explain this concept effectively or provided examples of how to handle novel values. Despite this, the comment is 4 as it identifies a specific area for improvement and encourages the authors to address it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should use a generic external knowledge base to avoid issues with points 1 and 2, as demonstrated in Figure 3. However, it does not provide explicit guidance on how to implement this suggestion or clarify what specific issues are being addressed. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply the proposed solution. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests using a generic external knowledge base to avoid issues with points 1 and 2, referencing Figure 3. However, it does not specify which part of the paper these points correspond to, making it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the solution, the lack of grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the writing is too confusing, making it difficult for the authors to understand if the suggested solution is valid. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to verify the issue or understand how to address it. The feedback is 3 as it points out a potential problem but does not provide detailed evidence or guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the writing, specifically mentioning that points 1 and 2 could be avoided by using a generic external knowledge base, as demonstrated in Figure 3. However, the comment lacks specific guidance on how to improve the writing or address the confusion. While it points out a potential area for improvement, it does not provide actionable steps or detailed suggestions for the authors to follow. This makes the comment 3, as it highlights a potential issue but does not offer comprehensive guidance for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment provides explicit questions and suggestions, it does not offer concrete guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not specify which part of the paper these questions or suggestions relate to, making it difficult for the authors to identify the exact sections or elements being addressed. The comment is 1 as it lacks specific references to sections, tables, or figures. While it provides some specificity in terms of the questions and suggestions, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not provide any specific reasoning, examples, or references to support these claims. The questions and suggestions are vague and lack detailed justification, making it difficult for the authors to understand the basis of the feedback or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of kcrossvalidation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment provides some guidance on potential improvements, it lacks depth and specificity. The questions and suggestions are somewhat vague, making it challenging for the authors to fully understand and address the feedback. The comment could be more helpful if it provided more detailed reasoning or examples to support the suggestions. Overall, the feedback is 3, as it offers some insights but could be more comprehensive and actionable."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a gap in the paper by noting the absence of indepth analysis of the experimental results. It provides a specific example, asking for clarification on why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This feedback is explicit and concrete, as it directly points out the need for a more detailed analysis and provides a clear direction for the authors to address this issue. The authors can infer that they should include a more thorough discussion of the experimental results, explaining the observed differences in model performance across different datasets. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. This allows the authors to accurately identify the part of the paper that requires attention. The comment is also specific because it provides a clear example of what needs to be addressed, prompting the authors to delve deeper into the analysis of their experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks indepth analysis of the experimental results, specifically questioning why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of indepth analysis of the experimental results. It specifically questions why the improvements of models are limited on the offense detection dataset and significant on the coarse stereotype set, which highlights a critical area for further exploration. This feedback is clear and actionable, as it directs the authors to provide a more detailed analysis of their experimental findings. However, the comment could be more helpful if it suggested specific ways to conduct this analysis or provided examples of how to interpret the results. Overall, the comment is 4 as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides several suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also suggests that the current approach of training on labeled data with a few input mask explanation annotations might be too simplistic, and the reviewer expresses skepticism about its effectiveness. However, the comment does not offer specific guidance on how to implement these suggestions or address the skepticism. The action is somewhat explicit but lacks detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also expresses skepticism about the current approach of training on labeled data with a few input mask explanation annotations, suggesting that it might be too simplistic. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the feedback is moderate, as it provides some guidance but lacks detailed examples or references. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the effectiveness of the proposed method, suggesting that the current approach might be too simplistic and that robustness/domain invariance interventions have failed in the past. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the skepticism. The feedback is 3 as it provides a general critique but lacks detailed evidence or reasoning to fully substantiate the claims. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides several suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also expresses skepticism about the current approach of training on labeled data with a few input mask explanation annotations, suggesting that it might be too simplistic. However, the comment lacks specific guidance on how to implement these suggestions or address the skepticism, making it 3. The feedback is valuable but could be more actionable with detailed examples or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search. It recommends ensuring that the baseline is fully tuned with similar resources to the proposed method for a fair comparison. However, the comment does not provide explicit guidance on how to conduct this tuning or what specific steps should be taken. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, recommending that the baseline be fully tuned with similar resources for a fair comparison. However, the comment does not specify which part of the paper discusses the hyperparameters or the baseline comparison, making it weakly grounded. It is specific in suggesting the need for a fair comparison, but without explicit references to sections or figures, the authors may struggle to identify the exact areas that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, recommending that the baseline be fully tuned with similar resources for a fair comparison. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or evidence, the claim remains 3, as it is based on logical reasoning but lacks sufficient detail to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper by pointing out the extensive hyperparameter search conducted, which could lead to unfair comparisons if the baseline is not similarly tuned. While the comment highlights a valid concern, it does not provide specific guidance or suggestions on how to address this issue, such as suggesting alternative tuning methods or providing examples of how to ensure a fair comparison. The feedback is 3 as it raises a critical point but lacks actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the definition of perplexity provided in the paper, stating that it is not accurate and that Equation 1 does not represent perplexity but rather crossentropy. While the comment identifies a specific issue with the definition and provides a clear explanation of the discrepancy, it does not offer any suggestions or guidance on how the authors might address this issue. The action is explicit but lacks concrete details on how to correct the definition or improve the explanation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the definition of perplexity provided in the paper, specifically mentioning that it is not accurate and that Equation 1 does not represent perplexity but rather crossentropy. However, the comment does not specify which part of the paper this critique refers to, such as a particular section or equation number. This lack of grounding makes it difficult for the authors to pinpoint the exact issue and address it effectively. While the comment is specific in its critique of the definition, the absence of explicit grounding limits its usefulness. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the definition of perplexity on line 259 is incorrect and that Equation 1 does not represent perplexity but rather crossentropy. This claim is supported by logical reasoning, as the reviewer provides a clear explanation of the difference between perplexity and crossentropy. However, the comment lacks specific examples or references to external sources that could further substantiate the claim. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the definition of perplexity in the paper, pointing out that the provided definition is inaccurate and that Equation 1 does not represent perplexity but rather crossentropy. This feedback is clear and actionable, as it directs the authors to reconsider the definition and potentially revise it to align with the correct understanding of perplexity. However, the comment could be more helpful if it provided suggestions on how to accurately define perplexity or how to clarify the distinction between perplexity and crossentropy in the paper. Despite this, the comment offers valuable guidance for improving the clarity and accuracy of the paper, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include more baselines for graph contrastive learning, specifically mentioning MVGRL and gptgnn, and test them on common datasets. This provides a clear and explicit action for the authors to take, as they know exactly which baselines to add and where to test them. The comment is concrete, as it specifies the exact baselines and datasets to consider, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"graph classification task\" and suggests adding more baselines for graph contrastive learning, such as MVGRL and gptgnn. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies which baselines are missing and suggests testing them on common datasets, providing detailed guidance on what needs to be done. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the compared baseline in the graph classification task is insufficient, specifically mentioning the absence of MVGRL and gptgnn. However, the comment does not provide any reasoning or justification for why these baselines are missing or why their inclusion is necessary. Without additional context or explanation, the authors may find it challenging to understand the basis for this claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the graph classification task by pointing out the absence of certain baselines, such as MVGRL and gptgnn. It suggests that the authors should include these baselines and test them on common datasets to provide a more comprehensive evaluation. This feedback is clear and actionable, as it directs the authors to specific areas for improvement and provides a clear path for enhancing their work. However, the comment could be more helpful if it included additional guidance on how to select appropriate datasets or why these baselines are crucial for a thorough evaluation. Overall, the comment is 4, as it offers valuable insights and actionable suggestions for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge mapbased defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge mapbased defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge mapbased defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is 5.", "helpfulness_rationale": "The review comment raises a significant concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It highlights that an adaptive attack against the edge mapbased defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and actionable suggestion for the authors to enhance the robustness of their defense strategies by considering a more nuanced type of adversarial attack. By addressing this concern, the authors can significantly improve the effectiveness of their defense mechanisms. Therefore, the comment is 5, as it offers a specific and constructive direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern regarding the theoretical foundation of the analysis, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. However, it does not provide explicit instructions or suggestions on how the authors might address these issues. The comment implies that the authors should consider providing these details, but it lacks concrete guidance on how to do so. As a result, the authors are left without a clear understanding of what specific actions to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the theoretical foundation of the analysis, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. It provides specific examples of what needs to be addressed, such as the lack of discussion on these aspects. However, it does not explicitly mention which part of the paper these issues are related to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis is weak due to the lack of discussion on the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the analysis is considered weak. Therefore, the claim is considered 2, as it lacks sufficient justification or supporting details.", "helpfulness_rationale": "The review comment identifies a potential weakness in the theoretical foundation of the analysis, specifically questioning the existence and smoothness of the solution of SDE (2a)(2d) and the guarantees of the discretization. This feedback is valuable as it highlights areas where the authors could strengthen their analysis by providing more detailed theoretical underpinnings. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as suggesting additional references or methods to include in the analysis. Without concrete recommendations, the authors may find it challenging to fully address the feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the realism of their generated images, leaving them without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"paper\" and \"supplemental material,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issue with the quality of generated images, noting that while continuous control is achieved, the realism of the results is limited. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the quality of generated images by the proposed method is limited, noting that while continuous control is achieved, the realism of the results is limited. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the quality of generated images, noting that while continuous control is achieved, the realism of the results is limited. This feedback is clear and actionable, as it highlights a key area for improvement in the paper. However, it could be more helpful if it provided suggestions on how to enhance the realism of the generated images or suggested specific techniques that could be employed. Despite this, the comment offers valuable guidance for the authors to address the identified weakness, making it 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point provides specific questions and suggestions for improvement regarding the description of the graph G in Section 3.3. It asks for clarification on how G is built using the human skeleton and suggests adding details about the size and elements of G, as well as the dimensions of G, X, and W to enhance understanding of the DGCN model. These suggestions are explicit and concrete, as they directly instruct the authors on what needs to be added or clarified in their draft. The comment is fully actionable, as it provides clear guidance on how to improve the paper.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as describing the size and elements of G, and adding the dimensions of G, X, and W to enhance understanding of the DGCN model. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the clarity and completeness of the description of the graph G in Section 3.3. It suggests that the authors should provide more details about the size and elements of G, as well as the dimensions of G, X, and W to better understand the DGCN model. While the comment identifies areas for improvement, it does not provide specific examples or references to support the claims. The suggestions are logical and based on common practices in describing mathematical models, but the lack of detailed reasoning or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific feedback on the clarity and completeness of the description of the graph G in Section 3.3. It suggests that the authors should clarify how G is built using the human skeleton and provide more details about the size and elements of G, as well as the dimensions of G, X, and W. These suggestions are actionable and constructive, as they guide the authors on what specific aspects of their paper need improvement. By addressing these points, the authors can enhance the clarity and understanding of their work, making the comment 5. Therefore, the comment is rated as 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point critiques a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counterargument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any explicit or implicit suggestions on how the authors should revise or improve their draft to address this issue. The authors are left without guidance on what specific changes to make or how to clarify the inaccurate claim. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (559560) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies what is incorrect, suggesting that the claim made in the paper is not entirely true and providing a counterargument about the Cycle Consistency loss. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the statement on lines 559560 is not entirely true, specifically regarding the Cycle Consistency loss. It provides a counterargument, suggesting that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the accuracy of the statement or understand the basis of the critique. Without detailed evidence or examples, the claim remains 3, as it lacks the necessary depth to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counterargument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any suggestions or guidance on how the authors might revise or improve their draft to address this issue. While it points out a potential inaccuracy, it lacks actionable advice or constructive feedback that would help the authors enhance their work. Therefore, the comment is 2, as it identifies a problem but does not provide sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the term \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or improve the clarity of their terminology. As a result, the authors are left without a clear path to follow, making the comment 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the term \"hyperspectral,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear definition of hyperspectral imaging, which helps the authors understand the confusion and how to address it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that calling \"hyperspectral\" is confusing and provides a definition of hyperspectral imaging. However, it does not offer any evidence or reasoning to support why this term is confusing or how it impacts the paper. The comment lacks specific examples or references to clarify the issue, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the terminology used in the paper, specifically the term \"hyperspectral.\" It suggests that this term might be confusing and provides a definition of hyperspectral imaging. However, the comment does not offer any actionable advice or suggestions on how the authors might address this confusion or improve the clarity of their terminology. While it points out a potential area for improvement, it lacks depth and does not provide guidance on how to implement the suggested changes. Therefore, the comment is 2, as it identifies a problem but does not offer substantial assistance to the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more detailed explanations of how each component contributes to the final performance improvements. It mentions specific examples, such as the combination of Linformer and window attention in Big Bird, to illustrate the need for such details. However, the comment does not explicitly instruct the authors to include these explanations or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to add more detailed explanations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"1), 2) and 3) mentioned above,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely, the contribution of each component to the final performance improvements, with an example provided. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should provide more detailed explanations of how each component contributes to the final performance improvements, with an example given. However, the comment lacks specific reasoning or references to support why this is necessary or how it would enhance the paper. The authors are left to infer the importance of this addition, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more detailed explanations of how each component contributes to the final performance improvements. It offers a concrete example, such as the combination of Linformer and window attention in Big Bird, to illustrate the need for such detailed explanations. This feedback is actionable and provides a clear direction for the authors to enhance their draft by adding more context and depth to their analysis. However, the comment could be more helpful if it included additional suggestions or guidance on how to present these explanations effectively. Overall, the comment is 4 as it directs the authors towards a specific area of improvement with a clear example, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights specific areas where details are missing in the paper, particularly regarding the grammar over kernels and the probabilities associated with it. It also questions the clarity of how inference is performed. While the comment identifies the need for more detailed explanations, it does not provide explicit instructions on how to address these issues or what specific actions the authors should take. The feedback is somewhat vague, as it leaves the authors to infer the necessary steps to improve the draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some of the details of the models are missing,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the \"grammar over kernels,\" providing clear guidance on what needs to be addressed. The comment is specific in detailing the lack of explanation regarding the grammar over kernels and the absence of probabilities associated with it, as well as the question about inference. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the lack of detail in the paper, specifically regarding the grammar over kernels and the absence of probabilities associated with it. It questions the clarity of how inference is performed, which is a valid point that could be addressed with additional explanation or examples. However, the comment does not provide specific references or detailed reasoning to support these claims, making it 3. The authors would need to infer the need for more detailed explanations and examples to address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks detail, particularly regarding the grammar over kernels and the absence of probabilities associated with it. It questions the clarity of how inference is performed, which is a critical aspect for understanding the practical application of the approach. While the comment highlights these weaknesses, it does not provide detailed suggestions or guidance on how to address them. The feedback is 3 as it points out areas that need improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. However, it does not provide specific guidance or suggestions on how the authors should address these issues. The comment lacks actionable steps, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the role of visual information in the paper, specifically mentioning the knowledgegraph memory and visualdriven reasoning as the main contributions. It also highlights the lack of explicit verification in the ablation study and questions the significance of the experimental results given the sample size. However, the comment does not specify which part of the paper discusses the role of visual information or the ablation study, making it weakly grounded. The comment is specific in detailing the issues with the ablation study and the experimental results, but without explicit references to sections or figures, it is challenging for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the paper, including the lack of clarity regarding the role of visual information, the absence of explicit verification in the ablation study, and questions about the significance of the experimental results. The comment provides specific examples, such as the similar performance of \"w/o perception module\" and \"w perception\" in Table 10, and questions the statistical significance of the improvements given the sample size. However, the reasoning is somewhat vague, as it does not provide detailed explanations or references to support the claims. The lack of specific examples or references makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, such as clarifying the role of visual information, providing explicit verification in the ablation study, and questioning the statistical significance of the experimental results. However, the comment lacks specific suggestions or actionable guidance on how the authors might address these issues. While it points out important weaknesses, it does not offer detailed feedback or constructive advice, making it 3. The authors would need to infer how to improve their draft based on the feedback, which limits the comment\"s overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. It also points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. The comment is fully actionable because it specifies exactly what needs to be done, including identifying and citing previous works on Lasso screening. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 4.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a specific issue: the lack of citation and comparison of previous works on Lasso screening, providing a clear direction for improvement. The comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the end of Section 4.2 states that Transfer Lasso showed the best accuracy in feature screening but does not provide any evidence or reasoning to support this claim. It suggests that previous works on Lasso screening are not cited or compared, specifically mentioning Ren et al. \"Safe feature screening for generalized LASSO.\" TPAMI 40.12 (2017): 29923006. However, the comment lacks detailed reasoning or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some support but lacks depth and clarity.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the end of Section 4.2 claims that Transfer Lasso showed the best accuracy in feature screening. However, it points out that previous works on Lasso screening are not cited or compared, providing a specific example of missing references. This feedback is clear and actionable, as it directs the authors to address the omission of relevant prior work and provide a comparison. By highlighting this gap, the comment offers constructive guidance for improving the paper\"s completeness and accuracy. Therefore, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive if it included suggestions for how to address the issue or additional relevant works."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the model has several components with hyperparameters that are not fully provided, suggesting that the authors may need to trace these parameters in the source code. However, it does not specify which components or hyperparameters are missing, nor does it provide guidance on how to address this issue. The action is implicit and vague, as the authors are left to infer that they need to trace the hyperparameters in the source code. Without explicit instructions or concrete steps, the authors cannot effectively apply this feedback to improve their draft. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the model,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the issue of missing hyperparameter information for several components, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model has many components whose hyperparameters are not fully provided, requiring the authors to trace them in the source code. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. Without detailed information or guidance, the claim is not 5, as it does not provide a clear path for the authors to improve their work. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the model has several components with hyperparameters that are not fully provided. This feedback is clear and actionable, as it directs the authors to trace these hyperparameters in the source code. However, the comment could be more helpful if it provided additional guidance on how to trace the hyperparameters or suggested alternative approaches for addressing this issue. Despite this, the feedback is 4 as it highlights a critical area for improvement and encourages the authors to take steps to enhance the transparency and reproducibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity in the notation used for results, specifically questioning the meaning of the percentage improvement claim for CIFAR10. While the comment identifies a specific issue with the notation, it does not provide explicit guidance on how the authors should clarify or correct the notation. The action is implicit, as the authors would need to infer that they need to clarify the notation and explain the meaning of the percentage improvement. However, the comment lacks concrete details on how to implement this clarification, making it 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the notation used for results, particularly regarding the percentage improvement claim for CIFAR10. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the lack of clarity in the notation and the ambiguity of the percentage improvement claim. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the notation for results is unclear and that the paper does not specify what the percentage improvement claim for CIFAR10 means. However, the comment does not provide any evidence or reasoning to support this claim, such as examples or references to specific sections of the paper. Without additional context or explanation, the authors are left to question the validity of the claim, making it 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of notation used in the results section, particularly regarding the percentage improvement claim for CIFAR10. It points out that the paper claims an improvement of 3%p but does not specify what the %p stands for, leaving the authors uncertain about the exact nature of the improvement. This feedback is clear and actionable, as it directs the authors to clarify the notation and provide a precise definition of the percentage improvement. However, the comment could be more helpful if it suggested specific ways to clarify the notation or provided examples of how to do so. Overall, the comment is 4 as it highlights a critical issue that needs addressing, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. While the comment identifies a potential issue with the evaluation methodology, it does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider using a human metric instead of an automatic one. However, the comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper discusses the human evaluation or the use of TSS. This makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific about the issue of using an automatic metric, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support why an automatic metric might be less convincing or why a human metric is preferable. Without additional justification or evidence, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the use of an automatic metric TSS for human evaluation, questioning its effectiveness compared to a human metric. This feedback highlights a potential weakness in the evaluation methodology, which could impact the convincingness of the human evaluation results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative metrics could be considered. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential issue but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TDMPC 2. While the comment implies that the current experiments are sufficient to prove the point, it does not explicitly instruct the authors to include experiments in more diverse domains. The action is implicit and somewhat vague, as the authors are not given specific guidance on which domains to include or how to conduct these experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the experiments to include more diverse domains, specifically mentioning TDMPC 2. However, it does not specify which part of the paper the experiments are currently located in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to include experiments across more diverse domains, but it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TDMPC 2. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would strengthen the paper. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TDMPC 2. This feedback is 3 as it identifies a potential area for improvement in the experimental design, which could strengthen the paper\"s claims. However, the comment lacks specificity and does not provide detailed guidance on how to conduct these additional experiments or what specific domains would be most beneficial. Without more detailed suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what steps they should take to evaluate the interpretability tax. Without concrete guidance or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. However, it does not specify which part of the paper this issue relates to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint where the evaluation should be conducted. Additionally, the comment does not provide specific guidance on how to evaluate the interpretability tax, leaving the authors without actionable steps. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not evaluate the magnitude of the interpretability tax associated with the method. However, the comment lacks specific evidence or references to support this claim. Without detailed reasoning or examples, the authors may find it challenging to understand why this omission is significant or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that it does not evaluate the magnitude of the interpretability tax associated with the method. This feedback is clear and actionable, as it highlights a potential gap in the paper\"s analysis or evaluation. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or what kind of evaluation would be appropriate. Despite this, the comment offers valuable guidance for the authors to enhance their draft, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper\"s main contribution lies in demonstrating the effectiveness of combining existing techniques, rather than proposing novel ones. However, it does not provide explicit guidance on how the authors should address this point or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to enhance the paper, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely that the approaches in Sec. 5 are straightforward and standard, and that the main contribution is showing the sufficiency of combining existing techniques. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the LUQ design is straightforward once the goal is clear, and the approaches in Section 5 are standard and explored in previous literature. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the validity of the assertion. Without detailed evidence or examples, the claim remains 3, as it is based on general observations without strong justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a critique of the paper\"s main contribution, suggesting that it primarily demonstrates the effectiveness of combining existing techniques rather than proposing novel ones. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or enhance their contribution. The feedback is 3 as it highlights a critical aspect of the paper\"s contribution, but it does not offer actionable advice or detailed insights to help the authors improve their draft. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to include the training losses or what specific information should be included. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or experimental setup, but without explicit mention, they cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses but lacks grounding as it does not pinpoint the relevant section. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not provide any reasoning, examples, or references to support why this is a concern or how it might impact the results. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to address the issue or what kind of training losses would be relevant. The comment is 3 as it points out a potential area for further exploration, but it does not offer actionable advice or suggestions for improvement, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It suggests that arenabased evaluation systems, such as Chatbot Arena, may not be suitable for evaluating single dialogue systems. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to respond or make changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It also critiques the use of arenabased evaluation systems like Chatbot Arena for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concerns about the evaluation methods, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arenabased evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. The feedback is 3, as it provides a general critique but lacks detailed evidence or reasoning. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the relevance of the proposed method to the authors\" motivations in the abstract section, specifically questioning the effectiveness of automatic scores and the cost of human evaluation. It critiques the use of arenabased evaluation systems, such as Chatbot Arena, for evaluating single dialogue systems, suggesting that these systems may not be suitable for the current scorebased evaluation systems. While the comment identifies a potential issue with the evaluation methodology, it lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is 3 as it points out a potential area for improvement, but it does not provide detailed advice or actionable steps for the authors to take. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. The authors are questioned about the fairness of this comparison. While the comment identifies a potential issue and suggests a possible reason for unfair comparison, it does not provide explicit guidance on how to address this concern or what specific changes should be made to the training process. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the impact of the 2x samples on the running speed and consider alternative approaches to ensure a fair comparison. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"RegMixup\" and its training process, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slower running speed and potentially unfair comparisons with other methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the training of RegMixup sees 2x samples per iteration, leading to a slower running speed and potentially unfair comparisons with other methods. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that other methods are indeed faster or that the comparison is unfair. Without detailed evidence or examples, the claim remains 3, as the authors may need to seek additional information to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slower running speed and potentially unfair comparisons with other methods. This feedback is clear and actionable, as it highlights a specific concern that the authors should investigate and address. However, the comment could be more helpful if it provided suggestions on how to mitigate the impact of the 2x samples or how to ensure a fair comparison with other methods. Despite this, the comment offers valuable insights that can guide the authors in improving their draft, making it 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the statistical significance of the improvements of the proposed model over the RL without feedback model, specifically noting that the improvements are not as high as suggested. It does not provide explicit instructions or suggestions on how to verify the statistical significance, such as which statistical tests to use or how to interpret the results. While the comment implies that the authors should perform this verification, it lacks concrete guidance on how to do so. Therefore, the comment is 3, as it identifies an action but does not provide detailed instructions on its execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statistical significance of the improvements, particularly noting that the BLEU1 score is worse than expected. This provides clear guidance on what needs to be verified. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the statistical significance of the improvements of the proposed model over the RL without feedback model, specifically noting that the BLEU1 score is worse than expected. However, it does not provide any evidence, reasoning, or references to support the claim that the improvements are not statistically significant. Without additional context or justification, the authors are left to question the validity of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the statistical significance of the improvements of the proposed model over the RL without feedback model, particularly noting that the BLEU1 score is worse than expected. It raises a question about the statistical significance of these improvements, which is a crucial aspect for validating the results. However, the comment does not provide any suggestions or guidance on how to address this issue or how to verify the statistical significance. While it highlights a potential area for concern, it lacks actionable advice, making it 3. The authors would need to conduct additional analysis to address this concern, but the comment does not offer a clear path forward. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about potential modifications to the method, specifically regarding the need to visit all ballaction pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific actions the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"continuation to the above remark,\" indicating a specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the need to relax the requirement of visiting all ballaction pairs with each iteration and explores the possibility of partially covering them. This provides clear guidance on what the authors should consider and how they might approach the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about potential modifications to the method, specifically regarding the need to visit all ballaction pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide any specific reasoning, examples, or references to support why this modification might be beneficial or how it could be implemented. The lack of detailed justification makes it difficult for the authors to understand the implications of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about potential modifications to the method, specifically regarding the need to visit all ballaction pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs, which could potentially improve efficiency. However, the comment lacks specific guidance or suggestions on how to implement these changes or what minimal assumptions might be needed. While it identifies an area for improvement, it does not provide actionable advice or detailed reasoning, making it 3. The authors would need to infer the necessary steps to address the comment, which limits its overall impact. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point questions whether the authors should use a better encoder, such as RoBERTabase, instead of BERT to improve the results. While it suggests an alternative model, it does not provide explicit guidance on how to implement this change or what specific improvements might be observed. The action is implicit and somewhat vague, as the authors need to infer that they should experiment with a different encoder and potentially report the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions whether a better encoder, such as RoBERTabase, could improve the results compared to using BERT. However, it does not specify which part of the paper this question pertains to, such as the methodology or experimental setup. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting an alternative model but does not provide detailed guidance on how to implement or evaluate this change. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether a better encoder, such as RoBERTabase, could improve the results compared to using BERT. While it suggests an alternative model, it does not provide specific evidence or reasoning to support this claim. The comment lacks detailed justification or examples to substantiate the assertion that a better encoder would lead to improved results. Therefore, the claim is considered 2, as it is somewhat supported but lacks sufficient detail or references to back it up.", "helpfulness_rationale": "The review comment raises a pertinent question about the potential benefits of using a better encoder, such as RoBERTabase, instead of BERT. It suggests that the authors should consider experimenting with a more advanced model to potentially improve their results. However, the comment lacks specific guidance on how to implement this change or what kind of improvements might be expected. While it provides a direction for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is 3, as it identifies a potential area for enhancement but does not fully support the authors in making the necessary changes. The score aligns with a rating of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, the comment does not provide explicit guidance on how to implement this suggestion, such as which specific datasets to include or how to analyze the results. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the comment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include more datasets, but without clear references to the paper, the authors may struggle to identify the exact areas where these datasets should be added or discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of the proposed technique across tasks with varying levels of reasoning requirements. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion or how to implement it effectively. Without detailed justification or examples, the claim is 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include more datasets on traditional multilingual tasks like XNLI and XTREME to demonstrate the generalizability of their proposed technique across tasks with varying levels of reasoning requirements. This feedback is 3 as it identifies a potential area for improvement in terms of the breadth of the evaluation. However, the comment lacks specific guidance on which datasets to include or how to analyze the results, making it somewhat vague. The authors would benefit from additional details on how to implement this suggestion effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like RefNeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. While the comment provides specific examples of potential baselines, it does not explicitly instruct the authors to implement these suggestions or provide detailed guidance on how to compare the methods. The action is implicit and somewhat vague, as the authors need to infer that they should include these baselines in their evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the choice of baseline methods, specifically mentioning RefNeRF and MipNerf for comparison, particularly in the appearance decomposition part and for larger outdoor scenes. However, it does not specify which part of the paper discusses the choice of baselines or the appearance decomposition method. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the suggested baselines, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the choice of baseline methods could be improved, particularly for the appearance decomposition part, by comparing to other existing methods like RefNeRF. It also recommends using MipNerf as a baseline for larger outdoor scenes. However, the comment does not provide specific reasoning or evidence to support why these methods are particularly relevant or beneficial for the study. While the suggestions are logical and could be considered, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of additional baseline methods for comparison, particularly in the context of appearance decomposition. It provides concrete examples of relevant baselines, such as RefNeRF and MipNerf, which could enhance the evaluation of the proposed method. However, the comment could be more helpful if it offered additional guidance on how to implement these comparisons or why these baselines are particularly suitable. Overall, the feedback is 3 as it directs the authors to consider expanding their evaluation, but it lacks depth and detailed suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a significant concern regarding the lack of implementation details for the proposed methods, which the authors should address in Section 4.1. While the comment explicitly suggests that the authors should include these details, it does not provide specific guidance on what aspects of the implementation should be included or how to present them effectively. The action is clear and explicit, but it lacks concrete details on how to implement the suggested changes. Therefore, the comment is 3, as it provides a clear direction but requires further elaboration to be fully actionable.", "grounding_specificity_rationale": "The comment identifies a specific area of concern regarding the lack of implementation details for the proposed methods, which is a clear and specific issue. However, it does not specify which part of the paper should address these details, making it weakly grounded. The comment is specific in detailing the need for implementation details, but the lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a concern about the lack of implementation details for the proposed methods, suggesting that these details should be included in Section 4.1. However, the comment does not provide any specific examples, references, or reasoning to support why this is a significant issue or how it affects the paper. Without additional context or evidence, the claim remains 3, as it lacks sufficient justification for the authors to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for understanding and replicating the research. By pointing out the absence of these details, the reviewer provides a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on what aspects of the implementation should be included or how to present them effectively. Despite this, the feedback is 4 as it directs the authors to a crucial area that needs attention, allowing them to enhance the clarity and reproducibility of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a significant issue with the paper, noting the absence of empirical evaluation and comparison with other methods. It also points out the lack of clarity regarding the practical value of the contribution, suggesting that even a theoretical paper should address this. The comment implies that the authors should provide empirical evidence and comparisons to enhance the paper\"s value. However, it does not specify which parts of the paper need to be revised or how to conduct the empirical evaluation. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the lack of empirical evaluation and comparison with other methods, which are specific aspects of the paper. It also highlights the absence of clarity regarding the practical value of the contribution, which is a specific issue that needs to be addressed. The comment is specific in detailing what needs to be addressed, such as providing empirical evidence and comparisons. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear about the practical value of the contribution. It suggests that even theoretical papers should address this issue. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of empirical evaluation and comparison with other methods. It highlights the absence of clarity regarding the practical value of the contribution, which is a significant concern for a theoretical paper. The comment suggests that even theoretical papers should address the practical implications of their work, implying that the paper is not suitable for publication at NeurIPS. While the comment points out a major weakness, it does not provide specific suggestions or guidance on how to address the issue. The feedback is 3 as it directs the authors to consider the practical value of their work, but it lacks actionable advice on how to improve the paper. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential confusion in the manuscript regarding the use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. While the comment identifies a specific issue, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the usage of P in the manuscript, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is 3, as it points out a specific issue but does not provide detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment identifies a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. This provides clear guidance on what needs to be addressed, making the comment specific. However, the comment does not explicitly mention the section or part of the paper where this inconsistency is discussed, which makes it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a specific issue in the manuscript regarding the inconsistent use of P, which is sometimes used as a probability and sometimes as a cumulative distribution function. This observation is clear and directly points out a potential confusion in the manuscript. However, the comment does not provide any additional context, examples, or references to support the claim. While the issue is verifiable, the lack of detailed explanation or examples makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue in the manuscript, noting that the variable P is sometimes used as a probability and sometimes as a cumulative distribution function, leading to confusion. This feedback is clear and actionable, as it highlights a potential inconsistency in the manuscript that could affect the clarity and accuracy of the presentation. By pointing out this inconsistency, the comment provides the authors with a specific area to address, which is crucial for improving the overall quality and readability of the paper. However, the comment could be more helpful if it suggested specific ways to clarify the usage of P or provided examples of how to avoid the confusion. Despite this, the feedback is 4 as it directs the authors to a critical issue that needs attention."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that other baselines should be included, referencing specific works in the related work section. It also indicates that the authors have addressed their concerns in a response, leading to an increase in the score. However, the comment does not provide explicit guidance on how to incorporate these additional baselines or how to test beforehand whether they are suitable. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"related work 29, 5, 6\" and \"other works discussed in related work,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies that the authors should include other baselines, such as those discussed in the related work section, and suggests that this would be beneficial. However, the comment does not provide specific guidance on what aspects of the baselines should be included or how they should be tested. This makes the comment fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point claims that other baselines should be included, referencing specific works in the related work section. It suggests that the authors should consider adding these baselines to the final version of the paper. However, the comment lacks specific examples or detailed reasoning to support this claim, making it 3. The authors\" response indicates that they have addressed their concerns, but the initial comment itself does not provide sufficient justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting the inclusion of additional baselines, referencing specific works in the related work section. It also acknowledges that the authors have addressed their concerns in a response, which led to an increase in the score. However, the comment lacks detailed guidance on how to incorporate these additional baselines or how to test them beforehand. While it provides a clear direction for improvement, the feedback could be more comprehensive and actionable if it included specific suggestions or examples. Therefore, the comment is 3, as it offers some insight but could be more detailed and constructive."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a discrepancy between the notation used in the text (L_task) and the notation used in Figure 1 (L_class). This suggests that the authors should ensure consistency in their notation throughout the paper. However, the comment does not provide explicit guidance on how to address this inconsistency or what specific changes need to be made. The action is implicit, as the authors can infer that they need to correct the notation, but the lack of detailed instructions makes the action vague and challenging to execute. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment points out a discrepancy in the notation used for the task loss, specifically noting that it is called L_task in the text but L_class in Figure 1. This provides a clear and specific reference to the part of the paper where the inconsistency is mentioned, allowing the authors to accurately identify the issue. The comment is fully grounded as it explicitly mentions the section or figure where the discrepancy is noted. It is also specific because it clearly specifies what needs to be addressed, which is the inconsistency in the notation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy in the notation used for the task loss, noting that it is referred to as L_task in the text but L_class in Figure 1. This observation is factual and requires no further verification or reasoning to understand. The comment is a normal statement, as it describes a factual inconsistency without making any claims or suggestions. Therefore, it is classified as \"No\".", "helpfulness_rationale": "The review comment identifies a specific inconsistency in the notation used for the task loss, noting that it is referred to as L_task in the text but L_class in Figure 1. This observation is factual and highlights a potential source of confusion for the readers. However, the comment does not provide any suggestions or guidance on how the authors might address this inconsistency or improve the clarity of their notation. While it points out a minor issue, it lacks actionable advice, making it 2. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide explicit guidance on what actions the authors should take to address these limitations or how to improve the network architecture. The comment lacks specificity and does not offer concrete suggestions for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is 1 as it does not provide clear references or context. Additionally, it does not specify what needs to be addressed or how the authors should respond to the question. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is 1, aligning with a score of 1.", "helpfulness_rationale": "The review comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" This feedback is 3 as it identifies a potential area for improvement or further discussion. However, the comment lacks specificity and does not provide detailed guidance or suggestions on how the authors might address these limitations or enhance their work. Without concrete examples or actionable advice, the authors may find it challenging to fully understand and incorporate the feedback into their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed method should be evaluated in machine translation to provide a more convincing evaluation. It implies that the current evaluation, which only uses answer generation and summarization, is close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The comment provides a clear action for the authors to take, which is to include machine translation in their evaluation. However, it does not specify how to implement this suggestion, such as which datasets or metrics to use. Therefore, the comment is 3, as it provides a clear direction but lacks concrete details on how to execute it.", "grounding_specificity_rationale": "The comment suggests that the evaluation of the proposed method should include machine translation, which is considered a \"close domain\" generation task, as opposed to the current \"open domain\" tasks of answer generation and summarization. However, the comment does not specify which part of the paper discusses the evaluation methodology or which sections should be expanded to include machine translation. This makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the type of evaluation that should be included, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the evaluation of the proposed method is limited to answer generation and summarization, which are considered close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that including machine translation would make the evaluation more convincing. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The lack of detailed justification or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2, as it provides a suggestion but lacks sufficient support.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the proposed method, noting that it only uses answer generation and summarization, which are considered close to \"open domain\" generation rather than \"close domain\" generation like machine translation. The reviewer suggests that including machine translation would make the evaluation more convincing. This feedback is 3 as it points out a specific area for improvement and provides a clear direction for the authors to consider. However, it lacks depth and does not offer detailed guidance on how to implement the suggested evaluation or what specific aspects of machine translation to focus on. Therefore, the comment is rated as 3, as it provides a clear direction but could be more comprehensive and actionable."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is explicit in its request for clarification, it does not provide any guidance or suggestions on how the authors might address these questions or what information they should include in their draft. The action is implicit, as the authors need to infer that they should clarify these details in their paper. However, the lack of concrete guidance on how to implement or address these questions makes the comment 3. Therefore, it aligns with a score of 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"dropout,\" which is a specific technique used in the paper. It also specifies what the authors need to clarify regarding the implementation of dropout, namely the dropping rate and the number of masks generated. This provides clear guidance on what part of the paper needs attention and what specific issues need to be addressed. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is factual and seeks clarification, it does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a specific question about the implementation details of the dropout mechanism, asking for clarification on the dropping rate and the number of masks generated. This feedback is clear and actionable, as it directs the authors to provide more detailed information about their implementation. However, the comment could be more helpful if it suggested ways to address these questions or provided examples of how to clarify them in the paper. Overall, the comment is 3 as it identifies a specific area for improvement but lacks depth in terms of guidance or suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the need for further justification of the effectiveness of the proposed twostage optimization approach. It suggests that the authors should include comparisons with other singlestage attacks and provide proper benchmarks and comparisons with stateoftheart algorithms to substantiate the effectiveness of the technical contributions. While the comment explicitly suggests what needs to be done, it lacks specific guidance on how to conduct these comparisons or what benchmarks to use. The action is clear but somewhat vague, as it does not provide detailed instructions on how to implement the suggested improvements. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the effectiveness of the proposed twostage optimization approach, suggesting that it needs further justification. It mentions the need for comparisons with other singlestage attacks and proper benchmarks and comparisons with stateoftheart algorithms. However, the comment does not specify which part of the paper discusses the proposed approach or where these comparisons should be made. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the need for additional comparisons, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the effectiveness of the proposed twostage optimization approach needs further justification. It suggests that the authors should include comparisons with other singlestage attacks and provide proper benchmarks and comparisons with stateoftheart algorithms to substantiate the effectiveness of the technical contributions. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the feedback. Therefore, the claim is considered 2, as it provides some basis for the suggestion but lacks sufficient detail or justification.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper by highlighting the need for further justification of the effectiveness of the proposed twostage optimization approach. It suggests that the authors should include comparisons with other singlestage attacks and provide proper benchmarks and comparisons with stateoftheart algorithms to substantiate the effectiveness of their technical contributions. This feedback is clear and actionable, as it provides specific areas for improvement and guidance on how to strengthen the paper. However, the comment could be more helpful if it included suggestions on which specific benchmarks or comparisons would be most effective. Overall, the comment is 4, as it effectively guides the authors in addressing a key weakness in their work."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the paper, noting that it does not provide information about the type of GPUs used and the inference time during testing. However, it does not offer any explicit or implicit suggestions on how the authors might address this gap. The comment lacks guidance on what actions the authors should take to include this information, leaving them without a clear path forward. As a result, the comment is 1, as it does not provide any actionable feedback or suggestions for improvement.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the missing information regarding the type of GPUs and inference time when testing. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not provide information about the type of GPUs used and the inference time during testing. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to address this issue or understand why it is important. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that it does not provide information about the type of GPUs used and the inference time during testing. This feedback is clear and actionable, as it highlights a crucial aspect that needs to be addressed to enhance the completeness and transparency of the paper. However, the comment could be more helpful if it suggested specific ways the authors might include this information or how it would impact the paper\"s conclusions. Despite this, the comment provides a clear direction for improvement, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the performance of RSD4PG monotonically increasing with respect to \u03bb values and suggests exploring smaller \u03bb values. It also points out missing variables (\u03c4 and \u03b7) in the objective function and a typo in the Qfunction notation. While the comment identifies specific areas that need clarification or correction, it does not provide explicit instructions on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to implement the suggestions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the performance of RSD4PG monotonically increasing with respect to \u03bb values, suggesting an exploration of smaller \u03bb values. It also points out missing variables (\u03c4 and \u03b7) in the objective function and a typo in the Qfunction notation. However, the comment does not explicitly mention which part of the paper these issues are discussed, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the issues that need to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the performance of RSD4PG monotonically increasing with respect to \u03bb values and suggests exploring smaller \u03bb values. It also points out missing variables (\u03c4 and \u03b7) in the objective function and a typo in the Qfunction notation. While the comment identifies specific areas that need clarification or correction, it lacks detailed reasoning or references to support these claims. The authors are left to infer the validity of the suggestions, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises specific questions and points out areas for improvement in the paper. It questions the performance of RSD4PG with respect to \u03bb values, suggesting an exploration of smaller values, and points out missing variables in the objective function and a typo in the Qfunction notation. While the comment identifies areas that need clarification or correction, it lacks detailed guidance on how to address these issues or what specific changes should be made. The feedback is 3 as it provides some insights into potential improvements but does not offer a comprehensive or actionable response. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific sentence in the paper that is confusing and requires clarification. It suggests that the authors should reread the sentence and the subsequent sentences to understand it better. However, the comment does not provide explicit guidance on how to clarify the sentence or what specific changes should be made. The action is implicit and vague, as it does not specify what needs to be done to make the sentence clearer. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sentence in the paper that is confusing, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies the issue with the sentence, which is its lack of clarity. The comment provides a clear indication of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that a specific sentence in the paper is confusing and requires clarification. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors cannot determine why the sentence is confusing or how it could be clarified. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with a sentence in the paper, noting that it is confusing and requires clarification. While the comment highlights a potential area for improvement, it does not provide detailed suggestions or guidance on how to clarify the sentence. The feedback is 3 as it points out a need for better clarity, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point provides specific instances where the authors need to address certain claims by citing relevant literature or providing evidence. For example, it points out that the statement about diffusion models outperforming generative adversarial networks on image generation benchmarks requires a citation. Similarly, it highlights the need for citations in sections discussing previous work and the efficiency of diffusion models. However, the comment does not explicitly instruct the authors on how to incorporate these citations or evidence, leaving the action somewhat vague. Therefore, the comment is 3, aligning with a score of 3.", "grounding_specificity_rationale": "The comment provides specific line numbers (7879, 129130, 156158, and 217218) where the authors need to address certain claims or provide evidence. This allows the authors to accurately identify the parts of the paper being discussed, making the comment fully grounded. Additionally, the comment specifies what needs to be addressed in each instance, such as the need for citations or evidence to support the claims made. Therefore, the comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point identifies specific claims made in the paper that require citations or evidence to support them. For instance, it points out that the statement about diffusion models outperforming generative adversarial networks on image generation benchmarks needs a citation. Similarly, it highlights the need for citations in sections discussing previous work and the efficiency of diffusion models. However, the comment does not provide specific examples or detailed reasoning to justify why these claims are important or how they impact the paper. The lack of detailed explanation or references makes the claims 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies specific areas in the paper where additional evidence or citations are needed to support claims made by the authors. It points out that the statement about diffusion models outperforming generative adversarial networks on image generation benchmarks requires a citation, as does the claim about previous work on diffusion models. Additionally, it highlights the need for evidence to support the claim about the efficiency of diffusion models. While the comment provides clear directions for improvement, it lacks detailed guidance on how to gather or present the necessary evidence or citations. This makes the feedback 3, as it directs the authors to specific areas for enhancement but does not fully address the need for actionable steps."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This observation is clear and explicit, providing a direct action for the authors to take: they should ensure consistency in the figures. However, the comment does not specify how the figures should be aligned or what changes need to be made to achieve consistency. While the action is clear, it lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1\" and \"Fig 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the inconsistency between the two figures, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This provides a clear and detailed explanation of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 is not consistent with Figure 2, specifically noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This claim is 3 as it provides a clear observation about the inconsistency between the two figures. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Figure 2, noting that Figure 1 shows a single shared encoderdecoder for multiple tasks, while Figure 2 shows one encoderdecoder per auxiliary task. This observation is clear and actionable, providing the authors with a direct point of comparison and highlighting a potential issue with the consistency of their figures. However, the comment could be more helpful if it suggested specific ways to address this inconsistency or provided guidance on how to ensure the figures are aligned. Overall, the feedback is 3 as it points out a clear issue that needs attention, but it lacks depth and actionable suggestions for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions whether each node attends to its own lowerlevel representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so or provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the representation of each node. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment questions whether each node attends to its own lowerlevel representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the authors can infer that it relates to the description of equation 2, the lack of explicit mention or clear grounding makes the comment weakly grounded. The comment is specific in questioning the representation of each node, but the lack of grounding makes it difficult for the authors to focus their attention. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions whether each node attends to its own lowerlevel representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. It lacks detailed explanation or examples to substantiate the assertion, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a specific question about the representation of each node in the context of the paper, particularly concerning equation 2. It suggests that the description implies only neighboring nodes are attended to, which may need clarification. However, the comment lacks depth and does not provide actionable guidance or suggestions on how the authors might address this issue. While it identifies a potential area for improvement, it does not offer concrete steps or insights to help the authors enhance their work. Therefore, the comment is 2, as it provides a minor insight but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions how the inequality after line 433 follows from Lemma 7, suggesting that it might be a combination of previous inequalities. The comment implies that the authors should clarify the connection between Lemma 7 and the inequality, but it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should explain the derivation of the inequality from Lemma 7. However, the comment lacks concrete details on how to implement this action, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l433,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors need to clarify how the inequality after line 433 follows from Lemma 7. This provides a clear direction for the authors to address the concern. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the logical connection between an inequality and Lemma 7, suggesting that the authors should clarify how the inequality follows from the lemma. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations, making it difficult for the authors to understand or address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the lack of clarity regarding how an inequality follows from Lemma 7. It provides a clear question that the authors should address to improve the readability and understanding of the paper. However, the comment does not offer any suggestions or guidance on how to clarify this connection, leaving the authors with a specific question but no actionable steps to take. While the feedback is 3 in pointing out a potential area for improvement, it lacks depth and could be more helpful with additional suggestions or guidance. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the paper, including the unclear main contribution, the overstated novelty claims, and the lack of clarity in how the proposed method handles dynamic largescale multitasking and automation. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should clarify the main contribution, provide evidence for the novelty claims, and explain how the method handles dynamic largescale multitasking and automation. While the authors can infer that they need to address these points, the lack of specific guidance on how to do so makes the comment 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment addresses the main contribution of the paper, noting that it is unclear and that the novelty claims are overstated or not wellsupported. It also points out the lack of clarity in how the proposed method handles dynamic largescale multitasking and automation. However, the comment does not specify which part of the paper discusses the main contribution, making it weakly grounded. It is specific in detailing the issues with the novelty claims and the lack of clarity in the method\"s handling of multitasking and automation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the main contribution of the paper is unclear and that the novelty claims are overstated or not wellsupported. It also notes the lack of clarity in how the proposed method handles dynamic largescale multitasking and automation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique, leading to a score of 1.", "helpfulness_rationale": "The review comment identifies several key issues with the paper, including the lack of clarity in the main contribution, the overstated novelty claims, and the unclear handling of dynamic largescale multitasking and automation. While the comment points out these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights important areas that need clarification, but it lacks depth and actionable advice, making it a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experiment comparison is weak because the authors only compare their method to the BERTbaseline. It recommends comparing the method to token pruning and token combination baselines. While the comment provides a clear direction for improvement by specifying which baselines should be included, it does not offer explicit guidance on how to conduct these comparisons or what specific aspects of the comparison should be emphasized. The action is somewhat explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the experiment comparison is weak and recommends comparing the method to token pruning and token combination baselines. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment specifies the type of baselines to include, it does not provide detailed guidance on how to conduct the comparison or what specific aspects of the comparison should be emphasized. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiment comparison is weak because the authors only compare their method to the BERTbaseline and suggests comparing it to token pruning and token combination baselines. However, the comment does not provide any specific reasoning or evidence to support why the BERTbaseline is insufficient or why token pruning and token combination baselines are necessary. Without detailed justification or examples, the claim lacks sufficient support, making it difficult for the authors to understand the basis for the critique. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a weakness in the experiment comparison, noting that the authors only compare their method to the BERTbaseline. It suggests that the authors should include comparisons to token pruning and token combination baselines to provide a more comprehensive evaluation of their method. This feedback is clear and actionable, as it directs the authors to specific areas where they can improve their experimental setup. However, the comment could be more helpful if it provided additional guidance on how to conduct these comparisons or what specific aspects of the baselines should be considered. Overall, the comment is 4, as it offers valuable suggestions for improvement but could be more detailed."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to add this comparison or provide guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer that they need to include these methods in their experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. However, it does not specify which part of the paper this comparison should be made, leaving the authors to infer that it should be in the experimental section. The comment is specific in its suggestion to include these methods, but it lacks grounding as it does not pinpoint the exact section or part of the paper that needs revision. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental section should include a comparison to coordinateaware methods like TFN or SchNet. While the comment implies that this comparison is necessary, it does not provide specific reasoning or examples to support why such a comparison is important or how it would enhance the paper. The lack of detailed justification or references makes the claim 3, as the authors may need to infer the importance of the suggested comparison. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the experimental section by suggesting that it should include a comparison to coordinateaware methods like TFN or SchNet. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s experimental evaluation. By comparing against methods that are aware of point coordinates, the authors can better demonstrate the effectiveness of their approach. However, the comment could be more helpful if it provided additional guidance on how to implement this comparison or why it is crucial. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential weakness in the paper by stating that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might identify or discuss these weaknesses, leaving the authors without a clear path forward. As a result, the comment is 1, as it does not offer any actionable steps or suggestions for improvement. Therefore, it aligns with the lowest score of 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper the authors did not show the possible weaknesses of the proposed model. It lacks any reference to a specific section, table, or figure, making it difficult for the authors to identify the exact area that needs improvement. Additionally, the comment is not specific because it does not provide any details on what aspects of the model\"s weaknesses are not addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors did not show the possible weaknesses of the proposed model. However, it does not provide any evidence, reasoning, or references to support this claim. Without specific examples or detailed explanations, the authors are left without guidance on how to address this issue or what aspects of the model\"s weaknesses need to be explored. Therefore, the comment is considered 1, as it lacks sufficient justification to be helpful.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the authors did not show the possible weaknesses of the proposed model. However, it lacks specific guidance or suggestions on how the authors might address this issue. Without actionable feedback or examples of how to demonstrate the weaknesses, the authors are left without a clear path forward to improve their work. The comment is vague and does not provide any constructive advice, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the novelty and contribution of the proposed method compared to existing extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not experiment with other extractthengenerate methods. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the novelty and contribution of the proposed method compared to existing extractthengenerate methodologies, specifically questioning what the system offers over previous methods. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its questioning but lacks grounding as it does not provide explicit references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the novelty and contribution of the proposed method compared to existing extractthengenerate methodologies. It suggests that the paper lacks a related work section and does not experiment with other extractthengenerate methods. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises important questions about the novelty and contribution of the proposed method compared to existing extractthengenerate methodologies. It highlights the lack of a related work section and the absence of experiments with other extractthengenerate methods, which are crucial for contextualizing the paper\"s contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or what additional experiments could be conducted to strengthen the paper. While it identifies a significant gap in the paper, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. While the comment implies that the authors should include more related work, it does not explicitly instruct them on how to do so. The action is implicit and somewhat vague, as the authors are not given specific guidance on which additional works to include or how to compare their method with BGLN. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the introduction of related work is insufficient and recommends providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. However, the comment does not specify which part of the paper the introduction of related work is located, making it weakly grounded. It is specific in suggesting the need for more work on GLN and the comparison with BGLN, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction of related work is insufficient and suggests providing more work on GLN to reflect the advantages or differences of the proposed method, specifically mentioning the difference from BGLN. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is not 5, aligning with a score of 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the introduction of related work, noting that it is insufficient and recommending the inclusion of more work on GLN to reflect the advantages or differences of the proposed method, particularly in comparison to BGLN. This feedback is clear and actionable, providing the authors with a specific direction for enhancing their paper. However, it could be more helpful if it included suggestions on which specific works to include or how to effectively compare the proposed method with BGLN. Overall, the comment is 4 as it offers a clear and constructive suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the rationale behind using only one dropout rate for Moon\"s approach, while suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to their draft. The action is implicit, as the authors need to infer that they should consider adding more parameters to their model or providing a rationale for their current choice. The comment is 3 because it identifies a potential issue but lacks concrete details on how to implement the suggested changes. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment questions the rationale behind using only one dropout rate for Moon\"s approach, while suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being addressed. The comment is specific in its suggestion regarding the need for additional parameters, but the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point questions the rationale behind using only one dropout rate for Moon\"s approach, suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to explain why this suggestion is necessary or beneficial. As a result, the claim is not verifiable, and the comment does not offer actionable guidance for the authors. Therefore, it is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the rationale behind using only one dropout rate for Moon\"s approach, suggesting that Variational dropout might benefit from additional parameters such as inputoutput and recurrent dropout. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to their draft. The feedback is 3 as it points out a potential area for enhancement, but it does not provide detailed actionable advice or examples, leaving the authors with limited direction for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the absence of largerscale experiments, specifically mentioning the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls or other nontrivial tiles. It suggests that the absence of these experiments might be due to a lack of time or scalability issues. The comment also provides examples of alternative experimental domains, such as simple videogame domains, which could have been used to better assess the method. However, the comment does not explicitly instruct the authors to include these types of experiments or provide detailed guidance on how to conduct them. The action is implicit and somewhat vague, as the authors need to infer that they should include largerscale experiments and consider specific examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for largerscale experiments, which allows the authors to accurately identify the part of the paper being addressed. It specifies the type of experiments that would be beneficial, such as those with larger stateaction spaces and nontrivial dynamics, including examples like gridworlds with walls and other nontrivial tiles. The comment also suggests alternative experimental domains, such as simple videogame domains, which further clarifies the need for additional experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the absence of largerscale experiments, specifically mentioning the lack of experiments with larger stateaction spaces and nontrivial dynamics, such as gridworlds with walls or other nontrivial tiles. It suggests that the absence of these experiments might be due to a lack of time or scalability issues. The comment provides examples of alternative experimental domains, such as simple videogame domains, which could have been used to better assess the method. However, the comment does not offer specific evidence or references to support the claim that the absence of these experiments is due to scalability issues. While the reasoning is logical, the lack of detailed justification or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of largerscale experiments, particularly those involving larger stateaction spaces and nontrivial dynamics. It questions the reason for this omission, suggesting that it might be due to a lack of time or scalability issues. The comment provides specific examples of alternative experimental domains, such as simple videogame domains, which could have been used to better assess the method. This feedback is valuable as it directs the authors to consider expanding their experimental evaluation to include more complex scenarios, thereby enhancing the robustness and generalizability of their findings. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these additional experiments or suggested specific methods for addressing scalability issues. Overall, the comment is 4, as it offers clear suggestions for improvement but could be more comprehensive in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the authors\" draft, noting that they did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This feedback is explicit and provides a clear action for the authors to take, which is to include such a measurement. The comment is specific in identifying the missing element and suggests a concrete way to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of quantitative measurement regarding occupation bias relative to real distributions in society, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing element, which is the lack of quantitative measurement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This is a specific claim that highlights a gap in the paper. However, the comment does not provide any evidence or reasoning to support this claim, such as examples of missing measurements or references to similar studies. Without additional context or justification, the authors may find it challenging to understand why this is a significant issue or how to address it. Therefore, the comment is considered 2, as it lacks sufficient evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area where the authors could improve their work by proposing a quantitative measurement to address the extent of occupation bias relative to real distributions in society. This feedback is clear and actionable, providing a direct suggestion for improvement. By highlighting the lack of such a measurement, the comment guides the authors to enhance the rigor and depth of their analysis. However, it could be more helpful if it suggested specific methods or examples for implementing the measurement. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or incorporate it into their work. The action is implicit, as the authors would need to infer that they should consider the impact of adaptive gradient methods on their findings and potentially explore this aspect in their analysis or experiments. The comment lacks concrete details on how to implement this suggestion, making it 3.", "grounding_specificity_rationale": "The comment raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area where the comment is relevant. While the comment is specific in its inquiry about the impact of adaptive gradient methods, the absence of explicit grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the use of adaptive gradient methods instead of SGD and suggests that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. However, the comment does not provide any specific reasoning, examples, or references to support the claim that adaptive gradient methods could affect the findings or amplify updates. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a pertinent question about the use of adaptive gradient methods instead of SGD, suggesting that such a method might affect the findings, particularly by amplifying updates for weights associated with hard features. This feedback is 3 as it identifies a potential area for consideration and prompts the authors to think critically about the implications of their choice of optimization method. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or incorporate it into their work. The feedback is incomplete and could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might incorporate information from 2hop neighbors or clarify the effectiveness of their method. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs improvement. The comment is 1 as it does not provide specific references or sections, and it is also not specific because it does not detail what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises concerns about the lack of information from 2hop neighbors and questions the effectiveness of the method. However, it does not provide any specific evidence, reasoning, or references to support these claims. Without detailed justification or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the method, specifically the lack of information from 2hop neighbors and questions the effectiveness of the approach. However, it does not provide any suggestions or guidance on how the authors might address these concerns or improve their method. The feedback is vague and lacks actionable advice, making it difficult for the authors to understand how to enhance their work. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While it implies that the authors should consider optimizing and validating their approach, the comment does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed for optimization and validation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ProtPainter,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the binder design, noting that ProtPainter only provides an empirical conformation estimation and lacks further optimization and validation. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While the comment suggests that further optimization and validation are required, it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient evidence or explanation.", "helpfulness_rationale": "The review comment identifies a specific issue with the binder design in ProtPainter, noting that it only provides an empirical conformation estimation and lacks further optimization and validation. This feedback is clear and actionable, as it highlights a gap in the methodology that could be addressed to improve the robustness and reliability of the results. However, the comment could be more helpful if it provided suggestions on how to optimize or validate the approach, such as suggesting specific optimization techniques or validation methods. Overall, the comment is 4 as it points out a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model\"s time scale of adaptation. While the comment provides some context and suggests a potential area for further exploration, it does not explicitly instruct the authors to provide this information or clarify it in their draft. The action is implicit, as the authors need to infer that they should provide more details about the training process and the impact of cycle duration. However, the comment lacks concrete guidance on how to address this, making it 3.", "grounding_specificity_rationale": "The comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model\"s time scale of adaptation. However, the comment does not specify which part of the paper Figure 7 is located in, making it weakly grounded. It is specific in detailing what needs to be clarified regarding the training process and the impact of cycle duration. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point requests clarification on how the model in Figure 7 was trained and suggests considering the impact of changing the cycle duration on the model\"s time scale of adaptation, referencing Smirnakis et al. Nature 1997. While the comment provides a specific reference to external work, it does not offer detailed reasoning or examples to support the claim that the model cannot handle longer time scales. The lack of explicit justification or detailed explanation makes the claim 3, as the authors would need to provide more context to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment requests clarification on how the model in Figure 7 was trained, specifically asking for details about the stimulus conditions and the impact of changing the cycle duration on the model\"s time scale of adaptation. It references Smirnakis et al. Nature 1997, which provides context for the discussion. However, the comment lacks specific guidance on what information the authors should include to address this request, making it 3. While it identifies an area for clarification, it does not provide detailed suggestions or examples, which could enhance its usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B using less data than H>N+B, and H>N>H and H>N>H using less data than H>N+B>H. While the comment identifies a potential issue with the comparability of the results, it does not explicitly instruct the authors to address this concern or provide guidance on how to ensure fair comparisons. The action is implicit and somewhat vague, as the authors need to infer that they should consider the data usage in their comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons in Table 2, particularly regarding the use of different amounts of data in the comparisons. The authors are informed about the specific comparisons that use less data, such as H>N and H>B compared to H>N+B, and H>N>H compared to H>N+B>H. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B compared to H>N+B, and H>N>H compared to H>N+B>H. However, the comment does not offer any justification or reasoning for why this comparability issue is a concern or how it might affect the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered 2, as it lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparability of results in Table 2, specifically regarding the use of different amounts of data in the comparisons. It provides examples of how certain comparisons use less data than others, such as H>N and H>B compared to H>N+B, and H>N>H compared to H>N+B>H. This feedback is clear and actionable, as it highlights a specific area where the authors should ensure fair comparisons. However, the comment could be more helpful if it suggested ways to address the issue, such as standardizing the data usage or providing additional context on the implications of the data differences. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several concerns about the placement of an addition, suggesting it might be counterintuitive. It also questions the understanding of the authors regarding the application of Algorithm 1 with different numbers of iterations (T=1 or T=2) and asks what happens for larger T. Additionally, it points out the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment provides some implicit guidance, it lacks concrete instructions on how to address these issues. The authors are left to infer the necessary actions, which makes the feedback 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment raises several concerns about the placement of an addition, questioning its counterintuitiveness. It also asks for clarification on the application of Algorithm 1 with different numbers of iterations (T=1 or T=2) and what happens for larger T. Additionally, it points out the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment does not specify which part of the paper these issues relate to, making it weakly grounded. The specificity of the comment is moderate as it identifies several areas for improvement but lacks detailed guidance on how to address them. Therefore, this comment is rated as 3.", "verifiability_rationale": "The review point raises several concerns about the placement of an addition, questioning its counterintuitiveness. It also asks for clarification on the application of Algorithm 1 with different numbers of iterations (T=1 or T=2) and what happens for larger T. Additionally, it points out the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand and address the issues. The feedback is 3 as it provides some context but lacks the necessary depth and clarity to fully substantiate the claims. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several concerns about the placement of an addition, questioning its counterintuitiveness. It also asks for clarification on the application of Algorithm 1 with different numbers of iterations (T=1 or T=2) and what happens for larger T. Additionally, it points out the absence of a reference to Laplacian eigenmaps in the introduction and mentions a figure that is not referenced. While the comment identifies areas for improvement, it lacks specific guidance on how to address these issues or provide additional context. The feedback is 3 as it highlights potential areas for clarification and improvement, but it could be more comprehensive with detailed suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the Conditional Batch Normalization (CBN) approach. However, the comment does not explicitly instruct the authors to remove or reorganize the section, nor does it provide specific guidance on how to better integrate the description of the proposed methodology with the model choice or how to use the time spent on ResNet architecture more effectively. The action is implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment does not specify which part of the paper is being addressed, making it weakly grounded. It is specific in its critique of the inclusion and relevance of Section 2.1 and the description of the ResNet architecture, but without explicit references to these sections, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the inclusion of Section 2.1, specifically Batch Normalization, and suggests that the description of the proposed methodology is independent of the model choice. It also implies that the time spent describing the ResNet architecture could be better used to provide motivation and intuition for the proposed Conditional Batch Normalization (CBN) approach. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is 3 as it provides a general critique but lacks detailed justification or references. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the inclusion of Section 2.1, specifically questioning the relevance of Batch Normalization in the context of the proposed Conditional Batch Normalization (CBN). It suggests that the description of the methodology might be independent of the model choice and that the time spent on describing the ResNet architecture could be better utilized to provide motivation and intuition for the CBN approach. While the comment highlights areas for potential improvement, it lacks specific guidance on how to address these issues or what changes might be necessary. The feedback is 3 as it points out areas for clarification and improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It highlights a potential inconsistency in the reasoning, suggesting that multiplying by a nicelyconditioned matrix might not result in a sparse matrix. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit and vague, as it leaves the authors to infer the need for clarification or correction. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue raised in the paper at line 122, where the authors assume a dense projection matrix multiplication leads to a sparse matrix. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly explains the inconsistency in the reasoning regarding the sparsity of the resulting matrix. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the assumption made in the paper regarding the sparsity of the resulting matrix after multiplication by a dense projection matrix. It points out a potential inconsistency in the reasoning, suggesting that multiplying by a nicelyconditioned matrix might not result in a sparse matrix. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper regarding the assumption made in equation (1) about the sparsity of the resulting matrix after multiplication by a dense projection matrix. It questions the reasoning behind this assumption, noting that multiplying by a nicelyconditioned matrix might not result in a sparse matrix. This feedback is 3 as it highlights a potential inconsistency in the paper\"s logic, prompting the authors to reconsider their assumptions. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue or clarify their reasoning. Overall, the comment offers a clear point of concern but lacks depth in terms of actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It also provides a reference to support the claim about NGF being an initial value problem (IVP). However, the comment does not explicitly instruct the authors to revise the statement or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the statement about initialization. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the role of initialization in the context of Natural Gradient Descent (NGD) and Natural Gradient Flow (NGF), suggesting that initialization should play a role similar to pretraining. It references a specific paper to support the claim about NGF being an initial value problem (IVP). However, the comment does not specify which part of the paper discusses initialization or how it relates to the discretization of NGF. This makes it weakly grounded, as the authors cannot confidently determine which section or part of the paper needs revision. The comment is specific in suggesting that the statement about initialization should be more carefully stated, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated, referencing a specific paper to support the claim that NGF is an initial value problem (IVP). The comment provides a logical reasoning by referencing a relevant external work, which helps the authors understand the basis of the claim. However, it lacks specific examples or detailed explanations of how the statement should be revised. This makes the claim 3, as it provides a basis for improvement but could be more robust with additional details. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area where the authors\" draft could be improved by providing a more detailed explanation of the role of initialization in the context of Natural Gradient Descent (NGD) and Natural Gradient Flow (NGF). It suggests that the statement about initialization should be more carefully stated and references a specific paper to support the claim that NGF is an initial value problem (IVP). This feedback is clear and actionable, as it directs the authors to enhance the clarity and precision of their explanation regarding initialization. However, the comment could be more helpful if it provided specific examples or guidance on how to rephrase the statement. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific instances where the authors\" draft could be improved. It highlights a potential issue with the phrasing at line 200, suggesting that the term \"for every arm a\" might imply a single optimistic parameter, which is not necessarily the case. The comment also suggests an alternative choice for T_0, namely T_0 = m Sqrt(T), and provides a mathematical condition that would improve the result. While the comment identifies specific areas for improvement, it does not explicitly instruct the authors on how to address these issues. The actions are implicit and somewhat vague, as the authors need to infer the necessary changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (L200 and L303) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, namely the phrasing at L200 and the suggestion for an alternative choice of T_0 at L303. This provides clear guidance on how to improve the draft, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts, each making a claim about the draft. The first part, \"for every arm a\" implies there is a single optimistic parameter, but of course it depends on a,\" is a subjective observation that requires further clarification or justification. The second part, \"Why not choose T_0 = m Sqrt(T)? Then the condition becomes B > Sqrt(m) T^(3/4), which improves slightly on what you give,\" is a suggestion for an alternative choice of T_0, but it lacks detailed reasoning or examples to support the claim. The comment is 3 as it provides some justification but lacks depth and specific references. Therefore, it aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific feedback on two distinct points in the paper. It highlights a potential issue with the phrasing at line 200, suggesting that the term \"for every arm a\" might imply a single optimistic parameter, which is not necessarily the case. This observation could be clarified or expanded upon to provide more context. Additionally, the comment suggests an alternative choice for T_0, namely T_0 = m Sqrt(T), and provides a mathematical condition that would improve the result. This feedback is actionable and constructive, as it offers specific suggestions for improvement. However, the comment could be more helpful if it included more detailed reasoning or examples to support the claims. Overall, the comment is 4, as it provides clear guidance for the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which aspects of the experimental section are weak or what additional experiments would be beneficial. The comment lacks concrete guidance on how to improve the experimental section, leaving the authors with a general idea but no specific direction to follow. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the experimental section is weak and that more experiments are needed. However, it does not specify which part of the paper the experimental section is located in, nor does it provide any details on what aspects of the experiments are weak or what additional experiments could be beneficial. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not provide any guidance on how to improve the experimental section or what kind of additional experiments would be helpful. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the experimental section is weak and suggests that more experiments are required. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why the experimental section is weak or what specific improvements are needed. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the experimental section, suggesting that more experiments are needed. However, it lacks specificity and does not provide any guidance on what additional experiments might be beneficial or how they could address the identified weakness. The comment is vague and does not offer actionable advice, leaving the authors with limited insight into how to improve their draft. As a result, the comment is 2, aligning with a score of 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the word \"of\" and use \"to\" instead. Additionally, it points out an issue with the sentence on line 265, which is grammatically incorrect and unclear. The feedback is explicit and concrete, as it clearly indicates what changes need to be made to the text. However, it does not provide guidance on how to revise the sentence on line 265 to improve its clarity. Therefore, the comment is 4, as it provides clear instructions for three specific lines but lacks guidance for the fourth line. This aligns with a score of 4.", "grounding_specificity_rationale": "The comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly mentions specific lines (2, 56, and 158) where the writing could be improved by removing the word \"of\" and using \"to\" instead. Additionally, it points out an issue with the sentence on line 265, which is grammatically incorrect and unclear. The comment is fully grounded as it explicitly mentions the lines being addressed, allowing the authors to accurately identify the parts of the paper being discussed. It is also specific because it provides clear examples of what needs to be changed and what is unclear. Therefore, this comment is 5, aligning with a score of 5.", "verifiability_rationale": "The review point consists of four specific suggestions for improving the writing style and clarity of certain sentences in the paper. Each suggestion is clear and provides a specific example of what needs to be changed. For instance, the comment instructs the authors to revise the sentence on line 2 to remove the word \"of\" and use \"to\" instead, which is a clear and actionable suggestion. Similarly, the comment points out issues with the sentence on line 56 and line 158, and it provides feedback on the sentence on line 265, which is grammatically incorrect and unclear. These suggestions are wellsupported and provide clear guidance for improvement. Therefore, the comment is 5, as it is thoroughly supported by explicit examples and clear reasoning.", "helpfulness_rationale": "The review comment provides specific suggestions for improving the writing style and clarity of certain sentences in the paper. It explicitly instructs the authors to revise the sentences on lines 2, 56, and 158 to remove the word \"of\" and use \"to\" instead. Additionally, it points out an issue with the sentence on line 265, which is grammatically incorrect and unclear. While the feedback is clear and actionable, it could be more helpful if it provided guidance on how to revise the sentence on line 265 to improve its clarity. Overall, the comment is 4 as it identifies areas for improvement and provides specific examples of what needs to be changed, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not provide explicit guidance on how the authors should address this question or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to respond. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. However, it does not provide any specific evidence, reasoning, or references to support the claim that the method might perform better in pure combinational logic or that it would be easier to model without staterelated registers. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the proposed method in pure combinational logic and suggests an interesting comparison between sequential and combinational designs. While it identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might address this question or what experiments could be conducted to substantiate the claim. The feedback is 3 as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point questions the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it suggests that the authors should provide this information, it does not explicitly instruct them to include it in the draft or specify how to calculate or present the results. The action is implicit, as the authors need to infer that they should add this information, but it lacks concrete guidance on how to do so. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions on implementation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiment section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern regarding the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. However, it does not provide any evidence, reasoning, or references to support this claim. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of the LDA+LSTM baseline in terms of the topic switch percent metric. While it identifies a potential area for clarification, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, as it does not offer any specific steps or insights that could help the authors enhance their work. Therefore, the comment is 2, as it only points out a potential area for improvement without providing any concrete suggestions or direction for the authors to follow."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This is an explicit action that the authors can directly implement by adding experiments with GPT3.5. The suggestion is clear and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests including experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs to be addressed. The comment is specific in its suggestion to include experiments with GPT3.5, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. While the suggestion is logical and aligns with the idea of costeffectiveness, it lacks specific examples or references to support the claim. The authors would need to infer the need for such experiments, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should include experiments with GPT3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly suggests an improvement that could enhance the paper\"s evaluation. By including experiments with GPT3.5, the authors can address the costeffectiveness of their approach and provide a more robust evaluation. This feedback is 4 as it offers a specific and actionable suggestion, but it could be further enhanced by providing more context or examples of how this would be implemented. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to include bold numbers for the baselines of previous work in Table 4, specifically mentioning the BLEU score for WMT17WIKT. This provides a clear and direct action for the authors to take, making the comment 5. The authors know exactly what needs to be done to improve their draft, which aligns with the definition of a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be included in the table, namely bold numbers for the baselines of previous work, particularly for WMT17WIKT, where the best BLEU result is in the baselines. This level of detail helps the authors understand exactly what changes are required. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement that requests the inclusion of specific formatting in Table 4, particularly for the baselines of previous work. It does not contain any subjective opinions or claims that require verification. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment is specific and actionable, providing clear guidance on what needs to be included in Table 4. It requests the addition of bold numbers for the baselines of previous work, particularly for WMT17WIKT, where the best BLEU result is mentioned. This feedback is valuable as it directly addresses a specific aspect of the paper and offers a clear direction for improvement. However, the comment could be more helpful if it included additional suggestions or considerations for the inclusion of this information. Overall, the comment is 4, as it provides a clear and actionable piece of feedback that empowers the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern regarding the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to the study of combining DQD with TD3. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the claim about the synergies between DQD and PPO, specifically noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to understanding these synergies. However, the comment does not specify which part of the paper discusses the synergies or the comparison to TD3GA, making it weakly grounded. The comment is specific in detailing the issue with the claim and the need for a central comparison, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim about the synergies between DQD and PPO is insufficiently backedup, specifically noting that the main paper does not mention the TD3GA algorithm. The comment suggests that the comparison to TD3GA should be central to understanding these synergies. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed guidance on how the authors might improve their draft. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the claim about the synergies between DQD and PPO, noting that the main paper does not mention the TD3GA algorithm. It suggests that the comparison to TD3GA should be central to understanding these synergies, which is a valuable piece of feedback. However, the comment could be more helpful by providing additional guidance on how the authors might address this issue or what specific aspects of the comparison should be emphasized. While it offers a clear direction for improvement, the lack of detailed suggestions limits its impact on the authors\" ability to enhance their draft. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights several issues with the figures and empirical results, such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the figures and empirical results. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of polishing of figures and empirical results, which impedes clarity and confidence in the findings. It also specifies the issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a lack of polishing of figures and empirical results, which impedes clarity and confidence in the findings. It provides specific examples of issues, such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, the comment does not provide detailed reasoning or references to support these claims, making it 3. The authors would need to infer the basis for these claims, which could be challenging. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several areas for improvement in the paper, specifically focusing on the figures and empirical results. It highlights issues such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. These observations provide valuable feedback on the clarity and confidence in the empirical findings. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address these issues, such as recommending improvements to the figures or suggesting additional experiments to enhance the robustness of the findings. Overall, the comment is 3 as it points out areas for improvement but lacks detailed actionable advice, making it a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the novelty of the work is limited, pointing out that tighter confidence intervals (CIs) with finetuning are expected outcomes. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might enhance the novelty of their work or what specific aspects need to be improved to make the findings more impactful. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the work is limited, pointing out that tighter confidence intervals (CIs) with finetuning are expected outcomes. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is 1 as it does not provide specific guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the work is limited, suggesting that tighter confidence intervals (CIs) with finetuning are expected outcomes. However, the comment does not provide specific evidence, examples, or references to support this claim. Without detailed reasoning or references, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the novelty of the work, suggesting that the findings might be expected outcomes of taskspecific finetuning. While it points out an area for consideration, it does not provide specific suggestions or guidance on how the authors might address this limitation or enhance the novelty of their work. The feedback is 3 as it highlights a potential issue, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to improve their draft. Therefore, the comment is rated as 3, corresponding to a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be stronger if it reported the numbers observed in a label noise experiment on ImageNet with 1000 classes, particularly focusing on nontail classes. This provides a clear and explicit action for the authors to take, as they can directly incorporate these additional results into their draft. The comment is specific in its suggestion and provides a concrete direction for improvement, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on nontail classes. This provides a clear and specific direction for the authors to enhance their analysis. However, the comment does not explicitly mention which part of the paper this suggestion relates to, making it weakly grounded. The suggestion is specific in its request for additional data, which would help stresstest the conjecture. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, particularly focusing on nontail classes. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the importance of this additional data to understand the full context of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper would be stronger if it reported additional numbers from a label noise experiment on ImageNet with 1000 classes, specifically focusing on nontail classes. This feedback is 3 as it provides a clear direction for the authors to enhance their analysis and potentially strengthen their conjecture. However, the comment lacks depth and does not offer specific guidance on how to interpret or utilize these additional results. While it identifies an area for improvement, it does not provide detailed suggestions or insights that would fully assist the authors in enhancing their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. It suggests that the authors should provide additional feedback to improve the paper. However, the comment does not explicitly instruct the authors on how to address this question or what specific feedback to provide. The action is implicit, as the authors need to infer that they should clarify the rationale behind their metric choice. The action is somewhat vague, as it lacks concrete guidance on how to improve the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its question, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. However, it does not provide any justification or reasoning to support this claim. The comment lacks specific examples or references to substantiate the assertion, making it difficult for the authors to understand the basis of the question. Without additional context or evidence, the claim remains 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is a better metric than the number of network updates. It prompts the authors to provide additional feedback to improve the paper. However, the comment lacks specificity and does not offer any suggestions or guidance on how to address the question or improve the paper. The feedback is somewhat vague and does not provide actionable advice, making it difficult for the authors to understand how to respond effectively. Therefore, the comment is rated as 2, as it identifies a potential area for improvement but does not provide sufficient guidance for the authors to act upon."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this question or what aspects of their work could be improved to clarify this point. As a result, the authors are left without any actionable feedback, making the comment 1.", "grounding_specificity_rationale": "The comment raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is 1 as it does not provide explicit references or guidance on where to find the relevant information. Additionally, it does not specify what needs to be addressed or how the authors might approach this question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors understand or address the question. Therefore, it is classified as \"No\" for verifiability.", "helpfulness_rationale": "The review comment raises a question about the realworld scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. This question is pertinent as it seeks to understand the practical implications of the proposed method. However, the comment does not provide any suggestions or insights on how the authors might address this question or what aspects of their work could be improved to clarify this point. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a relevant area for improvement but lacks depth and direction."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights several issues with the evaluation section, including the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of incontext examples. It also notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the comment identifies several areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve the evaluation section. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section of the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issues with the evaluation, such as the lack of transparency regarding the experiment setup, the absence of mention of the number of different sets of incontent examples used, and the lack of exploration of the effects of varying the number of incontext examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the evaluation in the paper is not sufficiently comprehensive and lacks transparency regarding the experiment setup. It provides specific examples, such as the absence of mention of the number of different sets of incontent examples used and the lack of exploration of the effects of varying the number of incontext examples. Additionally, it notes that the evaluation relies solely on one dataset, which may limit the generalizability of the results. These claims are supported by logical reasoning and examples, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or references to support the claims about the lack of transparency and the limitations of relying on a single dataset.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, specifically focusing on the comprehensiveness and transparency of the evaluation section. It highlights the lack of detail regarding the experiment setup, such as the number of different sets of incontent examples used, and the absence of exploration of the effects of varying the number of incontext examples. Additionally, the comment points out that the evaluation relies solely on one dataset, which may limit the generalizability of the results. While the feedback is clear and actionable, it could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as suggesting additional datasets or methods for exploring the impact of varying incontext examples. Overall, the comment is 4 as it provides valuable insights for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific area in the paper, Section 4.3, where the authors should include comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is explicit and provides a clear action for the authors to take, namely to add these experiments to better showcase the unique advantages or potential shortcomings of the proposed method. The comment is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This provides a clear direction for the authors to improve their draft by including these experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This claim is 3 as it suggests a specific area for improvement, but it does not provide detailed reasoning or examples to support why these comparisons are necessary or how they would enhance the paper. The authors would need to infer the need for such comparisons to fully understand the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper, Section 4.3, where the authors should include comparative experiments with other nonlinear blocks like bottleneck in ResNet or linear bottleneck in MobileNetV2. This feedback is actionable as it provides a clear direction for the authors to enhance their draft by adding these experiments. By doing so, the authors can better showcase the unique advantages or potential shortcomings of their proposed method in a broader context. This comment is 4 as it offers a specific and constructive suggestion for improvement, though it could be further expanded to provide more detailed guidance. Therefore, the comment aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, it does not provide explicit guidance on how the authors should address this suggestion, such as by including a more comprehensive related work section or discussing the relevance of these works in more detail. The action is implicit, as the authors need to infer that they should expand their related work section. While the comment is 3, it lacks concrete details on how to implement the suggestion, making it 3.", "grounding_specificity_rationale": "The comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section or aspect that needs attention. The comment is 1 as it does not provide clear guidance on which part of the paper should be revised. Additionally, the comment lacks specificity in detailing what aspects of the related work are missing or need attention. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, the comment lacks specific details or reasoning to support why these works are particularly relevant or how they could enhance the paper. Without additional context or explanation, the claim is difficult to verify, making it 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the submission would benefit from additional attention to related work, specifically mentioning examples such as 1, 2, and 3. However, the comment lacks specificity and does not provide detailed guidance on how the authors should address this suggestion. It does not specify which aspects of the related work are missing or how the authors could incorporate these works into their paper. Without concrete suggestions or examples, the feedback is 3 as it identifies a potential area for improvement but does not provide actionable guidance. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, it does not provide explicit guidance on how the authors should address this suggestion or what specific aspects of the algorithmic focus need to be explored. The comment implies that the authors should consider expanding the paper to include a more detailed discussion of the algorithmic aspects, but it lacks concrete steps or examples to guide them. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed guidance on how to implement it.", "grounding_specificity_rationale": "The comment suggests that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is specific in its suggestion regarding the focus on algorithmic aspects, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper should have focused on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without detailed justification or evidence, the claim remains 3, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the paper should have focused more on the algorithmic aspects of the solution, given the proposal of the Blackwell winner concept. This feedback highlights a specific aspect that could enhance the paper\"s contribution and novelty. However, the comment lacks detailed guidance on how the authors might address this suggestion or what specific aspects of the algorithmic focus they should explore. While it points out a potential area for improvement, it does not provide actionable steps or examples, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a clear and explicit action that the authors can take to improve their draft. The comment provides a specific request for clarification, which helps the authors understand what needs to be addressed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the difference between \"valid\" and \"orig\". This provides the authors with a clear understanding of what revisions are necessary. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should specify what \"valid\" and \"orig\" differ in within Figure 5. This is a request for clarification and does not contain a subjective opinion or claim that requires verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment is helpful as it provides a specific request for clarification regarding the terms \"valid\" and \"orig\" in Figure 5. By asking the authors to specify the difference between these terms, the comment directs them to a particular area of the paper that needs clarification. This feedback is actionable and constructive, as it helps the authors improve the clarity and completeness of their presentation. However, the comment could be more helpful if it provided additional guidance on how to clarify the terms or suggested specific ways to improve the figure. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that including a comparison to one of the methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. However, it does not provide explicit guidance on which methods to compare or how to adapt them for language tasks. The action is implicit, as the authors need to infer that they should consider comparing to specific methods and adapt them for language tasks. While the comment is 3, it lacks concrete details on how to implement the suggested comparison, making it 3.", "grounding_specificity_rationale": "The comment suggests including a comparison to methods mentioned in the computer vision setting, implying that the authors should consider comparing their approach to these methods. However, it does not specify which methods are being referred to or provide details on how this comparison would be beneficial. The comment is weakly grounded as it does not explicitly mention specific sections or parts of the paper, and it is not specific because it lacks details on the methods or the benefits of the comparison. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that comparing the methods to those mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind it. Without detailed justification or examples, the claim is considered 2, as it provides a general suggestion but lacks the necessary evidence to fully substantiate it.", "helpfulness_rationale": "The review comment suggests that including a comparison to methods mentioned in the computer vision setting would be more useful than comparing to lossbased sampling. While the comment provides a rationale for this suggestion, it lacks specific details or examples of which methods should be compared or how this comparison would enhance the paper. The feedback is 3 as it identifies a potential area for improvement, but it could be more actionable with additional guidance or examples. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, specifically referencing Chapter 4 of Steinwart and Christmann. While it prompts the authors to explore this connection, it does not provide explicit guidance on how to address it or what specific aspects of the connection should be investigated. The action is implicit and somewhat vague, as the authors are left to infer that they need to explore the connection further. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the connection between the third point and the properties of universal kernels, referencing a specific chapter in a relevant work. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing Chapter 4 of Steinwart and Christmann. While the comment provides a specific reference to a relevant work, it does not offer a detailed explanation or justification for why this connection is important or how it relates to the paper\"s content. The lack of explicit reasoning or examples makes it 3, as the authors would need to infer the relevance of the reference. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the connection between the third point of definition one and the properties of universal kernels, referencing a relevant work by Steinwart and Christmann. This feedback is 3 as it prompts the authors to explore a potential link that could enhance the depth and rigor of their paper. However, the comment lacks detailed guidance on how to investigate this connection or what specific aspects of the relationship should be explored. While it provides a direction for improvement, it does not offer comprehensive suggestions or actionable steps, making it 3."}
