{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. It also implies that the authors should provide more analysis on the dataset quality and the amount of noise it contains. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to address it. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset quality. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. It also implies that the authors should provide more analysis on the dataset quality and the amount of noise it contains. However, the comment does not specify which part of the paper discusses the dataset or where the authors should focus their analysis. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of dataset quality, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the quality of the artificially created dataset, suggesting that it might contain noise and misinformation. It implies that the authors should provide more analysis on the dataset quality and the amount of noise it contains. However, the comment lacks specific examples or references to support the claim that the dataset might contain noise or misinformation. Without detailed evidence or examples, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used in the study, specifically noting that it is artificially created and might contain noise or misinformation. The reviewer suggests that the authors should provide more analysis on the quality of the dataset and the amount of noise it contains. This feedback is somewhat helpful as it highlights a potential area for improvement and encourages the authors to consider the quality of their data. However, the comment could be more helpful if it provided specific guidance on how to analyze the dataset or suggested alternative approaches to address the issue. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the description of HIERENC, suggesting that the current explanation is unclear and that the method of averaging representations from all possible entity instantiations might introduce noise. However, the comment does not provide explicit guidance on how the authors should revise the description or address the issue of noise. While it identifies a problem, it lacks concrete steps or suggestions for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the description of HIERENC, providing a specific explanation of how the input (h_i) is processed. It highlights a potential issue with the method of averaging representations from all possible entity instantiations, suggesting that this approach might introduce noise. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific because it clearly specifies the issue with the description of HIERENC. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of HIERENC is unclear and suggests that averaging representations from all possible entity instantiations might introduce noise. While the reviewer provides a specific example of how the input is processed, the claim lacks detailed reasoning or references to support the assertion that this approach is problematic. The comment could be more verifiable with additional explanation or evidence, but it is still somewhat verifiable as it provides a basis for understanding the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the description of HIERENC, noting that the method of averaging representations from all possible entity instantiations might introduce noise. This feedback is clear and actionable, as it points out a potential problem with the methodology and suggests that the authors should reconsider their approach. However, the comment could be more helpful if it provided additional guidance on how to address the issue or alternative methods that might be more effective. Overall, the comment is mostly helpful as it highlights a significant area for improvement, but it could be more comprehensive with additional suggestions or details. Therefore, it is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this selection might affect the underestimation of performances. While the comment implies that the authors should provide a justification for this choice, it does not explicitly instruct them to do so. The action is implicit, as the authors need to infer that they should explain their reasoning. However, the comment lacks concrete guidance on how to address this issue or what specific aspects to consider in their justification. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the issue needs to be addressed. While the comment is specific in its inquiry about the impact of the selection on performance estimation, the absence of explicit grounding limits the authors' ability to understand the context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. However, it does not provide any specific reasoning, examples, or references to support the claim that this selection could lead to an underestimation of performances. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the rationale behind selecting only 10 answers from all correct answers and whether this might affect the underestimation of performances. While it identifies a potential issue in the methodology, it does not provide any specific guidance or suggestions on how to address this concern. The comment lacks actionable advice or detailed insights that would help the authors improve their draft. As a result, the feedback is somewhat helpful, as it highlights a potential area for improvement but does not offer comprehensive guidance for the authors to follow. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests clarification on the splits used for obtaining the ATIS numbers in Table 4. While it does not explicitly instruct the authors to provide this information, it implies that they should clarify this aspect in their response. The action is implicit, as the authors need to infer that they should address the lack of clarity in the table. However, the comment lacks concrete guidance on how to clarify the splits, making it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs clarification: \"what splits are used for obtaining the ATIS numbers.\" This provides a clear and precise indication of the issue that needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification regarding the splits used in Table 4. It does not contain any subjective opinions, judgments, or suggestions that require verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, it is labeled as \"No.\"', 'verifiability_label': 'No', 'helpfulness_rationale': 'The review comment requests clarification on the splits used for obtaining the ATIS numbers in Table 4. While it identifies a specific area that needs clarification, it does not provide any suggestions or guidance on how to address this issue. The comment is vague and lacks actionable advice, making it barely helpful. The authors are left without a clear understanding of what information is missing and how to improve the clarity of the table. Therefore, the comment is rated as 2: Barely Helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out a potential issue with the wording used in the paper, specifically the phrase \"on par or better,\" which might be misleading due to cognitive biases among NLP researchers. However, the comment does not provide explicit guidance on how the authors should correct the wording or what specific changes should be made. The action is implicit, as the authors need to infer that they should revise the wording to avoid ambiguity. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested change, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the phrase \"on par or better\" at line 791, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the wording, suggesting that it might be misleading due to cognitive biases among NLP researchers. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the phrase \"on par or better\" might be misleading due to cognitive biases among NLP researchers. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the wording used in the paper, specifically the phrase \"on par or better,\" which might be misleading due to cognitive biases among NLP researchers. The comment suggests that this wording could be corrected to avoid ambiguity, but it does not provide specific guidance on how to revise the wording or what changes should be made. While the feedback highlights a potential area for improvement, it lacks detailed suggestions or examples, making it somewhat helpful. The authors would need to infer the need for revision and potentially seek further clarification to fully address the comment. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of novelty in the paper, specifically mentioning that adversarial attacks on text have been explored in various NLP and image-text models. It acknowledges that the related work section summarizes these efforts and points out that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide explicit guidance on how the authors can address this issue or what specific aspects of their work need to be improved to enhance its novelty. The action is implicit and vague, as it does not specify how the authors can demonstrate the novelty of their work or what additional contributions they can make. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, such as a particular section, table, or figure. It also lacks specificity because it does not detail what aspects of the adversarial attacks or novelty are being questioned. The comment provides a general overview of the related work but does not offer specific guidance on how the authors can address the lack of novelty or what new contributions they can make. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks novelty because adversarial attacks on text have been explored in various NLP and image-text models, and the paper only applies similar ideas to video-text models. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim is unverifiable, as it lacks the necessary context or justification to be fully understood or addressed. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper, specifically noting that adversarial attacks on text have been explored in various NLP and image-text models. It suggests that the paper's novelty lies in applying similar ideas to video-text models. However, the comment does not provide specific guidance or suggestions on how the authors can address this issue or enhance the novelty of their work. It lacks actionable feedback, such as recommending additional experiments or analyses to demonstrate the unique contributions of the paper. As a result, the comment is barely helpful, as it only points out a potential weakness without offering concrete improvements or actionable advice. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the authors' proposed method of matching the head of noun phrases. While the comment highlights a potential issue with the method, it does not provide explicit guidance on how to address this problem or suggest alternative approaches. The action is implicit, as the authors need to infer that they should clarify or improve their method for handling such cases. However, the lack of concrete suggestions or detailed guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the authors' proposed method of matching the head of noun phrases. However, it does not specify which part of the paper this issue is discussed or addressed. The authors may infer that this relates to the methodology or experimental setup, but without explicit mention of a section or figure, the comment is weakly grounded. It is specific in questioning the method's applicability when the head word is not a pronoun, but the lack of grounding makes it difficult for the authors to pinpoint the exact area needing clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how an antecedent can be identified when the prediction is a pronoun, specifically questioning the authors' proposed method of matching the head of noun phrases. The comment highlights a potential issue with the method, but it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about how an antecedent can be identified when the prediction is a pronoun, particularly questioning the authors' proposed method of matching the head of noun phrases. This feedback highlights a potential ambiguity in the methodology and suggests that the authors need to clarify how their method handles cases where the head word is not a pronoun. While the comment identifies a specific area for improvement, it lacks detailed guidance or suggestions on how to address the issue. The feedback is somewhat helpful as it points out a potential weakness in the methodology, but it could be more actionable with additional guidance. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of results. However, the comment does not provide explicit guidance on what kind of discussions are needed or how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the convergence process and its implications. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of results. However, the comment does not specify which part of the paper these discussions should be included in, making it weakly grounded. The comment is specific in its suggestion to include discussions on convergence and stable points, but without explicit references to sections or figures, it is difficult for the authors to pinpoint the exact areas where these discussions should be added. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that some discussions are required on the convergence of the proposed joint learning process, specifically mentioning the probabilistic metric space and stable points. It implies that readers may find it challenging to understand how these stable points are obtained, which could hinder the repetition of results. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. The reasoning is somewhat vague, and the authors are left to infer the need for additional discussions. Therefore, the comment is barely verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that additional discussions on the convergence of the proposed joint learning process are necessary. It highlights the importance of explaining how stable points in probabilistic metric space are obtained, as this could be challenging for readers to understand and replicate the results. However, the comment does not provide specific guidance on what kind of discussions are needed or how to address the issue of convergence. While it points out a potential weakness, it lacks depth and actionable suggestions, making it somewhat helpful. The authors would need to infer the need for more detailed explanations, which could be improved with additional guidance. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the lack of description regarding the societal biases of the knowledge bases used in the paper. It questions whether the knowledge bases are free from such biases and whether the issue is affected by these restrictions. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure the knowledge bases are free from societal biases. The action is implicit and vague, as it does not specify how the authors should conduct this analysis or what methods they should use. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and if the issue is affected by these restrictions. However, the comment does not specify which part of the paper discusses the knowledge bases or where the issue is addressed. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific about the issue of societal biases, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and if the issue is affected by these restrictions. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the societal biases of the knowledge bases used in the paper, questioning whether they are free from such biases and if the issue is affected by these restrictions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what steps they should take to ensure the knowledge bases are free from societal biases. While it identifies a potential area for improvement, it does not provide actionable advice or detailed feedback, making it somewhat helpful. The comment is incomplete and could be more helpful with additional guidance or suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more details about the traits of the experts involved in the annotation process and justify why expert annotation is necessary, beyond its commercial value. It also asks for clarification on whether the experts are linguistic or domain experts, and whether the annotation process differs from what non-experts would do. This feedback is explicit and provides clear guidance on what needs to be addressed, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first point,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions and suggestions for the authors to consider, such as describing the traits of the experts, justifying the need for expert annotation, and clarifying the differences between expert and non-expert annotation. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the expertise of the annotators and the justification for expert annotation, which are relevant to the paper's methodology. However, it does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the concerns. The comment is somewhat verifiable as it offers a basis for discussion but lacks detailed evidence or reasoning to fully substantiate the claims. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is mostly helpful as it provides specific questions and suggestions for the authors to consider regarding the expertise of the annotators and the justification for expert annotation. It encourages the authors to clarify whether the experts are linguistic or domain experts and to explain how their annotation process differs from what non-experts would do. This feedback is actionable and provides a clear direction for improving the clarity and depth of the paper. However, it could be more helpful if it included additional guidance on how to address the linguistic challenges that may arise from expert annotation. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors would benefit from including examples of the system applied to actual texts, as opposed to other components or models. While the comment implies that this would be helpful, it does not explicitly instruct the authors to add such examples or specify how to do so. The action is implicit and somewhat vague, as the authors are left to infer that adding examples would improve the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including examples of the system on actual texts, which implies a specific part of the paper where such examples would be beneficial. However, it does not explicitly mention a particular section, table, or figure, making it weakly grounded. The comment is specific in its suggestion to include examples, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper would benefit from including examples of the system on actual texts, which implies that the current draft lacks such examples. However, the comment does not provide any specific reasoning or evidence to support this claim, such as explaining why these examples are important or how they would enhance the paper. Without additional context or justification, the claim remains somewhat vague and lacks verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper would benefit from including examples of the system applied to actual texts, which could enhance the understanding and impact of the work. However, the comment lacks specificity and does not provide detailed guidance on how to incorporate these examples or what aspects of the system should be illustrated. While it identifies a potential area for improvement, the feedback is somewhat vague and could be more actionable if it included suggestions for specific examples or sections where these examples would be most relevant. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper. It asks whether the CS is used for evaluation purposes and also for augmenting the training material. The comment implies that the authors should clarify how the CS is used and what data split is employed. However, it does not provide explicit instructions or detailed guidance on how to address these questions or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and the specific areas to address. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not specify which part of the paper discusses the use of the CS or the data split, making it difficult for the authors to pinpoint the exact sections that need clarification. While the questions are specific about the content being addressed, the lack of explicit grounding makes it challenging for the authors to fully understand the scope of the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. However, the comment does not provide any evidence, reasoning, or references to support these questions or claims. The questions are based on the authors' own understanding, but without further clarification or justification, they remain speculative. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises questions about the clarity of the use of the Challenge Set (CS) in the paper, specifically asking whether it is used for evaluation purposes and also for augmenting the training material. It also inquires about the data split used. While the comment identifies an area that needs clarification, it does not provide specific guidance or suggestions on how to address these questions or improve the draft. The feedback is somewhat helpful as it points out a potential area of confusion for the authors, but it lacks depth and actionable advice, making it only marginally helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses concern about the performance of nouns compared to clustering approaches, noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific analyses or improvements to address the performance discrepancy or the contradiction. The authors are left without clear guidance on how to address these issues, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the performance of nouns and clustering approaches, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the higher oracle GAP for PPDBClus compared to most clustering approaches and the contradiction with the claim of generalizability to all parts of speech. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. However, the comment lacks specific examples or references to support the claim that the clustering approach is generalizable to all parts of speech. Without additional evidence or context, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the performance of nouns compared to clustering approaches, specifically noting that the oracle GAP for PPDBClus is higher than most clustering approaches. It also points out a contradiction with the claim that the clustering approach is generalizable to all parts of speech, as the performance is not uniform. This feedback is somewhat helpful as it identifies a potential issue with the clustering approach's generalizability and highlights an area that needs further investigation. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address the performance discrepancy or the contradiction. Without actionable advice, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the discussion in section 5.2 is abstract and lacks clarity, making it difficult for the authors to understand why the new model is better than MH. It suggests providing examples of spurious structures to clarify the discussion. However, the comment does not explicitly instruct the authors to provide these examples or how to incorporate them into the discussion. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment refers to section 5.2 of the paper, providing specific guidance on how to improve the discussion by offering examples of spurious structures. This allows the authors to accurately identify the part of the paper being addressed, making the comment fully grounded. The comment is also specific as it clearly specifies what needs to be addressed, namely the lack of clarity in the discussion and the request for examples of spurious structures. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the abstract nature of the discussion in section 5.2, specifically questioning why the new model is better than MH. It suggests providing examples of spurious structures to clarify the discussion. However, the comment does not offer any specific reasoning, examples, or references to support why the discussion is abstract or why examples of spurious structures would clarify it. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of concern in the paper, namely the abstract nature of the discussion in section 5.2, which makes it difficult for the authors to understand why the new model is better than MH. The comment suggests providing examples of spurious structures to clarify the discussion, offering a clear and actionable direction for improvement. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate these examples into the discussion. Despite this, the feedback is mostly helpful as it directs the authors towards a concrete improvement that could enhance the clarity and impact of their work. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the probabilistic connection in the paper is not drawn formally enough to be considered more than motivational. It recommends that the authors either formalize this connection or adjust the language to clarify it. The comment provides explicit guidance on what needs to be done, specifically suggesting that the authors should formalize the connection or clarify the language. This action is concrete and directly actionable, as it gives the authors a clear direction for improvement. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the probabilistic connection in the paper is not drawn formally enough, implying that it is considered motivational. It recommends that the authors either formalize this connection or adjust the language to clarify it. However, the comment does not specify which part of the paper discusses the probabilistic connection, making it weakly grounded. It is specific in suggesting that the authors should formalize the connection or clarify the language, but without a clear reference to the specific section or part of the paper, the authors may find it challenging to pinpoint the exact area for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the probabilistic connection in the paper is not drawn formally enough, making it appear as motivational rather than substantiated. The comment suggests that the authors should either formalize this connection or adjust the language to clarify it. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth for full understanding and implementation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, noting that the probabilistic connection is not drawn formally enough, making it appear as motivational rather than substantiated. The comment suggests that the authors should either formalize this connection or adjust the language to clarify it. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the rigor and clarity of their work. By recommending concrete steps, the comment is mostly helpful, as it offers valuable guidance but could be further expanded to include additional suggestions or examples. Therefore, the comment aligns with a score of 4: Mostly Helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is explicit and provides a clear action for the authors to take, which is to include empirical evidence to substantiate the claim. The comment is specific in its suggestion and offers a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not specify which part of the paper discusses the third contribution or the Column Subset Selection problem, making it weakly grounded. It is specific in its suggestion to include empirical evidence, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand and address the suggestion effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should provide empirical evidence to support the claim that the proposed algorithm works better for the Column Subset Selection problem, as mentioned in the third contribution of the paper. This feedback is clear and actionable, as it directs the authors to include empirical evidence to substantiate their claim. By doing so, the authors can strengthen the validity of their contribution and provide a more comprehensive evaluation of their algorithm. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the empirical evaluation. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more detailed.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. While it prompts the authors to consider the appropriateness of their dataset choice, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take. The comment is somewhat vague, as it leaves the authors to infer the need for more detailed justification and consideration of the dataset's relevance. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section or aspect that needs attention. While the comment is specific about the question of dataset sufficiency, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of a 4-year period for studying style shifts and asks for clarification on the types of style shifts that occur within this timeframe. However, it does not provide any specific reasoning, examples, or references to support the claim that the dataset is insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of a 4-year period for studying style shifts, questioning whether the chosen timeframe is adequate to capture the necessary changes. It also asks for clarification on the types of style shifts that occur within this timeframe, which is crucial for understanding what the model is capturing. While the comment identifies a potential weakness in the dataset selection, it does not provide specific suggestions or guidance on how to address this issue. The feedback is somewhat helpful as it prompts the authors to consider the appropriateness of their dataset choice, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not provide explicit guidance on what needs to be addressed in those areas or how the authors should improve the clarity. The action is implicit and vague, as the authors are left to infer that they need to clarify the confusing parts mentioned in point 3. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges that the paper is not difficult to follow but identifies specific areas where confusion might occur, referring to \"point 3.\" However, it does not specify which part of the paper these areas of confusion are located in, making it difficult for the authors to pinpoint the exact issues. The comment is weakly grounded because it does not provide clear guidance on which sections need revision. It is also specific in that it mentions the potential confusion in \"point 3,\" but without further elaboration, the authors may struggle to understand what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point acknowledges that the paper is not difficult to follow but identifies several places that may cause confusion, referring to \"point 3.\" However, it does not provide any specific examples or detailed reasoning to support the claim that these areas are indeed confusing. Without concrete examples or references, the authors may find it challenging to understand the specific issues that need to be addressed. Therefore, the comment is barely verifiable, as it lacks sufficient evidence to support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment acknowledges that the paper is not difficult to follow but identifies several places that may cause confusion, referring to \"point 3.\" However, it does not provide specific examples or detailed reasoning to support the claim that these areas are indeed confusing. Without concrete examples or references, the authors may find it challenging to understand the specific issues that need to be addressed. The comment is somewhat helpful as it highlights areas for improvement, but it lacks depth and actionable guidance, making it incomplete in its feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the results, while based on \"standard\" techniques, are not immediately obvious and require a certain level of technical competency to understand. However, it does not provide explicit guidance on how the authors might address this issue or what specific aspects of the results need clarification. The comment implies that the authors should consider making the results more accessible or providing additional context to enhance understanding. While the action is somewhat inferred, it lacks concrete details on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results being based on \"standard\" techniques, which allows the authors to accurately identify the part of the paper being addressed. It also specifies that the results are not obvious a priori and require a degree of technical competency, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results, while based on \"standard\" techniques, are not obvious a priori and require a fair degree of technical competency. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the results, noting that they are based on \"standard\" techniques but are not immediately obvious or accessible to a broader audience. This suggests that the results may require additional context or explanation to be fully understood. However, the comment lacks specific guidance on how the authors might address this issue or what aspects of the results need clarification. While it points out a potential area for improvement, it does not provide detailed suggestions or actionable advice, making it somewhat helpful. The feedback is valuable but could be more impactful with additional guidance on how to enhance the clarity and accessibility of the results.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the conclusion that the direct model is clearly the better of the two, given the significant difference in the amount of data used for training the text disambiguation model and the end-to-end system. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might address the issue or what steps they should consider to strengthen their conclusions. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the issue of the amount of data used to train the text disambiguation model compared to the end-to-end system, questioning the conclusion that the direct model is clearly the better of the two. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the data difference and its impact on the conclusion, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the conclusion regarding the performance of the direct model compared to the end-to-end system, given the difference in the amount of data used for training. However, it does not provide any specific evidence, reasoning, or references to support the claim that the conclusion is questionable. Without additional context or justification, the reviewer's assertion remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the potential impact of the data difference between the text disambiguation model and the end-to-end system on the conclusion that the direct model is clearly the better of the two. It questions whether the conclusion is robust given the significant disparity in training data. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or strengthen their conclusions. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits the comment's overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, specifically regarding the recovery of updated parameters from projected gradients. While the comment identifies these areas, it does not provide explicit instructions or concrete guidance on how the authors should address these issues. The authors are left to infer that they need to provide a clearer motivation for GaRare and a more detailed explanation of the algorithmic process. This lack of explicit action makes the comment somewhat actionable, as it provides a general direction but lacks specific details on how to implement the changes. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. However, it does not specify which part of the paper discusses GaRare or the algorithmic process, making it weakly grounded. The comment is specific in detailing the issues that need to be addressed, such as the motivation for GaRare and the need for a more detailed algorithmic presentation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks clear motivation for GaRare and does not provide evidence or justification for its advantages over GaLore based on theoretical analysis. It also suggests that a more detailed algorithmic presentation is needed, particularly to clarify the process of recovering updated parameters from projected gradients. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or justification makes the claim somewhat verifiable, as the authors would need to provide additional information to address the concerns. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper: the lack of clear motivation for GaRare and the need for a more detailed algorithmic presentation, particularly regarding the recovery of updated parameters from projected gradients. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them. The feedback is somewhat helpful as it points out areas that require attention, but it lacks depth and actionable advice, leaving the authors with a general idea of what needs to be improved rather than detailed steps to follow. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any explicit or implicit suggestions on how the authors should address this gap or incorporate these works into their draft. Without specific guidance on what needs to be done, the authors are left without a clear action to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Continuous Conditional Random Fields\" and \"Continuous Conditional Neural Fields,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a missing link to similar work that has a similar structure to the CRF and ability to perform exact inference, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is missing a link to similar work on Continuous Conditional Random Fields and Continuous Conditional Neural Fields, noting that these works have a similar structure to the CRF and ability to perform exact inference. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this claim is valid or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the related work section by pointing out the absence of references to similar works on Continuous Conditional Random Fields and Continuous Conditional Neural Fields. These works have a similar structure to the CRF and can perform exact inference, which is relevant to the paper's topic. However, the comment does not provide any suggestions or guidance on how the authors might address this gap or incorporate these works into their draft. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it identifies a meaningful weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" While it suggests that the authors should provide more clarification, it does not explicitly instruct them to do so or offer specific guidance on how to clarify the similarity. The action is implicit, as the authors need to infer that they should clarify the relationship between their method and the cited work. However, the comment lacks concrete details on what aspects of the method need clarification, making it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the similarity between the method part and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" However, it does not specify which part of the paper this comparison is intended for, leaving the authors uncertain about the exact section being addressed. The comment is not grounded as it does not provide explicit references to sections, tables, or figures. Additionally, it lacks specificity because it does not detail what aspects of the method are similar to the related work or what clarification is needed. Therefore, this comment is not grounded and not specific, aligning with a score of 1: Not Grounded.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether the method part is similar to a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" This is a subjective claim, as it expresses an opinion about the similarity between the method and the cited work. However, the comment lacks specific evidence or reasoning to support this claim, making it difficult for the authors to understand the basis of the concern. Without further explanation or examples, the claim is not verifiable. Therefore, this comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the similarity between the method part of the paper and a related work cited in the paper, specifically \"Generating Adversarial Disturbances for Controller Verification.\" While the comment identifies a potential issue, it does not provide specific suggestions or guidance on how the authors might address this concern. The feedback is somewhat helpful as it prompts the authors to consider the relationship between their method and the cited work, but it lacks actionable advice on how to clarify or resolve the issue. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. Second, it suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific comparisons or exploring the potential of the technique. The feedback lacks concrete guidance on how to address the concerns or implement the suggestions, leaving the authors without clear directions for improvement. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. Second, it suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods. However, the comment does not specify which part of the paper addresses these issues or provide detailed guidance on how to address them. The authors cannot confidently determine which sections or aspects of the paper are being discussed, making the comment weakly grounded. Additionally, while it raises questions and suggestions, it lacks specificity in detailing what needs to be addressed or how to implement the suggestions. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises two questions: whether the comparison with other methods is fair given the use of a proposal generator pretrained on MSCOCO, and whether the proposed technique could promote existing class incremental semantic segmentation methods. While the questions are relevant and could provide valuable insights, the comment lacks specific examples, detailed reasoning, or references to support the claims. The absence of evidence or detailed explanations makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is considered borderline verifiable, as it provides some basis for discussion but lacks sufficient depth and support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises two main points: first, it questions the fairness of comparing the proposed method with others due to the use of a proposal generator pretrained on MSCOCO, which aggregates more information. This raises a valid concern about the comparability of the results. Second, the comment suggests that the proposed technique could potentially promote existing class incremental semantic segmentation methods, which is a valuable insight for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address the fairness issue or explore the potential of the technique. While it identifies important areas for consideration, it does not provide actionable steps or detailed feedback that would significantly enhance the authors' understanding and ability to improve their work. Therefore, the comment is somewhat helpful, as it offers some insights but lacks depth and specificity in addressing the concerns.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 4 is written in a very concise manner, which might be due to space limitations. It implies that the section could have been written more slowly to improve readability. However, the comment does not provide explicit guidance on how to achieve this, such as suggesting specific ways to expand the section or what content could be added to enhance readability. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand the section for better clarity. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the section is written in a very concise manner and suggests that it could have been written more slowly for easier readability. This provides clear guidance on what needs to be improved in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Section 4 is written in a very concise manner, which might be due to space limitations. It suggests that the section could have been written more slowly for easier readability. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing style of Section 4, noting that it is written in a very concise manner, which could hinder readability. While the comment highlights a potential area for improvement, it does not provide detailed suggestions or guidance on how to make the section more accessible or easier to understand. The feedback is somewhat helpful as it points out a clear weakness in the writing style, but it lacks depth and actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a table showing the distribution of video lengths across the dataset and to explain how they ensured a balanced representation of different video lengths across the 11 categories. This provides clear and concrete guidance on what needs to be done, making the comment highly actionable. The authors know exactly how to address the issue by adding a table and providing an explanation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to address the distribution of video lengths within the benchmark, which is a specific part of the paper. It also specifies what needs to be addressed, including the inclusion of a table showing the distribution and an explanation of how balanced representation was ensured across the 11 categories. This provides clear guidance for the authors to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not provide relevant explanations regarding the distribution of video lengths within the benchmark, which is crucial for assessing reasoning ability and robustness. The comment suggests that the authors should include a table showing the distribution of video lengths and explain how they ensured a balanced representation across the 11 categories. However, the comment lacks specific examples or references to support the claim that the current explanation is insufficient. Without detailed evidence or examples, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the lack of explanation regarding the distribution of video lengths within the benchmark. It highlights the importance of this distribution for assessing reasoning ability and robustness, suggesting that the authors should include a table showing the distribution and explain how they ensured a balanced representation across the 11 categories. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. However, the comment could be more helpful if it included specific examples or suggestions for how to ensure balanced representation. Overall, the comment is mostly helpful as it offers valuable guidance for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should take a cautious approach regarding the contribution until the promised dataset is made publicly available. However, it does not provide any specific guidance or actions on how the authors should proceed with this cautious approach. The comment lacks concrete instructions or suggestions on what steps the authors should take to address this issue, leaving them without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the promised dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, taking a cautious approach regarding the contribution until the dataset is publicly available. This provides clear guidance on how the authors should proceed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the promised dataset has not yet been made publicly available, suggesting a cautious approach should be taken. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to verify the accuracy of the statement. Without additional context or evidence, the claim remains speculative and unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the availability of a promised dataset, which is essential for the contribution of the paper. It suggests a cautious approach until the dataset is publicly accessible, highlighting a potential limitation that could affect the reproducibility and impact of the work. However, the comment does not provide specific guidance on how the authors might address this issue or what steps they should take to ensure the dataset is made available in the future. While it points out a significant concern, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the novelty of the proposed method, noting its similarity to existing attentional modules and group attention designs. It mentions that the paper does not discuss the relationship between the proposed method and ResNeSt, despite the structural similarities. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the method need to be clarified or differentiated. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the similarities and differences with existing methods and provide a more detailed explanation of their unique contributions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed method, noting its similarity to existing attentional modules and group attention designs. It mentions specific works [1, 2, 3] and ResNeSt [4], indicating that the authors should discuss these similarities and differences. However, the comment does not specify which part of the paper should be addressed or what specific aspects of the method need to be clarified. This makes it weakly grounded, as the authors cannot confidently determine the exact section or part of the paper being discussed. The comment is specific in identifying the issue of limited novelty and the need for a discussion on the relationship with existing methods, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the proposed method is limited due to its similarity to existing attentional modules and group attention designs, specifically referencing works [1, 2, 3] and ResNeSt [4]. The comment suggests that the paper does not adequately discuss these similarities or differences, which could be considered a valid critique. However, the claim lacks specific examples or detailed reasoning to fully substantiate the assertion of limited novelty. The absence of references or detailed explanations makes it somewhat verifiable, as the authors would need to provide more evidence to challenge or support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the novelty of the proposed method, noting its similarity to existing attentional modules and group attention designs. It provides specific references to previous works [1, 2, 3] and ResNeSt [4], highlighting the structural similarities between the proposed method and these existing modules. This feedback is valuable as it directs the authors to address the lack of novelty and to discuss the relationship between their method and existing approaches. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might differentiate their method or address the similarities. Overall, the comment is somewhat helpful as it points out a critical area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the authors' claim of achieving state-of-the-art results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to substantiate their claim. The feedback is somewhat vague and lacks concrete details, leaving the authors uncertain about how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors' claim about achieving state-of-the-art results on challenging scene text recognition tasks, which is a specific part of the paper. It also specifies what the authors claim, that their performance is primarily due to the first step, making comparisons with existing detection methods reasonable. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' claim of achieving state-of-the-art results is not convincing, as the performance is primarily due to the first step, making comparisons with existing detection methods reasonable. However, the comment lacks specific evidence or examples to support this claim. It does not provide detailed reasoning or references to substantiate the assertion that the performance is primarily due to the first step. Without this additional information, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to address it effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors' claim of achieving state-of-the-art results on challenging scene text recognition tasks. It questions the persuasiveness of this claim, suggesting that the performance is primarily due to the first step, which makes comparisons with existing detection methods reasonable. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or substantiate their claim. While it raises a valid concern, the feedback lacks actionable advice, making it somewhat helpful. The authors would need to conduct additional experiments or provide more detailed evidence to address the reviewer's concern effectively. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not provide any explicit or implicit guidance on how the authors should address this issue. The comment lacks specific details or suggestions on what changes might be necessary to clarify the concept. Without actionable steps or concrete advice, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a potential confusion regarding the implicit call to the Witness oracle, but it does not specify which part of the paper this issue is related to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in identifying the issue as a potential confusion regarding the implicit call to the Witness oracle. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the required implicit call to the Witness oracle is confusing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the call is confusing or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the implicit call to the Witness oracle, which could be confusing for readers. However, the comment lacks specific details or suggestions on how the authors might address this confusion. Without actionable guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a potential area for improvement but does not provide sufficient direction for the authors to act upon.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment does not provide explicit guidance on how to implement this suggestion or what specific changes are needed in the draft. The action is implicit and vague, leaving the authors uncertain about the exact steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of the proposed method not handling headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. However, the comment does not specify which part of the paper discusses the proposed method or headpose handling, making it weakly grounded. It is specific in questioning the authors' claim and suggesting an alternative approach, but without clear references to the relevant sections, the authors may struggle to identify the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors' claim that their proposed method cannot handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. The comment implies that the authors should consider how to condition headpose parameters in NeRF, similar to the approach in the cited work. However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to provide more evidence or explanation to fully understand the basis of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the proposed method's inability to handle headpose, suggesting that a previous work (Gafni et al. ICCV 2021) can control both facial expression and headpose. This feedback highlights a potential limitation of the proposed method and prompts the authors to consider how to address this issue. However, the comment could be more helpful if it provided specific suggestions or guidance on how to condition headpose parameters in NeRF, similar to the approach in the cited work. Without detailed insights or actionable steps, the authors may struggle to fully address the feedback. Therefore, the comment is mostly helpful, as it identifies a significant area for improvement but lacks depth in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a structural optimization component that has been emphasized multiple times, but it points out that the optimization algorithm is directly derived from previous works. This feedback suggests that the authors should clarify the novelty and contribution of their optimization approach. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects need to be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the novelty of their optimization algorithm. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the structural optimization component of the paper, which is a specific part of the work. It highlights that the optimization algorithm is directly derived from previous works, which reduces the contribution of the paper. However, the comment does not specify which section or part of the paper discusses the optimization algorithm, making it weakly grounded. The comment is specific in identifying the issue with the optimization algorithm, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the optimization algorithm is directly derived from previous works, which reduces the contribution of the paper. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to verify the assertion. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to seek additional information to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the structural optimization component of the paper, noting that it appears to be directly derived from previous works. This observation raises concerns about the novelty and contribution of the paper. While the comment highlights a specific area that needs clarification, it does not provide detailed guidance on how to address this issue or suggest specific improvements. The feedback is somewhat helpful as it points out a potential weakness, but it lacks actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that the pipeline method does not yield better average results compared to baseline models. It also points out that the baseline models are not well introduced in the experiments. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes need to be made to the draft. The action is implicit, as the authors would need to infer that they should improve the introduction of baseline models and potentially re-evaluate the experimental results. The lack of concrete instructions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experimental results of a pipeline method, specifically noting that it does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models are not well introduced in the experiments. However, the comment does not specify which part of the paper discusses the experimental results or the introduction of baseline models, making it weakly grounded. The comment is specific in detailing the issue with the results and the lack of introduction of baseline models, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the pipeline method does not yield better average results for both XVNLI and MaRVL, and that the baseline models are not well introduced in the experiments. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the feedback. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to conduct further investigation to confirm the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the experimental results, noting that the pipeline method does not yield better average results for both XVNLI and MaRVL. It also points out that the baseline models are not well introduced in the experiments. While the comment highlights a potential weakness in the experimental setup, it lacks detailed guidance on how the authors might address this issue or what specific changes could be made to improve the results. The feedback is somewhat helpful as it directs the authors' attention to a critical aspect of their experimental evaluation, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of reproducing a well-known result using a \"coarse\" methodology, suggesting that the observation has been made at each step of the evolution of language models. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative methodologies or providing more detailed analysis. The comment lacks concrete guidance on how the authors might address this concern or improve their draft. As a result, the comment is unactionable, aligning with a score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"coarse\" methodology used in reproducing a well-known result in the literature, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the methodology, questioning its necessity given prior observations. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reproduced a well-known result using a \"coarse\" methodology, questioning the necessity of this approach given prior observations. However, the comment lacks specific examples or references to support the claim that the observation has been made at each step of language model evolution. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to provide more context or justification to fully understand the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the authors' methodology for reproducing a well-known result about political bias in language models, specifically questioning the necessity of using a 'coarse' methodology given prior observations. While the comment identifies a potential issue with the approach, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their methodology. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks actionable advice or detailed suggestions, making it only marginally helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue regarding the related work section, specifically mentioning the importance of discussing modular networks for Visual Question Answering (VQA). It points out that the current introduction does not adequately address this aspect, suggesting that the authors should include it. However, the comment does not provide explicit guidance on how to incorporate this information or what specific examples or references should be included. The action is implicit, as the authors need to infer that they should add a discussion of modular networks for VQA, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work\" and \"modular networks for VQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need to mention related work on modular networks for VQA, such as [A], to provide a more comprehensive introduction. This provides the authors with clear guidance on what needs to be addressed in the related work section. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the introduction does not adequately address related work on modular networks for Visual Question Answering (VQA). It suggests that the authors should include this information to provide a more comprehensive introduction. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the introduction by pointing out the absence of discussion on related work on modular networks for Visual Question Answering (VQA). This is a significant oversight, as it suggests that the introduction does not adequately contextualize the work within the existing literature. By highlighting this omission, the comment provides the authors with a clear and actionable direction for improving their draft. It encourages them to include a discussion of relevant prior work, which is essential for establishing the novelty and significance of their contribution. However, the comment could be more helpful if it provided specific examples or references to guide the authors in incorporating this information. Overall, the feedback is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the authors' discussion by noting that they primarily focus on SSC and do not adequately contrast their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. While the comment identifies a specific area where the authors could improve their discussion, it does not provide explicit guidance on how to address this gap or what specific aspects of the contrast should be included. The action is implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on SSC and the lack of contrast with other methods like thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the contrast with these other methods. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors primarily focus on SSC and do not adequately contrast their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed explanations of why these methods are relevant or how the authors' method compares to them. Without this additional information, the claim remains somewhat verifiable, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the authors' discussion by pointing out that they primarily focus on SSC without adequately contrasting their method with other computationally efficient and theoretically sound subspace clustering methods, such as thresholded subspace clustering (TSC) and greedy subspace clustering by Park. This feedback is somewhat helpful as it highlights an area where the authors could enhance their discussion by providing a more comprehensive comparison with existing methods. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address this gap, such as suggesting additional comparisons or analyses that could be included in the paper. Overall, the comment provides a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the term \"semantic\" segmentation is not low-level because the categories are specified for each pixel. It implies that the statements about semantic segmentation being a low-level cue should be removed from the paper. However, the comment does not provide explicit instructions on how to remove these statements or what specific parts of the paper need to be revised. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the term \"semantic\" segmentation is not low-level because the categories are specified for each pixel, implying that the statements about semantic segmentation being a low-level cue should be removed from the paper. However, the comment does not specify which part of the paper discusses semantic segmentation or low-level cues, making it difficult for the authors to identify the exact section or figure that needs revision. The comment is specific in its critique but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that \"semantic\" segmentation is not low-level because the categories are specified for each pixel, suggesting that statements about semantic segmentation being a low-level cue should be removed. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the argument or how to address it. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it is based on a logical deduction but lacks sufficient substantiation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the terminology used in the paper, suggesting that \"semantic\" segmentation is not low-level due to the pixel-specific categories. This feedback is clear and actionable, as it directs the authors to reconsider the classification of semantic segmentation and potentially remove statements that imply it is a low-level cue. However, the comment could be more helpful if it provided additional context or examples to support the claim, allowing the authors to better understand the implications of this critique. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. While the comment implies that the authors should consider using a different dataset, it does not explicitly instruct them to do so or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should use another dataset for the ablation study. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the claim made in the paper regarding the improvement of proposed modules in accuracy and completeness, referencing a table. However, it does not specify which part of the paper the table is located in, making it difficult for the authors to identify the exact section being addressed. The comment suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D, but it does not provide specific guidance on how to implement this suggestion or why it is necessary. This lack of grounding and specificity makes it challenging for the authors to understand and address the feedback effectively. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the claim that the proposed modules improve in both accuracy and completeness based on a table, asking for clarification. It suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. However, the comment does not provide any specific reasoning or evidence to support the claim that the current dataset is sufficient or why the suggested datasets would be more appropriate. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the claim that the proposed modules improve in both accuracy and completeness, based on a table, and suggests using another dataset for the ablation study, such as the training set of Tanks & Temples or ETH3D. This feedback is somewhat helpful as it identifies a potential area for further investigation and suggests an alternative dataset that could provide additional insights. However, the comment lacks detailed guidance on why the suggested datasets would be more appropriate or how they might impact the results. The authors are left to infer the need for additional analysis, which limits the depth of the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their methodology. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and that the results are difficult to interpret. However, the comment does not specify which part of the paper discusses the methodology or the results, making it weakly grounded. The comment is specific in detailing the concerns about the methodology and the difficulty in interpreting the results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It suggests that previous work has considered multiple vulnerabilities simultaneously and reports on the presence of such vulnerabilities. The comment implies that the current approach may not be robust or generalizable, but it lacks specific examples or references to support these claims. Without detailed reasoning or evidence, the claim is somewhat verifiable, as it provides a basis for questioning the methodology but does not fully substantiate the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the ecological validity of the vulnerability discovery methodology, specifically questioning whether considering a single vulnerability at a time is an intended use case. It suggests that previous work has considered multiple vulnerabilities simultaneously and reports on the presence of such vulnerabilities, implying that the current approach may not be robust or generalizable. The comment also notes that the results are difficult to interpret, which could limit the impact of the study. However, the comment does not provide specific guidance or suggestions on how the authors might address these concerns or improve their methodology. While it identifies a potential issue, it lacks actionable advice, making it somewhat helpful. The feedback is valuable in highlighting a potential limitation but could be more impactful with detailed suggestions or recommendations for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the explanation of how a small degree of bias arises from a clear community structure, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. While the comment implies that the authors should provide more detailed explanations, it does not explicitly instruct them to do so or specify how to improve the explanation. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the relationship between community structure, degree bias, and the theorems. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the explanation of how a small degree of bias arises from a clear community structure, referencing Theorem 1 and 2. However, it does not specify which part of the paper this explanation is intended for, making it weakly grounded. The comment is specific in its critique of the lack of intuitive understanding of the relationship between community structure, degree bias, and the theorems. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the explanation of how a small degree of bias arises from a clear community structure is insufficient, noting that Theorem 1 and 2 prove the relationship but do not provide an intuitive understanding. However, the comment lacks specific examples or detailed reasoning to support this claim, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it identifies a gap in the explanation but does not provide sufficient evidence or guidance for improvement. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area where the paper could be improved by providing more detailed explanations. It points out that while Theorem 1 and 2 prove the relationship between community structure and degree bias, the explanation of how a small degree of bias arises from a clear community structure is not intuitive enough. This feedback is clear and actionable, as it directs the authors to enhance the clarity and depth of their explanation. However, it could be more helpful if it provided specific suggestions or examples for improving the explanation. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the paper deals with many graph notions and that the writing is generally good, but it also points out that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies areas where additional details are needed, it does not explicitly instruct the authors to provide these details or suggest specific ways to improve the explanations. The action is implicit and somewhat vague, as the authors are left to infer that they should add these details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"this paper,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the need for more details in the definition of the resistance distance and the explanations for Algorithm 1, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point acknowledges that the paper deals with many graph notions and that the writing is generally good, but it also suggests that more details could be provided, specifically mentioning the need for a definition of the resistance distance and more explanations for Algorithm 1. While the comment identifies areas where additional details are needed, it lacks specific examples or references to support the claim that more details are necessary. The feedback is somewhat verifiable as it provides a general suggestion but does not offer detailed reasoning or evidence to justify the need for more details. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies areas where the paper could be improved, specifically mentioning the need for more details in the definition of the resistance distance and additional explanations for Algorithm 1. While it acknowledges that the writing is generally good, it provides specific suggestions for enhancing clarity and comprehensibility. This feedback is mostly helpful as it offers actionable insights for the authors to improve their draft, but it could be more comprehensive if it included additional suggestions or examples of how to provide these details. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might enhance the originality of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, it does not specify which part of the paper this issue pertains to, such as the introduction, methodology, or results sections. Without explicit references or context, the authors cannot confidently determine which part of the paper needs to be addressed. Additionally, the comment does not provide specific suggestions or guidance on how to enhance the originality of the work. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the originality of the paper is limited because the main idea of variable splitting is not new and the algorithm is also not new. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address or improve their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the originality of the paper, specifically noting that the main idea of variable splitting and the algorithm are not new. However, it does not provide any suggestions or insights on how the authors might address this issue or enhance the originality of their work. The comment lacks actionable guidance and depth, leaving the authors without a clear path forward to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment implies that the authors should consider including such results, it does not explicitly instruct them to do so or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should include quantitative results on testing images. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the shape model invariance study, specifically questioning the sufficiency of evaluation on training images. However, it does not specify which part of the paper this study is located in, making it weakly grounded. The comment is specific in its request for quantitative results on testing images, which would help clarify the evaluation process. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sufficiency of the evaluation for the shape model invariance study, specifically questioning whether quantitative results on testing images are needed. While the comment does not contain a subjective claim or opinion, it poses a logical question that could be addressed with additional information or justification. However, without further context or explanation, the claim is considered borderline verifiable, as it lacks sufficient evidence or reasoning to fully substantiate the point.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the sufficiency of the evaluation for the shape model invariance study. It questions whether the current evaluation, which focuses on transformations of training images, fully supports the claim. The comment suggests that additional quantitative results on testing images might be necessary to strengthen the study. This feedback is somewhat helpful as it identifies a potential gap in the evaluation process and prompts the authors to consider expanding their analysis. However, it could be more helpful if it provided specific guidance on how to conduct the additional testing or what kind of results would be expected. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment implies that this related work should be discussed and compared against to provide a better understanding of the state-of-the-art. However, it does not explicitly instruct the authors to include or discuss this work in their draft. The action is implicit and somewhat vague, as the authors need to infer that they should address this omission. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the AAAI15 paper by Ghoshdastidar and Dukkipati, allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the authors should discuss and compare their work against this related paper, which deals with hypergraph data and tensors. This provides a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have missed a related work, \"Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications\" by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. The comment suggests that this related work should be discussed and compared against to provide a better understanding of the state-of-the-art. However, the comment lacks specific examples or detailed reasoning to support why this comparison is necessary or how it would enhance the paper. Without additional context or evidence, the claim is somewhat verifiable, as it provides a basis for improvement but lacks depth. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific related work, 'Spectral Clustering Using Multilinear SVD: Analysis, Approximations and Applications' by Ghoshdastidar and Dukkipati, which deals with hypergraph data and tensors. It suggests that this work should be discussed and compared against to provide a better understanding of the state-of-the-art. This feedback is clear and actionable, as it directs the authors to a specific area that needs attention and comparison. However, the comment could be more helpful if it provided more detailed guidance on how to discuss or compare the work, such as specific aspects or methodologies to consider. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises two main points regarding the scalability of the optimal transport distance computation and the exact computation of optimal transport. It questions whether the method scales on normal machines with a few cores and asks for clarification on how to compute exactly optimal transport from the doubly stochastic matrix obtained by the Sinkhorn method. While the comment provides explicit questions and requests for clarification, it does not offer concrete suggestions or actions for the authors to take. The actions are implicit and vague, leaving the authors uncertain about how to address these issues. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the scalability of the optimal transport distance computation, specifically questioning whether it scales on normal machines with a few cores. It also raises a question about how to compute exactly optimal transport from the doubly stochastic matrix obtained by the Sinkhorn method. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues with scalability and the exact computation of optimal transport, but the lack of grounding makes it difficult for the authors to pinpoint the exact parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the scalability of the optimal transport distance computation and the exact computation of optimal transport. It does not contain any subjective opinions or claims that require verification. The questions are factual and seek clarification, aligning with the classification of \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two important questions regarding the scalability of the optimal transport distance computation and the exact computation of optimal transport. It questions whether the method scales on normal machines with a few cores and asks for clarification on how to compute exactly optimal transport from the doubly stochastic matrix obtained by the Sinkhorn method. While the comment identifies specific areas that need clarification, it does not provide actionable suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights important aspects that require further explanation, but it lacks depth and does not offer concrete steps for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that the paper was difficult to follow, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any explicit or implicit actions for the authors to take to improve the clarity of the paper. The comment lacks guidance on how the authors might address these issues, such as suggesting specific sections to clarify or providing examples of how to improve the writing. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. This lack of grounding makes it challenging for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide specific suggestions or examples to address the issue, making it not specific. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the difficulty in following the paper, specifically mentioning the difficulty in understanding the experimental procedures and evaluations. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the reviewer's assertion remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a significant issue with the paper's readability, specifically mentioning the difficulty in following the experimental procedures and evaluations. This feedback is valuable as it points out a critical area that needs improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as providing clearer explanations, additional examples, or a more detailed description of the experimental setup. While the feedback identifies a clear weakness, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It provides an example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m, and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is explicit and provides concrete guidance on what needs to be addressed in the paper. The authors know exactly what aspects to consider and how to implement the suggested clarification, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific section of the paper (line 132), allowing the authors to accurately identify the part being addressed. It also provides specific guidance on what needs to be clarified, such as the aspects of the specific model that are specific to this example model and the clarification regarding the bounds of certain parameters. This level of detail ensures that the authors understand exactly what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It provides an example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is somewhat verifiable as it provides a clear example of what needs to be addressed, but it lacks detailed reasoning or references to support the claim fully. The authors can infer the need for clarification but may require additional context or examples to fully understand the implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on a particular aspect of the paper, suggesting that the authors should consider introducing the specific aspects of the model that are relevant to the example model being discussed. It offers a concrete example by mentioning that the authors should clarify that they are not operating in a setting with infinite subdivisions for \u03b3^1 and \u03b3^m and that certain parameters are bounded on one side (acceleration and scaling parameters). This feedback is clear and actionable, as it directs the authors to a specific area where they need to provide more detail or clarification. By addressing this suggestion, the authors can improve the clarity and precision of their paper, making the comment highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with large-scale datasets. While the comment identifies a potential issue with the learning rate condition, it does not provide explicit guidance on how the authors might address this concern or what changes could be made to the draft. The action is implicit, as the authors would need to infer that they should consider alternative learning rate scaling strategies or provide a more realistic justification for the current condition. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the scalability of the required condition on the learning rate, which is a critical aspect of the paper. It highlights a concern that the learning rate scales with the number of samples, a point that is not realistic in practice. The comment is fully grounded as it explicitly mentions the learning rate condition, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the learning rate condition and its implications for scalability. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the scalability of the required condition on the learning rate, specifically noting that it scales with the number of samples. The reviewer argues that this condition is not realistic because, in practice, the step size does not grow with the sample size, potentially leading to unreasonably large learning rates when dealing with large-scale datasets. The comment provides a logical reasoning for why the condition might be unrealistic, but it lacks specific examples or references to support the claim. Without additional evidence or references, the claim is somewhat verifiable, as it offers a plausible argument but does not provide a comprehensive basis for the authors to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the scalability of the required condition on the learning rate, noting that it scales with the number of samples. The reviewer argues that this condition is not realistic in practice, as the step size does not typically grow with the sample size, potentially leading to unreasonably large learning rates for large-scale datasets. While the comment highlights a potential issue with the learning rate condition, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the draft. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide explicit guidance on how to address this issue or clarify the sampling process. The action is implicit, as the authors would need to infer that they need to provide more details on sampling from the DPP. The lack of concrete instructions or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) and line 130. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying a potential issue with the clarity of the sampling process, but it does not provide detailed guidance on how to address this problem. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of sampling from the DPP when eigenfunctions are inaccessible, referencing Equation (10) and line 130. It also suggests that this issue is similar to sampling from the leverage score, as discussed in [3]. However, the comment lacks specific examples or detailed reasoning to support the claim that the sampling process is unclear or problematic. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the clarity of sampling from the DPP when eigenfunctions are inaccessible, specifically referencing Equation (10) and line 130. It also suggests that this problem is similar to sampling from the leverage score, as discussed in [3]. However, the comment does not provide specific guidance or suggestions on how to address this issue or clarify the sampling process. While it highlights a potential area for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the abstract effectively explains the proposed idea but does not provide details on how the idea was evaluated or what the outcome was. It also mentions minor language issues. While the comment identifies a gap in the abstract's content, it does not explicitly instruct the authors to include details about the evaluation process or the outcomes. The suggestion to address minor language issues is vague and lacks specific guidance. Therefore, the comment is somewhat actionable, as it highlights an area for improvement but does not provide clear instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of description regarding the evaluation process and outcomes, which is a clear indication of what needs to be addressed. The comment is clear and provides specific guidance on what the authors should include in the abstract. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract effectively explains the proposed idea but lacks description of how the idea was evaluated and what the outcome was. It also mentions minor language issues. However, the comment does not provide any specific examples or references to support the claim about the lack of detail in the evaluation process or the outcomes. The mention of \"minor language issues\" is vague and lacks specificity. Therefore, the claim is not verifiable, as it lacks sufficient evidence or justification. The comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the abstract, noting that while it effectively explains the proposed idea, it lacks details on how the idea was evaluated and what the outcome was. This feedback is clear and actionable, as it provides a specific suggestion for the authors to enhance the abstract by including information about the evaluation process and outcomes. However, the comment could be more helpful if it offered additional guidance on how to present this information effectively or suggested specific types of evaluations that could be included. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for solving a POMDP problem with a non-convex value function. The reviewer provides examples of such problems, including surveillance in museums with thresholded rewards and privacy-preserving data collection. However, the comment does not explicitly instruct the authors to address this concern or provide suggestions on how to improve the experimental section. The lack of explicit guidance or actionable steps leaves the authors uncertain about how to respond or enhance their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the experimental results of the paper, specifically questioning the motivation for solving a POMDP problem with a non-convex value function. It provides examples of such problems, including surveillance in museums with thresholded rewards and privacy-preserving data collection. However, the comment does not specify which part of the paper these examples are discussed in, making it weakly grounded. The comment is specific in detailing the issue with the experimental section, as it questions the lack of experiments on the mentioned settings. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the experimental results of the paper, specifically questioning the motivation for solving a POMDP problem with a non-convex value function. The reviewer provides examples of such problems, including surveillance in museums with thresholded rewards and privacy-preserving data collection. However, the comment does not offer any specific evidence, reasoning, or references to support the claim that the experiments are not useful or lack motivation. Without detailed justification or examples, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises concerns about the experimental results of the paper, specifically questioning the motivation for solving a POMDP problem with a non-convex value function. The reviewer provides examples of such problems, including surveillance in museums with thresholded rewards and privacy-preserving data collection, and questions why there are no experiments on these settings, even simulated ones. This feedback highlights a potential gap in the experimental section, suggesting that it may not be as useful as it could be. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their experimental design. While it identifies a weakness, it does not provide actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the authors' claim about the immense workload but disagrees with the assessment of the paper's contribution as incremental. It suggests that the paper is essentially a combination of GraphRAG and GraphCare [1] and points out that many key baselines were not cited. The comment also notes that essential RAG algorithms for EHR, such as MedRetriever [2], and commonly used GraphRAG algorithms like KGRAG [3], should have been introduced. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific sections to revise or how to incorporate the missing information. While the action is somewhat implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors' claim about the immense workload and the incremental contribution of the article, referencing specific works [1], [2], and [3]. It also provides specific suggestions for improvement, such as introducing essential RAG algorithms like MedRetriever and commonly used GraphRAG algorithms like KGRAG. This level of detail allows the authors to understand exactly what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' contribution is incremental and suggests that the paper is essentially a combination of GraphRAG and GraphCare [1]. It also points out that many key baselines were not cited and recommends introducing essential RAG algorithms like MedRetriever [2] and commonly used GraphRAG algorithms like KGRAG [3]. The claim about the incremental contribution is somewhat verifiable as it provides a basis for comparison with existing work, but it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestions for introducing additional algorithms are clear and actionable, making the comment mostly verifiable. Therefore, the comment aligns with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides a detailed critique of the authors' work, highlighting the incremental nature of their contribution and suggesting that the paper is essentially a combination of GraphRAG and GraphCare [1]. It also points out that many key baselines were not cited, which is a significant oversight. Additionally, the comment recommends introducing essential RAG algorithms like MedRetriever [2] and commonly used GraphRAG algorithms like KGRAG [3], which would enhance the paper's comprehensiveness. While the comment is mostly helpful, it could be more comprehensive by providing specific guidance on how to address the identified issues, such as suggesting specific sections to revise or how to incorporate the missing information. Overall, the feedback is valuable and actionable, making it a mostly helpful comment.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement is due to the network design or the nature of ImageNet. This provides clear guidance on what needs to be done and how to address the concern, making the comment highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to show a graph of T vs the number of images and Expectation(T) over the ImageNet test set, allowing the authors to accurately identify the parts of the paper that need revision. It is also specific because it provides clear guidance on what needs to be addressed, including the purpose of the graph and the question about the source of performance improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should include a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a question about whether the performance improvement stems from the network design or the nature of ImageNet. However, the comment lacks specific examples or references to support the claim that these visualizations are necessary or how they would address the concern about performance improvement. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by requesting the inclusion of a graph showing the plot of T vs the number of images and Expectation(T) over the ImageNet test set. It also raises a critical question about whether the performance improvement is due to the network design or the nature of ImageNet, which is an important consideration for understanding the results. By addressing these points, the comment offers actionable feedback that could help the authors enhance the clarity and depth of their analysis. However, the comment could be more helpful if it provided more detailed guidance on how to create the graph or how to address the question about the source of performance improvement. Overall, the feedback is mostly helpful as it directs the authors towards important areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, noting that the baseline and time-aware models show similar performance. It suggests that the proposed method might be more effective under different time-step scenarios. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes might be needed to demonstrate the effectiveness of the proposed methods. The action is implicit and vague, as it does not specify how the authors should modify their experiments or analysis to support their claims. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider, namely the performance of the baseline and time-aware models when the training and evaluation time-steps are the same. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, based on the observation that Figure 5 shows similar performance between the baseline and time-aware models. While the comment identifies a potential issue, it does not provide specific examples or references to support the claim that the proposed method might be more effective under different time-step scenarios. The reasoning is somewhat vague, as it lacks detailed explanation or evidence to substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some basis for the claim but lacks sufficient detail or justification.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the effectiveness of the proposed methods when the training and evaluation time-steps are the same, as evidenced by the similar performance shown in Figure 5. The comment suggests that the proposed method might be more effective under different time-step scenarios, which is a relevant point for consideration. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what additional experiments or analyses could be conducted to demonstrate the effectiveness of the proposed methods. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how disentanglement is guaranteed in the paper. It suggests that while the \"Broader Impacts and Limitations\" section mentions a limitation related to disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain biases. This feedback is explicit and provides a clear action for the authors to take, which is to elaborate on the mechanisms and guarantees of disentanglement. However, the comment does not specify exactly how this should be done, leaving some room for interpretation. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the issue of disentanglement, specifically questioning how it is guaranteed. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation related to disentangled latent vectors. However, the comment does not specify which part of the paper discusses disentanglement or how it is realized. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the issue of disentanglement, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of how disentanglement is guaranteed in the paper. It references the \"Broader Impacts and Limitations\" section, which mentions a limitation related to disentangled latent vectors. However, the comment does not provide specific examples or detailed reasoning to support the claim that the disentanglement is not clearly guaranteed. This lack of detailed explanation or evidence makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the clarity of how disentanglement is guaranteed in the paper. It points out that while the 'Broader Impacts and Limitations' section mentions a limitation related to disentangled latent vectors, the authors should provide more detail on how disentanglement is realized and guaranteed without certain biases. This feedback is clear and actionable, as it directs the authors to elaborate on the mechanisms and guarantees of disentanglement. However, the comment could be more helpful if it provided specific examples or suggestions for how to address this issue. Overall, the comment is mostly helpful, as it identifies a significant area for improvement and encourages the authors to provide more detailed explanations.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, it should be used a standard regularization trick. However, the comment does not provide any explicit or implicit guidance on how to implement this suggestion or what specific aspects of the comparison need to be addressed. The authors are left without a clear understanding of how to apply this feedback, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests using a standard regularization trick to compare the obtained complexity for the proposed method with the previous result in a strongly-convave case. However, it does not specify which part of the paper this comparison is intended for or which section discusses the previous result. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment is specific about the type of regularization trick, it lacks grounding, as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, it should be used a standard regularization trick. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, this comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that to compare the obtained complexity for the proposed method with the previous result in a strongly-convex concave case, it should be used a standard regularization trick. This feedback is somewhat helpful as it points out a specific area for improvement in the comparison of the proposed method with existing results. However, the comment lacks depth and does not provide detailed guidance on how to implement the suggested change or what specific aspects of the comparison need to be addressed. The authors would benefit from additional clarification or examples to fully understand and apply this feedback. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the handling of different types of inputs and the disordered citation. For the first part, it suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, and present their solutions. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be addressed and how to do it. However, the comment does not specify which part of the paper this discussion should be included in, leaving some ambiguity. For the second part, the comment suggests that the citation is disordered, but it does not provide specific guidance on how to correct it. While the action is somewhat explicit for the first part, the second part lacks detail, making the comment somewhat actionable overall.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the handling of different types of inputs, such as bio-medical signals or speech, suggesting that the authors should discuss this and present their solutions. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting that the authors should discuss how they handle these different types of inputs and present their solutions, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two main concerns: the handling of different types of inputs and the disordered citation. While the comment suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, it does not provide specific examples or references to support this claim. The suggestion to present solutions is clear, but the lack of detailed reasoning or examples makes the claim somewhat verifiable. The comment also mentions that the citation is disordered, but it does not elaborate on why it is disordered or how it should be corrected, which limits the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement: the handling of different types of inputs and the disordered citation. It suggests that the authors should discuss how they deal with various inputs, such as bio-medical signals or speech, and present their solutions in the paper. This provides a clear direction for the authors to enhance the paper's content and clarity. However, the comment lacks specific guidance on how to address the disordered citation, which limits its helpfulness. While the feedback is somewhat actionable, it could be more comprehensive if it included suggestions on how to correct the citation. Overall, the comment is mostly helpful, as it provides valuable insights but could be more detailed in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not 'Wh-types'/transformable. However, it does not provide any explicit or implicit suggestions on how to address this issue or what changes might be necessary. The comment lacks concrete guidance on how to improve the generalization of the model or what specific modifications could be made to the template mapping. As a result, the authors are left without a clear understanding of how to apply the feedback to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the question answering process, specifically mentioning the template mapping and its potential impact on generalization to questions that are not 'Wh-types'/transformable. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential problem with the template mapping, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the question answering process might cause poor generalization to questions that are not \"Wh-types\"/transformable due to the template mapping. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed evidence or examples, the authors may find it difficult to understand or address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the question answering process, specifically mentioning that the template mapping might cause poor generalization to questions that are not \"Wh-types\"/transformable. This feedback is somewhat helpful as it highlights a specific area that could be improved, but it lacks detailed guidance or suggestions on how to address this issue. The authors are left without a clear understanding of what changes might be necessary to enhance the generalization of their model. While the comment points out a potential problem, it does not provide actionable steps or examples to resolve it, making it somewhat helpful but not fully comprehensive. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the ICL-HAR, noting that it improves consistency and verifiability but negatively impacts accuracy scores. It suggests that this issue should be discussed or acknowledged in more detail in the main text. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects of the discussion should be included. The action is implicit, as the authors need to infer that they should expand the discussion to address the accuracy drop. While the action is somewhat concrete, the lack of detailed guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ICL-HAR,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the ICL-HAR improves consistency and verifiability but negatively impacts accuracy scores, which need to be discussed in more detail. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the label is 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the ICL-HAR improves consistency and verifiability but negatively impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. The comment suggests that this issue should be discussed or acknowledged in more detail in the main text. However, it does not provide specific examples, references, or detailed reasoning to support the claim that the accuracy drop is significant or why it should be discussed. The lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the significance of the accuracy drop and its implications. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the ICL-HAR, noting that while it improves consistency and verifiability, it negatively impacts accuracy scores, dropping from 70.4 to 55.6 on TRIP. This observation is important for the authors to address, as it highlights a potential trade-off between consistency and accuracy. However, the comment lacks actionable guidance on how the authors might address this issue or what specific aspects of the discussion should be expanded to acknowledge the accuracy drop. While it points out a critical area for improvement, the feedback could be more helpful if it provided suggestions or examples of how to discuss or acknowledge the accuracy drop in the main text. Therefore, the comment is somewhat helpful, as it identifies a significant issue but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the rock-paper-scissors example is inspired by previous work and requests that the authors cite the source appropriately. While the comment implies that the authors should cite the source, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should cite the source. However, the comment provides a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"rock-paper-scissors example,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests that the authors cite the source appropriately, providing clear guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the rock-paper-scissors example is inspired by an example from previous work and requests that the authors cite the source appropriately. This claim is somewhat verifiable as it suggests a specific action (citing the source) but does not provide detailed reasoning or examples to support why this is necessary. The authors would need to infer that citing the source is important to avoid plagiarism or to give proper credit to previous work. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the rock-paper-scissors example, noting that it is inspired by previous work and requests that the authors cite the source appropriately. This feedback is clear and actionable, as it directs the authors to address a potential issue of plagiarism or lack of proper attribution. By suggesting the authors cite the source, the comment provides a concrete step for improvement, making it mostly helpful. However, it could be more helpful if it offered additional guidance on how to find or reference the appropriate source. Overall, the comment is mostly helpful as it provides a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that comparing the model's performance only on pre-trained synthetic data is unfair and recommends demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to include specific details or actions to take, such as which real-world datasets to use or how to compare the performance across different losses. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to implement the suggested changes. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of comparing the model's performance only on pre-trained synthetic data, which is an important aspect of the paper. It suggests that demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses is necessary. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in that it clearly outlines the need for additional comparisons and demonstrations, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that comparing the model's performance only on pre-trained synthetic data is unfair and suggests demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses. This claim is somewhat verifiable as it provides a logical reasoning for why the comparison might be unfair and suggests a more comprehensive approach to evaluating the model. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the comparison of the model's performance, suggesting that it is unfair to only compare the model pre-trained on synthetic data. It recommends demonstrating the importance of the proposed three projection errors by showing performance on real-world datasets with different losses. This feedback is clear and actionable, providing a specific direction for the authors to improve their draft by including additional comparisons and demonstrations. However, it could be more helpful if it included specific examples of real-world datasets or detailed guidance on how to conduct these comparisons. Overall, the comment is mostly helpful as it offers a clear and constructive suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not provide explicit guidance on how to implement these suggestions or actions, such as specific steps or examples of how to conduct the calibration curves or discuss the differences. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the model AUC's ability to assess discriminant ability and suggests that it may be difficult to demonstrate consistency with actual risk. It recommends conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it suggests discussing the differences between the traditional method and the proposed method. However, the comment does not specify which part of the paper discusses the model AUC or where the calibration curves or feasibility discussion should be included. This makes it weakly grounded, as the authors cannot confidently determine which sections or parts of the paper need revision. The comment is specific in detailing the issues and suggestions, such as conducting calibration curves and discussing differences, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model AUC can assess discriminant ability but may be difficult to demonstrate consistency with actual risk. It suggests conducting calibration curves to show agreement and encourages the authors to prove the feasibility of the generated scoring system. Additionally, it recommends discussing the differences between the traditional method and the proposed method. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The feedback is somewhat verifiable as it provides a general direction but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model AUC's ability to demonstrate consistency with actual risk, suggesting that calibration curves could be used to show agreement. It also encourages the authors to prove the feasibility of the generated scoring system and to discuss the differences between the traditional method and the proposed method. While the comment provides some direction and suggestions, it lacks specific guidance on how to implement these recommendations or detailed examples of how to conduct the calibration curves or discuss the differences. This makes the feedback somewhat helpful, as it offers a general idea of what needs improvement but does not provide comprehensive actionable advice. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the sparsity patterns and suggests that the authors should clarify whether the observed results are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment does not provide explicit instructions on how the authors should address these issues or what specific actions they should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the sparsity patterns observed in the paper, suggesting that the authors should clarify whether these patterns are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment does not explicitly mention which part of the paper contains the sparsity patterns or the presentation of bits, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issue of sparsity patterns and the presentation of bits, the lack of explicit grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the sparsity patterns observed in the paper, suggesting that the authors should clarify whether these patterns are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the sparsity patterns are almost equally well, leaving the authors uncertain about the basis of the critique. The lack of detailed explanation or evidence makes it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the sparsity patterns observed in the paper, suggesting that the authors should clarify whether these patterns are specific to the sparsity detection problem or generalize to GNNs in general. It also points out that the presentation of bits in Section 4.3 could be improved. However, the comment lacks specific guidance or suggestions on how the authors might address these issues, leaving the authors with limited actionable feedback. The feedback is somewhat helpful as it identifies areas for improvement, but it does not provide detailed or constructive advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument for using Shapely values. It also recommends including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. These suggestions are clear and provide concrete guidance on how the authors can improve their draft. The comment is fully actionable, as it directly instructs the authors on what needs to be done to strengthen their argument and provide a more comprehensive analysis. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Shapely values\" and suggests comparing them with other methods like CaCE or raw gradients. This allows the authors to accurately identify the part of the paper being addressed. Additionally, the comment specifies the need for a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors need to provide a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support their argument. It also suggests including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space. While the comment provides a logical reasoning for the need for such comparisons and discussions, it lacks specific examples or references to support the claims. The authors would need to infer the need for these comparisons and discussions, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by recommending a comparison of Shapely values with other methods, such as CaCE or raw gradients, to support the argument for using Shapely values. It also suggests including a discussion on the advantages and disadvantages of transforming high-dimensional data to low-dimensional latent space, which could enhance the paper's comprehensiveness. These suggestions are clear and actionable, offering the authors a clear path to improve their draft. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the comparison or the specific aspects of the discussion to include. Overall, the comment is mostly helpful, as it identifies areas for improvement and provides a basis for the authors to enhance their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. While the comment implies that this comparison would be beneficial, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include such a comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that Section 6 could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, it does not specify which part of Section 6 this comparison should be made or what specific aspects of the comparison are needed. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in suggesting a comparison, but without further details, it remains somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the related work section could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis for the suggestion or how to address it. Without additional context or references, the claim is considered borderline verifiable, as it provides a general direction but lacks the necessary depth or specificity to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the related work section could benefit from comparing the perspective taken in the present manuscript to the contributions of prior efforts. This feedback is somewhat helpful as it identifies a potential area for improvement, specifically in enhancing the context and relevance of the related work section. However, the comment lacks specificity and does not provide detailed guidance on how to achieve this comparison or what aspects of prior work should be considered. As a result, the authors may need to infer the intended improvement, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the performance of the paper is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment does not provide explicit guidance on how to conduct this examination or what specific aspects of the performance should be analyzed. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests examining the performance with different numbers of scenarios, implying that the number of scenarios used for training might influence the results. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The comment is weakly grounded because the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting an area for further examination, but without clear guidance on how to implement this suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the performance of the paper is closely related to the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the performance of the paper might be influenced by the number of scenarios used for training. It proposes examining the performance with different numbers of scenarios, noting that the current paper uses a fixed number of 200. However, the comment lacks specific guidance on how to conduct this examination or what aspects of the performance should be analyzed. While it identifies a potential area for improvement, it does not provide actionable steps or detailed suggestions, making it somewhat helpful. The authors would need to infer the necessary actions, which limits the comment's effectiveness. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the comprehensiveness of the experiments conducted to validate the efficacy of CATER in different settings, such as architectural mismatch and cross-domain imitation. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might improve their draft or address any specific issues related to the comprehensiveness of their experiments. As a result, the authors are left without any actionable feedback, making this comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the experiments conducted to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the experiments conducted, providing clear guidance on the comprehensiveness of the validation process. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point describes the experiments conducted to validate the efficacy of CATER in various settings, including an architectural mismatch and cross-domain imitation. However, it does not provide any specific evidence, reasoning, or references to support the claim that these experiments are comprehensive or effective. Without additional context or justification, the authors may find it challenging to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights the comprehensiveness of the experiments conducted to validate the efficacy of CATER in various settings, such as an architectural mismatch between the victim and the imitation model and cross-domain imitation. While this feedback acknowledges the thoroughness of the experiments, it does not provide specific suggestions or guidance on how the authors might further enhance their work or address any potential limitations. The comment lacks actionable insights, leaving the authors with a general understanding of the strengths of their experiments but without clear directions for improvement. Therefore, the comment is somewhat helpful, as it identifies an area of strength but does not offer substantial guidance for enhancement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Appendix A.2 does not illustrate the state space representation of the environment clearly. While it points out a specific area that needs improvement, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the representation in the appendix, but without specific suggestions or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment explicitly mentions \"Appendix A.2,\" providing full grounding as the authors can accurately identify the part of the paper being addressed. It also specifies that the appendix does not illustrate the state space representation of the environment clearly, offering a clear and specific critique. This aligns with the definition of a comment that is fully grounded and specific, making it a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Appendix A.2 does not illustrate the state space representation of the environment clearly. However, it does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the state space representation in Appendix A.2. While it points out a potential area for improvement, it does not provide detailed guidance or suggestions on how the authors might enhance the clarity of this representation. The feedback is somewhat helpful as it directs the authors to a specific area that needs attention, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors' approach is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. The comment lacks guidance on how the authors might adapt their approach or what changes could be made to make it applicable to larger problems. As a result, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the authors' approach is only applicable to small or medium-scale problems, implying that it may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, the comment does not specify which part of the paper this issue is discussed or addressed, leaving the authors uncertain about the exact section or aspect that needs attention. Additionally, the comment lacks specificity in detailing what changes or adaptations could be made to make the approach applicable to larger problems. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' approach is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of this claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the authors\\' approach, noting that it is only applicable to small or medium-scale problems and may not be suitable for large-scale problems due to the limitations of current LP-solvers. This feedback highlights a potential constraint on the applicability of the authors\\' work, which could be valuable for the authors to consider in future iterations of their research. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or adapt their approach for larger problems. Without actionable advice or examples, the comment is somewhat helpful, as it points out a critical area for improvement but does not provide a comprehensive roadmap for the authors to follow. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the restrictive nature of the bounded noise assumption in stochastic optimization literature and mentions several efforts to extend these noise conditions, citing specific works. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting alternative assumptions or exploring the cited works. The comment lacks concrete guidance on how the authors might address the issue or incorporate the suggested references into their work. As a result, the authors are left without clear direction on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the bounded noise assumption in stochastic optimization literature, referencing specific works that extend these noise conditions. However, it does not specify which part of the paper discusses the bounded noise assumption or how it relates to the authors' work. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, while the comment mentions specific works, it does not provide detailed guidance on how these works could be integrated or discussed in the paper. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the bounded noise assumption, while common, is somewhat restrictive in stochastic optimization literature. It provides references to specific works that have extended these noise conditions, such as [A. Khaled and P. Richt\u00b4arik]. Better theory for sgd in the nonconvex world. TMLR 2023. [R. Gower, O. Sebbouh, and N. Loizou] Sgd for structured nonconvex functions: Learning rates, minibatching and interpolation. AISTATS 2021. However, the comment does not offer a detailed explanation of why the bounded noise assumption is restrictive or how the cited works address this limitation. While the references provide context, the lack of a thorough explanation or logical reasoning makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the bounded noise assumption, which is a common assumption in stochastic optimization literature. It acknowledges that this assumption is somewhat restrictive and provides references to works that have extended these noise conditions. However, the comment does not offer specific suggestions or guidance on how the authors might address this limitation or incorporate the suggested works into their research. While it highlights an important aspect of the literature, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as barely helpful, as it provides some context but lacks detailed guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the motivation need clarification. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the motivation behind using characteristic function regularization. However, it does not specify which part of the paper discusses this motivation, making it difficult for the authors to pinpoint the exact section or aspect that needs clarification. The comment is specific in identifying the issue but lacks grounding as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the overall motivation of using characteristic function regularization is not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the motivation is unclear or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the motivation behind using characteristic function regularization. However, it lacks specific details or suggestions on how the authors might address this issue or what aspects of the motivation need clarification. Without actionable guidance or examples, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It claims that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment does not provide explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how to improve the paper or what specific aspects need to be addressed to enhance the contribution. As a result, the comment is unactionable, as the authors are left without a clear path forward to improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the combination of existing techniques used in the paper, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a detailed description of the techniques used and suggests that the combination of these techniques is not surprising, implying that the contribution might be incremental. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper combines existing techniques, such as adaptation to an unknown level of corruption, varying variances treated with a weighted version of OFUL, and variable decision sets. It suggests that the combination of these techniques is not surprising and that the contribution could be considered incremental. However, the comment lacks specific examples or detailed reasoning to support the claim that the combination is not surprising or that the contribution is incremental. Without further elaboration or evidence, the claim remains somewhat verifiable, as it is based on the authors' interpretation of the results. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential limitation in the paper by suggesting that the combination of existing techniques might not be surprising, implying that the contribution could be considered incremental. While the comment points out a specific aspect of the paper that could be further explored or differentiated, it does not provide detailed guidance or suggestions on how to address this limitation or enhance the contribution. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable advice, making it only marginally beneficial for the authors. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the aggregation operation after \"Integration\" needs further clarification. It also provides a concrete action by instructing the authors to provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This direct and specific guidance allows the authors to understand exactly what needs to be addressed and how to implement the suggested changes. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Multiscale modeling\" and \"Integration,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for further clarification on the aggregation operation after \"Integration\" and suggests providing more details in the main paper and acknowledging the structure of other architectures if they are referred to. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the aggregation operation after \"Integration\" needs further clarification. While it provides a general direction for improvement, it lacks specific details or examples to guide the authors on how to clarify the operation. Without additional context or suggestions, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered borderline verifiable, as it provides some guidance but lacks the depth needed for full clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the need for further clarification on the aggregation operation after \"Integration.\" It provides a clear and actionable suggestion by instructing the authors to provide more details in the main paper and acknowledge the structure of other architectures if they are referred to. This feedback is specific and directly addresses a potential weakness in the paper, offering a clear path for improvement. However, the comment could be more helpful if it included examples or suggestions for how to clarify the aggregation operation. Overall, the comment is mostly helpful as it provides actionable guidance but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, suggesting that the authors should consider this in their work. However, the comment does not provide explicit guidance on how the authors should address this similarity or how they might differentiate their approach. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of energy models for image generation and compares it to GANs and VAEs, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the motivation and goals of the model, noting that they are similar to a prior VAE paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that energy models for image generation are less explored compared to GANs and VAEs, suggesting that exploring them further is a promising direction. It also notes that the motivation and goals of the model are similar to a prior VAE paper, implying that the authors should consider this in their work. However, the comment lacks specific examples or detailed reasoning to substantiate these claims, making it difficult for the authors to fully understand and address the feedback. The claim is somewhat verifiable, as it provides a general direction but lacks detailed support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that exploring energy models for image generation is a promising direction, noting that it is less explored compared to GANs and VAEs. It also points out that the motivation and goals of the model are similar to a prior VAE paper, which could help the authors understand the context of their work. However, the comment lacks specific guidance on how the authors might address this similarity or how they could differentiate their approach. While it provides a direction for further exploration, it does not offer detailed suggestions or actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the method should be evaluated on a different benchmark, such as Atari, to assess its generalizability to other domains. It provides a clear action for the authors to take, which is to run experiments on this new benchmark. The comment is explicit and concrete, as it directly instructs the authors on how to improve their draft by expanding the evaluation to include a different benchmark. This level of detail ensures that the authors know exactly what to do to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the evaluation on a single domain and suggests running experiments on a different benchmark, such as Atari, which is a common practice in the literature. This provides clear guidance on which part of the paper needs to be addressed. The comment is also specific because it specifies the need to evaluate the method on a different benchmark to assess its generalizability to other domains, including discrete action spaces and high-dimensional observations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is evaluated only on the Meta World domain, making it difficult to judge its generalizability to other domains. The reviewer suggests running experiments on a different benchmark, such as Atari, to verify the method's effectiveness with discrete action spaces and high-dimensional observations. This claim is somewhat verifiable as it provides a logical reasoning for why the evaluation is limited to a single domain and suggests a potential solution. However, it lacks specific examples or references to support the claim fully, which could make it less convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for improving the evaluation of the method. It highlights the limitation of evaluating the method on a single domain, specifically the Meta World robotic manipulation domain, and suggests running experiments on a different benchmark, such as Atari, to assess the method's generalizability. This recommendation is valuable as it addresses a critical aspect of the paper's evaluation, which is essential for demonstrating the robustness and applicability of the proposed method. By expanding the evaluation to include a different benchmark, the authors can provide a more comprehensive assessment of their method's performance and its potential for broader application. Therefore, the comment is highly helpful, as it offers a clear and constructive direction for improving the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not provide explicit guidance on how to conduct this analysis or what specific aspects of the model's behavior should be examined. The comment is vague and lacks concrete details, making it difficult for the authors to understand how to apply the suggested action. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should include an analysis of what the model does, which could be interesting. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in its suggestion to add an analysis, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to understand where to apply the suggestion. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include an analysis of what the model does, which could be interesting. However, the comment lacks specific details or examples to support this suggestion, making it difficult for the authors to understand how to incorporate such an analysis. Without clear guidance or references, the claim remains somewhat verifiable, as it lacks the necessary depth and specificity to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the strengths of the paper, such as the presentation of the method and the quality of the experiments, but identifies a significant weakness: the lack of analysis on what the model does. This feedback is valuable as it highlights an area where the authors could enhance their work by providing a deeper understanding of the model's behavior. However, the comment could be more helpful if it suggested specific ways to conduct this analysis or provided examples of what kind of analysis would be beneficial. Overall, the comment is somewhat helpful as it points out a crucial aspect that needs improvement, but it lacks detailed guidance, making it only partially beneficial.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the task setup description, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. While the comment identifies a specific issue with the clarity of the task setup, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify these aspects in their draft, but the action is not concrete or detailed. Therefore, the comment is somewhat actionable, as it points out a specific area for improvement but lacks explicit instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the task setup description, which is a specific part of the paper. However, it does not explicitly mention which section or part of the paper discusses the task setup, making it weakly grounded. The comment is specific in identifying the lack of clarity regarding the input notes in the EHR and the distance of the outcomes from the last note date. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it weakly grounded and specific. Therefore, the comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the task setup is not described clearly, specifically questioning which notes in the EHR are used as input and how far away the outcomes are from the last note date. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without specific examples or references, the authors are left to assume the claim is valid, which makes it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the task setup description in the paper. It points out that the authors do not clearly specify which notes in the EHR are used as input and how far away the outcomes are from the last note date. This feedback is valuable as it highlights a potential area of confusion for readers, suggesting that the authors should provide a more detailed explanation of the task setup. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the description, such as providing examples or a more structured explanation. Overall, the comment is somewhat helpful as it identifies a specific area for improvement but lacks detailed guidance on how to address it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy in the convergence rate of the proposed algorithm DMLCBO compared to previous works that utilize the double momentum technique. It suggests that the authors should discuss the reasons for this difference and the theoretical differences between DMLCBO and the mentioned works. While the comment provides a clear direction for the authors to address the issue, it does not specify how to analyze the convergence rate or the theoretical differences. The action is explicit but somewhat vague, as it lacks detailed guidance on how to implement the suggested discussion. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed algorithm DMLCBO and the double momentum technique, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by comparing the convergence rate of DMLCBO with previous works, such as SUSTAIN and MRBO, which is clearly detailed. The comment provides specific guidance on what needs to be discussed, including the reasons for the discrepancy in convergence rate and the theoretical differences between DMLCBO and the mentioned works. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed algorithm DMLCBO, based on the double momentum technique, does not achieve the same convergence rate as previous works like SUSTAIN and MRBO. The comment provides specific references to these works and suggests that the authors discuss the reasons for this discrepancy and the theoretical differences between DMLCBO and the mentioned works. This claim is supported by logical reasoning and references to specific works, making it mostly verifiable. However, it could be more robust with additional examples or detailed explanations of the theoretical differences. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed algorithm DMLCBO, noting that it does not achieve the same convergence rate as previous works that utilize the double momentum technique. It provides a clear comparison with previous works, such as SUSTAIN and MRBO, and suggests that the authors discuss the reasons for this discrepancy and the theoretical differences between DMLCBO and these works. This feedback is actionable and constructive, as it guides the authors to address a critical aspect of their algorithm's performance. However, the comment could be more helpful if it provided additional guidance on how to analyze the convergence rate or the theoretical differences. Overall, the comment is mostly helpful, as it offers valuable insights and directions for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide explicit guidance on how the authors might address these issues or what specific actions they should take to improve the modulator. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not specify which part of the paper discusses the modulator or where the issue of scalability is addressed. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs attention. While the comment is specific in its critique of the modulator's design, the absence of explicit references to the paper's sections or content makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the heuristic design of the modulator and suggests that it might be hard to justify due to potential scalability issues and the need for tedious hyperparameter tuning for diverse training data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the heuristic design of the modulator, specifically questioning its scalability and the need for tedious hyperparameter tuning for diverse training data. While the comment highlights a concern that could impact the robustness and generalizability of the model, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable advice or detailed recommendations, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of imitation learning, suggesting that obtaining labeled data through optimal problem-solving is necessary. However, it does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to conduct experiments or analyze the impact of labeled data size. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the necessity of obtaining labeled data for imitation learning, suggesting that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its critique, the absence of explicit references to the paper makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the necessity of obtaining labeled data for imitation learning and suggests that there are no experiments on the difficulties of obtaining this data or how performance changes with the size of the labeled data. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue raised. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of imitation learning, specifically questioning the necessity of obtaining labeled data and the lack of experiments on the challenges and performance changes associated with different sizes of labeled data. While the comment highlights a gap in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is somewhat helpful as it points out a potential area for further exploration, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper's exploration of the proposed method's implications for other NLP tasks is limited, which somewhat limits the generalizability of the results. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to explore the method's implications for other NLP tasks. The action is implicit and vague, as it does not specify how the authors can enhance the exploration of the method's implications. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"contrastive learning in code search tasks,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by stating that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the implications of the proposed method for other NLP tasks, which limits the generalizability of the results. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides a general observation but lacks sufficient detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper by pointing out that while it provides valuable insights for contrastive learning in code search tasks, it does not thoroughly explore the implications of the proposed method for other NLP tasks. This observation is somewhat helpful as it highlights a potential area for further exploration and could guide the authors in expanding the scope of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this limitation, such as suggesting additional experiments or analyses that could be conducted to explore the method's implications for other NLP tasks. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of the term \"certificate\" in the paper, specifically at line 267. It suggests that the term might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any explicit guidance or suggestions on how the authors should address this issue. The authors are left without a clear understanding of what changes or actions they should take to clarify the terminology. As a result, the comment is unactionable because it lacks specific instructions or guidance on how to resolve the potential misinterpretation. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the use of the term \"certificate\" in the paper, particularly at line 267. It highlights a potential misinterpretation due to the strong meaning of \"certificate\" in complexity theory. This provides clear grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific because it details the potential issue with the terminology, making it clear what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of the term \"certificate\" in some contexts might be misinterpreted due to its strong meaning in complexity theory. However, the comment does not provide any specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the term \"certificate\" in the paper, specifically at line 267. It points out that the term might be misinterpreted due to its strong meaning in complexity theory. This feedback is somewhat helpful as it highlights a potential area of confusion that the authors should consider. However, the comment lacks specific guidance or suggestions on how the authors might address this issue, such as providing alternative terminology or clarifying the context in which the term is used. Without actionable advice, the authors may find it challenging to improve their draft based on this feedback alone. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should conduct additional experiments to include these network structures. However, the comment does not specify which experiments should be conducted or how the results should be presented. The action is implicit and somewhat vague, as the authors need to infer the exact nature of the additional experiments. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider including these experiments. However, the comment does not specify which parts of the paper these additional experiments should be conducted on, making it weakly grounded. The comment is specific in suggesting the need for more experiments on specific network structures, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific details on how these experiments should be conducted or what results should be expected. The references provided are relevant, but the comment does not offer a clear rationale or detailed explanation of why these additional experiments are necessary. Therefore, the claim is somewhat verifiable, as it is supported by references but lacks detailed reasoning or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that more experiments on deeper networks, such as ResNet-50, and other network structures, such as MobileNet, are needed to strengthen the paper. It provides references to relevant works, which implies that the authors should consider conducting additional experiments to include these network structures. However, the comment lacks specific guidance on how these experiments should be conducted or what results should be expected. While it identifies an area for improvement, it does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the evaluation of the results, noting that while the analysis is detailed and comprehensive, it only considers two relatively old and small models. This feedback provides a clear and explicit action for the authors to take, which is to expand the evaluation to include more recent and larger models. The comment is specific in its suggestion, offering a concrete direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the results/analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the evaluation is limited to two relatively old and small models, which the authors can address by expanding their evaluation to include more recent and larger models. This provides a clear direction for improvement, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results/analysis, despite being detailed and comprehensive, are limited to only two relatively old and small models. This claim is somewhat verifiable as it provides a specific observation about the scope of the evaluation. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors could benefit from additional context or examples to better understand the limitations of the evaluation.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the evaluation of the results, noting that despite being detailed and comprehensive, the analysis is limited to only two relatively old and small models. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors should expand their evaluation to include more recent and larger models. By addressing this limitation, the authors can enhance the depth and comprehensiveness of their analysis, making the comment highly helpful. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a belief that KD can be viewed as a special form of LS under certain conditions, specifically when the teacher network is uniformly distributed and the temperature is set at 1. However, it does not provide explicit or implicit actions for the authors to take, such as suggesting how to incorporate this perspective into their work or providing further clarification. The comment lacks concrete guidance on how the authors might address this point or integrate it into their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It makes a claim about the relationship between KD and LS, but without referencing specific sections or elements of the paper, the authors cannot confidently determine where this comment applies. The comment is also not specific because it does not detail what needs to be addressed or how the authors should approach the relationship between KD and LS. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a belief that KD can be viewed as a special form of LS under specific conditions. However, it lacks detailed reasoning or examples to support this claim. Without specific evidence or logical reasoning, the authors may find it challenging to understand and address the comment effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for understanding but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment expresses a belief that KD can be viewed as a special form of LS under specific conditions, particularly when the teacher network is uniformly distributed and the temperature is set at 1. This observation is interesting and could provide valuable insights for the authors to consider in their work. However, the comment lacks actionable guidance or suggestions on how the authors might explore or incorporate this perspective into their research or draft. Without specific advice on how to address this point or integrate it into their work, the comment is somewhat helpful as it offers an interesting observation but does not provide comprehensive feedback. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more recent competing dynamic-pruning methods and results on large-scale datasets, such as ImageNet, to further verify the effectiveness of the proposed method. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be added to their draft. The comment is specific in its suggestions, detailing which areas require improvement and what kind of results should be included. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"No.3. 2021\" and \"Competing dynamic-pruning methods are kind of out-of-date,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including more recent works and results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper should include more recent competing dynamic-pruning methods and results on large-scale datasets, such as ImageNet, to verify the effectiveness of the proposed method. While the comment suggests the need for more recent comparisons, it does not provide specific examples or references to support this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some basis for improvement but lacks sufficient detail to be fully actionable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that the comparison with competing dynamic-pruning methods is outdated. It suggests including more recent works to provide a more comprehensive evaluation of the proposed method. Additionally, the comment highlights the lack of results on large-scale datasets, such as ImageNet, which are crucial for verifying the effectiveness of the method. This feedback is clear and actionable, as it provides specific suggestions for improvement that the authors can easily implement. However, the comment could be more helpful if it included specific examples of recent works or detailed guidance on how to conduct the additional experiments. Overall, the comment is mostly helpful, as it offers valuable insights and directions for enhancing the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. It suggests that while the choice might be interesting, it is not well-motivated. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of the task are interesting. The action is implicit and vague, as it leaves the authors to infer that they need to provide a clearer motivation for their choice. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the motivation, but without explicit references to sections or figures, the authors cannot confidently determine where to address this concern. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder. While the reviewer suggests that this choice is not well-motivated, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this particular choice is problematic or how it could be improved. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment questions the motivation behind using randomly sampled CIFAR images as backgrounds to make the task harder, suggesting that while the choice might be interesting, it is not well-motivated. This feedback highlights a potential gap in the paper's justification for the chosen experimental setup. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the motivation for their choice. While it identifies a concern, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve the motivation, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the readability of the text within a figure and its labels, suggesting that the text should be of the same size as the manuscript text. This feedback is explicit, as it directly instructs the authors to address the issue by adjusting the size of the text. It is also concrete, as it provides a clear and specific action to take. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue with the readability of the text within a figure and its labels, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the size of the text should be roughly the same as the manuscript text. This provides clear guidance on how to improve the figure and labels. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text inside the figure and its labels is too small to read without zooming, suggesting that the text should be roughly the same size as the manuscript text. This claim is somewhat verifiable as it provides a specific observation about the readability of the text, but it lacks detailed reasoning or examples to fully support the suggestion. The authors would need to infer the need for improvement based on the comment, which could be more effective with additional justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the readability of the text within a figure and its labels, noting that the text is too small to read without zooming. It suggests that the text should be roughly the same size as the manuscript text. This feedback is clear and actionable, providing the authors with a direct and specific direction to improve the presentation of their figures. By addressing this issue, the authors can enhance the clarity and accessibility of their work, making it easier for readers to understand the content. Therefore, the comment is highly helpful, as it offers a clear and constructive suggestion for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the motivation behind the paper is not clear and suggests that the introduction should be revised to make the paper easier to follow. While the comment identifies a potential issue with the clarity of the motivation, it does not provide specific guidance on how to revise the introduction or what aspects of the motivation need clarification. The action is implicit, as the authors would need to infer that they should revise the introduction to improve clarity. However, the comment lacks concrete details on what aspects of the motivation are unclear, making it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the motivation behind the paper is not clear and recommends revising the introduction to make the paper easier to follow. However, it does not specify which part of the introduction or the paper is unclear, leaving the authors to infer that the issue lies in the introduction. This lack of specific grounding makes it difficult for the authors to pinpoint the exact areas that need revision. Additionally, the comment does not provide specific examples or suggestions for how to improve the clarity of the motivation, making it under-specific. Therefore, this comment is weakly grounded and under-specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation is not clear and suggests that the introduction should be revised to make the paper easier to follow. However, the comment lacks specific details or examples to support this claim. It does not provide any evidence or reasoning to justify why the motivation is unclear or how the introduction could be revised to improve clarity. Without such details, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the motivation behind the paper, suggesting that the introduction should be revised to make the paper easier to follow. While the comment highlights a critical area for improvement, it lacks specific guidance or suggestions on how to revise the introduction or what aspects of the motivation need clarification. This feedback is somewhat helpful as it points out a crucial weakness, but it does not provide actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the use of multiple local prompts, suggesting that while it is intuitive, the features and their positions vary across different categories. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The comment implies that the authors should consider the variability in features and positions, but it lacks concrete instructions on how to implement this consideration. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the issue of using multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the variability in features and positions, but the lack of grounding makes it challenging for the authors to understand where to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that while it is intuitive that including multiple local prompts helps, the features and their positions vary across different categories. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of multiple local prompts, noting that while it is intuitive, the features and their positions vary across different categories. This observation is insightful and highlights a potential area for improvement in the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve the consistency of feature representation. While it points out a valid concern, it does not provide actionable advice or detailed feedback, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it offers a clear observation but lacks depth and specificity in addressing the issue.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might validate the alignment or what specific steps they should follow to ensure it is sufficiently validated. Without concrete suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a concern regarding the alignment of relabeled reward data with human annotator judgments, suggesting that this alignment is insufficiently validated. However, it does not specify which part of the paper this issue is discussed or addressed. The authors cannot confidently determine which section or aspect of the paper is being referred to, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to validate the alignment or what steps should be taken to address this issue. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the alignment of relabeled reward data with human annotator judgments remains insufficiently validated. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the alignment of relabeled reward data with human annotator judgments, noting that it remains insufficiently validated. This feedback is clear and actionable, as it highlights a potential weakness in the methodology or experimental design that could impact the reliability of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue, such as proposing specific validation methods or additional experiments. Overall, the comment is somewhat helpful as it points out a critical area for improvement, but it lacks depth and actionable guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper, noting that the experiments are conducted on a limited number of molecules and only include in-distribution testing. The reviewer suggests that the value of the method might be limited if it requires training for each molecule individually. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the draft. The action is implicit and vague, as it does not specify how the authors can expand their experiments or address the concern about the method's value. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of limited experiments on a small number of molecules and the lack of in-distribution testing. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the limitation in the experiments and suggests that the value of the method might be limited if it requires training for each molecule individually. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper only conducts experiments on a limited number of molecules and only provides in-distribution testing. This is a factual observation about the scope of the experiments. However, the comment does not provide any reasoning, examples, or references to support why this limitation is significant or how it affects the value of the method. Without additional context or justification, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, specifically that the experiments are conducted on a limited number of molecules and only include in-distribution testing. This observation is clear and highlights a potential constraint on the value of the method. However, the comment does not provide any suggestions or guidance on how the authors might address this limitation or improve their experiments. While it points out an important issue, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the symbols used in the paper are complicated and time-consuming to understand. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might simplify the symbols or make them more accessible to readers. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the symbols used in the paper are complicated and time-consuming to understand. However, it does not specify which part of the paper contains these symbols or provide any context for why this is an issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what makes the symbols complicated or how they could be simplified. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the symbols used in the paper are complicated and time-consuming to understand. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors cannot verify the validity of this claim or understand how it might impact their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the complexity of symbols used in the paper, which could hinder understanding. However, it lacks specificity and actionable suggestions for improvement. The authors are left without guidance on how to simplify the symbols or make them more accessible to readers. While the comment points out a potential area for improvement, it does not provide detailed feedback or constructive advice, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the extent to which the results are due to the ability to capture periodicity rather than compositionality more generally. It suggests that the comparison model, which cannot capture periodic relationships, is used in most experiments, except for Experiment 1b, where the relationships involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. While the comment poses a question that could lead to further exploration, it does not provide explicit guidance on how to address this question or what actions the authors should take. The action is implicit and vague, as the authors are left to infer how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It specifically mentions that the comparison model cannot capture periodic relationships and that most experiments, except for Experiment 1b, involve periodicity. The reviewer questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the role of periodicity in the results, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It questions whether adding periodicity to the spectral kernel would allow it to capture all the results at a similar level to the explicitly compositional model. However, the comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations to substantiate the question, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the extent to which the results are due to capturing periodicity rather than compositionality more generally. It highlights a specific aspect of the comparison model and questions whether adding periodicity to the spectral kernel could improve its performance. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this question or what experiments could be conducted to explore this issue further. While it identifies an area for improvement, the feedback is somewhat limited in its scope and does not offer actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it provides a starting point for discussion but lacks the depth needed for comprehensive improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concern about the paper's writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not provide specific suggestions or actions for the authors to take to improve the writing or presentation. The feedback is vague and lacks concrete guidance, leaving the authors uncertain about how to address the issues. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concern about the paper\\'s writing quality, suggesting it is rushed and difficult to read. It also points out issues with presentation and formatting, particularly in figures and tables. However, the comment does not specify which part of the paper is being addressed, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing or presentation need improvement further limits the comment\\'s effectiveness. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective opinion about the paper\\'s writing quality, suggesting it is rushed and difficult to read. It also mentions issues with presentation and formatting, particularly in figures and tables. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper\\'s writing quality, suggesting it is rushed and difficult to read. It also points out problems with presentation and formatting, particularly in figures and tables. However, the comment lacks specific suggestions or actionable advice on how the authors might improve the writing or presentation. While it highlights areas for improvement, it does not provide detailed guidance or examples, making it somewhat helpful. The feedback is somewhat helpful as it directs the authors to areas that need attention, but it could be more comprehensive with actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. While it implies that the introduction needs to be expanded, it does not provide specific guidance on what aspects of orthogonality should be elaborated upon or how the introduction should be revised. The action is implicit and vague, as the authors are left to infer the exact nature of the improvement needed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not specify which part of the introduction is lacking detail or what specific aspects of orthogonality need to be elaborated upon. The authors cannot confidently determine which section of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide guidance on how to make the introduction more detailed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the introduction to orthogonality in Part 2 could be more detailed. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left to infer the need for more detail, making the claim somewhat verifiable. The comment lacks depth and specificity, as it does not explain why the introduction needs to be more detailed or what aspects of orthogonality are missing. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the introduction to orthogonality in Part 2 could be more detailed. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the depth and clarity of the introduction. However, it does not offer additional guidance or examples on how to make the introduction more detailed, which could limit its helpfulness. Overall, the comment is somewhat helpful, as it directs the authors to a specific area for improvement but lacks depth in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that similar analyses have been conducted in prior works, noting that the results are not particularly surprising. It provides specific examples, such as the study of CIFAR-10 models on distribution shifts in RobustBench and the evaluation of adversarially trained models in [A, B]. However, the comment does not offer explicit or implicit suggestions on how the authors might address these points or improve their work. The authors are left without guidance on how to incorporate or discuss these findings, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific prior works and examples, such as RobustBench and [A, B], allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should consider by noting that similar analyses have been conducted on smaller scales and that the results are not particularly surprising. This provides clear guidance on how the authors might improve their work by referencing these prior studies. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar analyses have been conducted in prior works, specifically mentioning RobustBench and references [A, B]. It provides examples, such as the study of CIFAR-10 models on distribution shifts and the evaluation of adversarially trained models. However, the comment lacks detailed reasoning or specific examples to fully support the claim, making it somewhat verifiable. The authors would benefit from a more comprehensive explanation of how these prior works relate to their own research, enhancing the verifiability of the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies that similar analyses have been conducted in prior works, specifically mentioning RobustBench and references [A, B]. It highlights that the results are not particularly surprising, which suggests that the authors should consider expanding their work to include a more comprehensive discussion of these prior studies. However, the comment lacks specific guidance on how the authors might address these points or incorporate them into their draft. While it provides a starting point for improvement, the feedback could be more actionable by offering detailed suggestions or examples of how to integrate the findings from prior works. Therefore, the comment is somewhat helpful, as it identifies an area for enhancement but does not fully guide the authors in making the necessary changes.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might mitigate this computational overhead or what steps they could consider to balance model size and accuracy. Without specific suggestions or actions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the potential computational overhead introduced by the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor). However, it does not specify which part of the paper this issue is discussed or how it affects the overall methodology or results. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to mitigate this computational overhead or what steps the authors should take to balance model size and accuracy. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor) may introduce significant computational overhead. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without detailed reasoning or supporting evidence, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the hyper-parameters $b$ (bit-width) and $\\alpha$ (stability factor), suggesting that they may introduce significant computational overhead. This observation is important as it highlights a potential limitation in the pursuit of determining the optimal trade-off between model size and accuracy. However, the comment does not provide any specific suggestions or guidance on how the authors might address this issue or mitigate the computational overhead. Without actionable advice or detailed recommendations, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is somewhat helpful, as it points out a potential area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes might be necessary. The comment lacks concrete guidance on how to revise the study or clarify its nature. As a result, the authors are left without a clear understanding of what action to take to address the concern. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, it does not specify which part of the paper this comment is addressing, making it difficult for the authors to pinpoint the exact section or aspect being discussed. The comment is vague and lacks specificity, as it does not provide any details on what needs to be addressed or how the study should be revised. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the study is not an ablation study. As a result, the claim is not well-supported, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the classification of the study as an \"ablation\" study, arguing that it does not involve removing a component of the method. This feedback is somewhat helpful as it identifies a potential issue with the study's categorization, which could help the authors clarify the nature of their work. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern. Without actionable advice or examples, the authors may struggle to understand how to revise their study or clarify its classification. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). This provides a clear and explicit action for the authors to take, as they can now understand exactly what additional evaluations are needed to strengthen the comparison. The comment is specific in its suggestion, detailing which methods should be included in the evaluation. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not specify which part of the paper this evaluation is intended for, making it weakly grounded. It is specific in suggesting the inclusion of additional evaluations, but without clear references to sections or figures, the authors may find it challenging to identify the exact part of the paper that needs improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the evaluation. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluation would be stronger if the base DA methods were similarly evaluated with and without the architectural competitors such as AutoDial and AdaBN, which are direct competitors to TransferNorm (TN). This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their evaluation by including additional comparisons. By evaluating the base DA methods with and without these architectural competitors, the authors can provide a more comprehensive and robust assessment of the proposed TransferNorm architecture. This feedback is mostly helpful as it offers a clear and constructive suggestion for improvement, though it could be further expanded to include more detailed reasoning or examples. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve their evaluation or select more appropriate baselines. As a result, the authors are left without a clear understanding of what steps to follow to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the evaluation\" and \"the baselines used in the paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly states that the evaluation is weak and that the baselines are not designed for fair classification, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, the comment lacks specific details or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the evaluation section of the paper, specifically noting that the baselines used are not designed for fair classification. This feedback is clear and actionable, as it highlights a critical weakness in the evaluation methodology. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as suggesting alternative baselines or methods for ensuring fair classification. While the comment is somewhat helpful in pointing out a problem, it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. It suggests that the authors might be trying to present a more general setting than what is actually presented, which could make the exposition confusing. However, the comment does not provide explicit guidance on how to clarify the setting or what specific aspects need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer how to improve the clarity of the setting. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the first three paragraphs of section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of clarity in spelling out the setting, which needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this is a necessary improvement. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the setting needs to be spelled out more clearly in the first three paragraphs of section 2. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and precision of their writing. However, the comment could be more helpful if it offered specific suggestions or examples of how to clarify the setting. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method works on these newer approaches or what its advantages are compared to them. While the comment implies that the authors should consider using more recent baselines to make the experiments more convincing, it does not provide explicit guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors are left to infer that they should compare their method with more advanced 3D CNNs. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these 3D CNNs or what its advantages are compared to them. However, the comment does not specify which part of the paper discusses the choice of baselines or the experimental setup, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the issue of using older baselines, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of baselines used in the experiments, specifically mentioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these newer approaches or what its advantages are compared to them. While the comment raises a valid concern about the choice of baselines, it lacks specific examples or references to support the claim that the proposed method might not be effective on more advanced 3D CNNs. The authors are left to infer the need for comparison, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the choice of baselines used in the experiments, specifically questioning the use of older methods like R3D and C3D. It suggests that many papers have proposed more advanced 3D CNNs, such as X3D and SlowFast, and asks whether the proposed method also works on these newer approaches or what its advantages are compared to them. This feedback is somewhat helpful as it points out a potential gap in the experimental evaluation and encourages the authors to consider more recent baselines to strengthen their work. However, the comment could be more helpful if it provided specific guidance on how to compare the proposed method with these advanced 3D CNNs or suggested additional experiments to address this concern. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the implementation details of the attention module's integration with the ResNet-20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed (e.g., after each block or stage). While the comment explicitly asks for clarification, it does not provide any guidance on how the authors should address these questions or what specific changes might be needed. The action is implicit and vague, as the authors are left to infer that they need to clarify these details in their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the implementation details of the attention module's integration with the ResNet-20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not specify which part of the paper these details are discussed or where the authors can find this information. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the content it addresses, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the implementation details of the attention module's integration with the ResNet-20 architecture, specifically asking for clarification on how the attention module is attached, how many modules are used, and where they are placed. However, the comment does not provide any evidence or reasoning to support why these details are important or how they impact the paper. It lacks specific examples or references, making it difficult for the authors to understand the basis of the concern. As a result, the claim is not verifiable, and the comment does not provide actionable guidance for improvement. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises specific questions about the implementation details of the attention module's integration with the ResNet-20 architecture. It asks for clarification on how the attention module is attached, how many modules are used, and where they are placed, such as after each block or stage. This feedback is somewhat helpful as it points out a lack of clarity in the paper's description of the attention module's integration, which could hinder understanding and reproducibility. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address these questions or improve the clarity of their explanation. Overall, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions: first, it questions the performance of the proposed method at low bitrate compared to baselines, and second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The first part of the comment is explicit, as it directly asks for clarification on the precise bitrate range used for BD-rate comparison. However, the second part, while suggesting a related work, does not provide explicit guidance on how to incorporate or discuss this work. The action is somewhat vague, as the authors are left to infer how to apply the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two specific questions about the performance of the proposed method at different bitrates and suggests a related work for discussion. However, it does not explicitly mention which part of the paper these questions or suggestions relate to, making it weakly grounded. The questions are specific, as they ask for clarification on the bitrate range and suggest a comparison with a specific related work. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: first, it questions the performance of the proposed method at low bitrate compared to baselines, and second, it suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression. The first part of the comment is a question that requires the authors to clarify the precise bitrate range used for BD-rate comparison, which is a logical and verifiable request. The second part suggests a related work for discussion, which is also verifiable as it points to a specific area for further exploration. However, the comment lacks detailed reasoning or examples to fully support the suggestions, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific feedback on the performance of the proposed method at different bitrates, noting that it appears stronger at high bitrate but close to baselines at low bitrate. This observation is valuable for the authors to understand the limitations of their method. Additionally, the comment suggests discussing or comparing the proposed method with a related work on content adaptive algorithms in learned video compression, which could provide further context and insights. However, the comment could be more helpful if it offered specific guidance on how to incorporate or discuss this related work. Overall, the feedback is somewhat helpful as it identifies an area for improvement and suggests a relevant comparison, but it lacks detailed actionable advice.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This provides a clear and explicit action for the authors to take, as they need to clarify the distinction between these two concepts in their paper. The comment is specific in its suggestion and provides a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, it does not specify which part of the paper this distinction is relevant to, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to distinguish the all-or-nothing or cutoff phenomenon from usual statistical bounds, which are familiar to the machine learning and NeurIPS community. This feedback is specific and directly addresses a potential area of confusion or lack of clarity in the paper. By highlighting this distinction, the comment helps the authors improve the clarity and precision of their work, making it mostly helpful. However, it could be more helpful if it provided additional context or examples to further guide the authors in making this distinction.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the theoretical results of the paper, specifically that the utility guarantees are only provided for Gaussian features and noise. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the comment identifies a specific area for improvement and provides a clear direction for the authors to address it, it does not explicitly instruct them on how to compare the rates or what specific literature to consult. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"main (and only) theoretical result\" in the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it details the limitation of the theoretical result, which is the requirement for Gaussian features and noise, and suggests a comparison to existing rates in the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the main theoretical result in the paper provides utility guarantees only for Gaussian features and noise, which is a strong requirement compared to previous algorithms that do not need this assumption. It also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature. While the claim about the limitation of the theoretical result is logical and based on the description provided, the suggestion to compare rates lacks specific examples or references, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific limitation in the theoretical results of the paper, noting that the utility guarantees are only provided for Gaussian features and noise. This is a significant constraint, as previous algorithms do not require this assumption. The comment also suggests that the authors should compare the rates achieved by their procedure to existing rates in the literature, which is a valuable piece of feedback for improving the paper. However, the comment could be more helpful if it provided specific examples of existing rates or suggested particular literature to compare against. Overall, the feedback is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to follow, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that it would have been beneficial to compare the proposed extension with the original approach from Schiratti et al. (2015), even if only on the simulated data. However, the comment does not provide explicit guidance on how to implement this comparison or what specific aspects should be compared. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant to this comparison. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of the comparison, the lack of grounding makes it difficult for the authors to understand where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. However, the comment does not provide any specific reasoning, examples, or references to support why this comparison would be beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks sufficient evidence to be considered verifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the proposed extension with the original approach from Schiratti et al. (2015), even if only on simulated data. This feedback is somewhat helpful as it identifies a potential area for comparison that could enhance the paper's contribution. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects should be considered. The authors would need to infer the necessary steps to take, which limits the feedback's impact. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare their proposed method with more baselines, as there are several works that focus on the same questions. It provides specific examples of these works, such as [1, 2, 3], which implies that the authors should include these in their experimental comparisons to better demonstrate the effectiveness of their method. The comment is explicit in suggesting the addition of more baselines and provides concrete examples, making it clear how the authors should apply the feedback. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions, such as [1, 2, 3]. However, it does not specify which part of the paper these comparisons should be made in, such as the experimental section or a specific section discussing related work. While the comment is specific about the need for more comparisons, it lacks grounding as it does not clearly indicate which part of the paper is being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should compare their proposed method with more baselines, specifically mentioning several works that focus on the same questions. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without detailed reasoning or examples, the claim is unverifiable, as it lacks the necessary evidence to be fully understood or addressed. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experimental section, noting that the authors only compared their proposed method with two baselines. It suggests that there are other works focusing on similar questions and recommends adding more comparisons to better demonstrate the effectiveness of the proposed method. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental evaluation. However, the comment could be more helpful if it suggested specific additional baselines or provided guidance on how to conduct these comparisons effectively. Overall, the comment is mostly helpful, as it offers valuable insights but could be more comprehensive in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the analysis on BRP-NAS is somewhat barebones, as it only compares against 3 basic alternatives and ignores other NAS approaches like super-nets or one-shot methods. While the comment identifies a gap in the analysis, it does not provide explicit guidance on what specific comparisons or analyses should be included to address this issue. The action is implicit, as the authors would need to infer that they should expand the analysis to include more comprehensive comparisons. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"BRP-NAS\" and \"NAS (e.g. super-net/one-shot approaches, etc...)\", allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the analysis of BRP-NAS, namely the comparison against other NAS approaches like super-nets and one-shot methods. This provides the authors with a clear understanding of what needs to be addressed to improve the analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis on BRP-NAS is \"somewhat barebones\" because it only compares against 3 basic alternatives and ignores other NAS approaches like super-nets or one-shot methods. While the comment provides a general idea of what is missing, it lacks specific examples or references to support the claim. This makes the claim somewhat verifiable, as the authors would need to infer the missing comparisons to fully understand the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the analysis of BRP-NAS, noting that it only compares against 3 basic alternatives and overlooks other NAS approaches like super-nets or one-shot methods. This feedback is clear and actionable, as it provides the authors with a specific direction to enhance the comprehensiveness of their analysis. By highlighting the omission of relevant comparisons, the comment guides the authors to include a broader range of NAS approaches, which would strengthen the paper. However, the comment could be more helpful if it suggested specific comparisons or analyses that should be included. Overall, the feedback is mostly helpful, as it offers a clear direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset. It suggests that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide explicit guidance on what specific aspects of the methodology should be included or how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more details on the filtering process, but the lack of concrete instructions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"details around the filtering process used to create the Arabic climate change QA dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is lacking, namely \"more information on the translation and filtering methodology,\" which is crucial for assessing the dataset quality. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a lack of detail regarding the filtering process used to create the Arabic climate change QA dataset, suggesting that more information on the translation and filtering methodology is needed to assess the dataset quality. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the dataset quality is lacking. Without additional context or evidence, the authors may find it challenging to understand the specific issues or how to address them. Therefore, the comment is considered borderline verifiable, as it lacks sufficient justification or supporting details to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area where the authors could improve their paper by providing more details about the filtering process used to create the Arabic climate change QA dataset. It highlights the need for more information on the translation and filtering methodology to assess the dataset quality. This feedback is clear and actionable, as it directs the authors to a specific aspect of their work that requires further elaboration. However, the comment could be more helpful if it suggested specific ways to improve the dataset or provided examples of how to enhance the methodology. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not provide explicit instructions or concrete guidance on how to implement these suggestions. The authors are left to infer that they need to add more diverse attacks and analyze the impact of thresholds, but without specific steps or examples, the action remains vague. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, it does not specify which part of the paper this feedback pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to understand where to address the feedback. While the comment is specific in its suggestions, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment results could be enriched by including attacks with different strengths and by exploring how different thresholds influence detection performance. However, the comment lacks specific details or examples to support these claims, making it difficult for the authors to understand the basis of the suggestion. Without additional context or references, the claim remains somewhat verifiable, as it is based on logical reasoning but lacks concrete evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the experiment results by suggesting that they could be enriched with attacks of varying strengths and by exploring the influence of different thresholds on detection performance. This feedback is somewhat helpful as it points out specific aspects that could enhance the depth and comprehensiveness of the experimental analysis. However, the comment lacks detailed guidance or suggestions on how to implement these enhancements, which limits its impact on the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the impact of using different image sizes and variations of ResNets on the performance difference. While it suggests that the authors should provide more context or analysis regarding this aspect, the comment does not explicitly instruct the authors on how to address this issue or what specific actions they should take. The action is implicit and vague, as it leaves the authors to infer the need for additional information or analysis. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L170), allowing the authors to accurately identify the part being addressed. It also specifies what the authors should know, namely the impact of using different image sizes and variations of ResNets on the performance difference. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of using different image sizes and variations of ResNets on the performance difference. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of using different image sizes and variations of ResNets on the performance difference, specifically referencing line 170. While it prompts the authors to consider this aspect, it does not provide any guidance or suggestions on how to address this issue or what specific analysis might be needed. The comment is somewhat helpful as it identifies a potential area for further exploration, but it lacks depth and actionable advice, making it only slightly beneficial for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While the comment implies that the authors should provide a detailed description of the algorithm, it does not explicitly instruct them to do so or specify how to present it. The action is somewhat vague, as the authors are left to infer that they need to elaborate on the algorithm. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not specify which part of the paper this comment refers to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion to provide a detailed description of the algorithm, the absence of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. However, it does not provide any specific reasoning, examples, or references to support why this is necessary or beneficial. The comment lacks depth and does not offer a clear justification for the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the algorithm should be presented and described in detail to aid in understanding the proposed method. While this feedback is somewhat helpful as it points out an area for improvement, it lacks depth and specificity. The comment does not provide detailed guidance on how to present the algorithm or what aspects should be emphasized. Without specific suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore existing work that offers a way to compute the contribution of FFNs, even if a linear decomposition is not possible. It also recommends adding a line or two to indicate that there is no solution for this, which would improve the readability and provide a clearer overall picture for the reader. The comment is explicit in suggesting what action to take, and it provides concrete details on how to implement this action by recommending the inclusion of additional information. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the omission of FFNs due to the inability to obtain a linear decomposition, referencing a point mentioned in the paper. It suggests exploring existing work that offers an approximation or alternative method to compute the contribution of FFNs. However, the comment does not specify which part of the paper discusses the linear decomposition or where the suggestion to explore existing work should be placed. This makes it weakly grounded, as the authors may need to infer the specific sections to address. The comment is specific in suggesting what needs to be done, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should explore existing work that offers a way to compute the contribution of FFNs, even if a linear decomposition is not possible. It recommends adding a line or two to indicate that there is no solution for this, which would improve the readability and provide a clearer overall picture for the reader. The comment is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors would need to infer the relevance of the suggestion and potentially seek additional evidence to fully understand the reasoning behind it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by pointing out that the omission of FFNs due to the inability to obtain a linear decomposition could be addressed by exploring existing work that offers an approximation or alternative method to compute their contribution. The comment suggests that if no such work exists, the authors could add a note indicating that it is an open problem. This feedback is mostly helpful as it provides a clear direction for improvement, suggesting a specific area for further exploration or clarification. However, it could be more helpful if it included examples of existing work or a more detailed explanation of why this exploration is necessary. Overall, the comment offers actionable guidance that empowers the authors to enhance their draft, making it a mostly helpful feedback.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: first, it asks how the number of images impacts the model performance, and second, it suggests explaining the BYOL model in the abstract. While the questions are explicit and direct, they do not provide concrete guidance on how to address these issues. The authors are left to infer that they need to conduct further analysis or provide more context on the impact of image numbers and the BYOL model. The lack of specific instructions or suggestions for improvement makes the comment somewhat actionable. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two questions about the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. However, it does not specify which part of the paper these questions relate to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in that it asks for clarification and suggests an improvement, but the lack of grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: how the number of images impacts model performance and whether more training images make the performance worse or better. It also suggests explaining the BYOL model in the abstract. While the questions are logical and relevant to the paper, the comment lacks specific examples or references to support the claims. The authors are left to infer the basis for these questions, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two important questions regarding the impact of the number of images on model performance and suggests explaining the BYOL model in the abstract. These questions are relevant and could provide valuable insights for the authors to improve their understanding and presentation of the work. However, the comment lacks specific guidance or suggestions on how to address these issues, such as providing additional analysis or examples. While it identifies areas for improvement, it does not offer detailed feedback that would fully enhance the authors' draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the rationale behind the method's effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these losses are \"bound to help.\" However, the comment does not explicitly instruct the authors to include these explanations or provide specific guidance on how to do so. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component. However, it does not specify which part of the paper discusses this component, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its request for stronger arguments or intuitions, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the method's effectiveness, particularly regarding the L_pixel component, suggesting that the authors should provide stronger arguments or intuitions to explain why these losses are \"bound to help.\" However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the method works effectively. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to fully understand or address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by questioning the rationale behind the method's effectiveness, particularly concerning the L_pixel component. It suggests that the authors should provide stronger arguments or intuitions to explain why these losses are \"bound to help.\" This feedback is somewhat helpful as it highlights an area where the authors could improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided specific examples or guidance on how to strengthen the arguments or intuitions. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific changes could be made to the dataset. While it identifies a potential problem, the lack of actionable advice makes it difficult for the authors to respond effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. However, the comment does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or figure being addressed. While it provides some specificity by mentioning the concern about the dataset size, the lack of explicit grounding makes it challenging for the authors to understand the exact context of the comment. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. The comment provides a logical reasoning by comparing the dataset size to the typical training data of LLMs, making the claim somewhat verifiable. However, it lacks specific examples or references to support the claim fully, which could make it partially verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the sufficiency of the training data, specifically questioning whether 44k dialogues can capture a wide range of user traits and personalities across different content topics. It also suggests that LLMs are typically trained on trillions of tokens, implying that the dataset needs to be massive to cover varied domains. This feedback highlights a potential limitation in the dataset's ability to represent diverse user characteristics and topics, which could impact the model's performance and generalizability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative dataset sizes or methods for data augmentation. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. However, it does not provide any explicit or implicit suggestions on how to address this concern or improve the evaluation. The comment lacks concrete guidance on what alternative metrics or methods could be considered, making it difficult for the authors to take action to address the issue. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. However, it does not specify which part of the paper this concern pertains to, such as a particular section or table. This lack of grounding makes it challenging for the authors to identify the exact area that needs attention. While the comment is specific in its critique of the metric's limitations, the absence of explicit grounding reduces its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. However, the comment lacks specific examples or references to support the claim that binary classification is inadequate for this purpose. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of binary classification as a baseline metric, questioning its ability to assess models' understanding of fine-grained errors like technique errors. This feedback is somewhat helpful as it identifies a potential limitation in the evaluation methodology. However, the comment could be more helpful if it provided suggestions or guidance on alternative metrics or methods that could better capture the models' understanding of fine-grained errors. Without specific recommendations or examples, the authors may find it challenging to address the issue effectively. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It also highlights the difficulty in understanding under what conditions SynTextBench should be used over other metrics, such as MMLU or Big Bench for language generation. While the comment provides a clear action\u2014comparing the metric with others\u2014it does not offer specific guidance on how to conduct this comparison or what aspects to focus on. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"a large amount of work on LLM evaluation [2]\" and suggests comparing the SynTextBench metric with other metrics proposed in the literature. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it requests a comparison of SynTextBench with other metrics and highlights the difficulty in understanding when to use SynTextBench over other metrics like MMLU or Big Bench for language generation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not adequately compare the SynTextBench metric with other metrics proposed in the literature on LLM evaluation. It suggests that the authors should compare SynTextBench with metrics like MMLU and Big Bench to understand when to use it. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The reasoning is somewhat vague, as it does not provide detailed guidance on how to conduct the comparison or what aspects to focus on. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by pointing out that there has been significant work on LLM evaluation, and it would be beneficial to compare the SynTextBench metric with other metrics proposed in the literature. The comment suggests that the authors should clarify under what conditions SynTextBench should be used over other metrics, such as MMLU or Big Bench for language generation. This feedback is mostly helpful as it provides a clear direction for the authors to improve their draft by expanding the discussion on the comparison of evaluation metrics. However, it could be more helpful if it included specific examples or guidance on how to conduct this comparison. Overall, the comment is mostly helpful, aligning with a score of 4.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not provide explicit guidance on how the authors should address this concern or what changes might be necessary. The action is implicit, as the authors need to infer that they should consider the impact of including all reports. While the comment is somewhat specific in questioning the rationale, it lacks concrete suggestions on how to implement this change or what specific aspects of the reports might be easier to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to identify the exact section being addressed. While the comment is specific in questioning the rationale, the absence of explicit grounding makes it challenging for the authors to understand the context and relevance of the question. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the rationale for considering only ECG segments with one label assigned, suggesting that including all reports might be easier. This feedback is somewhat helpful as it highlights a potential area for improvement in the paper. However, the comment lacks depth and specificity, as it does not provide detailed reasoning or suggestions for how the authors might address this concern. Without additional guidance or examples, the authors may struggle to fully understand and incorporate the feedback into their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the paper regarding the discussion of scalability bounds, specifically mentioning the absence of a thorough exploration of the upper limits of FedDES's scalability, as well as the lack of discussion on memory requirements or computational complexity. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address these issues or what specific aspects of scalability they should focus on. The action is implicit, as the authors would need to infer that they should expand the discussion to include these elements. However, the lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the paper, namely the limited discussion of scalability bounds, memory requirements, and computational complexity. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the areas that need attention, such as the absence of a thorough exploration of scalability limits and the lack of discussion on memory requirements or computational complexity. This provides clear guidance for the authors to address these issues. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not thoroughly explore the upper limits of FedDES's scalability, specifically mentioning the absence of a discussion on memory requirements or computational complexity. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of a thorough discussion of scalability bounds, memory requirements, and computational complexity. This feedback is valuable as it highlights an area where the authors could enhance the depth and comprehensiveness of their work. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues, such as suggesting additional experiments or analyses that could be included. Without such guidance, the authors may find it challenging to effectively incorporate the feedback into their draft. Therefore, the comment is somewhat helpful, as it identifies a critical area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the interpretation of the statement \"NodeSort differentially sorts nodes depending on the base node.\" It asks for clarification on whether the base node affects the ordering, key nodes for attention, and model performance. While the comment prompts the authors to clarify their understanding, it does not provide explicit instructions or suggestions on how to address this clarification. The action is implicit, as the authors need to infer that they should clarify the statement. However, the comment lacks concrete guidance on what specific aspects to focus on or how to provide the clarification. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" However, it does not specify which part of the paper this statement is located in, making it difficult for the authors to identify the exact section being addressed. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the interpretation of a specific statement in the paper, \"NodeSort differentially sorts nodes depending on the base node.\" It asks for clarification on whether the base node affects the ordering, key nodes for attention, and model performance. However, the comment does not provide any evidence, reasoning, or references to support the claim that this interpretation is incorrect or requires clarification. Without additional context or justification, the authors are left to make their own interpretation, making the comment unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the interpretation of a specific statement in the paper, 'NodeSort differentially sorts nodes depending on the base node.' It asks whether the base node affects the ordering, key nodes for attention, and model performance. This question prompts the authors to clarify their understanding of the statement, which could help them better understand the implications of the method. However, the comment does not provide any suggestions or guidance on how to address this clarification or what specific aspects of the statement need further explanation. While it identifies an area for improvement, it lacks depth and actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the direction of the arrow in Figure 2 and its purpose in influencing n^(i). While it prompts the authors to consider the rationale behind the arrow's direction, it does not provide explicit guidance on how to address this question or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the purpose of the arrow and its impact on n^(i). However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the direction of the arrow in Figure 2, specifically asking why it goes from a Gaussian space to the latent space rather than the other way around. It also questions the purpose of this arrow in influencing n^(i). However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the question is specific about the content of the figure, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the direction of an arrow in Figure 2 and its purpose in influencing n^(i). While it prompts the authors to consider the rationale behind the arrow's direction, it does not provide any specific evidence, reasoning, or references to support the claim that the arrow should be directed from the latent space to n^(i). The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a specific question about the direction of an arrow in Figure 2 and its purpose in influencing n^(i). It challenges the authors to consider the rationale behind the arrow's direction, which could be crucial for understanding the model's behavior. However, the comment does not provide any suggestions or guidance on how to address this question or what changes might be necessary. While it identifies a potential area for clarification, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should consider the rationale behind the arrow's direction and its impact on n^(i), but without further guidance, the feedback is limited in its usefulness. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the use of abbreviations in Table 5, noting that they are not defined. While the comment identifies a problem, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to define the abbreviations, but the comment lacks concrete instructions on which abbreviations need to be defined and how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the abbreviations in Table 5 are not defined, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many abbreviations lack definition and cause confusion, specifically mentioning that \u201cAR\u201d in Table 5 stands for domain adaptation tasks and algorithms. While the comment identifies a potential issue with clarity and consistency in the use of abbreviations, it does not provide specific examples or references to support the claim. The authors are left to infer that the lack of definition for abbreviations could hinder understanding, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of abbreviations in Table 5, noting that they are not defined. This is a clear and actionable piece of feedback that could help the authors improve the clarity and readability of their paper. By defining the abbreviations, the authors can ensure that their work is easily understood by readers. However, the comment could be more helpful if it provided guidance on which abbreviations need to be defined or suggested specific definitions. Overall, the comment is somewhat helpful as it highlights a clear area for improvement, but it lacks depth and detail to fully assist the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. However, it does not provide explicit guidance or suggestions on how the authors should address this question or what aspects of the analysis might need to be reconsidered. The comment is vague and lacks concrete actions for the authors to take, making it difficult for them to understand how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the specific part of the paper being addressed. The comment is vague and lacks specificity, as it does not provide detailed guidance on what needs to be considered or addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of using advantage instead of q-value in the analysis, suggesting that there might be other technical considerations. While it prompts the authors to consider alternative approaches, it does not provide specific guidance or suggestions on what those considerations might be or how they could be addressed. The comment is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully address the issue. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the performance comparison in Table 1 due to the use of different sample weights in the training process for VINS compared to other baselines. However, it does not provide explicit or implicit actions for the authors to take to address this concern. The comment suggests that the authors should consider the impact of different sample weights on the comparison, but it does not offer specific guidance on how to adjust the comparison or what steps to take to ensure fairness. As a result, the authors are left without clear instructions on how to address the issue, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the fairness of the performance comparison in Table 1, specifically pointing out that VINS uses different sample weights in the training process compared to other baselines like DNS, AOBPR, SA, and PRIS, which all use sample weights of 1. However, the comment does not specify which part of the paper this issue is discussed or how it affects the results. The authors can infer that it relates to the experimental setup and results section, but the lack of explicit mention makes it weakly grounded. The comment is specific in identifying the issue with the sample weights, but the lack of grounding makes it difficult for the authors to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance comparison in Table 1 is unfair due to the use of different sample weights in the training process for VINS compared to other baselines. The reviewer provides a specific example, noting that VINS sets different sample weights while most compared baselines use a weight of 1. This claim is supported by the specific details provided, making it mostly verifiable. However, the comment could be strengthened by providing more context or examples to fully substantiate the claim. Overall, the comment is mostly verifiable, as it is supported by logical reasoning and specific examples, but it lacks some depth in explanation or references.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the performance comparison in Table 1, specifically noting that VINS uses different sample weights in the training process compared to other baselines. This observation is clear and highlights a potential weakness in the experimental setup. However, the comment does not provide actionable guidance or suggestions on how the authors might address this issue or ensure a fair comparison. While it points out a concern, it lacks depth and does not offer specific steps or recommendations for improvement, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time complexity of the method might be too high if the reply buffer is too large, referencing a specific paper. However, it does not provide explicit guidance on how to address this issue or what specific aspects of the method need to be improved to mitigate the high time complexity. The action is implicit and vague, as the authors are left to infer that they need to optimize the method or adjust the buffer size. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the time complexity issue related to a large reply buffer, referencing a specific paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear issue and suggests a potential solution by referencing a related work. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the time complexity will be too high if the reply buffer is too large, referencing a specific paper. While the claim is based on a logical argument about the relationship between buffer size and computational complexity, it lacks detailed reasoning or specific examples to fully substantiate the claim. The reference to the paper provides some context, but the authors may need to delve deeper into the cited work to fully understand the implications. Therefore, the comment is somewhat verifiable, as it provides a basis for further investigation but lacks complete justification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the time complexity of the method when the reply buffer is too large, referencing a specific paper. This feedback is somewhat helpful as it highlights a potential area for improvement and suggests that the authors should consider optimizing their method or adjusting the buffer size to enhance efficiency. However, the comment lacks detailed guidance on how to address this issue or what specific aspects of the method need to be improved. The authors would need to conduct further analysis to fully understand and implement the suggested changes, making the feedback somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not provide specific guidance on which baselines to include or how to implement these suggestions. The comment lacks concrete details, making it difficult for the authors to understand exactly what actions to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should display the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include additional baselines and perspectives, but without clear references to the paper, it is difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the basis of the suggestion. Without detailed reasoning or evidence, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include the performance of accelerating SGMs by involving other baselines with different perspectives, such as optimizing the discretization schedule or modifying the original SGM formulation. This feedback provides a clear direction for the authors to enhance their work by incorporating additional baselines and perspectives. However, the comment lacks specific examples or detailed guidance on which baselines to include or how to implement these suggestions, which limits its helpfulness. While it offers a valuable direction, the lack of depth makes it somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment does not specify which method should be used for comparison or how this comparison should be presented in the paper. The action is implicit, as the authors need to infer that they should include this comparison, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the proposed framework with a method designed to defend against multiple attacks, implying that the authors should include this comparison in their paper. However, it does not specify which method should be used for comparison or how this comparison should be presented. The comment lacks specific guidance on which part of the paper should address this comparison, making it weakly grounded. It is also specific in suggesting the need for a comparison with a method defending against multiple attacks, but the lack of grounding makes it difficult for the authors to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis for the suggestion. Without additional context or references, the claim is not fully verifiable, as it does not provide a clear rationale or evidence for why this comparison would be beneficial. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the authors should compare their proposed framework with a method designed to defend against multiple attacks, as this would provide a more meaningful comparison. However, the comment lacks specific guidance on which method to use for comparison or how to present this comparison in the paper. While it identifies a potential area for improvement, it does not offer detailed suggestions or examples, making it somewhat helpful. The authors would gain some insight into the need for a more comprehensive comparison, but the feedback could be more actionable with additional details. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to define the bounds for \\\\tau_i^l, which is crucial for understanding the time-warp function. This provides a clear and direct action for the authors to take, as they need to ensure that the bounds are clearly defined in their draft. The comment is specific and concrete, giving the authors a precise task to accomplish. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, indicated by the line number (l111), allowing the authors to accurately identify the section where the bounds for \\\\tau_i^l need to be defined. It is also specific because it clearly specifies what needs to be addressed, which is the definition of the bounds for \\\\tau_i^l to understand the time-warp function. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for clarification and a specific instruction regarding the definition of \\\\tau_i^l, which is important for understanding the time-warp function. It does not contain a subjective claim or opinion, but rather a suggestion for improvement. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it requests the authors to define the bounds for \\\\tau_i^l, which is crucial for understanding the time-warp function. This feedback provides a clear and direct instruction for the authors to improve their draft by ensuring that all necessary definitions are included. The comment is helpful because it directly addresses a specific aspect of the paper that needs clarification, guiding the authors to enhance the comprehensibility of their work. Therefore, the comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the efficiency of their method or what changes could be made to enhance its practical applicability. As a result, the authors are left without a clear understanding of how to proceed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. However, it does not specify which part of the paper this issue is discussed or how it relates to the overall content. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the problem with the efficiency of pairwise matching, but it lacks guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the efficiency of pairwise matching is very low, making it difficult to be used in practical application systems. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the efficiency of pairwise matching, noting that it is very low and difficult to be used in practical application systems. While this feedback highlights a potential weakness in the paper, it lacks actionable suggestions or guidance on how the authors might address this issue. The comment does not provide any specific advice on improving the efficiency of the method or enhancing its practical applicability. As a result, the authors are left without a clear understanding of how to improve their draft, making the comment somewhat helpful but lacking depth and actionable suggestions. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the allocation of Figure 1 is too naive and suggests that the authors could have edited the space of the main paper more wisely. While the comment identifies a potential issue with the figure's allocation, it does not explicitly instruct the authors on how to improve the space allocation or what specific changes should be made. The action is implicit, as the authors need to infer that they should consider alternative ways to utilize the space more effectively. However, the comment lacks concrete guidance on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the allocation of Figure 1, indicating that the authors need to consider more effective ways to utilize the space. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the allocation of Figure 1 is \"too naive\" and suggests that the authors could have edited the space of the main paper more wisely. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the allocation is indeed \"too naive\" or why the authors should consider alternative space utilization strategies. Without concrete examples or logical reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a minor weakness in the allocation of Figure 1, suggesting that it is too naive and that the authors could have edited the space of the main paper more wisely. While the comment points out a potential issue with the figure's allocation, it does not provide specific suggestions or guidance on how to address this problem. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction on how to enhance their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the first sentence of the abstract should be re-written. This is an explicit action that the authors can directly implement by revising the sentence. However, the comment does not provide any guidance on how to re-write the sentence or what aspects need to be addressed. The action is clear and explicit, but it lacks detail, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the first sentence of the abstract needs to be re-written. However, it does not specify which part of the abstract this refers to, making it difficult for the authors to pinpoint the exact section that requires revision. Additionally, the comment lacks specificity, as it does not provide any details on what aspects of the sentence need to be re-written or why it requires revision. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the first sentence of the abstract needs to be re-written. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this change is necessary or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the first sentence of the abstract needs to be re-written. While this provides a clear direction for improvement, it lacks specificity and does not offer any guidance on what aspects of the sentence should be revised or why it requires re-writing. The feedback is somewhat helpful as it identifies a specific area for improvement, but it does not provide actionable advice or detailed suggestions, leaving the authors with limited guidance on how to proceed. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. While the comment acknowledges the potential benefit of the approach, it does not provide explicit guidance on how to implement this method or what specific aspects of transferability it aims to improve. The action is implicit, as the authors would need to infer that they should consider adding such a method, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks specific guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its critique of the approach, but without clear references to the paper, the authors may find it challenging to understand which sections or aspects need attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that adding a method on top of other methods to improve transferability is a good idea but does not consider it a significant contribution. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that this approach is not a significant contribution. As a result, the claim is unverifiable due to the absence of supporting evidence or justification. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a critique of a potential method for improving transferability, suggesting that it may not be a significant contribution. While it offers a brief critique, it lacks depth and does not provide specific guidance or suggestions for improvement. The comment is somewhat helpful as it identifies a potential area for enhancement but does not offer actionable advice or detailed feedback on how to address the issue. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It also recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not provide explicit guidance on how to address these challenges or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment does not specify which part of the paper discusses the analysis of Adam under the (L0,L1)-smoothness condition, making it difficult for the authors to pinpoint the exact section or figure that needs attention. While the comment is specific about the issue of challenges and differences, the lack of grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the challenges in analyzing Adam under the (L0,L1)-smoothness condition and suggests that it might be possible to directly apply standard analysis. It recommends explaining the differences between this analysis and that of Zhang et al. However, the comment lacks specific examples or detailed reasoning to support the claim that standard analysis might be directly applicable. Without further elaboration or references, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area of concern regarding the analysis of Adam under the (L0,L1)-smoothness condition. It questions whether the challenges are significant enough to warrant detailed explanation and suggests that standard analysis might be directly applicable. This feedback is somewhat helpful as it highlights a potential gap in the paper's analysis and encourages the authors to clarify the challenges and differences with Zhang et al.'s work. However, the comment could be more helpful if it provided specific examples or guidance on how to address these challenges. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that most person re-ID methods build on pedestrian detectors and mentions the existence of end-to-end methods. However, it does not provide any explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this point or incorporate it into their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a general overview of person re-ID methods, categorizing them as building on pedestrian detectors or being end-to-end. However, it does not specify which part of the paper this observation relates to, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. Additionally, the comment lacks specificity in detailing what aspects of these methods are being discussed or how they could be improved. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that most person re-ID methods build on pedestrian detectors and mentions the existence of end-to-end methods. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the claim or how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a brief overview of person re-ID methods, categorizing them as building on pedestrian detectors or being end-to-end. While this observation is relevant to the field, the comment lacks depth and does not offer specific suggestions or guidance on how the authors might address this point in their work. It does not provide actionable feedback or insights that could help the authors improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding a first sentence to introduce Section 3.2. This is an explicit action that the authors can directly implement by adding a sentence at the beginning of the section. The comment is specific and provides clear guidance on how to improve the draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a first sentence to introduce the section, providing clear guidance on what needs to be done. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests adding a first sentence to introduce Section 3.2. This is a suggestion for improvement, but it does not contain a claim that requires verification or justification. The comment is factual and descriptive, aligning with the label \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is specific and actionable, as it suggests adding a first sentence to introduce Section 3.2. This is a clear and direct feedback that provides the authors with a concrete step to improve their draft. By adding this sentence, the authors can enhance the clarity and coherence of their paper. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. While the comment implies that the authors should clarify the term \"perfect,\" it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the term. However, the comment lacks concrete details on what specific clarification is needed, making it somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 44,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This provides clear guidance on what needs to be clarified or addressed. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the meaning of \"perfect\" in the context of the initial rationale selector and suggests that if it were perfect, no additional work would be needed. This is a subjective claim that requires the authors to interpret the term \"perfect\" in the context of the paper. However, the comment does not provide any specific examples or references to support the claim, making it difficult for the authors to understand the reasoning behind it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific point of confusion in the paper, namely the phrase \"perfect\" in the context of the initial rationale selector. It questions the meaning of \"perfect\" and suggests that if it were perfect, no additional work would be needed. This feedback is somewhat helpful as it highlights a potential ambiguity in the writing, which could be clarified to improve the paper's clarity. However, the comment could be more helpful if it provided additional context or suggestions for how to clarify the term. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zero-shot intent classifier. While it does not explicitly instruct the authors to address these questions, it implies that they should provide more clarity on these aspects. The action is implicit, as the authors need to infer that they should clarify these points in their draft. However, the questions are specific and direct, providing a clear direction for the authors to improve their paper. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 211,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the questions the authors should address regarding the use of domain ontologies and the details of the zero-shot intent classifier. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the experimental setup, specifically regarding the use of domain ontologies and the details of the zero-shot intent classifier. While it does not contain a subjective claim or opinion, it requests clarification on specific aspects of the methodology. The questions are logical and require the authors to provide more detailed information to support their claims or results. However, the comment lacks specific examples or references to substantiate the need for clarification. Therefore, it is somewhat verifiable, as it provides a basis for the authors to address but does not fully support the request for clarification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises two specific questions about the experimental setup, particularly concerning the use of domain ontologies and the details of the zero-shot intent classifier. It requests clarification on the number of questions created and the accuracy of the system. While the comment identifies areas where the authors could provide more detail, it does not offer suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it points out specific areas that need clarification, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of citations to recent works on self-play and population-play in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which suggests that the authors should include these citations to provide a more comprehensive context for their work. The comment is explicit in its suggestion to add these citations, making it highly actionable. The authors know exactly what needs to be done to improve their draft, which aligns with the criteria for a score of 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for citations to recent works on self-play and population-play in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which helps the authors identify the specific areas where citations are missing. The comment is also specific in detailing what needs to be addressed, namely the inclusion of these citations. Therefore, this comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks citations to recent works on self-play and population-play in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which serve as evidence to support the claim. The inclusion of these references would enhance the paper's context and relevance. Therefore, the claim is fully verifiable, as it is supported by explicit examples and references. The score is 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of citations to recent works on self-play and population-play in the context of exploration and coordination within MARL. It provides specific examples of relevant papers, such as https://arxiv.org/abs/1806.10071 and https://arxiv.org/abs/1812.07019, which are crucial for contextualizing the paper's contributions. By highlighting this omission, the comment offers actionable guidance for the authors to enhance the comprehensiveness and relevance of their work. This feedback is mostly helpful as it directs the authors to specific areas where they should include additional citations, but it could be more comprehensive if it suggested specific ways to integrate these references or discuss their relevance. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the abstention process, specifically asking how it differs from a decision threshold used by models. It does not provide explicit instructions or suggestions on how the authors should address this question or clarify the distinction. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to respond. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the abstention process and its relation to decision thresholds, but it does not specify which part of the paper this issue is discussed in. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. However, the comment is specific in its request for clarification regarding the difference between the abstention process and decision thresholds. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the abstention process and its relation to decision thresholds, but it does not contain a claim or suggestion that requires verification. It is a request for clarification and does not provide any evidence or reasoning to support a claim. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the abstention process and its relation to decision thresholds, which is a relevant point for clarification. However, it does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. The comment is vague and lacks actionable feedback, leaving the authors without a clear direction for improvement. Therefore, it is barely helpful, as it identifies a potential area for clarification but does not offer substantial assistance.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of meaningful baselines in the authors' comparisons, suggesting that they should include more sophisticated baselines such as a chain-of-thought prompting approach. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific baselines to consider. The action is implicit, as the authors need to infer that they should add more complex baselines to their comparisons. However, the lack of detailed guidance on how to select or implement these baselines makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the lack of meaningful baselines and suggesting a specific alternative baseline, the chain-of-thought prompting approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors limit their comparisons to simple naive baselines, despite mentioning various model criticism techniques in Section 2. The comment suggests that the authors should compare with a chain-of-thought prompting approach. However, the comment lacks specific examples or references to support the claim that the current baselines are insufficient or naive. It does not provide detailed reasoning or evidence to justify the need for more meaningful baselines. As a result, the claim is somewhat verifiable, as it identifies a potential issue but lacks sufficient evidence or justification to fully support the authors in addressing it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the lack of meaningful baselines in the comparisons. It suggests that the authors should include more sophisticated baselines, such as a chain-of-thought prompting approach, to provide a more comprehensive evaluation of their model criticism techniques. This feedback is clear and actionable, as it directs the authors to enhance the depth and rigor of their comparisons. However, the comment could be more helpful if it provided specific examples of how to implement these baselines or suggested additional baselines that could be considered. Overall, the comment is mostly helpful, as it effectively guides the authors to improve their draft by addressing a critical gap in their evaluation.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment prompts the authors to clarify their methodology, it does not provide explicit instructions or suggestions on how to address the question or improve the draft. The action is implicit, as the authors need to infer that they should clarify their methodology and discuss the generalization of their approach. However, the comment lacks concrete guidance on how to implement these suggestions, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the cardiac signal representation learning model is pretrained on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. However, the comment does not specify which part of the paper this question pertains to, such as a specific section or figure. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its questioning, the lack of grounding makes it challenging for the authors to understand the context. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the methodology of pretraining the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also asks about the generalization of this approach to scenarios where labels are not available. While the comment highlights a potential concern regarding the model's generalization, it does not provide any specific evidence, reasoning, or references to support the claim. The authors are left to infer the implications of this question, which makes the comment somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the methodology of pretraining the cardiac signal representation learning model, specifically whether it is done on the entire dataset or just the training set. It also inquires about the generalization of this approach to scenarios where labels are not available. While the comment highlights a potential concern regarding the model's generalization, it does not provide specific guidance or suggestions on how to address this issue or improve the draft. The feedback is somewhat helpful as it identifies a potential area for clarification, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific guidance or actions for the authors to take to address this concern. The comment lacks explicit instructions on how the authors should consider or address the hardware and software dependencies in their work. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which part of the paper these observations and decisions are discussed in, nor does it provide any specific examples or guidance on how to address this issue. The lack of grounding makes it difficult for the authors to understand which sections need revision, and the comment lacks specificity in detailing what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that some observations and design decisions might be hardware and software dependent. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this observation and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some observations and design decisions might be hardware and software dependent, which is a valid concern. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue. Without additional context or examples, the authors may struggle to understand the implications of this observation and how to incorporate it into their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not offer actionable advice or detailed guidance. The score is consistent with a rating of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results. It does not provide explicit instructions or suggestions on how the authors should address these concerns, such as suggesting alternative methods for validation or providing more detailed analysis. The actions are implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not specify which part of the paper \"Tab.\" refers to, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its questioning but weakly grounded due to the lack of explicit references. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any evidence, reasoning, or references to support these claims. The authors are left to interpret the questions without any guidance on how to address them or what evidence might be relevant. Therefore, the comment is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the accuracy of the ground truth and the significance of the differences observed in the ablation study results, specifically referencing \"Tab.\" However, it does not provide any suggestions or guidance on how the authors might address these concerns or improve their analysis. The feedback is vague and lacks actionable advice, leaving the authors without a clear path forward. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the lack of experimental details in the main body and the minimal explanations in the Appendix. It specifically mentions the PCA experiments in Figures 3, 7, and 8, noting that they are not explained. However, the comment does not provide explicit guidance on what specific details are missing or how the authors should address these issues. While the authors can infer that they need to include more experimental details in the main body and provide explanations for the PCA experiments, the lack of concrete suggestions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the PCA experiments in Figures 3, 7, and 8, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue of missing explanations in the Appendix, providing clear guidance on what needs to be addressed. This level of detail and specificity makes the comment fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It provides specific examples, such as the PCA experiments in Figures 3, 7, and 8, which are not explained. However, the comment does not offer any additional evidence or references to support these claims, making it difficult for the authors to verify the accuracy of the feedback. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors may need to independently verify the claims to fully understand the issues. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that many important experimental details are missing or relegated to the Appendix, and the Appendix lacks explanations or interpretations. It specifically mentions the PCA experiments in Figures 3, 7, and 8, which are not explained. This feedback is clear and actionable, as it provides the authors with specific areas to improve the completeness and clarity of their paper. By highlighting these issues, the comment guides the authors to include more detailed experimental information and explanations in the main body of the paper, enhancing its overall quality and readability. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper does not propose new evaluation metrics and only uses existing ones linearly combined. It also notes that the experimental analysis section lacks an in-depth exploration of the reasons behind the results. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions to take. The authors are left with a general understanding of what needs to be done but lack concrete steps to follow. Therefore, the comment is somewhat actionable, as it highlights areas for improvement but does not provide detailed guidance on how to implement them.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental analysis section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of new evaluation metrics and the need for an in-depth exploration of the reasons behind the experimental results. This provides the authors with clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not propose new evaluation metrics and only uses existing ones linearly combined. It also notes that the experimental analysis section lacks an in-depth exploration of the reasons behind the results. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for understanding but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting that it does not propose new evaluation metrics, relying solely on the linear combination of existing ones. It also points out that the experimental analysis section lacks an in-depth exploration of the reasons behind the results. This feedback is valuable as it highlights areas where the authors could enhance the depth and rigor of their analysis. However, the comment could be more helpful if it provided specific suggestions or guidance on how to develop new metrics or conduct a more thorough analysis of the experimental results. Without these additional details, the authors may find it challenging to fully address the feedback. Therefore, the comment is somewhat helpful, as it identifies important areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit action that the authors should take to avoid confusion and ensure clarity in their notation. The comment provides a direct and concrete instruction, making it highly actionable. The authors know exactly what needs to be addressed and how to implement the suggested change. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and explicit reference to specific parts of the paper, such as L166 and L176, which allows the authors to accurately pinpoint the issue. The comment is fully grounded as it provides specific references to the sections where the notation is used. It is also specific because it clearly specifies the problem with the notation, making it easy for the authors to understand and address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a factual observation that requires no further verification or reasoning to understand. The comment is clear and specific, making it verifiable. Therefore, it is classified as a comment that is fully verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notation used in the paper, noting that the symbol K is used to represent both a known kernel function and the number of layers. This is a clear and actionable feedback that highlights a potential source of confusion for the readers. By pointing out this inconsistency, the comment provides the authors with a concrete suggestion to improve the clarity and consistency of their notation. This feedback is valuable as it helps the authors enhance the readability and understanding of their work. Therefore, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the relevance of connections to human cognition, suggesting that the authors should clarify their reasoning. It points out that the authors themselves acknowledge the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. The comment questions the meaning of the statement regarding the interaction between cognitively basic adaptation mechanisms and the structure of the CPR, implying that it is unclear what the authors mean by \"perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether self-organization will fail or succeed than previously appreciated.\" The reviewer suggests that it would be surprising if behavioral economists ignored these things and needs more citation for comparison against \"previously appreciated.\" However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify their reasoning. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify their reasoning and provide more context or citations. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the relevance of connections to human cognition, suggesting that the authors should clarify their reasoning. It points out that the authors themselves acknowledge the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. The comment questions the meaning of the statement regarding the interaction between cognititively basic adaptation mechanisms and the structure of the CPR, implying that it is unclear what the authors mean by \"perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether self-organization will fail or succeed than previously appreciated.\" The reviewer suggests that it would be surprising if behavioral economists ignored these things and needs more citation for comparison against \"previously appreciated.\" However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. It is specific in questioning the relevance of human cognition connections, but without explicit references, the authors cannot confidently determine which part to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the relevance of connections to human cognition, suggesting that the authors should clarify their reasoning. It points out that the authors themselves acknowledge the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. The comment questions the meaning of the statement regarding the interaction between cognititively basic adaptation mechanisms and the structure of the CPR, implying that it is unclear what the authors mean by \"perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether self-organization will fail or succeed than previously appreciated.\" The reviewer suggests that it would be surprising if behavioral economists ignored these things and needs more citation for comparison against \"previously appreciated.\" However, the comment lacks specific examples or detailed reasoning to fully support the claim, making it somewhat verifiable. The authors would need to infer the basis for the claim, which limits its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the relevance of connections to human cognition, suggesting that the authors should clarify their reasoning. It points out that the authors themselves acknowledge the reductionist nature of the problem and the absence of mechanisms like bargaining and negotiation. The comment questions the meaning of the statement regarding the interaction between cognititively basic adaptation mechanisms and the structure of the CPR, implying that it is unclear what the authors mean by \"perhaps the interaction between cognitively basic adaptation mechanisms and the structure of the CPR itself has more of an effect on whether self-organization will fail or succeed than previously appreciated.\" The reviewer suggests that it would be surprising if behavioral economists ignored these things and needs more citation for comparison against \"previously appreciated.\" However, the comment does not provide specific guidance or suggestions on how the authors should address this issue or what additional context or citations they might need. The feedback is somewhat helpful as it identifies a potential area for clarification but lacks depth and actionable advice, leaving the authors with limited guidance on how to improve their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. While the comment identifies a specific issue with the writing style, it does not provide explicit guidance on how to revise the conclusion or suggest specific changes to make the word choice less flamboyant. The action is implicit, as the authors would need to infer that they should revise the conclusion to be more concise and less exaggerated. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the conclusion section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue of exaggerated wording and suggests that the word choice is a bit flamboyant in multiple places, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the wording in the conclusion is overly exaggerated and suggests that the word choice is a bit flamboyant in multiple places. While the comment identifies a subjective opinion about the writing style, it does not provide specific examples or references to support the claim. This lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the writing style in the conclusion, noting that the wording is overly exaggerated and that the word choice is a bit flamboyant in multiple places. This feedback is clear and actionable, as it provides the authors with a specific area to improve the tone and conciseness of their conclusion. However, the comment could be more helpful if it offered suggestions on how to revise the language or provide examples of more concise phrasing. Overall, the comment is mostly helpful, as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This provides a clear and explicit action for the authors to take, as they know exactly what experiments to conduct and what metrics to compare. The comment is specific in its suggestion, guiding the authors on how to improve their draft by adding these experiments. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this comparison should be made or which section of the paper discusses the proposed method. This makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This claim is somewhat verifiable as it provides a clear direction for the authors to take, but it lacks specific examples or references to support the comparison with other methods. The authors would need to conduct additional research to find relevant methods for comparison, which could be helpful but requires further elaboration. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and actionable, as it provides a clear direction for the authors to enhance their draft by conducting additional experiments. However, the comment could be more helpful if it included more detailed guidance on how to conduct these experiments or why these metrics are important. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes that clarifications are needed on how the embeddings are combined and fed into the CSCM. This feedback is explicit and provides a clear action for the authors to take, which is to clarify the combination and feeding of embeddings. However, the action is somewhat vague as it does not specify the exact steps or methods that need clarification. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific question about how historical observations are combined with inputs known over all time, particularly focusing on the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but highlights the need for clarifications on how the embeddings are combined and fed into the CSCM. This feedback is fully grounded as it explicitly mentions the part of the paper being addressed, allowing the authors to accurately identify the section. The comment is also specific, as it clearly specifies what needs clarification regarding the combination and feeding of embeddings. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about how historical observations are combined with inputs known over all time, specifically addressing the differences in sequence lengths (L vs L+M). It mentions that the text discusses separate embedding and addition with positional encoding but notes that clarifications are needed on how the embeddings are combined and fed into the CSCM. This feedback is somewhat verifiable as it points out a specific area where the paper lacks clarity, but it does not provide detailed reasoning or examples to support the claim. The authors would need to infer the need for clarification based on the feedback, which could be improved with more explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion in the paper, namely the combination of historical observations with inputs known over all time, particularly concerning the differences in sequence lengths (L vs L+M). It points out that while the text mentions separate embedding and addition with positional encoding, it lacks clarity on how the embeddings are combined and fed into the CSCM. This feedback is clear and actionable, as it directs the authors to clarify a specific aspect of their methodology. However, the comment could be more helpful if it provided additional context or examples to guide the authors in addressing this issue. Overall, the comment is mostly helpful, as it effectively highlights a need for clarification and improvement in the paper.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue, such as suggesting a method for analyzing hyper-parameter sensitivity or specifying their values. The action is implicit and vague, as the authors are left to infer how to improve the paper. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the hyper-parameters $m_1$, $m_2$, and $\\lambda$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion and specification of the sensitivity of these hyper-parameters. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified in the paper. This is a factual observation that requires no further verification or evidence. The comment is clear and specific, providing a direct observation about the absence of discussion and specification of these hyper-parameters. Therefore, it is classified as \"3: Somewhat Verifiable\" as it is clear but lacks some depth in terms of suggesting how the authors might address this issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the sensitivity of hyper-parameters such as $m_1$, $m_2$, and $\\lambda$ is not discussed and their values are not specified. This is a clear and actionable feedback that highlights a gap in the paper. By pointing out the lack of discussion and specification of these hyper-parameters, the comment provides the authors with a clear direction for improvement. However, it could be more helpful if it suggested specific methods or approaches for analyzing the sensitivity of these hyper-parameters or specifying their values. Despite this, the comment is mostly helpful as it directs the authors to an important area for attention, enabling them to enhance the completeness and clarity of their work. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the potential impact of similarity-aware positive sample selection on the performance of GNN-based encoders, specifically regarding over-smoothing and generalization performance. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization. The reviewer suggests that the authors should conduct more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not provide explicit guidance on how to conduct these additional experiments or what specific aspects of the model should be explored. The action is implicit and somewhat vague, as the authors are left to infer the need for more experiments and the specific areas to focus on. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the similarity-aware positive sample selection and its potential impact on the performance of GNN-based encoders, specifically regarding over-smoothing and generalization performance. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization. The reviewer suggests conducting more experiments on different downstream tasks and across different domains to address these concerns. However, the comment does not specify which part of the paper discusses the similarity-aware positive sample selection or the experiments conducted on the graph classification task. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs attention. While the comment is specific about the concerns and suggestions, the absence of explicit references to the paper's sections or content makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the potential impact of similarity-aware positive sample selection on the performance of GNN-based encoders, specifically regarding over-smoothing and generalization performance. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization. The reviewer suggests conducting more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific examples, detailed reasoning, or references to support the claims about the potential impact of the sample selection method. Without concrete evidence or detailed explanations, the claim remains somewhat verifiable, as the authors may need to infer the basis for the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the potential impact of similarity-aware positive sample selection on the performance of GNN-based encoders, specifically regarding over-smoothing and generalization. It questions whether selecting positive samples within the same dataset without introducing perturbation noise might lead to lower generalization performance. The reviewer suggests conducting more experiments on different downstream tasks and across different domains to address these concerns. However, the comment lacks specific guidance on how to conduct these additional experiments or what aspects of the model should be explored. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights a concern but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so or provide specific guidance on how to discuss the power of different architectures. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the discussion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its request for more discussion but lacks grounding as it does not mention a specific part of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. However, it does not contain any claims or opinions that require verification. The comment is purely descriptive and does not provide any evidence or reasoning to support the question or suggestion. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the expressiveness of \"fast SMP\" compared to \"SMP\" and suggests that the authors should provide more discussion on the power of different architectures. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to address this issue. The comment is somewhat helpful as it points out a potential area for further discussion, but it does not provide detailed feedback or actionable advice, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects need clarification. The comment lacks concrete guidance on how to improve the clarity of the paper, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a lack of clarity regarding the types of situations or social norms discussed in the main paper. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact area that needs clarification. The comment is specific in its critique but weakly grounded as it does not provide explicit references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the types of situations or social norms discussed in the main paper are not clear. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the paper regarding the types of situations or social norms discussed. However, it lacks actionable guidance or suggestions on how the authors might address this lack of clarity. Without specific advice on how to improve the clarity or provide more detailed explanations, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is barely helpful, as it points out a problem but does not offer substantial assistance in resolving it.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not provide explicit guidance on how to select additional baselines or domains, nor does it offer concrete steps on how to address the lack of motivation for the current choices. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment does not specify which parts of the paper these suggestions relate to, such as specific sections or tables. This makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the need for more baselines and domains, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also mentions that the choices of weighting and learning density functions are not strongly motivated. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the reasoning behind the suggestions. The feedback is somewhat verifiable as it provides a general direction for improvement but lacks detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that the authors should include more baselines and test on more domains to strengthen their empirical results. It also points out that the choices of weighting and learning density functions are not strongly motivated, which could be a significant issue. However, the comment lacks specific guidance on how to select additional baselines or domains, nor does it provide detailed suggestions on how to address the lack of motivation for the current choices. While it identifies areas for improvement, the feedback is somewhat vague and lacks depth, making it somewhat helpful. The authors would need to infer the necessary steps to address the feedback, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the comparability of their results. The comment lacks concrete guidance on what specific steps the authors should take to make their results more comparable or to enhance the significance of their proposed methods. As a result, the authors are left without a clear direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concern about the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, it does not specify which part of the paper this issue is related to, such as the results section, the discussion, or the methodology. Without clear grounding, the authors cannot confidently identify where the issue lies, making it difficult to address the concern effectively. Additionally, the comment lacks specificity in detailing what aspects of the results need to be improved to enhance comparability or significance. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern that the results are not comparable to existing methods, which may limit the significance of the proposed methods. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a concern regarding the comparability of the results to existing methods, suggesting that the proposed methods may not have significant value. However, the comment lacks specific details or suggestions on how the authors might address this issue or improve the significance of their results. It does not provide actionable guidance or insights into potential improvements, leaving the authors with limited information to enhance their draft. Therefore, the comment is barely helpful, as it highlights a potential problem but does not offer substantial assistance in resolving it.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the limited novelty of the paper, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. It mentions that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty or provide unique insights about the challenges of overcorrelation in recommender systems. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"limited novelty\" and \"DeCorr,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper is a straightforward application of existing literature, specifically DeCorr, in a specific application domain. The comment highlights the lack of unique insights about the challenges of overcorrelation in recommender systems, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is a straightforward application of existing literature, specifically DeCorr, to a specific application domain, lacking novelty. It suggests that the contribution is mainly the transposition of DeCorr's insights into graph collaborative filtering, with different datasets and backbones. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. The lack of evidence makes it difficult for the authors to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's novelty, suggesting that it primarily applies existing literature, specifically DeCorr, to a specific application domain. While the authors acknowledge the transposition of DeCorr's insights into graph collaborative filtering, they also note the lack of unique insights regarding the challenges of overcorrelation in recommender systems. This feedback is somewhat helpful as it highlights a critical area for improvement, but it lacks depth and actionable suggestions. The authors would benefit from more specific guidance on how to enhance the novelty and provide unique insights into the challenges of overcorrelation in recommender systems. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a limitation in the results of the paper, specifically regarding the assumption that the spectrum of a kernel is sub-gaussian. It notes that while Gaussian kernels are in this class, other popular kernels like Matern kernels, which have polynomial decay spectra, are not included. The comment suggests that the results could be restrictive due to this limitation. However, the comment does not provide explicit guidance on how the authors might address this issue or what steps they should take to improve their results. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific limitation in the results of the paper, focusing on the assumption that the spectrum of a kernel is sub-gaussian. It highlights that while Gaussian kernels are included, other popular kernels like Matern kernels, which have polynomial decay spectra, are not considered. This provides a clear and specific point of concern, allowing the authors to understand the exact issue being raised. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific because it details the limitation and suggests that the results could be restrictive. Therefore, this comment is classified as fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results of the paper could be restrictive due to the assumption that the spectrum of a kernel is sub-gaussian. It argues that while Gaussian kernels are included, other popular kernels like Matern kernels, which have polynomial decay spectra, are not considered. The comment provides a logical reasoning by explaining why the exclusion of Matern kernels might limit the generality of the results. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a limitation in the paper's results, specifically regarding the assumption that the spectrum of a kernel is sub-gaussian. It points out that while Gaussian kernels are included, other popular kernels like Matern kernels, which have polynomial decay spectra, are not considered. This observation suggests that the results of the paper could be restrictive due to this limitation. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve their results. While it highlights an important area for consideration, the feedback lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3, as it offers some insight but could be more comprehensive and constructive.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker's gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and vague, as it does not specify how the authors can implement the suggested changes or what steps they should take to resolve the issue. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\\'s gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table discussing the selection of ELMs. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of ELM choice and its potential drawbacks, it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker\\'s gender, which could be a drawback. The comment implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it is based on a logical inference but lacks sufficient support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the choice of ELM (male or female) and suggests that this choice might require prior knowledge of the speaker's gender, which could be a drawback. It implies that the accuracy should be calculated after using a gender detection model in the pipeline, at least in cases where vocal traits match speaker identity. This feedback highlights a potential issue with the methodology and suggests that the authors should consider the implications of using a gender detection model in their pipeline. However, the comment lacks specific guidance on how the authors might address this issue or what changes could be made to improve their draft. While it identifies a potential area for improvement, it does not provide detailed suggestions or actionable steps, making it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the technical depth or substance of their work. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, it does not specify which part of the paper this issue is related to, such as the introduction, methodology, or results sections. The authors cannot confidently determine which section is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity in detailing what aspects of the paper are lacking in technical substance or how the addition of a new loss impacts the overall contribution. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the paper is incremental and lacks technical substance, primarily adding a new loss to [31]. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the criticism. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that it is incremental and lacks technical substance, primarily adding a new loss to [31]. While this feedback highlights an area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable advice, such as recommending additional experiments, deeper analysis, or a more detailed explanation of the technical contributions. Without concrete suggestions, the authors may find it difficult to understand how to enhance the depth and impact of their work. Therefore, the comment is somewhat helpful, as it points out a need for improvement but does not fully support the authors in addressing it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the applicability of the model to real-world diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in real-world scenarios. However, the comment does not specify which part of the paper should be revised or how the empirical evidence should be presented. The action is implicit and vague, as it leaves the authors to infer the necessary steps to address the concern. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment does not specify which part of the paper discusses the model's applicability or where the empirical evidence should be provided. This lack of grounding makes it difficult for the authors to identify the specific section or part of the paper that needs revision. While the comment is specific in its suggestion to provide empirical evidence, the absence of explicit references to the paper limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the applicability of the model to real-world diffusion processes, suggesting that the authors should provide empirical evidence to support this claim. However, the comment lacks specific details or examples to substantiate this concern, making it difficult for the authors to understand the basis of the issue. Without additional context or references, the claim remains somewhat verifiable, as it is based on a general observation without clear justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the applicability of the model to real-world diffusion processes. It suggests that the authors should provide empirical evidence to support the claim that the proposed model captures diffusion phenomena in real-world scenarios. This feedback is valuable as it highlights a gap in the paper and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific guidance on how to conduct or present the empirical evidence. Despite this, the comment is mostly helpful as it directs the authors towards an important area for enhancement, making it a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a plot showing how different weights of the model change after unlearning, specifically focusing on which layers are most affected. This feedback is explicit and concrete, as it directly instructs the authors on what action to take and how to implement it. The comment provides a clear and detailed action, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests providing a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. However, it does not specify which part of the paper this plot should be included in or which sections of the paper it should address. This lack of grounding makes it difficult for the authors to understand where to apply the suggested improvement. While the comment is specific about the type of plot and its purpose, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a plot of how different weights of the model move after unlearning, specifically focusing on which layers are affected the most. This claim is somewhat verifiable as it provides a suggestion for an additional analysis that could enhance the understanding of the method's behavior. However, it lacks specific examples or references to existing literature that could support the claim, making it somewhat verifiable. The authors would need to conduct additional research or experimentation to fully validate the suggestion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improving the paper by requesting a plot that visualizes how different weights of the model change after unlearning. This feedback is actionable and constructive, as it directs the authors to a concrete step they can take to enhance the clarity and understanding of their method. By providing a visual representation of the weight changes, the authors can better illustrate the impact of unlearning on different layers of the model. This feedback is mostly helpful as it offers a clear and actionable suggestion, but it could be more comprehensive if it included additional guidance on how to interpret or present the plot effectively. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the novelty of the paper is limited, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into D and Phi_v. However, the comment does not provide explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how to enhance the novelty of the paper or what specific aspects need to be improved. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the methodology aspect of the paper, specifically mentioning the ENCODE part and the decomposition part. It provides a detailed explanation of the novelty of the paper, noting that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. This provides clear grounding as the authors can accurately identify the section being addressed. Additionally, the comment specifies what needs to be addressed, highlighting the limited novelty and suggesting that the authors should enhance the novelty of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited, specifically mentioning that the ENCODE part is already proposed in [10] and that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a specific claim about the novelty of the paper, it lacks detailed reasoning or references to support the assertion that the ENCODE part is already proposed in [10]. Without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the paper, specifically pointing out that the ENCODE part is already proposed in [10]. It also highlights that the incremental contribution lies in the decomposition part, which factorizes M_v into factor D and slices Phi_v. While the comment provides a clear observation about the novelty of the paper, it lacks actionable suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without specific advice or suggestions, the authors are left with limited insight on how to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not provide sufficient guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies issues with the presentation of the paper, specifically noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. While the comment explicitly states the issue with the presentation and provides a suggestion for improvement, it does not offer concrete guidance on how to create or integrate the illustrative figure into the paper. The action is implicit and somewhat vague, as the authors would need to infer how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"chapter 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it identifies the issue as the presentation being too equation-driven and the notation being convoluted and hard to follow, and suggests that an illustrative figure would have been helpful. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the presentation is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure would have been helpful. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism or how to address it. The feedback is somewhat verifiable as it provides a general idea but lacks detailed reasoning or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of the paper, noting that it is too equation-driven and that the notation in chapter 3 is convoluted and hard to follow. It suggests that an illustrative figure of the key concepts in section 3 would have been helpful. This feedback is clear and actionable, providing the authors with a concrete suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to create or integrate the illustrative figure effectively. Overall, the comment is mostly helpful as it directs the authors towards a specific area for improvement, but it could be more comprehensive with additional details. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, it does not provide any explicit or implicit actions for the authors to take to improve the presentation. The comment lacks guidance on how to enhance the subscripts or what specific improvements could be made. As a result, the authors are left without a clear understanding of what steps to undertake to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"figure3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the visual presentation, particularly the subscripts, and suggests that enhancing readability and aesthetic appeal would improve the presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the visual presentation of the data in Figure 3, specifically the subscripts, could be enhanced for better readability and aesthetic appeal. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to improve the presentation. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the visual presentation of data in Figure 3, noting that the subscripts could be enhanced for better readability and aesthetic appeal. This feedback is clear and actionable, as it provides a specific area for improvement that the authors can address. However, the comment could be more helpful if it offered suggestions on how to enhance the subscripts or provided examples of improved presentation. Despite this, the comment is mostly helpful as it directs the authors to a concrete area for improvement, allowing them to make targeted revisions to their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment is primarily a clarification request, asking for further explanation or justification of the concepts discussed. Without specific guidance on how to address the confusion or improve the explanation, the authors are left without actionable steps to enhance their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section being discussed. Additionally, the comment is not specific because it does not provide detailed feedback or suggestions on what needs to be addressed regarding the confusion between Batch Normalization and Online Normalization. The authors are left without guidance on how to clarify or resolve this issue. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, but it does not contain a claim or suggestion that requires verification. It is a request for clarification and does not provide any evidence or reasoning to support a claim. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the difference between Batch Normalization and Online Normalization in terms of gradient bias, which could be helpful for the authors to clarify their understanding of these concepts. However, the comment does not provide any suggestions or guidance on how to address the confusion or improve the explanation. It is a question that could be expanded upon with more detailed feedback or suggestions, but as it stands, it is barely helpful. Therefore, the comment is rated as 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. It also mentions that this formatting issue effectively violates the 9-page paper limit, which is a significant concern. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the formatting. The authors are left without guidance on how to resolve the whitespace problem or enhance the visual presentation of the paper. Therefore, the comment is unactionable as it lacks any direction for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W1,\" indicating a specific part of the paper being addressed. It also specifies the issue by detailing the formatting problems with equations and captions, which are common elements in academic papers. The comment is specific in its critique of the formatting, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions too close to the figures. This is presented as a violation of the 9-page paper limit, which is a factual observation. However, the comment lacks specific examples or references to support the claim that this formatting issue is a significant problem or how it impacts the paper's readability or adherence to standards. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the formatting of the paper, noting that equations are crammed together and captions are too close to the figures. This observation is presented as a potential violation of the 9-page paper limit, which is a significant concern. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the formatting. Without actionable feedback or recommendations, the authors are left without a clear path to resolve the problem. Therefore, the comment is barely helpful, as it highlights a weakness but does not offer any constructive advice for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the technical details and formulations are limited and suggests that the main novelty is reflected in the scheme or procedure. However, it does not provide explicit guidance on what specific aspects of the technical details or formulations need to be expanded or improved. The comment lacks concrete suggestions or actions for the authors to take, such as specifying which sections or parts of the paper require more detail or elaboration. As a result, the authors are left without a clear understanding of how to address the feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the technical details and formulations are limited and that the main novelty is reflected in the scheme or procedure. However, it does not specify which part of the paper this issue pertains to, such as specific sections, tables, or figures. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide specific guidance on what aspects of the technical details or formulations need to be expanded or improved. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the technical details and formulations are limited, suggesting that the main novelty is reflected in the scheme or procedure. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically noting that the technical details and formulations are limited and that the main novelty is reflected in the scheme or procedure. However, the comment lacks specificity and does not provide actionable guidance on how the authors might address this issue. It does not suggest specific areas that need improvement or offer alternative approaches to enhance the technical depth of the paper. Without concrete suggestions or examples, the authors may struggle to understand how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the paper's claim of better results in the Molecule generation experiment (Table 3) and the observation that adding the proposed constrained method yields lower validity and diversity. However, it does not provide explicit or implicit actions for the authors to take. The comment suggests that the authors should re-evaluate their results and consider the impact of the constrained method on validity and diversity. While the authors can infer that they need to address this issue, the comment lacks concrete guidance on how to do so. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the Molecule generation experiment, noting that the proposed constrained method yields lower validity and diversity compared to the paper\\'s claim of better results. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper\\'s claim of better results in the Molecule generation experiment (Table 3) is contradicted by the observation that adding the proposed constrained method yields lower validity and diversity. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a discrepancy between the paper\\'s claim of better results in the Molecule generation experiment (Table 3) and the observation that adding the proposed constrained method yields lower validity and diversity. This feedback highlights a potential issue with the paper\\'s claims and suggests that the authors should re-evaluate their results and consider the impact of the constrained method on validity and diversity. While the comment points out a specific area of concern, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it directs the authors to a critical area for improvement, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While the comment implies that additional detail would be beneficial, it does not explicitly instruct the authors to provide this description or specify how it should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on the description of the Starcraft environment. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, it does not specify which part of the paper this description should be included in or how it should be integrated. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also specific in terms of suggesting the inclusion of more description, but the lack of grounding makes it difficult for the authors to understand where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. However, it does not provide any specific reasoning, examples, or references to support why this additional description would be beneficial. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors would have liked more description of the Starcraft environment, potentially in an appendix. While this feedback provides a specific area for improvement, it lacks depth and actionable guidance. The comment does not specify how the additional description should be structured or what aspects of the Starcraft environment are most relevant. Without these details, the authors may find it challenging to effectively incorporate the suggested changes. Therefore, the comment is somewhat helpful, as it identifies a potential area for improvement but does not provide comprehensive guidance for the authors to follow.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This is a clear and explicit action that the authors can readily follow. The comment provides specific guidance on what needs to be included in the discussion, making it highly actionable. Therefore, this comment is rated as 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to know exactly where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This is a suggestion for improvement, but it lacks specific details or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion on the creation of the prompt dataset used in the few-shot case, along with its source. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the transparency and reproducibility of the research. By addressing this suggestion, the authors can strengthen their paper and provide valuable context for their work. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive if it included additional suggestions or details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not provide any specific guidance or suggestions on how the authors can address these issues. The comment lacks explicit actions or concrete steps that the authors can take to improve their draft. As a result, the authors are left without a clear understanding of what needs to be done to enhance the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses difficulty in following the motivation of the paper and suggests that it might be an incremental engineering paper. However, it does not specify which part of the paper is challenging to follow or why it is considered an incremental engineering paper. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity in explaining what aspects of the motivation are difficult to follow or why the paper is considered incremental. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is \"very difficult to follow the motivation of this paper\" and suggests that it might be an incremental engineering paper. However, the comment lacks specific evidence or reasoning to support these claims. It does not provide examples or references to substantiate the assertion that the motivation is difficult to follow or that the paper is incremental. Without detailed justification or examples, the claim remains vague and unconvincing, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the difficulty in following the motivation and the perception of it being an incremental engineering paper. While these points highlight areas for improvement, the comment lacks specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need attention, but it does not provide actionable steps or detailed advice on how to enhance the paper. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study on the weighting method of the cross-entropy loss would be beneficial. It also mentions an example where the authors note that their method underperforms due to repetitive background sounds, which the reviewer expects the weighting method to address. While the comment provides a clear action\u2014asking for an ablation study\u2014it does not specify how the authors should conduct this study or what aspects of the weighting method should be explored. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an ablation study on the weighting method of the cross-entropy loss, referencing an example where the authors note that their method underperforms due to repetitive background sounds. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in suggesting an ablation study, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an ablation study on the weighting method of the cross-entropy loss, referencing an example where the authors note that their method underperforms due to repetitive background sounds. This claim is somewhat verifiable as it provides a specific example of a potential issue and suggests a method to address it. However, it lacks detailed reasoning or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests an ablation study on the weighting method of the cross-entropy loss, noting that the authors' method underperforms due to repetitive background sounds. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a specific example to consider. However, it lacks detailed guidance on how to conduct the ablation study or what aspects of the weighting method should be explored. The comment could be more helpful if it offered more specific suggestions or a clearer direction for the authors to follow. Therefore, it aligns with a score of 3, as it provides some insight but requires further elaboration to be fully beneficial.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical weakness in the paper, stating that it lacks novelty and is incremental in nature. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any explicit or implicit suggestions on how the authors might address these issues or improve the paper. The authors are left without guidance on how to enhance the novelty or significance of their work, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It also critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not specify which part of the paper discusses the dataset or the approach, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks novelty and is incremental in nature, citing the design of a new dataset as a different train/test split of an existing dataset, SQUALL, and another synthetic benchmark paper based on a single question template. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of supporting evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper, specifically the lack of novelty and incremental nature of the work. It critiques the approach of designing a new dataset as a different train/test split of an existing dataset, SQUALL, and mentions another synthetic benchmark paper based on a single question template. However, the comment does not provide any suggestions or guidance on how the authors might address these issues or improve the novelty of their work. Without actionable feedback or specific suggestions, the comment is not helpful to the authors in enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments are only conducted on one game environment and that more experiments are necessary. While the comment implies that additional experiments should be performed, it does not specify which additional environments or types of experiments would be beneficial. The action is implicit, as the authors need to infer that they should conduct more experiments, but it lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments are only conducted on one game environment and that more experiments are necessary. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. The authors cannot confidently determine which section is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not provide details on what additional experiments should be conducted or why the current single environment is insufficient. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the experiments are only conducted on one game environment and suggests that more experiments are necessary. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this is a significant issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the experiments are only conducted on one game environment, suggesting that more experiments are necessary. While this feedback highlights a potential limitation in the scope of the experiments, it does not provide specific guidance on what additional experiments should be conducted or how to address the issue. The comment is somewhat helpful as it identifies a potential area for improvement, but it lacks depth and actionable suggestions, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not provide specific guidance on how to demonstrate the importance of these assumptions or what kind of examples would be effective. The action is implicit, as the authors need to infer that they should provide detailed explanations and examples to support their claim. The comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for detailed explanations and examples, but without clear references to specific sections or parts of the paper, the authors may find it challenging to understand where to address this feedback. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should explain why removing certain assumptions, such as bounded variance and bounded gradients, is an important contribution. This feedback is clear and actionable, as it prompts the authors to provide detailed explanations and examples to support their claims. However, the comment could be more helpful if it provided specific guidance on how to demonstrate the importance of these assumptions or suggested particular types of examples that would be effective. Overall, the comment is mostly helpful as it directs the authors towards a crucial aspect of their work that needs further elaboration.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the implementation of ImageNet, noting that it is slow and has low accuracy. It provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet-18, and mentions the accuracy is around 70%. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to improve the implementation. While the authors might infer that they need to optimize their implementation, the lack of explicit instructions or detailed suggestions makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ImageNet\" and provides specific details about the time taken to test an ImageNet picture using AlexNet and ResNet-18, as well as the accuracy. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the performance issues with the implementation, including the time taken and accuracy, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' implementation of ImageNet is slow and has low accuracy, providing specific details such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and an accuracy of around 70%. However, the comment lacks references or detailed reasoning to substantiate these claims. Without additional context or evidence, the authors may find it challenging to fully understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some support but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the implementation of ImageNet, noting that it is slow and has low accuracy. It provides concrete data, such as the time taken to test an ImageNet picture using AlexNet and ResNet-18, and mentions the accuracy is around 70%. This feedback is actionable as it highlights a clear weakness in the implementation and provides specific details that the authors can use to improve their work. However, the comment could be more helpful if it suggested specific ways to address the performance issues or provided guidance on optimizing the implementation. Overall, the comment is mostly helpful, as it offers valuable insights and actionable feedback that the authors can use to enhance their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that it might be effective. However, it does not provide explicit or implicit actions for the authors to take, such as conducting experiments or providing feedback on the use of labeled data. The comment lacks concrete guidance on how the authors might address this question or incorporate it into their work. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that it might be effective. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. The comment is weakly grounded as it does not provide explicit references to sections or figures. It is specific in suggesting that labeled data could be beneficial, but without grounding, the authors cannot confidently determine where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that it might be effective. It provides references to two papers, [a] Graph Contrastive Learning Automated and [b] Graph Contrastive Learning with Adaptive Augmentation, which are relevant to the topic of graph contrastive learning. However, the comment does not offer a detailed explanation or reasoning for why labeled data could be beneficial for consistency training, nor does it provide specific examples or comparisons to support the claim. The references are provided, but the reasoning behind the suggestion is not fully elaborated, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the potential benefits of using labeled data for consistency training in graph anomaly detection, suggesting that it might be effective. It provides references to two relevant papers, which could help the authors understand the context and potential applications of labeled data in this area. However, the comment lacks specific guidance or suggestions on how the authors might explore or incorporate this idea into their work. While it identifies an interesting area for further investigation, it does not offer actionable advice or detailed insights that would significantly enhance the authors' understanding or approach. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors to consider but lacks depth and actionable suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors' claim that their proposed classification network is universally as good as the standard softmax network, particularly in terms of classification accuracy. It suggests that building a new model for better out-of-distribution detection might come at the cost of losing classification accuracy. The comment implies that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications for the issue. While the comment suggests specific actions, such as reporting accuracy and providing theoretical justifications, it does not provide detailed guidance on how to implement these actions or what specific aspects of the model should be analyzed. The actions are somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors proposing a new classification network, allowing the authors to identify the specific part of the paper being addressed. It also specifies what the authors should report, namely the classification accuracy of the proposed classifier on ImageNet data, as well as the need for theoretical justifications. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the classification accuracy of the proposed network compared to the standard softmax network, particularly in the context of out-of-distribution detection. It suggests that the authors should report the classification accuracy on ImageNet data and provide theoretical justifications. However, the comment lacks specific examples or references to support the claim that the proposed network's classification accuracy is universally as good as the standard softmax network. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors would need to provide additional information to substantiate it. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the classification accuracy of the proposed network compared to the standard softmax network, particularly in the context of out-of-distribution detection. It questions whether the new model might sacrifice classification accuracy while improving out-of-distribution detection. The comment suggests that the authors should report the classification accuracy of their proposed classifier on ImageNet data and provide theoretical justifications for the issue. This feedback is somewhat helpful as it identifies a potential weakness and provides a direction for improvement, but it lacks depth and specificity in terms of how the authors might address the issue or what specific aspects of the model should be analyzed. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide explicit guidance or suggestions on how the authors might address these issues or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to understand how to apply it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a concern about the practical implementation and testing of recognition lists, specifically focusing on the scenario where new items are included in the list of available items in memory. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in its critique of the implementation, the lack of grounding makes it challenging for the authors to fully understand and address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the practical implementation and testing of recognition lists, specifically questioning how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that such an exhaustive list is difficult to implement or test. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the practical implementation and testing of recognition lists, particularly in the context of old vs. new judgments. It questions how an exhaustive list could be effectively implemented and how concrete predictions could be tested with simulations. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or what changes could be made to improve their draft. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The feedback could be more helpful if it included suggestions for alternative approaches or detailed explanations of how to implement and test the recognition lists effectively.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. It does not provide explicit instructions on how to address these points, such as suggesting specific sections or types of descriptions to include. The comment is somewhat vague, as it implies that the authors should consider these aspects but does not offer concrete guidance on how to do so. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should describe possible alternate formulations for Confidence Diversity (CD) and asks for clarification on why entropy is not a good measure of the spreading of teacher predictions. However, it does not specify which part of the paper this issue is related to, such as a specific section or figure. The comment is vague and does not provide detailed guidance on what needs to be addressed. Therefore, it is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the clarity of the paper regarding the concept of Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It asks for clarification on why entropy is not a good measure of the spreading of teacher predictions, specifically referencing line 115 and line 113. However, the comment does not provide any evidence, reasoning, or references to support these claims. The authors are left to interpret the questions and potentially seek clarification from the authors themselves, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the concept of Confidence Diversity (CD) and its relationship to Predictive Uncertainty. It questions why entropy is not a good measure of the spreading of teacher predictions, particularly referencing line 115 and line 113. This feedback is valuable as it highlights a potential gap in the paper's explanation and encourages the authors to clarify these points. However, the comment could be more helpful if it provided suggestions or guidance on how to address these issues, such as suggesting additional experiments or analyses that could help clarify the concept. Overall, the comment is somewhat helpful, as it points out an area for improvement but lacks depth in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the strong assumptions made for the termination states of instructions, particularly in the general case where manual labeling of large datasets is expensive. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment identifies a potential problem but lacks guidance on how the authors might address it, such as suggesting alternative assumptions or methods for handling the cost of labeling. Without specific actions or suggestions, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the assumption for termination states of instructions, noting that it is strong and expensive to label data manually in the general case. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure being referenced. The comment is specific in its critique of the assumption but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the assumption for termination states of instructions is strong and expensive to label data manually in the general case. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer's assertion remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumptions made for the termination states of instructions, specifically noting that it is expensive to label data manually in the general case. This feedback highlights a practical concern that could impact the feasibility and applicability of the research. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue, such as proposing alternative assumptions or methods for handling the cost of labeling. Without specific recommendations or detailed feedback, the comment is somewhat helpful as it points out a potential area for improvement but does not provide a comprehensive roadmap for the authors to follow. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It suggests that the paper should be more explicit about the contribution, noting that it involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer expresses confusion about the paper's point until this clarification is provided. While the comment identifies a specific issue and suggests a way to address it, it does not provide explicit guidance on how to make the contribution clearer or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the contribution in the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the nature of the contribution with respect to ECE_sweep, specifically mentioning that it involves choosing the number of bins using data, which is autotuning a hyperparameter. This provides a clear reference point for the authors to understand the issue being raised. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that requires clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not clearly describe the nature of the contribution with respect to ECE_sweep, specifically mentioning that it involves choosing the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that this is not fundamentally different and would prefer the paper to be upfront about the contribution. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific issue with the paper, namely the lack of clarity regarding the nature of the contribution with respect to ECE_sweep. It highlights that the paper does not clearly explain how the contribution relates to the choice of the number of bins using data, which is essentially autotuning a hyperparameter. The reviewer suggests that the paper should be more explicit about this contribution to avoid confusion. While the comment points out a potential area for improvement, it does not provide detailed guidance or suggestions on how to clarify the contribution or address the confusion. The feedback is somewhat helpful as it directs the authors to a specific area that needs attention, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the related work section, noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is explicit and provides a clear action for the authors to take: they should consider incorporating these methods as baselines in their experiments. The comment is specific in identifying the issue and offers a concrete suggestion for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies a gap in the related work by noting that while other methods for training NMT models beyond MLE are discussed, none of them are used as baselines. This provides a clear and actionable suggestion for improvement, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the related work section discusses other methods for training NMT models beyond MLE but does not include any of these methods as baselines. This claim is somewhat verifiable as it highlights a gap in the related work section, but it lacks specific examples or references to support the claim. The authors would need to infer that the omission of baselines is a significant oversight, which could be addressed by providing more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a gap in the related work section by noting that while it discusses other methods for training NMT models beyond MLE, it does not include any of these methods as baselines. This feedback is clear and actionable, as it provides a specific suggestion for improvement: the authors should consider incorporating these methods as baselines in their experiments. By doing so, the authors can provide a more comprehensive comparison and better contextualize their work. This feedback is mostly helpful as it offers a clear direction for enhancing the paper, but it could be more comprehensive if it suggested specific methods or baselines to include. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential ambiguity in the terminology used in the paper, specifically regarding the term \"efficient proxy.\" It questions whether the authors are referring to a specific proxy or a family of efficient proxies. While the comment identifies a potential issue with the clarity of the terminology, it does not provide explicit guidance on how the authors should clarify this point or suggest specific changes to the text. The action is implicit, as the authors need to infer that they should clarify the terminology, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the terminology used in the paper, particularly the term \"efficient proxy.\" It questions whether the authors are referring to a specific proxy or a family of efficient proxies, which is a clear and specific issue. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The authors can infer that it relates to the introduction or methodology sections where the term is used, but the lack of explicit mention makes it challenging to pinpoint the exact location. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the clarity of the terminology used in the paper, specifically regarding the term \"efficient proxy.\" It points out that the use of the word \"is\" could imply a specific proxy, while the absence of a named \"Efficient Proxy\" suggests the authors might be referring to a family of proxies. This raises a valid concern about the precision of the terminology. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to clarify the terminology to avoid confusion, but the comment does not provide detailed guidance on how to do so. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the terminology used in the paper, specifically regarding the term \"efficient proxy.\" It questions whether the authors are referring to a specific proxy or a family of efficient proxies, which is a crucial point for clarity. However, the comment does not provide specific suggestions or guidance on how the authors might clarify this terminology, leaving the authors with a general understanding of the issue but without actionable steps to address it. As a result, the comment is somewhat helpful, as it highlights an important area for improvement but lacks depth and specificity in its feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this combination of methods or why it is being used. Without further clarification or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not specify which part of the paper this combination is discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in detailing the methods used, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any claim or suggestion that requires verification. The comment is purely descriptive and does not offer any critical feedback or reasoning that would help the authors understand why this combination of methods might be problematic or how it could be improved. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment describes a specific combination of methods used in the paper, including stacking methods from Mirzasoleiman et al., 2020 and Group-learning setting, and then using DBSCAN for clustering. However, it does not provide any critical feedback, suggestions, or reasoning on why this combination might be problematic or how it could be improved. The comment lacks actionable insights or guidance for the authors to address this issue. As a result, it does not offer any meaningful value to the authors in terms of improving their draft. Therefore, the comment is rated as not helpful at all, corresponding to a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The suggestion to explore the resilience of the metric to the choice of random projection is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable, as it does not provide clear instructions or specific steps for the authors to follow. The comment is also somewhat vague, as it does not specify how to analyze the variability or what kind of analysis would be helpful. As a result, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It also implies that the authors might have missed this in the appendix. However, the comment does not specify which part of the paper it is referring to, making it weakly grounded. The comment is specific in its suggestion to explore the resilience of the metric to the choice of random projection, but without explicit references to the appendix or specific sections, the authors may find it challenging to address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors might have missed this in the appendix. However, the comment lacks specific examples or references to support the claim that pathological projection matrices could skew the scores. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the variability of results with the chosen random projection matrix and suggests that pathological projection matrices could skew the MFTMA capacity and width scores. It implies that the authors might have missed this in the appendix, which could be a valuable insight for improving the robustness of their findings. However, the comment lacks specific guidance on how to address this issue or what steps the authors should take to explore the resilience of their metric to different random projection matrices. While it identifies a potential area for improvement, it does not provide actionable advice or detailed suggestions, making it somewhat helpful. The comment could be more helpful if it offered concrete recommendations or examples of how to analyze the variability or what kind of analysis would be beneficial. Overall, the comment is somewhat helpful, as it points out a potential issue but does not fully guide the authors in addressing it.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the performance should be evaluated. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the evaluation of FGT should be used to assess the performance of the proposed method and comparative methods, implying that the evaluation is currently only used for the ablation study. However, the comment does not specify which part of the paper discusses the evaluation of FGT or the ablation study, making it weakly grounded. It is specific in suggesting that the evaluation should be expanded, but without clear guidance on how to do so. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the evaluation of FGT is only used to assess the method performance in the ablation study, suggesting that it should be used to evaluate the performance of the proposed method and comparative methods. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the evaluation is limited to the ablation study. As a result, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the evaluation of the proposed method, noting that the current evaluation of FGT is only used in the ablation study and suggests that it should be used to assess the performance of the proposed method and comparative methods. This feedback is clear and actionable, as it provides a specific direction for improvement. However, it could be more helpful if it included suggestions on how to conduct this additional evaluation or what specific aspects of performance should be considered. Overall, the comment is mostly helpful, as it highlights a clear area for improvement but lacks some depth in terms of actionable guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the model is overly simple, which could be a feature or a bug. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit actions or concrete steps that the authors can take to improve their model. As a result, the authors are left without a clear understanding of what changes are needed or how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the model is overly simple, which could be a feature or a bug. However, it does not specify which part of the paper this issue is related to, such as the methodology, experimental setup, or results. Without this context, the authors cannot determine where to address the issue. Additionally, the comment does not provide specific guidance on how to make the model more complex or how to address the potential bug. Therefore, the comment is not grounded and lacks specificity, making it ungrounded and not specific. This aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the model is overly simple, which could be a feature or a bug. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the model's complexity, suggesting that it might be overly simple. However, it does not provide specific feedback or suggestions on how the authors might address this issue or what changes could be made to enhance the model's complexity. The comment lacks actionable guidance, leaving the authors without a clear understanding of how to improve their draft. As a result, the feedback is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the originality of the paper, specifically questioning how it contributes novelly to the understanding of the winner-take-all property given that similar findings have been reported in previous works. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or enhance the originality of their work. The lack of actionable advice leaves the authors uncertain about how to proceed to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the originality of the paper by questioning the novelty of the findings in light of previous works that have explored the winner-take-all property. It mentions specific previous works, such as NN-based clustering algorithms, and highlights the use of this property in the paper. However, the comment does not specify which part of the paper discusses the findings or how the authors might address the originality concern. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper it addresses. Additionally, the comment is specific in identifying the issue of originality but lacks detailed guidance on how to address it. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's findings are not novel, as similar results have been reported in previous works, particularly in NN-based clustering algorithms. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to seek additional information to address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a concern about the originality of the paper's findings, specifically questioning how the work contributes novelly to the understanding of the winner-take-all property, given that similar findings have been reported in previous works. While the comment identifies a potential issue with the paper's novelty, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the originality of their work. The feedback is somewhat helpful as it highlights an important aspect of the paper that needs attention, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to improve their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of run-times in the experiments to aid readers in applying the method. While the comment provides explicit actions\u2014mentioning the computational cost and including run-time examples\u2014it does not specify how to integrate these details into the main paper or experiments. The actions are clear and concrete, but the lack of detailed guidance on implementation makes the comment somewhat actionable. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method. It also recommends including a rough example of run-times in the experiments to aid readers in applying the method. However, the comment does not specify which part of the paper this should be included in, making it weakly grounded. It is specific in suggesting what needs to be addressed\u2014mentioning the computational cost and providing run-time examples. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should briefly mention the negligible computational cost of CHR in the main paper to motivate the method and include a rough example of run-times in the experiments. This claim is somewhat verifiable as it provides a logical suggestion for improving the paper's clarity and motivation. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the paper by mentioning the negligible computational cost of CHR and suggesting the inclusion of run-time examples in the experiments. This feedback is actionable and offers concrete guidance on how the authors can enhance the motivation and clarity of their work. By highlighting these aspects, the comment helps the authors address potential weaknesses and improve the overall impact of their research. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. The comment is explicit in its suggestion and provides concrete details on how the authors can address the issue by including these comparisons. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a specific example of a baseline to consider, which is testing on a smaller subset of RepoEval. However, the comment lacks detailed reasoning or references to support why these comparisons are necessary or how they would enhance the paper. The suggestion is somewhat vague and could benefit from additional context or justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors include comparisons with existing code completion commercial applications, such as Copilot, for their code completion tasks. It provides a concrete example of a baseline to consider, which is testing on a smaller subset of RepoEval. This feedback is actionable and offers a clear direction for the authors to enhance their work by incorporating additional comparisons. However, the comment could be more helpful if it provided more detailed guidance on how to implement these comparisons or why they are essential. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria used for this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not explicitly instruct the authors to address these questions or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more detail and consider additional tasks or datasets. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. It is specific in its suggestion to provide more detail and consider additional tasks or datasets, but without clear references to specific sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It suggests that the authors should provide more insight into the criteria behind this selection and consider whether other tasks or datasets might yield different insights. However, the comment does not provide any specific reasoning, examples, or references to support why this choice might limit generalizability or what alternative approaches could be considered. Without additional context or justification, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the generalizability of the choice to evaluate on only a subset of the Massive Text Embedding Benchmark (MTEB). It questions whether the criteria for this selection are clear and whether other tasks or datasets might provide different insights. This feedback is somewhat helpful as it highlights an important aspect of the study that could impact the broader applicability of the findings. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or what additional tasks or datasets they could consider. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions regarding the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies that the authors should clarify the reasoning behind this choice. The second question suggests showing performance on test samples from the observational (in) distribution, indicating that the authors should provide this information to better understand the model's performance. While the comment provides explicit questions that guide the authors to clarify and provide additional information, it lacks concrete instructions on how to address these questions or what specific actions to take. Therefore, the comment is somewhat actionable, as it provides a clear direction but does not offer detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses two specific issues related to the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. It explicitly mentions \"shifted-MNIST\" and \"test samples from the observational (in) distribution,\" providing clear grounding for the parts of the paper being discussed. The comment is specific in its suggestions, as it requests clarification on the choice of shift values and the inclusion of performance metrics on specific test samples. This allows the authors to understand exactly what needs to be addressed and how to improve their draft. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises two questions about the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies a need for clarification on the choice of shift values. The second question suggests showing performance on test samples from the observational (in) distribution, indicating a need for additional data or results. However, the comment does not provide any specific reasoning, examples, or references to support these claims. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the questions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two important questions regarding the use of shifted-MNIST and the performance of the model and baselines on test samples from the observational (in) distribution. The first question asks why shift=0 is better than shift~ N ( 0 , \u03c3 2 ) , which implies that the authors should clarify the reasoning behind this choice. The second question suggests showing the performance of the model and baselines on test samples from the observational (in) distribution, indicating that the authors should provide this information to better understand the model's performance. While the comment identifies areas for improvement and provides specific questions for clarification, it lacks detailed guidance on how to address these issues or what specific actions the authors should take. The feedback is somewhat helpful as it directs the authors to areas that need further explanation and analysis, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of detail in the experimental description, which makes it difficult for readers to judge the results. It suggests that the authors should provide more clarity to allow readers to better understand the experimental setup. However, the comment does not explicitly instruct the authors on what specific aspects of the description need to be improved or how to enhance clarity. While the authors can infer that they should add more detail, the action is not concrete and lacks specific guidance on what to include. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"experiment description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the lack of detail in the experimental description, which is crucial for readers to judge the results. The comment provides clear guidance on what needs to be improved, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of experimental details is lacking in clarity, making it difficult for readers to judge the results. However, the comment does not provide specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the lack of detail in the experimental description, which hinders the reader's ability to judge the results. It provides a clear and actionable suggestion to improve the clarity of the experimental details, making it a valuable feedback for the authors. However, the comment could be more helpful if it offered specific examples or guidance on how to enhance the clarity of the description. Despite this, the feedback is mostly helpful as it directs the authors towards a critical area for improvement, allowing them to enhance the manuscript. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should provide more explanation to clarify certain aspects, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically mentions the CBR contribution and requests a discussion on the implications of minimizing different terms in Equation 3. However, the comment does not explicitly instruct the authors to add more explanation or discussion, nor does it provide detailed guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should provide more explanation, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically mentions the CBR contribution and requests a discussion on the implications of minimizing different terms in Equation 3. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the need for more explanation and discussion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper should provide more explanation to clarify certain aspects, particularly regarding the main contributions and the discussion of different optimization strategies. It requests a discussion on the implications of minimizing different terms in Equation 3. However, the comment lacks specific examples or references to support the claim that more explanation is needed. While it suggests a direction for improvement, it does not provide detailed reasoning or evidence to justify the need for additional explanation. Therefore, the claim is somewhat verifiable, as it is based on a logical suggestion but lacks sufficient support.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a need for more explanation in the paper, particularly regarding the main contributions and the discussion of different optimization strategies. It specifically requests a discussion on the implications of minimizing different terms in Equation 3, providing a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to structure this discussion or what specific aspects of the optimization strategies should be highlighted. Overall, the feedback is somewhat helpful as it points out a crucial area for improvement but lacks depth and detail in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This provides a clear and explicit action for the authors to take, as they can directly incorporate this definition into their draft. The comment is specific in its suggestion, detailing exactly what needs to be added to improve the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. However, it does not specify which part of the paper this definition should be included in, such as a specific section or paragraph. This lack of grounding makes it difficult for the authors to identify the exact location where the definition should be added. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This is a clear and logical suggestion that provides a specific action for the authors to take. However, the comment does not provide any additional context, examples, or references to support the claim that this definition is necessary or beneficial. While the suggestion is logical and actionable, it lacks depth and specific guidance, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including a formal or intuitive definition of treewidth, which is central to the paper\\'s proofs. This feedback is specific and actionable, as it provides a clear direction for the authors to improve their draft by adding a crucial element that supports the logical flow and understanding of the paper. By including this definition, the authors can enhance the clarity and coherence of their work, making it more accessible and easier to follow. The comment is well-structured and provides a direct suggestion for improvement, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the paper's self-contained nature and suggests that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments. While the comment identifies specific issues and requests, it does not provide explicit guidance on how to address these concerns or what specific actions the authors should take to improve the paper. The actions are implicit and somewhat vague, as the authors are left to infer how to make the paper self-contained and reproducible. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the paper not being self-contained understandable given the NIPS format, suggesting that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments to allow reproduction of their results. However, the comment does not specify which sections or parts of the paper are affected by this issue, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the necessity of the supplementary material and the request for source code release. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not self-contained understandable given the NIPS format, suggesting that the supplementary material is necessary for understanding large parts of the main paper and ensuring reproducibility. It also requests the authors to release the source code of their experiments to allow reproduction of their results. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of evidence or references weakens the verifiability of the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical issue with the paper's self-contained nature, noting that it is not understandable given the NIPS format and that the supplementary material is necessary for a comprehensive understanding and reproducibility. It also requests the authors to release the source code of their experiments, which is a valuable suggestion for enhancing the paper's impact and allowing others to reproduce the results. However, the comment could be more helpful by providing specific examples of where the supplementary material is needed or suggesting additional steps the authors could take to improve the paper's self-containment. Despite this, the feedback is mostly helpful as it highlights important areas for improvement and encourages the authors to enhance the paper's accessibility and reproducibility.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the necessity of the added complexity of using multiple INs at different speeds in the dynamics predictor. It suggests that the design choice is not ablated, and the authors should consider whether one IN would suffice. However, the comment does not provide explicit guidance on how to address this question or what actions the authors should take to clarify or resolve it. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in questioning the design choice, the absence of explicit grounding makes it challenging for the authors to understand the context. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. However, it does not provide any evidence, reasoning, or references to support the claim that this design choice is important or how it impacts the model. Without specific justification or examples, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of using multiple INs at different speeds in the dynamics predictor, suggesting that the design choice is not ablated. It prompts the authors to consider whether one IN would suffice, which is a relevant and important question for understanding the model's complexity and efficiency. However, the comment does not provide any guidance or suggestions on how to address this question or what experiments might be needed to substantiate the claim. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the experimental results, noting that the opponent's performance is not as good as expected because it does not aim to maximize the multi-agent payoff. However, it does not provide explicit or implicit actions for the authors to take in response to this observation. The comment lacks guidance on how the authors might address this issue or what changes could be made to the experiments. As a result, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the opponent not aiming to maximize the multi-agent payoff, explaining why the results are not surprising. This provides clear guidance on what needs to be addressed in the experiments. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experiments do not come as a complete surprise because the opponent does not aim to maximize the multi-agent payoff, as evidenced by the experiments where the opponent maximizes classical SE and AE. However, the comment lacks specific examples or detailed reasoning to substantiate this claim. It does not provide a clear explanation of why the opponent's behavior is not surprising or how this observation impacts the overall findings. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on an observation but lacks thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific observation about the experimental results, noting that the opponent's performance is not as good as expected because it does not aim to maximize the multi-agent payoff. This observation is based on the fact that the opponent maximizes classical SE and AE instead of the multi-agent payoff. However, the comment does not provide actionable feedback or suggestions on how the authors might address this issue or improve their draft. It lacks depth and guidance, making it somewhat helpful as it highlights a potential area for improvement but does not offer concrete steps for the authors to take. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. It implies that the authors should clarify why they chose REINFORCE, potentially referencing the attention model paper they are building upon. However, the comment does not explicitly instruct the authors to include this rationale in their draft or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a rationale and understand how to implement it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. However, it does not specify which part of the paper this choice is made or which section discusses the training methodology. This lack of grounding makes it difficult for the authors to identify the exact part of the paper that needs revision. While the comment is specific in suggesting the need for clarification, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a rationale for their choice of the REINFORCE algorithm for training, specifically in comparison to other algorithms like PPO. The comment implies that the authors should clarify why they chose REINFORCE, potentially referencing the attention model paper they are building upon. However, the comment lacks specific examples or detailed reasoning to support the claim that the choice of algorithm is critical or requires further justification. Without additional context or evidence, the claim remains somewhat verifiable, as the authors would need to provide more detailed reasoning to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to improve their draft by explaining the rationale behind their choice of the REINFORCE algorithm for training. It specifically asks for clarification on why this algorithm was chosen over alternatives like PPO, which is relevant to the attention model paper they are building upon. This feedback is valuable as it prompts the authors to provide a more detailed justification for their methodological choices, enhancing the clarity and depth of their work. However, the comment could be more helpful if it offered additional guidance on how to articulate this rationale effectively. Overall, the comment is mostly helpful, as it identifies a specific area for improvement and encourages the authors to provide more detailed reasoning.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the statement. As a result, the authors are left without any actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not specify which part of the paper this statement is located in, making it difficult for the authors to pinpoint the exact issue. The comment is specific in its critique of the statement but lacks grounding as it does not provide clear guidance on how to address the confusion or clarify the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left to interpret the statement and its implications, making it difficult to verify the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses confusion about a statement in Theorem 5.1, suggesting that it might indicate a disadvantage of MMD DRO. While the comment identifies a potential issue with the statement, it lacks specific guidance or suggestions on how the authors might address this confusion or clarify the issue. The feedback is somewhat helpful as it points out a potential area of concern, but it does not provide actionable steps or detailed explanations to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper lacks insight into this aspect, which is important for task domain adaptation. However, the comment does not provide explicit guidance on how to address these questions or what specific actions the authors should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact section being addressed. The comment is weakly grounded as it lacks specific references to sections or figures. It is also specific in detailing the questions that need to be addressed, but the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It suggests that the paper lacks insight into this aspect, which is important for task domain adaptation. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the paper lacks insight into this aspect. The lack of evidence or justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises important questions about the use of morphologic segmentation across different domains and whether it should be conducted differently or remain invariant. It highlights a potential gap in the paper's discussion, noting that the assumption of invariance might not be accurate and that the paper lacks insight into this aspect. However, the comment does not provide specific guidance or suggestions on how the authors might address these questions or improve their draft. While it identifies a relevant area for clarification, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it provides some insight but lacks depth and guidance for the authors to improve their work.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are explicit and provide clear guidance on what the authors should clarify in their draft. The feedback is concrete, as it directly instructs the authors to address these specific aspects of their method. Therefore, the comment is highly actionable, as it provides explicit and detailed instructions for improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. While the questions are specific, the comment does not explicitly mention which part of the paper these questions relate to, such as a particular section or figure. This makes it weakly grounded, as the authors may need to infer the relevant parts. However, the questions are clear and specific, providing detailed guidance on what needs to be clarified. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are factual and do not contain subjective opinions or claims that require verification. The comment is a normal statement, as it does not provide any additional information or reasoning to support the questions. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two specific questions about the object detection based attention mechanism, asking whether it is performed on the image or a convolutional feature map and whether rescaling is involved. These questions are clear and actionable, providing the authors with specific areas to clarify in their draft. By addressing these questions, the authors can improve the clarity and completeness of their method description. The feedback is detailed and constructive, offering a clear direction for improvement. Therefore, the comment is mostly helpful, as it provides actionable guidance but could be more comprehensive if it suggested specific ways to address the questions or provide additional context.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that utilize summary tokens. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this gap. The authors are left to infer that they should include a discussion of these works, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Set Transformer\" and provides a link, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing discussion about the Set Transformer and other related works that use summary tokens. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is missing a discussion about the Set Transformer and other related works that use summary tokens. However, it does not provide any specific reasoning or evidence to support this claim. Without additional context or references, the authors are left to question the validity of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out the absence of a discussion about the Set Transformer and other related works that use summary tokens. This is a valuable piece of feedback as it highlights an area where the authors could enhance the comprehensiveness and depth of their work. However, the comment lacks specific guidance on how the authors might address this gap, such as suggesting particular aspects of the Set Transformer to discuss or how to compare their approach with other methods. While it provides a clear direction for improvement, the lack of detailed suggestions makes it somewhat helpful. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide explicit guidance on what needs to be addressed or how to improve the analysis. The authors are left to infer that they should either provide a more detailed analysis or acknowledge that this aspect is not covered. This lack of explicit action or guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its focus on the theoretical support, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that this is an essential theoretical support. Without additional context or justification, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the theoretical support for the use of Fourier features in accelerating NTK convergence, specifically in the high-frequency range. It suggests that the authors may have overlooked this aspect or that it is not adequately analyzed. This feedback highlights a potential gap in the paper's theoretical foundation, which is crucial for understanding the merits of Fourier features. However, the comment does not provide specific guidance or suggestions on how to address this gap or improve the analysis. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to their draft. The comment lacks concrete guidance on how to improve the paper, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its request for details, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the methodology, specifically regarding how the network is trained to fit the residual instead of directly learning the input-output mapping. However, it does not provide any claim, suggestion, or critique that requires verification. The comment is purely factual and descriptive, lacking any opinions or assertions that need to be substantiated. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the methodology, noting that the authors do not provide details on how the network is trained to fit the residual instead of directly learning the input-output mapping. This feedback is valuable as it highlights a potential gap in the clarity and completeness of the paper. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies an area for improvement, it does not provide concrete steps or examples for the authors to follow, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not explicitly instruct the authors to provide more details about the experiment setup or how it relates to the BadNets paper. While the authors can infer that they need to clarify the experimental setup, the action is implicit and somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not specify which part of Section 3.3 is being referred to, making it weakly grounded. The comment is specific in asking for details about the experiment setup, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section that needs clarification. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point asks for clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment does not contain a claim or assertion that requires verification. It is a request for clarification and additional information, which is helpful but does not involve making a claim that needs to be substantiated. Therefore, this comment is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment requests clarification on the experiment setup in Section 3.3, specifically mentioning data augmentation methods and learning rate. It also provides a reference to BadNets, which is relevant to the topic of backdooring attacks. However, the comment lacks specificity and does not provide detailed guidance on how the authors should address this request. While it identifies an area for improvement, it does not offer actionable steps or suggestions for the authors to take. Therefore, the comment is barely helpful, as it provides a vague indication of what needs clarification but does not offer concrete advice or direction for the authors to follow.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not provide explicit instructions or suggestions on how the authors should address this concern, such as conducting a statistical significance test or providing justification for the closeness of the numbers. While the comment implies that the authors should consider this aspect, it lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable, as it identifies a potential issue but does not provide detailed steps for resolution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. However, it does not specify which part of the paper this comparison is made, nor does it provide any guidance on how to address this issue. The authors cannot confidently determine which section or part of the paper is being referenced, making the comment weakly grounded. Additionally, the comment is specific in questioning the statistical significance of the numbers, but without further details or suggestions, it remains somewhat specific. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the statistical significance of the numbers when comparing the proposed method with baselines. It does not contain a subjective claim or suggestion, but rather a request for clarification or further analysis. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a valid concern about the statistical significance of the numbers when comparing the proposed method with baselines. It questions whether the closeness of the numbers suggests a lack of statistical significance, which is a crucial aspect for validating the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue, such as conducting a statistical significance test or providing additional analysis. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it highlights an important consideration but does not offer comprehensive guidance for the authors.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference in HMMs, specifically focusing on common inference tasks. It asks which tasks can be computed exactly or approximately with an NP-SPEC-HMM. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks concrete actions or detailed instructions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the focus on learning HMMs with non-parametric emission distributions, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the impact of these distributions on inference and asks about common inference tasks in discrete HMMs, such as filtering, smoothing, and marginal observation likelihood. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the impact of non-parametric emission distributions on inference in HMMs, specifically asking which common inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. While the question is clear and directly relates to the paper's focus, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks depth and does not offer any guidance or justification for the question, making it difficult for the authors to understand the basis of the inquiry. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the impact of non-parametric emission distributions on inference in HMMs, specifically asking which common inference tasks can be computed exactly or approximately with an NP-SPEC-HMM. This question highlights a potential gap in the paper's discussion of how these distributions affect inference. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. It lacks actionable feedback, leaving the authors without clear direction on how to enhance their work. Therefore, the comment is barely helpful, as it identifies a relevant area for improvement but does not offer any constructive advice or suggestions.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a deficiency in the analysis of experimental results, specifically noting that the authors mention the poor performance of the scope prompting method on GPT-3.5-turbo but do not provide any analysis of the underlying reasons. This feedback is explicit and directs the authors to address the lack of analysis. However, it does not provide specific guidance on what kind of analysis to include or how to approach it. The action is clear but somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the analysis of experimental results, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT-3.5-turbo, providing a clear indication of what needs to be addressed. This level of detail helps the authors understand exactly where the issue lies and what improvements are needed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the analysis of experimental results is insufficient, specifically noting that the authors mention the poor performance of the scope prompting method on GPT-3.5-turbo but do not provide any analysis of the underlying reasons. This claim is somewhat verifiable as it highlights a gap in the analysis, but it lacks specific examples or references to support the claim. The authors are encouraged to provide a more detailed analysis, but the comment does not offer concrete guidance on how to do so. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the analysis of experimental results, specifically noting that the authors mention the poor performance of the scope prompting method on GPT-3.5-turbo but fail to provide any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to address the lack of analysis and provide a more comprehensive understanding of the results. By highlighting this deficiency, the comment encourages the authors to enhance the depth and rigor of their experimental analysis, which is crucial for the overall quality and impact of the paper. Therefore, the comment is mostly helpful, as it provides a clear direction for improvement but could be further enhanced with specific suggestions for analysis.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the necessity of the low-rank factorization in the introduction, given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment does not provide explicit guidance on how the authors should address this point or what specific aspects of the discussion need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the necessity of the low-rank factorization in the introduction, given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment does not specify which part of the paper this relates to, making it weakly grounded. It is specific in questioning the relevance of the low-rank factorization in the context of the main result, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of the low-rank factorization in the introduction, given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. However, the comment lacks specific examples or detailed reasoning to support the claim that the low-rank factorization is unnecessary or that the implications for low-rank matrix factorization are significant. Without concrete evidence or references, the authors may find it difficult to fully understand and address the feedback. Therefore, the comment is considered borderline verifiable, as it provides some basis for discussion but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the motivation in the introduction, specifically questioning the necessity of low-rank factorization given that the main result focuses on polytopes. It suggests that if the result has implications for low-rank matrix factorization, these should be explicitly discussed. This feedback is somewhat helpful as it points out a potential gap in the motivation and encourages the authors to consider the broader implications of their work. However, the comment could be more helpful if it provided specific examples or guidance on how to address the issue. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point mentions that an alternating direction method is used to solve a min-min problem but does not specify which method is being referred to. This lack of specificity makes it difficult for the authors to understand which method is being discussed and how it relates to the min-min problem. Without additional context or clarification, the authors are left without a clear action to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what is being discussed or how the authors should address the issue. The comment lacks both grounding and specificity, making it difficult for the authors to understand and respond to it effectively. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point is a factual statement about the use of an alternating direction method to solve a min-min problem. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is brief and lacks specificity, as it only mentions that an alternating direction method is used to solve a min-min problem without specifying which method is being referred to. This lack of detail makes it difficult for the authors to understand the context or how to address the issue. The comment does not provide any actionable feedback or suggestions for improvement, leaving the authors with no guidance on how to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific suggestions or actions for the authors to take to address this issue. It lacks concrete guidance on how to enhance the novelty of their work or what specific aspects of their approach could be improved to differentiate it from existing methods. As a result, the authors are left without a clear understanding of how to respond to this critique and improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to understand where the comment is relevant and how to address it. Additionally, the comment is specific in its critique of the novelty, but without grounding, it is challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the novelty of the paper is limited because interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the novelty of the paper, suggesting that interpreting the prediction of deep neural networks using a linear model is not a new approach for model interpretation. While this observation is accurate, the comment lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or suggestions for improvement, the authors may find it challenging to respond effectively to this critique. Therefore, the comment is barely helpful, as it points out a concern but does not provide substantial guidance for the authors to improve their draft.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. While the comment provides a clear direction for improvement, it does not offer specific guidance on how to expand the experiments or what additional baselines should be included. The authors know that they need to address these limitations but lack detailed instructions on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks concrete details on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not specify which parts of the paper these issues are related to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the issues with the experiments, it lacks grounding as it does not provide clear references to the relevant sections of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments should be more comprehensive and general, specifically noting that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand the basis of these suggestions or how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the experiments section, noting that they should be more comprehensive and general. It highlights the limitations of the current experiments, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. This feedback provides a clear direction for the authors to enhance their experimental setup, but it lacks detailed guidance on how to achieve this comprehensiveness or generalization. While the comment is somewhat helpful as it points out areas for improvement, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. While it implies that this addition would be beneficial, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the table would benefit from such an addition. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to incorporate the suggested approach. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, it does not specify which part of Table-1 would benefit from this addition or what specific issues the authors are addressing. The comment lacks grounding as it does not provide clear guidance on which section or aspect of the paper needs improvement. It is also specific in suggesting a particular approach, but without context, it is difficult for the authors to understand how to apply this suggestion. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. However, it does not provide any reasoning, examples, or references to support why this addition would be beneficial or how it would improve the paper. The comment lacks specific justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests adding an optimization-based meta-learning approach, such as MAML or implicit-MAML, to Table-1. This feedback is somewhat helpful as it points out a potential area for improvement by suggesting a specific approach that could enhance the paper. However, the comment lacks depth and does not provide detailed reasoning or guidance on how to implement this suggestion effectively. The authors would need to infer the exact steps to incorporate the suggested approach, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using few-shot examples for Chain-of-Thought (CoT). However, it does not provide explicit guidance on how the authors should conduct or present this ablation study. The action is implicit, as the authors need to infer that they should include an ablation study to justify their prompt choice. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using few-shot examples for Chain-of-Thought (CoT). However, it does not specify which part of the paper this issue is related to, such as the methodology or experimental setup sections. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in that it identifies a lack of explanation regarding the prompt choice and suggests a potential improvement, but without clear grounding, it is difficult for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks an ablation study explaining the choice of prompt, specifically mentioning the potential benefits of using few-shot examples for Chain-of-Thought (CoT). However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the lack of an ablation study explaining the choice of prompt, particularly the use of few-shot examples for Chain-of-Thought (CoT). This feedback is somewhat helpful as it highlights a potential gap in the paper's analysis and suggests a way to strengthen the methodology. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the ablation study or why this specific choice of prompt is important. Without additional context or suggestions, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, it does not provide explicit guidance on how the authors should revise the text to address this concern. The comment implies that the authors need to clarify the distinction between causal mechanisms and temporal relationships, but it lacks specific instructions on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Page 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of the term \"causal mechanisms,\" recommending careful consideration of its distinction from temporal relationships. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point on page 1 suggests that the term \"causal mechanisms\" should be used carefully, as it is different from a temporal relationship. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this distinction is important or how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment on page 1 points out a potential issue with the use of the term \"causal mechanisms,\" suggesting that it should be used carefully as it is different from a temporal relationship. This feedback is clear and identifies a specific area for improvement, but it lacks detailed guidance on how the authors should revise the text to address this concern. While it provides a starting point for the authors to consider, the comment could be more helpful if it offered suggestions on how to clarify the distinction or provide examples of how to use the term appropriately. Therefore, the comment is somewhat helpful, as it identifies a meaningful issue but does not fully guide the authors in addressing it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment implies that the authors should consider whether the performance drop is significant enough to support the claim of \"better than random.\" However, it does not provide explicit guidance on how to address this concern or what specific aspects of the performance drop need to be clarified. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more evidence or justification for the claim. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"You write: 'Evidently, replacing any of the procedure steps of XAIFOOLER with a random mechanism dropped its performance'\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the claim that \"better than random\" is a strong demonstration of capability, providing a clear direction for the authors to address this concern. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment does not provide any evidence, reasoning, or references to support this claim. It lacks specific examples or detailed explanations to substantiate the assertion that the performance drop is significant enough to be considered \"better than random.\" Without additional context or justification, the claim remains unsubstantiated, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment questions the claim that replacing procedure steps of XAIFOOLER with a random mechanism results in a performance drop, specifically questioning whether this demonstrates a strong capability. The comment is somewhat helpful as it identifies a potential area for clarification or further justification in the paper. However, it does not provide specific guidance or suggestions on how the authors might address this concern or strengthen their claims. The feedback is clear but lacks depth and actionable advice, making it somewhat helpful rather than fully helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide explicit guidance on how to incorporate this discussion into the draft or what specific aspects of the results should be addressed. The action is implicit, as the authors need to infer that they should add a discussion related to the mentioned paper. While the suggestion is concrete in terms of the topic, the lack of explicit guidance on how to implement it makes the comment somewhat actionable. Therefore, this comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not specify which part of the paper this discussion should be included in, making it weakly grounded. It is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". However, the comment does not provide any specific reasoning, examples, or references to support why this discussion is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should include a discussion of how their results relate to the lower bounds on kernel learning using low-rank approximation, as discussed in the paper \"On the Complexity of Learning with Kernels\". This feedback is somewhat helpful as it identifies a specific area for improvement by suggesting a relevant discussion that could enhance the paper's context and depth. However, the comment lacks detailed guidance on how to incorporate this discussion or what specific aspects of the results should be addressed. While it provides a direction for improvement, it does not offer comprehensive advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the novelty of using PCA to reduce the interaction count and suggests that the significance of the paper's results is unclear. It also provides a rationale for why PCA is intuitive and requests clarification on whether the assumptions are met, referencing a specific paper. While the comment identifies a potential issue with the novelty and significance of the paper, it does not explicitly instruct the authors to address these concerns or provide specific guidance on how to improve the paper. The action is implicit, as the authors need to infer that they should discuss the novelty and significance of their approach and address the assumptions of PCA. However, the comment lacks concrete details on how to do so, making it somewhat actionable. Therefore, the comment is rated as 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the novelty of using PCA to reduce the interaction count and questions the significance of the paper results. It provides a rationale for why PCA is intuitive and requests clarification on whether the assumptions are met, referencing a specific paper. However, the comment does not explicitly mention which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the relevant part. The comment is specific in detailing the concern about the novelty and significance of the results and the assumptions of PCA. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the novelty of using PCA to reduce the interaction count and the clarity of the paper's results. It provides a rationale for why PCA is intuitive and requests clarification on whether the assumptions are met, referencing a specific paper. This provides some support for the claim, as it offers a logical explanation and references external work. However, the comment could be more robust by including more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment raises a question about the novelty of using PCA to reduce the interaction count and the clarity of the paper's results. It provides a rationale for why PCA is intuitive and requests clarification on whether the assumptions are met, referencing a specific paper. This feedback is somewhat helpful as it identifies a potential area for improvement in the paper's novelty and significance. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these concerns or enhance the clarity of their results. Without actionable advice or detailed feedback, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and asking for a comparison with relation extraction/generation models in few-shot settings. While the comment identifies a potential issue with the choice of models, it does not provide explicit guidance on how the authors should address this concern or what specific changes might be necessary. The action is implicit, as the authors would need to infer that they should consider using more advanced models or compare their performance with relation extraction/generation models. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and asking for a comparison with relation extraction/generation models in few-shot settings. However, the comment does not specify which part of the paper discusses the choice of models or where the authors might find more information. This lack of grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. While the comment is specific in its request for comparison, the absence of explicit references or sections makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of few-shot RC models in the paper, suggesting that they are not state-of-the-art and asking for a comparison with relation extraction/generation models in few-shot settings. The comment provides specific references to support the claim that the models used are not state-of-the-art, which helps the authors understand the basis of the critique. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the choice of few-shot RC models used in the paper, suggesting that they are not state-of-the-art. It also raises a question about how the performance of these models compares to relation extraction/generation models in few-shot settings. While the comment points out a potential area for improvement, it does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their models. The feedback is somewhat helpful as it highlights a potential area for further exploration and comparison, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide results for the discussion of using sequential MCB vs a single MCT layers for the decision head. However, it does not specify how these results should be presented or what aspects of the results are important to highlight. The comment implies that the authors should include results, but it lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the discussion of using sequential MCB vs a single MCT layers for the decision head, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests more information about what was observed in this discussion, indicating that the authors need to provide results or detailed observations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the discussion of using sequential MCB vs a single MCT layers for the decision head, noting that no results were shown. However, it does not provide any specific reasoning, examples, or references to support why this observation is important or how it impacts the paper. The comment lacks detailed justification or context, making it difficult for the authors to understand the significance of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of the paper that requires further clarification, namely the discussion of using sequential MCB versus a single MCT layer for the decision head. It notes that no results were shown, which is a significant gap in the analysis. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what results they should include. While it highlights an important area for improvement, the lack of actionable feedback limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a critical gap but does not offer concrete suggestions for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. While it implies that the authors should consider this aspect, it does not provide explicit guidance on how to control the number of distribution sets or what specific actions should be taken. The comment is somewhat vague, as it leaves the authors to infer the need for further exploration and experimentation. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not specify which part of the paper this question pertains to, such as a specific section or table. This makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in its question about the number of distribution sets, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. However, it does not provide any specific reasoning, examples, or references to support why this choice is questionable or what impact it might have. The comment lacks detailed justification or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of 20 distribution sets and suggests exploring the impact of using fewer sets. This feedback is somewhat helpful as it identifies a potential area for further investigation or clarification. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue. The comment could be more helpful if it offered actionable advice or examples of how to control the number of distribution sets or what implications this choice might have. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. While the comment provides a clear direction for improvement by recommending the use of transformer models, it does not specify which transformer models should be used or how the experiments should be conducted. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. However, it does not specify which transformer models should be used or how the experiments should be conducted. The comment is fully grounded as it mentions the type of models being used, but it is not specific because it does not provide detailed guidance on which models to use or how to conduct the experiments. Therefore, this comment is fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the perplexity experiments should be conducted using transformer-based language models, which are more current and relevant to the field. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, indicating that using transformer models would better align the paper with current NLP trends. However, it lacks specific examples or references to support the claim, which could enhance its verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the perplexity experiments, noting that they are conducted on obsolete language models that are rarely used in current NLP research. The comment suggests that the authors should consider using transformer-based language models, which are more relevant and widely used in the field. This feedback is clear and actionable, providing a specific direction for improvement that aligns with current trends in NLP. By recommending the use of transformer models, the comment offers valuable guidance for enhancing the paper's relevance and impact. However, it could be more helpful if it provided specific examples of transformer models or suggested additional experiments to further align the paper with current NLP trends. Overall, the comment is mostly helpful as it effectively highlights a critical area for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the estimation process. The comment lacks concrete guidance on what needs to be done to clarify or improve the estimation of mu. As a result, the authors are left without a clear understanding of how to respond to this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section or context. The comment is specific in its critique of the estimation process but lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the estimation of mu, which is described as the proportion of missing observations. However, it does not provide any specific reasoning, examples, or references to support why this estimation is unclear or problematic. The comment lacks detailed justification or context, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the estimation of mu, which is described as the proportion of missing observations. However, the comment does not provide any specific guidance or suggestions on how to address this issue or improve the estimation process. It lacks actionable feedback, leaving the authors without a clear understanding of how to respond or enhance their work. Therefore, the comment is barely helpful, as it highlights a concern but does not offer any constructive or actionable advice. The score of 2 aligns with this assessment.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide high-probability bounds instead of only bounds in expectation. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides explicit guidance on what should be added, it lacks specific instructions on how to implement these changes, such as which parts of the paper should be revised or what specific techniques should be used to derive the high-probability bounds. The action is somewhat explicit but could be more concrete with detailed guidance on implementation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of providing only bounds in expectation and suggests adding high-probability bounds, which is a specific and actionable suggestion. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. However, the comment does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The specificity of the comment is high as it clearly specifies what needs to be addressed in terms of improving the bounds and robustness measures. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that only bounds in expectation are provided and suggests that high-probability bounds would be more informative. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim about the current bounds. The reasoning is somewhat clear but could be strengthened with additional details or references to similar work. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the paper should provide high-probability bounds instead of only bounds in expectation. It also recommends adding measures of robustness, such as error bars or standard deviation, to the experiments. This feedback is actionable and provides clear guidance on what the authors should do to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it included specific examples or suggestions on how to derive the high-probability bounds or how to implement the robustness measures. Despite this, the comment offers valuable insights that would significantly improve the draft, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the paper's motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the model to explicitly enforce diversity. The authors are left without guidance on how to proceed, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the paper's motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. However, the comment does not specify which part of the paper discusses the motivation of diversity or how the authors might address this issue. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying the issue with the model's explicit enforcement of diversity, but it lacks guidance on how to improve the model. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the paper's motivation of \"diversity,\" noting that the word is in the title but the model does not explicitly enforce it. The reviewer expresses disappointment that the diversity term is not incorporated into the model, despite the initial excitement. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the model does not enforce diversity explicitly. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some indication of a concern but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment highlights a significant concern regarding the paper's motivation of \"diversity,\" noting that the word is prominently featured in the title but the model does not explicitly enforce it. The reviewer expresses disappointment with this discrepancy, suggesting that the initial excitement about incorporating the diversity term into the model was not fully realized. However, the comment lacks actionable suggestions or guidance on how the authors might address this issue or improve the model to explicitly enforce diversity. Without specific advice or examples, the authors are left without a clear path forward, making the comment somewhat helpful. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any guidance on what these missing experiments should include or how they should be conducted. The authors are left without any actionable steps to take, as they do not know what additional experiments to add or how to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not specify which part of the paper these experiments are intended to address or how they relate to the existing content. The authors cannot confidently determine which sections or aspects of the paper need to be expanded or improved based on this feedback. Additionally, the comment lacks specificity in detailing what is missing or how these experiments should be conducted. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some experiments are missing, specifically mentioning contrastive learning and adversarial learning. However, it does not provide any justification or reasoning for why these experiments are missing or how their absence impacts the paper. Without additional context or explanation, the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that some experiments are missing, particularly those related to contrastive learning and adversarial learning. However, the comment lacks depth and does not provide any suggestions or guidance on how these missing experiments could be addressed or what additional content might be included. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap between the lower and upper bounds in the paper, specifically mentioning that the existing bound with the independence number might be better for some graphs. It also notes that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment does not provide explicit guidance on how the authors should address this gap or what specific changes might be necessary. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a gap between the lower and upper bounds in the paper, specifically mentioning the discrepancy between \\\\sqrt(\\\\beta) and \\\\beta^{1/3}. It also notes that the existing bound with the independence number might be better for some graphs and that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment does not specify which part of the paper discusses these bounds or results, making it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a gap between the lower and upper bounds in the paper, specifically mentioning that the existing bound with the independence number might be better for some graphs. It also notes that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment lacks specific examples or detailed reasoning to support the claim that the existing bound might be better in certain cases. Without concrete evidence or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a gap between the lower and upper bounds in the paper, specifically mentioning that the existing bound with the independence number might be better for some graphs. It also notes that this issue is relevant for the results on the adaptive adversary and counterfactual feedback. However, the comment lacks specific guidance or suggestions on how the authors might address this gap or improve their results. While it points out an area for potential enhancement, it does not provide actionable advice or detailed insights into how the authors could achieve this. Therefore, the comment is somewhat helpful, as it highlights a potential improvement but does not offer comprehensive guidance for the authors to implement it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this issue. The comment lacks guidance on how the authors might investigate or resolve this discrepancy, leaving them without a clear path forward. As a result, the comment is unactionable, as it does not offer any actionable feedback or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment refers to \"the reported ablation studies in Table 2,\" which provides a clear reference point for the authors to understand the context of the issue. However, it does not specify which part of the table or section of the paper the ablation studies are located, making it weakly grounded. The comment is specific in questioning the results of the ablation studies, particularly the performance of the complete loss function compared to those with some terms missing. This specificity allows the authors to understand the exact issue being raised. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the results of the ablation studies in Table 2, specifically noting that the complete loss function performed worse than those with some terms missing. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this observation is significant or how it might impact the conclusions of the study. Without additional context or justification, the claim remains unverifiable, as the authors are left without a clear understanding of the issue or how to address it. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue in the reported ablation studies, noting that the complete loss function performed worse than those with some terms missing. This observation raises a question about the results and their implications, which could be a valuable point for the authors to address. However, the comment lacks actionable suggestions or guidance on how the authors might investigate or resolve this discrepancy. While it points out a potential area for further analysis, it does not provide any specific steps or insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights a potential issue but does not offer detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include an experiment where the image is occluded, similar to a previous suggestion. It provides two reasons for this suggestion: (a) to simulate irregularity in neural/behavioral data, such as keypoint detection failures, and (b) to allow the inspection of the model's long-range inference capacity. The comment implies that these experiments should be included in the final version of the paper, unless the authors can provide a reason for exclusion. However, the action is implicit, as the authors need to infer that they should run these experiments. The suggestion is somewhat vague, as it does not provide specific details on how to implement the occlusion or how to analyze the results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests an experiment where the image is occluded, similar to a previous suggestion. It provides two reasons for this suggestion: (a) to simulate irregularity in neural/behavioral data, such as keypoint detection failures, and (b) to allow the inspection of the model\\'s long-range inference capacity. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. It is specific in detailing what the authors should do\u2014include an experiment with occluded images and explain how it simulates irregularity and allows for the inspection of long-range inference capacity. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the model\\'s long-range inference capacity. While the suggestion is logical and provides a rationale for why such an experiment would be beneficial, it lacks specific examples or references to similar studies that could support the claim. The comment is somewhat verifiable as it offers a clear reasoning for the suggestion, but it could be strengthened with additional evidence or examples. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for an additional experiment that could enhance the paper by simulating irregularity in neural/behavioral data and allowing for the inspection of the model\\'s long-range inference capacity. The suggestion is clear and actionable, as it outlines the type of experiment that would be beneficial and provides reasoning for why it would be valuable. However, the comment could be more helpful if it included details on how to implement the occlusion or how to analyze the results of the experiment. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, allowing the authors to consider adding this experiment to their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the abstract contains a statement that is unclear and suggests that it should be more high-level, avoiding technical details. While the comment identifies a specific issue with the abstract, it does not provide explicit guidance on how to revise the abstract to make it clearer or more high-level. The authors are left to infer that they need to rephrase the abstract to remove the technical details and make it more accessible. This lack of explicit guidance makes the comment somewhat actionable, as the authors know what needs to be addressed but are not given concrete steps to take. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the abstract of the paper, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly identifies the issue with the abstract, namely the unclear statement about ensuring low-rank feature subspaces, a small number of attacked samples, and other mild assumptions. The comment suggests that the abstract should be more high-level and less technical, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the abstract is unclear and suggests that it should be more high-level, avoiding technical details. However, the comment does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the abstract is unclear or how to revise it to be more high-level. Therefore, the comment is considered unverifiable, as it lacks sufficient justification or evidence to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the abstract, noting that it is unclear and contains technical details that might be unnecessary for a high-level overview. The comment suggests that the abstract should be more accessible and less technical, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific suggestions or examples of how to rephrase the abstract to achieve this goal. Without concrete guidance, the authors may struggle to improve their draft effectively. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement, it does not explicitly instruct the authors on which modalities to include or how to present the results. The suggestion is somewhat vague, as it lacks specific guidance on which tasks or modalities to focus on. Therefore, the comment is somewhat actionable, as it gives a general idea of what needs to be done but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. However, it does not specify which modalities or tasks should be included, nor does it provide guidance on how to present the results or address the concerns about expected test loss. The comment is not grounded as it does not clearly identify the specific part of the paper being addressed, and it is not specific because it lacks detailed guidance on what needs to be done. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests including results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. However, the comment lacks specific examples or references to support the claim that expected test loss is not meaningful in these scenarios. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth to fully substantiate the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include results in other modalities, such as language-related tasks, and questions the significance of expected test loss in these contexts. While the comment provides a direction for improvement by suggesting additional experiments, it lacks specific guidance on which modalities or tasks to include, making it somewhat helpful. The feedback is actionable but could be more comprehensive if it offered detailed suggestions or examples of how to present the additional results. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/few training steps. While the comment identifies a specific area needing clarification, it does not provide explicit guidance on how to address this issue or what actions the authors should take to improve their draft. The action is implicit and vague, as the authors are left to infer how to enhance their work. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/f few training steps. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue, as it clearly explains the gap in the motivation and the need for the authors to address how the method effectively leverages few-shot learning and ensures generalization. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the motivation of the work should be further justified, specifically regarding how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/few training steps. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the motivation of the work, specifically questioning how the proposed method effectively utilizes the \"few-shot\" aspect and guarantees generalization to new tasks with 0/few training steps. This feedback is valuable as it highlights a critical area that needs further clarification and justification. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues. While it points out a crucial weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community, particularly since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their work need improvement. While it identifies a potential area for enhancement, it lacks concrete suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat actionable, as it highlights a concern but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the straightforward and naive use of Gaussian Process (GP) in the paper, suggesting that dynamical modeling has been widely investigated in the GP community, particularly since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment does not specify which part of the paper discusses the use of GP or where the authors might have made this critique. This lack of grounding makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs improvement. While the comment is specific in its critique of the GP usage, the absence of explicit references or sections makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of Gaussian Process (GP) is straightforward and naive, suggesting that dynamical modeling has been widely investigated in the GP community, particularly since the introduction of Gaussian Process Dynamical Models in NIPs 2005. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the straightforward and naive use of Gaussian Process (GP) in the paper, suggesting that dynamical modeling has been widely investigated in the GP community, particularly since the introduction of Gaussian Process Dynamical Models in NIPs 2005. While the comment highlights a concern about the depth of the use of GP, it does not provide specific guidance or suggestions on how the authors might address this issue or incorporate more sophisticated modeling techniques. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable advice or detailed examples to guide the authors in enhancing their work. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the differential privacy application is \"half-baked\" and encourages the authors to think through it more clearly. It also recommends moving the experimental results from the appendix to the main paper. However, the comment does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the differential privacy application is \"half-baked\" and recommends the authors to think through it more clearly. It also suggests moving the experimental results from the appendix to the main paper. However, the comment does not specify which part of the paper discusses the differential privacy application or the experimental results, making it difficult for the authors to identify the exact sections that need attention. While the comment is specific about the issues with the differential privacy application and the placement of experimental results, the lack of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the differential privacy application is \"half-baked\" and recommends the authors to think through it more clearly. It also suggests moving the experimental results from the appendix to the main paper. However, the comment lacks specific examples or detailed reasoning to support these claims. Without further elaboration or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient detail or justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the differential privacy application, suggesting that it is \"half-baked\" and could benefit from more clarity. It also recommends moving the experimental results from the appendix to the main paper, which could improve the paper's presentation and impact. However, the comment lacks specific guidance on how the authors might address the \"half-baked\" nature of the differential privacy application or what specific aspects need clarification. While it provides some direction, the feedback could be more actionable and detailed to fully assist the authors in improving their draft. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation. It suggests that using robotic manipulation in general might be more appropriate. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify the methodology. The action is implicit, as the authors need to infer that they should clarify the methodology's specificity to bimanual manipulation. The comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its suggestion, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the clarity of the proposed methodology's specificity to bimanual manipulation, suggesting that using robotic manipulation in general might be more appropriate. This feedback highlights a potential ambiguity in the methodology description, which could lead to confusion for readers. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the methodology. While it identifies an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not provide detailed guidance on how to resolve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide METEOR results, which are also reported in recent works. This is an explicit action that the authors can readily follow, as it clearly indicates what additional information is needed to improve the draft. The comment is specific in its request, detailing the exact metric (METEOR) that should be included. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide METEOR results, which are also reported in recent works. However, it does not specify which part of the paper this information should be included in or how it relates to the content of the paper. The comment lacks grounding as it does not provide clear guidance on where the METEOR results should be added or discussed. It is also specific in its request for METEOR results, but without context, it is difficult for the authors to understand the exact need. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide METEOR results, which are also reported in recent works. However, the comment does not specify which part of the paper this information should be included in or how it relates to the content of the paper. It lacks detailed reasoning or references to support the claim that METEOR results are necessary or beneficial. Without specific guidance or examples, the authors may find it challenging to understand the need for this additional information. Therefore, the comment is considered borderline verifiable, as it provides some indication of the need for METEOR results but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the authors should provide METEOR results, which are also reported in recent works. This feedback is specific and actionable, as it directs the authors to include additional information that aligns with current standards and practices in the field. By providing these results, the authors can enhance the comprehensiveness and comparability of their work. However, the comment could be more helpful if it offered guidance on how to present or interpret the METEOR results. Overall, the feedback is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific aspect of the paper that could be improved by providing more detailed commentary on the use of AutoML approaches, particularly in extracting hints for future network architecture design. It suggests that the authors should elaborate on the takeaways from the found architecture. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of AutoML approaches, specifically focusing on extracting hints for future network architecture design. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide more detailed commentary on the takeaways from the found architecture, but it lacks explicit references to specific sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors did not spend much time commenting on the use of AutoML approaches, particularly in extracting hints for future network architecture design. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains somewhat verifiable, as it is based on an observation without thorough justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the authors did not adequately comment on the use of AutoML approaches, particularly in extracting hints for future network architecture design. This feedback is somewhat helpful as it highlights a potential gap in the paper's discussion and suggests that the authors should provide more detailed commentary on this aspect. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue. Overall, the comment provides a clear direction for improvement, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and that the inclusion of empirical results would be beneficial. However, it does not specify which sections of the introduction need to be revised or how the authors should make the text more concise. While the comment provides a general direction for improvement, it lacks specific guidance on what needs to be done to achieve conciseness or how empirical results should be integrated. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main part of the paper, especially the introduction, could be more concise and that including empirical results would be beneficial. However, it does not specify which sections of the paper are being referred to, making it difficult for the authors to pinpoint the exact areas that need improvement. The comment is vague in its suggestion to include empirical results, as it does not provide any guidance on how to incorporate them or what kind of empirical results would be most relevant. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the main part of the paper, particularly the introduction, could be more concise and that including empirical results would be beneficial. However, the comment does not provide any specific reasoning, examples, or references to support why the introduction should be more concise or why empirical results are necessary. Without detailed justification or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main part of the paper, particularly the introduction, could be more concise and that including empirical results would be beneficial. While the comment identifies a potential area for improvement, it lacks specific guidance on how to achieve conciseness or how to integrate empirical results effectively. The feedback is somewhat helpful as it points out areas for enhancement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3: Somewhat Helpful, as it offers some insight but requires further elaboration to be fully beneficial.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL's performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide explicit guidance on how to address this limitation or what specific experiments should be conducted. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their experiments to more complex games. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"ReBeL's performance on more complex problem\" and \"bigger depth,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a limitation in the experimental setup, noting that the experiments were only conducted on two typical games, and suggests exploring the performance on more complex problems with larger depth. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It suggests that the ReBeL's performance on more complex problems, especially those with larger depth, could be explored. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the experiments were limited to two typical games. This lack of evidence makes it difficult for the authors to understand the basis of the claim and how it might impact their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the experimental setup, noting that the author only conducted experiments on two typical games. It highlights the ReBeL's performance on more complex problems, especially those with larger depth, which could lead to significant inputs for the value and policy functions. This feedback is somewhat helpful as it points out a potential area for improvement in the experimental design. However, it lacks specific guidance on how to address this limitation or what additional experiments could be conducted to strengthen the paper. The comment provides a clear direction for improvement but could be more helpful with additional suggestions or examples. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited. It also notes that many previous works focus on this topic and that adding topic entities seems incremental. However, the comment does not provide specific guidance or suggestions on how to address these issues or improve the paper. The authors are left without a clear understanding of what needs to be done to enhance their work, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the improvements on different datasets are trivial and that the novelty of the paper is limited, implying that the authors should consider adding topic entities. However, it does not specify which part of the paper discusses the improvements on different datasets or the novelty of the paper. The comment lacks grounding as the authors cannot confidently determine which sections or aspects of the paper are being addressed. Additionally, the comment is somewhat specific in that it points out the triviality of improvements and the incremental nature of adding topic entities, but it does not provide detailed guidance on how to address these issues. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements on different datasets are trivial and that the novelty of the paper is limited, suggesting that adding topic entities seems incremental. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the criticism. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, suggesting that the improvements on different datasets are trivial and that the novelty of the paper is limited. It also implies that adding topic entities might be incremental. However, the comment lacks specific guidance or suggestions on how to address these issues or enhance the paper's novelty. While it points out areas for improvement, it does not provide actionable steps or detailed feedback that would help the authors make meaningful revisions. As a result, the comment is somewhat helpful, as it offers a general direction for improvement but lacks depth and specificity. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not provide any explicit or implicit suggestions on how the authors might address this gap or what aspects of the discussion could be expanded. The comment identifies a specific area that needs attention but does not offer guidance on how to improve the draft. As a result, the authors are left without a clear direction for action, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific gap in the paper by pointing out the lack of discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in identifying the missing discussion but lacks grounding as it does not provide clear guidance on where to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left to infer the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a discussion on the theoretical guarantee of the hierarchical strategy compared to the global optimal of the original QUBO. This is a crucial aspect that needs to be addressed to strengthen the paper's theoretical foundation. However, the comment lacks specific guidance or suggestions on how the authors might approach this discussion or what aspects of the analysis could be expanded. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides a clear direction for the authors to follow but does not offer detailed guidance on implementation.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative measures for evaluating the generated VCEs, noting that the evaluation is primarily based on visual inspection. While it identifies a gap in the methodology, it does not provide explicit guidance on how to address this issue or suggest specific quantitative measures that could be used. The action is implicit, as the authors would need to infer that they should consider adding quantitative metrics to their evaluation process. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"generally lacking a quantitative measure to evaluate the generated VCEs,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of lacking quantitative measures and suggests that the evaluation is primarily based on visual inspection. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is generally lacking a quantitative measure to evaluate the generated VCEs, with evaluation primarily relying on visual inspection. This claim is somewhat verifiable as it provides a clear observation about the evaluation methodology but lacks specific examples or references to support the claim. The authors would need to infer that the lack of quantitative measures is a significant issue, but the comment does not offer detailed reasoning or evidence to fully substantiate the claim. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of quantitative measures for evaluating the generated VCEs. It notes that the evaluation is primarily based on visual inspection, which may not provide a comprehensive or objective assessment. This feedback is valuable as it highlights a gap in the methodology and suggests that the authors should consider incorporating quantitative measures to enhance the rigor and depth of their evaluation. However, the comment could be more helpful if it provided specific examples of quantitative measures that could be used or suggested alternative evaluation methods. Overall, the comment is mostly helpful as it points out a critical area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that the authors claim their method performs better than baselines, but the error range is high, suggesting that the performance differences are not significant. However, the comment does not provide explicit guidance or suggestions on how the authors can address this issue or improve their results. It lacks concrete actions or detailed feedback on what specific aspects of the method or experiments need to be revised to achieve more substantial improvements. As a result, the authors are left without clear direction on how to enhance their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of marginal improvements over baselines and the high error range, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the concern regarding the performance differences between methods and the need for more significant improvements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' method only marginally improves over baselines, with performance differences within the error bar range. This claim is somewhat verifiable as it provides a specific observation about the performance of the method. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors could strengthen the comment by providing more context or evidence to support their assertion about the significance of the performance differences.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a key issue with the authors' claims regarding the performance of their method compared to baselines. It points out that the improvements are marginal and within the error bar range, suggesting that the performance differences are not significant. This feedback is valuable as it highlights a potential overstatement in the authors' claims and provides a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions or guidance on how the authors might address this issue, such as conducting additional experiments or refining their analysis. Overall, the comment is somewhat helpful, as it provides a clear insight but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights issues with the generated videos, noting that only some are convincing and that the action recognition performance is below the state-of-the-art on the UCF dataset. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks guidance on how the authors might improve the video generation or action recognition performance. As a result, the authors are left without a clear path to follow, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment mentions \"generated videos\" and \"action recognition performance,\" but it does not specify which part of the paper these issues are discussed in. The authors cannot confidently determine which section or figure is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details about what needs to be addressed or how the issues can be resolved. Therefore, the comment is weakly grounded and not specific, aligning with category 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the generated videos have significant artifacts and that the action recognition performance is below the state-of-the-art on the UCF dataset. However, the comment lacks specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies issues with the generated videos, specifically noting the presence of significant artifacts and the low action recognition performance compared to state-of-the-art methods on the UCF dataset. It also questions the depth of the architectures used, suggesting that more complex models might be necessary. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues. While it highlights areas for improvement, it does not provide specific steps or recommendations for the authors to take, making it somewhat helpful. The feedback is clear but could be more comprehensive with detailed suggestions or examples of how to improve the video generation and action recognition processes.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method. It also asks for clarification on how to select representative images. However, the comment does not provide explicit guidance or suggestions on how to address these issues. The authors are left to infer that they need to clarify these aspects, but the action is not concrete or detailed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in its request for clarification but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method and how to select representative images. However, it does not provide any specific reasoning, examples, or references to support why this is an issue or how it could be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the diversity and representativeness of the new proposed evaluation set compared to the previous method, as well as the selection of representative images. This feedback highlights a potential gap in the paper's methodology or experimental design, suggesting that the authors need to clarify how their new evaluation set differs from existing methods and how they ensure the selection of representative images. However, the comment lacks specific guidance or suggestions on how to address these issues, leaving the authors with a general idea of what needs improvement but without concrete steps to take. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide detailed actionable feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. These suggestions are clear and direct, allowing the authors to understand exactly what needs to be added to their draft. The comment is fully actionable as it provides concrete guidance on how to improve the paper. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors include a background section to introduce the basic RL framework, specifically mentioning elements like MDP, trajectories, and policy. It also recommends providing a brief overview of the original DPO algorithm to clarify the modifications proposed in the methods section. This feedback is fully grounded as it explicitly mentions the sections that need improvement, allowing the authors to accurately identify the parts of the paper that require attention. The comment is also specific, as it clearly specifies what needs to be included in these sections to enhance clarity and understanding. Therefore, this comment is rated as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy, to clarify the RL context being considered. It also recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. While the comment provides a clear rationale for the suggestions, it lacks specific examples or references to support the claim that these additions would enhance the clarity and understanding of the paper. However, the reasoning is logical and well-structured, making the claim mostly verifiable. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific and actionable feedback by suggesting that the authors include a background section to introduce the basic RL framework, including elements of the MDP, trajectories, and policy. This would help clarify the RL context being considered, making it easier for readers to follow the subsequent sections. Additionally, the comment recommends providing a brief overview of the original DPO algorithm to distinguish the modifications proposed in the methods section. These suggestions are clear and constructive, offering the authors a clear path to improve the clarity and comprehensiveness of their paper. Therefore, the comment is highly helpful, as it provides detailed guidance on how to enhance the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method when users continuously add new languages due to limited model capacity. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment identifies a problem but does not offer guidance on how to mitigate it or suggest potential solutions. As a result, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the proposed method's limitation when users continuously add new languages due to limited model capacity. However, it does not specify which part of the paper this issue is related to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in identifying the potential limitation, the absence of grounding information makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the proposed method's limitation when users continuously add new languages due to limited model capacity. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method, specifically that it may encounter issues when users continuously add new languages due to limited model capacity. This feedback highlights a critical area that needs attention and suggests that the authors should consider how to address this limitation. However, the comment lacks specific guidance or suggestions on how to mitigate this issue, such as potential solutions or strategies for handling the continuous addition of languages. While it points out a significant concern, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it provides a clear area for improvement but does not offer detailed guidance on how to achieve it.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). While it raises a valid point about the need to clarify the connection between the term and the cited work, it does not provide explicit guidance on how the authors should address this question or incorporate it into their draft. The action is implicit, as the authors need to infer that they should clarify the relevance of the term. However, the comment lacks concrete details on how to do so, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 54,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider by questioning the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). While it does not contain a subjective claim or suggestion, it prompts the authors to consider the connection between the term and the cited work. However, it lacks specific examples or references to support the claim, making it difficult for the authors to fully understand the context and implications of the question. Therefore, the comment is considered borderline verifiable, as it provides some basis for discussion but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the relevance of the term \"interpretable\" program to the work of Doshi-Velez and Kim (2017). This question prompts the authors to consider the connection between the term and the cited work, which could help them clarify their terminology and ensure consistency in their use of terms. However, the comment does not provide any suggestions or guidance on how the authors might address this question or incorporate it into their draft. While it identifies an area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the similarity of the proposed method to an approach in [10] and suggests that [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the proposed method. The action is implicit and vague, as it does not specify how the authors should explore or implement the suggestions. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the similarity of the proposed method to an approach in [10] and suggests that [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment does not specify which part of the paper discusses the proposed method or the approach in [10], making it difficult for the authors to pinpoint the exact sections that need attention. Additionally, while the comment suggests an improvement, it does not provide specific guidance on how to implement it. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the similarity of the proposed method to an approach in [10] and suggests that [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to understand the basis of the critique. Without clear justification or references, the claim remains somewhat verifiable, as it is based on an assumption rather than a well-supported argument. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the similarity of the proposed method to an approach in [10] and suggests that [10] could also be equipped with scoring causal predictions and interventional data. It implies that the authors should consider why [10] cannot use these side information. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or incorporate these ideas into their work. It lacks actionable insights and detailed feedback, making it barely helpful. The authors are left without a clear understanding of how to improve their method or address the concerns raised.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. However, it does not provide any explicit or implicit suggestions on how to address this issue or improve the analysis. The comment lacks concrete guidance on what changes could be made to the results or how the authors might enhance their interpretation. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the Atari game results are discussed in, nor does it provide any context or explanation for why the results are limited to a single game and baseline. The authors cannot confidently determine which section or part of the paper is being addressed, making it difficult to understand the issue being raised. Additionally, the comment is not specific because it does not detail what aspects of the results are difficult to interpret or what suggestions could be made to improve the analysis. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the Atari game results are limited to a single game and a single baseline, making them difficult to interpret. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the Atari game results, noting that they are based on a single game and a single baseline, making it difficult to interpret. While the comment highlights a potential issue with the scope of the results, it does not provide specific suggestions or guidance on how the authors might address this limitation or improve the analysis. The feedback is somewhat helpful as it points out a weakness that needs attention, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. While the comment implies that these additions are necessary, it does not explicitly instruct the authors to conduct these experiments or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand their evaluation to include these aspects. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not specify which part of the paper this evaluation is related to, such as the methodology or results sections. This lack of grounding makes it difficult for the authors to identify the exact areas that need improvement. While the comment is specific about the type of experiments needed, the absence of explicit references to the paper's sections or content makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the evaluation needs experiments on distributed deployment and a larger model. However, it does not provide any specific reasoning, examples, or references to support why these experiments are necessary or how they would enhance the paper. The comment lacks detailed justification, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the evaluation of the paper needs to include experiments on distributed deployment and a larger model. This feedback is specific and actionable, as it provides clear guidance on what additional experiments the authors should conduct to strengthen their evaluation. By addressing these points, the authors can enhance the comprehensiveness and robustness of their evaluation, making the comment highly helpful. However, the comment could be more helpful if it provided more detailed guidance on how to conduct these experiments or what specific aspects of the evaluation should be considered. Overall, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment does not explicitly instruct the authors to conduct this exploration or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should test the model with larger parameters. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment does not specify which part of the paper discusses the model's performance or parameters, making it weakly grounded. It is specific in questioning the claim and suggesting an additional experiment, but without clear references to the sections or figures, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the claim or understand the reasoning behind it. The feedback is somewhat verifiable as it provides a direction for further investigation but lacks detailed justification or evidence. Therefore, it aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment questions the authors' claim of superior performance due to fewer parameters, suggesting that the baseline model might have been tested with standard parameter settings. It implies that the authors should explore whether the proposed model's performance improves with larger word embedding and LSTM parameters. However, the comment lacks specific guidance or suggestions on how to conduct this exploration or what experiments to perform to substantiate the claim. While it points out a potential area for further investigation, it does not provide actionable steps or detailed feedback that would help the authors address the issue effectively. Therefore, the comment is somewhat helpful, as it identifies a potential weakness but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for finetuning the extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not provide explicit guidance on how to implement this finetuning or suggest specific methods or techniques to use. The action is implicit, as the authors need to infer that they should finetune the hyperparameters and consider the factors mentioned. While the comment is somewhat actionable, it lacks concrete details on how to execute the finetuning process, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the need for finetuning extra hyperparameters k and \u03b7, which depend on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, it does not specify which part of the paper this issue is related to, such as a specific section or table where these hyperparameters are introduced or discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion regarding the finetuning process, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the extra hyperparameters k and \u03b7 require finetuning, which depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the introduction of extra hyperparameters, k and \u03b7, which require finetuning. It highlights that this finetuning depends on the availability of the environment or a good Offline Policy Estimation (OPE) method. However, the comment does not provide any guidance or suggestions on how to address this issue or what specific methods or techniques could be used for finetuning. While it points out a potential area for improvement, it lacks actionable advice or detailed insights that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it identifies a problem but does not offer comprehensive guidance for resolution.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out a discrepancy in the regularization methods used for the LN model and the GLM, suggesting that the authors should try to reproduce the main features of previous models to ensure a fair comparison. However, the comment does not provide explicit instructions or detailed guidance on how to implement this suggestion, such as which specific features to reproduce or how to adjust the regularization parameters. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization methods used in the LN model and the GLMs, specifically noting a discrepancy in the regularization techniques. It mentions the LN model needing regularization and then applying regularization in the form of a cropped stimulus to both LN models and GLMs. The comment also references the work of Pillow et al., which did not use cropping but employed L1 regularization and low-rank approximation. This provides a clear and specific reference to the issue, allowing the authors to understand the exact part of the paper that needs attention. The comment is fully grounded as it explicitly mentions the sections or parts of the paper being discussed, and it is specific because it details the discrepancy in regularization methods. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about a discrepancy in the regularization methods used for the LN model and the GLMs. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. The comment provides specific references to the work of Pillow et al., which did not use cropping but employed L1 regularization and low-rank approximation. This provides a clear basis for the claim, making it mostly verifiable. However, the comment could be strengthened by including more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a specific issue with the regularization methods used in the LN model and the GLMs, noting a discrepancy with the work of Pillow et al. It suggests that the authors should try to reproduce the main features of previous models to ensure a fair comparison. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft. However, it could be more helpful if it included additional guidance on how to reproduce the features or what specific aspects to focus on. Overall, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the study, specifically the lack of analysis of inference time. It suggests that since the method is direct and does not require detection or keypoint grouping, it would be beneficial to compare its inference speed to previous top-down and bottom-up pose estimation methods. However, the comment does not provide explicit guidance on how the authors should conduct this analysis or what specific metrics to use. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of study of inference time, which is a specific aspect of the paper. It also suggests comparing the inference speed to previous top-down and bottom-up pose estimation methods, providing clear guidance on what needs to be addressed. This allows the authors to accurately identify the part of the paper being addressed and understand the specific issue that needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a study of inference time, which is a significant aspect for evaluating the practical applicability of a pose estimation method. It suggests comparing the inference speed to previous top-down and bottom-up methods, implying that this comparison would provide valuable insights. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the lack of inference time study is a critical omission. While the suggestion is logical, the lack of detailed evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the study by pointing out the absence of an analysis of inference time. It suggests that since the method is direct and does not require detection or keypoint grouping, it would be beneficial to compare its inference speed to previous top-down and bottom-up pose estimation methods. This feedback is valuable as it highlights a crucial aspect that could enhance the practical applicability and comprehensiveness of the research. However, the comment could be more helpful if it provided specific guidance on how to conduct the inference time analysis or suggested particular metrics for comparison. Overall, the comment is mostly helpful as it directs the authors to an important area for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment does not provide explicit guidance on how to address these limitations or what specific aspects of the discussion need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the claim about evolutional dropout and internal covariate shift, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the limitations of the claim, suggesting that Batch Normalization standardizes variance and centers activation, which should be discussed explicitly. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses an opinion about the claim regarding evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also mentions that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. However, the comment lacks specific examples or detailed reasoning to support the claim, making it difficult for the authors to fully understand and address the issue. The feedback is somewhat verifiable as it provides a general direction but lacks depth and specificity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific concern regarding the claim about evolutional dropout and internal covariate shift, suggesting that it is limited to increasing the variance of low-variance units. It also points out that Batch Normalization standardizes variance and centers activation, implying that these limitations should be discussed explicitly. This feedback is clear and actionable, providing the authors with a specific area to address in their paper. However, the comment could be more helpful if it offered additional guidance on how to discuss these limitations or what specific aspects of the discussion need to be expanded. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include not only the retrieved and final attention maps but also the tentative attention maps in the qualitative figures. This provides a clear and explicit action for the authors to take, as they know exactly what additional information they should include in their figures. The comment is specific in its request, detailing what is missing and why it would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including \"tentative attention maps\" in the qualitative figures, which implies that the authors should consider adding this information. However, it does not specify which part of the paper these figures are located in, making it weakly grounded. The comment is specific in its suggestion to include a particular type of attention map, which would help the authors improve the clarity and comprehensiveness of their qualitative analysis. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including \"tentative attention maps\" in the qualitative figures, which implies that the authors should consider adding this information. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks sufficient support, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests including \"tentative attention maps\" in the qualitative figures, which could enhance the comprehensiveness and depth of the analysis presented in the paper. By providing this feedback, the reviewer offers a specific and actionable suggestion for improvement. However, the comment could be more helpful if it included additional context or examples of how these maps would be beneficial or how they could be integrated into the figures. Overall, the comment is somewhat helpful as it identifies a potential area for improvement but lacks depth and specificity in its guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which aspects of the contribution need more detail or how the authors should go about adding this description. The action is implicit and vague, as it does not provide concrete guidance on what specific elements of the contribution require additional explanation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should add more description about the contribution of the paper. However, it does not specify which part of the paper this contribution is discussed in, nor does it provide any guidance on what aspects of the contribution need more detail. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity, as it does not detail what kind of description is needed or how it should be added. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the authors should add more description about the contribution of the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this addition is necessary or how it would improve the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should add more description about the contribution of the paper. However, it lacks specificity and does not provide any guidance on what aspects of the contribution need more detail or how the authors should go about adding this description. The comment is vague and does not offer actionable feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should include supervised baselines in their experiments, particularly for datasets of a certain scale. It provides a rationale for why this is important, explaining that full annotation is often available for datasets of this size and that it would be informative to compare self-supervised methods to fully supervised pre-trained networks. However, the comment does not explicitly instruct the authors on how to implement this suggestion, such as which specific baselines to include or how to compare the results. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for supervised baselines in the experiments, which is a specific part of the paper. It provides a clear rationale for why these baselines are important, explaining that they are relevant for datasets of a certain scale and that comparing self-supervised methods to fully supervised pre-trained networks would be informative. This level of detail helps the authors understand what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks supervised baselines, which is a reasonable suggestion given the scale of the datasets used in the experiments. The comment provides a rationale for why these baselines are important, explaining that full annotation is often available for datasets of this scale and that comparing self-supervised methods to fully supervised pre-trained networks would be informative. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for these baselines and understand the reasoning behind the suggestion, which aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for why these baselines are important, particularly for datasets of a certain scale where full annotation is often available. The suggestion to include these baselines and compare them to fully supervised pre-trained networks is actionable and would help the authors contextualize their results and strengthen the paper. However, the comment could be more helpful if it provided specific examples of what these baselines might be or suggested particular methods for comparison. Overall, the feedback is mostly helpful as it highlights a crucial aspect of the paper that needs improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the paper: the minimal performance differences between methods and the use of outdated and saturated benchmarks. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should consider re-evaluating their results or selecting more appropriate benchmarks, but it does not offer specific guidance on how to do so. Without concrete steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the performance differences between methods and the use of outdated benchmarks, but it does not specify which part of the paper these issues are discussed in. The authors cannot confidently determine which sections or figures are being referred to, making the comment weakly grounded. However, it provides specific feedback on the minimal performance differences and the need for more appropriate benchmarks, which is clear and specific. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point, which may be due to random variation. It also suggests that the benchmarks used are outdated and likely saturated, citing a specific reference. The claim about minimal performance differences is somewhat verifiable as it is supported by the observation of small differences in results. However, the claim about outdated benchmarks lacks specific examples or detailed reasoning, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the performance differences between methods are minimal across evaluations, with differences less than 1 percentage point. This observation suggests that the results may be due to random variation, which is a critical point for the authors to address. Additionally, the comment points out that the benchmarks used are outdated and likely saturated, indicating a need for more appropriate benchmarks. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address these concerns, such as re-evaluating their results or selecting more relevant benchmarks. The feedback is somewhat helpful as it points out areas for improvement, but it lacks actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions for the authors to consider. It questions the effectiveness of the method on Hopper, which has deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. Additionally, it asks why BEAR is missing from the baselines. While the comment provides some guidance, it lacks explicit instructions on how to address these points or what specific actions the authors should take. The suggestions are somewhat vague and do not offer detailed guidance on how to conduct the additional evaluations or include BEAR in the baselines. Therefore, the comment is somewhat actionable, as it provides some direction but lacks concrete details on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment does not specify which part of the paper discusses the method's application or evaluation on Hopper, making it weakly grounded. While it provides some specificity by questioning the method's effectiveness and suggesting additional evaluations, the lack of explicit grounding makes it difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. It also questions why BEAR is missing from the baselines. However, the comment lacks specific reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The questions are open-ended and do not provide detailed guidance or evidence, leaving the authors uncertain about the validity and relevance of the feedback. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several important questions and suggestions for the authors to consider. It questions the method's effectiveness on Hopper, a domain with deterministic dynamics, and suggests evaluating it on domains with non-deterministic dynamics to assess its empirical efficacy. This provides a clear direction for further experimentation and analysis. Additionally, the comment points out the absence of BEAR in the baselines, which is a relevant concern for the authors to address. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to conduct the additional evaluations or include BEAR in the baselines. While it offers some actionable feedback, the lack of comprehensive suggestions limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. While the comment implies that this justification is necessary, it does not explicitly instruct the authors to include it in their draft. The action is implicit, as the authors need to infer that they should add a theoretical or conceptual explanation for the effectiveness of these techniques. However, the comment lacks concrete guidance on how to provide this justification, such as suggesting specific types of theocratical reasoning or examples. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. However, it does not specify which part of the paper this justification should be included in, making it weakly grounded. The comment is specific in its request for a justification, but without clear guidance on where to include it, the authors may struggle to apply this feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide a theocratical justification for why co-training and weight averaging improve results. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to address it. Without additional context or guidance, the claim remains vague and challenging to implement. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient evidence or detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors provide a theocratical justification for why co-training and weight averaging improve results. This feedback is clear and actionable, as it directs the authors to enhance the theoretical or conceptual basis of their findings. However, the comment could be more helpful if it provided specific examples or guidance on how to construct such a justification. Despite this, the feedback is mostly helpful as it offers a clear direction for improvement, allowing the authors to address a key aspect of their work. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not provide any explicit or implicit guidance on how the authors might address this issue or incorporate Bayesian considerations into their derivation. The authors are left without any actionable steps to take, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are included. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section that needs revision. Additionally, the comment does not provide specific guidance on how to address the issue or incorporate Bayesian considerations. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the authors\\' derivation falls into classical learning theory-based bounds, which are not realistic unless Bayesian considerations are taken into account. The reviewer provides an example of Bayesian-PAC based bounds, suggesting that the authors should consider incorporating Bayesian considerations. However, the comment lacks detailed reasoning or specific references to support the claim that classical bounds are unrealistic without Bayesian considerations. The authors may find it challenging to fully understand and address the issue without additional context or evidence. Therefore, the comment is considered borderline verifiable, as it provides some justification but lacks depth and clarity.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors\\' derivation, suggesting that it falls into classical learning theory-based bounds, which may not yield realistic results without incorporating Bayesian considerations. This feedback is somewhat helpful as it points out a specific area that needs attention and suggests a potential direction for improvement. However, the comment lacks detailed guidance or examples on how the authors might address this issue or incorporate Bayesian considerations into their derivation. Without further elaboration or suggestions, the authors may find it challenging to fully understand and implement the feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment does not provide explicit guidance on what specific aspects of the method need to be elaborated upon or how the authors should present these details. The action is implicit and vague, as it does not specify which parts of the paper require additional details or what kind of information should be included. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigrates the uncertainty of the label distribution. However, the comment does not specify which part of the paper this feedback is intended for, making it weakly grounded. It is specific in detailing what needs to be addressed, but without clear references, the authors may struggle to identify the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that more details about the proposed method should be presented, specifically regarding how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that these details are missing or insufficient. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that more details about the proposed method should be presented. It highlights the need for a clearer explanation of how the implicit distribution characterizes the uncertainty of each label value and how the model mitigates the uncertainty of the label distribution. However, the comment lacks specificity in terms of which parts of the paper require additional details or what kind of information should be included. While it provides a general direction for improvement, it does not offer detailed guidance or examples, making it somewhat helpful. The authors would benefit from a more comprehensive feedback that includes specific suggestions or questions to address the identified areas of improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential limitation of the proposed method in detecting hallucinations in open-ended responses, providing a specific example to illustrate the issue. It suggests that the method might struggle with prompts like \"introduce a sports celebrity to me,\" where sampled responses could pertain to different individuals, making it challenging to identify shared information for consistency checking. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific improvements could be made to the method. The action is implicit and somewhat vague, as it leaves the authors to infer the need for further investigation or modification. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue with the proposed method, noting its potential struggle to detect hallucinations in open-ended responses. It provides a concrete example, such as the prompt \"introduce a sports celebrity to me,\" to illustrate the challenge. However, the comment does not explicitly mention a specific part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in detailing the problem and providing an example, which helps the authors understand the issue and its implications. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method might struggle to detect hallucinations in open-ended responses, providing an example of a prompt that could lead to this issue. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the concern or how to address it. Without detailed reasoning or examples, the claim is not fully verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential limitation of the proposed method in detecting hallucinations in open-ended responses, using a specific example to illustrate the issue. This feedback is somewhat helpful as it highlights a specific area where the method might struggle, providing the authors with a clear understanding of a potential weakness. However, the comment could be more helpful if it offered suggestions or guidance on how the authors might address this issue or improve the method. Overall, the comment provides a valuable insight but lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the clarity of how theoretical findings relate to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment does not provide explicit guidance on how to verify this claim or what specific steps the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"theoretical findings\" and suggests verifying the conclusion about \"label noise and model size on MNIST and CNN.\" This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the verification of the conclusion on MNIST and CNN. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of how theoretical findings relate to real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment does not provide any specific reasoning, examples, or references to support why this verification is necessary or how it would strengthen the paper. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by questioning the connection between theoretical findings and real-world deep learning models. It suggests that the authors should verify the conclusion about label noise and model size on MNIST using CNNs. However, the comment lacks specific guidance on how to conduct this verification or what data or experiments would be necessary. While it points out an area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explicitly mention the requirement of choosing a Gaussian distribution for p(y | H_f(t_n)) to ensure the applicability of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs section. However, the comment does not provide specific guidance on how the authors should address this point or what changes need to be made to the draft. The action is implicit and vague, leaving the authors uncertain about how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should explicitly mention the requirement of choosing a Gaussian distribution for p(y | H_f(t_n)) to ensure the applicability of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs section. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact location. While the comment is specific about the content it addresses, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should explicitly mention the requirement of choosing a Gaussian distribution for p(y | H_f(t_n)) to ensure the applicability of Kalman Filtering and Smoothing and CVI. It also notes that this assumption is already made in the ELBOs section. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. The absence of detailed justification or evidence weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the choice of distribution for p(y | H_f(t_n)) and its implications for the applicability of Kalman Filtering and Smoothing and CVI. It suggests that the authors should explicitly mention this requirement, which is already assumed in the ELBOs section. This feedback is clear and actionable, as it provides a specific point for the authors to address in their draft. However, the comment could be more helpful if it offered additional guidance on how to ensure the Gaussian assumption is consistently applied throughout the paper. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the application of weight decay, suggesting that the authors should expect suboptimal cosine similarities for large weight decay parameters. It also notes that the plots do not extend to these large weight decay strengths, where cosine similarities are not reported. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit and vague, as it does not specify how the authors should adjust their analysis or plots to account for this observation. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the application of weight decay in the paper, noting that the plots do not extend to large weight decay strengths where cosine similarities are expected to be suboptimal. However, the comment does not explicitly mention which part of the paper this issue is discussed in, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact location of the problem. While the comment is specific in its critique of the results, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the plots do not extend to large weight decay strengths where cosine similarities are expected to be suboptimal, based on the observation that suboptimal cosine similarities are anticipated with suboptimally weighted decay. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to verify the reasoning or understand the basis of the critique. The absence of detailed evidence or logical reasoning weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the application of weight decay, noting that the plots do not extend to large weight decay strengths where cosine similarities are expected to be suboptimal. This observation is based on the understanding that suboptimal weight decay would lead to suboptimal cosine similarities. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their analysis. While it highlights a potential area for further exploration, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results to show that minimizing HSICcond-i could perform better than minimizing HSIC_HOOD, potentially using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, the comment points out the absence of a correctness test and comparative experiments with other metrics for the proposed test metric, suggesting the inclusion of visualization results or schematic diagrams to aid understanding. While the comment provides explicit suggestions for improvement, it lacks detailed guidance on how to implement these suggestions, such as specific types of visualizations or schematic diagrams to include. Therefore, the comment is mostly actionable, as it identifies the need for additional qualitative experiments and provides some direction but lacks concrete details on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the lack of qualitative experiments to demonstrate the validity of the conditional independence model, suggesting the inclusion of illustrative experimental results. It provides specific examples, such as using a toy dataset to demonstrate the separability of inlier and outlier features, which helps the authors understand the need for additional experiments. However, the comment does not explicitly mention specific sections or parts of the paper that require these experiments, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing visualization results or schematic diagrams to aid understanding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of qualitative experiments to demonstrate the validity of the conditional independence model. It suggests providing illustrative experimental results, such as using a toy dataset to demonstrate the separability of inlier and outlier features, and proposes the inclusion of a correctness test and comparative experiments with other metrics for the proposed test metric. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. The lack of detailed justification makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some indication of the issue but lacks sufficient evidence or explanation to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of qualitative experiments to demonstrate the validity of the conditional independence model. It provides specific suggestions for improvement, such as including illustrative experimental results using a toy dataset to demonstrate the separability of inlier and outlier features. Additionally, the comment highlights the absence of a correctness test and comparative experiments with other metrics for the proposed test metric, suggesting the inclusion of visualization results or schematic diagrams to aid understanding. While the comment is clear and actionable, it could be more helpful if it provided more detailed guidance on how to conduct these experiments or visualize the results effectively. Overall, the feedback is mostly helpful as it directs the authors towards important areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a systematic study of the impact of the cost of incentivization on performance would be helpful. It provides specific examples, such as examining the reward incentives for different values of \\alpha and the collective return. The comment implies that the authors should conduct this analysis to provide a more comprehensive understanding of the system. However, it does not explicitly instruct the authors to perform this analysis or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a systematic study of the impact of the cost of incentivization on performance, providing specific examples such as examining reward incentives for various values of \\alpha and the collective return. This guidance is clear and specific, as it outlines what aspects of the analysis should be included. However, the comment does not explicitly mention which part of the paper this analysis should be conducted in, making it weakly grounded. The authors can infer that it relates to the discussion of roles between \"winners\" and \"cooperators,\" but the lack of explicit mention reduces the grounding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a systematic study of the impact of the cost of incentivization on performance would be helpful, providing specific examples such as examining reward incentives for various values of \\alpha and the collective return. The comment implies that this analysis could provide a more comprehensive understanding of the system. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the basis for the suggestion, which limits the verifiability. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a helpful suggestion for improving the paper by systematically studying the impact of the cost of incentivization on performance. It offers specific examples, such as examining the reward incentives for various values of \\alpha and the collective return, which could enhance the depth and comprehensiveness of the analysis. The comment also suggests that this analysis could provide a more nuanced understanding of the roles between 'winners' and 'cooperators.' However, the feedback could be more actionable if it included guidance on how to conduct this analysis or what specific data or experiments would be necessary. Overall, the comment is mostly helpful as it identifies a valuable area for improvement but could be more detailed in its suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly suggests that the approach description in Section 3 is difficult to follow and recommends using the additional page of the camera-ready version to extend this description rather than adding more experiments. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the clarity of the approach description. The comment is explicit and concrete, giving the authors a precise understanding of how to address the issue. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"approach description (\u00a7 3),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the approach description by suggesting that the additional page of the camera-ready version should be used instead of adding more experiments. This provides a clear direction for the authors to enhance their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the approach description in Section 3 is difficult to follow and suggests using the additional page of the camera-ready version to extend it. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the approach description is difficult to follow or how the suggested solution would address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the approach description in Section 3, noting that it is difficult to follow. It suggests that the additional page of the camera-ready version should be used to extend the approach description rather than adding more experiments. This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to enhance the clarity of the description or suggested specific ways to restructure the content. Overall, the comment is mostly helpful as it directs the authors towards a concrete improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the experiments section: the lack of interpretive insights into why the proposed gyro-structures outperform existing methods and the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to include more detailed interpretations of the results and expand their comparisons to include a broader range of methods. This lack of explicit action makes the comment somewhat actionable, as it provides a clear direction but lacks concrete steps for implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the experiments part of the paper, specifically mentioning the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. It also highlights the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques in manifold-based learning. However, the comment does not specify which part of the experiments section this issue is related to, such as specific tables or figures. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the issues with the experiments, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments part lacks interpretive insights into why the proposed gyro-structures outperform existing methods. It also notes the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach outperforms simpler or more commonly used techniques. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of interpretive insights into why the proposed gyro-structures outperform existing methods. It also highlights the absence of comparisons with other state-of-the-art methods that do not rely on gyro-structures, making it unclear whether the proposed approach is truly superior. This feedback is valuable as it directs the authors to enhance the depth and comprehensiveness of their experimental analysis. However, the comment could be more helpful if it provided specific suggestions or examples of how to include additional comparisons or interpretive insights. Overall, the comment is somewhat helpful, as it directs the authors to areas for improvement but lacks detailed guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. This comment is explicit in its request for additional evidence and analysis, providing a clear action for the authors to take. It specifies what kind of evidence or analysis is needed, making it concrete. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper needs revision. Additionally, the comment is specific in its request for more evidence and analysis, but without grounding, it is difficult for the authors to know where to focus their efforts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by suggesting that the authors should provide more evidence or analysis to support the training effectiveness property of the dataset or other key properties that explain the importance and possible use-cases of _LMGQS_ over other QFS datasets. This feedback is clear and actionable, as it directs the authors to enhance the depth and clarity of their analysis. However, the comment could be more helpful if it provided specific examples or guidance on what kind of evidence or analysis would be beneficial. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the claim that improvements are due to distillation rather than regularization effects. It suggests that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. However, the comment does not provide explicit guidance on how the authors should conduct these ablation studies or what specific aspects need to be addressed. While the action is implied, it is vague and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the claim that improvements are due to distillation rather than regularization effects, suggesting that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. However, the comment does not specify which part of the paper discusses the fine-tuning process or the results related to GLUE without validation. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs revision. While the comment is specific about the issue of regularization effects and the need for ablation studies, it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the improvements in the paper could be due to regularization effects rather than distillation, as the fine-tuning was performed for 10 epochs without early stopping. The reviewer suggests that this could lead to high variances and the need for proper ablation studies. However, the comment lacks specific examples or references to support the claim about the potential impact of regularization effects. While the reasoning is logical, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the claim that improvements are due to distillation rather than regularization effects. It points out that the fine-tuning was performed for 10 epochs without early stopping, which could lead to high variances and the need for proper ablation studies. This feedback is somewhat helpful as it highlights a specific area that requires further investigation and analysis. However, it could be more helpful if it provided more detailed guidance on how to conduct these ablation studies or suggested specific experiments to verify the claim. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper, to enhance the credibility of the framework. It also recommends including experiments on morphologically rich and low-resource languages. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific tasks or languages to include or how to analyze the results. The actions are implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper, to enhance the credibility of the framework. It also recommends including experiments on morphologically rich and low-resource languages. However, the comment does not specify which parts of the paper these additions or experiments should be included in, making it weakly grounded. The comment is specific in its suggestions, as it provides clear directions for improving the robustness and effectiveness of the framework. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests adding performance on word similarity and sentence translation tasks, similar to the MUSE paper, to enhance the credibility of the framework. It also recommends including experiments on morphologically rich and low-resource languages. However, the comment lacks specific references or detailed reasoning to support these suggestions, making it difficult for the authors to understand the basis for these recommendations. The claims are somewhat verifiable as they provide a general direction for improvement but lack detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the experiments section of the paper. It recommends adding performance evaluations on word similarity and sentence translation tasks, similar to those used in the MUSE paper, to enhance the credibility and robustness of the framework. Additionally, it suggests including experiments on morphologically rich and low-resource languages, which would broaden the scope and applicability of the research. While the comment is clear and actionable, it could be more helpful if it provided more detailed guidance on how to implement these suggestions or included specific examples of how to conduct the additional experiments. Overall, the feedback is mostly helpful as it offers valuable insights for improving the paper, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1-shot scenario and the absence of a 1-shot setting in the experiments. While it prompts the authors to clarify how node importance is used in a 1-shot setting, it does not provide explicit instructions or detailed guidance on how to address these issues. The action is implicit, as the authors need to infer that they should clarify the methodology and experimental setup. However, the lack of concrete suggestions or detailed guidance makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1-shot scenario and the absence of a 1-shot setting in the experiments. However, it does not specify which part of the paper these questions pertain to, such as the methodology or experimental section. This lack of grounding makes it difficult for the authors to identify the exact areas that need clarification. While the comment is specific in its questions about node importance and the 1-shot setting, the absence of explicit references to sections or figures makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1-shot scenario and the absence of a 1-shot setting in the experiments. However, it does not provide any claims or opinions that require verification. The comment is purely descriptive and does not offer any suggestions or judgments that could be evaluated. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises questions about the methodology and experimental setup, specifically regarding the use of node importance in a 1-shot scenario and the absence of a 1-shot setting in the experiments. It also points out that related works, such as RALE, have a 1-shot setting, which is not addressed in the paper. While the comment identifies a potential gap in the paper's discussion and experimental setup, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights areas for improvement but lacks depth and actionable advice. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these issues. While the comment implies that the authors should expand on this topic, it does not provide specific guidance on what aspects of the discussion should be included or how to address the problems. The action is implicit, as the authors need to infer that they should add more detailed discussions on this topic. However, the lack of concrete details makes the action somewhat vague. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should include more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to include more discussions on this topic, but without a clear reference to a specific section or part of the paper, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include more discussions about why LLMs struggle with fine-grained hard constraints and how to address these problems. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to incorporate it into their work. Without additional context or references, the claim remains somewhat verifiable, as it lacks sufficient justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper should include more discussions about why Large Language Models (LLMs) struggle with fine-grained hard constraints and how to address these issues. This feedback is somewhat helpful as it highlights a specific area where the authors could enhance their work by providing a more comprehensive analysis or discussion. However, the comment lacks depth and does not offer specific guidance on what aspects of the discussion should be included or how to address the problems. To be more helpful, the comment could provide examples or suggestions for addressing the issue, making it more actionable for the authors. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while the experimental results suggest the value of the proposed approach for self-supervised learning on 360 video data with spatial audio, the paper does not provide sufficient insights into why this specific type of data is important for self-supervised learning. The comment implies that the authors should elaborate on the significance of this data type in the context of self-supervised learning. However, it does not explicitly instruct the authors to add more details or examples to support this claim. The action is implicit and somewhat vague, as the authors need to infer that they should provide more context or insights. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of insights into why self-supervised learning is needed for 360 video data with spatial audio. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for more insights but lacks detail on what those insights should include or how they should be presented. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not provide sufficient insights into why self-supervised learning is needed for 360 video data with spatial audio. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the paper does not offer sufficient insights. As a result, the claim is not well-supported, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a gap in the paper by pointing out that while the experimental results suggest the value of the proposed approach for self-supervised learning on 360 video data with spatial audio, the paper lacks insights into why this specific type of data is important for self-supervised learning. This feedback highlights a need for the authors to provide more context or explanation regarding the significance of this data type in the context of self-supervised learning. However, the comment does not offer specific suggestions or guidance on how to address this gap, leaving the authors with a clear understanding of the issue but without actionable steps to improve their draft. Therefore, the comment is somewhat helpful, as it identifies a meaningful area for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This provides a clear and explicit action for the authors to take, as they need to average their results over multiple runs to ensure the statistical significance of their findings. The comment is specific in its suggestion, detailing exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this issue pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs improvement. While the comment is specific in its suggestion, the absence of grounding limits its usefulness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the results should be averaged over multiple runs to determine statistical significance. This is a logical and straightforward recommendation that aligns with standard practices in statistical analysis. However, the comment does not provide specific examples or references to support this claim, which could make it less convincing. While the reasoning is clear, the lack of detailed justification or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the results should be averaged over multiple runs to determine statistical significance. This is a clear and actionable piece of feedback that directly addresses a potential issue with the statistical analysis of the results. By averaging results over multiple runs, the authors can ensure that their findings are robust and statistically significant, which is crucial for the validity of their conclusions. This feedback provides a specific and constructive suggestion that the authors can easily implement to improve the quality of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the trade-offs between annotation effort and training performance. While the comment implies that the authors should highlight these observations, it does not provide explicit instructions on how to do so. The action is somewhat explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the observations and conclusions are hidden in the experimental section, implying that the authors should highlight them. However, it does not specify which part of the experimental section contains these observations or conclusions, making it weakly grounded. The comment is specific in its suggestion to highlight the observations and conclusions, which is useful for understanding the trade-offs of annotation effort and training performance. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the observations and conclusions are hidden in the experimental section and recommends highlighting them to improve understanding of the trade-offs between annotation effort and training performance. However, the comment does not provide any specific examples, reasoning, or references to support why highlighting these observations would be beneficial. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting that the observations and conclusions are hidden in the experimental section. It suggests that highlighting these observations would enhance the reader's understanding of the trade-offs between annotation effort and training performance. This feedback is clear and actionable, providing a direct suggestion for improvement that could significantly enhance the paper's clarity and impact. However, the comment could be more helpful if it offered additional guidance on how to effectively highlight these observations or suggested specific ways to present the information. Overall, the comment is mostly helpful as it provides a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the performance comparison of KDE and other approaches when the decision space is beyond binary. It references Remark 1 and a specific paper by Zhang et al. [44], suggesting that the authors should consider this comparison. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be addressed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment references \"Remark 1\" and a specific paper by Zhang et al. [44], suggesting that the authors should consider a performance comparison of KDE and other approaches when the decision space is beyond binary. However, the authors cannot confidently determine which part of the paper this remark is located in, as it is not explicitly mentioned. The comment is specific in its suggestion to compare performance on datasets with a decision space beyond binary, but the lack of grounding makes it difficult for the authors to identify the exact section or part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the performance comparison of KDE and other approaches when the decision space is beyond binary, referencing Remark 1 and a specific paper by Zhang et al. [44]. While the comment suggests that this comparison might be necessary, it does not provide a detailed explanation or justification for why this comparison is important or how it would impact the paper. The lack of specific reasoning or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about the performance comparison of KDE and other approaches when the decision space is beyond binary, referencing Remark 1 and a specific paper by Zhang et al. [44]. While the comment identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how to conduct this comparison or what aspects of the comparison should be considered. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" While the first question prompts the authors to explore the relationship between model capacity and FID, it does not provide explicit guidance on how to address this. The second part acknowledges unexpected artifacts but does not offer specific suggestions or actions for the authors to take. The comment lacks explicit and concrete actions or suggestions for the authors to address these issues, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" However, it does not specify which part of the paper these questions relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to identify the exact areas that need attention. While the questions are specific about the issues, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions: \"How the capacity of the SR model affects the FID\" and \"since the proposed method is pipelining, there are some unexpected artifacts.\" These questions are open-ended and do not contain specific claims or opinions that require verification. They are more like requests for clarification or further exploration, which do not align with the definition of a claim. Therefore, the comment is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises two questions about the impact of the SR model's capacity on the FID score and notes the presence of unexpected artifacts due to the pipelining of the proposed method. While the questions highlight potential areas for further investigation and clarification, they do not provide specific guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it identifies areas that require attention, but it lacks depth and actionable advice, making it only marginally helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the paper lacks additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. While it suggests that these experiments are needed, it does not provide explicit guidance on how to conduct them or what specific aspects of the paper should be compared or analyzed. The action is implicit and somewhat vague, as the authors need to infer that they should perform these experiments to address the lack of additional experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not specify which part of the paper these experiments are missing from or where they should be added. This makes it difficult for the authors to identify the exact areas that need improvement. The comment is not grounded as it does not provide specific references or sections, and it is also not specific because it does not detail what kind of experiments are needed or how they should be conducted. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper lacks additional necessary experiments, including comparison experiments, ablation studies, and hyperparameter analysis. However, it does not provide any specific reasoning or examples to support this claim. Without detailed justification or references, the authors may find it challenging to understand why these experiments are necessary or how they would enhance the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of additional necessary experiments, such as comparison experiments, ablation studies, and hyperparameter analysis. This feedback is valuable as it highlights specific areas where the paper could be strengthened to provide a more comprehensive evaluation of the proposed method. However, the comment could be more helpful if it provided suggestions on how to conduct these experiments or what specific aspects of the method should be compared or analyzed. Despite this, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the fairness of the comparison between the proposed method and the state-of-the-art (SOTA). It points out that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental results and highlights a concern regarding the fairness of the comparison between the proposed method and the state-of-the-art (SOTA). It points out that without prior information, the proposed method does not show an advantage compared to the SOTA, similar to the benchmarks. However, the advantage is only evident when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. While the comment is specific about the issue of fairness and the additional complexity of the proposed method, it does not explicitly mention which part of the paper this issue is discussed in. This makes it weakly grounded, as the authors may need to infer the section being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer suggests that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim somewhat verifiable, as it is based on logical reasoning but lacks sufficient support. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue with the fairness of the comparison between the proposed method and the state-of-the-art (SOTA). It highlights that the proposed method lacks an advantage without prior information, similar to the benchmarks, and that the advantage only emerges when prior knowledge is used. The reviewer points out that the proposed method essentially requires two representation models, VAE/GAN + CL, which adds complexity and cost. This feedback is valuable as it challenges the authors to consider the fairness of their comparisons and the practical implications of their method. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these issues, such as alternative experimental setups or additional analysis. Overall, the comment is somewhat helpful, as it raises important concerns but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not provide explicit guidance on how to incorporate these games into the experiments or what specific aspects of the methods should be analyzed in this context. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. The authors may infer that it pertains to the experimental setup or results, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of collaborative games and the comparison with competitive settings, but without a clear reference to the paper, it is weakly grounded and specific. Therefore, this comment aligns with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should include collaborative games, which would be interesting to see how the evaluated methods behave in both collaborative and competitive settings. However, the comment lacks specific details or examples to support this suggestion, making it difficult for the authors to understand the reasoning behind it. Without additional context or references, the claim is considered borderline verifiable, as it provides a general direction but lacks the necessary depth or evidence to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that the experiments should include collaborative games to provide a more comprehensive evaluation of the methods. While it offers an interesting direction for future work, it lacks specific guidance on how to incorporate these games into the experiments or what aspects of the methods should be analyzed in this context. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, making it difficult for the authors to be convinced of the results. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue. It lacks concrete guidance on what specific information should be included or how the authors should present the experimental settings to make the figures more convincing. Without actionable steps or detailed guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figures 1 to 9,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly identifies the issue as the missing experimental settings for these figures, which makes them hard to be convincing. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental settings for Figures 1 to 9 are missing, making them hard to be convincing. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the experimental settings are missing or how this impacts the persuasiveness of the figures. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that the experimental settings for Figures 1 through 9 are missing, which makes it difficult for the authors to be convinced of the results. This feedback is clear and actionable, as it highlights a critical gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided some guidance on how the authors might include or present the experimental settings to make the figures more convincing. Despite this, the comment is mostly helpful as it directs the authors to a specific area that requires improvement, allowing them to enhance the clarity and persuasiveness of their work. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the rationale behind the work, suggesting that some parameter isolation methods are tailored to leverage sparsity, which could impact the learning of new task knowledge. However, the comment does not provide explicit guidance on how the authors should address this issue or clarify their rationale. The action is implicit and vague, as it does not specify what needs to be done to resolve the ambiguity. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the rationale behind the work, specifically mentioning the observation that current parameter isolation methods often hinder the acquisition of new task knowledge. It suggests pathway protection based on the sparsity exhibited by activation channels in deep networks. However, the comment does not specify which part of the paper this observation is made or where the authors discuss the proposed method. This makes it difficult for the authors to pinpoint the exact section or part of the paper that needs clarification. While the comment is specific about the issue of parameter isolation methods and sparsity, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some parameter isolation methods are specifically tailored to leverage sparsity, which could hinder the acquisition of new task knowledge. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand and address the issue. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the rationale behind the work, specifically questioning how the proposed method avoids impeding the learning of new task knowledge. It highlights that some parameter isolation methods are tailored to leverage sparsity, which could impact the acquisition of new task knowledge. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or clarify their rationale. While it points out a potential ambiguity, it lacks actionable advice or specific examples to help the authors improve their draft. Therefore, the comment is somewhat helpful, as it raises a valid concern but does not offer comprehensive feedback for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the regularization term appears to be ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific changes should be made to the regularization term. While the authors understand the need for theoretical support and alternative statistics, they are left without clear instructions on how to address these issues. The comment is somewhat actionable as it identifies a potential improvement but lacks concrete details on how to achieve it. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the regularization term, which is a specific part of the paper. It provides feedback on the ad-hoc nature of the term and suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not specify which part of the paper discusses the regularization term or provide detailed guidance on how to incorporate these alternative statistics. The authors can infer that the comment pertains to the regularization section, but the lack of explicit mention makes it weakly grounded. The comment is specific in its critique of the ad-hoc nature and the need for theoretical support, but the lack of grounding makes it weakly grounded and specific. Therefore, it aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the regularization term is ad-hoc and lacks theoretical support, suggesting that other statistics could be used instead of the mean and standard deviation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. The lack of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the claim but lacks sufficient detail to fully substantiate it.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the regularization term, noting that it appears to be ad-hoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide specific guidance on how to implement these suggestions or what changes should be made to the regularization term. While it highlights an area for improvement, the lack of detailed feedback limits its helpfulness. The authors are left with a general idea of what could be improved but without concrete steps to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct comparisons with existing fairness algorithms in the experimental section. It provides a clear action for the authors to take, which is to integrate benchmark comparisons against state-of-the-art fairness algorithms. This action is explicit and concrete, as it specifies exactly what needs to be done to enhance the paper. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for comparisons with existing fairness algorithms and suggests integrating benchmark comparisons against state-of-the-art fairness algorithms. This provides detailed guidance on what needs to be done to enhance the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors have not conducted comparisons with existing fairness algorithms in the experimental section. It suggests that integrating benchmark comparisons against state-of-the-art fairness algorithms would enhance the paper by providing tangible evidence of the proposed method\\'s performance and positioning the ManyFairHPO framework within the existing FairML research landscape. However, the comment lacks specific examples or references to existing fairness algorithms, making it somewhat verifiable. The authors would need to infer the need for such comparisons and the importance of benchmarking to fully understand the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the experimental section by noting the absence of comparisons with existing fairness algorithms. It provides a clear and actionable suggestion to integrate benchmark comparisons against state-of-the-art fairness algorithms, which would enhance the paper\\'s credibility and demonstrate the effectiveness of the proposed method. By offering this constructive feedback, the comment guides the authors to improve the depth and impact of their research. However, the comment could be more helpful if it provided specific examples of existing fairness algorithms or suggested particular benchmarks to include. Overall, the feedback is mostly helpful as it highlights a crucial area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the supervised pretraining method based on the homo-lumo gap, suggesting that it might lead to negative transfer. It provides an example of this issue by mentioning the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. However, the comment does not explicitly instruct the authors to address this issue or provide guidance on how to mitigate it. While the authors can infer that they should consider alternative pretraining methods or discuss the implications of this finding, the action remains somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to supervised pretraining based on the homo-lumo gap, which is a particular aspect of the paper. It mentions the potential for negative transfer and provides an example of this issue by referencing the performance of Transformer-M on the QM9 dataset. However, the comment does not explicitly mention which part of the paper discusses the homo-lumo gap or the specific tasks where Transformer-M performs poorly. This makes it challenging for the authors to pinpoint the exact section or part of the paper being addressed, but it is clear that the issue is specific to the homo-lumo gap. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that supervised pretraining based on the homo-lumo gap may lead to negative transfer, as evidenced by the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. This claim is somewhat verifiable as it provides a specific example of a potential issue and suggests that it contradicts the paper\\'s claim of Transformer-M being a \"general-purpose neural network model.\" However, the comment lacks detailed reasoning or references to support the claim fully, making it somewhat verifiable. Therefore, the label is 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the supervised pretraining method based on the homo-lumo gap, suggesting that it might lead to negative transfer. It provides an example by mentioning the poor performance of Transformer-M on most tasks in the QM9 dataset, except for homo, lumo, and gap. This observation is important as it challenges the paper\\'s claim that Transformer-M is a \"general-purpose neural network model.\" However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their model. While it highlights a critical point, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to the paper. The action is implicit, as the authors would need to infer that they should reconsider the name or provide a more nuanced description of the phenomenon. The comment is somewhat actionable because it points out a specific issue but lacks concrete details on how to implement the suggested changes. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue regarding the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. However, the comment does not specify which part of the paper discusses this phenomenon, making it weakly grounded. It is specific in detailing what the issue is and why the name might be problematic, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the name \"distributional generalization\" used to describe a phenomenon, suggesting that it might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. The comment provides a logical explanation for why the name might be too strong, but it lacks specific examples or references to support the claim. Without detailed examples or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires additional evidence to fully substantiate it.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the name used to describe a phenomenon, suggesting that \"distributional generalization\" might be too strong and that the empirical phenomenon is better described as the ideal of the total variation between the test and train distributions of the network\u2019s outputs vanishing to zero. This feedback is somewhat helpful as it points out a specific area for improvement and provides a clear rationale for why the current name might be misleading. However, the comment could be more helpful if it offered suggestions for alternative names or ways to clarify the phenomenon's description. Overall, the comment provides a valuable insight that could guide the authors in refining their terminology and enhancing the clarity of their work. Therefore, it is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the theoretical contribution as \"ok\" but expresses concern about its strength, noting that it is \"weak, unpractical bound\" and that the proof does not provide \"particular mathematical novelty.\" However, the comment does not offer any specific suggestions or actions for the authors to take to address these issues. It lacks concrete guidance on how to improve the theoretical contribution or the proof. As a result, the authors are left without a clear understanding of what steps they should undertake to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the theoretical contribution and the proof, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the theoretical contribution, such as being \"weak, unpractical bound\" and lacking \"particular mathematical novelty.\" This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical contribution is \"ok\" but not \"particularly strong,\" given existing results. It further criticizes the contribution as a \"weak, unpractical bound\" and notes that the proof does not provide \"particular mathematical novelty.\" However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the criticism. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it provides a general assessment but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the theoretical contribution as \"ok\" but expresses concern about its strength, noting that it is a \"weak, unpractical bound\" and that the proof does not provide \"particular mathematical novelty.\" This feedback provides a clear assessment of the theoretical contribution's limitations, which is valuable for the authors to understand the scope of their work. However, the comment lacks actionable suggestions or guidance on how the authors might address these issues or improve the contribution. While it identifies a weakness, it does not offer specific steps or strategies for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hoped-for rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide explicit guidance on how to do so. The action is implicit, as the authors need to infer that they should clarify the phrase, but it lacks concrete details on what specific changes or additions are needed. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to address it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific line numbers (L240 and L428), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what the authors should clarify, namely the meaning of the phrase \"is sufficient\" in the context of the sum of \"optimistic\" hoped-for rewards and the expected actual rewards. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of the phrase \"is sufficient\" in the context of the paper, specifically concerning the sum of \"optimistic\" hoped-for rewards and the expected actual rewards. While the comment implies that the authors should clarify this phrase, it does not provide any specific examples, reasoning, or references to support the claim that the phrase is unclear or requires clarification. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment points out a specific ambiguity in the paper, particularly regarding the phrase 'is sufficient' at lines 240 and 428. It suggests that the authors might be trying to convey that the sum of 'optimistic' hoped-for rewards is close to the expected actual rewards. However, the comment does not provide any guidance or suggestions on how the authors could clarify this phrase or address the potential ambiguity. Without specific advice on what changes to make or how to rephrase the sentence, the authors may find it challenging to improve their draft based on this feedback. Therefore, the comment is barely helpful, as it identifies a potential issue but lacks actionable guidance.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the theoretical discussions could be improved by providing sample complexity-type results for not returning NSF, such as the sufficient amount of training data points needed. However, it does not explicitly instruct the authors to include these results or provide detailed guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they should add these results. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexity-type results related to not returning NSF. However, it does not specify which part of the paper these discussions are in, making it weakly grounded. The comment is specific in its suggestion to include additional results, but the lack of grounding makes it difficult for the authors to pinpoint the exact area for improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical discussions could be improved by providing sample complexity-type results for not returning NSF. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. The comment lacks sufficient evidence or justification to be considered fully verifiable. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that the current theorems could be enhanced by including sample complexity-type results for not returning NSF. This feedback is actionable, as it provides a clear direction for the authors to consider adding additional results to strengthen their theoretical analysis. However, the comment could be more helpful if it offered more detailed guidance on how to derive or incorporate these results. Overall, the comment is mostly helpful, as it provides a valuable suggestion for improvement but lacks some depth in terms of actionable steps.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the authors' VAD (Visual Audio Description) description, suggesting that it discards TF (Time-Frequency) bins with a magnitude less than epsilon. The reviewer argues that this approach is problematic because it discards TF bins with zero magnitude, which could lead to division by zero. The comment implies that the authors should reconsider their VAD definition, as it is not aligned with the typical understanding of VAD, which focuses on the presence of speech over time rather than frequency. However, the comment does not provide explicit guidance on how the authors should revise their VAD description or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer the need for a more detailed explanation or a different approach to their VAD definition. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"VAD description,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the VAD description, explaining why it is puzzling and suggesting that it discards TF bins with zero magnitude, which could lead to division by zero. The comment further critiques the VAD definition, noting that it is not aligned with the typical understanding of VAD, which focuses on the presence of speech over time rather than frequency. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' VAD description is puzzling and suggests that it discards TF bins with a magnitude less than epsilon, which could lead to division by zero. The reviewer argues that this approach is not aligned with the typical understanding of VAD, which focuses on the presence of speech over time rather than frequency. However, the comment lacks specific examples or references to support the claim that the VAD definition is problematic or misaligned with standard practices. Without detailed reasoning or evidence, the claim is difficult to verify, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides a detailed critique of the authors' VAD description, questioning its approach of discarding TF bins with a magnitude less than epsilon. It highlights that this method is problematic because it could lead to division by zero and suggests that a VAD should focus on the presence of speech over time rather than frequency. This feedback is clear and actionable, as it identifies a specific issue with the VAD description and offers a clear alternative approach. However, the comment could be more helpful if it provided more detailed guidance on how to revise the VAD description or suggested specific changes to address the identified problem. Overall, the comment is mostly helpful, as it provides valuable insights for improvement but could be more comprehensive.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses concerns about the paper's readability and the lack of clear intuition for how the pieces fit together, as well as the limited context provided by the experiments. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment lacks specific guidance on how to improve the paper's clarity or provide more context for the experiments. Without actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concerns about the paper's readability and the lack of clear intuition for how the pieces fit together, as well as the limited context provided by the experiments. However, it does not specify which part of the paper is difficult to follow or lacks context. The authors cannot confidently determine which sections or aspects of the paper are being addressed, making the comment weakly grounded. Additionally, the comment is somewhat specific in that it identifies the issues of clarity and context, but it does not provide detailed guidance on how to address these problems. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses concerns about the paper's readability and the lack of clear intuition for how the pieces fit together, as well as the limited context provided by the experiments. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The comment lacks sufficient evidence or justification to be considered verifiable. Therefore, it is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper's readability, noting that it is not particularly easy to follow and lacks a clear intuition for how the pieces fit together. The authors are also criticized for the experiments having little context, which hinders the reader's understanding. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it points out areas that need attention, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fairness of comparing the student and refinement networks, which are trained simultaneously. It suggests that the comparison might be unfair and requests the authors to provide KID/FID metrics for their teacher network. While the comment implies that the authors should provide these metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include the requested metrics to address the concern about fairness. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the request for metrics, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. However, the comment does not provide any reasoning, examples, or references to support the claim that the comparison might be unfair. Without additional context or justification, the authors may find it difficult to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fairness of comparing student and refinement networks, which are trained simultaneously, and requests the authors to provide KID/FID metrics for their teacher network. This feedback is somewhat helpful as it identifies a potential issue with the experimental setup and suggests a specific metric to include, which could enhance the transparency and rigor of the evaluation. However, the comment lacks depth and does not provide detailed guidance on how to address the fairness concern or why the comparison might be unfair. The authors would need to infer that they should include the requested metrics to improve the clarity of their results. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment implies that the authors should consider this alternative, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to implement or explore this suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 157,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should consider regarding the scaling of the refined region vector, suggesting an alternative approach. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the scaling of the refined region vector and suggests an alternative approach by introducing a scaling variable before the attention weight. While the comment is based on a logical observation about the scaling factor, it does not provide specific examples or references to support the claim that the current approach might be limiting. The suggestion for an alternative approach is clear, but the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific aspect of the paper that could be improved by suggesting an alternative approach to scaling the refined region vector. It questions the current method and proposes an alternative, which could potentially enhance the model's performance. However, the comment lacks depth and does not provide detailed reasoning or examples to support the claim. While it offers a direction for improvement, it does not fully address the potential impact or provide comprehensive guidance on how to implement the suggested change. Therefore, the comment is somewhat helpful, as it provides a starting point for the authors to consider but lacks the depth needed for a fully comprehensive feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue related to goal misspecification in the ALFRED benchmark, noting that the LLM did not accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks guidance on how the authors might improve their draft to address this problem, such as suggesting specific changes or improvements to the methodology or experimental setup. Without actionable steps or suggestions, the authors are left without a clear path to resolve the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to goal misspecification in the ALFRED benchmark, noting that failures occurred due to the LLM's inability to accurately recover the formal goal predicate, especially with ambiguities in human language. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in detailing the problem, the absence of explicit grounding information makes it challenging for the authors to understand where to focus their improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that failures on the ALFRED benchmark often occurred due to goal misspecification, where the LLM did not accurately recover the formal goal predicate, especially when faced with ambiguities in human language. This claim is somewhat verifiable as it provides a specific example of a problem that can occur in the ALFRED benchmark. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors could benefit from additional evidence or examples to strengthen the claim and provide a clearer understanding of the issue.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue related to goal misspecification in the ALFRED benchmark, noting that failures often occur due to the LLM's inability to accurately recover the formal goal predicate, particularly when faced with ambiguities in human language. While the comment highlights a potential problem, it does not provide actionable suggestions or guidance on how the authors might address this issue. Without specific advice on improving the methodology or experimental setup, the authors are left without a clear path to resolve the problem. Therefore, the comment is somewhat helpful, as it points out a weakness but lacks depth and direction for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two main concerns: the small improvement of the proposed method over SOTA methods like IGEV and the question of whether there is a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to understand why the effect is not significantly improved. Additionally, the reviewer questions whether Sampling-Gaussian can significantly improve such frameworks. While the comment provides explicit suggestions for analysis and questions, it lacks concrete guidance on how to conduct the analysis or what specific aspects to focus on. The authors are left with a general idea of what to do but without detailed steps or examples, making the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises two specific concerns about the improvement of the proposed method over SOTA methods like IGEV and questions about the presence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. However, it does not explicitly mention which part of the paper these concerns relate to, such as specific sections, tables, or figures. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its questioning, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions about the improvement of the proposed method over SOTA methods like IGEV and the presence of a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to determine why the effect is not significantly improved. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the improvement is small or that there is no multi-peak distribution problem. Without these elements, the claim is difficult to verify, making the comment mostly unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two main concerns: the small improvement of the proposed method over SOTA methods like IGEV and the question of whether there is a multi-peak distribution problem in iterative optimization schemes similar to IGEV. The reviewer suggests analyzing the distribution of disparities produced by IGEV compared to other baselines to understand why the effect is not significantly improved. Additionally, the reviewer questions whether Sampling-Gaussian can significantly improve such frameworks. While the comment identifies potential areas for improvement and provides a direction for analysis, it lacks specific guidance on how to conduct the analysis or what specific aspects to focus on. The feedback is somewhat helpful as it points out areas for further investigation but does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should delve deeper into how specific models behave differently when ReGuide is applied, providing a more nuanced understanding of the conclusions. It gives an example of comparing false positive rates (FPR) between models with and without ReGuide. However, the comment does not explicitly instruct the authors to conduct this analysis or present the results in a specific way. While the action is implied, it lacks concrete guidance on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests a deeper investigation into how specific models behave differently when ReGuide is applied, which is a specific aspect of the paper. However, it does not explicitly mention which part of the paper this investigation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare false positive rates (FPR) between models with and without ReGuide, providing a clear direction for the authors to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should provide a deeper investigation into how specific models behave differently when ReGuide is applied, particularly focusing on false positive rates (FPR). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without detailed guidance or evidence, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting a deeper investigation into how specific models behave differently when ReGuide is applied. It provides a specific example, such as comparing false positive rates (FPR) between models with and without ReGuide, which could enhance the nuance of the conclusions. However, the comment lacks broader context or suggestions on how to conduct this analysis effectively, leaving the authors with limited guidance on how to implement the proposed enhancement. While the feedback is somewhat helpful, it could be more impactful with additional details or examples. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable suggestion that provides clear guidance on how the authors can improve their draft. By explicitly stating the need for clarification, the comment directs the authors to address a potential ambiguity in their presentation. The action is both explicit and concrete, as it clearly specifies what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. However, it does not specify which part of the paper this clarification is needed, making it weakly grounded. The comment is specific in its suggestion, as it clearly identifies the need for clarification regarding the nature of the Fourier modes. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a suggestion for improvement, but it does not provide any specific reasoning, examples, or references to support why this clarification is necessary or beneficial. The comment lacks depth and does not offer a clear justification for the suggestion, making it difficult for the authors to understand the rationale behind it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should clarify whether the Fourier modes are represented as real or complex numbers. This is a specific and actionable piece of feedback that could help improve the clarity and precision of the paper. By addressing this suggestion, the authors can ensure that their presentation is unambiguous and easier to understand. However, the comment could be more helpful if it provided additional context or examples of how this clarification might impact the overall understanding of the paper. Despite this, the feedback is clear and actionable, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the notations $h, g$ and $\\delta$ are introduced without clear definitions of their input and output domains. While the comment identifies a specific issue with the clarity of the notations, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to clarify the notations, but the comment lacks concrete instructions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a clear area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. However, it does not specify which part of the paper these notations are introduced in, making it weakly grounded. The comment is specific in detailing the problem with the notations, but the lack of grounding makes it difficult for the authors to pinpoint the exact location of the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point highlights a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. This is a clear and specific claim that requires the authors to clarify these notations for better understanding and consistency. The comment is fully verifiable as it provides a direct and actionable suggestion for improvement, allowing the authors to address the issue effectively. Therefore, the comment is rated as 5: Fully Verifiable.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment identifies a specific issue with the notations $h, g$ and $\\delta$ by pointing out that their input and output domains are not clearly defined. This is a clear and actionable feedback that helps the authors improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided additional guidance on how to define these domains or suggested specific ways to improve the clarity of the notations. Despite this, the feedback is mostly helpful as it directs the authors to a critical area for improvement, allowing them to enhance the quality of their work. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that it is unclear how much performance gain is attributed to the task formulation versus the use of pre-trained language models. It suggests including results using the GCPG model without pre-trained initializations to address this ambiguity. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct these additional experiments or present the results. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and then decide how to implement them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"missing ablations,\" which allows the authors to accurately identify the part of the paper being addressed. It specifies what needs to be addressed by suggesting the inclusion of results using the GCPG model without pre-trained initializations. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the clarity of performance gains attributed to the task formulation versus pre-trained language models. It suggests including results using the GCPG model without pre-trained initializations to address this ambiguity. However, the comment lacks specific examples or references to support the claim that the current results are unclear or that the suggested experiment would provide additional insights. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may need to infer the need for additional experiments and results to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by pointing out the lack of clarity regarding the performance gains attributed to the task formulation versus the use of pre-trained language models. It suggests including results using the GCPG model without pre-trained initializations to address this ambiguity. This feedback is valuable as it provides a clear direction for the authors to enhance the transparency and rigor of their experimental results. However, the comment could be more helpful if it offered additional guidance on how to conduct these additional experiments or present the results effectively. Overall, the comment is mostly helpful, as it highlights a significant area for improvement and provides a clear suggestion for addressing it.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a difficulty in understanding the axes of Figure 1, but it does not provide any explicit or implicit suggestions on how to address this issue. The authors are left without guidance on how to clarify the axes or improve the figure's clarity. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Figure 1 is located in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is specific in that it points out a lack of clarity regarding the axes of the figure, which is a clear issue that needs to be addressed. However, without the specific section mentioned, the authors cannot confidently determine where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point states that it is \"hard to understand what the axes are for Figure 1,\" which is a subjective observation about the clarity of the figure. However, it does not provide any specific reasoning or examples to support why this is a problem or how it could be addressed. Without additional context or suggestions, the claim lacks sufficient justification and is therefore considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of Figure 1, noting that it is difficult to understand what the axes represent. This feedback is clear and actionable, as it directs the authors to improve the figure's clarity, which is a crucial aspect of effective communication in research papers. However, the comment could be more helpful if it provided suggestions on how to improve the figure's clarity, such as adding labels or explanations. Despite this, the comment is mostly helpful as it highlights a significant area for improvement, allowing the authors to address the issue effectively.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of direct runtime comparisons with existing methods, suggesting that such comparisons are necessary to demonstrate the efficiency of the proposed approach. It implies that the authors should include these comparisons to provide a more comprehensive evaluation of their method. However, the comment does not specify which existing methods should be compared or how the comparisons should be conducted, leaving the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of missing direct runtime comparisons with existing methods, which is a specific aspect of the paper. It highlights the importance of these comparisons to demonstrate the efficiency of the proposed approach. However, the comment does not explicitly mention which part of the paper discusses the runtime comparisons or where these comparisons should be included. This makes it challenging for the authors to pinpoint the exact section that needs revision. Therefore, the comment is weakly grounded but specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that direct runtime comparisons with existing methods are missing, which is a valid concern. The comment suggests that these comparisons are necessary to demonstrate the efficiency of the proposed approach, as implicit differentiation usually incurs additional computational costs. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for these comparisons based on the reasoning provided, which could be improved with more detailed justification or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of direct runtime comparisons with existing methods. This is a crucial aspect for evaluating the efficiency and practicality of the proposed approach. The comment suggests that such comparisons are necessary to demonstrate the effectiveness of the proposed method, which is a valuable piece of feedback for the authors. However, the comment could be more helpful if it provided specific examples of existing methods that should be compared or suggested ways to conduct these comparisons. Despite this, the feedback is mostly helpful as it directs the authors to an important area for improvement, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning and that it lacks any technical contribution. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the framework could be improved to add technical contribution. The comment lacks concrete guidance on how to enhance the framework or what new elements could be introduced to differentiate it from existing approaches. As a result, the authors are left without a clear path to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section or aspect being addressed. It is also not specific because it does not provide details on what aspects of the framework are lacking in technical contribution. The comment is vague and does not offer any guidance on how to address the issue of the framework being a simple combination of existing methods. Therefore, this comment is not grounded and not specific, aligning with category 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the proposed framework is a simple combination of meta-learning and federated learning and that it lacks any technical contribution. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the framework is considered a simple combination or how it lacks technical contribution. Therefore, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the proposed framework, suggesting that it is a simple combination of meta-learning and federated learning and lacks any technical contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or enhance the framework. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft. Therefore, the comment is barely helpful, as it highlights a concern but does not offer substantial assistance in addressing it.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that including case studies and error studies would enhance the paper by providing a more convincing demonstration of the effectiveness of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation. However, the comment does not explicitly instruct the authors to include these elements or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors are left to infer that they should add case studies and error studies to their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including case studies and error studies to enhance the paper\\'s effectiveness, providing an example of a case study in the context of graph pre-training for AMR parsing and generation. However, it does not specify which part of the paper should be addressed or how these studies should be integrated. The authors can infer that the feedback pertains to the methodology or results sections, but the lack of explicit mention makes it weakly grounded. The comment is specific in suggesting the inclusion of case studies and error studies, but the absence of detailed guidance on implementation makes it somewhat grounded and specific. Therefore, this comment aligns with category 3: Weakly Grounded and Specific.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that including case studies and error studies would enhance the paper\\'s effectiveness by providing a more convincing demonstration of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed reasoning or references to support the claim that these studies would be beneficial. While the suggestion is logical, the absence of specific examples or references makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that including case studies and error studies would enhance the paper's effectiveness by providing a more convincing demonstration of the proposed components. It provides an example of a case study in the context of graph pre-training for AMR parsing and generation, which helps to illustrate the point. However, the comment lacks detailed guidance on how to implement these studies or what specific aspects of the proposed components should be highlighted. While it offers a valuable suggestion, the feedback could be more helpful if it included more detailed examples or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the traditional DCI framework, suggesting that it may already consider explicitness (E) and size (S). It provides examples, such as the need for a fixed capacity of probing and latent size to evaluate disentanglement (D). The comment also notes that DCI and ES might be entangled, and changing the capacity of probing or latent size can affect the DCI evaluation. However, the comment does not explicitly instruct the authors to address these concerns or provide specific guidance on how to improve their draft. The action is implicit and vague, as the authors are left to infer what needs to be done. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the traditional DCI framework and its consideration of explicitness (E) and size (S). It provides examples, such as the need for a fixed capacity of probing and latent size to evaluate disentanglement (D). The comment also notes the entanglement between DCI and ES, suggesting that changes in probing capacity or latent size can affect the DCI evaluation. However, the comment does not specify which part of the paper discusses the DCI framework or where the authors can find the relevant information. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in detailing the issues with the DCI framework, but without clear grounding, it is difficult for the authors to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the traditional DCI framework, suggesting that it may already consider explicitness (E) and size (S). It provides examples, such as the need for a fixed capacity of probing and latent size to evaluate disentanglement (D). The comment also notes the entanglement between DCI and ES, indicating that changes in probing capacity or latent size can affect the DCI evaluation. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. While the logic is somewhat clear, the absence of concrete examples or references makes it somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises concerns about the traditional DCI framework, suggesting that it may already consider explicitness (E) and size (S). It provides examples, such as the need for a fixed capacity of probing and latent size to evaluate disentanglement (D). The comment also notes the entanglement between DCI and ES, indicating that changes in probing capacity or latent size can affect the DCI evaluation. However, the comment lacks specific guidance or suggestions on how the authors might address these concerns or improve their draft. While it identifies an area for improvement, it does not provide actionable steps or detailed advice, making it somewhat helpful. The feedback is somewhat helpful as it highlights potential issues but could be more comprehensive with actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should discuss the rationale behind the manual disentanglement and explore alternative approaches. The lack of concrete suggestions or detailed guidance makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not specify which part of the paper this issue is discussed or addressed, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of manual disentangling, it lacks grounding as it does not provide clear guidance on which part of the paper to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on why manual disentanglement is used and whether everything could be learned instead. However, the comment does not provide any specific reasoning, examples, or references to support the claim that manual disentanglement is a significant issue or why it is necessary. Without additional context or justification, the claim is difficult to verify, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the manual disentangling process in the paper, specifically questioning why the semantic segmentation network is the first module in the pipeline. It suggests that the paper could benefit from a discussion on the rationale behind this choice and whether everything could be learned instead. This feedback is somewhat helpful as it points out a specific area for improvement and encourages the authors to consider alternative approaches. However, the comment could be more helpful if it provided more detailed guidance or examples on how the authors might address this issue or what specific changes they could make to their draft. Overall, the comment offers a clear direction for improvement, but it lacks depth and specificity, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method appears to simply adopt the self-attention mechanism from transformers and apply it to graphs. The reviewer expresses confusion about how the proposed method enhances generalization for distant nodes. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or clarify the connection between the theoretical analysis and the proposed method. The action is implicit and vague, leaving the authors uncertain about how to improve their draft. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method seems to simply adopt the self-attention mechanism from transformers and apply it to graphs. However, the comment does not specify which part of the paper this issue is related to, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the issue of the connection between theory and method, it lacks grounding as it does not provide explicit references or sections. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the connection between the theoretical analysis and the proposed method, specifically noting that the proposed method appears to simply adopt the self-attention mechanism from transformers and apply it to graphs. The reviewer expresses confusion about how the proposed method enhances generalization for distant nodes. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the proposed method is merely a direct adoption of the self-attention mechanism. Without additional context or evidence, the claim remains somewhat verifiable, as it is based on an interpretation of the method without clear justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the connection between the theoretical analysis and the proposed method, specifically questioning how the proposed method enhances generalization for distant nodes. It suggests that the method might be simply adopting the self-attention mechanism from transformers and applying it to graphs, which raises concerns about the novelty and impact of the proposed approach. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or clarify the connection between the theoretical analysis and the proposed method. While it points out a potential weakness, it does not provide actionable feedback or detailed insights that would help the authors improve their draft. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it does not provide explicit guidance on how the authors should address this problem. The authors are left to infer that they need to improve the clarity of their presentation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not provide detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"some pieces\" and \"equation (12),\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies that the presentation of these methods is vague and requires checking the original paper for understanding. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some pieces of the paper use existing methods, specifically mentioning equation (12), and notes that the presentation of these methods is vague, requiring the authors to check the original paper to understand them. While the comment identifies a potential issue with the clarity of the presentation, it lacks specific examples or references to support the claim that the presentation is vague or difficult to understand. The authors are left to infer the meaning, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the presentation of certain pieces of the paper, noting that some methods are described using existing methods, such as equation (12), and that their presentation is vague, requiring the authors to consult the original paper to understand them. This feedback is clear and actionable, as it highlights a potential area for improvement in the clarity and consistency of the paper. However, the comment could be more helpful if it provided suggestions on how the authors might improve the presentation or clarify the methods. Overall, the comment is mostly helpful, as it directs the authors to address a specific issue but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the stability definition needs better justification, specifically pointing out that the left side can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\). It proposes a more reasonable treatment by making the definition lower bounded. While the comment provides a clear action\u2014improving the justification of the stability definition\u2014it does not offer specific guidance on how to achieve this. The authors are left with a general direction but lack concrete steps to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the stability definition, suggesting that it needs better justification. It points out that the left side of the definition can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\), and proposes a more reasonable treatment by making the definition lower bounded. However, the comment does not specify which part of the paper discusses the stability definition, making it weakly grounded. It is specific in detailing the issue with the definition, but without explicit references, the authors may need to infer the section being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the stability definition needs better justification, specifically noting that the left side can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\). The comment suggests a more reasonable treatment by making the definition lower bounded. However, the comment lacks specific examples or references to support the claim about the arbitrariness of the left side, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the suggestion for improvement is not fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the stability definition, noting that the left side can be arbitrarily small under certain constructions of \\\\(\\\\tilde{g}\\\\). It suggests a more reasonable treatment by making the definition lower bounded. This feedback is clear and actionable, providing the authors with a specific direction to improve their work. However, it could be more helpful if it included additional details or examples to illustrate the problem. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional context or examples. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment does not provide explicit guidance on how to compare the methods or how to address the notations issues. The actions are implicit and vague, leaving the authors uncertain about the specific steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests comparing the effectiveness of the proposed method against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if it does not address the notations issues. However, the comment does not specify which part of the paper discusses the methodology or the issues mentioned above, making it difficult for the authors to pinpoint the exact sections that need attention. The comment is specific in its suggestions but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also suggests aiming for a more application-oriented venue if the notations issues are not addressed. However, the comment lacks specific examples or references to support the claim about the comparison with existing methods or the nature of the issues mentioned above. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should compare its effectiveness against existing methods, such as contrastive decoding, and addresses issues mentioned above. It also implies that the paper should aim for a more application-oriented venue if the notations issues are not addressed. However, the comment lacks specific guidance on how to compare the methods or what issues need to be addressed. It does not provide detailed suggestions or examples, making it somewhat helpful as it identifies areas for improvement but does not offer actionable steps for the authors to take. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several concerns about the algorithm's effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. While the comment identifies several areas for improvement, it does not provide explicit guidance on how the authors should address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the algorithm, specifically mentioning its reliance on the entire training dataset. It also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies areas that need improvement, such as the algorithm's performance with incomplete datasets and the comprehensiveness of the validation experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several concerns about the algorithm's effectiveness, particularly its reliance on the entire training dataset. It questions whether the algorithm can operate effectively when the training dataset is not fully perceptible. The comment also critiques the comprehensiveness of the validation experiments, the lack of analysis regarding time complexity and efficiency, and the need for the authors to further elucidate the technical contribution rather than the form of the attack. While the comment provides some context and questions, it lacks specific examples or detailed reasoning to fully substantiate the claims. The feedback is somewhat verifiable, as it identifies areas for improvement but does not provide comprehensive evidence or detailed explanations. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several important points regarding the algorithm's effectiveness, the comprehensiveness of the validation experiments, and the need for a clearer analysis of time complexity and efficiency. It also suggests that the authors should further elucidate the technical contribution rather than focusing solely on the form of the attack. While the comment identifies key areas for improvement, it lacks specific guidance on how the authors might address these issues or what changes could be made to enhance the paper. The feedback is somewhat helpful as it provides a general direction for improvement but does not offer detailed suggestions or actionable steps for the authors. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed method is not well-positioned in the literature and points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the positioning of their method in the literature. The action is implicit and vague, as it does not specify how the authors should conduct a thorough literature review or what specific aspects of their method need to be highlighted. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"proposed method\" and suggests a thorough literature review, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. This provides clear guidance on what the authors should consider in their literature review. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed method is not well-positioned in the literature and suggests that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. The comment provides specific examples of related work, which supports the claim and offers a clear rationale for why the method might not be as novel as initially presented. However, it could be more robust if it included a broader range of references or a more detailed explanation of how the proposed method differs from or builds upon these existing works. Overall, the claim is mostly verifiable, as it is supported by logical reasoning and specific examples, but it could be strengthened with additional evidence.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant issue with the proposed method, noting that it is not well-positioned in the literature. It points out that the key idea of representing the marginal score as the expectation of scores of distributions conditioned on inputs is already known and used in existing works, such as the denoising score matching objective [1] and score-interpolation [2]. This feedback is valuable as it highlights a potential gap in the authors' understanding of the existing literature and suggests that the method might not be as novel as claimed. However, the comment could be more helpful if it provided specific guidance on how the authors could address this issue, such as suggesting a more comprehensive literature review or highlighting the unique aspects of their method that differentiate it from existing approaches. Overall, the comment is somewhat helpful, as it identifies a critical area for improvement but lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is explicit and provides a clear action for the authors to take, which is to include a gradient comparison between KL and PCC. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"matching metric\" and the \"Pearson correlation coefficient (PCC)\" as key components of the paper. It also specifies the issue with the assumption that PCC is a more relaxed constraint compared to KL divergence, suggesting that the constraint strength should be defined by the gradient distribution. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence due to its invariance to scale and shift. It argues that the constraint strength of a loss function is defined by its gradient distribution and provides an example comparing KL divergence and MSE loss. The comment suggests that it is necessary to provide a gradient comparison between KL and PCC to support the claim. This feedback is mostly verifiable as it provides a logical reasoning and an example to support the claim, but it lacks specific references or detailed explanations of how the gradient comparison would be conducted. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the assumption that the Pearson correlation coefficient (PCC) is a more relaxed constraint compared to KL divergence. It critiques the reasoning based on scale and shift invariance and suggests that the constraint strength should be defined by the gradient distribution. The comment provides a clear example comparing KL divergence and MSE loss, which helps the authors understand the issue and the need for a gradient comparison between KL and PCC. This feedback is detailed and actionable, offering a specific suggestion for improvement that could enhance the paper's clarity and rigor. Therefore, the comment is highly helpful, as it provides a clear and constructive critique that guides the authors in addressing a critical aspect of their work.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. It also expresses confusion about certain aspects of the paper. While the comment implies that the authors should address these questions, it does not provide explicit instructions or detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about specific aspects of the paper, such as the handling of a debate and the potential reasons for changes in distribution. However, it does not explicitly mention which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact sections being addressed. While the questions are specific, the lack of explicit grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the handling of a debate in the paper and the potential reasons for changes in distribution. However, it does not provide any specific evidence, examples, or references to support these claims. The questions are open-ended and lack detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the handling of a debate in the paper, specifically questioning why the distribution might have changed and whether experiments disentangle changes in distribution from the removal of information. It also expresses confusion about certain aspects of the paper. While the comment identifies areas that need clarification, it lacks detailed guidance or suggestions on how to address these issues. The feedback is somewhat helpful as it points out specific areas of concern, but it does not provide actionable steps or detailed explanations to help the authors improve their draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. The reviewer suggests that direct comparison using the numbers from the paper is unfair and recommends reproducing the results using the same setting, as most recent methods have their code released. While the comment identifies an issue and suggests a potential solution, it does not provide explicit guidance on how to reproduce the results or what specific steps should be taken. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of AdamW with cosine learning rate for training the proposed method, while comparing it with methods that use Adam with fixed learning rate. This provides a specific point of comparison and highlights a potential issue with the fairness of the comparison. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in detailing the issue with the learning rate settings and suggesting that reproducing results with the same setting would be beneficial. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed method uses AdamW with cosine learning rate, while comparing methods use Adam with fixed learning rate. This raises a concern about the fairness of the comparison, as the learning rate settings differ significantly. The reviewer suggests that reproducing results using the same setting would be a more equitable approach, given that many recent methods have their code released. This claim is somewhat verifiable as it highlights a potential issue with the experimental setup and suggests a way to address it. However, it lacks specific examples or references to support the claim fully, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of the comparison between the proposed method and other methods. It points out that the proposed method uses AdamW with cosine learning rate, while the compared methods use Adam with fixed learning rate. This discrepancy in learning rate settings could lead to unfair comparisons. The reviewer suggests that reproducing the results using the same setting would be a more equitable approach, as many recent methods have their code released. This feedback is somewhat helpful as it highlights a specific area for improvement and provides a suggestion for a more fair comparison. However, it could be more helpful if it included more detailed guidance on how to reproduce the results or what specific steps should be taken. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that the plots are \"terrible\" and provides specific reasons for this assessment, such as being too small, having hard-to-distinguish colors, poorly labeled axes, and visually similar labels. It also mentions that these issues are the reason for the sub-standard clarity rating. The comment suggests that the authors should improve the plots, but it does not provide explicit guidance on how to do so. The actions are implicit and somewhat vague, as the authors need to infer how to make the plots clearer. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the plots, which are the main presentation of the experimental results. It provides specific feedback on the issues with the plots, such as their size, color distinguishability, axis labeling, and label similarity. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it details the problems with the plots and suggests improvements. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the plots are \"terrible\" and provides specific reasons for this assessment, such as being too small, having hard-to-distinguish colors, poorly labeled axes, and visually similar labels. These reasons are detailed and offer clear examples of the issues with the plots. However, the comment does not provide any references or logical reasoning to support these claims, making it somewhat verifiable. The authors can infer that the feedback is based on their own experience, but the lack of explicit evidence weakens the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific feedback on the quality of the plots, which are the main presentation of the experimental results. It identifies several issues, such as the plots being too small, having hard-to-distinguish colors, poorly labeled axes, and visually similar labels. These observations are actionable and directly address the authors' presentation of their findings. By highlighting these issues, the comment guides the authors to improve the clarity and effectiveness of their visual data representation, which is crucial for conveying their results effectively. The feedback is detailed and constructive, making it highly valuable for enhancing the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review comment explicitly states that Table 1 does not show standard deviations, which is a specific and actionable piece of feedback. It also suggests that the experiments should be more extensive, providing a clear direction for improvement. The comment is explicit and concrete, allowing the authors to understand exactly what needs to be addressed and how to enhance their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the absence of standard deviations and suggests that the experiments should be more extensive, providing clear guidance on what needs to be improved. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Table 1 does not show standard deviations, which is a factual observation. However, it does not provide any reasoning or evidence to support why this omission is significant or how it impacts the overall quality of the submission. The comment lacks specific examples or references to other works that might highlight the importance of including standard deviations. As a result, the claim is not fully verifiable, making it difficult for the authors to understand the implications of the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that Table 1 lacks standard deviations, which is a crucial piece of information for understanding the experimental results. It also suggests that the experiments should be more extensive, implying that the current scope might be limiting the impact of the submission. This feedback is clear and actionable, providing the authors with a direct path to improve the completeness and robustness of their work. However, the comment could be more helpful if it offered specific guidance on how to conduct more extensive experiments or suggested alternative ways to present the data. Overall, the comment is mostly helpful as it highlights a significant area for improvement and encourages the authors to enhance their submission.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is hard to follow and recommends improving the structure, specifically mentioning the introduction, method, and experiments sections. It also suggests focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment does not provide explicit guidance on how to improve the structure or visualize the figures. The actions are implicit and somewhat vague, as the authors need to infer what specific changes to make. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improving the structure of the paper, specifically mentioning the introduction, method, and experiments sections. It also recommends focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment does not specify which parts of the paper these sections or figures correspond to, making it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is somewhat specific in its suggestions, the lack of explicit grounding makes it challenging for the authors to fully understand and address the feedback. Therefore, this comment is weakly grounded and somewhat specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper is hard to follow and recommends improving the structure, particularly the introduction, method, and experiments sections. It also suggests focusing more on the IEM in Figure 3 and improving the visualization of Figures 7 and Figure. However, the comment lacks specific examples or detailed reasoning to support these claims. The suggestions are somewhat vague and do not provide clear guidance on how to improve the structure or visualization. Therefore, the claim is somewhat verifiable, as it provides some basis for improvement but lacks depth and specificity.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies areas where the paper could be improved, specifically mentioning that it is hard to follow and suggesting improvements in structure and visualization. It recommends focusing more on the IEM in Figure 3 and enhancing the visualization of Figures 7 and Figure. However, the comment lacks specific guidance on how to achieve these improvements, such as suggesting particular restructuring techniques or visualization methods. While it provides a general direction for improvement, the feedback is somewhat vague and could be more helpful if it included actionable suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. While the comment implies that the authors should consider expanding their experiments, it does not provide explicit guidance on which specific architectures or tasks to include. The action is implicit and somewhat vague, as the authors are left to infer the exact nature of the suggested expansion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, it does not specify which parts of the paper these experiments are discussed in, making it weakly grounded. The comment is specific in its suggestion to expand the experiments, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments are limited to neural networks and image classification tasks and recommends exploring the performance of attacks on other architectures and classification tasks. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a limitation in the scope of the experiments conducted in the paper, noting that they are limited to neural networks and image classification tasks. It suggests that exploring the performance of attacks on other architectures and classification tasks would be interesting and could provide a more comprehensive evaluation of the proposed methods. While the comment highlights an area for improvement, it does not provide specific guidance on which architectures or tasks to consider, nor does it offer suggestions on how to conduct these additional experiments. This feedback is somewhat helpful as it points out a potential avenue for future research but lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the authors' choice of using a transformer model without locality bias, questioning its suitability given the nature of neighborhood interactions in the context of limited information propagation. The reviewer suggests that the authors should explain why the lack of locality in transformers is not a concern. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the model or data might need to be considered. The action is implicit and vague, as it does not specify how the authors should respond or what changes might be necessary. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the suitability of using a transformer model without locality bias, questioning its effectiveness in capturing neighborhood interactions. However, it does not specify which part of the paper this concern pertains to, such as a particular section, table, or figure. The authors may need to infer that the issue relates to the methodology or experimental setup, but the comment lacks explicit grounding. The comment is specific in its critique of the model's suitability, but without clear grounding, the authors may struggle to identify the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the suitability of using a transformer model without locality bias, questioning its effectiveness in capturing neighborhood interactions. The reviewer provides a logical argument based on the concept of limited information propagation, suggesting that neighborhood agents should naturally have more impacts on each other compared to distant nodes. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to provide additional evidence or reasoning to address the reviewer's concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a valid concern about the suitability of using a transformer model without locality bias, questioning its effectiveness in capturing neighborhood interactions. The reviewer provides a logical argument based on the concept of limited information propagation, suggesting that neighborhood agents should naturally have more impacts on each other compared to distant nodes. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. While it identifies a potential issue, it does not provide detailed guidance or suggestions on how the authors might address this concern or what changes could be made to the model or data. As a result, the comment is somewhat helpful, as it highlights an area for improvement but does not offer comprehensive feedback or actionable steps for the authors to take.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the model's overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to mitigate the potential impairment. The comment implies that the authors should consider the trade-off and its implications, but it lacks concrete steps or suggestions on how to implement this consideration. Therefore, the comment is not actionable, as it does not provide clear guidance on how the authors can improve their draft.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the mitigation strategies aimed at reducing memorization and their potential impact on the model\\'s overall performance. However, it does not specify which part of the paper discusses these mitigation strategies or how they are implemented. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in that it highlights a potential trade-off between reducing memorization and maintaining performance, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the impact of mitigation strategies on the model\\'s overall performance, suggesting a potential trade-off between reducing memorization and maintaining utility. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to be considered fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable, as it hints at a concern but does not provide enough detail to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a concern about the impact of mitigation strategies on the model\\'s overall performance, specifically questioning whether these strategies might significantly impair the model\\'s utility. This feedback is valuable as it highlights a potential trade-off between reducing memorization and maintaining performance, which is a critical consideration for the effectiveness of the mitigation strategies. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address this issue or what additional experiments could be conducted to assess the impact of the mitigation strategies. While it identifies a significant area for improvement, the lack of detailed actionable advice limits its overall helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, noting that other comparable papers did not employ it. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or clarify the reasoning behind their choice. The action is implicit, as the authors would need to infer that they should explain the rationale for using 6-fold cross-validation. The comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the use of 6-fold cross-validation, questioning its necessity given that other comparable papers did not use it. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the rationale behind the choice of cross-validation, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of using 6-fold cross-validation, suggesting that other papers did not employ it. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the choice of cross-validation. Without detailed justification or evidence, the claim is considered borderline verifiable, as it provides some context but lacks sufficient support to fully substantiate the argument.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a valid concern about the lack of explanation for the use of 6-fold cross-validation, particularly in the context of other papers that did not employ it. This feedback highlights a potential gap in the paper's reasoning and could help the authors clarify their methodology. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as explaining the rationale behind the choice of cross-validation or comparing it to other methods. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights the effectiveness of the proposed engineering method for ReC and notes the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. While the comment identifies an area for clarification, it does not provide explicit guidance on how to address this request or what specific aspects of the heuristic components need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the impact of these components. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the Non-Ambiguous Query Generation procedure,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the need for clarification regarding the impact of heuristic components, particularly the sophisticated filtering template used in this procedure. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper presents a highly effective engineering method for ReC but notes the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. While the claim is based on the observation of the method's components, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors are left to infer the need for clarification, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment acknowledges the effectiveness of the proposed engineering method for ReC but highlights the incorporation of combinatorial and heuristic aspects, particularly the Non-Ambiguous Query Generation procedure, which relies on a sophisticated filtering template. The comment requests clarification on the impact of these heuristic components. This feedback is somewhat helpful as it identifies a specific area where the authors could provide more detail or explanation. However, the comment could be more helpful if it offered suggestions on how to address the request for clarification or provided examples of how the heuristic components might impact the results. Overall, the comment provides a clear direction for improvement but lacks depth and actionable guidance, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses doubt about the proposed method's ability to train without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. While the comment highlights a potential issue with the method's reliance on camera information, it does not provide explicit guidance on how to address this concern or suggest any specific actions the authors should take. The feedback is vague and lacks concrete steps, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the proposed method's ability to train without camera information, specifically referencing Line 223 and the \"knowledge of CAD model correspondences.\" However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific about the concern regarding camera information, the lack of explicit grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses doubt about the proposed method's ability to train without camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. The comment highlights a potential issue with the method's reliance on camera information, but it does not provide any supporting evidence, examples, or references to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the proposed method's reliance on camera information, specifically questioning the feasibility of ray marching without knowing the viewpoint or the origin of the ray. This feedback highlights a potential limitation or area for improvement in the method's implementation. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what changes could be made to the method. While it identifies a critical point, the absence of actionable advice limits its helpfulness to the authors. Therefore, the comment is somewhat helpful, as it points out a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, it does not provide explicit instructions or detailed guidance on how to achieve this clarification. The action is implicit, as the authors need to infer that they should elaborate on the improvements of their method over ODA. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested improvement. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ODA,\" one of the methods for solving the MOIP problem, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of clarity on how the presented method improves performance and computation speed compared to using ODA. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is rated as 5: Fully Grounded and Specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should clarify how their presented method improves performance and computation speed compared to using ODA. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out that the paper does not clearly explain how the presented method enhances performance and computation speed compared to using ODA. This feedback is valuable as it highlights a gap in the clarity and depth of the paper. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might address this issue, such as suggesting additional experiments or analyses that could demonstrate the improvements. While the comment is somewhat helpful, it lacks the depth and actionable advice needed for the authors to fully address the feedback. Therefore, it is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. While the comment provides a clear direction for improvement, it does not specify which additional datasets should be used or how the experiments should be conducted. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. However, the comment does not specify which datasets are being referred to or which parts of the paper should be addressed. This makes it difficult for the authors to identify the specific sections or parts of the paper that need improvement. Therefore, the comment is not grounded, as it does not provide clear guidance on which parts of the paper to focus on. It is also not specific because it does not detail what needs to be done to conduct the additional experiments or how the full dataset experiments should be conducted. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests conducting experiments on more datasets to provide a more comprehensive evaluation of the proposed method. It also encourages conducting experiments on the full dataset instead of the low-resource regime. However, the comment lacks specific details or examples of which additional datasets should be used or how the experiments should be conducted. Without this information, the authors may find it challenging to understand the exact nature of the suggested improvements. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks sufficient detail to be fully actionable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of experimental results on more datasets. This is a crucial aspect for evaluating the robustness and generalizability of the proposed method. The suggestion to conduct experiments on more datasets is clear and actionable, providing the authors with a concrete direction for improvement. However, the comment could be more helpful if it offered specific examples of additional datasets or guidance on how to conduct these experiments effectively. Despite this, the feedback is mostly helpful as it highlights a critical area for enhancement and encourages a more comprehensive evaluation of the proposed method.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues: the lack of clarity in how the generic argument task and the random argument task support the authors' claims, and the cumbersome nature of the dataset transformation and experimental setup. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should clarify the tasks and improve the clarity of the dataset transformation and experimental setup, but it does not offer specific guidance on how to do so. Therefore, the comment is unactionable, as it lacks the necessary details for the authors to implement the suggested improvements.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the clarity of the generic argument task and the random argument task in relation to the authors' claims, as well as the cumbersome nature of the dataset transformation and experimental setup. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with the clarity and complexity of the tasks and setup, providing clear guidance on what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the generic argument task and the random argument task did not clearly prove the authors' claims, and that the dataset transformation and experimental setup were cumbersome and unclear. However, the comment lacks specific examples or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies two main issues with the paper: the lack of clarity in how the generic argument task and the random argument task support the authors' claims, and the cumbersome nature of the dataset transformation and experimental setup. While the comment highlights these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out areas that need clarification and improvement, but it lacks actionable advice or detailed suggestions for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should explore how their model works with tabular data, noting that it is another popular form of multi-modal data. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the model should be examined. The action is implicit and vague, as it leaves the authors to infer the necessary steps to address the suggestion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests exploring the use of tabular data as another form of multi-modal data, noting that it is a popular approach. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or table. The comment is vague and does not provide detailed guidance on how to implement this suggestion or what aspects of the model should be examined. As a result, the comment is not grounded and lacks specificity, making it difficult for the authors to understand what needs to be addressed. Therefore, this comment aligns with a score of 1: Not Grounded and Not Specific.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that tabular data is another popular form of multi-modal data and that it would be interesting to see how the model works with it. However, the comment does not provide any specific reasoning, examples, or references to support this claim. It lacks detailed justification or evidence to substantiate the suggestion, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should explore how their model works with tabular data, noting that it is another popular form of multi-modal data. While the comment identifies an interesting avenue for further investigation, it lacks specific guidance or suggestions on how to approach this exploration. The feedback is somewhat helpful as it points out a potential area for improvement, but it does not provide detailed instructions or examples to help the authors enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from low-resourced languages with high-resourced ones. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct the additional analysis or what specific aspects of the alignment should be explored. The authors know that they need to expand their analysis, but the comment does not offer concrete steps on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It recommends adding more analysis, visualizations, or case studies for different languages, including language families, and specifically mentions the alignment of entities from low-resourced languages with high-resourced ones. However, the comment does not specify which part of the paper discusses entity representations or alignment, making it difficult for the authors to pinpoint the exact section that needs improvement. While the authors can infer that the feedback pertains to the analysis of entity representations, the lack of explicit grounding makes the comment weakly grounded. The specificity of the comment is moderate as it provides some guidance on what aspects to focus on, but without clear references, it remains weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper has weak analysis on the alignment of entity representations, particularly for language-agnostic characters. It suggests that the authors should add more analysis, visualizations, or case studies for different languages, including language families, and specifically mention the alignment of entities from low-resourced languages with high-resourced ones. However, the comment lacks specific examples or references to support the claim that the analysis is weak. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered borderline verifiable, as it provides a general suggestion but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the analysis of entity representations, particularly for language-agnostic characters. It suggests that the authors should provide more analysis, visualizations, or case studies to enhance the understanding of multilingual alignment. The comment also raises an interesting question about the alignment of entities from low-resourced languages with high-resourced ones, which could be a valuable addition to the paper. However, the comment lacks specific guidance on how to conduct the additional analysis or what specific aspects of the alignment should be explored. While it provides a clear direction for improvement, the feedback could be more helpful if it included concrete suggestions or examples. Therefore, the comment is somewhat helpful, as it offers a clear area for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues with the references list: the presence of duplicates and the absence of publication venues and years for many papers. While it identifies specific areas that need attention, it does not provide explicit instructions on how to correct these issues or what steps the authors should take to address them. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"references list,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the references list, including the presence of duplicates and the absence of publication venues and years. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the references list contains duplicates and that publication venues and years are missing. While it identifies these issues, it does not provide any reasoning, examples, or references to support these claims. The authors are left to determine whether these issues are significant and how to address them, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The comment identifies specific issues with the references list, such as the presence of duplicates and missing publication venues and years. This feedback is clear and actionable, providing the authors with concrete information about areas that need improvement. However, the comment could be more helpful if it suggested specific steps or strategies for addressing these issues, such as recommending a thorough review of the references or providing guidance on how to ensure accurate and complete information. Overall, the comment is mostly helpful as it highlights important areas for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the theoretical analysis presented in Theorem 1, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare the theoretical results with other comparable methods. However, the comment does not provide explicit guidance on how to analyze or compare the results, nor does it offer concrete steps on what specific comparisons should be made. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Theorem 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the theoretical analysis, namely the lack of clarity regarding the error bound and the need for comparison with other comparable methods. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the theoretical analysis in Theorem 1 is unclear and weak, specifically questioning the meaning of the error bound. It suggests that the authors need to analyze and compare the theoretical results with other comparable methods. However, the comment lacks specific examples or references to support the claim about the lack of clarity or the need for comparison. Without detailed reasoning or evidence, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the theoretical analysis in Theorem 1, noting that the error bound is unclear and lacks comparison with other comparable methods. This feedback is actionable as it provides a clear direction for the authors to improve the clarity and depth of their theoretical analysis. However, the comment could be more helpful if it offered specific suggestions or guidance on how to analyze and compare the results with other methods. Despite this, the comment is mostly helpful as it directs the authors towards a crucial area for improvement, allowing them to enhance the rigor and clarity of their theoretical analysis.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of the pseudo-code for the proposed method. While it prompts the authors to explain the performance difference, it does not provide explicit guidance on how to address the missing pseudo-code or what steps should be taken to include it. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide the pseudo-code. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, referencing specific works. However, it does not specify which part of the paper this comparison is intended for, making it weakly grounded. The comment is specific in its request for clarification and the inclusion of a pseudo-code, but without clear references to the sections or figures, the authors may struggle to identify the exact areas needing attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about why explicit methods perform better than implicit methods on locomotion tasks and notes the absence of the pseudo-code for the proposed method. It references two external works, [1] and [2], which are relevant to the discussion. However, the comment lacks detailed reasoning or specific examples to fully support the claim about the performance difference or the absence of the pseudo-code. While the references provide some context, the overall claim is somewhat verifiable as it is based on logical reasoning and references, but it could be more robust with additional details or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the performance of explicit methods compared to implicit methods on locomotion tasks, referencing specific works. It also points out the absence of the pseudo-code for the proposed method, which is a critical detail for reproducibility and understanding. However, the comment lacks depth and actionable suggestions. It does not provide guidance on how the authors might address the performance discrepancy or how to include the missing pseudo-code effectively. While it identifies an important issue, the feedback is somewhat limited in its scope and does not offer comprehensive advice for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model's ability to handle various image noise types. While the comment implies that the authors should provide a reason for this limitation, it does not explicitly instruct them to add more noise types or explain the reasoning behind the choice of Gaussian noise. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model's ability to handle various image noise types. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in questioning the choice of noise type, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model's ability to handle various image noise types. However, the comment does not provide any specific reasoning or justification for this choice, nor does it offer any suggestions or examples to address the issue. Without additional context or explanation, the claim is unverifiable, as the authors are left to infer the reasoning behind the limited scope of the experiments. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid question about the rationale behind showing results only on images corrupted with Gaussian noise, despite the paper mentioning the model's ability to handle various image noise types. This feedback highlights a potential gap in the experimental evaluation, as it does not explore the model's performance across a broader range of noise types. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or expand their experiments. While it identifies an area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods. It implies that this visualization is crucial for supporting the research motivation of the paper. However, the comment does not provide explicit guidance on how to create the visualization or what specific aspects of the visualization should be included. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should visualize the effect of increasing data dimensionality on the performance of existing PU learning methods, which is important for supporting the research motivation of the paper. However, the comment does not specify which part of the paper this visualization should be included in, making it weakly grounded. It is specific in suggesting the need for visualization, but the lack of explicit mention of a particular section or figure makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that existing PU learning methods will suffer a gradual decline in performance as the dimensionality of the data increases. This is a logical assertion based on common knowledge in machine learning, where higher dimensionality can lead to increased complexity and potential performance degradation. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to provide evidence or references to substantiate this claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the authors' claim regarding the performance decline of PU learning methods with increasing data dimensionality. It suggests that visualizing this effect would be beneficial for supporting the research motivation of the paper. While the comment highlights an important aspect that could enhance the paper's impact, it lacks specific guidance on how to create the visualization or what aspects of the visualization should be included. This makes the feedback somewhat helpful, as it provides a direction for improvement but does not offer detailed actionable steps. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication from a teachability perspective and suggesting that the authors check for differences in figures. However, the comment does not provide explicit guidance on how to simplify the descriptions or what specific changes should be made. The suggestions are somewhat vague and lack concrete details, making it challenging for the authors to implement them effectively. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication from a teachability perspective and suggesting that the authors check for differences in figures. However, the comment does not specify which part of the paper contains these convoluted descriptions or the figures being referenced, making it weakly grounded. The suggestions are specific, as they provide concrete examples of what the authors could do to improve the clarity of their results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication from a teachability perspective and suggesting that the authors check for differences in figures. However, the comment lacks detailed reasoning or examples to fully support the claim that the descriptions are convoluted or that the suggested references are relevant. The feedback is somewhat verifiable, as it provides some justification but could be more robust with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the convoluted nature of result descriptions, providing an example of a sentence that is difficult to understand. It suggests that the authors should consider simplifying these descriptions, which is a valuable piece of feedback for improving the clarity and readability of the paper. The comment also offers specific suggestions, such as referencing related work on speaker-listener communication from a teachability perspective and suggesting that the authors check for differences in figures. These suggestions are actionable and provide the authors with concrete directions for improvement. However, the comment could be more helpful if it included more detailed guidance on how to simplify the descriptions or what specific changes should be made. Overall, the feedback is mostly helpful as it offers actionable suggestions and identifies areas for improvement, but it could be more comprehensive with additional details.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the definition of approximation error is ambiguous and could be better clarified by providing a mathematical characterization. While the comment implies that the authors should provide a mathematical characterization, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it leaves the authors to infer that they need to add a mathematical characterization. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the definition of approximation error is ambiguous and could be better clarified by providing a mathematical characterization. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific about the need for a mathematical characterization, the lack of grounding makes it challenging for the authors to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the definition of approximation error is ambiguous and suggests that it would be better to provide a mathematical characterization. However, the comment does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand why the definition is ambiguous or how a mathematical characterization would address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the definition of approximation error, noting that it is ambiguous and could be clarified with a mathematical characterization. This feedback is specific and actionable, as it suggests a concrete way to improve the clarity and precision of the paper. By recommending a mathematical characterization, the authors are provided with a clear direction for enhancing the presentation of their work. However, the comment could be more helpful if it included examples or further elaboration on how to implement the mathematical characterization. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific issues with the proposed model, noting that it produces only one node changing cluster per time step due to a reassignment probability of 1/n, which limits the model\\\\'s dynamics. It also points out that the model is simplistic, as it only changes edges with the average cluster size of one node. However, the comment does not provide explicit or implicit suggestions on how to address these issues or improve the model. The authors are left without guidance on how to enhance the model\\\\'s dynamics or complexity. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses specific issues with the proposed model, noting that it produces only one node changing cluster per time step due to a reassignment probability of 1/n, which limits the model\\\\'s dynamics. It also points out that the model is simplistic, as it only changes edges with the average cluster size of one node. However, the comment does not specify which part of the paper discusses the model or the experimental setup, making it difficult for the authors to pinpoint the exact section being addressed. While the comment is specific in detailing the issues with the model, the lack of grounding makes it challenging for the authors to understand which part of the paper needs revision. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the proposed model produces only one node changing cluster per time step due to a reassignment probability of 1/n, which limits the model\\\\'s dynamics. It also states that the model is simplistic, as it only changes edges with the average cluster size of one node. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. The reasoning provided is logical but lacks detailed evidence or examples to substantiate the claims fully. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies specific issues with the proposed model, noting that it produces only one node changing cluster per time step due to a reassignment probability of 1/n, which limits the model\\\\'s dynamics. It also points out that the model is simplistic, as it only changes edges with the average cluster size of one node. However, the comment does not provide any suggestions or guidance on how to address these issues or improve the model. Without actionable feedback or recommendations, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, as it highlights weaknesses but lacks depth and direction for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should provide details about the division of the dataset into training and testing sets, including the numbers used and the method of division. It specifies that the division should be explained, whether it was random or based on other considerations. This provides clear and concrete guidance on what information is missing and how it should be addressed. The authors know exactly what additional details they need to include to improve their draft. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for details about the division of the dataset into training and testing sets, including the numbers and the method of division. This allows the authors to accurately identify the part of the paper that requires attention. The comment is also specific because it clearly specifies what information is missing and how it should be addressed, such as whether the division was random or based on other considerations. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point is a request for additional information regarding the division of the dataset into training and testing sets. It does not contain a subjective claim or opinion, but rather a suggestion for improvement. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is highly helpful as it provides specific and actionable feedback on a critical aspect of the paper. It highlights the importance of including details about the division of the dataset into training and testing sets, including the numbers used and the method of division. This feedback is clear and directly addresses a potential weakness in the paper, guiding the authors to improve the transparency and reproducibility of their work. By specifying what information is missing, the comment empowers the authors to enhance their draft significantly. Therefore, this comment is rated as highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing guidance on how to address these issues. The feedback lacks concrete steps or detailed suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique of the need for human labor and the limitations of long-text inputs, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable as it provides some context but lacks depth and clarity, which could be improved with more detailed explanations or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises concerns about the need for human labor in building text descriptions for each task and questions the optimality of textual formats for policy learning. It also mentions that the long-text input could restrict the scalability of the framework, referencing a previous question. However, the comment lacks specific suggestions or actionable feedback on how to address these issues. While it identifies potential areas for improvement, it does not provide detailed guidance or examples for the authors to consider, making it somewhat helpful. The feedback is incomplete and could be more beneficial with additional insights or suggestions. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any evidence or proof to support this claim. It also does not suggest any specific actions or improvements that the authors should take to address this issue. The comment lacks explicit guidance on how the authors might address the lack of theoretical results, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"this work,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the lack of new theoretical results. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the use of a specific type of loss in a particular setting might be new, but it does not provide any evidence or proof to support this claim. The comment lacks specific examples or references to substantiate the assertion that the work does not prove any new theoretical results. Without supporting evidence, the claim remains unsubstantiated, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential gap in the paper by pointing out that while the use of a specific type of loss in a particular setting might be new, the work does not provide any new theoretical results. This feedback highlights a critical aspect of the paper that needs further exploration or clarification. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional theoretical analysis could be included. While it points out a potential area for improvement, it does not offer actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'}"}
{"generated_text": "{'actionability_rationale': 'The review comment suggests a hypothesis about the nature of the \"trivial\" and \"impossible\" parts of the data and proposes that human test results might support it. However, it does not provide explicit guidance on how the authors should test this hypothesis or what evidence they should present to either prove or disprove it. The comment lacks concrete steps or detailed instructions on how to implement the suggested action, making it somewhat actionable. The authors are left with a vague idea of what to do but no clear direction on how to proceed. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is referring to, making it difficult for the authors to identify the exact section being addressed. It also lacks specificity, as it does not provide detailed guidance on what evidence should be presented to prove or disprove the hypothesis. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data and suggests that human test results might support it. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the claim remains speculative and difficult to verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a hypothesis about the nature of \"trivial\" and \"impossible\" parts of the data, suggesting that the \"trivial\" part might be highly consistent with the training set, while the \"impossible\" part might involve ambiguous labels or atypical object poses. The comment questions whether the authors could provide more evidence to support or disprove this hypothesis, which is a valuable suggestion for improving the paper. However, the comment lacks specific guidance on how the authors might conduct this analysis or what kind of evidence would be most effective. While it provides a direction for improvement, it could be more helpful with additional details on how to implement the suggestion. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the testing of the model on other tasks within the bAbI dataset. It does not provide explicit instructions or suggestions on how to address this concern, such as testing on additional tasks or providing a rationale for the choice of Task 1. While the comment implies that the authors should consider expanding their testing, it lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed instructions on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of testing on other tasks, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the testing of the model on other tasks within the bAbI dataset, specifically mentioning that it was only tested on Task 1. However, it does not provide any evidence, reasoning, or references to support why testing on other tasks would be beneficial or necessary. The comment lacks specific details or justification, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the testing of the model on other tasks within the bAbI dataset, specifically noting that it was only tested on Task 1. This feedback highlights a potential area for improvement, as testing on additional tasks could provide a more comprehensive evaluation of the model's capabilities. However, the comment lacks specific guidance or suggestions on how to address this concern, such as testing on other tasks or providing a rationale for the choice of Task 1. While it identifies a potential issue, it does not offer actionable advice or detailed insights, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment indicates that it is difficult for the authors to follow Section 3.2 and suggests that they may improve it by providing more illustrations and examples. While the comment explicitly suggests an action\u2014improving the section and providing additional illustrations and examples\u2014it does not specify how the authors should go about improving the section or what kind of illustrations and examples would be beneficial. The action is clear and direct, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that it is difficult for the authors to follow Section 3.2 and recommends providing more illustrations and examples. However, it does not specify which part of Section 3.2 is particularly challenging to follow, nor does it provide any guidance on what kind of illustrations or examples would be helpful. The comment lacks grounding as it does not pinpoint the specific section or part of the paper that needs improvement. It is also not specific because it does not offer detailed suggestions on how to improve the section. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is difficult to follow Section 3.2 and suggests that the authors may improve it by providing more illustrations and examples. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the difficulty or how to address it. Without additional context or evidence, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of Section 3.2, suggesting that it is difficult for the authors to follow. It provides a specific suggestion for improvement by recommending that the authors enhance the section with more illustrations and examples. While the comment highlights a specific area for improvement and offers a clear direction for action, it lacks depth and does not provide detailed guidance on what kind of illustrations or examples would be most beneficial. This makes the feedback somewhat helpful, as it gives the authors a starting point for enhancing their draft, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as exploring alternative methods or optimizations. While the action is implied, it is vague and lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the time complexity of the proposed algorithm, specifically mentioning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, suggesting that it might make the algorithm impractical for such problems. However, the comment does not specify which part of the paper discusses the algorithm or the hypervolume calculation, making it difficult for the authors to pinpoint the exact section or figure being addressed. While the comment is specific about the issue of time complexity, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical for such problems. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the hypervolume calculation is time-consuming or impractical. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the time complexity of the proposed algorithm, specifically concerning the repeated calculation of hypervolume in LaMOO. It highlights that this calculation could be time-consuming, especially for problems with many objectives, potentially making the algorithm impractical for such problems. While the comment identifies a potential weakness in the algorithm's efficiency, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited insight into how to enhance the algorithm. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to incorporate such results. The comment is somewhat vague, as it leaves the authors to infer the necessary actions, which could be more detailed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment acknowledges that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, it does not specify which part of the paper discusses the dataset or the experiments. The authors cannot confidently determine which section or figure this comment refers to, making it weakly grounded. The comment is specific in suggesting the inclusion of results on larger datasets, but without a clear reference, the authors may struggle to address it effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dataset used in the experiments is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. However, the comment does not provide any specific reasoning or evidence to support this claim, such as examples of why small datasets are insufficient or how the suggested larger datasets would enhance the results. Without detailed justification or references, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used in the experiments, noting that it is small and suggests that results on medium or large datasets, such as ImageNet, would be more convincing. While the comment highlights a valid point about the need for more comprehensive datasets, it does not provide specific guidance on how the authors might address this issue or what additional experiments could be conducted. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks actionable suggestions or detailed guidance, which could leave the authors with limited direction on how to enhance their work. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should delve deeper into the limitations of evolutionary methods, particularly regarding leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and suggests that the authors should be more precise in their critical remarks. The comment implies that the authors should clarify what \"brittle convergence properties\" mean and consider the adoption of DeepRL methods. However, the comment does not provide explicit guidance on how to address these points or what specific actions the authors should take to improve their draft. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper should explore deeper aspects of evolutionary methods, such as leveraging state, reactiveness, and learning during an episode. It also critiques the title as being too generic and suggests that the authors should be more precise in their critical remarks. However, the comment does not specify which part of the paper discusses these limitations, making it difficult for the authors to identify the exact section that needs improvement. While the comment is specific about the areas that need attention, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the paper for being too generic and vague, particularly in its title, and suggests that the authors should be more precise in their critical remarks. It also questions the clarity of the term \"brittle convergence properties\" and suggests considering the adoption of DeepRL methods. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The feedback is somewhat verifiable as it provides some reasoning but lacks detailed evidence or references, which could help the authors improve their draft. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment critiques the paper's title as being too generic and suggests that the authors should be more precise in their critical remarks. It also questions the clarity of the term 'brittle convergence properties' and suggests considering the adoption of DeepRL methods. While the comment identifies areas for improvement, such as enhancing the depth of discussion on evolutionary methods and refining the title, it lacks specific guidance or actionable suggestions on how to address these issues. The feedback is somewhat helpful as it provides some direction but could be more detailed to fully assist the authors in improving their draft. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. While the questions are explicit and direct, they do not provide any guidance or suggestions on how the authors might address these issues. The authors are left with a clear understanding of what needs to be clarified but are not given any actionable steps to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises several questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. However, it does not specify which part of the paper these questions pertain to, such as a specific section or figure. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the questions are specific about the methodology, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. These questions are factual and descriptive, as they seek clarification on specific aspects of the methodology. However, they do not contain any subjective opinions or claims that require verification. Therefore, the comment is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises several important questions about the methodology, specifically regarding the synthesis of the focal stack, the forward model used, and the handling of depth discontinuities at edges. These questions are clear and direct, providing the authors with specific areas to clarify and improve their methodology. However, the comment lacks suggestions or guidance on how to address these issues, which limits its helpfulness. While it identifies areas for improvement, it does not offer actionable steps or detailed explanations, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This provides a clear and explicit action for the authors to take, as they can directly incorporate this comparison into their work. However, the comment does not specify how to implement this comparison or what aspects of the comparison should be included, making it somewhat actionable. The minor point about the low jailbreaking percentage is not actionable as it does not provide guidance on how to address this issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"GCG\" and \"other LLMs,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of a comparison of the approach with other LLMs, particularly in the context of crafting adversarial prompts and transferring them. The comment is specific in detailing the need for such a comparison, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This claim is somewhat verifiable as it suggests a logical extension of the work, but it lacks specific examples or references to support the idea of such a comparison. The comment does not provide detailed reasoning or evidence to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include a comparison of their approach with other LLMs, specifically mentioning the potential for crafting adversarial prompts and transferring them. This provides a clear and actionable direction for the authors to enhance their work by expanding the scope of their analysis. However, the comment lacks specific guidance on how to implement this comparison or what aspects of the comparison should be included, which limits its helpfulness. While it offers a valuable suggestion, the lack of detailed guidance makes it somewhat helpful, as it provides a starting point but requires further elaboration from the authors. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the authors' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment highlights a potential area of confusion for the authors, it does not provide explicit guidance on how to address this issue or what specific aspects need clarification. The action is implicit, as the authors are expected to infer that they need to provide a more detailed explanation of the difference between similarity and exit times. However, the comment lacks concrete details on how to achieve this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the authors' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the authors\\' claim about the novelty of unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. However, it does not provide any specific evidence, reasoning, or references to support the claim or the need for clarification. The comment lacks depth and does not offer a clear path for the authors to address the issue. Therefore, it is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the novelty of the authors' claim regarding unsupervised feature selection from a diffusion perspective and seeks clarification on the difference between similarity and exit times. While the comment identifies a potential area of confusion for the authors, it does not provide specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it highlights a point that needs clarification, but it lacks depth and actionable advice, making it only somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the limitations of the unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. It does not provide explicit instructions or suggestions on how the authors should address this question or what changes might be needed in their draft. The comment is vague and lacks concrete guidance, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its inquiry about the limitations of the framework, but it lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. However, it does not provide any specific evidence, reasoning, or references to support the claim that the framework might not be applicable to these types of formulations. Without additional context or justification, the authors may find it challenging to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the limitations of a unified framework in handling different types of POMDP formulations, specifically continuous or infinite spaces. This question is relevant as it challenges the authors to consider the scope and applicability of their framework. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this limitation or expand their work. Without actionable feedback or detailed insights, the authors may find it difficult to improve their draft based on this comment alone. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the dataset created by the authors is optional and recommends using the Kialo dataset, which is well-studied and cleaner. However, it does not provide explicit guidance on how the authors should implement this suggestion or what specific actions they should take to incorporate the Kialo dataset into their work. The comment implies that the authors should consider using the Kialo dataset as an additional resource, but it lacks concrete steps or details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is well-studied and cleaner. However, it does not specify which part of the paper discusses the dataset creation or how the authors should address this suggestion. The comment lacks grounding as it does not provide clear references to specific sections or parts of the paper, making it difficult for the authors to identify the exact area that needs attention. Additionally, the comment is specific in its recommendation to use the Kialo dataset, but without grounding, it is challenging for the authors to understand how to apply this suggestion. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the dataset creation process is optional and recommends using the Kialo dataset, which is well-studied and cleaner. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the recommendation. Without detailed reasoning or evidence, the claim is not fully verifiable, as it does not provide a clear justification for why the Kialo dataset is a suitable alternative. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset creation process, suggesting that the Kialo dataset, which is well-studied and cleaner, could be a more suitable alternative. While the comment provides a recommendation, it lacks specific guidance on how the authors should implement this suggestion or what steps they should take to incorporate the Kialo dataset into their work. The feedback is somewhat helpful as it points out a potential improvement but does not offer detailed instructions or examples, leaving the authors with limited actionable advice. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the limited number of tasks in the experiments and suggests that the authors should include at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to their draft. While the authors can infer that they need to expand their experiments and provide sequential results, the lack of concrete instructions makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses concerns about the limited number of tasks in the experiments and suggests including at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment does not specify which part of the paper discusses the experiments or tasks, making it weakly grounded. The comment is specific in detailing the issue with the number of tasks and the desired format of the results. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the limited number of tasks in the experiments and suggests including at least 10 tasks. It also requests sequential results in terms of tasks learned rather than epochs. However, the comment does not provide any specific reasoning, examples, or references to support why this suggestion is necessary or beneficial. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how it relates to the paper's content. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the experimental setup, specifically the limited number of tasks used. It suggests that the authors should include at least 10 tasks and provide sequential results in terms of tasks learned rather than epochs. This feedback is somewhat helpful as it highlights an area for improvement and provides a direction for the authors to consider. However, the comment lacks depth and does not offer specific guidance on how to address the issue or what changes might be necessary. The authors would need to infer the exact steps to take, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the parameter S, suggesting that it remains a problem. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how to address this issue or what steps should be taken to resolve it. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the parameter S, suggesting that it remains a problem. However, it does not specify which part of the paper this issue pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the problem with the parameter S. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the parameter S, suggesting that it remains a problem. However, it does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the parameter S, suggesting that it remains a problem. However, it does not provide any specific guidance or suggestions on how to address this issue or what steps the authors should take to resolve it. The comment lacks depth and actionable advice, leaving the authors without a clear path forward to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While it implies that human evaluation is a good idea, it does not provide explicit instructions or guidance on how to implement this suggestion. The authors are left to infer that they should conduct a human evaluation, but the comment lacks concrete details on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to understand where to apply the suggestion. While the comment is specific in its recommendation, the absence of grounding information makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. While the comment implies that human evaluation is a more reliable approach, it does not provide specific examples or references to support this claim. The lack of detailed reasoning or evidence makes it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks key elements for full verification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that a human evaluation for caption generation would be more convincing than relying solely on automatic metrics. This feedback is valuable as it highlights a potential limitation in the current evaluation approach and suggests an alternative method that could provide more reliable results. However, the comment lacks specific guidance on how to conduct a human evaluation or what criteria should be used. While it identifies an important area for improvement, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers a clear direction but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. The comment suggests that this should be mentioned clearly. However, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the paper. The action is implicit, as the authors can infer that they need to clarify the experimental setup in the paper. The comment is somewhat actionable because it identifies a specific area that needs attention, but it lacks concrete details on how to implement the suggested change. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"The experimental setup borrowed from [2] is only semi-real,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely that multi-node seed cascades are artificially created by merging single-node seed cascades. This provides clear guidance on how the authors should improve the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental setup is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This claim is supported by the statement itself, which provides a clear explanation of the issue. However, the comment lacks specific examples or references to external works that could further substantiate the claim. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental setup, noting that it is only semi-real because multi-node seed cascades are artificially created by merging single-node seed cascades. This observation is clear and provides a specific point for the authors to address in their paper. By highlighting this detail, the comment offers a constructive suggestion for improving the transparency and rigor of the experimental setup description. However, the comment could be more helpful if it provided additional guidance on how to address this issue or suggested specific ways to improve the clarity of the experimental setup. Overall, the comment is mostly helpful as it identifies a meaningful aspect of the paper that needs attention, but it could be more comprehensive with additional suggestions or guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several limitations in the paper, specifically regarding the scope of bias benchmarks and the absence of assessments on state-of-the-art generative models. It points out that the current benchmarks only assess gender, race, and religion, and suggests that other important biases and datasets should be included. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific datasets or models to include. While the action is implied, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitations of the bias benchmarks, specifically noting that they only assess gender, race, and religion. It also mentions the absence of assessments on state-of-the-art generative models like GPT. However, the comment does not specify which part of the paper these limitations are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as expanding the scope of bias benchmarks and including assessments on state-of-the-art models. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bias benchmarks only assess gender, race, and religion, and that other important biases and datasets are missing. It also notes the absence of assessments on state-of-the-art generative models like GPT. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. The absence of detailed evidence or examples weakens the verifiability of the claim, aligning with a score of 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the paper, specifically the limited scope of bias benchmarks. It points out that the current benchmarks only assess gender, race, and religion, and that other important biases and datasets are missing. Additionally, it notes the absence of assessments on state-of-the-art generative models like GPT. This feedback is somewhat helpful as it highlights areas where the paper could be improved by expanding the scope of the analysis. However, the comment could be more helpful if it provided specific suggestions or guidance on how the authors might address these limitations, such as recommending additional datasets or models to include. Overall, the comment offers valuable insights but lacks actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method is sensitive to hyperparameters and recommends performing a careful hyperparameter search to find a proper $\\alpha$ for a new problem. This provides a clear and explicit action for the authors to take, as they need to conduct a hyperparameter search and adjust the $\\alpha$ value accordingly. The comment is specific in its suggestion, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the method's sensitivity to hyperparameters, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for how to apply this sensitivity, namely by performing a careful hyperparameter search to find a proper $\\alpha$ for a new problem. This guidance is detailed and actionable, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the method is sensitive to hyperparameters, suggesting that careful hyperparameter search is necessary to find a proper $\\alpha$ for a new problem. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how it impacts their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the method's sensitivity to hyperparameters, suggesting that careful hyperparameter search is necessary to find a proper $\\alpha$ for a new problem. This feedback is clear and actionable, providing the authors with a specific direction to improve their method. However, the comment could be more helpful if it offered additional guidance on how to conduct the hyperparameter search or what specific strategies might be effective. Overall, the comment is mostly helpful as it highlights a critical aspect of the method that needs attention, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point identifies specific issues with Figure 3, such as the clarity of the workflow, captions, and the representation of communication modes. However, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to improve the clarity of the figure, but without specific suggestions or examples, the action remains vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear workflow, captions, and confusing representation of communication modes. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that Figure 3 is challenging to understand due to unclear workflow, captions, and confusing representation of communication modes. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is challenging to understand due to unclear workflow, captions, and confusing representation of communication modes. While the comment highlights a clear area for improvement, it lacks actionable guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out a specific area that needs attention, but it does not provide detailed suggestions or examples of how to improve the figure. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. While it identifies a lack of clarity, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the method need clarification. The action is implicit, as the authors would need to infer that they should provide more details or examples to explain the concept. However, the comment lacks concrete instructions on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"SSL pre-training stage of the proposed method,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is unclear, namely the meaning of \"learned [MASK] embedding.\" This provides the authors with a clear understanding of the issue and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of \"learned [MASK] embedding\" in the SSL pre-training stage of the proposed method. However, it does not provide any claim, reasoning, or evidence to support the concern. The comment lacks context or justification, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is classified as \"1: Unverifiable\" because it does not offer any substantiated feedback or guidance.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the term \"learned [MASK] embedding\" in the context of the proposed method's SSL pre-training stage. This feedback is clear and actionable, as it highlights a lack of clarity in the paper that could hinder understanding. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as providing additional explanations or examples. While it points out a potential area for improvement, it lacks depth and could be more helpful if it offered more detailed advice or suggestions. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of their results need to be clarified or revised. Without concrete suggestions or instructions, the authors are left without a clear path forward, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, it does not specify which part of the paper this issue is related to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique regarding the derivative nature of the results, the absence of grounding information limits its effectiveness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the reported results are partially derivative, extending findings from standard networks to hyper-networks. However, the comment lacks specific evidence or references to support this claim. Without detailed examples or references to the specific literature the authors are building upon, the claim remains somewhat verifiable. The authors would need to provide more context or evidence to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the reported results, suggesting that they are partially derivative, extending findings from standard networks to hyper-networks. While this observation is insightful, it lacks actionable guidance or suggestions for the authors to address this concern. The comment does not provide specific advice on how the authors might clarify or revise their results to ensure they are not derivative. Without concrete feedback or suggestions, the authors may struggle to improve their draft based on this comment alone. Therefore, the comment is rated as barely helpful, as it highlights a potential issue but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that Figure 3 is difficult to read, but it does not provide any specific guidance or suggestions on how to improve the figure's readability. The authors are left without any actionable steps to take to address this issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper Figure 3 is located in, making it difficult for the authors to identify the issue. Additionally, the comment is specific in that it identifies the problem as the difficulty in reading the figure, but without grounding, the authors cannot pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that Figure 3 is \"very hard to read anything on the figure.\" However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors cannot verify the claim or understand why it is an issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 3, noting that it is difficult to read anything on the figure. However, it lacks actionable suggestions or guidance on how to improve the figure's readability. Without specific advice on how to enhance the figure's clarity, the authors are left without a clear path to address the issue. This makes the comment barely helpful, as it points out a problem but does not provide sufficient assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. While the comment provides a general direction for improvement, it lacks specific guidance on which parts of the GAT training process need to be addressed or how the rewriting should be done. The authors are left with a broad understanding of what needs to be done but without concrete steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"245,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences need rewriting for clarity. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the GAT is trained with the whole model and suggests that it needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. However, the comment lacks specific details or references to support these claims. It does not provide any evidence or reasoning to justify why the GAT is trained with the whole model or why it needs to be reviewed by an English native speaker. Without this additional information, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the GAT training process, noting that it is trained with the whole model. It also suggests that the paper needs to be reviewed by an English native speaker and that some sentences require rewriting for clarity. While the comment points out a potential area for improvement, it lacks detailed guidance on how to address the issue or what specific changes might be necessary. The feedback is somewhat helpful as it highlights a potential area for improvement, but it does not provide actionable steps or detailed suggestions for the authors to follow. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides two specific suggestions for the authors to consider: replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1 instead of the Adam default value. However, it does not explicitly instruct the authors on how to implement these changes or provide guidance on why these replacements or adjustments are necessary. The actions are implicit, as the authors need to infer that they should make these changes and understand the reasoning behind them. The lack of detailed guidance on how to apply these suggestions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for the authors to consider, such as replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1. However, it does not specify which part of the paper these suggestions relate to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact areas where these changes should be made. While the suggestions are specific in terms of the proposed changes, the lack of grounding makes it challenging for the authors to understand the context and relevance of these suggestions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two specific questions about the methodology used in the paper. The first question pertains to the replacement of `n^2/(2*s^2)` with an arbitrary parameter `lambda`, and the second question concerns the justification for using a SGD learning rate of ~0.1, which is different from the Adam default value. While the questions are clear and specific, they do not provide any supporting evidence or reasoning to justify why these choices were made or why they might be beneficial. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of these questions and how they might impact the paper. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient justification to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides two specific suggestions for the authors to consider, such as replacing `n^2/(2*s^2)` with an arbitrary parameter `lambda` and using a SGD learning rate of ~0.1 instead of the Adam default value. However, the comment does not offer any justification or reasoning for why these changes might be beneficial or how they could impact the results. Without additional context or explanation, the authors may find it challenging to understand the rationale behind these suggestions and how to implement them effectively. The feedback is somewhat helpful as it points out areas for improvement but lacks depth and detailed guidance, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model's performance under different scenarios. The comment also suggests that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, it does not specify which part of the paper should be revised or how the error analysis should be conducted. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that error analysis is crucial for evaluating model performance and identifying potential issues, and it encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. It also mentions that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, the comment does not specify which part of the paper should be revised or how the error analysis should be conducted, making it weakly grounded. The comment is specific in its suggestion to conduct error analysis and provide detailed explanations, but the lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that error analysis is crucial for evaluating model performance and identifying potential issues. It encourages the authors to conduct error analysis and provide detailed explanations of the model\\'s performance under different scenarios. The comment implies that error analysis will aid in guiding subsequent improvements and expansions of the ERC research. However, the claim lacks specific examples or references to support the assertion that error analysis is crucial or how it should be conducted. The reasoning is somewhat vague, making it difficult for the authors to fully understand and implement the suggestion. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a clear and actionable suggestion for the authors to enhance their paper by conducting error analysis. It emphasizes the importance of error analysis in evaluating model performance and identifying potential issues, which can guide subsequent improvements and expansions of the ERC research. The comment encourages the authors to provide detailed explanations of the model\\'s performance under different scenarios, which is a valuable piece of feedback. However, the comment could be more helpful if it offered specific guidance on how to conduct the error analysis or what aspects of the model should be analyzed. Despite this, the feedback is mostly helpful as it directs the authors towards a crucial aspect of improving their research. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should analyze the domain gap between datasets and discuss how this gap might affect the adaption of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. While the comment provides explicit actions\u2014analyzing the domain gap and discussing its impact, as well as exploring fine-tuning on synthetic data\u2014the actions are somewhat vague. The authors are not given specific guidance on how to analyze the domain gap or what aspects to discuss. However, the comment does offer a clear direction for improvement, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. However, the comment does not specify which part of the paper addresses the domain gap or synthetic data, making it weakly grounded. The comment is specific in suggesting actions to improve the analysis, but without clear references to specific sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests analyzing the domain gap between datasets and discusses the potential impact of this gap on the adaptation of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or detailed explanations, the authors may find it challenging to understand and address the suggestions effectively. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient support for the claims.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the draft by analyzing the domain gap between datasets and discussing its potential impact on the adaptation of the method. It also recommends exploring the possibility of fine-tuning a pre-trained model on synthetic data to enhance the value of the approach. While the comment offers actionable feedback, it could be more helpful if it included more detailed guidance on how to analyze the domain gap or what aspects to discuss. Additionally, providing examples or specific suggestions for fine-tuning would further enhance the comment's usefulness. Overall, the feedback is mostly helpful as it directs the authors towards important areas for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. However, the comment does not provide explicit guidance on how to incorporate this method or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors would need to infer that they should include a comparison with a NCE-based method and potentially discuss the findings of the referenced paper. The lack of concrete details makes the action somewhat vague, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including at least one NCE-based method for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. However, the comment does not specify which part of the paper this comparison should be made or where the authors should discuss the findings of the referenced paper. This makes it difficult for the authors to identify the specific section or aspect of the paper that needs improvement. Therefore, the comment is not grounded, as the authors cannot confidently determine which part of the paper it addresses. Additionally, the comment is specific in suggesting the inclusion of a comparison with a NCE-based method, but the lack of grounding makes it difficult to apply. This aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that at least one NCE-based method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. However, the comment lacks specific details or examples to support the claim, making it difficult for the authors to understand the basis of the suggestion or how to incorporate it into their work. The absence of a clear rationale or reference to specific sections of the paper makes the claim somewhat verifiable, as it provides a general direction but lacks the necessary depth for the authors to act upon. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that at least one NCE-based method should be included for comparison, referencing a specific paper that demonstrates the possibility of learning an Energy-Based Model (EBM) on natural images with a strong noise distribution. This feedback is somewhat helpful as it identifies a potential area for improvement by suggesting a relevant comparison. However, the comment lacks depth and does not provide specific guidance on how to incorporate this method or what aspects of the comparison should be highlighted. The authors would need to infer the need for comparison and potentially discuss the findings of the referenced paper, which limits the actionable value of the comment. Therefore, it aligns with a score of 3, as it offers some direction but could be more comprehensive and detailed.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiment section could be improved by carrying out significance tests on the human evaluation results and comparing the proposed method with some recent LLMs. While the comment provides explicit actions\u2014carrying out significance tests and comparing with recent LLMs\u2014it does not specify how these actions should be implemented or what data should be used for the significance tests. The lack of detailed guidance on how to conduct these tests or select appropriate baselines makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests improvements to the experiment section, specifically mentioning the need to carry out significance tests on human evaluation results and to compare the proposed method with recent LLMs. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or table. This makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific about the types of improvements, the lack of grounding makes it challenging for the authors to understand which part of the paper to focus on. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiment section could be improved by carrying out significance tests on the human evaluation results and comparing the proposed method with some recent LLMs. However, the comment lacks specific details or references to support these suggestions. It does not provide examples of how to conduct the significance tests or which recent LLMs should be used for comparison. Without these details, the authors may find it challenging to understand and implement the suggested improvements. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient evidence or guidance.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies specific areas for improvement in the experiment section, such as the need to carry out significance tests on human evaluation results and to compare the proposed method with recent LLMs. This feedback is clear and actionable, providing the authors with concrete suggestions for enhancing the rigor and relevance of their experimental evaluation. However, the comment could be more helpful if it included specific examples of how to conduct the significance tests or which recent LLMs should be used for comparison. Despite this, the feedback is mostly helpful as it directs the authors towards important improvements that would strengthen their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly instructs the authors to discuss a specific work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, which is relevant to the topic of joint error in unsupervised domain adaptation (UDA). It also suggests that the authors should illustrate the relationship between this work and their proposed method and explain why their method is better. This provides a clear and concrete action for the authors to take, as they know exactly what needs to be addressed and how to do it. The comment is fully actionable, as it gives explicit guidance on what to include in the discussion and how to compare the proposed method with existing work. Therefore, this comment is rated as highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific issue of joint error in unsupervised domain adaptation (UDA), which is a well-defined part of the paper. It also specifies the need to discuss a previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and to illustrate the relationship between this work and the proposed method. This provides clear guidance on what part of the paper needs attention and what specific issues need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' assertion about the lack of research on joint error in unsupervised domain adaptation (UDA) is inaccurate, as previous work has already addressed this issue. The comment provides a specific reference to \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment\" from ICML2019, which supports the claim. However, the comment could be more robust by including a brief summary or explanation of the relevance of this work to the authors' proposed method. Despite this, the claim is mostly verifiable as it is supported by a specific reference, making it a score of 4.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment is highly helpful as it identifies a specific gap in the authors' claim regarding the lack of research on joint error in unsupervised domain adaptation (UDA). It directs the authors to a relevant previous work, \"Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment,\" from ICML2019, and suggests that they discuss this work in relation to their proposed method. By providing a specific reference and a clear direction for discussion, the comment offers actionable guidance that helps the authors strengthen their paper by acknowledging and building upon existing research. This feedback is detailed and constructive, making it highly helpful for improving the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art (SOTA) methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. However, the comment does not provide explicit guidance on how the authors should address this issue or what steps they should take to ensure a fair comparison. While the authors can infer that they need to consider the dataset size in their analysis, the lack of concrete suggestions or actions makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the fairness of the comparison with state-of-the-art methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the impact of dataset size on accuracy, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the fairness of the comparison with state-of-the-art methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer suggests that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the claim is not fully verifiable without additional context or evidence. Therefore, this comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a valid concern about the fairness of the comparison with state-of-the-art methods due to the use of a newly collected 209M dataset, while existing methods use smaller datasets. The reviewer points out that the superior performance of the proposed method might be attributed to the larger dataset size, which significantly impacts accuracy. This feedback highlights a potential issue with the experimental setup and suggests that the authors should consider the impact of dataset size on their results. However, the comment could be more helpful if it provided specific guidance on how the authors could address this issue, such as by conducting additional experiments with smaller datasets or by normalizing the dataset size across methods. Overall, the comment identifies a meaningful weakness but lacks detailed suggestions, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should use powerful pre-trained language models like BERT and XLNet as the base encoder for all methods and then compare the efficacy of the transfer parts instead of using the simplest n-gram features. This provides a clear and explicit action for the authors to take, as they know exactly what needs to be done to improve their draft. The comment is specific in its suggestion, detailing which models to use and how to compare the transfer parts. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation in the NLP field\" and suggests using powerful pre-trained language models like BERT and XLNet as the base encoder. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides clear guidance on how the authors should improve their draft by comparing the efficacy of the transfer parts instead of using the simplest n-gram features. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using powerful pre-trained language models like BERT and XLNet as the base encoder can overcome the domain-shift problem, and suggests comparing the efficacy of the transfer parts instead of using the simplest n-gram features. While the claim is based on the understanding of domain adaptation in the NLP field, it lacks specific references or detailed reasoning to fully substantiate the suggestion. The comment provides a logical argument but could be strengthened with more detailed explanations or examples. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending the use of powerful pre-trained language models like BERT and XLNet as the base encoder for domain adaptation in the NLP field. It suggests comparing the efficacy of the transfer parts instead of relying on simpler n-gram features. This feedback is actionable and offers a clear direction for the authors to enhance their draft by incorporating more advanced models and conducting a more thorough comparison. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why these models are particularly effective for domain adaptation. Overall, the comment is mostly helpful as it provides a valuable insight into potential improvements, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a critical issue regarding the proposed method, which includes several complicated modules and more parameters than the baselines. It questions whether the main performance gain is due to a specific module or simply the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, it does not offer any explicit or implicit actions for the authors to take to address this issue. The authors are left without guidance on how to conduct further analysis or experiments to clarify the source of the performance gain. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the proposed method, which comprises several complicated modules and has more parameters than the baselines. It highlights a critical issue regarding the source of the main performance gain, questioning whether it originates from a particular module or is merely due to the increased number of parameters. The comment also notes that the current ablation study does not provide definitive answers to these questions. However, the comment does not specify which part of the paper discusses the proposed method or the ablation study, making it weakly grounded. The comment is specific in identifying the issue with the performance gain and the lack of clarity in the ablation study. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the source of performance gains in the proposed method, specifically questioning whether the gains are due to a particular module or simply the increased number of parameters. The comment suggests that the current ablation study does not provide definitive answers to these questions. However, the comment lacks specific examples or references to support the claim that the ablation study is insufficient. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as the authors may need to conduct further analysis to address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a critical issue with the proposed method, which involves several complicated modules and a higher number of parameters compared to the baselines. It questions the source of the main performance gain, specifically whether it is due to a particular module or simply the increased number of parameters. The comment highlights that the current ablation study does not provide definitive answers to these questions, which is a significant concern for the authors. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or conduct further analysis to clarify the source of the performance gain. While it points out a crucial area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, as it identifies a significant problem but does not provide sufficient guidance for the authors to address it.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly asks for more explanation regarding why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. However, the comment does not provide specific guidance on how to address the request for more explanation or how to incorporate the suggestion about \"pure theory\" papers. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific section of the paper (lines 196-7), allowing the authors to accurately identify the part being addressed. It also specifies what needs to be addressed, namely, the requirement for more explanation regarding why two quantities are different and how this captures the difference in learning settings. The comment is specific in its request for clarification and suggests a leaning toward acceptance, which provides a clear direction for the authors. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the explanation of why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. However, the comment lacks specific examples or detailed reasoning to support the claim that the explanation is insufficient or that the suggestion about \"pure theory\" papers is relevant. Without additional context or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area in the paper that requires more explanation, specifically regarding why two quantities are different and how this captures the difference in learning settings. It also expresses a leaning toward acceptance, suggesting that the authors should consider the possibility of including \"pure theory\" papers. While the comment highlights a potential area for improvement, it does not provide detailed guidance or suggestions on how to address the issue or incorporate the suggestion about \"pure theory\" papers. The feedback is somewhat helpful as it points out a specific area for clarification but lacks depth and actionable advice. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a clear and explicit instruction that provides a direct action for the authors to take. It specifies what needs to be discussed, making the action concrete and actionable. The authors know exactly what aspect of the model they should address and how to do so. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment requests the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its request for discussion, but the lack of grounding makes it difficult for the authors to know where to address this feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point asks the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This is a request for clarification and does not contain a subjective claim or suggestion that requires verification. The comment is factual and descriptive, aligning with the classification of \"No.\" Therefore, the comment is classified as \"No.\"', 'verifiability_label': 'No', 'helpfulness_rationale': 'The review comment requests the authors to discuss the sensitivity of fixed tuning parameters in the model, both in terms of strengths and weaknesses. This feedback is specific and actionable, as it directs the authors to address a particular aspect of their model that could impact its performance and reliability. By discussing the sensitivity of these parameters, the authors can provide valuable insights into the robustness and generalizability of their model. This feedback is clear and constructive, offering a direct path for improvement. Therefore, the comment is mostly helpful, as it provides a clear direction for the authors to enhance their work.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. However, the comment does not provide explicit guidance on how to conduct this exploration or how to determine the number of random seeds. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests exploring the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also raises a question about the number of random seeds used for learning the policies. However, the comment does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its request for additional experiments and clarification on the number of random seeds, but without explicit references to sections or figures, it is difficult for the authors to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the number of random seeds used for learning the policies (DDPO and IPPG) in the experiment results. However, it does not provide any justification or reasoning for why this information is important or how it might impact the results. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the significance of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises an interesting question about the performance of the proposed framework with different policy gradient approaches, specifically mentioning DDPO and IPPG. It also asks for clarification on the number of random seeds used for learning the policies, which is a crucial aspect for reproducibility and understanding the robustness of the results. However, the comment lacks depth and does not provide any suggestions or guidance on how to address this issue or what experiments could be conducted to explore this further. While it identifies a potential area for improvement, it does not offer actionable advice or detailed insights, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. This provides a clear and explicit action for the authors to take, as they can directly apply this feedback by expanding their evaluation to include additional datasets and tasks. The comment is specific in its suggestion, detailing exactly what needs to be done to strengthen the paper. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. However, it does not specify which parts of the paper are being referred to, making it difficult for the authors to identify the exact sections that need improvement. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which parts of the paper need to be expanded or revised. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper's evaluation would be stronger if it were applied to more datasets and more tasks. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion or how to implement it effectively. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper's evaluation, noting that it is based on only one dataset and one task. This feedback is clear and actionable, as it suggests that expanding the evaluation to include more datasets and tasks would strengthen the results and conclusions. By providing a specific direction for improvement, the comment empowers the authors to enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it offered additional guidance on how to select or expand the datasets and tasks, or suggested specific types of tasks that would be beneficial to include. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment implies that the authors should consider this extension, it does not provide explicit instructions or detailed guidance on how to incorporate it into the paper. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the considerations in the paper to kernel (ridge) regression and suggests that this could be presented in the context of kernel interpolation/smoothing. While the comment identifies a potential area for expansion or clarification, it does not provide specific guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it points out a potential avenue for improvement, but it lacks depth and actionable advice, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that some claims in the paper might be inspired from existing studies and recommends adding supportive references. It provides an example of a section (Lines 55-64) where this issue is mentioned. However, the comment does not explicitly instruct the authors to add these references or provide specific guidance on which references to include. The action is implicit and somewhat vague, as the authors are left to infer that they need to add references to support the claims made in the specified section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions Lines 55-64 of the paper, allowing the authors to accurately identify the section being addressed. It is also specific because it provides a clear example of claims that have been discussed in existing studies, suggesting that the authors should add supportive references to these claims. This provides a clear direction for improvement, making the comment highly actionable and grounded.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some claims in the paper are inspired from existing studies and suggests adding supportive references. It provides an example of a section (Lines 55-64) where this issue is mentioned. However, the comment lacks specific references or detailed reasoning to support the claim that the claims are inspired from existing studies. Without concrete examples or references, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by suggesting that some claims might be inspired from existing studies. It provides an example of a section (Lines 55-64) where this issue is mentioned, specifically regarding the identification of four critical factors affecting the performance of chain-of-thought prompting. However, the comment does not offer detailed guidance on how to address this issue or what specific references might be relevant. While it highlights an important aspect of academic integrity, the feedback lacks actionable steps for the authors to take, making it somewhat helpful. The authors would need to infer that they should add references to support the claims made in the specified section, which limits the comment's helpfulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not provide explicit guidance on how to implement these unique tasks or what specific aspects of the dataset should be utilized for these tasks. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the tasks performed on the dataset are somewhat standard, specifically mentioning figure captioning and matching figures/sub-figures to appropriate captions. It proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment does not specify which part of the paper these tasks are discussed or proposed for, making it weakly grounded. The comment is specific in detailing the suggestion for unique tasks, but the lack of grounding makes it difficult for the authors to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the tasks performed on the dataset are somewhat standard and proposes the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. However, the comment lacks specific examples or references to support the claim that the current tasks are standard or that the proposed tasks would effectively demonstrate the dataset's diversity. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general suggestion but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement by suggesting the inclusion of unique tasks, such as interleaved image-text tasks like Question Answering from images, to showcase the diversity of the dataset. This feedback is somewhat helpful as it provides a direction for enhancing the tasks performed on the dataset, but it lacks specific guidance on how to implement these unique tasks or what aspects of the dataset should be utilized. The comment is clear and actionable in its suggestion, but it could be more helpful if it provided more detailed examples or guidance on how to integrate these tasks into the current draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, as well as its applicability to binary classification scenarios where the true mean is known. It questions whether the framework remains relevant given the challenges of non-vanishing duality gaps and the difficulty of maximization over non-norm type constraints. Additionally, it asks whether the framework can provide intuitions on the risk upper bound. The comment also suggests exploring the use of covariance or other statistics to design a better defense. However, it does not provide explicit guidance on how the authors should address these questions or incorporate them into their draft. The action is implicit and somewhat vague, as the authors need to infer the specific areas that require attention and how to address them. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, specifically questioning its applicability given the challenges of non-vanishing duality gaps and the difficulty of maximization over non-norm type constraints. It also asks about the relevance of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not explicitly mention specific sections, tables, or figures of the paper, making it weakly grounded. It is specific in detailing the issues and questions raised, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact parts of the paper that need attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, specifically questioning whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints make the algorithm irrelevant. It also asks about the applicability of the framework in binary classification scenarios where the true mean is known through an oracle, suggesting the use of covariance or other statistics to design a better defense. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. The questions are open-ended and lack sufficient justification or evidence to guide the authors in addressing them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises several questions about the relevance of the framework in the context of non-convex losses and non-norm type defenses, as well as its applicability to binary classification scenarios where the true mean is known through an oracle. It questions whether the non-vanishing duality gap and the difficulty of maximization over non-norm type constraints make the algorithm irrelevant, or if it could still provide some intuition on the risk upper bound. Additionally, it suggests exploring the use of covariance or other statistics to design a better defense. However, the comment lacks specific guidance or suggestions on how the authors might address these questions or incorporate them into their draft. While it identifies areas for improvement, it does not provide actionable steps or detailed reasoning, making it somewhat helpful. The feedback is valuable but could be more comprehensive and actionable to fully assist the authors in enhancing their work.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about an experiment involving sparsifying trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide explicit instructions or suggestions on how to implement this experiment or what specific actions the authors should take. The comment lacks concrete guidance on how to conduct the experiment or what results to expect, leaving the authors with no clear direction on how to address the question. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear question about an experiment involving sparsifying trained models to reduce the number of selected features and comparing accuracy to the proposed model. This guidance is detailed and specific, enabling the authors to understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about an experiment involving sparsifying trained models to reduce the number of selected features and comparing accuracy to the proposed model. However, it does not provide any justification, reasoning, or references to support why this experiment is relevant or how it would impact the results. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about an experiment involving sparsifying trained models to reduce the number of selected features and comparing accuracy to the proposed model. While it identifies a potential area for exploration, it does not provide specific guidance or suggestions on how to conduct this experiment or what results to expect. The comment lacks actionable advice, making it somewhat helpful as it highlights a potential area for improvement but does not offer detailed guidance on how to address it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several areas where the paper lacks detail, making it difficult for the authors to reproduce the results. It specifically mentions the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide explicit instructions or suggestions on how the authors should address these issues. While it identifies the areas needing more detail, it does not offer concrete guidance on how to improve the paper. Therefore, the comment is somewhat actionable, as it points out specific areas for improvement but lacks detailed guidance on how to implement these suggestions.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of detail in the techniques, making it difficult to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. This allows the authors to accurately identify the parts of the paper that need improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights specific areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not provide any specific examples, references, or logical reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of detail regarding the techniques used, which makes it difficult for the authors to reproduce the results. It provides specific examples of areas where the paper lacks detail, such as the sparsification process, the generation of landmarks on edges, the number of landmarks used, the type of image features, the fixed radius with different scales, and achieving shape invariance. However, the comment does not offer any suggestions or guidance on how the authors might address these issues or improve the paper. While it highlights the need for more detail, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the FIITED approach, suggesting that relying solely on utility scores for eviction decisions could introduce biases. It provides an example of how this might occur, where recent chunks might be evicted prematurely. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to mitigate it. The action is implicit and somewhat vague, as the authors are left to infer that they need to consider alternative eviction strategies or incorporate additional factors beyond utility scores. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"FIITED\" and its utility-based approach to determining chunk significance. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the issue with relying solely on utility scores for eviction decisions, providing a clear explanation of the potential bias and an example of how it might occur. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that relying solely on utility scores for eviction decisions in the FIITED approach might introduce biases. It provides an example of how this could occur, where recent chunks might gain a temporary high utility, leading to premature evictions of other valuable chunks. However, the comment lacks specific references or detailed reasoning to fully substantiate the claim. While the reasoning is logical, the absence of concrete evidence or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the FIITED approach, specifically the reliance on utility scores for eviction decisions. It highlights that this approach might introduce biases, as recent chunks could gain a temporary high utility, leading to premature evictions of other valuable chunks. While the comment points out a valid concern, it does not provide specific suggestions or guidance on how to address this issue or improve the approach. The feedback is somewhat helpful as it raises a critical point that could impact the effectiveness of the method, but it lacks actionable advice for the authors to improve their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to clarify the performance and contribution of the framework. The action is implicit and somewhat vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It mentions that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment also notes that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in detailing what is missing in the experimental aspect, such as quantitative experiments and comparisons between algorithms. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the experimental results, specifically regarding the performance and contribution of different parts of the framework. It notes that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment suggests that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of concrete evidence makes it difficult for the authors to fully understand and address the issues raised. Therefore, the comment is considered borderline verifiable, as it provides some basis for concern but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by highlighting the lack of clarity regarding the performance and contribution of different parts of the framework, particularly from an experimental perspective. It points out that while the result section shows promising visual stimuli results, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the presented ones. The comment also notes that it is unclear what the exact performance of the whole framework and individual parts is compared to other solutions. This feedback is somewhat helpful as it directs the authors to areas where they need to provide more detailed explanations and experimental evidence. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these issues, such as recommending additional experiments or providing more detailed analyses. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what specific aspects of the model need to be clarified. The comment lacks concrete guidance on how the authors can improve the draft to address this concern. As a result, the authors are left without a clear understanding of what actions to take to enhance the paper. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it does not provide specific guidance on what needs to be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. However, it does not provide any specific evidence, reasoning, or references to support the claim that the model could generate novel knowledge or testable hypotheses. Without additional context or justification, the claim remains speculative and lacks verifiability. Therefore, this comment is classified as unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the novelty and testability of the model in generating knowledge or hypotheses about neuron data. This is a valid concern that could impact the paper's contribution and impact. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the model need clarification. Without actionable feedback or detailed suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not provide sufficient guidance for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, it does not provide explicit guidance on how to simplify the theorem or what aspects should be emphasized. The action is implicit, as the authors would need to infer that they should simplify the theorem and explain it more clearly. The comment lacks concrete details on how to achieve this simplification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that a simplified version of Theorem 2 could be presented for the general audience, noting that it is currently difficult to understand. However, it does not specify which part of the paper this comment is addressing, such as a particular section or figure. The comment is specific in its suggestion to simplify the theorem, but it lacks grounding as the authors cannot confidently determine which part of the paper it pertains to. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that a simplified version of Theorem 2 could be presented for the general audience, as it is currently difficult to understand. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is important or how it could be implemented. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential improvement to the paper by suggesting that a simplified version of Theorem 2 could be presented for the general audience. This is a valuable suggestion as it could enhance the accessibility and understanding of the paper for a broader audience. However, the comment lacks specific guidance on how to simplify the theorem or what aspects should be emphasized. While it provides a direction for improvement, it does not offer detailed actionable feedback, making it somewhat helpful. The authors would need to infer the need for simplification and potentially seek additional guidance to implement this suggestion effectively. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should conduct experiments using a larger resolution than 224*224. While it implies an action, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with a larger resolution, which implies that the authors should consider the impact of image resolution on performance. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. The comment is vague and does not provide detailed guidance on how to address this suggestion. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the authors should conduct experiments using a larger resolution than 224*224 to see how the performance might be affected. This is a suggestion for an additional experiment, which is a logical and reasonable request. However, the comment does not provide any specific reasoning or evidence to support why this suggestion is important or how it might impact the results. The lack of detailed justification or examples makes the claim somewhat verifiable, as it is based on a logical suggestion but lacks thorough backing.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests conducting additional experiments with a larger image resolution to observe the impact on performance. This is a valuable and actionable suggestion that could provide further insights into the robustness and generalizability of the findings. By exploring the effects of different resolutions, the authors can strengthen their analysis and potentially identify limitations in their current approach. However, the comment could be more helpful if it provided specific guidance on how to implement the suggestion or what aspects of the draft should be updated to reflect the new experiments. Overall, the comment is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide explicit guidance on how the authors should revise their method or what specific changes to make. The action is implicit, as the authors need to infer that they should reconsider their approach and potentially implement the suggested alternative. While the action is somewhat concrete, it lacks detailed instructions on how to apply it, making the comment borderline actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"KeyQN section\" and the specific part of the section, \"What is the keypoint mask averaged feature vector?\". This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the approach used in calculating the averaged feature vector and suggests an alternative method. This provides clear guidance on what needs to be addressed in the section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the current method might be incorrect or why the alternative approach is better. Without additional context or explanation, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment questions the approach used in the KeyQN section, specifically regarding the calculation of the averaged feature vector. It suggests that the current method might be incorrect and proposes an alternative approach. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors should revise their method or what changes to implement. While it identifies a potential issue, it does not offer actionable feedback or detailed reasoning to help the authors address the concern effectively. Therefore, the comment is somewhat helpful, as it highlights a potential area for improvement but does not provide comprehensive guidance for the authors to follow.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a specific and explicit action that the authors can take to improve their draft. By adding this detail, the authors can provide more context and clarity regarding the behavior of the algorithms. The comment is clear and concrete, allowing the authors to understand exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors might want to mention that the algorithms follow the sampled policy for a while. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the algorithms follow the sampled policy for a while, but it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how it relates to the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that the authors might want to mention that the algorithms follow the sampled policy for a while. This is a clear and actionable piece of feedback that could enhance the clarity and completeness of the paper. However, the comment lacks broader context or suggestions for other potential improvements, which could limit its overall impact. Therefore, the comment is somewhat helpful, as it offers a specific and actionable piece of feedback but could be more comprehensive.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper by suggesting that the lower bound results for round complexity in batched ranking problems are not novel, as they follow easily from existing collaborative ranking results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes they should make to their draft to improve its novelty or contribution. The action is implicit and vague, as it does not specify how the authors can demonstrate the novelty of their work or how they can strengthen their contribution. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"proving lower bounds for round complexity\" and \"batched ranking problems,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the paper exploits an easy reduction from collaborative ranking, making the comment specific in its critique. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that proving lower bounds for round complexity is a major part of work involved in batched ranking problems, but the paper exploits an easy reduction from collaborative ranking, making the lower bound results follow as an easy corollary. This claim is somewhat verifiable as it provides a logical reasoning for why the results might not be novel, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the novelty of the paper's contribution, specifically regarding the lower bound results for round complexity in batched ranking problems. It suggests that these results might be easily derived from existing collaborative ranking results, which could diminish the paper's impact. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or enhance the novelty of their work. While it highlights a concern, it lacks actionable advice or detailed feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not provide specific guidance on how to implement these suggestions or what aspects of the prompting technique need to be improved. The action is implicit and vague, as the authors are left to infer that they should explore more sophisticated prompting techniques. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the prompting technique used in the study is basic and does not fully leverage the potential of LLMs. It recommends that carefully curated prompts could yield better results in generating systematic reviews. However, the comment does not specify which part of the paper discusses the prompting technique or where the authors should focus their attention. This lack of grounding makes it difficult for the authors to understand which section or aspect of the paper needs improvement. Additionally, the comment is specific in its suggestion to use carefully curated prompts, but without clear guidance on how to implement this suggestion, it remains somewhat specific. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the prompting technique used in the study is basic and fails to leverage the full potential of LLMs. It suggests that carefully curated prompts could yield better results in generating systematic reviews. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. Without detailed reasoning or evidence, the claim is considered borderline verifiable, as it provides a general observation but lacks the necessary depth to be fully substantiated.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the study by pointing out that the prompting technique used is basic and does not fully leverage the capabilities of LLMs. It suggests that carefully curated prompts could lead to better results in generating systematic reviews. However, the comment lacks specific guidance on how to implement this suggestion or what aspects of the prompting technique need improvement. While it highlights an area for potential enhancement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or examples for the authors to follow. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or enhance the novelty of their approach. Without actionable guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the novelty of the proposed video storyboarding approach, specifically mentioning that it relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or figure that needs attention. The comment is specific in detailing the issue but lacks grounding as it does not provide clear references or sections for the authors to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the innovation of the proposed video storyboarding approach is limited, as it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. The comment provides a specific example of a similar approach, suggesting that the novelty is limited. However, it lacks detailed reasoning or references to support the claim fully, making it somewhat verifiable. The authors would need to infer the basis of the claim, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the novelty of the proposed video storyboarding approach, noting that it primarily relies on frame-wise SDSA, similar to ConsiStory, with the main difference being the mask source. While the comment highlights this limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. Without actionable feedback or suggestions for improvement, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out a weakness but lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the zero-shot nature of the experiment and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It also provides examples of tasks that could be used to demonstrate the transferability. However, the comment does not explicitly instruct the authors to address these points or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to clarify the transferability and provide more information about the tasks. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the zero-shot nature of the experiment and questions the transferability due to the difficulty of the source and target tasks. It provides examples of tasks, such as \"Walker-run\" being harder than \"walker-walk,\" and suggests that the manipulation scenario with different rotations could provide sufficient information for policy transfer. However, the comment does not explicitly mention specific sections or parts of the paper that need attention, making it weakly grounded. It is specific in detailing the issues with the transferability and the potential limitations of the tasks. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the zero-shot nature of the experiment and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides examples, such as \"Walker-run\" being harder than \"walker-walk,\" and suggests that the manipulation scenario with different rotations could provide sufficient information for policy transfer. However, the comment lacks specific references or detailed reasoning to fully substantiate these claims. The authors are left to infer the basis for these claims, making the comment somewhat verifiable. Therefore, it aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a critical question about the zero-shot nature of the experiment and suggests that the transferability might be limited due to the difficulty of the source and target tasks. It provides examples, such as 'Walker-run' being harder than 'walker-walk,' and suggests that the manipulation scenario with different rotations could provide sufficient information for policy transfer. However, the comment does not offer specific guidance or suggestions on how to address these concerns or improve the paper's clarity regarding transferability. While it identifies a potential issue, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they need to clarify the transferability and provide more information about the tasks to address the concerns raised.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. It also mentions that the authors have provided an addendum clarifying the novelty of the datasets and the motivations for their choice. However, the comment does not explicitly instruct the authors to add more datasets or provide additional details on their selection. While the suggestion is clear, it lacks concrete guidance on how to address the issue, such as proposing specific datasets or methods for evaluation. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of dataset size and the number of datasets used for the tasks, allowing the authors to accurately identify the part of the paper being addressed. It also provides specific feedback on the need for more datasets to ensure a rigorous evaluation, particularly when some datasets are too large for all algorithms. The comment is specific in its suggestion to add more datasets and clarify the novelty of the datasets, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the number of datasets used for the tasks might be insufficient for a rigorous evaluation, especially if some datasets are too large for all algorithms. The authors provide an addendum clarifying the novelty of the datasets and the motivations for their choice, which supports the claim. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the number of datasets used for the tasks, suggesting that having 5, 6, and 4 datasets might not be sufficient for a rigorous evaluation, particularly if some datasets are too large for all algorithms. The authors are provided with an addendum clarifying the novelty of the datasets and the motivations for their choice, which updates the reviewer's assessment. While the comment highlights a valid concern and offers some clarification, it could be more helpful if it provided specific suggestions or guidance on how to address the issue, such as proposing additional datasets or methods for evaluation. Overall, the comment is somewhat helpful as it points out a potential weakness and offers some context, but it lacks detailed actionable feedback. Therefore, it aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their method. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about how the proposed method addresses sparse reward problems, suggesting that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment does not specify which part of the paper discusses the method or the experiments, making it difficult for the authors to identify the exact section being addressed. While the question is specific about the issue of sparse rewards, the lack of grounding makes it challenging for the authors to understand the context and respond effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment lacks specific examples or detailed reasoning to support the claim that the proposed method is similar to dense reward signals or that Qmix could solve sparse-reward tasks. Without clear evidence or references, the claim is difficult to verify, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a question about how the proposed method addresses sparse reward problems and suggests that it might be similar to providing a dense reward signal. It also questions whether other methods, such as Qmix, could solve sparse-reward tasks. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or improve their method. While it identifies a potential area for improvement, it does not provide actionable feedback or detailed insights that would help the authors enhance their draft. Therefore, the comment is somewhat helpful, as it points out a relevant issue but does not offer comprehensive guidance for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. While the comment identifies a potential issue and suggests a clarification, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the dataset usage and compare training conditions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. However, the comment does not specify which part of the paper discusses the dataset or the training process, making it difficult for the authors to pinpoint the exact section that needs clarification. While the comment is specific about the issue of dataset usage and comparison, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of the curated AH36M dataset for training and suggests that it is not clearly indicated. It also asks whether other methods, such as HMR and SPIN, have access to this dataset during training for a fair comparison. However, the comment does not provide any evidence, reasoning, or references to support the claim that the dataset usage is unclear or that the comparison is unfair. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the clarity of the use of the curated AH36M dataset for training. It questions whether the dataset is used for training and whether other methods, such as HMR and SPIN, have access to the same data during training, which could affect the fairness of the comparison. While the comment identifies a potential issue, it does not provide specific guidance or suggestions on how the authors might address this concern or what changes could be made to improve the fairness of their comparisons. The feedback is somewhat helpful as it highlights an important aspect of the methodology that needs clarification, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. It also points out that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and even the pre-trained model is compared with other models. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. The authors are left without guidance on how to clarify the motivation, ensure fair comparisons, or address the concerns about the model's size and the comparison methods. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the clarity of the motivation for using an adversarial network in the model and questions the fairness of the experimental comparisons. However, it does not specify which part of the paper these issues are related to, such as the introduction, methodology, or results sections. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in identifying the issues with the motivation and experimental comparisons, the absence of explicit references to specific sections or parts of the paper limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the clarity of the motivation for using an adversarial network and the fairness of the experimental comparisons. However, it does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of these concerns and how to address them. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies two main issues with the paper: the lack of clarity in the motivation for using an adversarial network and the unfairness of the experimental comparisons. It also points out that the proposed model is equipped with newly added components (CAT and GAN), making it a larger model than others, and even the pre-trained model is compared with other models. However, the comment does not provide specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights areas for improvement, but it lacks actionable advice or detailed explanations, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the tuning of hyperparameters, specifically mentioning step size, N, and $\\delta t$. It notes that the optimization process is performed on a sample-by-sample basis, raising questions about the potential variation in optimal hyperparameters. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue, such as proposing specific methods for hyperparameter tuning or analyzing the impact of different hyperparameters. While the authors can infer that they need to clarify the robustness of their hyperparameter choices, the lack of concrete actions or suggestions makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of hyperparameter tuning, specifically mentioning step size, N, and $\\delta t$. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for tuning these hyperparameters and questioning the variation in optimal hyperparameters due to the sample-by-sample optimization process. However, without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the tuning of hyperparameters, specifically mentioning step size, N, and $\\delta t$. It questions the robustness of the optimization process, which is performed on a sample-by-sample basis, and suggests that there might be significant variation in optimal hyperparameters. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the hyperparameters need to be tuned or that the optimization process is robust. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the tuning of hyperparameters, specifically mentioning step size, N, and $\\delta t$. It highlights that the optimization process is performed on a sample-by-sample basis, raising concerns about the variation in optimal hyperparameters. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue, such as proposing methods for hyperparameter tuning or analyzing the impact of different hyperparameters. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness to the authors. Therefore, the comment is rated as somewhat helpful, as it offers a clear observation but lacks detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to others. It suggests that the authors should provide an analysis for the inferior results, as they contradict the motivation. However, the comment does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. While the action is implied, it lacks concrete guidance, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of limited comparisons and inconsistent performance, suggesting that the authors should provide an analysis for the inferior results. However, it does not specify which part of the paper this issue is related to, such as the experimental section or the results section. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs improvement. While the comment is specific in its critique of the performance comparison, the absence of grounding information makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the performance is only compared with a few methods and that the proposed method is not consistently better than others. This claim is supported by the observation that the results violate the motivation. However, the comment lacks specific examples or references to support the claim that the results are inconsistent or violate the motivation. Without detailed evidence or examples, the claim is somewhat verifiable, as it provides a general observation but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the limited number of methods used for comparison and the inconsistent performance of the proposed method compared to other methods. It highlights that the results do not align with the motivation, suggesting that the authors should provide an analysis for these inferior results. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs further investigation and explanation. However, the comment could be more helpful if it provided specific guidance on how to conduct the analysis or what aspects of the results to focus on. Overall, the comment is mostly helpful, as it effectively points out a key area for improvement but could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting that the paper only compares ELF (the author\\'s method) with a baseline without Mid Vision Feedback (MVF) but lacks a comparison with the image classification results of Mid Vision Feedback (MVF). This feedback suggests that the authors should include such a comparison to better demonstrate the contribution of their method. However, the comment does not provide explicit guidance on how to conduct this comparison or what specific aspects of the comparison should be included. The action is implicit and somewhat vague, as the authors need to infer that they should add a comparison with the image classification results of MVF to strengthen the experimental demonstration. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of sufficient experimental demonstration of the contribution points, specifically highlighting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experimental demonstration, namely the comparison with the image classification results of MVF. This provides the authors with a clear understanding of what needs to be addressed to strengthen the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The comment suggests that this lack of comparison does not prove the superiority of the schema searched by ELF (the author\\'s method) over the schema in MVF. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional evidence or justification, the claim remains somewhat verifiable, as the authors may need to infer the basis for the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a significant gap in the experimental demonstration of the paper's contribution points. It highlights the lack of comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for substantiating the claim that the schema searched by ELF (the author's method) is better than the schema in MVF. This feedback is valuable as it directs the authors to include a more comprehensive experimental comparison, thereby strengthening the paper's claims. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects of the comparison should be included. Overall, the comment is mostly helpful, as it points out a critical area for improvement but lacks detailed suggestions.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. It recommends using different notation to avoid this ambiguity. The comment is explicit in identifying the issue and provides a clear suggestion for improvement. However, it does not specify how the authors should implement this change, such as suggesting alternative notations or providing examples of how to use them. While the action is clear, the lack of detailed guidance makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section or element being addressed. The comment is specific in its suggestion to use different notation, but the lack of grounding makes it challenging for the authors to understand where to apply the change. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the use of \"D\" to represent both dimensionality of points and dilation factor could lead to confusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why this is a significant issue or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the use of the symbol \"D\" in the paper, suggesting that it is used to represent both the dimensionality of points and the dilation factor, which could lead to confusion. While the comment highlights a specific area that needs clarification, it does not provide detailed guidance or suggestions on how to address this issue. The feedback is somewhat helpful as it points out a potential area for improvement, but it lacks depth and actionable advice, making it difficult for the authors to fully understand and implement the suggested changes. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the clarity of the concept of \"state\" in the paper, suggesting that it is represented by the \"grid status\" and obtained after applying an action. It also asks whether the term \"elements\" is equivalent to \"states\" or \"actions,\" implying that more elaboration is needed. While the comment explicitly states the need for clarification, it does not provide specific guidance on how the authors should elaborate on the concept or the relationship between \"elements,\" \"states,\" and \"actions.\" The action is clear but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the concept of \"state\" in the paper, specifically questioning its clarity and providing examples of how it is represented. It references specific lines (186-187) to pinpoint the part of the paper being discussed. However, it does not specify what needs to be addressed in terms of elaborating on the concept or providing more context. The comment is fully grounded as it mentions specific lines, but it is under-specific because it does not detail what needs to be addressed. Therefore, this comment is categorized as fully grounded and under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point questions the clarity of the concept of \"state\" in the paper, specifically asking whether \"elements\" are equivalent to \"states\" or \"actions.\" This is a subjective question that requires clarification and does not present a claim that needs verification. The comment is factual and descriptive, aligning with the classification of \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the concept of \"state\" in the paper, specifically questioning whether \"elements\" are equivalent to \"states\" or \"actions.\" This feedback is somewhat helpful as it highlights a specific area that needs clarification, which can guide the authors in improving the consistency and accuracy of their terminology. However, the comment lacks depth and does not provide detailed suggestions or guidance on how to elaborate on the concept or address the ambiguity. As a result, it is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not provide explicit guidance on how to detail the innovative aspects or what specific aspects need to be elaborated upon. The action is implicit and vague, as the authors are left to infer that they need to provide more details on the innovative aspects of the FRM. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the proposed FRM is a simple combination of channel attention and spatial attention and that the innovative aspects should be detailed. However, it does not specify which part of the paper this comment is addressing, such as a specific section or figure. The comment is vague and does not provide any guidance on what needs to be detailed or how to elaborate on the innovative aspects. As a result, the authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Since the comment lacks specificity in detailing what needs to be addressed, it is not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspects should be detailed. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the FRM is a simple combination of these attention mechanisms. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the proposed FRM, suggesting that it is a simple combination of channel attention and spatial attention. It implies that the innovative aspects of the FRM should be detailed. However, the comment lacks specificity and does not provide concrete suggestions or guidance on how to elaborate on the innovative aspects. Without additional details or examples, the authors may struggle to understand what specific aspects need to be detailed or how to improve the presentation of the FRM. Therefore, the comment is barely helpful, as it provides a general observation but lacks actionable feedback.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy by reorganizing the sections. It explicitly mentions the actions of moving the first paragraph of Section 4 into Section 3 and placing the remainder of Section 4 before Section 3. This provides clear and concrete guidance on how the authors can improve their draft by reorganizing the sections. The comment is explicit and detailed, allowing the authors to directly apply the suggested changes. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy by reorganizing the sections. However, it does not specify which parts of the sections are redundant or why they are redundant. The authors cannot confidently determine which parts need to be moved or reorganized. While the comment provides a general suggestion for improvement, it lacks specificity in terms of what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that Section 3 and Section 4 are slightly redundant and proposes specific actions to address this redundancy by reorganizing the sections. However, it does not provide any evidence or reasoning to support why these sections are redundant or how the proposed reorganization would improve the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential redundancy between Section 3 and Section 4, suggesting that the first paragraph of Section 4 could be moved to Section 3 and the remainder of Section 4 could be placed before Section 3. This feedback is specific and actionable, providing clear guidance on how the authors can reorganize their sections to improve the flow and clarity of their paper. By addressing this redundancy, the authors can enhance the logical structure and coherence of their work. The comment is mostly helpful as it offers a concrete suggestion for improvement, though it could be further expanded to include additional considerations or examples. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not provide explicit guidance on how to conduct these analyses or experiments, nor does it offer concrete steps for the authors to take. The comment is somewhat actionable as it identifies a potential area for improvement but lacks detailed instructions on how to implement it. Therefore, it aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, it does not specify which part of the paper these analyses or experiments should be conducted in, making it weakly grounded. The comment is specific in its suggestions for improvement, but without clear references to specific sections or parts of the paper, it is difficult for the authors to pinpoint where to address these points. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper could be more novel and interesting by exploring theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that such analyses are missing. This lack of evidence makes the claim somewhat verifiable, as the authors would need to infer the need for these analyses based on the existing content. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that it could be more novel and interesting if it included theoretical analyses or extensive experiments to explain why a simple greedy selection approach outperforms more principled acquisition functions, and why deterministic MLP predictors outperform robust probabilistic predictors. This feedback is somewhat helpful as it provides a direction for enhancing the paper's contribution, but it lacks specific guidance on how to conduct these analyses or experiments. The comment does not offer detailed suggestions or examples, which could make it more actionable for the authors. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point asks the authors to provide a citation for the k-max problem, implying that it has been discussed elsewhere in the paper. However, it does not explicitly instruct the authors to include a citation or specify where the discussion can be found. The action is implicit and somewhat vague, as the authors need to infer that they should add a citation and then determine where to place it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment asks the authors to provide a citation for the k-max problem, implying that it has been discussed elsewhere in the paper. However, it does not specify which part of the paper or section contains the discussion, making it weakly grounded. The comment is specific in its request for a citation, but the lack of grounding makes it difficult for the authors to know where to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point is a question asking for clarification or additional information regarding the k-max problem. It does not contain a claim that requires verification or justification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is a question that prompts the authors to provide a citation for the k-max problem, suggesting that it has been discussed elsewhere in the paper. While it identifies a potential area for improvement by requesting a citation, it does not offer specific guidance on how to address the issue or what information might be relevant. The comment is vague and lacks actionable suggestions, making it barely helpful. Therefore, it aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. While the comment explicitly mentions these issues, it does not provide specific guidance on how the authors should address them. The authors are left to infer that they need to clarify the contributions in the introduction and ensure that the supporting material is moved to the main sections. This lack of explicit guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Introduction,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. Additionally, it points out that the material supporting the main contributions, including the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, it aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that there is forward referencing in the paper, material is introduced without proper explanation, and the contributions are not clearly explained in the introduction. It also notes that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is in the appendix rather than the main sections. While the comment identifies these issues, it lacks specific examples or references to support the claims, making it somewhat verifiable. The authors would need to infer the basis for these claims, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies two main issues with the paper: the lack of explanation for forward referencing and the unclear explanation of contributions in the introduction. It also points out that the material supporting the main contributions, such as the deep-rag algorithm and discussion on high concurrency, is located in the appendix rather than the main sections. This feedback is clear and actionable, providing the authors with specific areas to address in their draft. By highlighting these issues, the comment guides the authors to improve the clarity and organization of their paper, making it mostly helpful. However, it could be more helpful if it suggested specific ways to address these issues, such as providing examples or restructuring the sections. Overall, the comment is mostly helpful as it offers clear guidance for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific area where the authors lack analysis, namely the security and privacy protection of the proposed framework. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment identifies a gap in the analysis but does not offer guidance on what steps to take to improve the draft. As a result, the authors are left without a clear direction on how to enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific area of the paper that needs analysis, namely the security and privacy protection of the proposed framework. However, it does not specify which part of the paper this analysis should be conducted in, making it weakly grounded. The comment is specific in pointing out the lack of analysis, but without clear guidance on how to address this issue, the authors may find it challenging to improve their draft. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not analyze the security and privacy protection of the proposed framework. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact areas that need improvement. Without additional context or references, the authors may struggle to address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of analysis regarding the security and privacy protection of the proposed framework. This is a crucial aspect that needs to be addressed for the paper to be considered complete and robust. However, the comment does not provide any suggestions or guidance on how the authors might approach this analysis, leaving the authors without a clear direction on how to improve their draft. While the feedback highlights an important area for improvement, it lacks depth and actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. It suggests that the authors should clarify this point, but it does not provide specific guidance on how to do so. The comment is clear in identifying a gap in the explanation, but it lacks concrete instructions on how to address it. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detail on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. However, it does not specify which part of the paper this explanation should be included in, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether the authors explicitly explain the understanding one reaches by looking at the PPP maps. While the comment raises a valid point about the need for clarity in the explanation, it does not provide any specific examples, references, or detailed reasoning to support the claim. The lack of detailed justification or examples makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient evidence to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by pointing out that while the authors mention the importance of reliable PPP metrics for understanding PPP effects, they do not explicitly explain what kind of understanding one reaches by examining the PPP maps. This feedback is somewhat helpful as it highlights a specific area where the authors could improve the clarity and depth of their explanation. However, the comment could be more helpful if it provided some guidance or examples on how to clarify this point. Overall, the comment offers a clear direction for improvement, making it somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The suggestion to provide a stronger baseline is vague and lacks concrete details on how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the training data, the lack of grounding makes it challenging for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the training data for the RBI model, suggesting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer proposes that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone. However, the comment lacks specific examples or references to support the claim that such supervision is ignored. It does not provide detailed reasoning or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a concern about the training data for the RBI model, specifically noting that it only trains on rewarded actions and may ignore useful supervision from rewardless actions. The reviewer suggests that this could be a significant factor in the effectiveness of FP + RBI compared to RBI alone, and recommends providing a stronger baseline to prove the usefulness of FP. However, the comment lacks specific guidance on how the authors should address this issue or what actions they should take to improve their draft. While it identifies a potential weakness, it does not provide detailed suggestions or examples to help the authors strengthen their work. Therefore, the comment is barely helpful, as it offers a general idea but lacks actionable advice.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to clarify the statement. The action is implicit and vague, as it does not specify how the authors should revise the statement or what specific aspects need to be addressed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a concern about the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. It also points out that the primary benefit seems to be the reduction of gradient path by the slow RNN. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to identify the exact section that needs revision. While the comment is specific in its critique of the multi-scale statement, it lacks grounding as it does not provide explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. The reviewer provides a logical argument explaining why this distinction is important and how it affects the understanding of the model. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the multi-scale statement, suggesting that the slow and fast RNNs operate on logical time scales rather than physical time scales. This observation is insightful and could help the authors clarify their explanation of the model. However, the comment does not provide specific guidance on how the authors might address this issue or what changes could be made to improve the clarity of their explanation. While it offers a valuable point for consideration, the feedback lacks depth and actionable suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the evaluation methodology, suggesting that the use of expected performance under observation noise might not be representative of the decision-maker's true interests. It proposes that the paper's formulation, where the decision-maker cares about the noise, should be clarified upfront. The comment is explicit in identifying the issue and provides a clear suggestion for improvement by recommending that the distinction be made clearer. However, it does not specify how the authors should go about clarifying this distinction, leaving some room for interpretation. Therefore, the comment is mostly actionable, as it provides a clear direction but lacks detailed guidance on implementation.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the evaluation methodology, suggesting that the use of expected performance under observation noise might not be representative of the decision-maker's true interests. It highlights that the paper's formulation, where the decision-maker cares about the noise, should be clarified upfront. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. It is specific in detailing the concern about the evaluation methodology and the need for clarification. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the use of expected performance under observation noise might not be representative of the decision-maker's true interests, suggesting that the paper's formulation, where the decision-maker cares about the noise, should be clarified upfront. The comment provides a logical reasoning by pointing out the discrepancy between the evaluation methodology and the paper\\'s formulation. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the need for clarification based on the reasoning provided, which could be improved with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the evaluation methodology, specifically suggesting that the use of expected performance under observation noise might not align with the decision-maker\\'s true interests as reflected in the paper\\'s formulation. It proposes that the distinction between these two approaches should be clarified upfront to enhance the clarity and accuracy of the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve the presentation of their methodology. However, it could be more helpful if it included suggestions on how to clarify the distinction or examples of how to do so. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the authors' explanation of the poor long-range modelling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific aspects of their model or analysis need to be revised. The suggestion is implicit and lacks concrete details, making it difficult for the authors to understand how to implement the feedback. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the poor long-range modelling ability of DGNs, specifically mentioning oversquashing, vanishing/exploding gradients, and oversmoothing. It references a specific paper to support the claim about oversmoothing. However, the comment does not explicitly mention which part of the paper it is addressing, such as a specific section or figure. This makes it weakly grounded, as the authors may need to infer the part of the paper being discussed. The comment is specific in detailing the issue and suggesting an additional factor to consider, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the poor long-range modelling ability of DGNs could be due to oversmoothing, in addition to oversquashing and vanishing/exploding gradients, referencing a specific paper. This claim is supported by logical reasoning and the reference to a relevant external work, providing a clear basis for the authors to understand and potentially address the issue. The comment is mostly verifiable as it offers a specific example and justification for the claim, but it could be strengthened by including more detailed reasoning or examples. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential issue with the authors' explanation of the poor long-range modeling ability of DGNs, suggesting that it might be due to oversmoothing in addition to oversquashing and vanishing/exploding gradients. It references a specific paper to support the claim about oversmoothing, which provides a clear basis for the authors to understand and potentially address the issue. However, the comment could be more helpful if it offered specific guidance on how the authors might incorporate or discuss oversmoothing in their analysis or experiments. Overall, the comment is somewhat helpful as it highlights an important aspect that needs further consideration, but it lacks detailed actionable suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks explicit instructions or concrete advice on what needs to be done to clarify the problem formulation. As a result, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper the problem formulation is unclear in, making it difficult for the authors to identify the exact section that needs attention. However, it is specific in that it identifies the issue as the problem formulation being unclear in the statement and introduction examples. This provides a clear direction for the authors to focus their attention, but the lack of specific section identification makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the problem formulation is somewhat unclear in the statement and introduction examples. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity of the problem formulation in the statement and introduction examples. However, it lacks specific details or suggestions on how the authors might address this issue. Without actionable guidance or examples, the authors may find it challenging to improve their draft. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient assistance for the authors to make meaningful improvements.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This provides a clear and explicit action for the authors to take, as they can directly implement the suggestion by adding experiments with these models. The comment is specific in its recommendation, detailing which models should be used and how this would enhance the paper\\'s applicability and generalizability. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments with different LLM families, such as OPT, BLOOM, or other alternatives, to provide valuable insights into the method\\'s applicability and generalizability. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its recommendation, as it clearly identifies the need for additional experiments and specifies the models to be used. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper lacks experiments on different LLM families and recommends conducting trials with models like OPT, BLOOM, or other alternatives. This claim is somewhat verifiable as it provides a suggestion for improvement but lacks specific examples or references to support the claim. The authors could benefit from additional context or references to understand the significance of the suggested experiments. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the absence of experiments on different LLM families. It suggests conducting trials with models like OPT, BLOOM, or other alternatives to provide valuable insights into the method\\'s applicability and generalizability across various LLM families. This feedback is clear and actionable, as it directly points out an area where the authors can enhance their work. By suggesting specific models to include in the experiments, the comment provides a concrete direction for improvement, making it highly helpful for the authors. Therefore, the comment aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method described in the paper only works for generative models that can be fine-tuned as in/outpainting models. However, it does not provide any explicit or implicit actions for the authors to take, such as suggesting alternative approaches or providing additional details. The comment lacks guidance on how the authors might address this limitation or improve their method. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the method described in the paper only works for generative models that can be fine-tuned as in/outpainting models. However, it does not specify which part of the paper this limitation is discussed or how it affects the overall methodology. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address this limitation or improve the method. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the method described in the paper only works for generative models that can be fine-tuned as in/outpainting models. However, the comment lacks specific evidence or examples to support this claim. It does not provide any references or logical reasoning to substantiate the assertion that the method is limited to in/outpainting models. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out a limitation in the method described in the paper, specifically that it only works for generative models that can be fine-tuned as in/outpainting models. While this observation highlights a potential constraint on the applicability of the method, it does not provide any suggestions or guidance on how the authors might address this limitation or improve their approach. The comment lacks actionable feedback, leaving the authors without clear directions on how to enhance their work. Therefore, the comment is barely helpful, as it identifies a problem but does not offer any constructive advice or suggestions for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer suggests that the current presentation does not align with the initial understanding of the first part, which involves taking random weights, learning curves between weights, and finding nice weights to be mixed into the final ensemble. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to improve the connection between the two parts. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. However, it does not specify which sections or parts of the paper these connections are discussed, making it weakly grounded. The comment is specific in identifying the issue with the weak connection between the two parts, but it lacks detailed guidance on how to improve this connection. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses a concern about the weak connection between the first part of the paper, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the initial understanding of the first part and contrasts it with the actual content of the paper, suggesting that the current presentation does not align with the initial understanding. However, the comment lacks specific examples or references to support the claim that the connection is weak. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential weakness in the paper by pointing out a lack of connection between the first part, which discusses curve finding, and the second part, which focuses on FGE. The reviewer provides a detailed explanation of the initial understanding of the first part and contrasts it with the actual content of the paper, suggesting that the current presentation does not align with the initial understanding. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the connection between the two parts. While it highlights an area for improvement, the feedback is somewhat vague and could be more helpful if it provided actionable advice or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use long-term storage through pose graphs in SLAM, like those discussed in the appendix. However, the comment does not provide explicit guidance on how to incorporate or discuss these methods, nor does it specify which aspects of the proposed method should be compared or contrasted with these existing approaches. The action is implicit and vague, leaving the authors uncertain about how to apply the suggested discussion. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"general ideas\" and \"topological reasoning\" in the context of the proposed method, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the methods that should be discussed, such as those using generalized Voronoi graphs or semantic maps, and those related to long-term storage through pose graphs in SLAM. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that some general ideas are already present in other methods for exploration, specifically mentioning topological reasoning and methods using generalized Voronoi graphs or semantic maps, as well as long-term storage through pose graphs in SLAM. The comment provides examples of these methods, such as those discussed in the appendix, which helps to support the claim. However, the reasoning could be more detailed, and the claim is mostly verifiable as it is supported by specific examples but lacks a broader context or detailed explanation of how these methods relate to the proposed approach. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': \"The review comment identifies a potential area for improvement by suggesting that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, such as those employing generalized Voronoi graphs or semantic maps, and those that use long-term storage through pose graphs in SLAM. This feedback is somewhat helpful as it provides a clear direction for the authors to consider, but it lacks depth and specificity. The comment does not offer detailed guidance on how to incorporate or discuss these methods, which limits its impact on improving the draft. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experimental setup, tasks, and other details, which are currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. This provides explicit guidance on where to move specific content, making it clear and actionable for the authors. The suggestion is concrete, as it specifies which sections should be moved and where they should be placed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the experimental setup, tasks, and other details, which are currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. This provides explicit guidance on where to move specific content, making it clear and actionable for the authors. The comment is fully grounded as it explicitly mentions the appendix and the main body of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it specifies which details should be moved back and which background information should be moved to the appendix. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the experimental setup, tasks, and other details, currently in the appendix, should be moved back into the main body of the paper. It also recommends moving some background information from Section 2 to the appendix. While the comment provides a clear rationale for why these changes might be beneficial, it lacks specific examples or detailed reasoning to fully support the claim. The suggestion is logical and based on common practices in academic writing, but it could be strengthened with additional justification or examples. Therefore, the comment is mostly verifiable, as it provides a reasonable basis for the claim but could benefit from more detailed support.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment provides specific feedback on the organization of the paper, suggesting that moving certain details from the appendix to the main body would improve the interpretability of the experimental setup and tasks. It also recommends moving some background information from Section 2 to the appendix. This feedback is actionable and constructive, as it offers clear guidance on how the authors can enhance the clarity and coherence of their paper. By addressing these suggestions, the authors can significantly improve the readability and understanding of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the claim that \"Memb is apparently the previous state-of-the-art,\" but it does not provide any explicit or implicit suggestions on how to address this issue. The comment lacks guidance on whether the authors should include a reference or provide more context to support the claim. Without specific instructions on what needs to be done, the authors are left without actionable steps to take. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, such as a particular section or figure. It is also not specific because it does not detail what is missing or needs to be addressed regarding the claim about \"Memb being the previous state-of-the-art.\" Without this information, the authors cannot confidently understand the scope of the feedback. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that \"Memb is apparently the previous state-of-the-art,\" but it does not provide any supporting evidence or references to substantiate this claim. Without any justification or references, the authors are left without a basis to verify or address the claim. This makes the comment unverifiable, as it lacks the necessary evidence to support the assertion.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the claim that \"Memb is apparently the previous state-of-the-art\" but does not provide any specific guidance or suggestions on how to address this concern. It lacks actionable feedback, as it does not instruct the authors on what to include or how to substantiate the claim. Without additional context or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should study the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This comment provides a clear and explicit action for the authors to take, as they can directly address this suggestion by conducting additional experiments or analyses. The action is also concrete, as it specifies the exact aspect of the study that needs to be explored. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area where the comment applies. While the comment is specific about the type of study to be conducted, the lack of grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this suggestion or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests studying the impact of the ratio of unseen classes, specifically how performance varies with different ratios of unlabeled examples. This feedback is clear and actionable, as it provides a specific direction for the authors to explore in their work. By focusing on the impact of the ratio of unseen classes, the authors can gain a deeper understanding of their model's performance and potentially improve its robustness. However, the comment could be more helpful if it included suggestions for how to conduct this study or what specific metrics to use. Overall, the comment is mostly helpful as it offers a clear and actionable direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It also suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide explicit guidance on how the authors should clarify this point or address the potential use of epsilon-greedy exploration. The action is implicit, as the authors need to infer that they should clarify the meaning of \"epsilon-greedy\" and consider its implications for their strategy. The action is vague because it does not specify how to clarify the meaning or what aspects of the strategy need to be addressed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Just before Appendix D.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the meaning of \"epsilon-greedy\" in the context of the training process and suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. This provides clear guidance on what needs to be clarified or addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It does not contain a subjective claim or suggestion but rather asks for clarification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the meaning of \"epsilon-greedy\" in the context of the training process described in Appendix D.2. It suggests that the authors might be using epsilon-greedy exploration in addition to their proposed strategy. However, the comment does not provide any guidance or suggestions on how the authors should clarify this point or address the potential use of epsilon-greedy exploration. While it identifies an area that needs clarification, it lacks actionable advice or detailed feedback, making it barely helpful. Therefore, the comment aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow, with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough. However, the comment does not provide explicit guidance on how the authors might address this issue or what specific aspects of the method need to be improved. The action is implicit and vague, leaving the authors without a clear path to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow, with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough. However, the comment does not specify which part of the paper this critique refers to, such as a specific section or figure. This lack of grounding makes it difficult for the authors to understand where the critique applies and how to address it. Additionally, the comment is specific in its critique of the method's novelty, but without clear grounding, it remains challenging for the authors to implement the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and how to address it. Therefore, the comment is considered borderline verifiable, as it provides some basis for the claim but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the proposed method, suggesting it is a direct combination of GCN and normalizing flow with a minor modification in the transformed distribution. It claims that the technical contribution is not significant enough. However, the comment lacks specific details or suggestions on how the authors might address this issue or what aspects of the method need improvement. Without actionable feedback or guidance, the authors may find it challenging to understand the critique and how to respond effectively. Therefore, the comment is barely helpful, as it identifies a potential weakness but does not provide sufficient direction for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, it does not provide explicit guidance on how to implement this improvement or what specific aspects of the feature selection should be considered. The action is implicit and vague, as it leaves the authors to infer the necessary steps to take. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the proposed invariant learning module in Section 4.2, specifically mentioning mask selection and raw-level features. It also refers to the discussion of representation learning in the appendix, suggesting that the feature selection could be improved by considering representation learning. However, the comment does not specify which part of the paper the authors should focus on for improvement, making it weakly grounded. The comment is specific in suggesting that the feature selection could be enhanced by considering representation learning, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the feature selection presented in Section 4.2 could be further improved by considering representation learning, which is discussed in the appendix. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of why considering representation learning would enhance the feature selection process or how it could be implemented. Without these details, the claim is difficult for the authors to fully understand and address. Therefore, the comment is considered borderline verifiable, as it provides some basis for improvement but lacks sufficient depth and clarity to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the feature selection presented in Section 4.2 could be further enhanced by considering representation learning, which is discussed in the appendix. This feedback is somewhat helpful as it points out a specific aspect that could be improved, but it lacks detailed guidance on how to implement this suggestion or what specific aspects of the feature selection should be considered. The comment provides a clear direction for improvement but does not offer a comprehensive or actionable plan, leaving the authors with a general idea of what to work on. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details are missing, specifically mentioning the lack of understanding regarding the design of rewards. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on what specific details are missing or how the authors should clarify the design of rewards. Without concrete suggestions or examples, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is weakly grounded as it does not specify which part of the paper is missing details or lacks understanding regarding the design of rewards. However, it is specific in identifying the issue of missing details and the lack of understanding about the reward design. This allows the authors to infer that the feedback pertains to a specific section or part of the paper where these details are discussed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some details are missing and provides an example of a lack of understanding regarding the design of rewards. However, it does not offer any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how it relates to their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the draft, noting that some details are missing and that the design of rewards is not fully understandable. This feedback is clear and actionable, as it points out a gap in the paper that needs to be addressed. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might improve the clarity of the reward design. Despite this, the comment offers a valuable insight that can guide the authors in enhancing their draft, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the computational efficiency of Prithvi WxC, suggesting that its runtime should be discussed as a limitation. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the draft. The comment implies that the authors should consider discussing the runtime, but it lacks concrete instructions or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the computational efficiency of Prithvi WxC, specifically mentioning its large parameter count and suggesting that its runtime should be discussed as a limitation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to discuss the runtime, but without clear references to the paper, the authors may find it challenging to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the computational efficiency of Prithvi WxC, particularly its runtime, should be discussed as a limitation due to its large parameter count. However, the comment lacks specific evidence or references to support this claim, making it difficult for the authors to understand the basis of the argument. Without detailed reasoning or examples, the claim remains somewhat verifiable, as it is based on a logical inference but lacks sufficient justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the computational efficiency of Prithvi WxC, specifically mentioning its large parameter count and suggesting that its runtime should be discussed as a limitation. This feedback is somewhat helpful as it highlights a specific area for improvement and provides a clear rationale for why the runtime should be discussed. However, the comment could be more helpful if it offered additional guidance on how to address the issue or suggested specific ways to improve the draft. Overall, the comment provides a clear direction for the authors to consider, but it lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the quality of paraphrases used for training data generation. It points out that the difference between the paraphrases and the original sentences is unclear, which could impact the subsequent steps and the overall quality of the training data. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paraphrases. The feedback is somewhat vague and lacks concrete details on how to implement the suggested improvement. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of generating paraphrases for training data, specifically noting that the difference between the paraphrases and the original sentences is unclear. This provides a clear indication of which part of the paper the comment is focused on, allowing the authors to accurately identify the section being discussed. However, the comment does not specify what needs to be addressed in terms of improving the paraphrases or how to ensure the quality of the training data. While the authors can infer that they need to clarify the differences between paraphrases and original sentences, the comment lacks specific guidance on how to achieve this. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the quality of paraphrases used for training data generation, specifically noting that the difference between the paraphrases and the original sentences is unclear. This is a valid concern as the quality of the training data is crucial for the model's performance. However, the comment does not provide specific examples or references to support the claim that the difference is unclear or how this impacts the subsequent steps. While the reasoning is logical, the lack of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the quality of paraphrases used for training data generation. It highlights that the difference between the paraphrases and the original sentences is unclear, which can significantly impact the subsequent steps and the overall quality of the training data. The comment provides a clear and actionable suggestion that the authors should clarify the differences between the paraphrases and the original sentences to ensure the quality of the training data. This feedback is valuable as it directs the authors to a specific area that needs improvement and provides a clear path for addressing it. Therefore, the comment is mostly helpful, as it offers a clear and actionable suggestion that can significantly enhance the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, indicating that the writing could be improved. However, it does not provide any specific suggestions or actions for the authors to take to enhance their writing. The comment lacks explicit guidance on what aspects of the writing need improvement or how the authors can address these issues. As a result, the comment is unactionable because it does not offer concrete steps for the authors to follow. Therefore, it aligns with the label 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment is somewhat specific in that it highlights the difficulty in understanding the main idea and theoretical analysis, but without further guidance on how to improve these aspects, it remains somewhat specific. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the exact nature of the issue. Without additional context or suggestions, the claim is unverifiable. Therefore, the comment aligns with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment acknowledges the authors' difficulty in understanding the main idea and theoretical analysis of the paper, suggesting that the writing could be improved. However, it lacks specific suggestions or guidance on how to enhance the clarity or coherence of the writing. While it identifies an area for improvement, the comment does not provide actionable advice or detailed feedback that would help the authors address the issue. As a result, the comment is somewhat helpful, as it highlights a potential area for improvement but does not offer comprehensive or constructive suggestions. Therefore, it aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the fairness of comparisons made in the experiments, specifically noting that the domain-specific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zero-shot single-image 3D reconstruction models might be unfair. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the experiments or comparisons. The action is implicit, as the authors need to infer that they should consider alternative datasets or methods to ensure fair comparisons. While the action is somewhat vague, it is clear that the authors need to address the issue of fairness in their comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Pix3D\" and \"Pix3D,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the comparisons to zero-shot single-image 3D reconstruction models, highlighting the unfairness of the comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that comparisons to zero-shot single-image 3D reconstruction models are unfair because the domain-specific model and experiments are both conducted on Pix3D. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why the comparisons are unfair. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the fairness of comparisons made in the experiments, specifically noting that the domain-specific model and the experiments are both conducted on Pix3D. This observation suggests that the comparisons to zero-shot single-image 3D reconstruction models might be unfair. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to ensure fair comparisons. While it highlights a concern, it lacks actionable advice or detailed recommendations, making it somewhat helpful. The authors would need to infer that they should consider alternative datasets or methods to ensure fair comparisons, but the comment does not provide explicit guidance on how to do so. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D (Contrastive 2D) approach. However, it does not specify which aspects of the C2D approach would benefit from these experiments or how the experiments should be conducted. The comment implies that the authors should consider adding such experiments, but it lacks concrete guidance on what specific experiments to perform or how to integrate them into the draft. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or aspect that needs improvement. The comment is specific in its suggestion regarding the type of experiments, but it lacks grounding as it does not mention specific sections or parts of the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. However, the comment lacks specific details or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without additional context or evidence, the claim remains somewhat verifiable, as it lacks sufficient justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that additional experiments on realistic noisy datasets, such as WebVision, would provide more support for the C2D approach. While the comment identifies a potential area for improvement, it lacks specific guidance on how to conduct these experiments or what aspects of the C2D approach would benefit from such experiments. The suggestion is somewhat helpful as it points out a potential enhancement to the paper, but it does not provide detailed instructions or examples, leaving the authors with limited actionable feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes they should make to the tasks. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not specify which part of the paper discusses these tasks, making it difficult for the authors to pinpoint the exact issue. The lack of specific guidance on what needs to be addressed or how to improve the tasks makes the comment weakly grounded. Therefore, it aligns with category 2: Weakly Grounded and Not Specific.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice. However, the comment does not provide any specific evidence, examples, or references to support these claims. The feedback lacks detailed reasoning or justification, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises concerns about the abstract visual reasoning tasks, suggesting they are unintuitive and overly difficult. It questions whether the current formulation is necessary or if simpler tasks might suffice, which provides a clear area for improvement. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or what changes could be made to the tasks. While it identifies a potential weakness, it does not offer actionable advice or detailed feedback, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits its overall impact. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of visualization in the paper, specifically mentioning the absence of intermediate processes and comparisons. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue. The comment lacks concrete guidance on what kind of visualizations would be beneficial or how to incorporate them into the draft. Without specific advice on what to visualize or how to compare, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a lack of essential visualization of intermediate processes and comparisons, but it does not specify which part of the paper this issue pertains to. The authors cannot confidently determine which sections or figures are missing these visualizations. This lack of grounding makes it difficult for the authors to address the issue effectively. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that there is a lack of essential visualization of intermediate processes and comparisons in the paper. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the specific areas where the visualization is lacking. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, noting the lack of essential visualization of intermediate processes and comparisons. This feedback is clear and actionable, as it directs the authors to enhance the visual representation of their work. However, the comment could be more helpful if it provided suggestions on what kind of visualizations would be beneficial or how to effectively compare the intermediate processes. Despite this, the comment offers a clear direction for improvement, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the expected counterfactual violates $\\mathcal{P}_2$ as stated in Definition 1. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might correct the violation or what changes are necessary to align the counterfactual with the stated property. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Definition 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies that the expected counterfactual violates $\\mathcal{P}_2$ as stated in Definition 1, providing a clear indication of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the expected counterfactual violates $\\mathcal{P}_2$ as stated in Definition 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the expected counterfactual, noting that it violates $\\mathcal{P}_2$ as stated in Definition 1. While this feedback highlights a potential flaw in the paper, it lacks actionable guidance or suggestions on how the authors might address this issue. The comment does not provide any insight into how the authors could correct the violation or what changes might be necessary to align the counterfactual with the stated property. Without specific advice or suggestions, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it points out a problem but does not offer substantial guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the importance of the result and questions the novelty of the findings, particularly in light of existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve their draft. The feedback is vague and lacks actionable steps for the authors to take. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or theorem. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the result, it lacks grounding as it does not provide clear references or sections to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment lacks detailed reasoning or specific examples to support the claim that the findings are not surprising or that the iteration complexity is no longer dimension-free. The absence of references or detailed explanations makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises concerns about the importance of the result and questions the novelty of the findings, referencing existing work on perturbed gradient descent. It highlights a specific issue with the iteration complexity of Theorem 3, noting that it is no longer dimension-free. However, the comment lacks detailed reasoning or specific examples to support the claim that the findings are not surprising or that the iteration complexity is no longer dimension-free. The feedback is somewhat helpful as it identifies a potential area for improvement, but it does not provide actionable guidance or suggestions for the authors to address the concerns. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue, it does not provide explicit instructions or suggestions on how to address this concern. The authors are left to infer that the comment implies a need to clarify the methodology used in the grid search. However, the action is implicit and somewhat vague, as it does not specify what needs to be done to address the issue. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or figure being referenced. The comment is not grounded as it lacks specific references or context. Additionally, it does not provide specific guidance on how to address the issue, making it under-specific. Therefore, this comment is weakly grounded and under-specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about whether the grid search of the learning rate is performed on the validation set. However, it does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to assume that the reviewer is questioning the methodology, but the comment lacks sufficient information to address this concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether the grid search of the learning rate is performed on the validation set. While it identifies a potential issue in the methodology, it does not provide any suggestions or guidance on how to address this concern. The comment lacks depth and specificity, as it does not offer any actionable advice or insights into how the authors might improve their approach. Without additional context or suggestions, the authors are left without a clear path to enhance their work. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized ones. It does not provide explicit instructions or suggestions on how to address this issue, such as adding data or discussing the implications of the sample's diversity. The action is implicit, as the authors would need to infer that they should consider the diversity of their sample and its impact on generalizability. However, the comment lacks concrete guidance on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line number (L393) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the question about the diversity of the sample and its generalizability to other groups, especially marginalized groups. This provides clear guidance on what aspect of the paper requires attention. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the diversity of the sample and its generalizability to other groups, particularly marginalized groups. It does not contain a subjective claim or suggestion but rather poses a question that could be addressed by the authors. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a pertinent question about the diversity of the sample and its generalizability to other groups, especially marginalized ones. This is a critical aspect of ensuring the robustness and applicability of the research findings. However, the comment does not provide any suggestions or guidance on how to address this issue, such as adding data or discussing the implications of the sample's diversity. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the sufficiency of the number of images in the VioT dataset to text the validity of the approach. While it identifies a potential issue with the dataset size, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve the dataset or the approach. The comment lacks concrete suggestions or detailed instructions on how to enhance the dataset or the validity of the approach. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the VioT dataset, specifically mentioning the number of images in each category. It questions whether the number of images is sufficient to text the validity of the approach. However, the comment does not specify which part of the paper discusses the VioT dataset or the approach being questioned, making it weakly grounded. The comment is specific in identifying the issue with the dataset size, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the sufficiency of the number of images in the VioT dataset to text the validity of the approach. While it raises a concern about the dataset size, it does not provide any specific reasoning, examples, or references to support the claim that the number of images is too small. The comment lacks detailed justification or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the dataset used in the study, specifically questioning the sufficiency of the number of images in the VioT dataset to text the validity of the approach. While the comment highlights a concern, it does not provide specific suggestions or guidance on how to address this issue or improve the dataset. The feedback is somewhat helpful as it points out a potential limitation, but it lacks actionable advice or detailed suggestions for improvement, leaving the authors with limited insight into how to enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights several issues with the paper, including its difficulty to follow, the need for more intuitive explanations of mathematical derivations, and the lack of detailed explanations for figure captions. It suggests that the authors should provide additional explanations and legends for figures, such as explaining the colors in Fig. 2. However, the comment does not explicitly instruct the authors on how to incorporate these suggestions or provide concrete guidance on what specific changes to make. The actions are implicit and somewhat vague, as the authors are left to infer how to address the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the paper's difficulty to follow and suggests the need for more intuitive explanations of mathematical derivations. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not specify which part of the paper these issues are present, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing additional explanations and legends for figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is hard to follow and suggests that more intuitive explanations of mathematical derivations are needed. It also points out the lack of detailed explanations for figure captions, specifically mentioning the need to explain the colors in Fig. 2. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as the authors may need to infer the issues based on their own experience. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas where the paper could be improved, specifically noting that it is hard to follow and lacks intuitive explanations for mathematical derivations. It also points out the absence of detailed explanations for figure captions, such as the need to explain the colors in Fig. 2. While the comment provides some guidance on what needs to be addressed, it lacks depth and specificity, as it does not offer detailed suggestions or examples of how to improve the clarity and accessibility of the paper. The feedback is somewhat helpful as it highlights areas for improvement, but it could be more actionable with additional guidance. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a critical concern about the sensitivity of the empirical results to hyperparameter choices. It highlights the importance of this issue, noting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any explicit guidance or suggestions on how the authors might address this concern, such as conducting additional experiments or providing a detailed analysis of the impact of different hyperparameter settings. The action is implicit, as the authors are left to infer that they need to investigate the robustness of their results to hyperparameter variations. While the comment is somewhat actionable, it lacks concrete details on how to implement the suggested action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the sensitivity of the empirical results to hyperparameter choices, which is a crucial issue. However, it does not specify which part of the paper this concern pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its focus on hyperparameter sensitivity, the absence of explicit grounding makes it challenging for the authors to address the issue effectively. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the sensitivity of the empirical results to hyperparameter choices, suggesting that incorrect choices could potentially negate the benefits of the method. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a critical concern about the sensitivity of the empirical results to hyperparameter choices, noting that incorrect choices could potentially negate the benefits of the method. This is a significant issue that needs to be addressed to ensure the robustness and reliability of the findings. However, the comment lacks specific guidance or suggestions on how the authors might investigate or mitigate this issue. While it highlights an important area for improvement, the feedback is somewhat limited in its actionable nature, as it does not provide detailed steps or recommendations for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the motivation of the paper, suggesting that the cross-encoder architecture is not \"ignoring cross-entity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment does not provide any specific guidance or suggestions on how the authors might address these issues or improve their draft. The feedback lacks actionable steps, leaving the authors without a clear path to respond or enhance their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the motivation of the paper, specifically questioning the claim that the cross-encoder architecture \"ignores cross-entity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment does not specify which part of the paper this critique refers to, making it difficult for the authors to identify the exact section being addressed. While the comment is specific in its critique of the claims made about the cross-encoder architecture, the lack of grounding makes it challenging for the authors to understand the context and address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the cross-encoder architecture is not \"ignoring cross-entity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the accuracy of the critique. Without detailed reasoning or evidence, the claim remains unsubstantiated, and the authors may struggle to address the feedback effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the motivation of the paper, specifically questioning the claim that the cross-encoder architecture \"ignores cross-entity comparison\" and that it \"attends to all candidates at once\" to obtain matching scores. While the comment highlights a potential flaw in the paper's reasoning, it does not provide any suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is somewhat helpful as it points out a critical issue, but it lacks actionable advice, leaving the authors without a clear path to respond or enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the use of an \"antiquated GNN model and method\" and suggests that this impacts the performance of the framework. It also mentions that the baseline algorithms/methods are \"antiquated.\" However, the comment does not provide any specific guidance or suggestions on how the authors should address this issue. The authors are left without a clear understanding of what changes or improvements are needed to enhance the performance of the framework or the baseline methods. Therefore, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing, making it difficult for the authors to identify the exact section or aspect being discussed. It mentions the use of an \"antiquated GNN model and method\" and suggests that this impacts the performance of the framework, but it does not provide specific details on which sections or parts of the paper are affected. Additionally, the comment does not specify what needs to be addressed or how the authors should improve their work. Therefore, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the work uses an \"antiquated GNN model and method,\" which seriously impacts the performance of the framework. It also states that the baseline algorithms/methods are \"antiquated.\" However, the comment lacks specific examples or references to support these claims. Without detailed evidence or examples, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the use of an \"antiquated GNN model and method,\" which could impact the performance of the framework. It also points out that the baseline algorithms/methods are \"antiquated,\" suggesting a need for improvement. However, the comment lacks specific guidance or suggestions on how the authors might address these issues or what changes could be made to enhance the performance of their framework or baseline methods. While it highlights a critical area for improvement, the feedback is somewhat limited in its actionable value, as it does not provide detailed steps or recommendations for the authors to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides two explicit actions for the authors to take: first, to clarify the experiment and its implications, and second, to strengthen the experiment by addressing the issue of pseudo feature importance. The actions are clear and specific, giving the authors a direct understanding of what needs to be done. The comment also suggests that the experiment could be strengthened by addressing the issue of pseudo feature importance, which provides a concrete direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"one experiment to estimates the quality of uncertainty estimates,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely, the issue of using pseudo feature importance and the reliance on Prop 3.2 and a large enough perturbation value. This provides clear guidance on how to improve the experiment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a claim about the limitations of the experiment due to the use of pseudo feature importance and the reliance on Prop 3.2 and a large perturbation value. It suggests that the experiment could be strengthened by addressing these issues. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed guidance on how to strengthen the experiment. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experiment, noting that it uses pseudo feature importance instead of true feature importance, which makes it difficult to assess the correctness of the results. The comment suggests that the experiment could be strengthened by addressing the reliance on Prop 3.2 and a large perturbation value. This feedback is clear and actionable, providing the authors with a specific direction for improving their work. However, the comment could be more helpful if it offered additional suggestions or guidance on how to address the identified issue. Overall, the comment is mostly helpful, as it provides a clear and actionable critique that empowers the authors to enhance their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. While the comment identifies two separate issues, it does not explicitly instruct the authors to address these by providing detailed experimental settings and the code. The action is implicit and somewhat vague, as the authors need to infer that they should include these details to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of experimental settings and result reproducibility, which are critical aspects of a scientific paper. However, it does not specify which part of the paper discusses these settings or where the code is mentioned. This makes it difficult for the authors to pinpoint the exact sections that need improvement. While the comment is specific about the issues raised, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experimental settings are not mentioned properly, which is critical for result reproducibility. It also notes that the authors do not provide the code. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the exact issues. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical issue regarding the lack of proper mention of experimental settings, which is essential for result reproducibility. It also points out that the authors do not provide the code, which is a significant omission. While the comment highlights these weaknesses, it does not offer specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it directs the authors to areas that need improvement, but it lacks actionable advice or detailed suggestions, making it mostly helpful rather than highly helpful. Therefore, the comment aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different feedback to better reflect real-life situations. However, it does not provide explicit instructions or detailed guidance on how to implement this suggestion. The action is implicit, as the authors need to infer that they should explore methods to increase the diversity of feedback. While the suggestion is concrete in terms of exploring different feedback types, the lack of explicit guidance on how to achieve this makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback to better reflect real-life situations. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. The authors may need to infer that this relates to the feedback provided in the paper, but the comment lacks full grounding. The comment is specific in its suggestion to increase feedback diversity, but without clear grounding, it is difficult for the authors to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback to better reflect real-life situations. However, it does not provide any specific reasoning, examples, or references to support the claim that the feedback lacks diversity. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the diversity of teacher feedback, suggesting that the authors might consider turking or generating different kinds of feedback to better reflect real-life situations. This feedback is somewhat helpful as it prompts the authors to consider methods for increasing the diversity of feedback, which could enhance the robustness and comprehensiveness of their work. However, the comment lacks specific guidance on how to implement this suggestion or what methods to explore, making it somewhat helpful. The authors would need to infer that they should consider techniques like turking or generating different feedback types to address the issue. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide explicit instructions on how to achieve this, such as specific sections or formatting to include. The action is implicit, as the authors need to infer that they should add a summary of the supplement experiments to the main text. This makes the comment somewhat actionable, as it provides a clear direction but lacks concrete guidance on implementation. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not specify which part of the paper this clarification should be made, leaving the authors to infer that it should be in the main text. The comment is specific in its suggestion to clarify and summarize the experiments, but it lacks grounding as it does not point to a specific section or element of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence, making it difficult for the authors to understand why this clarification is necessary or how it would benefit their work. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the main text should clarify the presence of additional experiments in the supplement and preferably summarize their results. However, it lacks specific guidance on how to achieve this, such as suggesting where in the text these experiments should be discussed or what kind of summary would be most effective. The comment identifies a potential area for improvement but does not provide actionable feedback or detailed suggestions, making it somewhat helpful. The authors would need to infer that they should add a summary of the supplement experiments to the main text, but the comment does not offer concrete steps or examples to facilitate this process. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation provides a clear and explicit action for the authors to take, as they can compare their results with these specific works to better understand their performance relative to existing methods. The comment is concrete, as it specifies exactly which papers to compare with, and it provides a clear direction for the authors to follow. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation is fully grounded as it explicitly mentions the papers to be compared, allowing the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies which papers to compare with, providing a clear direction for the authors to follow. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point recommends comparing the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This recommendation is somewhat verifiable as it provides a clear suggestion for comparison, but it lacks specific details or examples of how the comparison should be conducted or what aspects of the performance should be evaluated. Without additional context or guidance, the authors may find it challenging to fully understand and implement the recommendation. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a clear recommendation to compare the performance of the proposed method with two specific papers, \"Multilingual unsupervised neural machine translation with denoising adapters\" and \"MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer\". This suggestion is actionable and offers a concrete direction for the authors to enhance their work by benchmarking against existing methods. By comparing their results with these specific papers, the authors can better understand the relative performance of their approach and identify areas for improvement. However, the comment could be more helpful if it provided additional guidance on how to conduct the comparison or what specific aspects of the performance should be evaluated. Overall, the comment is mostly helpful as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests that the approach should be extended to more general settings. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to extend the approach or what specific changes should be made. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific setting of the paper, including the requirements for the model and the episodic nature of the problem. It also specifies the need to extend the approach to more general settings, providing clear guidance on what needs to be addressed. This allows the authors to accurately identify the part of the paper being discussed and understand the specific issue being raised. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific question about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. While the comment does not provide a claim or assertion, it raises a question that could be addressed by the authors. However, without further elaboration or justification, the comment lacks sufficient detail to be considered fully verifiable. Therefore, it is categorized as \"2: Borderline Verifiable.\"', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific concern about the limitations of the current setting, which requires knowledge of the model or access to a generative model, and suggests extending the approach to more general settings. This feedback is clear and actionable, as it provides a direction for improvement by identifying a potential area where the approach could be broadened. However, the comment could be more helpful if it offered specific examples or guidance on how to extend the approach to more general settings. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. While the comment identifies a specific detail that needs clarification, it does not provide explicit guidance on how the authors should address this question or what information they should include in their response. The action is implicit, as the authors need to infer that they should clarify the feature extractor used. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 201,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This provides a clear direction for the authors to address the question. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the dimensionality of each region being 512 and asks for clarification on which feature extractor is used. This is a factual question that requires the authors to provide additional information or context. However, the comment does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment identifies a specific detail in the paper, namely the dimensionality of each region being 512, and asks for clarification on which feature extractor is used. This is a clear and actionable piece of feedback that helps the authors understand a potential gap in their explanation or methodology. By prompting the authors to clarify this aspect, the comment provides a direct path for improvement, making it somewhat helpful. However, it could be more helpful if it suggested specific ways to address the question or provided examples of how to clarify the feature extractor. Therefore, the comment is rated as 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which parts of the paper these details should be included in or how they should be presented. The action is implicit, as the authors can infer that they need to add these details, but the lack of specificity makes it difficult to know exactly what to do. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not specify which part of the paper these details should be included in or how they should be presented. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what kind of information or examples would be beneficial. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it does not offer any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that providing computation, algorithm, or implementation details would be helpful for readers. However, it lacks specificity and does not offer any guidance on how these details should be presented or what kind of information would be most beneficial. Without additional context or suggestions, the comment is vague and does not provide actionable feedback for the authors to improve their draft. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct the analysis or what specific aspects of the methods should be examined. The suggestion to compare with other methods is clear, but the lack of detailed instructions on how to perform the analysis makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a lack of analysis regarding the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. However, it does not specify which part of the paper this analysis should be conducted or which sections of the paper discuss the methods being compared. This makes it difficult for the authors to pinpoint the exact areas that need improvement. While the comment is specific about the type of analysis and comparison suggested, the lack of grounding makes it challenging for the authors to understand which parts of the paper are relevant. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is insufficient analysis of the effectiveness of each data augmentation method and suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing. The comment provides specific references to support the suggestion, which helps the authors understand the basis for comparison. However, the claim about the lack of analysis is somewhat vague and lacks detailed reasoning or examples to fully substantiate the critique. Therefore, the comment is mostly verifiable, as it provides some support but could be more robust with additional details or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by noting the lack of analysis regarding the effectiveness of each data augmentation method. It also suggests comparing the approach to other paraphrasing methods, such as EDA or LLM-based paraphrasing, to clarify the unique advantages of the proposed method. The inclusion of references to specific works provides a basis for comparison and adds depth to the feedback. This comment is mostly helpful as it offers clear guidance on areas for improvement and provides a framework for the authors to enhance their analysis and comparisons. However, it could be more comprehensive if it included specific suggestions on how to conduct the analysis or what aspects of the methods should be compared.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an ablation study is needed to understand the effect of each component in learning with MMD. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not explicitly instruct the authors to conduct an ablation study or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the need for an ablation study and the specific steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of learning with MMD, specifically mentioning the need for an ablation study to understand the effect of each component. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in detailing the need for an ablation study and providing examples of alternative approaches, which helps the authors understand what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that an ablation study is necessary to understand the net effect of each component in learning with MMD. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss. However, the comment lacks specific references or detailed reasoning to support the claim that an ablation study is essential. While the examples are helpful, the absence of a clear justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper, namely the need for an ablation study to understand the effect of each component in learning with MMD. It provides examples of alternative approaches, such as using typical knowledge distillation loss or distilling a Hydra architecture with MMD loss, which could help the authors better understand the proposed method. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the ablation study or suggested specific components to analyze. Overall, the feedback is somewhat helpful as it points out a crucial aspect that needs further exploration, but it lacks depth and actionable suggestions for improvement.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the performance of a model when negative samples are assigned to a distractor class. While it prompts the authors to consider this scenario, it does not provide explicit instructions or suggestions on how to address this question or what actions should be taken. The comment lacks concrete guidance on how to analyze or improve the model's performance in this context. Therefore, the action is implicit and vague, making the comment barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about the performance of a model when negative samples are assigned to a distractor class. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact area where the question should be addressed. While the comment is specific in its inquiry about model performance, the absence of grounding information limits its usefulness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point poses a question about the performance of a model when negative samples are assigned to a distractor class. It does not contain a claim or assertion that requires verification or justification. The comment is factual and descriptive, asking for an analysis of a specific scenario. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the performance of a model when negative samples are assigned to a distractor class. While it prompts the authors to consider this scenario, it does not provide any specific guidance or suggestions on how to address this question or what actions should be taken. The comment lacks depth and does not offer actionable insights or constructive feedback that would help the authors improve their work. Therefore, it is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of quantitative analysis regarding computational gains from replacing the MAE model with a CNN-based data augmentation strategy. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements. The comment is explicit in stating the need for quantitative analysis and provides concrete details on what kind of measurements would be beneficial. This allows the authors to directly address the issue by including the suggested analysis in their draft. Therefore, the comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"computational gains\" and \"quantitative analysis,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it specifies the need for quantitative measurements such as GPU hours, memory usage, or training time to substantiate the claim of computational benefits. This provides clear guidance on what needs to be addressed to support the claim. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks quantitative analysis on computational gains from replacing the MAE model with a CNN-based data augmentation strategy. It suggests that a quantitative analysis, such as GPU hours, memory usage, or training time, would provide stronger evidence of efficiency improvements. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand how to substantiate the assertion. The lack of detailed reasoning or examples makes the claim somewhat verifiable, as it lacks the necessary depth to fully substantiate the claim.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of quantitative analysis to support the claim of computational gains from replacing the MAE model with a CNN-based data augmentation strategy. It provides a clear suggestion for improvement by recommending the inclusion of specific measurements such as GPU hours, memory usage, or training time. This feedback is actionable and constructive, as it guides the authors on what additional data and analysis are needed to substantiate their claims. By addressing this feedback, the authors can strengthen the evidence supporting their conclusions and enhance the overall impact of their work. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing the methods, which would make the comparison less efficient for these scenes. However, it does not provide explicit guidance on how to incorporate this information into the comparison or what specific actions the authors should take to address this issue. The comment implies that the authors should consider the time taken for these processes, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies an important aspect that needs attention but does not provide detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the time taken for COLMAP and scene-by-scene fine-tuning, suggesting that this should be considered when comparing methods, which would make the comparison less efficient for these scenes. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing what needs to be considered, but without clear references, the authors may find it challenging to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time taken for COLMAP and scene-by-scene fine-tuning should be considered when comparing methods, which would make the comparison less efficient for these scenes. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this claim is valid or how it impacts the comparison. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the comparison of methods, specifically mentioning that the time taken for COLMAP and scene-by-scene fine-tuning should be considered. This feedback highlights a critical aspect that could affect the efficiency and comparability of the methods discussed. However, the comment lacks depth and does not provide specific guidance on how to address this issue or what adjustments might be necessary. While it points out a potential area for improvement, it does not offer actionable steps or detailed suggestions, making it somewhat helpful. The authors would need to infer the importance of considering the time taken for these processes, which limits the comment's overall impact.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. While the comment identifies specific areas that need attention, it does not provide explicit guidance on how to address these issues or what actions the authors should take. The actions are implicit and somewhat vague, as the authors are left to infer how to improve their draft. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. However, it does not specify which section or part of the paper this discussion is related to, making it weakly grounded. The comment is specific in its questions about the experiments conducted with FMN, the scaling of adaptive convolutions, and the potential limitations of FMN with a large number of filter parameters. This provides clear guidance on what needs to be addressed, but the lack of explicit grounding makes it challenging for the authors to pinpoint the exact areas to focus on. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the discussion and analysis of the \"filter manifold network\" (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. While the comment provides specific questions and areas for clarification, it lacks detailed reasoning or references to support the claims made. The authors are left to interpret the questions and address them, which limits the verifiability of the feedback. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some guidance but lacks sufficient evidence or justification.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises several important questions and concerns about the discussion and analysis of the 'filter manifold network' (FMN), which is a central part of the technique. It questions whether the authors experimented with other architectures for FMN, how adaptive convolutions scale with the number of filter parameters, and whether FMN can scale reasonably well with a large number of filter parameters. These questions highlight potential gaps in the paper's analysis and provide specific areas for the authors to address. However, the comment lacks detailed guidance or suggestions on how to improve the discussion or experiments related to FMN. While it identifies areas for improvement, it does not offer concrete steps or examples for the authors to follow, making it somewhat helpful. Therefore, the comment aligns with a score of 3, as it provides some insight but could be more comprehensive and actionable.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. While the comment provides a clear direction for the authors to explore, it does not explicitly instruct them on how to conduct this analysis or present the results. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed model and its two factors, noise and exponential moving average. It also specifies the need to see how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. This provides clear guidance on what aspects of the model need further exploration or analysis. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the proposed model benefits from two factors: noise and keeping an exponential moving average. It recommends seeing how much each factor contributes individually and how much gain can be obtained by using a noise-free exponential moving average. However, the comment does not provide any specific reasoning, examples, or references to support why this analysis is important or how it would enhance the paper. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper by suggesting that the authors explore the individual contributions of noise and exponential moving average in their proposed model. It provides a clear direction for the authors to consider, specifically asking how much gain can be obtained by using a noise-free exponential moving average. This feedback is actionable and constructive, as it guides the authors to conduct further analysis and potentially enhance their model. However, the comment could be more helpful if it provided additional context or suggestions for how to approach this analysis. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the reporting of results, suggesting that the paper only shows results after a significant amount of training. It also speculates about the potential impact of early training on the CNN's performance. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve their draft. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the reporting of results, specifically noting that the results are only reported after a significant amount of training. It also speculates about the potential impact of early training on the CNN's performance. However, the comment does not specify which part of the paper discusses the results or the training process, making it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific about the issues raised, it lacks grounding as it does not clearly identify the parts of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the reporting of results, specifically noting that the results are only reported after a significant amount of training. It also speculates about the potential impact of early training on the CNN's performance, suggesting that the model parameters might be \"essentially garbage\" and that the planning component might \"hurt\" more than it helps. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors are left to interpret the speculation, which makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a pertinent concern about the reporting of results, noting that the paper only presents results after a significant amount of training. This is particularly relevant in reinforcement learning, where understanding the agent's behavior during the learning process is crucial. The comment suggests that the authors might be interested in exploring how the CNN performs with less data, which is a valuable point for consideration. However, the comment lacks specific guidance or suggestions on how the authors could address this issue or what additional experiments might be necessary. While it identifies an important area for improvement, the feedback could be more helpful if it provided more detailed insights or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions. It suggests that the authors should consider these aspects and provide details on how they are addressed in the manuscript. While the comment implies that the authors should include this information, it does not explicitly instruct them to add it or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these details. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"DocRED\" and \"multiple entity mentions,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with how documents are handled in DocRED and how multiple entity mentions are treated, requesting that this information be included in the manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the handling of documents in DocRED and the treatment of multiple entity mentions, suggesting that this information is missing from the manuscript. However, it does not provide any specific examples, reasoning, or references to support why this information is important or how it should be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises specific questions about the handling of documents in DocRED and the treatment of multiple entity mentions, which are important aspects of the manuscript. It points out that this information is currently missing, suggesting that the authors should consider these aspects and provide details on how they are addressed. However, the comment lacks depth and does not offer specific guidance or suggestions on how to improve the manuscript based on these observations. While it identifies a gap in the manuscript, it does not provide actionable feedback that would help the authors enhance their work. Therefore, the comment is somewhat helpful, as it highlights areas for improvement but does not fully address the authors' needs for comprehensive feedback.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are well-designed and demonstrated. It further recommends adding another stream for low-resolution, which might not be a major contribution for a top-tier venue like ICLR. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting specific ways to enhance the contribution or address the concern. The feedback lacks concrete guidance on how to improve the paper or what specific aspects need attention. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses an opinion about the marginal contribution of the paper, suggesting that the methods used are well-designed and demonstrated. It recommends adding another stream for low-resolution, which might not be a significant contribution for a top-tier venue like ICLR. However, the comment does not specify which part of the paper discusses the methods or the contribution, making it difficult for the authors to pinpoint the exact area that needs attention. The lack of specific guidance on how to address the concern or what aspects to improve makes the comment weakly grounded. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are well-designed and demonstrated. It recommends adding another stream for low-resolution, which might not be a major contribution for a top-tier venue like ICLR. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations to substantiate the assertion that the contribution is marginal. Without such support, the claim remains subjective and difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses an opinion that the contribution of the paper is marginal, suggesting that the methods used are well-designed and demonstrated. It recommends adding another stream for low-resolution, which might not be a major contribution for a top-tier venue like ICLR. However, the comment lacks specific guidance or suggestions on how the authors could address this concern or enhance the contribution of their work. It does not provide actionable advice or detailed feedback on what aspects of the paper could be improved to make the contribution more significant. As a result, the comment is barely helpful, as it identifies a potential issue but does not offer concrete steps for the authors to take to address it.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments described, such as the Brusselator, due to time constraints. While the comment highlights a potential issue with the authors' engagement with the appendix, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The feedback is implicit and lacks concrete details, making it difficult for the authors to understand how to apply it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments, such as the Brusselator, due to time constraints. However, it does not specify which part of the Appendix or the paper the authors should focus on or what specific issues they might be facing. The comment lacks grounding as it does not provide clear guidance on which sections or parts of the paper need attention. It is also not specific because it does not detail what aspects of the experiments are unclear or require further explanation. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a concern about the authors not carefully reading the additional experiments described in the Appendix, such as the Brusselator, due to time constraints. However, it does not provide any specific reasoning or evidence to support this claim. The comment lacks detailed justification or examples to explain why the authors might not have read the appendix thoroughly. Without additional context or reasoning, the claim is difficult to verify, making it unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges the value of the comprehensive Appendix but expresses a concern about the authors not carefully reading the additional experiments, such as the Brusselator, due to time constraints. While the comment highlights a potential issue with the authors' engagement with the appendix, it does not provide specific suggestions or guidance on how to address this concern. The feedback is somewhat helpful as it identifies a potential area for improvement, but it lacks actionable advice or detailed suggestions, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should demonstrate the scalability of LFF by showing its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This provides a clear and explicit action for the authors to take, as they need to expand their experiments to include these more complex tasks. The comment is specific in its suggestion and offers a concrete direction for improvement, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need to demonstrate the scalability of LFF on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This provides clear guidance on which part of the paper the authors should focus on. The comment is also specific, as it specifies the type of tasks that would help demonstrate the scalability of LFF. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car, and suggests that demonstrating LFF's effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids, is important for fully demonstrating its scalability. This claim is somewhat verifiable as it provides a logical reasoning for why the suggested tasks are important for demonstrating scalability, but it lacks specific examples or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that most continuous control experiments are performed on simple and low-dimensional tasks, such as cartpole or mountain car. It suggests that to fully demonstrate the scalability of LFF, the authors should show its effectiveness on more challenging DRL tasks with higher input dimensionality, such as locomotion of ants or humanoids. This feedback is clear and actionable, providing a specific direction for the authors to enhance their experiments and better showcase the capabilities of LFF. By addressing this suggestion, the authors can significantly improve the comprehensiveness and impact of their work, making the comment highly helpful.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the paper for considering only one deep learning-based baseline, MULT, which was proposed in 2019 and is no longer considered state-of-the-art. However, the comment does not provide any explicit or implicit suggestions for improvement or additional baselines that could be considered. The authors are left without guidance on how to address this issue or what other baselines might be relevant. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment provides a list of references related to multimodal sentiment analysis and emotion recognition, but it does not specify which part of the paper these references are relevant to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not specify what needs to be addressed in relation to these references, such as how they might improve the paper or what aspects of the paper are lacking in comparison to these works. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the paper regards MULT as the only deep learning-based baseline that considers cross-sensory interaction but notes that MULT was proposed in 2019 and is thus out of fashion. This claim is somewhat verifiable as it provides a specific example of a baseline and its publication year, allowing the authors to understand the context of the criticism. However, it lacks detailed reasoning or references to support the claim fully, which could make it somewhat verifiable. Therefore, the comment aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper by suggesting that the authors should consider more recent baselines for comparison, as the current baseline, MULT, was proposed in 2019 and may no longer be considered state-of-the-art. This feedback is somewhat helpful as it points out a potential gap in the literature review and suggests an area for improvement. However, the comment could be more helpful if it provided specific examples of more recent baselines or suggested how the authors could address this issue in their work. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While it suggests that these terms likely denote the Encoder and Decoder networks, the comment does not provide explicit guidance on how the authors should define these terms or where they should be defined. The action is implicit, as the authors need to infer that they should define W and V, but it lacks concrete details on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear indication of what needs to be addressed but does not offer specific guidance on how to implement the action.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific sections of the paper (p.3, A4, eq.3 and eq.4) where the terms W and V are not defined. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies that the terms W and V are not defined in these sections, and it suggests that these terms likely denote the Encoder and Decoder networks. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the terms W and V are not defined in the paper, specifically in equations 3 and 4. While the comment identifies a potential issue with the clarity of the paper, it does not provide any specific examples or references to support the claim. The authors are left to infer that the terms are likely undefined, but without further explanation or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the terms W and V are not defined in equations 3 and 4. This is a clear and actionable feedback that highlights a lack of clarity in the paper. By pointing out the missing definitions, the comment provides the authors with a direct instruction to improve the readability and understanding of their work. However, the comment could be more helpful if it suggested specific ways to define these terms or provided examples of how they are used. Overall, the feedback is somewhat helpful as it directs the authors to a critical area for improvement, but it lacks depth in terms of actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the fixed nature of negative chips generated from the lightweight RPN and whether they are updated during the training process. It also asks whether alternating between generating negative chips and training the network could potentially improve performance. While the comment poses a question that could guide the authors to consider an alternative approach, it does not provide explicit instructions or suggestions on how to implement this idea or what specific changes might be necessary. The action is implicit and somewhat vague, as the authors are left to infer the need for further exploration and experimentation. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the fixed nature of negative chips generated from the lightweight RPN and whether they are updated during the training process. It also asks whether alternating between generating negative chips and training the network could potentially improve performance. However, the comment does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. While the question is specific about the topic, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the fixed nature of negative chips generated from the lightweight RPN and whether they are updated during the training process. It also asks whether alternating between generating negative chips and training the network could potentially improve performance. However, the comment does not provide any evidence, reasoning, or references to support the claim that this approach might be beneficial. Without specific justification or examples, the authors are left to consider the question independently, making the comment unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the fixed nature of negative chips generated from the lightweight RPN and whether they are updated during the training process. It also inquires whether alternating between generating negative chips and training the network could potentially improve performance. While the comment identifies a potential area for exploration and experimentation, it does not provide specific guidance or suggestions on how the authors might approach this question or what changes could be made to the methodology. The feedback is somewhat helpful as it prompts the authors to consider an alternative approach, but it lacks depth and actionable advice, making it only somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide explicit guidance on how to conduct this evaluation or what specific aspects of the approach should be considered. The action is implicit, as the authors need to infer that they should perform this evaluation, but it lacks concrete details on how to implement it. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not specify which part of the paper this question pertains to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area where the comment is relevant. While the comment is specific in its suggestion to evaluate the approach on new and old patients, the absence of explicit grounding makes it challenging for the authors to understand which part of the paper needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. However, it does not provide any specific reasoning, examples, or references to support why this evaluation is necessary or how it would impact the results. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the applicability of the proposed approach to new and old patients, suggesting that the authors should evaluate the approach on both groups. This feedback highlights a potential area for improvement in the paper, specifically regarding the generalizability of the proposed method. However, the comment lacks specific guidance on how to conduct this evaluation or what aspects of the approach should be considered. While it identifies a relevant area for improvement, the lack of detailed suggestions or examples makes it somewhat helpful. The authors would need to infer the need for further evaluation, which limits the comment's impact. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. While the comment implies that the authors should conduct a more detailed analysis, it does not explicitly instruct them to do so or provide specific guidance on how to analyze the training dynamics. The action is somewhat vague, as the authors need to infer that they should perform a more thorough analysis. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute. It implies that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. It is specific in suggesting that the authors should provide an analysis explaining the training dynamics, but without a clear reference to a specific section or figure, the authors may find it challenging to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper lacks in-depth analysis, specifically regarding the inverse scaling observed over compute, and suggests that the authors should provide an analysis explaining the training dynamics to make the paper more solid. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper: the lack of in-depth analysis regarding the inverse scaling observed over compute. It suggests that the authors should provide an analysis explaining the training dynamics to strengthen the paper. This feedback is clear and actionable, as it directs the authors to a specific area where they can improve their work. However, the comment could be more helpful if it provided some guidance on how to conduct this analysis or suggested specific methods for investigating the training dynamics. Despite this, the comment is mostly helpful as it highlights a crucial aspect of the paper that needs attention, providing the authors with a clear direction for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not provide explicit instructions or guidance on how the authors should address these questions or what specific actions they should take. The comment implies that the authors should consider these additional evaluations, but it lacks concrete steps or suggestions on how to do so. As a result, the authors are left without clear direction on how to improve their draft based on this feedback. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to identify the exact sections or content being addressed. The comment is not grounded as it does not provide explicit references to specific sections, tables, or figures. Additionally, it lacks specificity in detailing what additional insights or evaluations are needed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. However, it does not provide any specific evidence, reasoning, or references to support these claims or questions. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the inquiry or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises questions about the performance of the algorithm on the Clothing1M dataset and suggests exploring its performance on other real-world datasets like WebVision, evaluated by DivideMix. This feedback highlights a potential area for further investigation and could guide the authors in enhancing the robustness and generalizability of their results. However, the comment lacks specific suggestions or guidance on how the authors might approach these additional evaluations or what specific aspects of the algorithm's performance should be considered. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that it does not describe the hyperparameters used by each defense or how they are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack, indicating the amount of clean data required to remove the attack. This feedback provides a clear and explicit action for the authors to take, as they need to include details about the hyperparameters used and their derivation. The suggestion to optimize hyperparameters against the attack is also concrete, offering a specific direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment addresses the lack of description regarding hyperparameters used by each defense and how they are derived, suggesting a maximally charitable evaluation of defenses. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper does not describe the hyperparameters used by each defense or how they are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack, indicating the amount of clean data required to remove the attack. This claim is somewhat verifiable as it highlights a gap in the paper's description of hyperparameters, but it lacks specific examples or references to support the claim fully. The authors would need to provide more detailed information to address this feedback effectively. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the lack of description regarding the hyperparameters used by each defense and how they are derived. It suggests that a maximally charitable evaluation of defenses would optimize hyperparameters against the attack, indicating the amount of clean data required to remove the attack. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by including detailed information about the hyperparameters and their derivation. The suggestion to optimize hyperparameters against the attack is also constructive, offering a concrete way to enhance the paper's evaluation. Therefore, the comment is highly helpful, as it addresses a critical aspect of the paper that needs clarification and improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern about the practical implications of the theoretical results, suggesting that the paper could benefit from providing more take-away points for practitioners. It also notes that the main take-away point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not explicitly instruct the authors to include more practical takeaways or clarify the novelty of the finding. While the authors can infer that they need to address these points, the action is implicit and somewhat vague, as it lacks specific guidance on how to incorporate practical takeaways or clarify the novelty. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the practical implications of the theoretical results, suggesting that the paper could benefit from providing more take-away points for practitioners. It also notes that the main take-away point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty. However, the comment does not specify which part of the paper discusses the theoretical results or the take-away points, making it weakly grounded. The comment is specific in detailing the issue with the practical implications and the lack of clarity regarding the novelty of the finding. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the theoretical results lack immediate practical implications, which is a subjective observation. It suggests that the paper could benefit from providing more take-away points for practitioners, but this is not a claim that requires verification. The comment also notes that the main take-away point about querying a cluster proportionally to the square root of its size is unclear regarding its novelty, but this is a critique rather than a claim that needs verification. Therefore, the comment does not contain any claims that require verification, and it should be classified as \"X\".', 'verifiability_label': 'X', 'helpfulness_rationale': \"The review comment identifies a key area for improvement by pointing out that the theoretical results lack immediate practical implications, which is a valuable insight for applied researchers. It suggests that the paper could benefit from providing more take-away points for practitioners, which would enhance its relevance and impact. Additionally, the comment highlights a specific point of confusion regarding the novelty of the main take-away point about querying a cluster proportionally to the square root of its size, which is a constructive critique that could guide the authors in refining their work. However, the comment could be more helpful if it provided specific suggestions or examples for how to address these issues. Overall, the feedback is somewhat helpful as it identifies important areas for improvement but lacks detailed guidance, making it a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of introducing separators in Section 4, asking for clarification on their purpose beyond T/I/O. While it prompts the authors to explain the role of separators, it does not provide explicit guidance on how to address this issue or what specific changes might be needed. The action is implicit, as the authors need to infer that they should clarify the purpose of separators. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of introducing separators and asks for clarification on their purpose beyond T/I/O, providing a clear direction for the authors to address the issue. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the necessity of introducing separators in Section 4, specifically asking for clarification on their purpose beyond T/I/O. While it does not contain a direct claim or assertion, it prompts the authors to consider the rationale behind the introduction of separators. However, without further explanation or context, the comment lacks sufficient detail to be fully verifiable. The authors would need to infer the need for clarification, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area of confusion regarding the introduction of separators in Section 4, questioning their purpose beyond T/I/O. This feedback is valuable as it highlights a potential gap in the explanation of the method or results, prompting the authors to clarify the role of separators. However, the comment could be more helpful if it provided suggestions or guidance on how to address this issue, such as suggesting additional context or examples. Overall, the comment is somewhat helpful as it points out a specific area for improvement but lacks depth in terms of actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide explicit guidance on which alternative strategies to explore or how to implement them. The action is implicit, as the authors need to infer that they should consider other pooling methods and potentially explore them. While the comment is somewhat actionable, it lacks concrete details on how to proceed with the exploration or implementation of alternative pooling strategies. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific line in the paper (L235), allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the choice of mean pooling and suggesting alternative strategies, such as other pooling methods. This provides clear guidance on what needs to be considered or addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. However, it does not provide any specific reasoning, examples, or references to support why mean pooling is chosen or why other strategies might be better. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of mean pooling for token aggregation, suggesting that other pooling strategies might be considered. This feedback is somewhat helpful as it prompts the authors to consider alternative approaches, which could potentially improve the robustness or effectiveness of their method. However, the comment lacks depth and does not provide specific guidance or suggestions on which alternative pooling strategies to explore or how to implement them. As a result, while it offers a starting point for improvement, it does not fully empower the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. While the comment implies that the authors should provide these details, it does not explicitly instruct them to include them in the draft. The action is implicit, as the authors can infer that they need to add this information, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks specific instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in that it identifies a missing detail that needs clarification, but the lack of grounding makes it difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the training details of the VQGAN, specifically whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This is a factual question that requires the authors to provide specific details about their training process. However, the comment does not offer any additional context, reasoning, or references to support the need for this information. As a result, the claim is somewhat verifiable, as it is based on a logical request for clarification but lacks sufficient justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific question about the training details of the VQGAN, asking whether it is pre-trained or trained solely on the 88,635 images from the Computer Vision Figures dataset. This question highlights a potential gap in the authors' explanation of their methodology, as it is crucial to provide clear and detailed information about the training process to ensure the reproducibility and understanding of the work. However, the comment does not offer any suggestions or guidance on how to address this issue, leaving the authors with a clear area for improvement but without actionable advice. Therefore, the comment is somewhat helpful, as it identifies a specific area that needs clarification but lacks depth in its suggestions.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the work should include and compare to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also recommends a discussion on how the work differs from other chatbox research works. However, the comment does not provide explicit guidance on how to incorporate these comparisons or discussions into the paper. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests including and comparing to specific related works, such as Li et al. (2017) and He et al. (2015), which are mentioned by name. This provides clear grounding as the authors can accurately identify the sections or parts of the paper where these works are discussed. The comment also recommends a discussion on how the work differs from other chatbox research works, which is specific and provides guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests including and comparing to specific related works, such as Li et al. (2017) and He et al. (2015), and recommends a discussion on how the work differs from other chatbox research works. However, the comment lacks specific examples or detailed reasoning to support why these comparisons are necessary or how they would enhance the paper. Without clear justification or examples, the claim is difficult for the authors to fully understand and address. Therefore, the comment is barely verifiable, aligning with a score of 2.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment suggests that the work should include and compare to specific related works, such as Li et al. (2017) and He et al. (2015), at least conceptually. It also recommends a discussion on how the work differs from other chatbox research works. However, the comment lacks specific guidance on how to incorporate these comparisons or discussions into the paper, leaving the authors with a general idea of what needs to be addressed but without detailed instructions. This makes the comment somewhat helpful, as it provides a direction for improvement but could be more comprehensive with additional details or examples. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, particularly in the MSVD dataset, where minor improvements are observed. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the methods. The authors are left without guidance on what steps to take to enhance the generality of their methods or to achieve more significant improvements in performance. As a result, the comment lacks actionable information, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the proposed methods, DualIS and DualDIS, and refers to specific results in Table 3, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the methods are not generic on some cross-model retrieval tasks, particularly in the MSVD dataset, where minor improvements are observed. This level of detail provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed methods, DualIS and DualDIS, are not generic on some cross-model retrieval tasks, specifically noting that the performance in MSVD (Table 3) shows minor improvements. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to fully understand or address the issue. Therefore, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proposed methods, DualIS and DualDIS, noting that they are not generic on some cross-model retrieval tasks, particularly in the MSVD dataset, where minor improvements are observed. While the comment highlights a potential limitation of the methods, it does not provide any suggestions or guidance on how to address this issue or improve the methods. The feedback is somewhat helpful as it points out a specific area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction on how to enhance their work. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the experimental strengths of the proposed approach, suggesting that running the algorithm on 40 different networks from the training phase might be unnecessary. It proposes an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their experimental setup. The action is implicit and vague, as it does not specify how the authors should compare their approach to the suggested alternative or what specific aspects of their experimental design need to be reconsidered. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or table discussing the experimental setup. This makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific about the concern regarding the number of networks and the alternative approach, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the experimental strengths of the proposed approach, specifically questioning the necessity of running the algorithm on 40 different networks from the training phase. It suggests an alternative method, running vanilla Adam on the final network with 40 random initial points, where one of these restarts could reach the global minimum. This feedback highlights a potential inefficiency in the experimental setup and provides a constructive suggestion for improvement. However, the comment lacks depth and does not offer detailed guidance on how the authors might address this concern or what specific changes they should consider. While it identifies an area for improvement, it could be more helpful with additional suggestions or a more thorough analysis of the implications of the proposed alternative. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue regarding the performance of FedSP in Table 1 and Table 2 on some datasets, suggesting that the theme is mainly about FedSP. However, it does not provide explicit guidance on what needs to be improved or how the authors should address this issue. The comment implies that the authors should consider revising their draft to better reflect the performance of FedSP, but it lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it identifies a potential area for improvement but does not provide detailed guidance on how to implement it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the performance of FedSP on some datasets, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the performance of FedSP is not the best in Table 1 and Table 2 on some datasets. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or data, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue regarding the performance of FedSP in Table 1 and Table 2 on some datasets, noting that it is not the best. This feedback is clear and actionable, as it highlights a potential area for improvement in the authors' draft. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or what specific aspects of the performance could be improved. Overall, the comment is somewhat helpful, as it identifies a meaningful weakness but lacks depth in terms of actionable guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific guidance or suggestions on how the authors might explore the dataset further. The comment lacks explicit instructions or concrete details on what aspects of the dataset should be investigated or how it could enhance the paper. As a result, the authors are left without a clear understanding of how to address this feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this exploration should occur, leaving the authors uncertain about the exact location or scope of the suggestion. Additionally, the comment lacks specificity in terms of what aspects of the dataset should be explored or how it could enhance the paper. Without these details, the authors cannot confidently determine how to address the feedback. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors are left without a clear understanding of why this suggestion is important or how it could be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specific guidance or suggestions on how the authors might explore the dataset further or what aspects of the dataset should be investigated. Without actionable advice or examples, the authors are left without a clear understanding of how to address this feedback. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient detail to guide the authors in enhancing their work.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point acknowledges that it is not yet possible to realize efficiency gains on GPU, which is a common observation in the field of pruning. However, it does not provide any specific guidance or suggestions for how the authors might address this issue or improve their work. The comment lacks actionable steps or concrete advice, leaving the authors without a clear path to follow. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper it is addressing. It makes a general statement about the difficulty of realizing efficiency gains on GPU, which is a common observation in the field of pruning. However, it does not provide specific guidance or suggestions for how the authors might address this issue or improve their work. Therefore, the comment is not grounded and does not specify what needs to be addressed, making it unspecific. This aligns with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is not yet possible to realize efficiency gains on GPU, as with most work on pruning. However, the comment lacks specific evidence or references to support this claim. It does not provide examples or detailed reasoning to substantiate the assertion, making it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment acknowledges that it is not yet possible to realize efficiency gains on GPU, which is a common observation in the field of pruning. However, it does not provide any specific suggestions or insights on how the authors might address this issue or improve their work. The comment lacks actionable guidance and does not offer any constructive feedback that could help the authors enhance their draft. As a result, the comment is barely helpful, as it does not provide any meaningful direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the cost of insurance for men and women after a method is applied. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider to provide a comprehensive answer. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the cost of insurance for men and women after a method is applied, but it does not specify which part of the paper this question relates to. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance or suggestions on how to address this question or what information is needed to answer it. Therefore, the comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the cost of insurance for men and women after a method is applied. However, it does not provide any context, reasoning, or references to support the question or its relevance to the paper. Without additional information or justification, the authors are left without a basis for understanding or addressing the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the cost of insurance for men and women after a method is applied. However, it does not provide any context, reasoning, or suggestions on how to address this question or what information might be relevant. The comment lacks depth and actionable feedback, leaving the authors without guidance on how to improve their draft or address the question. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should clarify the difference between the meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not explicitly instruct the authors on how to clarify this difference or what specific aspects of the paper need to be addressed. While the suggestion is clear, the lack of detailed guidance on implementation makes it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. However, the comment does not specify which part of the paper discusses meta solvers or centralized RL, making it difficult for the authors to pinpoint the exact section that needs clarification. While the suggestion is specific about the content to be clarified, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors should clarify the difference between meta solvers and centralized RL, where agents share weights, and provides a specific example by citing Foester et al. This claim is somewhat verifiable as it offers a suggestion for improvement and includes a reference to support the claim. However, the comment lacks detailed reasoning or explanation of why this clarification is necessary or how it would benefit the paper. The authors would need to infer the importance of this clarification, which could be improved with more context or justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors clarify the difference between meta solvers and centralized RL, where agents share weights. It provides a specific example, citing Foester et al., to illustrate the concept. This feedback is clear and actionable, as it directs the authors to address a potential ambiguity in their paper. However, the comment could be more helpful if it offered additional guidance on how to clarify this difference or what specific aspects of the paper need to be addressed. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the paper's categorization method, noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the practice of posting papers on arXiv earlier. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their categorization method. The action is implicit, as the authors would need to infer that they should consider the arXiv publication dates when categorizing the papers. The lack of concrete instructions or suggestions makes the action vague and difficult to implement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the categorization of papers based on publication years on the ACL anthology, noting that many papers are posted on arXiv earlier. However, it does not explicitly mention which part of the paper this issue pertains to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific in its critique, the lack of grounding makes it challenging for the authors to fully understand and address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper's categorization method, which splits papers based on publication years on the ACL anthology, is inaccurate because many papers are posted on arXiv earlier. The reviewer provides an example, such as the BERT paper being available on arXiv before the ACL anthology. However, the comment lacks detailed reasoning or references to support the claim comprehensively. While the example provides some context, it does not fully substantiate the claim, leaving the authors with limited guidance on how to address the issue. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a potential issue with the paper's categorization method, specifically noting that splitting papers based on publication years on the ACL anthology might be inaccurate due to the practice of posting papers on arXiv earlier. The reviewer provides an example, such as the BERT paper being available on arXiv before the ACL anthology, which highlights the inconsistency in the categorization. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their categorization method. While it points out a potential problem, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should consider the arXiv publication dates when categorizing the papers, but the comment does not provide detailed steps or examples to facilitate this improvement. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises two distinct issues regarding the proposed relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. However, it does not provide explicit or implicit actions for the authors to take to address these concerns. The comment lacks guidance on how the authors might clarify their reasoning or provide additional context to support their claims. As a result, the authors are left without clear directions on how to improve their draft, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses two distinct issues: the relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. However, it does not specify which parts of the paper these issues relate to, such as specific sections or algorithms. This lack of grounding makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in its critique of the proposed method and the algorithm, the absence of explicit references to sections or algorithms makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises two questions about the rationale behind the proposed relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. However, it does not provide any supporting evidence, reasoning, or references to justify why the authors chose to use an arbitrary parameter \u03b2 instead of the true upper bound or why QRS and RS behave differently. Without additional context or explanation, the claims are not verifiable, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises two distinct points regarding the proposed relaxation of rejection sampling and the differences between QRS and RS in Algorithm 1. However, it lacks depth and actionable suggestions, failing to provide clear guidance on how the authors might address these concerns or improve their draft. The comment identifies areas for improvement but does not offer specific advice or detailed explanations, leaving the authors with limited insight into how to enhance their work. As a result, the feedback is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the experimental results on the last two datasets, noting that they are not convincing enough to validate the effectiveness of the proposed method. It also questions whether the performance is similar to IRM, which could be due to problems mentioned above. However, the comment does not provide explicit or implicit actions for the authors to take, such as suggesting alternative datasets, conducting additional experiments, or revising the analysis. Without concrete guidance on how to address these issues, the authors are left without a clear path forward. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the experimental results on the last two datasets, noting that they are not convincing enough to validate the effectiveness of the proposed method. It also questions whether the performance is similar to IRM, which could be due to problems mentioned above. However, the comment does not specify which part of the paper these datasets are associated with, making it difficult for the authors to pinpoint the exact issue. While it identifies the area of concern, it lacks specificity in detailing what needs to be addressed. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises concerns about the experimental results on the last two datasets, suggesting they are not convincing enough to validate the effectiveness of the proposed method. It questions whether the performance is similar to IRM, which could be due to problems mentioned above. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the results are not convincing. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a concern regarding the experimental results on the last two datasets, noting that they are not convincing enough to validate the effectiveness of the proposed method. It also questions whether the performance is similar to IRM, which could be due to problems mentioned above. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve the experimental setup. Without actionable feedback or detailed recommendations, the authors are left without a clear path forward to enhance their work. Therefore, the comment is barely helpful, as it points out a potential weakness but does not provide substantial guidance for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long entity is known. However, it does not provide explicit instructions or suggestions on how the authors should address this question or what changes might be needed in their draft. The action is implicit, as the authors would need to infer that they should provide a detailed explanation or justification for the inclusion of both entities. The comment lacks concrete guidance on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about why both entities are detected in Figure 2 and asks for a comparison with a scenario where only the long one is known. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification and comparison, but without explicit references to a particular section or figure, the authors may find it challenging to pinpoint the exact area of concern. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the necessity of detecting both entities in Figure 2 and asks for a comparison with a scenario where only the long entity is known. However, it does not provide any specific reasoning, examples, or references to support why both entities should be detected or how this differs from knowing just the long one. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the question. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the necessity of detecting both entities in Figure 2 and asks for a comparison with a scenario where only the long entity is known. This question prompts the authors to consider the rationale behind their choice of detection and whether it aligns with the expected outcomes. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to their draft. While it identifies a potential area for clarification, it does not offer actionable feedback that would significantly enhance the authors' understanding or improve their work. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but does not provide comprehensive guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. While the comment identifies a specific point of confusion, it does not provide explicit guidance on how the authors should address this issue or what changes might be necessary. The action is implicit, as the authors need to infer that they should clarify the meaning of \"chunks\" in the context of the paper. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment aligns with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Line 285,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it directly questions the clarity of the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still sequential information. This is a subjective question that seeks to understand the authors' interpretation of the term. While it does not contain a claim that requires verification, it does prompt the authors to clarify a specific aspect of their work. Therefore, it aligns with a score of \"X\", as it does not contain a claim that needs verification.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a specific question about the phrase \"non-sequential information such as chunks\" and asks for clarification on whether chunks are still considered sequential information. This feedback is clear and actionable, as it prompts the authors to clarify a point of confusion in their paper. By addressing this question, the authors can improve the clarity and precision of their writing. However, the comment could be more helpful if it provided additional context or suggested specific ways to clarify the phrase. Overall, the comment is somewhat helpful, as it identifies a need for clarification but lacks depth in its suggestions. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about a specific aspect of Theorem 1, questioning the validity of an assumption regarding a node with 0 neighbors. While the reviewer identifies a potential issue with the theorem, the comment does not provide explicit guidance or suggestions on how to address this concern. The authors are left to infer that they need to clarify or correct the theorem, but the lack of concrete steps or detailed explanations makes the action implicit and vague. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises a question about a specific aspect of Theorem 1, focusing on a potential issue with an assumption regarding a node with 0 neighbors. However, it does not specify which part of the paper this theorem is located in, making it difficult for the authors to pinpoint the exact section being addressed. The comment is specific in its critique of the theorem but lacks grounding as it does not provide clear guidance on how to address the issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the validity of Theorem 1, specifically questioning the assumption that a node with 0 neighbors would result in an upper bound of 0. While the reviewer expresses a concern, the comment lacks detailed reasoning or examples to substantiate the claim. It does not provide specific references or logical arguments to support the assertion that this assumption is incorrect or needs clarification. As a result, the claim is somewhat verifiable, as it is based on a subjective observation without sufficient evidence or justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a specific question about Theorem 1, pointing out a potential issue with the assumption that a node with 0 neighbors would result in an upper bound of 0. This feedback is somewhat helpful as it identifies a potential area of concern and encourages the authors to clarify or correct the theorem. However, the comment lacks detailed guidance or suggestions on how to address this issue, leaving the authors with limited actionable steps. The feedback is clear but could be more comprehensive if it provided specific advice or examples on how to resolve the concern. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while it mentions the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions. The comment suggests that the paper should explore why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not specify how the authors should address this issue or what kind of analysis or solutions they should propose. The action is implicit and vague, as it leaves the authors to infer the necessary steps to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the handling of rumors generated by GPT, specifically noting that the paper mentions the challenges of detecting such rumors but lacks further analysis or solutions. It questions why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the issue of the difficulty in detecting GPT-generated rumors compared to natural ones, but without explicit references to sections or figures, the authors may need to infer the part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the difficulty of detecting GPT-generated rumors compared to natural rumors, suggesting that the paper does not provide a clear analysis or explanation for this phenomenon. It implies that the experimental results might be counterintuitive, as artificial rumors, being written by humans, should be as difficult to detect as natural rumors. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the paper does not address this issue. Without additional context or evidence, the authors may find it challenging to fully understand and address the concern raised. Therefore, the comment is considered borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a gap in the paper by pointing out that while it acknowledges the challenges of detecting rumors generated by GPT, it does not provide further analysis or solutions. The comment questions why GPT-generated rumors are as difficult to detect as natural rumors, despite the fact that artificial rumors are also written by humans and should be about the same difficulty. This raises a valid concern that the paper does not address, and it suggests that the authors should explore this issue further. However, the comment lacks specific guidance or suggestions on how to analyze or address this concern, making it somewhat helpful. The feedback is clear and identifies an area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. While the comment identifies a potential issue with the technical contribution, it does not provide explicit guidance on how the authors should address this limitation or what specific aspects of the section need improvement. The action is implicit, as the authors would need to infer that they should consider a more formal and principled approach to enhance the technical contribution. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the technical contribution, noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This provides the authors with a clear understanding of what needs to be addressed to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the technical contribution is limited, specifically noting that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This claim is somewhat verifiable as it provides a specific example of a limitation in the technical contribution, but it lacks detailed reasoning or references to support the claim fully. The authors would need to infer the basis for this claim, which could be improved by providing more context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the technical contribution of the paper, specifically pointing out that the contents of Section 4 are not about a formal and principled solution but rather focus on heuristics. This feedback is clear and actionable, as it highlights a specific area where the authors could enhance the rigor and depth of their work. By emphasizing the need for a more formal and principled approach, the comment provides a clear direction for improvement. However, it could be more helpful if it suggested specific ways to address this limitation or provided examples of how to incorporate a more formal approach. Overall, the comment is mostly helpful, as it offers valuable insights into areas for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a regret about the limited exploration of the probability mass function in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the case of Boosted Decision Trees (BDT) of different depths. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to incorporate different probability mass functions into their experiments. The suggestion is vague and lacks concrete details, making it difficult for the authors to understand how to implement it. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"MixBoost\" and \"probability mass function,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the probability mass function is practically unexploited and suggests considering various distributions to add depth to the experimental setting. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses a regret about the limited exploration of the probability mass function in the paper, specifically mentioning that it is practically unexploited. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the case of Boosted Decision Trees (BDT) of different depths. However, the comment lacks specific examples or references to support the claim that the quasi-uniform distribution is well-suited or why it is the only choice. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by pointing out that the probability mass function is practically unexploited in the paper. It suggests that considering various probability mass functions could add depth to the experimental setting, particularly in the case of Boosted Decision Trees (BDT) of different depths. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work. However, the comment could be more helpful if it offered more detailed guidance on how to implement this suggestion or provided examples of alternative probability mass functions that could be explored. Overall, the comment is mostly helpful, as it offers a clear and constructive suggestion for improvement.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to the comparison. The comment lacks concrete guidance on how to improve the draft or what specific actions the authors should take. As a result, the comment is unactionable, as it does not provide the authors with any direction or steps to follow to improve their work.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not specify which part of the paper this comparison is made or which models are being compared. The lack of specific grounding makes it difficult for the authors to identify the exact section or aspect of the paper that needs attention. Additionally, the comment does not provide any guidance or suggestions on how to address the issue of fairness in the comparison. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. However, it does not provide any specific reasoning, examples, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the concern, making it difficult for the authors to understand the basis of the critique. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparing accuracies when ChatGPT shows a higher percentage of abstention than other models. This is a pertinent issue that could affect the validity of the comparisons made in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to ensure a fair comparison. While it identifies a potential weakness, it lacks actionable advice, making it somewhat helpful. The authors would need to infer how to improve their draft based on this feedback, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the authors should discuss connections with a specific paper, [a], which is relevant to their topic. It provides a clear and concrete action by instructing the authors to include and discuss this reference. The comment is fully actionable as it clearly specifies what needs to be done, making it a 5.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"relevant to your topic\" and provides a specific reference, [a], which is directly related to the topic of supervised learning in QBF solving. It also specifies the need to discuss connections with this paper, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the references below are relevant to the topic and recommends discussing connections with a specific paper, [a]. However, it does not provide any reasoning or justification for why these references are relevant or how they should be discussed. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis for the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out missing references that are relevant to the topic. It suggests discussing connections with a particular paper, [a], which is relevant to the topic of supervised learning in QBF solving. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by including and discussing the suggested reference. However, the comment could be more helpful if it offered additional guidance on how to integrate the discussion of the reference or what aspects of the connection should be explored. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this relationship might be replaced by other relationships and implies that explaining this point would be beneficial. However, the comment does not provide explicit guidance on how the authors should explore or address this issue. The suggestion to explain the point is vague and lacks concrete steps for the authors to take. Therefore, the comment is barely actionable, as it does not offer specific actions or detailed guidance on how to improve the draft.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the training process of a model, specifically questioning the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this relationship might be replaced by other relationships and implies that explaining this point would be beneficial. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to explore alternative relationships, but without clear references to the paper, it is difficult for the authors to pinpoint the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss, suggesting that this relationship might be replaced by other relationships. The comment implies that explaining this point would be beneficial, but it does not provide specific examples or references to support the claim. While the suggestion to explore alternative relationships is logical, the lack of detailed reasoning or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises a question about the necessity of a monotonic relationship between the degree of a single-task predictor participation and the weight of the corresponding task loss. It suggests that this relationship might be replaced by other relationships and implies that explaining this point would be beneficial. However, the comment lacks specific guidance on how the authors might explore or address this issue, making it somewhat helpful. It provides a clear area for improvement but does not offer detailed suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3, as it identifies a potential area for enhancement but could be more comprehensive with additional guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the comparison of computation cost or running time, but it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes could be made to the draft to include such a comparison. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the comparison of computation cost or running time, but it does not specify which part of the paper this comparison is intended for or how it relates to the content of the draft. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific guidance on how to address the comparison or what aspects of the paper need to be revised. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point raises a question about the comparison of computation cost or running time, but it does not provide any specific claims, opinions, or suggestions. It is a factual question that does not require verification or justification. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the comparison of computation cost or running time, which is a relevant aspect for evaluating the efficiency and practicality of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or incorporate such a comparison into their draft. Without specific advice or suggestions, the authors are left without actionable feedback, making the comment unhelpful. Therefore, the comment aligns with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. While it prompts the authors to consider the privacy implications of their approach, it does not provide explicit guidance on how to address these concerns or suggest specific actions to improve the draft. The comment is somewhat vague, as it leaves the authors to infer the need for further discussion and clarification. Therefore, the comment is somewhat actionable, aligning with a score of 3.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. However, it does not specify which part of the paper these questions relate to, making it difficult for the authors to pinpoint the exact section or aspect being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. It is also not specific because it does not detail what needs to be addressed or how the questions should be answered. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. While it prompts the authors to consider the privacy implications of their approach, it does not provide specific evidence or reasoning to support the claim that the approach is more privacy-preserving than others. The questions raised are logical but lack detailed justification or references, making the comment somewhat verifiable. Therefore, it aligns with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises questions about the privacy-preserving nature of the proposed approach compared to other federated learning methods and questions the relevance of privacy preservation in the context of traffic signal control. It suggests that one might think this is a bad example of an application of federated learning, which could provide valuable insights for the authors to consider. However, the comment lacks specific guidance or suggestions on how to address these concerns or improve the draft. While it identifies an area for improvement, it does not provide actionable feedback or detailed reasoning, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the description of the neural network is hard to understand, but it also indicates that the final paragraph of the section clarifies it. The comment implies that the authors should consider starting the section with this clearer explanation. However, the action is implicit, as the authors need to infer that they should start the section with the final paragraph. The action is also somewhat vague, as it does not provide specific guidance on how to integrate the clearer explanation into the beginning of the section. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the section of the paper (line 528), allowing the authors to accurately identify the part being addressed. It is also specific because it provides clear guidance on how to improve the clarity of the description of the neural network by suggesting that the final paragraph of the section should be used as the starting point. This provides a clear direction for the authors to enhance the readability of the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the description of the neural network is hard to understand, suggesting that the final paragraph of the section clarifies it. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the description is unclear. As a result, the claim is not fully verifiable, making the comment somewhat verifiable. The authors would need to infer the basis of the claim, which limits its effectiveness in guiding them to improve the clarity of their description.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the description of the neural network, noting that the final paragraph of the section clarifies it. It provides a clear suggestion for improvement by recommending that the authors consider starting the section with this clearer explanation. This feedback is actionable and constructive, as it directly addresses a potential weakness in the paper's presentation and offers a concrete solution. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate the clearer explanation into the beginning of the section. Overall, the comment is mostly helpful, as it provides valuable feedback that the authors can readily address.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to implement this suggestion or what specific aspects of the model should be addressed. The action is implicit, as the authors would need to infer that they should consider adding attention-based enc-dec training to their model. However, the lack of concrete details or examples makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section or aspect that needs attention. The comment is specific in its suggestion but lacks grounding as it does not provide context or references to the specific sections or parts of the paper that are being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is relevant or beneficial. The comment lacks depth and does not offer a clear justification for the proposed change, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the model's limitation to CTC loss and suggests exploring attention-based enc-dec training. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to implement this exploration or what aspects of the model should be considered. The comment is somewhat helpful as it points out a limitation and suggests a direction for future work, but it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should be included. While the comment implies that the current division might be redundant or unnecessary, it does not provide explicit guidance on how the authors should revise the tables or what specific changes are needed. The action is implicit, as the authors need to infer that they should consider removing or consolidating the division. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable. Therefore, the comment aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Section 3 (line 247-252)\" and the specific issue regarding the division of tables. It clearly specifies what the authors should consider, questioning whether one type (the column header) should work. This provides the authors with a clear understanding of the part of the paper being addressed and the specific issue to address. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should work. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely descriptive and does not offer any new information or reasoning that would help the authors understand or address the issue. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the division of tables in Section 3, specifically questioning whether one type (the column header) should work. While it identifies a potential issue with the organization of the tables, it does not provide any suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, as it does not offer any specific advice or recommendations for improvement. Therefore, it is barely helpful, as it does not provide the authors with any meaningful insights or direction for enhancing their draft. The comment is rated as 2: Barely Helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point criticizes the paper for using only two attack methods, which are considered naive, and suggests that other classical attack methods in NLP could be used. However, it does not provide explicit guidance on which other methods should be considered or how they might improve the paper. The comment implies that the authors should explore additional attack methods, but it lacks concrete suggestions or detailed instructions on how to implement this feedback. As a result, the authors are left without a clear understanding of what specific changes to make, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the paper for using only two attack methods, which are considered naive, and suggests that other classical attack methods in NLP could be used. However, it does not specify which other methods should be considered or provide examples of how they might be relevant. The comment lacks grounding as it does not mention specific sections or parts of the paper that need to be addressed. It is also not specific because it does not detail the reasons for the critique or suggest how the authors might improve their draft. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point critiques the paper for using only two attack methods, which are considered naive, and suggests that other classical attack methods in NLP could be used. However, the comment does not provide specific examples or references to support the claim that the chosen methods are indeed naive or that other methods are more appropriate. The reasoning is somewhat vague, as it lacks detailed justification or examples to substantiate the claim. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some basis for the critique but lacks sufficient detail to fully support the claim.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the paper for using only two attack methods, which are considered naive, and suggests that other classical attack methods in NLP could be used. It provides a rationale by mentioning the use of random token addition and universal adversarial suffixes as the two methods considered. However, the comment does not offer specific examples of other attack methods that could be relevant or explain why the current methods are insufficient. While it identifies a potential area for improvement, it lacks detailed guidance or suggestions on how the authors might address this issue. Therefore, the comment is somewhat helpful, as it provides a direction for improvement but does not fully support the authors in enhancing their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific steps they should take to ensure fair comparisons. The action is implicit and vague, as it does not specify how the authors can mitigate the risk of information leakage or how they should adjust their methodology to ensure fairness. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not specify which part of the paper discusses the incorporation of prior knowledge or the comparisons with existing SSL methods. This lack of grounding makes it difficult for the authors to pinpoint the exact sections that need attention. While the comment is specific in its critique, the absence of explicit references to the paper's sections or content limits its effectiveness. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It suggests that the pretrained visual model and target dataset might leak additional information, potentially skewing results and leading to issues of unfairness. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the incorporation of prior knowledge could lead to unfair comparisons. Without concrete evidence or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis of the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the fairness of comparisons with existing SSL methods due to the incorporation of prior knowledge. It highlights a potential risk that the pretrained visual model and target dataset might leak additional information, skewing results and leading to unfair comparisons. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or ensure fair comparisons. While it identifies a critical area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is rated as barely helpful, as it provides a clear insight but lacks depth and practical guidance for the authors.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses surprise at the dominance of function words over content words in a Japanese sentence, but it does not provide any explicit or implicit suggestions for improvement or clarification. The authors are left without guidance on how to address this observation or what might be causing it. As a result, the comment lacks actionable feedback, making it unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the reviewer is referring to, such as a particular section or figure. It is also not specific because it does not provide details on what is surprising or how the dominance of function words over content words might be addressed. Without explicit references or detailed guidance, the authors cannot confidently understand the basis of the comment or how to respond. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which is followed by a question about the reviewer\\'s understanding. While the observation is based on a subjective interpretation of the content, the comment lacks specific evidence or reasoning to support the claim. The authors are left without a clear understanding of why this observation is surprising or what it implies. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a subjective observation about the dominance of function words over content words in a Japanese sentence, which is followed by a question about the reviewer\\'s understanding. While the comment highlights an interesting aspect of the content, it does not provide specific feedback or suggestions on how this observation might be addressed or improved. The authors are left without actionable guidance on how to respond to this observation or what might be causing it. Therefore, the comment is barely helpful, as it lacks depth and direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that using the minimal k-means objective over multiple seeds as a baseline is more reasonable than the average of k-means objectives with multiple seeds. It provides specific references to support this claim, making it explicit and concrete. The authors know exactly what needs to be changed and how to implement it, as the suggestion is clear and detailed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the average of k-means objectives with multiple seeds should be replaced with the minimal k-means objective over multiple seeds as a baseline. It provides specific references to support this claim, making it fully grounded as it explicitly mentions the part of the paper being addressed. The comment is also specific as it clearly specifies what needs to be addressed, suggesting a change in the baseline used for comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the average of k-means objectives with multiple seeds should be replaced with the minimal k-means objective over multiple seeds as a baseline. It provides specific references to support this claim, such as [1] Jin, Chi, et al. \"Local maxima in the likelihood of gaussian mixture models: Structural results and algorithmic consequences.\" Advances in neural information processing systems 29 (2016): 4116-4124, and [2] Fr\u00e4nti, Pasi, and Sami Sieranoja. \"K-means properties on six clustering benchmark datasets.\" Applied Intelligence 48.12 (2018): 4743-4759. These references provide logical reasoning and evidence to support the claim, making it fully verifiable. Therefore, the comment is rated as 5.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment provides a minor suggestion to improve the baseline used for comparison in the paper. It recommends using the minimal k-means objective over multiple seeds instead of the average of k-means objectives with multiple seeds. The comment also includes references to support the suggestion, providing a clear rationale for why this change might be beneficial. This feedback is actionable and constructive, as it offers a specific and logical improvement that the authors can implement to enhance their work. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a missing reference related to the concept of unrolling, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment does not provide explicit guidance on how to incorporate this discussion or where to add it in the draft. The action is implicit, as the authors need to infer that they should include a discussion of the missing reference and its relevance to their work. The lack of concrete instructions on how to implement this suggestion makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"unrolling\" and provides a link to a specific paper, \"Lista,\" which is relevant to the topic. It also specifies what needs to be addressed by discussing the similarities and differences between the proposed work and Lista, placing the paper in the appropriate context. This provides clear guidance on which part of the paper should be addressed and what specific issues need to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that an important reference is missing, specifically mentioning \"Lista\" and providing a link to the paper. It suggests that the paper should discuss the similarities and differences between the proposed work and Lista, placing it in the appropriate context. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is closely related to the idea of unrolling and that the omission of this reference is significant. Without additional context or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out a missing reference that is closely related to the core idea of unrolling, specifically mentioning \"Lista\" and providing a link to the paper. It highlights the importance of discussing the similarities and differences between the proposed work and Lista to properly contextualize the paper. However, the comment lacks specific guidance on how to integrate this discussion into the draft or where to add it. While it provides a clear direction for improvement, the absence of detailed suggestions or examples makes it somewhat helpful. The authors would benefit from additional guidance on how to effectively incorporate this discussion, making the comment mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the specific definition of the sparsity of the residual term in the paper, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. While the comment explicitly asks for clarification and provides a clear direction for the authors to address the issue, it lacks concrete guidance on how to demonstrate the advantages of the proposed method or how to provide evidence for the sparsity assumption. The action is explicit but somewhat vague, as it does not offer detailed steps or examples for the authors to follow. Therefore, the comment is mostly actionable.', 'actionability_label': '4', 'grounding_specificity_rationale': 'The comment addresses the specific issue of the sparsity of the residual term in the paper, which is a clear and specific concern. It questions the definition of sparsity, asking whether it implies the inclusion of many zero elements, and suggests providing evidence for the sparsity assumption across various noisy cases. Additionally, it recommends comparing the advantages of the proposed method with existing methods. The comment is fully grounded as it explicitly mentions the part of the paper being addressed, and it is specific in detailing what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, corresponding to a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the specific definition of the sparsity of the residual term in the paper, asking whether it implies the inclusion of many zero elements. It also suggests that the authors should provide evidence to support the sparsity assumption across various noisy cases and compare the advantages of their proposed method with existing methods. While the comment raises a valid point about the need for clarification and evidence, it lacks specific examples or references to support the claim that the sparsity assumption is not well-defined or that the proposed method offers advantages over existing ones. The feedback is somewhat verifiable as it identifies an area for improvement but does not provide detailed guidance or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area of concern regarding the definition of the sparsity of the residual term in the paper. It questions whether the term implies the inclusion of many zero elements and suggests that the authors provide evidence to support the sparsity assumption across various noisy cases. Additionally, the comment recommends comparing the advantages of the proposed method with existing methods, which is a valuable suggestion for improving the paper. However, the comment could be more helpful if it provided specific examples or guidance on how to demonstrate the advantages of the proposed method or how to substantiate the sparsity assumption. Overall, the feedback is mostly helpful as it highlights important areas for improvement and encourages the authors to address these concerns, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not use the structural connections between the brain and body. However, the comment does not provide any explicit or implicit actions for the authors to take. It does not specify how the authors should revise the term or what kind of structural connections should be used. Without concrete guidance, the authors are left without a clear path to address the issue. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the term \"connectivity\" and its potential misleading use. It clearly specifies what needs to be addressed, which is the issue with the term \"connectivity'. However, the comment does not provide specific details or examples of how the authors should revise the term or what kind of structural connections should be used. This makes the comment specific in identifying the issue but lacking in detail, resulting in a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the term \"connectivity\" is misleading because it does not use the structural connections between the brain and body. However, the comment lacks specific examples or references to support this claim. Without detailed reasoning or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the term \"connectivity\" in the paper, suggesting that it is misleading because it does not use the structural connections between the brain and body. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or revise the term. Without actionable feedback or detailed examples, the authors may find it difficult to understand the implications of the comment and how to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It also directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which implies that this section contains more detailed feedback. However, the comment does not explicitly instruct the authors to address these issues or provide specific guidance on how to improve the polish or polish the paper. The action is implicit and somewhat vague, as the authors need to infer that they should focus on the missing details and improve the polish. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which provides a clear indication of the areas needing attention. However, the comment does not specify which parts of the paper are missing details or require improvement, making it weakly grounded. The comment is specific in identifying the need for polish and addressing missing details, but the lack of explicit references to specific sections or elements makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is not polished and lacks polish, noting missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which implies that this section contains more detailed feedback. However, the comment lacks specific examples or references to support the claim about missing details or areas needing improvement. Without detailed examples or references, the claim is somewhat verifiable, as the authors may need to infer the specific issues that need to be addressed. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, noting that it is not polished and lacks polish, with missing details in related work, experiments, and writing. It directs the authors to a specific section labeled \"Clarity, Quality, Novelty And Reproducibility,\" which suggests that this section contains more detailed feedback. However, the comment does not provide specific examples or actionable suggestions for improvement, such as what aspects of the related work, experiments, or writing need to be expanded or clarified. While it highlights the need for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out areas for enhancement but does not offer comprehensive feedback. The score is consistent with the label 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the methodology, suggesting that the authors should study the importance of orthogonal matrix weights in their model. It implies that the current approach might be unnecessary and that a deeper analysis of the necessity of orthogonal matrices is needed. However, the comment does not provide explicit guidance on how to conduct this study or what specific aspects of the model should be examined. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the methodology of the paper, specifically mentioning the use of orthogonal matrix weights and the potential redundancy of steps 2 and 3. It suggests that the authors should study the importance of orthogonal matrix weights, implying that the current approach might be unnecessary. However, the comment does not specify which part of the paper this issue pertains to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine the exact area of concern. The comment is specific in its suggestion to study the importance of orthogonal matrix weights, but without clear grounding, it is difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a claim about the potential redundancy of steps 2 and 3 in the methodology, suggesting that the importance of orthogonal matrix weights might be overstated. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or logical arguments to substantiate the assertion that the current approach might be unnecessary. Without concrete evidence or justification, the claim is difficult for the authors to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential issue with the methodology, specifically suggesting that steps 2 and 3 might be redundant and that the importance of orthogonal matrix weights could be overstated. It implies that the authors should study the necessity of orthogonal matrix weights to validate their use. However, the comment lacks specific guidance on how to conduct this study or what aspects of the model should be examined. While it points out a potential area for improvement, the feedback is somewhat vague and could be more helpful if it provided more detailed suggestions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises concerns about the toy-like nature of the models and datasets used in the paper, suggesting that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small should be considered. It also questions the feasibility of experimenting on language tasks. While the comment implies that the authors should address these issues, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises concerns about the models and datasets used in the paper, suggesting that they are too toy-like. It specifically mentions CIFAR100, ResNet 34 or 50, and ViT-tiny or small as examples of more challenging datasets. However, the comment does not specify which part of the paper discusses the models and datasets, making it weakly grounded. The specificity of the comment is moderate as it clearly identifies the issue with the models and datasets but does not provide detailed guidance on how to address it. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the models and datasets used in the paper, suggesting that they are too toy-like and that more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small should be considered. However, the comment does not provide specific reasoning or examples to support why these datasets are necessary or how they would improve the paper. Without detailed justification or references, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out that the models and datasets used are too simplistic, specifically mentioning the need for more challenging datasets like CIFAR100, ResNet 34 or 50, and ViT-tiny or small. It also raises questions about the feasibility of experimenting on language tasks, which could be a valuable point for discussion. However, the comment lacks actionable guidance on how the authors might address these issues or what specific experiments could be conducted to improve the paper. While it provides a clear direction for improvement, the feedback is somewhat limited in its depth and specificity, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of natural ablation studies, specifically mentioning the importance of including a baseline where scratchGAN is pretrained. It suggests that this is crucial for supporting the central argument against pretraining. However, the comment does not provide explicit guidance on how to conduct these ablations or what specific results should be included. The action is implicit and somewhat vague, as the authors are left to infer the need for additional experiments and the specific details of these experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"natural ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the need for a baseline where scratchGAN is pretrained, providing clear guidance on what needs to be addressed. However, the comment lacks specificity in terms of which sections or parts of the paper should include these ablations. While it identifies the need for additional experiments, it does not specify which sections or figures should be revised or expanded. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that some natural ablation studies are missing, specifically mentioning the importance of including a baseline where scratchGAN is pretrained. This claim is somewhat verifiable as it highlights a specific area where additional experiments could strengthen the paper. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the need for these additional experiments and the specific results to be included, which could be improved with more detailed justification or references.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by pointing out the absence of natural ablation studies, particularly the importance of including a baseline where scratchGAN is pretrained. This is a crucial aspect for supporting the central argument against pretraining. However, the comment lacks depth and specificity, as it does not provide detailed guidance on how to conduct these ablations or what specific results should be included. While it highlights an important point, the feedback could be more helpful if it offered concrete suggestions or examples of how to address this issue. Therefore, the comment is somewhat helpful, as it provides a clear direction but lacks the depth needed for comprehensive improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant gap in the paper by noting the absence of a comparison against baselines. It points out that the functionality similarity comparison study only reports accuracy across optimization levels of binaries, without considering any baselines. The comment suggests that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting specific baselines to include or how to conduct a more comprehensive comparison. While the action is implied, it is vague and lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"no comparison against baselines\" and \"functionality similarity comparison study,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of the lack of comparison against baselines and suggests that the study only reports accuracy across optimization levels of binaries without considering baselines. The comment further provides context by mentioning that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch, which are similar tasks. This level of detail helps the authors understand what needs to be addressed and how to improve the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks a comparison against baselines, specifically noting that the functionality similarity comparison study only reports accuracy across optimization levels of binaries without considering baselines. The comment suggests that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch, which are similar tasks. However, the comment does not provide specific examples or references to support the claim that the paper is widely-understood and lacks such comparisons. This lack of detailed evidence makes the claim somewhat verifiable, as the authors may need to infer the basis of the claim or seek additional context to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out the absence of a comparison against baselines in the functionality similarity comparison study. It highlights that the study only reports accuracy across optimization levels of binaries without considering baselines, which is a common practice in many papers. The comment suggests that many papers have developed architecture-agnostic similarity comparison or reported it as codesearch, which are similar tasks. This feedback is valuable as it directs the authors to include a more comprehensive comparison, potentially enhancing the depth and relevance of their work. However, the comment could be more helpful if it provided specific examples of baselines or suggested how the authors might conduct a more thorough comparison. Overall, the comment is mostly helpful as it identifies a crucial area for improvement and offers a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention a specific detail in Section SI 6.5 regarding the evaluation process, noting that it differs from the evaluation in Mnih et al. [7] due to the absence of human starts. This comment provides an explicit action for the authors to take, which is to include this detail in their manuscript. The action is concrete as it specifies exactly what needs to be added, making it highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"SI 6.5,\" allowing the authors to accurately identify the section being addressed. It is also specific because it clearly specifies what needs to be mentioned in that section, namely the difference in evaluation due to the absence of human starts. This provides the authors with clear guidance on what to include, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors should mention a specific detail in Section SI 6.5 regarding the evaluation process, noting that it differs from the evaluation in Mnih et al. [7] due to the absence of human starts. This claim is somewhat verifiable as it provides a clear reason for the authors to include this detail, but it lacks specific examples or references to support the claim fully. The authors would benefit from additional context or examples to strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific and actionable suggestion for the authors to include in Section SI 6.5. It highlights a detail that is important for the evaluation process, noting that the evaluation differs from that in Mnih et al. [7] due to the absence of human starts. This feedback is clear and directly addresses a specific aspect of the manuscript, offering a concrete improvement that the authors can easily implement. The comment is mostly helpful as it provides a clear direction for enhancing the draft, but it could be more comprehensive if it suggested additional areas for improvement or elaborated on the implications of this change. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a gap in the paper by noting that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. The comment implies that the authors should include such metrics to substantiate their claims of efficiency. However, the action is implicit, as the authors need to infer that they should report metrics to demonstrate efficiency. The action is also somewhat vague, as it does not specify which metrics should be reported or how they should be presented. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the authors discuss the advantages of their proposed method over previous work in terms of efficiency. This allows the authors to accurately identify the section being addressed. The comment is also specific because it points out a lack of reporting of metrics that would demonstrate the efficiency of the proposed method. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper does not report any metric that shows the proposed method is more efficient to train compared to previous work. However, the comment lacks specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant gap in the paper by pointing out that while the authors discuss the advantages of their proposed method in terms of efficiency, they do not provide any specific metrics to support this claim. This feedback is valuable as it highlights a critical area where the paper lacks substantiation. By requesting the inclusion of metrics, the comment directs the authors to a specific action that would strengthen the paper\\'s claims of efficiency. However, the comment could be more helpful if it provided examples of metrics that could be used or suggested ways to present the results. Overall, the comment is mostly helpful as it identifies a clear area for improvement and encourages the authors to address it.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern that the contribution of the paper is not enough, specifically mentioning that it addresses the overfitting problem of training GANs with limited data and proposes differentiable augmentation. However, the comment does not provide any explicit or implicit suggestions on how the authors might improve their draft to address this concern. It lacks concrete guidance on what specific aspects of the contribution could be expanded or enhanced. Without actionable advice, the authors are left without a clear path to improve their work. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the contribution of the paper, which is the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. This allows the authors to accurately identify the part of the paper being addressed. However, the comment is not specific because it does not provide detailed guidance on how the authors might improve their draft to address the concern about the contribution being limited. It lacks specific suggestions or examples of how the authors could enhance their work. Therefore, the comment is fully grounded but under-specific, aligning with category 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point claims that the contribution of the paper is not enough, specifically mentioning the overfitting problem of training GANs with limited data and the proposed differentiable augmentation. However, the comment lacks specific evidence or reasoning to support this claim. It does not provide examples, references, or detailed explanations of why the contribution is limited. Without this additional information, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper, specifically the limited contribution of addressing the overfitting problem of training GANs with limited data and proposing differentiable augmentation. While the comment highlights an important factor, it lacks depth and actionable suggestions for improvement. It does not provide specific guidance on how the authors might enhance their contribution or address the identified limitation. As a result, the feedback is somewhat helpful, as it points out an area for improvement but does not offer comprehensive or detailed advice. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point requests the authors to provide more details about the state-space, actions, and the space of theta. While the authors can infer that they need to clarify these aspects, the comment does not explicitly instruct them to do so. The request for more details is clear, but the action of providing these details is implicit, making the comment somewhat actionable. The lack of explicit instructions or guidance on how to provide the additional details makes it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions a specific part of the paper, L81, allowing the authors to accurately identify the section being addressed. It is also specific because it requests detailed information about the state-space, actions, and the space of theta, which are crucial elements of the paper. The request for clarification and precision is clear and directly addresses the need for more detailed explanations in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point requests more details about specific aspects of the paper, such as the state-space, actions, and the space of theta. While the request is clear and specific, it does not contain any subjective opinions or claims that require verification. The comment is factual and descriptive, aligning with the classification of \"No Claim.\"', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment is mostly helpful as it identifies specific areas where the authors could provide more details, such as the nature of the state-space, actions, and the space of theta. By requesting these details, the comment encourages the authors to clarify and enhance the clarity of their paper. However, the comment could be more helpful if it provided additional guidance on how to present these details or suggested specific ways to improve the clarity of the paper. Overall, the feedback is clear and actionable, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. The authors acknowledge this in Section 3, where they mention the inapplicability of Theorem 1 due to normalization. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes might be necessary to the proof technique. While the authors are informed about the problem, they are left without a clear path to resolve it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"W2.3. Proof Technique\" and \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the reliance on a special case where a contradiction arises as matrix norms approach infinity. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof technique relies on a special case where a contradiction arises as matrix norms approach infinity, which is acknowledged in Section 3. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it somewhat verifiable. The authors are informed about the issue but are not given a clear path to address it, which limits the comment's helpfulness. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the proof technique, noting that it relies on a special case where a contradiction arises as matrix norms approach infinity. This is acknowledged in Section 3, where the authors mention the inapplicability of Theorem 1 due to normalization. While the comment highlights a potential weakness in the proof, it does not provide specific guidance or suggestions on how the authors might address this issue or improve the proof technique. The feedback is somewhat helpful as it points out a critical area for improvement, but it lacks actionable advice, making it a 3: Somewhat Helpful comment.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, particularly for benchmarks using IoU-based metrics like KITTI and Waymo. It also critiques colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment does not provide explicit guidance on how the authors should implement these suggestions or what specific changes need to be made to their draft. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the authors should consider using LiDAR-based segmentation as the downstream task instead of object detection, particularly for benchmarks using IoU-based metrics like KITTI and Waymo. It also critiques colorization-based pre-training for learning semantics, arguing that object detection requires accurate locations and poses. However, the comment does not specify which part of the paper discusses the choice of downstream tasks or the evaluation metrics used, making it difficult for the authors to pinpoint the exact areas that need revision. While the comment provides some specificity regarding the choice of tasks and metrics, it lacks grounding as it does not explicitly mention sections or figures in the paper. Therefore, this comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the choice of object detection as the downstream task, suggesting that LiDAR-based segmentation might be a better choice, especially for benchmarks using IoU-based metrics like KITTI and Waymo. It also questions the effectiveness of colorization-based pre-training in learning semantics, arguing that object detection requires accurate locations and poses. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the reasoning behind the critique. The feedback is somewhat verifiable as it provides a general rationale but lacks detailed evidence or references to substantiate the claims. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques the choice of object detection as the downstream task, suggesting that LiDAR-based segmentation might be a more suitable alternative, particularly for benchmarks using IoU-based metrics like KITTI and Waymo. It also questions the effectiveness of colorization-based pre-training in learning semantics, arguing that object detection requires accurate locations and poses. While the comment identifies potential areas for improvement and offers a rationale for considering alternative tasks, it lacks specific guidance on how the authors might implement these suggestions or what changes would be necessary to their draft. The feedback is somewhat helpful as it provides insights into potential improvements but does not offer detailed actionable advice. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential contradiction between the objective of Eq (12) and the IPO (Iterative Proportional Fitting) method. However, it does not provide explicit guidance on how the authors should address this contradiction or what specific changes might be necessary. The comment lacks concrete instructions or suggestions, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making it difficult for the authors to apply the feedback effectively. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment mentions \"Eq (12)\" and \"IPO,\" which provides some grounding as the authors can infer that the reference is to a specific equation and method in the paper. However, the comment does not specify what aspect of Eq (12) is in contradiction with IPO, making it weakly grounded. The comment is specific in identifying a potential issue with the objective of Eq (12) in relation to IPO, but it lacks detailed guidance on how to address this contradiction. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the objective of Eq (12) is in contradiction with IPO. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without further explanation or evidence, the authors are left to question the validity of the claim, making it difficult to address effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential contradiction between the objective of Eq (12) and the IPO method, which is a specific area of concern for the authors. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue. Without actionable advice or examples, the authors may struggle to understand the nature of the contradiction and how to resolve it. Therefore, the comment is barely helpful, as it offers limited insight and lacks practical assistance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It suggests that the image encoder may struggle to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve their draft. The action is implicit, as the authors would need to infer that they should consider the limitations of the image encoder in handling semantic concepts and potentially explore alternative approaches or provide more detailed explanations. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment addresses the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, specifically questioning whether the image encoder can produce meaningful embeddings for new concepts. It mentions that DINO representations are observed to contain rich geometric information, which is less of a concern for geometrically distinctive concepts. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in questioning the adaptation capacity for concepts where class labels correlate more with semantics rather than geometry, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the adaptation capacity of the proposed visual memory to accommodate ever-growing concepts, particularly when class labels correlate more with semantics than geometry. It questions whether the image encoder can produce meaningful embeddings for new concepts in such cases, especially considering the effectiveness of DINO representations for geometrically distinctive concepts. However, the comment does not provide any specific examples, reasoning, or references to support the claim that the adaptation capacity might be an issue. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the concern and how to address it. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a pertinent question about the adaptation capacity of the proposed visual memory, particularly concerning its ability to handle concepts where class labels correlate more with semantics than geometry. It highlights a potential limitation in the image encoder's ability to produce meaningful embeddings for new concepts in such cases. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for concern, it lacks actionable advice, making it somewhat helpful. The authors would need to infer that they should consider the limitations of the image encoder and potentially explore alternative approaches or provide more detailed explanations to address the concern. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This provides a clear and explicit action for the authors to take, as they need to add this comparison to their draft. The suggestion is concrete, as it specifies which loss functions to include and provides examples, making it easy for the authors to understand and implement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests adding a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. However, it does not specify which part of the paper this comparison should be made or which sections or figures would benefit from this addition. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, while the suggestion is specific in terms of the loss functions to include, the lack of grounding makes it difficult for the authors to understand where to apply the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This claim is somewhat verifiable as it provides specific examples of loss functions that could be included, offering a clear direction for the authors to enhance their work. However, it lacks detailed reasoning or references to support the suggestion comprehensively, which could make it partially verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should include a comparison against state-of-the-art loss functions used in face/iris verification, such as Center-Loss, A-Softmax, AM-Softmax, and ArcFace. This feedback is specific and actionable, as it provides clear examples of loss functions that could enhance the paper's contribution. By adding this comparison, the authors can strengthen their work and provide a more comprehensive evaluation of their approach. However, the comment could be more helpful if it included additional guidance on how to conduct this comparison or why these specific loss functions are relevant. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the intent of Section 5.2, but it does not provide any explicit or implicit guidance on what the authors should do to address this question. The comment lacks specificity and does not offer any suggestions or actions for the authors to take. As a result, the authors are left without any direction on how to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is being addressed, making it difficult for the authors to identify the section or figure being referred to. Additionally, the comment is not specific because it does not provide any details on what is intended or how it should be addressed. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the intent of Section 5.2 but does not provide any claim, suggestion, or critique that requires verification. It is a factual question that does not offer any guidance or reasoning to support the authors in understanding or addressing the issue. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the intent of Section 5.2, which could be helpful for the authors to clarify the purpose and scope of the section. However, it does not provide any specific suggestions or guidance on how to address this question or improve the section. The comment lacks actionable feedback, making it somewhat helpful as it identifies an area for improvement but does not offer detailed assistance. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. It also recommends including this information in a dedicated section to enhance clarity. The comment provides a clear and explicit action for the authors to take, which is to define the threat model more explicitly and include it in a dedicated section. This action is concrete, as it specifies exactly what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. It also recommends including this information in a dedicated section to enhance clarity. However, the comment does not specify which part of the paper discusses the threat model, making it weakly grounded. While it provides specific guidance on what needs to be addressed, the lack of explicit mention of the section or part of the paper makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the threat model needs further clarification and proposes defining it more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. It recommends including this information in a dedicated section to enhance clarity. However, the comment lacks specific examples or references to support the claim that the threat model is unclear or needs clarification. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides a general direction but lacks detailed justification or examples.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, namely the clarity of the threat model. It suggests that the authors should define the threat model more explicitly by specifying the attacker\u2019s level of access, capabilities, and the defender's available resources. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and comprehensiveness of their work. By including this information in a dedicated section, the authors can improve the overall understanding and coherence of the paper. Therefore, the comment is highly helpful, as it offers specific and actionable guidance for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the chat-GPT baseline is rudimentary and that few-shot approaches should be tested. It also recommends including discourse relation information in the prompts, possibly using a Chain-of-Thought style, to potentially improve the results. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific changes should be made to the draft. The action is implicit, as the authors would need to infer that they should test few-shot approaches and consider adding discourse relation information to the prompts. While the suggestion is somewhat actionable, it lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the chat-GPT baseline, noting that it is rudimentary and that few-shot approaches are not tested. It also suggests including discourse relation information in the prompts, potentially using a Chain-of-Thought style, to improve results. However, the comment does not specify which part of the paper discusses the baseline or the prompts, making it weakly grounded. It is specific in detailing what needs to be addressed, such as testing few-shot approaches and incorporating discourse relation information. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the chat-GPT baseline is rudimentary and that few-shot approaches are not tested. It suggests that including discourse relation information in the prompts, possibly using a Chain-of-Thought style, might yield good results. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the claim is not fully verifiable without additional context or evidence. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a weakness in the paper by pointing out that the chat-GPT baseline is rudimentary and that few-shot approaches are not tested. It suggests that including discourse relation information in the prompts, possibly using a Chain-of-Thought style, could potentially improve the results. However, the comment does not provide specific guidance on how to implement these suggestions or what changes should be made to the draft. While it offers some insight into potential improvements, the feedback lacks depth and actionable advice, making it somewhat helpful. The authors would need to infer that they should test few-shot approaches and consider adding discourse relation information to the prompts, which limits the comment's helpfulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly suggests that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10), ideally with error-bars. It also points out that the plotted curves are from single runs, which might be subject to significant fluctuations, and that the models are small, making it an excuse for not providing statistics. The comment provides clear guidance on how the authors should present their results, including specific actions such as calculating means over multiple runs and including error bars. This explicit and detailed feedback allows the authors to directly address the issue and improve their presentation of the results. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the results comparing standard- vs. evolutional dropout on shallow models, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on how the results should be presented, including the need to present them as a mean over many runs (at least 10) with error bars, and highlights the issue with the plotted curves being from single runs. This detailed feedback helps the authors understand exactly what needs to be addressed and how to improve their presentation. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the results comparing standard- vs. evolutional dropout on shallow models should be presented as a mean over many runs (at least 10) with error bars. This claim is somewhat verifiable as it provides a clear suggestion for improving the presentation of results, but it lacks specific examples or references to support the claim. The authors are encouraged to consider the potential impact of single-run fluctuations on the interpretation of the results, which is a reasonable point. However, the comment could be more robust with additional evidence or references to support the claim. Therefore, it is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides specific feedback on the presentation of results, suggesting that the comparison between standard and evolutional dropout on shallow models should be presented as a mean over many runs with error bars. This is a clear and actionable suggestion that addresses a potential issue with the interpretation of the results due to single-run fluctuations. By providing guidance on how to present the data more robustly, the comment helps the authors improve the clarity and reliability of their findings. However, the comment could be more helpful if it included additional suggestions or considerations for the analysis of the results. Overall, the feedback is mostly helpful as it offers a clear direction for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should provide more detail about the experimental environment, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. While the comment explicitly suggests what information should be included, it does not provide specific guidance on how to describe the environment or what aspects to focus on. The action is clear and explicit, but it lacks concrete details on how to implement the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also highlights that different versions of the environment can impact training and inference speeds. However, the comment does not specify which part of the paper this issue pertains to, making it weakly grounded. While it provides some specificity by mentioning the versions and their potential impact, it lacks detailed guidance on what aspects of the environment need to be described. Therefore, the comment is weakly grounded and somewhat specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors need to describe the experimental environment in more detail, specifically mentioning the CUDA and PyTorch versions. It also notes that different versions of the environment can affect training and inference speeds. However, the comment does not provide any specific examples, references, or detailed reasoning to support why this information is necessary or how it impacts the results. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by suggesting that the authors should provide more detail about the experimental environment, including the CUDA and PyTorch versions. It also highlights the importance of this information in understanding the impact on training and inference speeds. While the comment is clear and identifies a specific area for improvement, it lacks detailed guidance on how to describe the environment or what aspects to focus on. The feedback is somewhat helpful as it directs the authors to a crucial aspect of their experimental setup that could affect the reproducibility and interpretability of their results. However, it could be more helpful with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should mention the evaluation metric used in the paper to improve clarity and understanding of the results. It provides a specific example of where this information is missing, namely lines 078-079 and line 08. However, the comment does not explicitly instruct the authors on how to incorporate this information or what specific metric should be mentioned. While the action is implied, it is vague and lacks concrete guidance on how to implement it. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines of the paper (078-079 and line 08), allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the inclusion of the evaluation metric for clarity and comparability. This provides clear guidance on how to improve the paper, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the evaluation metric should be mentioned for clarity and comparability, providing a specific example of where this information is missing. However, the comment lacks detailed reasoning or examples to fully support the claim. It does not provide specific references or logical reasoning to justify why mentioning the evaluation metric is crucial for understanding the results. As a result, the claim is somewhat verifiable, as it is partially supported but lacks depth and clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement in the paper by suggesting that the evaluation metric should be mentioned for clarity and comparability. It provides a clear example of where this information is missing, specifically in lines 078-079 and line 08. By highlighting the importance of including the evaluation metric, the comment offers a concrete suggestion that could enhance the understanding and comparability of the results reported in the paper. However, the comment could be more helpful if it provided additional guidance on how to choose the appropriate metric or why it is important to include it. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a clear rationale for the suggestion.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide explicit guidance on how to address this concern or what specific actions the authors should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to resolve the issue or enhance the applicability of the approach. As a result, the authors are left without a clear understanding of how to proceed, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a concern about the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not specify which part of the paper this issue pertains to, such as a specific section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its critique of the bounds, the absence of explicit grounding makes it challenging for the authors to understand where to focus their attention. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the bounds of a certain approach have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the reviewer's assertion remains unsubstantiated, making the comment unverifiable. The authors are left without a basis to understand or address the issue raised, as there is no clear reasoning or evidence provided to support the claim.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the bounds of a certain approach, noting that they have o(1) terms and improve over previous results for arbitrarily long inputs. However, it does not provide any suggestions or guidance on how to address this issue or enhance the applicability of the approach. The comment lacks actionable advice, leaving the authors without a clear path to improvement. As a result, the feedback is not particularly helpful, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion or clarify the distinction in their draft. The action is implicit, as the authors would need to infer that they should clarify the distinction in the introduction or methodology sections. However, the lack of specific guidance on how to clarify the distinction makes the action vague and somewhat challenging to implement. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment expresses confusion about whether the paper targets single-token or multi-token cloze queries, noting that this distinction is not clear until reading the conclusion. However, it does not specify which part of the paper this confusion pertains to, making it difficult for the authors to pinpoint the exact section that needs clarification. The comment is specific in its critique of the clarity of the distinction, but it lacks grounding as it does not provide explicit references to sections or figures. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point expresses confusion about whether the paper targets single-token or multi-token cloze queries, noting that this distinction is not clear until reading the conclusion. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the confusion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment highlights a potential confusion regarding whether the paper targets single-token or multi-token cloze queries, noting that this distinction is not clear until the conclusion. While the comment identifies a specific area of confusion, it lacks actionable guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it points out a potential area for clarification, but it does not provide detailed advice or examples to help the authors improve their draft. Therefore, the comment aligns with a score of 3, as it offers some insight but lacks depth and actionable suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity regarding the major contributions of the paper and criticizes the approach of analyzing previous work as a contribution. However, it does not provide explicit or implicit actions for the authors to take to address this issue. The comment suggests that the authors should clarify their contributions, but it does not offer specific guidance on how to do so. Without concrete suggestions or steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper is unclear regarding its major contributions or critique the approach of analyzing previous work as a contribution. The authors cannot confidently determine which section or aspect of the paper is being addressed. Additionally, the comment is not specific because it does not provide detailed guidance on how to clarify the contributions or critique the approach. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that it is unclear what the major contributions of the paper are and criticizes the approach of analyzing previous work as a contribution. However, the comment does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically the lack of clarity regarding the major contributions. It also critiques the approach of analyzing previous work as a contribution, which is a valuable point for the authors to consider. However, the comment lacks actionable suggestions or detailed guidance on how the authors might address these issues. While it highlights important areas for improvement, it does not provide specific steps or examples for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. It implies that the authors should consider this extension, but it does not explicitly instruct them to do so or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should extend the feature and understand the implications of such an extension. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section or context. The comment is specific in its suggestion but lacks grounding as it does not provide clear references or context within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests extending the protected feature A to a vector form, providing an example of how this could be done. However, it does not offer any justification or reasoning for why this extension is necessary or beneficial. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests extending the protected feature A to a vector form, providing an example of how this could be done. This feedback is specific and actionable, as it offers a clear direction for the authors to consider in their work. However, it lacks depth and does not provide detailed reasoning or guidance on why this extension is necessary or beneficial. While it offers a starting point for improvement, the comment could be more helpful if it included additional context or elaborated on the implications of such an extension. Therefore, the comment is mostly helpful, aligning with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might improve the technical contribution or what specific aspects need to be revised. Without concrete suggestions or actionable steps, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, it does not specify which part of the paper this comparison is made or where the similarity is discussed. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in identifying a potential issue with the technical contribution, but it lacks detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the technical contribution of the paper is limited because $kNN-ECD$ is very similar to $kNN-MT$. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand why the technical contribution is limited or how to address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential limitation in the technical contribution of the paper, suggesting that the similarity between $kNN-ECD$ and $kNN-MT$ might limit the novelty of the work. However, the comment lacks specific details or actionable suggestions on how the authors might address this issue or enhance their contribution. Without further guidance or examples, the authors may struggle to understand the implications of this feedback or how to improve their draft. Therefore, the comment is barely helpful, as it provides a general observation but lacks depth and actionable advice.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. While it provides a clear action\u2014adding an example and a figure\u2014it does not specify where these should be placed or how they should be designed. The action is explicit but lacks concrete details, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not specify which part of the paper this explanation is intended for, making it weakly grounded. The comment is specific in its suggestion to include an example and a figure, but without clear references to the relevant sections, the authors may find it challenging to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the paper. Without additional context or justification, the claim lacks verifiability, making it difficult for the authors to understand the basis for the suggestion. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment suggests that an example and a figure would be helpful in explaining the definition of uniform shattering. While it provides a clear direction for improvement by recommending the inclusion of an example and a figure, it lacks specificity regarding where these elements should be placed or how they should be designed. The feedback is somewhat helpful as it identifies a potential area for enhancement, but it does not offer detailed guidance or suggestions for implementation. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the novelty of their method or what specific aspects need to be revised. Without actionable suggestions or guidance, the authors are left without a clear path forward to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, it does not specify which part of the paper this concern relates to, such as a particular section, table, or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not provide specific details about what aspects of the method need to be revised or improved to enhance its novelty. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. However, the comment lacks specific evidence or references to support this claim. It does not provide detailed reasoning or examples to substantiate the assertion that the method is not novel. Without clear justification or supporting evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses a concern about the novelty of the proposed transductive method, suggesting it is similar to a common approach in semi-supervised learning, specifically self-training methods. While the comment identifies a potential issue with the novelty of the method, it does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their approach. The feedback is somewhat helpful as it highlights a potential area for improvement, but it lacks actionable advice or detailed suggestions, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the assumption among classes is not practical and suggests that the formulation or definition in the manuscript is somewhat trivial. It highlights the importance of optimization and theoretical property analysis, indicating that some conclusions or insights can be gained. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to make the assumption more practical or to enhance the manuscript. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment critiques the assumption among classes, suggesting it is not practical. However, it does not specify which part of the manuscript discusses this assumption, making it difficult for the authors to identify the exact section or content being addressed. The comment is specific in its critique of the assumption but lacks grounding as it does not provide explicit references or sections. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the assumption among classes, suggesting it is not practical. However, it does not provide specific examples, reasoning, or references to support this claim. The comment lacks detailed justification or evidence to substantiate the assertion that the assumption is not practice. Without additional context or examples, the claim remains somewhat verifiable, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the assumption among classes, suggesting that it is not practical. It also notes that the formulation or definition in the manuscript is somewhat trivial, but highlights the importance of optimization and theoretical property analysis, which can lead to some conclusions or insights. While the comment points out a specific area for improvement, it lacks detailed guidance on how the authors might address the issue or what specific changes could be made to enhance the manuscript. The feedback is somewhat helpful as it directs the authors to consider the practicality of their assumptions and the potential for further analysis, but it could be more actionable with additional suggestions. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of the multi-view clustering approach, specifically questioning why other views are useful if the paraphrase similarity view performs significantly better. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform a detailed analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It highlights the lack of detailed analysis regarding the differences and similarities between the views, noting that only one empirical example is provided. However, the comment does not specify which part of the paper discusses the multi-view clustering approach or the views themselves, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it difficult for the authors to pinpoint the exact sections to focus on. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It suggests that the authors should provide a more detailed analysis of the differences and similarities between the views to draw solid conclusions. However, the comment lacks specific examples or references to support the claim that the other views are not useful. It does not provide a clear rationale or evidence to justify the need for a more detailed analysis. Therefore, the claim is not verifiable, as it lacks sufficient support or justification.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a valid concern about the effectiveness of the multi-view clustering approach, specifically questioning the usefulness of other views given the superior performance of the paraphrase similarity view. It points out that while the paraphrase similarity view performs significantly better, the authors do not provide a detailed analysis of how the different views differ or how they contribute to the clustering task. The comment suggests that the authors should include a more comprehensive analysis to draw solid conclusions about the usefulness of the different views. This feedback is somewhat helpful as it identifies a gap in the analysis and provides a direction for improvement, but it could be more actionable with additional guidance on how to conduct the analysis. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment does not explicitly instruct the authors to provide these results or specify how to do so, leaving the action somewhat vague. The authors can infer that they need to provide more detailed results, but the lack of concrete guidance makes the action somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment does not explicitly mention which part of the paper this issue is related to, such as specific sections or figures. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of model size affecting performance, it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment lacks specific examples or detailed reasoning to substantiate the claim, making it difficult for the authors to understand the basis of the critique. The absence of clear evidence or references makes the claim somewhat verifiable, as it relies on the authors' interpretation and the provided reference. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a valid concern about the rationale behind the model size increase affecting performance, referencing a recent paper that suggests scaling laws apply to dense retrieval models. It implies that the authors should provide more detailed preliminary experimental results on Wikipedia to support their claims. However, the comment lacks specific guidance on how to address this issue or what additional experiments might be necessary. While it identifies a potential area for improvement, it does not offer detailed suggestions or actionable steps for the authors to take, making it somewhat helpful. The feedback is clear but could be more comprehensive to fully assist the authors in enhancing their draft.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper uses analysis to justify the use of the information axis as a tool. It also points out that the conclusion mentions the need for related experiments to demonstrate the tool's effectiveness. However, the comment does not provide explicit guidance on how the authors should conduct these experiments or what specific aspects of the information axis tool need to be explored. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper uses much analysis to justify the use of the information axis as a tool. It also mentions that the conclusion points out the need for related experiments to demonstrate the tool's effectiveness. However, the comment does not specify which part of the paper this analysis or justification is located in, making it difficult for the authors to pinpoint the exact section being addressed. Additionally, while the comment implies the need for related experiments, it does not provide specific guidance on what those experiments should entail or how they should be conducted. This lack of specificity and grounding makes the comment weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests that the paper uses much analysis to justify the use of the information axis as a tool. It also mentions that the conclusion points out the need for related experiments to demonstrate the tool's effectiveness. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the criticism. Without clear reasoning or references, the claim remains somewhat verifiable, as it is based on an inference rather than a direct assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement by suggesting that the paper could benefit from additional experiments to demonstrate the effectiveness of the information axis tool. It points out that the conclusion mentions the need for related experiments, which implies that the current analysis might not be sufficient to fully justify the use of the tool. However, the comment lacks specific guidance on what kind of experiments would be beneficial or how the authors should approach them. While it highlights a potential gap in the paper, it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity. The authors would need to infer the necessary steps to address the feedback effectively.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what steps they should consider. Without specific suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it does not provide explicit references or guidance on where to find the relevant information. Additionally, it lacks specificity as it does not detail what the authors should do to address this question or what evidence they should provide. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The comment expresses interest in knowing if other multilingual pretraining setups also struggle with Greek. However, it does not provide any specific feedback, suggestions, or guidance on how the authors might address this question or what steps they should consider. The comment lacks actionable insights and does not offer any constructive feedback that could help the authors improve their work. Therefore, it is barely helpful, as it does not provide any meaningful direction for the authors to follow.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the text in lines 293-295 is unclear and difficult for readers to understand and evaluate. It suggests that the authors should clarify this section by providing more context or explanation. However, the comment does not specify how the authors should clarify the text or what specific aspects need to be addressed. The action is implicit and vague, as it requires the authors to infer the need for clarification and then decide how to implement it. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the text in lines 293-295, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that the text is unclear and difficult for readers to understand and evaluate, suggesting that the authors should clarify the section by providing more context or explanation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the text in lines 293-295 is unclear and difficult for readers to understand and evaluate. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why the text is unclear or how to improve its clarity. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the text in lines 293-295, noting that it is difficult for readers to understand and evaluate. This feedback is clear and actionable, as it directs the authors to clarify the text by providing more context or explanation. However, the comment could be more helpful if it suggested specific ways to improve the clarity, such as by adding examples or rephrasing the sentence. Overall, the comment is somewhat helpful as it highlights a need for improvement but lacks detailed guidance on how to achieve it. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment highlights a significant issue with the organization and clarity of the proofs in the paper, noting that many proofs lack clean logic and are difficult to follow. It provides a specific example, asking whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. While the comment identifies a clear area for improvement, it does not provide explicit guidance on how to reorganize the proofs or improve their clarity. The action is implicit, as the authors would need to infer that they should reorganize the proofs to enhance readability and rigor. However, the comment lacks concrete details on how to achieve this, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proof,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the organization and clarity of the proofs, providing a clear example of what needs improvement. The comment requests clarification on a specific aspect of Lemma 3, which is a detailed and specific request for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proof is \"extremely not well organized\" and that many proofs lack \"clean logic and are very hard to follow,\" making it difficult to rigorously check the correctness of the proof. The comment provides a specific example, asking whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. However, the claim lacks detailed reasoning or examples to fully substantiate the assertion about the poor organization and lack of logic in the proofs. While the comment provides a basis for improvement, it does not offer a comprehensive explanation or evidence to support the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the organization and clarity of the proofs in the paper, noting that many proofs lack clean logic and are difficult to follow, which hinders the rigorous checking of their correctness. The comment provides a specific example, asking whether the result in Lemma 3 holds for any polynomial function $P(\\gamma)$. This feedback is valuable as it highlights a critical area for improvement, but it lacks detailed guidance on how to reorganize the proofs or enhance their clarity. While it points out a specific issue, it does not offer comprehensive suggestions or detailed examples of how to address the problem. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This provides a clear and explicit action for the authors to take, as they can directly address this suggestion by incorporating experiments on real-world datasets. The comment is specific in its recommendation, detailing what kind of experiments would be beneficial. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests conducting experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or figure. This makes it difficult for the authors to identify the exact area where the change is needed. While the comment is specific in its recommendation, the lack of grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This claim is based on the premise that real-world datasets would provide a more realistic evaluation of the disentangled representation learning approach. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the reasoning behind the suggestion, which could be improved with additional justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the paper should conduct experiments on real-world datasets instead of synthetic ones, particularly for the out-of-distribution setting. This is a valuable and actionable suggestion that could enhance the paper's relevance and impact. By recommending the use of real-world datasets, the comment provides a clear direction for improving the experimental validation of the proposed approach. However, the comment could be more helpful if it included specific examples of real-world datasets or detailed guidance on how to conduct these experiments. Overall, the feedback is mostly helpful as it offers a clear and actionable suggestion for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests showing smoothed ground truth (GT) shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any explicit or implicit guidance on how to implement this suggestion, such as which specific elements of the figures should be highlighted or how the smoothing process should be visualized. The action is vague and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5, which provides some grounding as it mentions specific figures. However, it does not specify which parts of the figures should be highlighted or how the smoothing process should be visualized, making the comment specific but lacking in detail. The authors can infer that the issue is related to the clarity of the figures but cannot fully understand the scope of the suggestion. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. However, it does not provide any specific reasoning, examples, or references to support why this suggestion is beneficial or how it would enhance the understanding of the reconstruction quality. The comment lacks detailed justification, making it difficult for the authors to understand the basis of the suggestion and how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests showing smoothed ground truth shapes in Figure 3 and Figure 5 to help readers better understand the quality of the reconstruction. While this feedback is relevant and could improve the clarity of the paper, it lacks depth and specificity. The comment does not provide detailed guidance on how to visualize the smoothed shapes or what aspects of the reconstruction quality would be enhanced by this visualization. As a result, the feedback is somewhat helpful, as it identifies an area for improvement but does not offer comprehensive suggestions or actionable steps for the authors to take. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the mixed use of notations $\\hat{Y}$ and $Y$ in Section 2. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. The comment lacks concrete guidance on what needs to be done to ensure consistency in notation usage. Without specific instructions or examples, the authors are left without a clear path to resolve the problem. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment points out an issue with the mixed use of notations $\\hat{Y}$ and $Y$ in Section 2. However, it does not specify which part of Section 2 is affected, making it difficult for the authors to pinpoint the exact issue. The comment is weakly grounded as it does not provide enough context for the authors to accurately identify the section being addressed. Additionally, it lacks specificity in detailing what needs to be addressed regarding the inconsistent notation usage. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the notations of $\\hat{Y}$ and $Y$ are used in a mixed way in Section 2. However, the comment does not provide any specific examples or references to support this claim. Without detailed evidence or context, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the mixed use of notations $\\hat{Y}$ and $Y$ in Section 2. While it points out a specific area that needs attention, it does not provide any suggestions or guidance on how the authors might address this inconsistency. The comment lacks depth and actionable advice, leaving the authors without a clear path to improve their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper lacks important references for domain adaptation. It suggests that the authors should cite and discuss these references in the revised manuscript. This feedback is explicit and provides a clear action for the authors to take, which is to include and discuss the missing references. The comment is specific in its suggestion, guiding the authors on what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"domain adaptation,\" allowing the authors to accurately identify the part of the paper that needs improvement. It is also specific because it clearly specifies that the authors should cite and discuss important references for domain adaptation. This provides the authors with a clear understanding of what needs to be addressed in the revised manuscript. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks important references for domain adaptation and suggests that the authors should cite and discuss these references. However, the comment does not provide any specific examples of missing references or explain why these references are crucial. Without detailed justification or examples, the claim is somewhat verifiable, as it lacks sufficient evidence to fully support the assertion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the lack of important references for domain adaptation. It provides a clear and actionable suggestion for improvement by recommending that the authors cite and discuss these missing references in the revised manuscript. This feedback is specific and directly addresses a critical aspect of the paper, offering the authors a clear direction for enhancing their work. However, the comment could be more helpful if it provided examples of the missing references or suggested specific ways to integrate them into the manuscript. Despite this, the comment is mostly helpful as it effectively guides the authors toward addressing a key issue. Therefore, the comment is rated as 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises a concern about the suspicious performance of the SCNN model on domain pricing, suggesting that it might be due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to investigate or resolve the concern. The suggestion for presentation is vague and lacks concrete details. Therefore, the comment is not actionable, as it does not provide clear instructions or guidance on how the authors can improve their draft. The comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises concerns about the SCNN model's performance on domain pricing, suggesting it might be \"lucky\" due to hyperparameter tuning. It questions whether the chosen hyperparameters are at the end of the searched range and notes the suspiciously large distance to the next best model. However, the comment does not specify which part of the paper discusses the SCNN model or the domain pricing experiments, making it difficult for the authors to pinpoint the exact issue. While the comment is specific about the concerns regarding the model's performance, it lacks grounding as it does not clearly identify the section or part of the paper being addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the suspicious performance of the SCNN model on domain pricing, questioning whether the chosen hyperparameters are at the end of the searched range and noting the large distance to the next best model. However, the comment does not provide any specific evidence, examples, or references to support these claims. Without detailed reasoning or supporting data, the authors may find it challenging to address the concern effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about the suspicious performance of the SCNN model on domain pricing, questioning whether the chosen hyperparameters are at the end of the searched range and noting the large distance to the next best model. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their model's performance. The presentation suggestions are vague and do not provide actionable steps for the authors to take. As a result, the comment is somewhat helpful, as it highlights a potential area for improvement but does not offer detailed guidance or constructive feedback. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not provide explicit guidance on what needs to be clarified or how the authors should address these issues. The comment lacks concrete actions or suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment acknowledges that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, it does not specify which parts of the paper these issues pertain to, such as specific sections or tables. This makes it difficult for the authors to pinpoint the exact areas that need clarification. While the comment is specific about the nature of the issues, it lacks grounding as it does not provide clear references or sections to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that some aspects of the experimental setup were unclear or poorly motivated, specifically mentioning corpora and datasets. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors are left without a clear understanding of what specific issues need to be addressed. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the clarity and motivation of the experimental setup, specifically mentioning corpora and datasets. However, it lacks specificity and does not provide detailed guidance or suggestions on how to address these issues. The comment is vague and does not offer actionable advice, leaving the authors with limited insight into how to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters compared to competing approaches. It also notes that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is explicit and provides a clear action for the authors to take: they should provide more detailed information about the size of each hourglass module. However, the comment lacks specific guidance on how to measure or compare the size of the model, making it somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the size of the model in terms of depth or number of parameters compared to competing approaches. It also notes that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is fully grounded as it explicitly mentions the part of the paper where the model is described, allowing the authors to accurately identify the section being addressed. However, the comment is somewhat specific as it does not provide detailed guidance on how to compare the model size with competing approaches or how to determine the size of each hourglass module. Therefore, this comment is rated as 4: Fully Grounded and Under-Specific.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point raises a question about the size of the model in terms of depth or number of parameters compared to competing approaches. It notes that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is somewhat verifiable as it points out a lack of detail in the description of the model architecture, which could be addressed by providing more information. However, the comment does not offer specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement by questioning the size of the model in terms of depth or number of parameters compared to competing approaches. It highlights that while the authors mention the model consists of 4 hourglass modules, they do not specify the size of each module. This feedback is clear and actionable, as it directs the authors to provide more detailed information about the model architecture. However, the comment could be more helpful if it suggested specific ways to compare the model size with competing approaches or provided examples of how to measure the size of each module. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the metric learning theory in the paper, suggesting that it is not novel or better than existing theoretical results. It implies that the authors should consider how to improve the metric learning aspect of their work. However, the comment does not provide specific guidance on what changes or improvements could be made to address the identified issue. The action is implicit and vague, as the authors are left to infer that they need to enhance the metric learning section. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment critiques the metric learning theory in the paper, referencing the generalization theory of neural networks and suggesting that the proposed metric perspective analysis does not offer better results compared to previous theoretical findings. It implies that the part of metric learning in the paper does not seem to work. However, the comment does not specify which part of the paper discusses metric learning, making it difficult for the authors to pinpoint the exact section that needs improvement. While the comment is specific in its critique of the metric learning theory, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the metric learning theory in the paper is not novel or better than existing theoretical results, referencing the generalization theory of neural networks. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide a clear explanation of how the proposed metric perspective analysis compares to previous results or why it does not offer better outcomes. Without additional context or evidence, the claim is difficult to verify, making the comment borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment critiques the metric learning theory in the paper, noting that it is not novel or better than existing theoretical results. It suggests that the proposed metric perspective analysis does not offer improved outcomes compared to previous findings. This feedback provides a clear direction for the authors to consider how to enhance the metric learning aspect of their work. However, the comment lacks specific suggestions or guidance on how to improve the metric learning section, leaving the authors with a general idea but without actionable steps. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide detailed guidance for the authors to follow.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a potential confusion in the paper regarding the use of the symbol \"r\" to denote both the risk for minimization problems and the primal risk for minimax problems. While the comment highlights a potential issue with clarity, it does not provide explicit guidance on how the authors should address this confusion. The authors are left to infer that they need to clarify the notation, but the comment lacks concrete steps or suggestions on how to do so. Therefore, the comment is somewhat actionable, as it points out a specific issue but does not provide detailed guidance on how to resolve it.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the use of \"r\" to denote the risk for minimization problems and primal risk for minimax problems, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the confusion regarding the notation, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that using \"r\" to denote the risk for minimization problems and primal risk for minimax problems simultaneously is confusing. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand why this confusion arises or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential source of confusion in the paper regarding the use of the symbol \"r\" to denote different types of risks. While it points out a specific issue with the notation, it does not provide any suggestions or guidance on how the authors might address this confusion. The comment is clear and identifies a potential area for improvement, but it lacks actionable advice or detailed suggestions, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. However, it does not provide explicit guidance on how to address this issue or what actions the authors should take to improve their draft. The comment is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. However, it does not specify which part of the paper this question relates to, such as a particular section or figure. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its inquiry about the importance of test examples and the potential use of corpus residual value, but it lacks detailed guidance on how to address this issue. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. However, it does not provide any specific reasoning, examples, or references to support the claim that this is a significant issue or how it might be addressed. The comment lacks detailed justification or evidence, making it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a question about the importance of test examples and suggests exploring whether a corpus residual value can detect differences in the test set. This question is relevant to the authors as it highlights a potential issue with the robustness of their experimental setup. However, the comment lacks specific guidance or suggestions on how to address this concern or what actions the authors should take to improve their draft. While it identifies a potential area for improvement, it does not provide detailed feedback or actionable advice, making it somewhat helpful. The authors would need to infer how to address the issue, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not explicitly instruct the authors to change the dataset or provide specific guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the suggested dataset and understand the reasoning behind it. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. It provides a rationale for this suggestion, explaining that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment does not specify which part of the paper discusses the choice of the testbed dataset, making it difficult for the authors to identify the exact section being addressed. While the suggestion is specific, the lack of grounding makes it challenging for the authors to understand the context and apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the choice of the testbed dataset, WebQuestionsSP, and suggests using the more popular WebQuestions benchmark set instead. The reasoning provided is that WebQuestions is more intuitive and straightforward for weak supervision tasks and would facilitate direct comparison with mainstream QA research. However, the comment lacks specific examples or references to support the claim that WebQuestions is more intuitive or straightforward for weak supervision tasks. Without detailed justification or evidence, the claim is somewhat verifiable, as it provides a rationale but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the choice of the testbed dataset, suggesting that the authors consider using the more popular WebQuestions benchmark set instead of WebQuestionsSP. The rationale provided explains why this change would be more intuitive and straightforward for weak supervision tasks, as it aligns with the requirements of the NSM method and facilitates direct comparison with mainstream QA research. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. However, the comment could be more helpful if it included additional guidance on how to conduct the comparison or what specific aspects of the results would be relevant to consider. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be further enhanced with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It also implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not provide explicit guidance on how to address this issue or what specific actions the authors should take to improve their draft. The action is implicit and vague, as it leaves the authors to infer the need for demonstration and action. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment does not specify which part of the paper discusses sparsity or training, making it difficult for the authors to pinpoint the exact area that needs revision. While the comment is specific about the issue of sparsity and its relevance, it lacks grounding as it does not provide clear references to specific sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the necessity of making claims about sparsity in training, suggesting that it is not obvious why sparsity is desirable. It implies that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment lacks specific examples or references to support the claim that sparsity is desirable or how it can be demonstrated. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable. Therefore, the comment is rated as 2.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a valid concern about the necessity of making claims about sparsity in training, questioning whether it is obvious that sparsity is desirable. It suggests that the authors should demonstrate the benefits of sparsity, such as improved performance or cost savings, especially in the context of parallelized computation. However, the comment lacks specific guidance on how to address this issue or what actions the authors should take to improve their draft. While it identifies a potential area for improvement, it does not provide detailed suggestions or examples, making it somewhat helpful. The feedback is incomplete and could be more actionable with additional details, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the model design and learning details, noting that they are fragmented or missing. It suggests that the authors could provide a model illustration plot, pseudo-code table, or code repository to address this issue. The comment implies that these additional details are necessary for reproducibility, especially given the less-known nature of Neurochaos Learning. However, the action is implicit, as the authors need to infer that they should provide these additional details to improve the clarity and reproducibility of their work. The comment is somewhat actionable because it provides a clear direction for improvement, but it lacks concrete guidance on how to implement these suggestions, such as specific examples of what kind of details should be included or how to effectively integrate them into the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of unclear model design and learning details, suggesting that the authors could provide a model illustration plot, pseudo-code table, or code repository to improve clarity and reproducibility. However, the comment does not specify which part of the paper discusses the model design or learning details, making it weakly grounded. It is specific in suggesting what kind of additional details would be helpful, but without clear references to the sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the model architecture and learning details are fragmented or missing, which could hinder reproducibility. It suggests that providing a model illustration plot, pseudo-code table, or code repository would address this issue. However, the comment lacks specific examples or references to support the claim that these details are indeed missing or fragmented. Without detailed examples or references, the authors may find it difficult to fully understand and address the issue. Therefore, the claim is somewhat verifiable, as it provides a logical basis but lacks sufficient evidence to fully substantiate the assertion.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the clarity of the model design and learning details, noting that they are fragmented or missing. It provides specific suggestions for improvement, such as including a model illustration plot, pseudo-code table, or code repository, which would enhance the reproducibility of the work. Additionally, the comment highlights the importance of demonstrating integrated details, especially given the less-known nature of Neurochaos Learning, to facilitate reproducibility. While the comment is clear and actionable, it could be more helpful if it provided more detailed guidance on what specific aspects of the model design or learning details should be included. Overall, the feedback is mostly helpful as it offers clear directions for improvement, but it could be more comprehensive with additional details.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should clarify the generalization to specific TSP instances, particularly the fine-tuning step in DIMES. It also recommends comparing DIMES with other methods on TSP100, both with and without meta-learning. While the comment provides a clear direction for improvement, it does not specify which parts of the paper need to be addressed or how the authors should implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific sections to focus on and the exact nature of the comparison. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the generalization to specific TSP instances, particularly the fine-tuning step in DIMES, and suggests that the authors should clarify this generalization. It also recommends comparing DIMES with other methods on TSP100, both with and without meta-learning. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. While it provides some specificity by suggesting comparisons, it lacks detailed guidance on how to implement these suggestions. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the generalization of the proposed method to specific TSP instances, particularly the fine-tuning step in DIMES. It suggests that the authors should clarify the differences between DIMES and other methods, especially in addressing generalization gaps. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable, as it provides some context but lacks sufficient support for the authors to address the issue effectively.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a specific area for improvement by pointing out the need for clearer clarification regarding the generalization of the proposed method to specific TSP instances, particularly the fine-tuning step in DIMES. It suggests that the authors should elaborate on how DIMES addresses the generalization gaps compared to other methods. Additionally, the comment recommends a comparison of DIMES with other methods on TSP100, both with and without meta-learning, which could provide valuable insights. However, the comment lacks detailed guidance on how to implement these suggestions or specific examples to support the claims, making it somewhat helpful. The feedback is clear and actionable, but it could be more comprehensive with additional details to fully assist the authors in improving their draft.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. While the comment identifies a potential nuance in the original claim, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of their analysis might need to be reconsidered. The action is implicit and somewhat vague, as the authors are left to infer that they should consider the impact of different features on their analysis. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the claim is made, allowing the authors to accurately identify the section being addressed. It also specifies what the authors should consider, namely the impact of different features on answer detection, such as POS/dependency parse features. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the claim that the readability of RC datasets does not directly affect question difficulty, suggesting that this conclusion might be influenced by the method or features used for answer detection, such as POS/dependency parse features. This critique is somewhat verifiable as it provides a specific example of a potential factor that could affect the conclusion, but it lacks detailed reasoning or references to support the claim fully. The authors are left to infer the basis of the critique, which could be improved with more explicit justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment critiques a specific claim made in the paper, pointing out that the conclusion about the relationship between dataset readability and question difficulty might be influenced by the method or features used for answer detection. This critique is valuable as it highlights a potential nuance in the original claim and suggests that the authors should consider the impact of different features on their analysis. However, the comment could be more helpful if it provided specific guidance on how the authors might address this issue or what additional experiments or analyses they could conduct to strengthen their findings. Overall, the comment is somewhat helpful as it identifies an important aspect of the paper that needs further consideration, but it lacks detailed actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space used in the study. It suggests that the authors should provide evidence or analysis to support the claim that the space is meaningful, such as examining whether the addition of morphological variants results in semantically coherent outcomes. However, the comment does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide evidence or analysis to support the claim. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the meaningfulness of the geometry of the vector space used in the study, specifically questioning whether the space is meaningful and suggesting that the authors provide evidence or analysis to support this claim. It does not specify which part of the paper this question pertains to, making it weakly grounded. However, the comment is specific in its request for evidence and analysis, which would help the authors address the issue. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the meaningfulness of the geometry of the vector space used in the study, specifically questioning whether the space is meaningful and suggesting that the authors provide evidence or analysis to support this claim. The comment does not provide any specific examples, reasoning, or references to support the claim that the space is meaningful. Without such evidence, the claim remains speculative and lacks verifiability. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises a pertinent question about the meaningfulness of the vector space used in the study, specifically questioning whether the geometry of the space is meaningful and whether the morphfitting results in a more meaningful space or just better embeddings. It suggests that the authors should provide evidence or analysis to support the claim that the space is meaningful, such as examining whether the addition of morphological variants results in semantically coherent outcomes. This feedback is somewhat helpful as it identifies a potential area for improvement and encourages the authors to provide evidence or analysis to support their claims. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct this analysis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks. While the comment identifies areas for improvement, it does not provide explicit guidance on how to improve the writing quality or address the issue of missing related work. The authors are left to infer that they need to revise the explanation of basic memory networks and the forward model to be more concise and that they should include more reinforcement learning tasks in the related work section. This lack of explicit and detailed guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the writing quality of the paper should be improved, specifically pointing out that the authors spend the same space on explaining basic memory networks and the forward model. It also notes that the related work section has missing pieces on more reinforcement learning tasks in the literature. However, the comment does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact areas that need improvement. The lack of specific guidance on what aspects of the writing quality or the related work section require improvement makes the comment weakly grounded. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the writing quality of the paper should be improved, specifically noting that the authors spend the same space on explaining basic memory networks and the forward model. It also mentions that the related work section has missing pieces on more reinforcement learning tasks. However, the comment lacks specific examples or detailed reasoning to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of evidence or references weakens the verifiability of the claim, aligning with a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies two main areas for improvement: the writing quality of the paper and the completeness of the related work section. It points out that the authors spend the same space on explaining basic memory networks and the forward model, suggesting that the explanation could be more concise. Additionally, it notes that the related work section lacks coverage of more reinforcement learning tasks. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is somewhat helpful as it directs the authors to areas that need improvement, but it lacks depth and actionable advice, making it a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not provide any explicit or implicit suggestions or actions for the authors to take. The comment lacks guidance on how the authors might address this question or what aspects of their work could be improved. Without specific advice or direction, the authors are left without a clear path to respond or improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the number of different kinds of physical interactions that can be included in a simulation. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is not grounded as it does not provide explicit references to specific sections, tables, or figures. Additionally, it lacks specificity because it does not detail what information or analysis is needed to address the question. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point poses a question about the number of different kinds of physical interactions that can be included in a simulation. It does not contain any claims, opinions, or suggestions that require verification or justification. The comment is purely factual and descriptive, aligning with the classification of \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment poses a question about the number of different kinds of physical interactions that can be included in a simulation. While it highlights a potential area for clarification or further exploration, it does not provide any specific guidance or suggestions on how the authors might address this question or what aspects of their work could be improved. The comment lacks actionable feedback, leaving the authors without a clear path to respond or enhance their draft. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of one-hot encoding for the categorical dataset, which could negatively impact model performance. While the comment identifies specific issues with the dataset selection and suggests that the authors should consider the importance of categorical features and one-hot encoding, it does not provide explicit guidance on how to address these issues or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the specific part of the paper being addressed, namely the model comparison section. It provides detailed feedback on the dataset selection, noting that only one dataset contains categorical features while the others are exclusively numerical. This feedback is specific, as it clearly specifies what needs to be addressed in the model comparison section. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point critiques the model comparison by highlighting the limitation of the dataset selection, specifically noting that only one dataset contains categorical features, while the others are exclusively numerical. It also points out the absence of one-hot encoding for the categorical dataset, which could negatively impact model performance. The comment provides a clear and logical explanation of why the dataset selection is inadequate and suggests that the authors should consider the importance of categorical features and one-hot encoding. However, it lacks specific examples or references to support the claim, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a detailed critique of the model comparison section, highlighting a significant limitation in the dataset selection. It points out that only one dataset contains categorical features, while the others are exclusively numerical, which is a notable omission given the importance of categorical features in deep learning. The comment also notes the absence of one-hot encoding for the categorical dataset, which could negatively impact model performance. This feedback is clear and actionable, as it provides specific examples of areas where the authors could improve their draft. However, the comment could be more helpful if it suggested specific ways to address these issues or provided guidance on how to include one-hot encoding in the analysis. Overall, the comment is mostly helpful, as it identifies a critical weakness and offers constructive feedback for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the pruning strategy, suggesting that it might not be effective for large networks due to the lack of mention of global top Q values of the metric over the average of gradients. It implies that this omission could lead to the breaking of acceleration techniques like quantization and sparsification. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to pruning strategies, particularly in the context of large networks and distributed training. It highlights a potential problem with the lack of mention of global top Q values of the metric over the average of gradients, which could impact the effectiveness of acceleration techniques like quantization and sparsification. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The specificity of the comment is clear, as it specifies the potential problem with pruning strategies and the impact on acceleration techniques. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that pruning majorly works with large networks, which are usually trained in distributed settings, but does not mention anything about potential necessity to find global top Q values of the metric over the average of gradients. This omission could potentially break big portion of acceleration techniques, such as quantization and sparsification. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the full extent of the issue. The reasoning is somewhat vague, and the claim is not fully verifiable without additional context or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a potential issue with the pruning strategy, specifically noting that it might not work effectively for large networks due to the lack of mention of global top Q values of the metric over the average of gradients. This observation is relevant as it could impact the effectiveness of acceleration techniques like quantization and sparsification. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or what changes could be made to improve the pruning strategy. While it highlights a potential problem, it lacks actionable advice, making it somewhat helpful. The authors would need to infer the necessary steps to address the issue, which limits the comment's usefulness. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. While it identifies a potential issue, it does not provide any explicit or implicit actions for the authors to take. The authors are left without guidance on how to address this concern, making the comment unactionable. Therefore, this comment aligns with the lowest score of 1.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not specify which subfigures are in question or provide any details about the figures themselves. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment does not specify what needs to be addressed or how the issue should be resolved, making it not specific. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point questions whether some subfigures in Figs 1 and 2 have been swapped by mistake. However, it does not provide any evidence, reasoning, or references to support this claim. Without any justification or explanation, the authors are left without a basis to address or verify the issue. Therefore, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a concern about potential errors in the subfigures of Figs 1 and 2, questioning whether they have been swapped by mistake. However, it does not provide any specific details or suggestions on how to address this issue. The comment lacks actionable guidance, leaving the authors without a clear path to improve their draft. As a result, the feedback is not helpful, aligning with a score of 1.', 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review comment acknowledges that the dropout probe improves sensitivity and identifies a potential concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not provide explicit guidance on how the authors should address this concern or what specific aspects of the discussion need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the issue of the dropout probe improving sensitivity and highlights a concern about the increased risk of false positives. It suggests that this issue should be a substantial part of the discussion. However, the comment does not specify which part of the paper this issue is related to, such as a specific section or figure. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper needs attention. The comment is specific in identifying the concern about false positives, but without grounding, it is difficult for the authors to apply the feedback effectively. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the dropout probe improves sensitivity but also raises a concern about the increased risk of false positives. The comment suggests that this issue should be a substantial part of the discussion. However, the comment lacks specific examples or detailed reasoning to substantiate the claim about the increased risk of false positives. It does not provide references or logical arguments to support the assertion, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential concern regarding the increased risk of false positives when using the dropout probe, which improves sensitivity. It suggests that this issue should be a substantial part of the discussion. While the comment highlights a specific area that needs attention, it does not provide detailed guidance on how to address this concern or what aspects of the discussion should be expanded. The feedback is somewhat helpful as it points out a potential issue that could impact the validity of the results, but it lacks depth and actionable suggestions for improvement. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a discrepancy between the authors' claim about the placement of the regret bound and the reviewer's inability to find it in the supplementary material. While the comment points out a potential issue with the authors' claim, it does not provide explicit guidance on how the authors should address this concern. The action is implicit, as the authors need to infer that they should double-check the placement of the regret bound and ensure it is correctly referenced. However, the comment lacks concrete details on how to implement this action, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the authors' claim about the placement of the regret bound in the appendix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the authors did not find the regret bound for the mini-batch estimator in the supplementary material, and it references a specific paper [1] that might contain the relevant information. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors' claim about the regret bound being cast to the appendix is not supported by the supplementary material. However, the comment does not provide any specific evidence or references to substantiate this claim. Without additional information or examples, the reviewer's assertion remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors' claim regarding the placement of the regret bound in the appendix. It points out that the authors did not find the regret bound for the mini-batch estimator in the supplementary material, referencing a specific paper [1] that might contain the relevant information. This feedback is clear and actionable, as it directs the authors to double-check the placement of the regret bound and ensure it is correctly referenced. However, the comment could be more helpful if it provided additional guidance on how to verify the claim or suggested alternative approaches to address the issue. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment points out that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, it does not provide explicit guidance on how the authors should address this issue or what specific methods they should include in their discussion. The action is implicit and vague, as it leaves the authors without a clear understanding of how to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the paper,\" allowing the authors to accurately identify the part being addressed. It is also specific because it highlights the lack of discussion and comparison of exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper is not sound because it does not discuss or compare exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the criticism. Without detailed examples or references, the claim is somewhat verifiable, as it provides a general idea but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant weakness in the paper by pointing out the absence of discussion and comparison of exploration methods in RL literature, such as count-based methods and intrinsic motivations (RND, ICM). This feedback is valuable as it highlights an area where the paper could be strengthened by providing a more comprehensive overview of the existing literature. However, the comment could be more helpful if it suggested specific methods or approaches that the authors should consider discussing or comparing. While it provides a clear direction for improvement, the lack of detailed guidance limits its impact on the authors. Therefore, the comment is mostly helpful, as it offers actionable feedback but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies several areas that need clarification or improvement, it does not provide explicit instructions on how to address these issues. The actions are implicit and somewhat vague, as the authors are left to infer how to resolve the issues. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises several questions and concerns about specific aspects of the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment does not explicitly mention specific sections or parts of the paper that need attention, making it weakly grounded. The specificity of the feedback is moderate, as it clearly specifies what needs to be addressed, such as the coefficient and hyperparameter details. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises several questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the feedback. The questions raised are logical and require the authors to provide more detailed information, but without additional context or evidence, the claims are not fully verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises several important questions and concerns about the paper, such as the impact of inference on speed, the possibility of only doing inference, the coefficient of the p(L, E | X) term in line 307, and the lack of hyperparameter details. It also notes that the writing is not careful and hinders understanding. While the comment identifies specific areas that need clarification or improvement, it lacks detailed guidance on how to address these issues. The feedback is somewhat helpful as it points out areas for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation identifies a key weakness of the method. However, the comment does not provide any explicit or implicit suggestions on how to address this issue or improve the method. The authors are left without guidance on what steps to take to enhance their work, making the comment unactionable. Therefore, the comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the proposed compression\" and \"PQ,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the proposed compression performs worse than PQ when a small code length is allowed, which is a clear and specific critique. This provides the authors with a clear understanding of what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the proposed compression performs worse than PQ when a small code length is allowed, which is identified as the main weakness of the method. However, the comment lacks specific evidence or references to support this claim. Without additional context or data, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific weakness in the proposed compression method, noting that it performs worse than PQ when a small code length is allowed. This observation highlights a critical limitation of the method, which could be a significant concern for practical applications. However, the comment lacks actionable suggestions or guidance on how to address this issue or improve the method. While it points out a problem, it does not provide the authors with a clear path forward or additional insights to enhance their work. Therefore, the comment is somewhat helpful, as it identifies a weakness but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment does not explicitly instruct the authors to add more detailed analyses or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer what needs to be done. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"language/nationality\" and provides examples of the data included, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the analysis could be more detailed by comparing different languages/nationalities and raises a question about potential interesting observations. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the label is 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. However, the comment lacks specific examples or references to support the claim that the analysis could be more detailed or that there are interesting observations to be made. Without additional evidence or guidance, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests that some analyses could be more detailed, specifically mentioning the inclusion of data from various languages and nationalities. It provides an example of the data included and raises a question about potential interesting observations comparing different languages/nationalities. This feedback is somewhat helpful as it identifies an area for improvement and encourages the authors to consider more detailed analyses. However, the comment could be more helpful if it provided specific guidance on how to conduct these analyses or suggested particular types of observations that could be made. Overall, the comment offers some insight but lacks depth and actionable suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment does not explicitly instruct the authors to address these questions or provide guidance on how to do so. The action is implicit, as the authors need to infer that they should investigate and potentially illustrate the conservation of properties in their work. While the action is somewhat concrete, it lacks explicit instructions on how to implement it, making the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"many solvers' algorithms\" and provides examples of how they guarantee mathematical properties, such as conservation of mass or charge in physics-related continuous PDEs. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it asks about the behavior of learning F^\\\\dagger in this regard, suggesting that the authors investigate whether it can preserve these properties and how to illustrate this numerically. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment does not offer any specific reasoning, references, or examples to support the claims made, leaving the authors to infer the basis of the questions. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to rely on their own understanding and reasoning to address the questions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises several insightful questions and suggestions regarding the conservation of mathematical properties in the context of learning F^\\\\dagger, particularly in relation to symplectic integrators and Hamiltonian systems. It asks whether the learning process can preserve these properties and provides examples of how to illustrate this numerically. However, the comment lacks specific guidance or suggestions on how to address these questions or what experiments or analyses might be necessary. While it identifies an important area for further exploration, it does not provide actionable steps or detailed insights that would significantly enhance the authors' understanding or improve their work. Therefore, the comment is somewhat helpful, as it highlights potential areas for improvement but does not offer comprehensive guidance for the authors to follow.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper should include a variety of tasks beyond link prediction where the proposed method (PE) is important. However, it does not provide any specific guidance or suggestions on how to achieve this, such as which tasks to include or how to demonstrate the importance of PE in those tasks. The comment lacks explicit instructions or concrete details, making it difficult for the authors to understand what actions they should take to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not specify which tasks or sections of the paper need to be addressed to achieve this. The authors cannot confidently determine which part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity in detailing what tasks should be included or how they should be presented. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point suggests that the paper should include a variety of tasks beyond link prediction where PE is important. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this suggestion or how to incorporate it into their work. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the paper should include a variety of tasks beyond link prediction where the proposed method (PE) is important. However, it lacks specific guidance or suggestions on how to achieve this, such as which tasks to include or how to demonstrate the importance of PE in those tasks. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not provide actionable feedback or detailed examples, leaving the authors with limited direction for enhancing their draft. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a specific concern about the evaluation of the quality of \\overline{\\Pi} in the context of finding an optimal policy for every test MDP in S_{test}. It suggests that the current approach of using summation might be misleading, as it could select a subset of policies that are good for the majority of MDPs but bad for the remaining ones. The reviewer proposes using the minimum over S_{test} instead, which would highlight the worst-case performance. However, the comment does not provide explicit guidance on how the authors should implement this suggestion or what specific changes they should make to their draft. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the evaluation of the quality of \\overline{\\Pi} in the context of finding an optimal policy for every test MDP in S_{test}. It suggests that the current approach of using summation might be misleading and proposes using the minimum over S_{test} instead. This provides clear guidance on what needs to be addressed in the paper, making it fully grounded. The comment is also specific as it details the issue and suggests a concrete alternative evaluation method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a specific concern about the evaluation of the quality of \\overline{\\Pi} in the context of finding an optimal policy for every test MDP in S_{test}. It suggests that the current approach of using summation might be misleading, as it could select a subset of policies that are good for the majority of the MDPs but bad for the remaining ones. The reviewer proposes using the minimum over S_{test} instead, which would highlight the worst-case performance. However, the comment does not provide any specific examples, references, or detailed reasoning to support the claim that the summation approach is misleading or why the minimum approach is more appropriate. This lack of detailed justification makes the claim somewhat verifiable, as the authors may need to infer the reasoning or seek additional evidence to fully understand the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific concern about the evaluation of the quality of \\overline{\\Pi} in the context of finding an optimal policy for every test MDP in S_{test}. It suggests that the current approach of using summation might be misleading, as it could select a subset of policies that are good for the majority of the MDPs but bad for the remaining ones. The reviewer proposes using the minimum over S_{test} instead, which would highlight the worst-case performance. This feedback is clear and actionable, as it provides a specific suggestion for improvement that could enhance the robustness of the evaluation. However, it could be more helpful if it included examples or further elaboration on why the minimum approach is more appropriate. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded for greater depth and impact.', 'helpfulness_label': '4'}"}
{"generated_text": "{'actionability_rationale': 'The review point suggests that footnotes are used excessively, making the paper distracting, and recommends moving important content into the main body and details about parameter settings into the appendix. While the comment provides explicit guidance on how to improve the paper by suggesting specific actions, such as moving content to the main body and appendix, it does not offer detailed instructions on how to execute these actions. The authors are left with a general idea of what needs to be done but lack specific steps to follow. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"footnotes\" and \"parameter settings,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on how to improve the paper by suggesting that excessive footnotes are distracting and that important content should be moved into the main body, with details about parameter settings moved to the appendix. This provides a clear direction for the authors to make necessary changes. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that footnotes are used too extensively, making the paper distracting, and suggests moving important content to the main body and details about parameter settings to the appendix. While the comment provides a general rationale for the suggestion, it lacks specific examples or references to support the claim about the excessive use of footnotes. The authors are left with a general understanding of the issue but without detailed guidance on how to address it. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but lacks the depth needed for full verification.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the excessive use of footnotes, which can make the paper distracting. It provides actionable suggestions for improvement, such as moving important content to the main body and details about parameter settings to the appendix. This feedback is clear and constructive, offering the authors specific guidance on how to enhance the readability and flow of their paper. However, the comment could be more helpful if it included additional suggestions or considerations, such as specific examples of content that could be moved or a more detailed explanation of why the current use of footnotes is problematic. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the inclusion of few-shot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not provide explicit guidance on how to implement this suggestion, such as which specific demonstrations to include or how they should be structured. The comment is somewhat vague, as it leaves the authors to infer the exact action needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the inclusion of few-shot demonstrations would be beneficial for the paper, implying that the authors should consider adding them. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or figure. The comment is vague in terms of specificity, as it does not provide detailed guidance on what aspects of the few-shot demonstrations should be included or how they should be presented. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. The comment does not provide specific examples or references to support the claim that the inclusion of zero-shot results is necessary or beneficial. As a result, the claim is considered unverifiable due to the lack of supporting evidence or logical reasoning. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the inclusion of zero-shot generation results, suggesting that it might satisfy general curiosity but lacks a clear justification or reasoning. While the comment identifies a potential area for improvement, it does not provide specific guidance or suggestions on how to address this issue or what aspects of the results might be relevant. The feedback is somewhat helpful as it prompts the authors to consider the inclusion of zero-shot results, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should acknowledge some of the older works in the related works section. While the comment implies that the authors should include these older works, it does not provide specific guidance on how to identify or incorporate them. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed to address the suggestion. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the authors should acknowledge some of the older works in the related works section. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to acknowledge older works, but without a clear reference to the section or part of the paper, the authors may find it challenging to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should acknowledge some of the older works in the related works section. However, it does not provide any specific examples, references, or reasoning to support this claim. Without additional context or evidence, the authors may find it difficult to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that the authors should acknowledge some of the older works in the related works section. While this feedback is relevant and provides a direction for improvement, it lacks specificity and does not offer detailed guidance on which older works should be acknowledged or how to integrate them into the paper. The comment is somewhat helpful as it identifies a potential area for enhancement, but it could be more actionable with additional details or examples. Therefore, the comment aligns with a score of 3, indicating that it is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights potential issues with the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment does not provide explicit or implicit actions for the authors to take to address these issues. It lacks guidance on how to optimize the method or what specific changes might be necessary to reduce the time complexity. Without concrete suggestions or actionable steps, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment addresses the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization-based methods. However, it does not specify which part of the paper these issues are discussed in, such as a particular section or figure. This makes it difficult for the authors to pinpoint the exact areas that need attention. While the comment is specific in detailing the issues, it lacks grounding as it does not provide clear references to the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the time complexity of the proposed method is high, citing the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization methods. However, the comment lacks specific evidence or references to substantiate these claims. Without detailed reasoning or examples, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered borderline verifiable, as it provides some basis for concern but lacks sufficient support.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies potential issues with the time complexity of the proposed method, specifically mentioning the use of an item-oriented autoencoder, the expense of the elementwise function, and the large number of hidden units compared to typical matrix factorization-based methods. While the comment highlights these concerns, it does not provide specific suggestions or guidance on how the authors might address these issues or optimize their method for better efficiency. Without actionable advice or detailed feedback on how to improve the method, the authors may find it challenging to make meaningful changes to their draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and specificity in its suggestions.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. This comment provides a clear and explicit action for the authors to take, which is to label the figures more precisely. The suggestion is concrete, as it specifies exactly what needs to be done to improve the clarity of the figures. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, it does not explicitly mention which figures are being referred to, making it weakly grounded. The comment is specific in its suggestion to improve the clarity of the figures by providing more detailed labels. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the figures would be clearer if they specified \"pre-trained solution encoders & solution decoders,\" given that there are multiple types of autoencoders. However, the comment does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the reasoning behind the suggestion. Without additional context or evidence, the claim is considered unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the clarity of the figures, suggesting that labeling them as \"pre-trained solution encoders & solution decoders\" would improve their readability. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the presentation of their figures. By addressing this suggestion, the authors can make their figures more understandable and effectively communicate their findings. Therefore, the comment is mostly helpful, as it offers a clear and actionable improvement that could significantly enhance the draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the absence of comparisons with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also suggests that the relevance of the occlusion experiment is unclear, as the method does not seem to propose anything specific to occlusion. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting specific comparisons or clarifying the relevance of the occlusion experiment. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific comparisons with NeRF-based methods, such as \"Zero-1-to-3\" and \"point-e,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the relevance of the occlusion experiment, questioning its significance in the context of the method. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises concerns about the lack of comparison with NeRF-based methods, specifically mentioning \"Zero-1-to-3\" and \"point-e.\" It also questions the relevance of the occlusion experiment, suggesting that it does not align with the method's specific contributions. However, the comment lacks detailed reasoning or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of specific examples or justifications weakens the verifiability of the claim. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment identifies a significant gap in the paper by pointing out the absence of comparisons with NeRF-based methods, specifically mentioning 'Zero-1-to-3' and 'point-e.' This feedback is valuable as it highlights the need for the authors to contextualize their work within the existing literature. Additionally, the comment questions the relevance of the occlusion experiment, suggesting that it does not align with the method's specific contributions. However, the comment lacks detailed guidance on how the authors should address these issues, such as providing specific comparisons or clarifying the relevance of the occlusion experiment. While the feedback is somewhat helpful in identifying areas for improvement, it could be more actionable with additional suggestions or guidance. Therefore, the comment aligns with a score of 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment explicitly asks for clarification and suggests a more detailed analysis, it does not provide explicit instructions on how to conduct the analysis or what specific aspects need to be detailed. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information on the extraction process and its impact on the experiment. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"p indicates the proportion of documents,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on how parts of sentences and documents are extracted and whether the extraction rules have an effect on the experiment, along with a request for a more detailed analysis. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises questions about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. However, the comment does not provide any evidence, reasoning, or references to support the need for such clarification or detailed analysis. Without specific examples or references, the authors may find it challenging to understand the basis for the request. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the extraction of proportions from documents and sentences, specifically asking for clarification on how these parts are extracted and whether the extraction rules have an effect on the experiment. It also suggests a more detailed analysis. While the comment identifies a potential area for clarification and suggests a more thorough analysis, it lacks specific guidance on what aspects of the extraction process or the impact on the experiment need further exploration. The feedback is somewhat helpful as it points out a potential area for improvement, but it could be more actionable with additional suggestions or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. While it prompts the authors to provide more discussion, it does not explicitly instruct them to do so or offer concrete guidance on how to address this concern. The action is implicit, as the authors need to infer that they should discuss the application of the meta sampler and its timing. However, the lack of detailed guidance on how to implement this discussion makes the action somewhat vague. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This makes it difficult for the authors to identify the exact area that needs clarification. While the comment is specific in its request for more discussion, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the application of the meta sampler, specifically whether it is used in a decoupled way and when it is applied. However, it does not provide any evidence, reasoning, or references to support the claim that the authors only apply the meta sampler in a decoupled way or when specific epochs are used. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the application of the meta sampler, asking whether it is used in a decoupled way and when it is applied. This feedback is somewhat helpful as it prompts the authors to clarify their methodology and potentially provide more context or discussion on the application of the meta sampler. However, the comment lacks depth and does not offer suggestions or guidance on how to address the concern, leaving the authors with limited actionable feedback. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper. However, the comment does not explicitly instruct the authors on how to implement these changes or what specific steps to take. The action is implicit and somewhat vague, as the authors need to infer the necessary actions and may require additional guidance to execute them effectively. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using fairness-aware metrics like Equality odds (EO) and conducting more experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper. However, the comment does not specify which part of the paper discusses the use of metrics or the experimental setup, making it difficult for the authors to identify the exact sections that need revision. While the suggestion to use specific metrics and datasets is clear, the lack of explicit grounding makes it challenging for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should use fairness-aware metrics like Equality odds (EO) and conduct more experiments on datasets like COMPAS and Drug Comsumption, referencing a cited AAAI paper. This claim is somewhat verifiable as it provides a clear direction for improvement by suggesting specific metrics and datasets to enhance the fairness of the experiments. However, it lacks detailed reasoning or examples to fully substantiate the claim, which could make it challenging for the authors to fully understand and implement the suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides specific suggestions for improvement, such as using fairness-aware metrics like Equality odds (EO) and conducting additional experiments on datasets like COMPAS and Drug Comsumption. It also encourages the authors to follow a cited AAAI paper, which could be helpful in understanding how to implement these suggestions. However, the comment lacks detailed guidance on how to integrate these changes into the draft or what specific aspects of the experiments need to be addressed. While it offers a clear direction for improvement, the feedback could be more helpful if it included more detailed instructions or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the content on lines 107-114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment highly actionable. The explicit suggestion to either rephrase, include in a discussion, or remove the content gives the authors a direct path to improvement.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the content on lines 107-114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. This provides the authors with clear guidance on how to address the issue, making the comment highly actionable. However, the comment does not specify which part of the paper this refers to, leaving the authors to infer that it is the content on lines 107-114. Therefore, the comment is fully grounded but lacks specificity, aligning with a score of 4.', 'grounding_specificity_label': '4', 'verifiability_rationale': 'The review point suggests that the content on lines 107-114 is speculative or overly opinionated and recommends it be stated as a remark, included in a Discussion section, or removed. While the comment provides a clear recommendation, it lacks specific examples or references to support the claim that the content is speculative or overly opinionated. This makes the claim somewhat verifiable, as the authors would need to independently assess the content to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific section of the paper (lines 107-114) as being speculative or overly opinionated, suggesting that it should be rephrased, included in a discussion section, or removed. This feedback is clear and actionable, providing the authors with a direct path to improve the clarity and objectivity of their work. By offering specific suggestions for how to address the issue, the comment is mostly helpful, as it guides the authors in making necessary revisions. However, it could be more helpful if it provided additional context or examples to support the claim about the content being speculative or opinionated.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement achieved by the changes suggested in the paper. While the comment implies that these baselines should be included, it does not explicitly instruct the authors to do so or provide specific guidance on how to incorporate them. The action is implicit and somewhat vague, as the authors are left to infer that they need to add these baselines to their experiments. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to include these baselines, but without clear references to the sections or figures, the authors may find it challenging to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. However, the comment lacks specific details or references to support the claim that these baselines are necessary or would provide additional insights. Without further elaboration or examples, the authors may find it challenging to understand the rationale behind the suggestion or how to incorporate it into their work. Therefore, the comment is considered borderline verifiable, as it provides some basis for consideration but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment suggests considering additional baselines, such as Rope and Alibi relative positional embeddings, to verify the performance improvement obtained by the changes suggested in the paper. This feedback is somewhat helpful as it provides a specific direction for the authors to enhance their experiments and validate their results. However, the comment lacks depth and does not offer detailed guidance on how to implement these baselines or why they are crucial for verifying the performance improvement. While it points out a potential area for further exploration, the feedback could be more impactful with additional context or suggestions. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two key areas for improvement: the lack of analysis regarding the neighborhood size h and the use of different hyperparameter sets per dataset. It suggests that the authors should provide insights into how performance varies with a constant set of parameters and analyze the influence of h on the model's performance. While the comment identifies specific issues and areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions should be taken. The authors are left to infer the necessary steps, making the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the missing element of the value of neighborhood size h and the analysis of its influence on the model\\'s performance, which is a key parameter of the proposed strategy. It also mentions that different hyperparameter sets are used per dataset, which is not ideal. However, the comment does not specify which part of the paper discusses the neighborhood size or the hyperparameter sets, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing insights into performance variation with a constant set of parameters. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the paper is missing an analysis of the value of neighborhood size h and its influence on the model\\'s performance. It also notes that different hyperparameter sets are used per dataset, which is not ideal. The comment suggests that the authors should provide insights into how performance varies with a constant set of parameters. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issues. Therefore, the claim is somewhat verifiable, as it provides a general direction but lacks detailed justification or evidence.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement in the paper: the lack of analysis regarding the neighborhood size h and the use of different hyperparameter sets per dataset. It highlights the importance of providing insights into how performance varies with a constant set of parameters and analyzing the influence of h on the model\\'s performance. This feedback is clear and actionable, as it directs the authors to address specific aspects of their work that could enhance its robustness and clarity. However, the comment could be more helpful if it provided more detailed guidance on how to conduct the analysis or what specific metrics to consider. Overall, the comment is mostly helpful, as it offers valuable insights that can guide the authors in improving their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. While the comment prompts the authors to consider these aspects, it does not provide explicit instructions or suggestions on how to address these questions or incorporate them into the paper. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not specify which part of the paper addresses this issue, making it weakly grounded. It is specific in detailing the question about the model's behavior with imperfect multimodal data, but without explicit references to sections or figures, the authors cannot confidently identify the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It asks about the impact on the model and whether it can leverage additional modalities to infer missing ones. However, the comment does not provide any evidence, reasoning, or references to support these claims or questions. Without additional context or justification, the authors are left to interpret the questions as speculative, making the comment unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises important questions about the model's performance when multimodal data is imperfect, specifically when certain modalities are missing. It prompts the authors to consider the impact on the model and whether it can leverage additional modalities to infer missing ones. This feedback is valuable as it highlights a potential area for further exploration and analysis, which could enhance the robustness and applicability of the model. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these questions or incorporate them into the paper. Overall, the comment is somewhat helpful, as it identifies a relevant area for improvement but lacks depth and actionable advice.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment suggests an analysis, it does not provide explicit guidance on how to conduct this analysis or what specific actions the authors should take. The action is implicit and somewhat vague, as the authors are left to infer that they need to analyze the dataset and provide statistics. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"General Discussion,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear question and suggestion for analysis, asking for statistics on the effectiveness of negation or intensity words in the SST dataset. This guidance is detailed and specific, making the comment fully grounded and specific.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. While the comment does not contain a subjective claim, it suggests an analysis that could be beneficial for the paper. However, it lacks specific examples or references to support the suggestion, making it somewhat verifiable. The authors would need to infer the need for this analysis, which limits the verifiability of the comment.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about the effectiveness of negation or intensity words in the SST dataset, specifically asking for statistics on how often these words change the polarity of the context. This feedback is somewhat helpful as it identifies a potential area for further analysis that could enhance the understanding of the dataset's characteristics. However, the comment lacks detailed guidance or suggestions on how to conduct this analysis, which limits its impact on the authors. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the authors\\' draft, noting that they do not verify the stability of the OGE-Aug model on OOD benchmarks like DrugOOD, where SPE [2] is validated. This feedback is explicit and provides a clear action for the authors to take, which is to verify the stability of their model on these benchmarks. The comment is specific in its suggestion, guiding the authors to address a particular aspect of their work. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the stability of the OGE-Aug on OOD benchmarks such as DrugOOD,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of verification of the model\\'s stability on these benchmarks. The comment provides a clear direction for the authors to take, making it fully grounded and specific. Therefore, this comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors do not verify the stability of the OGE-Aug model on OOD benchmarks such as DrugOOD, where SPE [2] is validated. This claim is somewhat verifiable as it points out a specific issue related to the evaluation of the model\\'s stability. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to provide more context or evidence to fully understand the implications of this feedback.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the authors\\' draft, noting that they do not verify the stability of the OGE-Aug model on OOD benchmarks such as DrugOOD, where SPE [2] is validated. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that needs verification. By highlighting this omission, the comment provides a concrete suggestion for improvement, which can help the authors enhance the robustness and reliability of their model. Therefore, the comment is mostly helpful, as it offers a clear and actionable direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors consider additional methods for parameter-efficient training, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. While the comment provides a direction for improvement by suggesting specific methods to explore, it does not explicitly instruct the authors on how to implement these suggestions or what specific aspects of the draft should be addressed. The action is implicit and somewhat vague, as the authors need to infer the need for further experimentation and consider how to integrate these methods into their work. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests considering additional methods for parameter-efficient training, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. However, it does not specify which part of the paper this suggestion relates to, making it weakly grounded. The comment is specific in its suggestion to explore alternative methods for parameter-efficient training, which could enhance the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests considering additional methods for parameter-efficient training, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. This is a suggestion for improvement, but it lacks specific examples or references to support why these methods are relevant or beneficial. The comment does not provide detailed reasoning or evidence to justify the suggestion, making it difficult for the authors to understand and implement the proposed changes. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests considering additional methods for parameter-efficient training, such as freezing layers or using LoRA, in addition to applying SVD to BERT embeddings. This feedback is somewhat helpful as it provides a direction for the authors to explore alternative approaches that could enhance the efficiency and effectiveness of their model. However, the comment lacks specific guidance on how to implement these suggestions or what aspects of the draft should be addressed. While it offers a valuable insight, the feedback could be more impactful with additional details or examples. Therefore, the comment is rated as somewhat helpful, corresponding to a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide explicit guidance on how to expand the section or what specific baselines should be included. The action is implicit, as the authors need to infer that they should add comparisons to these baselines, but it lacks concrete details on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a general direction but lacks specific guidance on execution.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not specify which part of the paper the related work section is located, nor does it provide any guidance on which baselines should be included or how to compare them. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment is not specific about the nature of the comparison or the criteria for selecting strong baselines. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis for this suggestion or how to implement it effectively. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests expanding the related work section by comparing the current work to strong baselines that use coordinates. This feedback is somewhat helpful as it points out a potential area for improvement by highlighting the need for a more comprehensive comparison with existing baselines. However, the comment lacks specificity and does not provide detailed guidance on which baselines to include or how to structure the comparison. This leaves the authors with a general direction but without actionable steps to enhance their work. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the experiments are limited to training on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment implies that multiple seed experiments would provide a more robust evaluation. However, it does not explicitly instruct the authors to conduct multiple seed experiments or provide detailed guidance on how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer that they should perform multiple seed experiments to address the issue. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the limitation of the experiments being conducted on a single seed, which makes it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. However, the comment does not specify which part of the paper this issue is discussed in, such as a particular section or figure. This lack of grounding makes it challenging for the authors to identify the exact area that needs improvement. While the comment is specific in its critique of the experimental setup, the absence of explicit grounding makes it difficult for the authors to understand where to focus their attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the experiments are limited to training on a single seed, making it difficult to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that multiple seed experiments would provide a more robust evaluation. However, the claim lacks specific examples or references to support the assertion that single seed experiments are insufficient for assessing the significance of performance differences. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant limitation in the experimental setup, noting that the experiments are conducted using a single seed, which makes it challenging to assess the significance of performance differences and the true impact of the proposed cycle consistency loss on convergence. The comment suggests that conducting multiple seed experiments would provide a more robust evaluation, which is a valuable and actionable piece of feedback. However, the comment could be more helpful by providing specific guidance on how to implement multiple seed experiments or by suggesting alternative methods for evaluating the significance of the results. Despite this, the feedback is mostly helpful as it directs the authors towards a crucial improvement in their experimental design, enhancing the reliability and robustness of their findings. Therefore, the comment is rated as 4: Mostly Helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. While it highlights a lack of clarity in the motivation, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the motivation need clarification. The action is implicit, as the authors would need to infer that they should provide a clearer explanation of the motivation behind their choice of distributions. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact section they need to address. While the comment is specific in questioning the motivation, the absence of grounding information limits its usefulness. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. However, it does not provide any specific reasoning, examples, or references to support why this choice is unclear or problematic. Without additional context or justification, the claim remains unverifiable. Therefore, the comment is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the motivation behind using the VMF distribution and the truncated normal distribution to characterize the angle and magnitude of the target vector. It highlights a lack of clarity in the rationale behind these choices, which could hinder the understanding and reproducibility of the research. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their methodology. While it identifies an important area for improvement, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a concern regarding the accessibility of the proposed method due to the requirement of a multi-GPU setup for optimizations. It suggests that this requirement might limit the potential users who can access or implement the method. However, the comment does not provide any explicit or implicit actions for the authors to take to address this issue. It lacks specific guidance on how to make the method more accessible or how to justify the need for a multi-GPU setup. Without actionable steps or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"optimizations in the proposed method\" and the \"requirement of a multi-GPU setup,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly explains the issue of accessibility due to the need for a multi-GPU setup, which could limit potential users. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the requirement of a multi-GPU setup for the proposed method makes it inaccessible to many potential users. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the accessibility of the proposed method due to the requirement of a multi-GPU setup for optimizations. This is a valid concern that could limit the potential users who can access or implement the method. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or make the method more accessible. Without actionable feedback or detailed suggestions, the authors may find it challenging to improve their draft based on this comment alone. Therefore, the comment is somewhat helpful, as it highlights a potential weakness but does not provide comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the current system captures semantics through RNN-based models and recommends comparing it with another system that also captures semantics. It also suggests using Ref-[2] as a strong baseline for comparison. However, the comment does not provide explicit guidance on how to implement these suggestions, such as which specific aspects of the comparison should be highlighted or how the performance of the current system should be evaluated against the baseline. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests comparing the current system with another system that captures semantics, implying a need for comparison. However, it does not specify which part of the paper this comparison should be made or which sections of the paper are relevant. The comment is weakly grounded as the authors cannot confidently determine which part of the paper it addresses. It is also specific in suggesting a comparison with Ref-[2] as a strong baseline, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests comparing the current system with another system that captures semantics, recommending Ref-[2] as a strong baseline. However, it lacks specific details or references to support the claim that Ref-[2] is a strong baseline. The comment does not provide a clear rationale or evidence for why this comparison is necessary or how it would benefit the paper. As a result, the claim is not verifiable, making the comment unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests comparing the current system with another system that captures semantics, recommending Ref-[2] as a strong baseline. However, it lacks specific guidance on how to implement this comparison or what aspects of the comparison should be highlighted. The suggestion to compare with another system that captures semantics is somewhat helpful as it points out a potential area for improvement, but it does not provide detailed instructions or examples to guide the authors in making the comparison. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects of the model or assumptions need to be investigated. Without concrete suggestions or a clear path forward, the authors are left without actionable steps to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact area that needs attention. The comment is vague and lacks specificity, as it does not provide detailed guidance on what needs to be addressed or how to approach the issue. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment does not provide any specific evidence, reasoning, or references to support the claim that the model does not fully succeed. Without additional context or justification, the authors are left without a clear understanding of how to address the issue or what specific aspects of the model or assumptions need to be investigated. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about why the model does not fully succeed in identifying the true sources in the triangle dataset, suggesting that one of the assumptions might not be satisfied or that there are learning difficulties. However, the comment does not provide any specific guidance or suggestions on how the authors might address this issue or what steps they could take to improve their model. It lacks actionable advice and detailed insights, making it difficult for the authors to understand how to proceed. As a result, the comment is barely helpful, as it identifies a potential problem but does not offer constructive feedback or actionable steps for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the suitability of the metrics used for evaluating continual learning in specific settings, noting that these metrics are not applicable when task boundaries are unknown or non-existent. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative metrics. The comment lacks concrete actions or suggestions for improvement, leaving the authors without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment critiques the suitability of the metrics used for evaluating continual learning, specifically mentioning that they are not applicable in settings where task boundaries are unknown or non-existent. However, it does not specify which part of the paper discusses these metrics or the datasets used. This makes it difficult for the authors to identify the exact section or part of the paper that needs revision. While the comment is specific about the issue of metric applicability, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point critiques the suitability of the metrics used for evaluating continual learning, specifically mentioning that they are not applicable in settings where task boundaries are unknown or non-existent. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or evidence, the claim remains somewhat verifiable, as it lacks the necessary depth and context to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue with the metrics used for evaluating continual learning, noting that they are not suitable for settings where task boundaries are unknown or non-existent. This critique is valuable as it highlights a limitation in the paper's evaluation methodology, which could impact the validity of the results. However, the comment does not provide actionable suggestions or guidance on how the authors might address this issue or improve their evaluation approach. While it points out a potential weakness, it lacks depth and does not offer concrete steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their draft. As a result, the authors are left without a clear understanding of what to do next, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not specify which part of the paper this question pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to identify the exact part of the paper being addressed. While the comment is specific in its question about the rationale, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. However, it does not provide any claim, suggestion, or reasoning to support this question. The comment lacks any evidence or justification, making it unverifiable. Therefore, it is classified as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the rationale behind using only the information up to time step t in the user decoder, instead of using information from all time steps. This question highlights a potential area for clarification or further explanation in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes they should consider making to their draft. Without actionable feedback or suggestions, the authors are left without a clear understanding of how to improve their work. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and guidance.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations, should be considered. However, the comment does not provide explicit guidance on how to implement this controlled baseline or what specific experiments should be conducted to address this issue. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific issue related to the different locations of induction heads and FV heads within the model, which could be a confounding factor affecting ICL performance. It suggests that a controlled baseline should be considered to ablate heads at different locations. However, the comment does not explicitly mention which part of the paper this issue is discussed, making it weakly grounded. The comment is specific in detailing the potential confounding factor and suggesting a controlled baseline, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the different locations of induction heads and FV heads within the model, suggesting that this could be a confounding factor affecting the performance difference when ablating these heads. The comment implies that a controlled baseline, where heads are ablated at different locations, should be considered. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, and the lack of detailed justification or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential confounding factor related to the different locations of induction heads and FV heads within the model, which could affect the performance difference when ablating these heads. It suggests that a controlled baseline, where heads are ablated at different locations, should be considered to address this issue. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by addressing the potential confounding factor. However, the comment could be more helpful if it included suggestions on how to implement the controlled baseline or what specific experiments should be conducted. Overall, the comment is mostly helpful, as it offers a clear and actionable suggestion for improvement.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point explicitly states that a section on synonym identification is missing under the similarity measurement section, which describes how the multiple-choice task is approached. This provides a clear and direct action for the authors to take, namely to include this section in their draft. The comment is explicit and concrete, as it specifies exactly what is missing and where it should be added. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"similarity measurement\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the missing section, \"a section on synonym identification,\" which describes how the multiple-choice task is approached. This provides the authors with a clear understanding of what is missing and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that a section on synonym identification is missing under the similarity measurement section, which describes how the multiple-choice task is approached. However, the comment does not provide any reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it difficult to understand why this section is missing or how it impacts the paper. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the paper by pointing out the absence of a section on synonym identification under the similarity measurement section. This is a clear and actionable piece of feedback that would help the authors improve their draft by ensuring all relevant aspects are addressed. The comment is specific and provides a clear direction for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific guidance on how to create this overview or what aspects should be included. The comment is vague and lacks concrete instructions, leaving the authors uncertain about how to implement the suggested improvement. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not specify which part of the paper this overview should be included in or how it should be structured. The authors cannot confidently determine which section or part of the paper is being addressed, making the comment weakly grounded. Additionally, the comment is specific in its suggestion to include an overview, but it lacks details on what aspects of the workflow and model should be covered. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that an overview of the workflow and the model would make it easier for readers to understand the work. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand why this suggestion is beneficial or how to implement it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment suggests that an overview of the workflow and the model would make it easier for readers to understand the work. While this feedback is relevant and could help the authors improve the clarity and accessibility of their paper, it lacks specific guidance on how to create such an overview or what aspects should be included. The comment is somewhat helpful as it identifies a potential area for improvement, but it does not provide detailed suggestions or actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. The comment implies that this issue should be discussed in the paper, but it does not provide explicit guidance on how to address it or what specific aspects of the paper need revision. The action is implicit and somewhat vague, as the authors are left to infer that they need to discuss the issue of bias in the sketch. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It suggests that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not specify which part of the paper discusses the sketch or the ridge regression problem, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of bias, it lacks grounding as it does not provide clear references to the relevant sections or parts of the paper. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It claims that this cannot be computed accurately without a significant runtime, potentially leading to bias that defeats the purpose of the approach. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand the basis of the concern and how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential issue with the feasibility of debiasing the sketch due to the need to know the statistical dimension d_lambda of the design matrix A. It points out that this cannot be computed accurately without a significant runtime, which could lead to bias that defeats the purpose of the approach. The comment suggests that this issue should be discussed in the paper, but it does not provide specific guidance on how to address it or what aspects of the paper need revision. While the feedback highlights a potential weakness, it lacks depth and actionable suggestions, making it somewhat helpful. The authors are left to infer the need for further discussion and may require additional guidance to fully understand the implications of the comment. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses a concern about the ablations in the paper, noting that they seem to raise many questions. However, it does not provide any specific guidance or suggestions on how the authors should improve the experiment setup or address these questions. The comment lacks explicit actions or concrete details, leaving the authors uncertain about what changes to make. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment expresses concerns about the ablations in the paper, noting that they raise many questions. However, it does not specify which part of the paper the ablations are discussed in, nor does it provide any guidance on how to address these questions or improve the experiment setup. The lack of specific grounding makes it difficult for the authors to understand which section or aspect of the paper needs attention. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point expresses concerns about the ablations in the paper, noting that they raise many questions. However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses concerns about the ablations in the paper, noting that they raise many questions. However, it lacks specificity and actionable suggestions, making it difficult for the authors to understand the issues or how to address them. Without detailed feedback or guidance, the comment does not provide substantial value for improving the draft. Therefore, it is rated as barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a weakness in the paper by noting that while a reasonable argument is made about the usefulness of the proposed models for learning representations of low-frequency words, no empirical evidence is provided to support this claim. The comment suggests that the authors could have explored this aspect further, which implies an action to conduct additional experiments or analysis. However, the comment does not specify how to conduct these experiments or what specific data to use, making the action somewhat vague. The feedback is explicit in identifying the need for empirical evidence but lacks concrete guidance on how to achieve this. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses a specific aspect of the paper by focusing on the usefulness of the proposed models for learning representations of low-frequency words. It highlights that while a reasonable argument is made, no empirical evidence is provided to test the hypothesis. The comment suggests that the authors could have looked deeper into this aspect, implying a need for further exploration. However, the comment does not explicitly mention which part of the paper discusses this aspect, making it weakly grounded. It is specific in identifying the need for empirical evidence and questioning the lack of explanation regarding improvements, such as the use of word similarity datasets. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that no empirical evidence is provided to test the hypothesis about the usefulness of the proposed models for learning representations of low-frequency words. However, the comment does not offer any specific examples, references, or detailed reasoning to support this claim. The lack of evidence or justification makes it difficult for the authors to understand why this claim is valid or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a specific area where the paper could be strengthened by providing empirical evidence to support the claim about the usefulness of the proposed models for learning representations of low-frequency words. It highlights the absence of such evidence and suggests that the authors could explore this aspect further, which is a valuable piece of feedback. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct the additional experiments or analysis. Without concrete examples or detailed instructions, the authors may find it challenging to fully address the feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the error analysis on the movie dataset, noting that it is missing. It suggests that the authors should provide information on the cases where the model fails to help other researchers continue with the task. However, the comment does not offer explicit guidance on how to address this issue or what specific information should be included in the error analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to add a detailed error analysis section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"error analysis on the movie dataset,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the missing error analysis, and suggests that the authors should provide information on the cases where the model fails to help other researchers continue with the task. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the error analysis on the movie dataset is missing, which is a factual observation. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the context or address the issue effectively. The comment lacks detailed reasoning or evidence, which limits its verifiability. Therefore, it is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper, specifically noting the absence of error analysis on the movie dataset. This is a critical oversight as it hinders the ability of other researchers to build upon or understand the limitations of the model. The comment is clear and actionable, providing a direct suggestion for improvement by emphasizing the need for detailed error analysis. However, it could be more helpful if it offered additional guidance on how to conduct or present the error analysis effectively. Overall, the comment is mostly helpful as it highlights a crucial area for improvement, but it could be more comprehensive with additional suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on what those details should include. The authors are left without a clear understanding of what information is needed to address the issue, making the comment somewhat vague and lacking in actionable guidance. Therefore, this comment is rated as 2: Borderline Actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment indicates that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which part of the paper contains these missing details, making it difficult for the authors to identify the exact section or part that needs attention. Additionally, the comment lacks specificity, as it does not provide any guidance on what these missing details are or how they should be addressed. Therefore, this comment is weakly grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the nature of the missing details or how to address them. Without additional context or evidence, the claim remains vague and lacks verifiability. Therefore, this comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that some details of the proposed method are missing, referencing a \"questions section below.\" However, it does not specify which details are missing or provide any guidance on how to address this issue. The feedback is vague and lacks actionable suggestions, leaving the authors without a clear understanding of what information is needed to improve their draft. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment suggests that the authors should include an ablation study, but it does not specify how to conduct it or what components to analyze. Without concrete guidance, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment highlights a specific issue with the lack of ablation analysis in the main paper, which makes it difficult to determine the source of a small performance gain. However, it does not specify which part of the paper lacks ablation analysis or provide any guidance on how to address this issue. The comment is not grounded as it does not mention specific sections, tables, or figures, and it is not specific because it does not detail what kind of ablation analysis would be beneficial. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the lack of ablation analysis in the main paper makes it difficult to determine the source of a small performance gain. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the lack of ablation analysis makes it difficult to determine the source of a small performance gain. This feedback is clear and actionable, as it highlights a critical gap in the analysis that could impact the paper's conclusions. However, the comment could be more helpful if it provided suggestions on how to conduct the ablation analysis or what components to analyze. Despite this, the comment offers valuable guidance for the authors to improve their draft, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). It also mentions that the authors use a threshold (Th.) in their experiments. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how to address this observation or incorporate the threshold into their work. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"2,\" which allows the authors to accurately identify the part of the paper being addressed. It also specifies what the authors should do, namely, to show that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels. This provides clear guidance on how to address the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that when the number of classes is large (>8), the noise rate of similarity labels is less than class labels, and the authors use a threshold (Th.) in their experiments. However, the comment does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left without a basis to understand or verify the claim. Therefore, the comment is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides a specific observation about the noise rate of similarity labels compared to class labels when the number of classes is large (>8). It also mentions that the authors use a threshold (Th.) in their experiments. However, the comment lacks actionable guidance or suggestions on how the authors might address this observation or incorporate the threshold into their work. Without specific advice or steps to improve the draft, the feedback is limited in its usefulness to the authors. Therefore, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point indicates that the CNN experiments are not fully convincing but does not provide any specific details or suggestions on how to improve them. The comment lacks explicit guidance on what aspects of the experiments need to be addressed or how the authors should enhance the results. Without concrete actions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is not grounded as it does not specify which part of the paper the CNN experiments are discussed in, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment is not specific because it does not provide details on what aspects of the experiments are not convincing or how the authors might address this issue. Without specific guidance or examples, the authors cannot effectively respond to the comment. Therefore, this comment is rated as Not Grounded and Not Specific, corresponding to a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point claims that the CNN experiments are not fully convincing, but it does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors are left without a clear understanding of why the experiments are not convincing or how they might address this issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment expresses concern about the CNN experiments, stating they are not fully convincing. However, it lacks specific details or suggestions on how the authors might address this issue or improve the experiments. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but does not provide sufficient depth or direction for the authors to act upon.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper should place more emphasis on prompt design, noting that different prompts can lead to varying performance outcomes. It implies that the authors should discuss effective prompt design strategies. However, the comment does not provide specific guidance on how to implement this suggestion, such as which aspects of prompt design should be emphasized or what techniques should be discussed. The action is implicit and somewhat vague, as the authors need to infer the specific areas where more emphasis is needed. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. It is specific in detailing the need for more emphasis on prompt design and the importance of discussing effective strategies, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper should place more emphasis on prompt design, particularly in the context of MenatQA. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. However, the comment lacks specific examples or references to support the claim that different prompts may result in varying performance outcomes or how to effectively design prompts. Without detailed examples or references, the authors may find it challenging to fully understand and address the issue. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific area for improvement in the paper, suggesting that more emphasis should be placed on prompt design. It highlights the importance of discussing how different prompts can lead to varying performance outcomes and emphasizes the need for effective prompt design strategies. This feedback is clear and actionable, providing the authors with a specific direction to enhance their work. However, the comment could be more helpful if it offered additional guidance on which aspects of prompt design should be emphasized or what techniques could be used to improve prompt design. Despite this, the comment is mostly helpful as it directs the authors towards a crucial area of improvement, making it a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. While the comment implies that the authors should consider using adaptive methods, it does not provide explicit guidance on how to implement this change or what specific aspects of the current method need to be addressed. The action is implicit and somewhat vague, as the authors are left to infer that they should explore adaptive methods. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. However, it does not specify which part of the paper this question pertains to, such as a particular section or table. This lack of grounding makes it difficult for the authors to pinpoint the exact area that needs clarification. While the comment is specific in its questioning of the method, the absence of explicit grounding makes it challenging for the authors to understand the context and address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. However, it does not provide any evidence, reasoning, or references to support the claim that adaptive methods are superior or why freezing is necessary. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about the use of freezing in MLS selection, specifically questioning why it is used when adaptive methods might be more effective. This feedback highlights a potential area for clarification and improvement in the paper, as it challenges the authors to justify their choice of method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue. While it identifies a potential weakness, it does not offer actionable advice or detailed insights, making it somewhat helpful. Therefore, the comment aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It also recommends performing a similar analysis on the proposed model. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions or detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors are left to infer the exact steps needed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It references a specific paper (https://arxiv.org/abs/2104.06378) to support the claim. However, the comment does not explicitly mention which part of the paper it is addressing, making it weakly grounded. It is specific in suggesting that the authors perform a similar analysis on their proposed model, but the lack of explicit grounding makes it difficult for the authors to pinpoint the exact section or part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It references a specific paper (https://arxiv.org/abs/2104.06378) to support the claim. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the connection between the existing work and the proposed model, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about whether the proposed knowledge-CLIP model addresses a specific issue and suggests that existing work has performed similar analyses. It references a specific paper to support the claim, providing a basis for comparison. However, the comment lacks detailed guidance on how the authors might perform such an analysis or what specific aspects of the model they should focus on. While it identifies an area for improvement, it does not offer actionable steps or suggestions for the authors to take, making it somewhat helpful. The feedback is valuable but could be more comprehensive if it provided more detailed guidance or examples.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is an explicit action that the authors can directly implement by adding a brief explanation in the relevant section of the paper. The comment is specific and provides a clear direction for improvement, allowing the authors to know exactly what needs to be addressed. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"l.97,\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it suggests that the authors should consider explaining how novel values in the test set are handled for clarity, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the authors should consider explaining how novel values in the test set are handled for clarity. This is a suggestion for improvement, but it lacks specific details or examples of how this explanation could be provided. Without additional context or guidance, the authors may find it challenging to understand the exact nature of the suggestion or how to implement it. Therefore, the comment is considered borderline verifiable, as it provides some indication of what needs to be addressed but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by pointing out that the authors should consider explaining how novel values in the test set are handled for clarity. This feedback is actionable and directly addresses a potential area of confusion or lack of understanding in the paper. By providing a clear direction for improvement, the comment empowers the authors to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to explain the handling of novel values, such as suggesting specific examples or techniques. Overall, the comment is mostly helpful as it identifies a clear area for improvement and provides a starting point for the authors to enhance their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point mentions that similar methods have been proposed for multi-task learning but does not discuss them in the paper, referencing a specific work [1]. While it implicitly suggests that the authors should discuss these methods, the action is not explicit, and the authors are left to infer that they need to address this gap. The comment lacks concrete guidance on how to incorporate or discuss these methods, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"multi-task learning,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out that similar methods have been proposed but are not discussed in the paper, referencing a specific work [1]. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the label is 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that similar methods have been proposed for multi-task learning but are not discussed in the paper, referencing a specific work [1]. This claim is somewhat verifiable as it provides a reference to support the assertion that similar methods exist. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment points out that similar methods have been proposed for multi-task learning but are not discussed in the paper, referencing a specific work [1]. This feedback is somewhat helpful as it identifies a gap in the paper's discussion of related work. However, it lacks depth and actionable suggestions for the authors to address this issue. The comment does not provide guidance on how to incorporate or discuss these methods, leaving the authors with limited direction for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not provide explicit instructions or suggestions on how the authors should conduct this comparison or what specific aspects of the computation should be considered. The action is implicit and vague, as the authors are left to infer that they need to perform a comparison. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment questions whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not specify which part of the paper this comparison should be made or which methods are being referred to. The lack of specific grounding makes it difficult for the authors to identify the exact section or aspect of the paper that needs attention. Additionally, the comment does not provide any guidance on how to conduct the comparison or what specific aspects of the computation should be considered. As a result, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. However, it does not provide any specific evidence, reasoning, or references to support this claim. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about whether the authors have compared the computational cost of FedMITR with other methods, which is expected to be higher. While it identifies a potential area for further analysis, it does not provide specific guidance or suggestions on how the authors might approach this comparison or what aspects of the computation should be considered. The comment is somewhat helpful as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it only marginally helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment provides explicit questions and suggestions, it does not offer concrete guidance on how to address these issues or what specific actions the authors should take. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises questions about the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not specify which part of the paper these questions or suggestions relate to, making it difficult for the authors to identify the exact sections or elements being addressed. The comment is not grounded as it lacks specific references to sections, tables, or figures. While it provides some specificity in terms of the questions and suggestions, the lack of grounding makes it challenging for the authors to understand the context and relevance of the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. However, it does not provide any specific reasoning, examples, or references to support these claims. The questions and suggestions are vague and lack detailed justification, making it difficult for the authors to understand the basis of the feedback or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises several questions and suggestions regarding the choice of 0.6 for glove embedding similarity, the use of k-cross-validation, and the potential impact of using other influential loss functions, such as mean or NDCG. While the comment provides some guidance on potential improvements, it lacks specific details or actionable steps for the authors to take. The questions and suggestions are somewhat helpful as they point out areas for further exploration and refinement, but they do not offer comprehensive or detailed feedback. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point provides several suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also suggests that the current approach of training on labeled data with a few input mask explanation annotations might be too simplistic, and the reviewer expresses skepticism about its effectiveness. However, the comment does not offer specific guidance on how to implement these suggestions or address the skepticism. The action is somewhat vague, as the authors are left to infer how to apply the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment provides specific suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also suggests that the current approach of training on labeled data with a few input mask explanation annotations might be too simplistic, and expresses skepticism about its effectiveness. However, the comment does not specify which part of the paper these suggestions relate to, making it weakly grounded. The specificity of the comment is moderate as it provides some guidance but lacks detailed examples or references. Therefore, the comment is weakly grounded and specific, aligning with label 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the effectiveness of the proposed method, suggesting that the current approach might be too simplistic and that robustness/domain invariance interventions have failed in the past. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the skepticism. The reasoning is logical but lacks detailed evidence, which could be improved with additional references or examples. Therefore, the comment is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment provides several suggestions for improving the paper, such as using modern backbone baselines like ResNet50 or DenseNet121 for feature extraction, which is a concrete action. It also suggests that the current approach of training on labeled data with a few input mask explanation annotations might be too simplistic, and expresses skepticism about its effectiveness. However, the comment does not offer specific guidance on how to implement these suggestions or address the skepticism, leaving the authors with limited actionable feedback. The feedback is somewhat helpful as it identifies areas for improvement but lacks depth and detail, making it only partially beneficial for the authors to enhance their draft. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search. It recommends ensuring that the baseline is fully tuned with similar resources to the proposed method for a fair comparison. However, the comment does not provide explicit guidance on how to conduct this tuning or what specific steps should be taken. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, recommending that the baseline be fully tuned with similar resources for a fair comparison. However, the comment does not specify which part of the paper discusses the hyperparameters or the experimental setup, making it weakly grounded. It is specific in suggesting the need for a fair comparison, but without clear references, the authors may struggle to identify the exact sections to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the paper introduces multiple hyperparameters and conducts an extensive hyperparameter search, recommending that the baseline be fully tuned with similar resources for a fair comparison. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. Without additional context or references, the claim is considered borderline verifiable, as it provides a general idea but lacks sufficient justification.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a potential issue with the paper, specifically the extensive hyperparameter search conducted, and suggests that ensuring the baseline is fully tuned with similar resources could lead to a fairer comparison. This feedback is somewhat helpful as it highlights a potential area for improvement in the experimental setup. However, the comment lacks specific guidance on how to conduct this tuning or what specific steps should be taken to ensure a fair comparison. The suggestion is clear but could be more actionable with additional details or examples. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques the definition of perplexity provided in the paper, specifically mentioning that it does not align with the actual definition of perplexity and that Equation 1 appears to be more similar to cross-entropy. While the comment identifies a specific issue with the definition, it does not provide explicit guidance on how the authors should revise their definition or Equation 1. The action is implicit, as the authors would need to infer that they need to correct the definition and potentially adjust Equation 1. However, the lack of concrete instructions on how to implement these changes makes the comment somewhat actionable. Therefore, this comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"L259\" and \"Equation 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the definition of perplexity and Equation 1, explaining that the current definition does not align with the actual definition of perplexity and that Equation 1 resembles cross-entropy. This provides the authors with clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the definition of perplexity on line 259 is incorrect and that Equation 1 is more similar to cross-entropy. This claim is supported by the authors' critique of the definition and the comparison with Equation 1. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific issue with the definition of perplexity in the paper, pointing out that it does not align with the actual definition. It also critiques Equation 1, suggesting that it is more similar to cross-entropy than perplexity. This feedback is clear and actionable, as it provides the authors with specific areas to reconsider and improve their understanding of perplexity. However, the comment could be more helpful if it offered suggestions on how to revise the definition or Equation 1 to align with the correct understanding of perplexity. Despite this, the comment is mostly helpful as it directs the authors to areas needing clarification and correction, which is valuable for improving the draft. Therefore, the comment is rated as 4: Mostly Helpful.\", 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment raises a major concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It suggests that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive evaluation of their defense strategies. The comment is specific in its suggestion, detailing the type of adversarial attack that should be considered. Therefore, the claim is fully verifiable as it provides a clear and actionable direction for improvement.', 'verifiability_label': '5', 'helpfulness_rationale': 'The review comment raises a significant concern about the evaluation of the proposed strategies, specifically the method of purifying the input image before passing it to the model. It highlights that an adaptive attack against the edge map-based defense strategies could result in structural damage to the edge map. However, the reviewer emphasizes the need to evaluate the proposed defense against an adversarial attack that crafts adversarial examples to produce minimal structural alterations to the edge map but mislead the model predictions. This feedback provides a clear and actionable suggestion for the authors to enhance their evaluation process, ensuring that their defense strategies are robust against more sophisticated attacks. By addressing this concern, the authors can significantly improve the reliability and effectiveness of their proposed methods. Therefore, the comment is highly helpful, as it offers a specific and constructive direction for improvement.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the experimental results, noting that they lack standard deviations, making it difficult to assess the significance of the results. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue, such as including standard deviations in future experiments or analyses. Without concrete guidance on how to improve the results, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the experimental results,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as the lack of standard deviations, which makes it difficult to judge the significance of the results. This provides the authors with a clear understanding of what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the experimental results do not contain standard deviations, making it difficult to judge the significance of the results. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the experimental results, noting that they lack standard deviations, which makes it challenging to judge the significance of the results. This feedback is clear and actionable, as it highlights a critical aspect of the experimental analysis that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how the authors might include standard deviations or discuss their implications. Despite this, the comment offers valuable guidance for improving the clarity and rigor of the experimental results, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a limitation in the quality of generated images by the proposed method, noting that while continuous control is achieved, the realism of the results is limited. However, it does not provide any specific suggestions or actions for the authors to take to address this issue. The comment lacks explicit guidance on how the authors might improve the realism of their generated images, leaving them without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"paper\" and \"supplemental material,\" allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issue with the quality of generated images, noting that while continuous control is achieved, the realism of the results is limited. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the quality of generated images by the proposed method is limited, noting that while continuous control is achieved, the realism of the results is limited. However, the comment does not provide any specific evidence, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the quality of generated images, noting that while continuous control is achieved, the realism of the results is limited. This feedback is clear and actionable, as it highlights a key area for improvement in the paper. However, it could be more helpful if it provided suggestions on how to enhance the realism of the generated images or suggested specific techniques that could be employed. Despite this, the comment offers valuable guidance for the authors to address the identified weakness, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point critiques a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counter-argument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any explicit or implicit suggestions on how the authors should revise or improve their draft to address this critique. The authors are left without guidance on what specific changes to make or how to clarify the issue. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions specific lines (559-560) in the paper, allowing the authors to accurately identify the part being addressed. It also specifies what is incorrect, suggesting that the claim made in the paper is not entirely true and providing a counter-argument about the Cycle Consistency loss. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement on lines 559-560 is not entirely true, specifically regarding the Cycle Consistency loss. It provides a counter-argument, suggesting that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to verify the accuracy of the statement or understand the basis of the critique. Without detailed evidence or examples, the claim remains somewhat verifiable, as it lacks the necessary support to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment identifies a specific claim made in the paper regarding the Cycle Consistency loss, suggesting that it is not entirely accurate. It provides a counter-argument, stating that the loss can be iterated between two phases of reconstructions with two separate standard backpropagation processes. However, the comment does not offer any suggestions or guidance on how the authors might revise or improve their draft to address this critique. While it points out a potential issue, it lacks actionable advice, leaving the authors without a clear path forward. Therefore, the comment is barely helpful, as it identifies a problem but does not provide sufficient guidance for improvement.\", 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights specific areas where details are missing in the paper, particularly regarding the grammar over kernels and the probabilities associated with it. It also questions the clarity of how inference is performed. While the comment identifies the need for more detailed explanations, it does not provide explicit instructions on how to address these issues or what specific actions the authors should take. The feedback is somewhat vague, as it leaves the authors to infer the necessary steps to improve the draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses specific issues related to the models and grammars used in the paper, particularly focusing on the lack of detail regarding the grammar over kernels and the probabilities associated with it. It also questions the clarity of how inference is performed. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The specificity of the comment is high as it clearly identifies the areas needing more detail and explanation. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises concerns about the lack of detail regarding the grammar over kernels and the probabilities associated with it, questioning the clarity of how inference is performed. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The feedback is somewhat vague, as it leaves the authors to infer the need for more detailed explanations and examples. Therefore, the comment is rated as 3: Somewhat Verifiable, as it provides some basis for understanding the issue but lacks sufficient detail to fully substantiate the claims.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies specific areas where the paper lacks detail, particularly regarding the grammar over kernels and the probabilities associated with it. It questions the clarity of how inference is performed, which is a crucial aspect for understanding the practical application of the approach. While the comment highlights these issues, it does not provide specific suggestions or guidance on how to address them. The feedback is somewhat helpful as it points out areas needing improvement, but it lacks depth and actionable advice, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include qualitative results, possibly with zoomed-in views, for cases where previous methods failed but are okay with the proposed method. It also recommends showing failure cases and analyzing the limitations. While the comment provides a clear direction for improvement, it lacks specific guidance on how to present these qualitative results or what specific aspects of the failure cases should be analyzed. The authors are aware of the need to include these elements but may struggle to know exactly how to implement the suggestions. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests including qualitative results, zoomed-in views, and analysis of failure cases, which are relevant to the paper. However, it does not specify which part of the paper these elements should be included in, making it weakly grounded. The comment is specific in its suggestions, as it clearly indicates what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests including qualitative results, zoomed-in views, and analysis of failure cases, which are valuable additions to the paper. However, the comment lacks specific examples or references to support these suggestions, making it difficult for the authors to understand how to implement them effectively. Without detailed guidance or examples, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully actionable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests including qualitative results, zoomed-in views, and analysis of failure cases, which are valuable additions to the paper. By providing these elements, the authors can enhance the depth and impact of their work. However, the comment lacks specific guidance on how to present these qualitative results or what aspects of the failure cases should be analyzed. While it offers a clear direction for improvement, the feedback could be more helpful if it included examples or suggestions for specific analyses. Overall, the comment is somewhat helpful, as it identifies areas for enhancement but does not provide detailed guidance for implementation.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This provides a clear and explicit action for the authors to take, as they can directly address the ambiguity in the title. The comment is specific in its suggestion, detailing exactly what needs to be done to improve the clarity of the title. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. However, it does not provide specific guidance on which part of the paper this issue is related to, such as a particular section or figure. The authors may need to infer that the title is ambiguous based on the context of the paper, but the comment lacks full grounding. It is specific in its suggestion to clarify the title, but the lack of grounding makes it difficult for the authors to pinpoint the exact area that needs attention. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the title is ambiguous and could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This claim is somewhat verifiable as it provides a clear suggestion for improvement, but it lacks specific examples or references to support the claim fully. The authors would need to infer the need for clarification based on the context of the paper, which could be challenging. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential ambiguity in the title, suggesting that it could be clarified to specify that it refers to machine comprehension of text rather than human reading comprehension. This feedback is clear and actionable, as it provides a specific suggestion for improvement that the authors can easily implement. By addressing this ambiguity, the authors can enhance the clarity and precision of their paper, making it easier for readers to understand the scope of their work. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement without being overly detailed or vague.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. While the comment identifies a potential issue with the evaluation methodology, it does not provide explicit guidance on how the authors should address this concern or what specific changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider using a human metric instead of an automatic one. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, it does not specify which part of the paper discusses the human evaluation or the use of TSS. This makes it difficult for the authors to pinpoint the exact section or aspect that needs clarification. While the comment is specific about the issue of using an automatic metric, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions the use of an automatic metric TSS for human evaluation, suggesting that a human metric would be more convincing. However, the comment does not provide any specific reasoning, examples, or references to support why an automatic metric might be less convincing or why a human metric is preferable. Without additional justification or evidence, the claim lacks sufficient support, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a valid concern about the use of an automatic metric TSS for human evaluation, questioning its effectiveness compared to a human metric. This feedback highlights a potential weakness in the evaluation methodology, which could impact the convincingness of the human evaluation results. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or what alternative metrics could be considered. While it identifies an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, as it points out a potential issue but does not offer comprehensive guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. While the comment implies that the current experiments are sufficient to prove the point, it does not explicitly instruct the authors to include experiments across more diverse domains. The action is implicit, as the authors need to infer that they should conduct additional experiments to strengthen the paper. However, the comment lacks concrete guidance on which specific domains to include or how to design these experiments. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. However, it does not specify which part of the paper the experiments are currently discussed in, making it difficult for the authors to identify the exact section that needs improvement. The comment is specific in its suggestion to include experiments across more diverse domains, but it lacks grounding as it does not provide clear references or sections within the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2. However, the comment lacks specific examples or references to support this suggestion, making it difficult for the authors to understand the rationale behind the recommendation. Without detailed reasoning or examples, the claim is somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the experiments should be expanded to include more diverse domains, specifically mentioning TD-MPC 2, to strengthen the paper. This feedback is clear and actionable, as it provides a specific direction for improvement by recommending the inclusion of additional experiments. However, the comment could be more helpful if it offered guidance on how to select or design these additional experiments. Despite this, the suggestion is valuable and provides a clear path for the authors to enhance their work, making it mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two main issues with the authors' draft: the lack of confidence intervals for their results and the limited evaluation on only two datasets. While the comment identifies these areas as needing improvement, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to include confidence intervals and expand their evaluation to more datasets. This lack of explicit action makes the comment somewhat actionable, as the authors can deduce the necessary steps but do not have a clear roadmap for implementation. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the lack of confidence intervals for the results and the limited evaluation on only two datasets. It references specific papers in the RNP community, which provides context and suggests that the authors should consider expanding their evaluation to include more datasets. However, the comment does not explicitly mention which part of the paper discusses the results or the evaluation methodology, making it weakly grounded. The specificity of the comment is moderate as it clearly specifies the issues with the results and evaluation, but it could be more specific by detailing which parts of the paper need to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the authors do not show confidence intervals for their results, making it unclear whether performance gains are statistically significant. It also notes that the evaluation is limited to only two datasets, which are standard in the RNP community. The comment references specific papers in the RNP community, providing context and suggesting that the authors should consider expanding their evaluation. However, the claim lacks detailed reasoning or specific examples to fully support the assertion about the limited evaluation. The references provided are relevant but do not offer a comprehensive explanation of why the evaluation is limited to two datasets. Therefore, the comment is mostly verifiable, as it provides some justification but could be strengthened with more detailed reasoning or examples.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a critical issue with the authors' draft: the lack of confidence intervals for their results, which makes it difficult to assess the statistical significance of performance gains. It also points out that the evaluation is limited to only two datasets, which may not be sufficient to generalize the findings. The comment references specific papers in the RNP community, providing context and suggesting that the authors should consider expanding their evaluation to include more datasets. This feedback is clear and actionable, as it directs the authors to address the missing confidence intervals and broaden their evaluation. However, it could be more helpful if it provided specific guidance on how to calculate or incorporate confidence intervals or suggested additional datasets for evaluation. Overall, the comment is mostly helpful, as it highlights important areas for improvement and provides a clear direction for the authors to follow.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper's main contribution lies in demonstrating the effectiveness of combining existing techniques, rather than proposing novel ones. However, it does not provide explicit guidance on how the authors should address this point or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or detailed instructions on how to enhance the paper, leaving the authors uncertain about how to proceed. Therefore, the comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what needs to be addressed, namely the straightforward nature of the LUQ design and the standard approaches explored in previous literature. This provides clear guidance on how the authors should respond to the comment. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the LUQ is straightforward to design once the goal is clear and that the approaches in Section 5 are standard and explored in previous literature. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to verify the validity of the assertion. Without detailed evidence or examples, the claim remains somewhat verifiable, as the authors may need to conduct further research to substantiate the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential weakness in the paper by suggesting that the main contribution lies in demonstrating the effectiveness of combining existing techniques rather than proposing novel ones. This observation is insightful and could help the authors position their work more effectively within the existing literature. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional contributions they could make to enhance the paper. While it provides a valuable perspective, the feedback could be more helpful if it included actionable advice or suggestions for improvement. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While the comment implies that the authors should provide training losses to address the question, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are not given a clear direction on how to include the training losses or what specific information should be included. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not specify which part of the paper this question pertains to, such as a specific section or figure. The authors may infer that it relates to the methodology or experimental setup, but without explicit mention, they cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for training losses but lacks grounding as it does not pinpoint the relevant section. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. However, it does not provide any reasoning, examples, or references to support why this is a concern or how it might impact the results. The comment lacks specific details or evidence to substantiate the claim, making it difficult for the authors to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the stability of training a deep localization network with the differentiable Sinkhorn and suggests that the authors should include some training losses. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance or examples on how to address the concern. The comment is somewhat helpful as it points out a potential issue that could affect the robustness of the results, but it does not offer actionable advice or suggestions for improvement. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the training of RegMixup, suggesting that it sees 2x samples per iteration, which could lead to a slower running speed compared to other methods. The authors are informed that this could result in an unfair comparison. However, the comment does not provide explicit guidance on how to address this issue or what specific changes should be made to the training process. While the authors are aware of the potential problem, they are left without a clear path to resolve it. The action is implicit and somewhat vague, as it does not specify how to mitigate the unfair comparison or what modifications might be necessary. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"RegMixup,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the training process, noting that RegMixup sees 2x samples per iteration, which could lead to a slower running speed and an unfair comparison with other methods. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the training of RegMixup sees 2x samples per iteration, leading to a slower running speed and an unfair comparison with other methods. While the claim is based on the authors' own observation, it lacks specific evidence or references to support the claim that other methods do not see 2x samples. The reasoning is logical, but the absence of detailed evidence or examples makes it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a potential issue with the training of RegMixup, noting that it sees 2x samples per iteration, which could lead to a slower running speed and an unfair comparison with other methods. This feedback is clear and actionable, as it highlights a specific concern that could impact the validity of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue or what modifications might be necessary to ensure a fair comparison. Overall, the comment is mostly helpful as it points out a critical issue that needs attention, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any explicit or implicit suggestions or actions for the authors to take to address this question. The comment lacks guidance on how the authors might investigate or discuss the scalability of their method, leaving them without a clear path forward. As a result, the comment is unactionable, as it does not offer any actionable feedback or suggestions for improvement.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit mention or context, the authors may find it challenging to identify the exact area of the paper being addressed. Therefore, the comment is weakly grounded, as it does not provide clear guidance on which part of the paper needs attention. It is also specific in that it asks a question about scalability, which is a relevant issue for the paper. However, the combination of weak grounding and specificity aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. However, it does not provide any claim, suggestion, or critique that requires verification or justification. The comment is purely factual and descriptive, lacking any opinions or assertions that would need to be substantiated. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the scalability of the method as the corpus size or hidden dimension size is increased. This is a relevant concern for the authors, as it pertains to the practical applicability and robustness of their method. However, the comment does not provide any suggestions or insights on how the authors might address this issue, such as potential experiments or analyses they could conduct. Without actionable guidance or suggestions, the comment is somewhat helpful as it identifies an important area for consideration but lacks depth and direction for improvement. Therefore, it aligns with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide explicit guidance on how to implement these suggestions or what specific actions the authors should take. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"continuation to the above remark,\" indicating a specific part of the paper being addressed. It also specifies what needs to be addressed, namely, the need to relax the requirement of visiting all ball-action pairs with each iteration and explores the possibility of partially covering them. This provides clear guidance on what the authors should consider and how they might approach the issue. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs. However, the comment does not provide any specific reasoning, examples, or references to support why this modification might be beneficial or how it could be implemented. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors may need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a question about potential modifications to the method, specifically regarding the need to visit all ball-action pairs in each iteration. It suggests exploring the possibility of relaxing this requirement by partially covering the pairs, which could be beneficial for improving efficiency. However, the comment lacks specific guidance on how to implement these suggestions or what minimal assumptions might be needed. While it identifies an area for improvement, it does not provide detailed feedback or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity. The authors would need to infer the necessary steps to address the feedback effectively.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether the authors should use a better encoder, such as RoBERTa-base, instead of BERT to improve the results. While it suggests an alternative model, it does not provide explicit guidance on how to implement this change or what specific improvements might be observed. The action is implicit, as the authors need to infer that they should experiment with a different encoder and analyze the results. However, the comment lacks concrete details on how to conduct this experiment or what specific aspects to focus on. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed guidance on implementation.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions whether a better encoder, such as RoBERTa-base, could improve the results instead of using BERT. However, it does not specify which part of the paper this question pertains to, such as the methodology or experimental setup. Without explicit mention of a section or table, the authors cannot confidently determine where to address this feedback. The comment is specific in its suggestion to use a better encoder, but the lack of grounding makes it difficult for the authors to apply the feedback effectively. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether a better encoder, such as RoBERTa-base, could improve the results instead of using BERT. While it suggests an alternative model, it does not provide any specific reasoning or evidence to support why this might be the case. The comment lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a pertinent question about whether using a better encoder, such as RoBERTa-base, could improve the results compared to using BERT. This is a valuable point for consideration, as it suggests an alternative approach that could potentially enhance the performance of the model. However, the comment does not provide specific guidance on how to implement this change or what specific improvements might be expected. While it offers a direction for improvement, it lacks depth and actionable advice, making it somewhat helpful. The authors would need to conduct additional experiments or analysis to explore this suggestion, which limits the comment's overall impact. Therefore, the comment is rated as somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should demonstrate how their proposed method can achieve fair policy learning without significantly impacting the performance of predictive models. This provides a clear and explicit action for the authors to take, as they need to show the practical application of their method in achieving fair policy learning while maintaining predictive performance. The comment is specific in its suggestion, guiding the authors on what needs to be demonstrated. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without significantly damaging the predictive model performance. However, it does not specify which part of the paper this demonstration should be included in, making it weakly grounded. The comment is specific in its suggestion, as it clearly indicates what needs to be addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should demonstrate how to use their proposed method to achieve fair policy learning without significantly damaging the predictive model performance. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand how to implement the suggested demonstration. Without additional context or guidance, the claim remains somewhat verifiable, as it provides a general direction but lacks the necessary depth to be fully substantiated. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment provides a specific suggestion for improvement by recommending that the authors demonstrate how their proposed method can achieve fair policy learning without significantly impacting the predictive model performance. This feedback is actionable and constructive, as it guides the authors on what aspect of their work needs further clarification or demonstration. By addressing this suggestion, the authors can enhance the clarity and impact of their paper, making it more valuable to the readers. Therefore, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive if it included additional details or examples.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant concern regarding the lack of implementation details for the proposed methods. It suggests that these details should be included in Section 4.1. While the comment identifies a specific area that needs improvement, it does not provide explicit guidance on how to implement these details or what specific information should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to add implementation details to the specified section. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment identifies a specific concern regarding the lack of implementation details for the proposed methods, which is a clear issue that needs to be addressed. It explicitly mentions that these details should be described in Section 4.1, providing full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed\u2014implementation details in Section 4.1. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point highlights a concern regarding the lack of implementation details for the proposed methods, suggesting that these details should be included in Section 4.1. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a significant concern regarding the lack of implementation details for the proposed methods, which is a critical aspect for understanding and replicating the research. By pointing out the absence of these details, the reviewer provides a clear and actionable suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on what kind of implementation details should be included or how the authors might address this issue. Despite this, the feedback is mostly helpful as it directs the authors to a specific area that needs attention, allowing them to make meaningful improvements to their draft. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a significant issue with the paper, noting the absence of empirical evaluation and comparison with other methods. It also points out the lack of clarity regarding the practical value of the contribution, suggesting that even a theoretical paper should address this. The comment implies that the authors should provide empirical evidence and comparisons to demonstrate the practical value of their contribution. However, it does not specify which parts of the paper need to be revised or how to conduct the empirical evaluation. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the lack of empirical evaluation and comparison with other methods, which are specific areas of the paper that need improvement. It also highlights the absence of clarity regarding the practical value of the contribution, which is a critical aspect of the paper. The comment is specific in detailing what needs to be addressed, such as providing empirical evidence and comparisons. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper lacks empirical evaluation and comparison with other methods, making it unclear about the practical value of the contribution. It suggests that even theoretical papers should address this. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence or detailed explanation makes it difficult for the authors to understand and address the issue effectively. Therefore, the claim is unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a critical weakness in the paper: the absence of empirical evaluation and comparison with other methods, which makes it difficult to assess the practical value of the contribution. It also points out that even theoretical papers should address the practical significance of their work, which is not the case here. This feedback is valuable as it highlights a significant gap in the paper's evaluation and provides a clear direction for improvement. However, the comment could be more helpful if it suggested specific ways to conduct the empirical evaluation or comparisons, such as recommending particular datasets or methods. Overall, the comment is mostly helpful as it directs the authors towards addressing a crucial aspect of their work, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also mentions that combining RL and planning has been discussed in PRM-RL and asks if the algorithms can be applied in more general tasks. While the comment identifies a potential area for further exploration, it does not provide explicit guidance on how to address the limitations or how to expand the application of the method. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the applicability of the method discussed in the paper, specifically mentioning that it can be applied in general MDP but is limited in navigation problems. It also references PRM-RL, indicating that combining RL and planning has been discussed in that context. However, the comment does not specify which part of the paper discusses the method or navigation problems, making it weakly grounded. The comment is specific in suggesting that the authors explore the application of the algorithms in more general tasks, but without explicit references to sections or figures, the authors may need to infer the relevant parts. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the method discussed in the paper can be applied in general MDP but is limited in navigation problems. It also references PRM-RL, suggesting that combining RL and planning has been discussed in that context. However, the comment lacks specific examples or detailed reasoning to fully support the claim. While the reference to PRM-RL provides some context, the authors would need to infer the specific areas where the method is limited and how it could be applied more broadly. Therefore, the claim is somewhat verifiable, as it provides some basis but lacks detailed justification or examples.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a limitation in the paper, noting that the method discussed can be applied in general MDP but is limited in navigation problems. It also references PRM-RL, which has already explored the combination of RL and planning, suggesting that the authors could consider applying these algorithms in more general tasks. This feedback provides a clear direction for the authors to expand the scope of their work and explore additional applications of their method. However, the comment could be more helpful if it offered specific suggestions or examples of how to achieve this expansion, such as suggesting particular tasks or datasets to consider. Overall, the comment is mostly helpful as it highlights an area for improvement and provides a starting point for further exploration, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a lack of clarity in the definition of the \"contrastive gap,\" which is a core concept of the work. It points out that while an intuitive example is provided, the setting of this example is less convincing, and a clear, formal definition is still missing. However, the comment does not provide explicit guidance on how the authors should define the contrastive gap or what specific aspects need clarification. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a clear and formal definition. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the \"contrastive gap,\" which is a specific part of the paper being addressed. It provides a clear and specific explanation of the issue, noting that the concept has not been defined clearly and lacks a formal definition. The comment also suggests that the setting of the example is less convincing, indicating a need for improvement in the example's presentation. This level of detail allows the authors to understand exactly what part of the paper needs attention and what specific issues need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the \"contrastive gap\" has not been defined clearly, which is a subjective opinion. It suggests that the setting of the example is less convincing and that a clear, formal definition is still lacking. However, the comment does not provide specific examples or references to support the claim that the definition is unclear or lacking. Without additional evidence or reasoning, the claim remains somewhat verifiable, as the authors may need to infer the basis for the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a significant issue with the paper by pointing out that the \"contrastive gap\" is not clearly defined. This is a crucial oversight that could hinder the understanding and impact of the work. The comment suggests that while an intuitive example is provided, the setting of this example is less convincing, and a clear, formal definition is still lacking. This feedback is valuable as it highlights a specific area where the authors need to improve the clarity and rigor of their work. However, the comment could be more helpful if it provided suggestions on how to define the contrastive gap or examples of how to make the setting of the example more convincing. Overall, the comment is somewhat helpful, as it identifies a critical issue but lacks detailed guidance for improvement.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that other baselines should be included, referencing specific works in the related work section. It also indicates that the authors have addressed their concerns and raised their score. However, the comment does not provide explicit guidance on how to incorporate these additional baselines or how to test beforehand whether they are suitable. The action is implicit and vague, as the authors are left to infer the exact steps needed to improve their draft. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"related work [29, 5, 6]\" and \"other works discussed in related work,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including other baselines and testing beforehand, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that other baselines should be included, referencing specific works in the related work section. It also suggests that the authors have addressed their concerns and raised their score, indicating that the feedback is based on their response. However, the comment lacks detailed reasoning or examples to fully support the claim, making it somewhat verifiable. The authors are encouraged to include other baselines, but the comment does not provide specific guidance on how to do so or why these baselines are necessary. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment suggests that other baselines should be included, referencing specific works in the related work section. It also indicates that the authors have addressed their concerns and raised their score, implying that the feedback is based on their response. However, the comment lacks detailed guidance on how to incorporate these additional baselines or how to test beforehand whether they are suitable. While it provides a clear direction for improvement, the feedback could be more helpful if it included specific suggestions or examples of how to enhance the draft. Therefore, the comment is somewhat helpful, as it identifies an area for improvement but does not provide comprehensive guidance.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point identifies a specific issue in the paper, noting that the authors set \\alpha_m uniformly to 1/M, implying that contributions from all modalities are the same. It then references works in multimodal fusion that suggest dynamically weighting modalities is important. However, the comment does not provide explicit guidance on how the authors should address this issue or what changes they should make to their draft. The action is implicit, as the authors need to infer that they should consider dynamic weighting of modalities. While the suggestion is concrete, the lack of explicit guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"line 113,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies what the issue is, noting that the authors set \\u03b1_m uniformly to 1/M, implying that contributions from all modalities are the same. The comment further suggests that works in multimodal fusion have shown the importance of dynamically weighting modalities, providing a clear direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that setting \\u03b1_m uniformly to 1/M implies that contributions from all modalities are the same, which is a logical deduction based on the definition of \\u03b1_m. However, the comment does not provide specific examples or references to support this claim, making it somewhat verifiable. The authors would need to infer the reasoning and potentially seek additional evidence to fully understand the point. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a specific issue in the paper, noting that the authors set \\u03b1_m uniformly to 1/M, which implies that contributions from all modalities are the same. It then references works in multimodal fusion that suggest dynamically weighting modalities is important. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a relevant direction for the authors to explore. However, the comment could be more helpful if it offered guidance on how to implement or address the issue of dynamic weighting. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or what changes could be made to improve clarity. The comment lacks concrete guidance on how to revise the text or what specific aspects of the phrase should be clarified. As a result, the authors are left without a clear understanding of what actions to take to improve the draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, which is difficult to understand. However, it does not specify which part of the paper this issue occurs, making it weakly grounded. The comment is specific in identifying the problem with the phrase, but without a clear reference to the specific section or line, the authors may find it challenging to address the issue effectively. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the phrase \"to meet\" is difficult to understand, but it does not provide any specific examples or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the criticism or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific issue with the use of the phrase \"to meet\" in the paper, noting that it is difficult to understand. While the comment highlights a potential area for improvement, it lacks actionable guidance or suggestions on how the authors might address this issue. The authors are left without a clear understanding of what changes could be made to improve the clarity of the text. Therefore, the comment is barely helpful, as it points out a problem but does not provide sufficient direction for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address these limitations or what specific aspects of the method need to be improved. Without clear instructions or suggestions, the authors are left without a clear path to follow, making the comment unactionable. Therefore, this comment is rated as 1: Unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or aspect being addressed. The comment is vague and lacks specificity, as it does not provide detailed guidance on what needs to be addressed or how the authors should respond. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as \"pretty shallow.\" However, it does not provide any specific evidence, reasoning, or references to support these claims. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered unverifiable, aligning with a score of 1.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment raises questions about the limitations of the method, specifically in the context of a graph case where the network was described as 'pretty shallow.' However, it does not provide any specific feedback or suggestions on how the authors might address these limitations or improve their method. The comment lacks actionable guidance, leaving the authors without a clear understanding of what needs to be done to enhance their work. Therefore, the comment is not helpful at all, aligning with a score of 1.\", 'helpfulness_label': '1'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is explicit in its request for clarification, it does not provide any guidance or suggestions on how the authors should address these questions. The authors are left to infer that they need to provide this information, but the action is not concrete. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"dropout\" and refers to the \"response letter,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on the \"dropping rate\" and the \"number of masks generated,\" providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the implementation details of the dropout mechanism, specifically asking for clarification on the dropping rate and the number of masks generated. While the comment is factual and seeks clarification, it does not provide any additional context, reasoning, or references to support the request. The authors are left to infer that they need to provide this information, but the comment lacks depth and does not offer any guidance on how to address it. Therefore, the comment is considered borderline verifiable, as it provides some context but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises a specific question about the implementation details of the dropout mechanism, asking for clarification on the dropping rate and the number of masks generated. This is a clear and actionable feedback that helps the authors understand a potential area of confusion or lack of clarity in their paper. By addressing this question, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it provided additional context or guidance on how to address the question. Overall, the feedback is somewhat helpful as it identifies a specific area for clarification, but it lacks depth and could be more comprehensive.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights the need for further justification of the effectiveness of the proposed two-stage optimization approach. It suggests that the authors should include comparisons with other single-stage attacks and provide proper benchmarks and comparisons with state-of-the-art algorithms to substantiate the effectiveness of the technical contributions. While the comment explicitly suggests what needs to be done, it lacks specific guidance on how to conduct these comparisons or what benchmarks to use. The action is clear but somewhat vague, as it does not provide detailed instructions on how to implement the suggested improvements. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the effectiveness of the proposed two-stage optimization approach, suggesting that it needs further justification. It mentions the need for comparisons with other single-stage attacks and proper benchmarks and comparisons with state-of-the-art algorithms. However, the comment does not specify which part of the paper discusses the proposed approach or where these comparisons should be made. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the comment is specific about the need for additional comparisons, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the effectiveness of the proposed two-stage optimization approach needs further justification, specifically mentioning the lack of comparisons with other single-stage attacks and state-of-the-art algorithms. The comment suggests that only showing performance drops on fusion models is insufficient to demonstrate effectiveness. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague, as it does not provide detailed guidance on how to conduct the necessary comparisons or benchmarks. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies a critical gap in the paper by highlighting the lack of justification for the effectiveness of the proposed two-stage optimization approach. It points out that the current evidence is insufficient, as it only shows performance drops on fusion models and lacks comparisons with other single-stage attacks and state-of-the-art algorithms. This feedback is valuable as it directs the authors to strengthen their claims and provide more comprehensive evidence to support their technical contributions. However, the comment could be more helpful if it offered specific suggestions or guidance on how to conduct these comparisons or benchmarks. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more detailed in its suggestions.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment provides a specific action for the authors to take, indicating that they should adjust the connections in the figure to accurately represent the data. The action is explicit and concrete, as it clearly specifies what needs to be done. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear and actionable suggestion for improving the figure by adjusting the connections between the Second Inpainted Images, the Inpainted Image, and the Images Masked by Second Masks. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point suggests that the Perceptual Metric in Figure 2 should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This comment is specific and provides a clear suggestion for improvement, but it does not offer any reasoning or evidence to support why this adjustment is necessary or beneficial. Without additional context or justification, the authors may find it challenging to understand the basis for this suggestion. Therefore, the comment is considered borderline verifiable, as it lacks sufficient support to fully substantiate the claim.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with Figure 2, suggesting that the Perceptual Metric should connect the Second Inpainted Images with the Inpainted Image but not the Images Masked by Second Masks. This feedback is clear and actionable, providing the authors with a specific direction to improve the accuracy and clarity of their figure. By addressing this suggestion, the authors can enhance the visual representation of their data and ensure that the figure accurately reflects the relationships between the different images. This level of detail and specificity makes the comment highly helpful for improving the draft.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point questions whether each node attends to its own lower-level representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or what changes could be made to the draft. The action is implicit, as the authors would need to infer that they should clarify the representation or provide additional context. The lack of concrete guidance makes the comment somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment questions whether each node attends to its own lower-level representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. It is specific in questioning the representation and the description of equation 2, but without explicit references, the authors may struggle to identify the exact section to address. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point questions whether each node attends to its own lower-level representation, suggesting that only neighboring nodes are attended to based on the description of equation 2. However, the comment does not provide any specific evidence, reasoning, or references to support this claim. Without additional context or justification, the authors may find it difficult to understand the basis of the question or how to address it. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a specific question about the representation of nodes in the paper, particularly concerning whether each node attends to its own lower-level representation or only neighboring nodes. This question is based on the description of equation 2, which suggests that only neighboring nodes are attended to. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what changes could be made to the draft. While it identifies a potential area for clarification, it lacks actionable feedback, making it somewhat helpful. The authors would need to infer that they should clarify the representation or provide additional context, which limits the comment's usefulness.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the paper, including the unclear main contribution, the overstated novelty claims, and the lack of clarity in how the proposed method handles dynamic large-scale multitasking and automation. However, it does not provide explicit or implicit actions for the authors to take to address these issues. The comment suggests that the authors should clarify the main contribution, provide evidence for the novelty claims, and explain how the method handles dynamic large-scale multitasking and automation. While the authors can infer that they need to address these points, the lack of specific guidance on how to do so makes the comment somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses the main contribution of the paper, noting that it is unclear and that the novelty claims are overstated or not well-supported. It also points out the lack of clarity in how the proposed method handles dynamic large-scale multitasking and automation. However, the comment does not specify which part of the paper discusses the main contribution, making it weakly grounded. It is specific in detailing the issues with the novelty claims and the lack of clarity in the method's handling of multitasking and automation. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that the main contribution of the paper is unclear and that the novelty claims are overstated or not well-supported. It also notes the lack of clarity in how the proposed method handles dynamic large-scale multitasking and automation. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of evidence makes it difficult for the authors to understand the basis of the critique, leading to a score of 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies several key issues with the paper, including the lack of clarity in the main contribution, the overstated novelty claims, and the unclear handling of dynamic large-scale multitasking and automation. While the comment points out these areas for improvement, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it highlights important areas that need clarification, but it lacks actionable advice or detailed suggestions, making it somewhat helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment raises questions about the novelty and contribution of the proposed idea compared to existing methodologies, specifically in the context of long document summarization. It suggests that the paper does not adequately address the differences between the proposed system and previous extract-then-generate methodologies. However, the comment does not provide explicit guidance on how the authors should address these questions or what specific actions they should take to clarify the novelty of their approach. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to understand how to improve their draft. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the novelty and contribution of the proposed idea compared to existing methodologies, specifically in the context of long document summarization. It suggests that the paper does not adequately address the differences between the proposed system and previous extract-then-generate methodologies. However, the comment does not specify which part of the paper it is addressing, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its questioning of the novelty and contribution, the lack of grounding makes it challenging for the authors to fully understand the feedback. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the novelty and contribution of the proposed idea compared to existing methodologies, specifically in the context of long document summarization. It suggests that the paper does not adequately address the differences between the proposed system and previous extract-then-generate methodologies. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The feedback is somewhat verifiable, as it provides a general direction for improvement but lacks detailed evidence or references. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': \"The review comment raises important questions about the novelty and contribution of the proposed idea compared to existing methodologies, specifically in the context of long document summarization. It highlights the lack of a related work section and the absence of experiments comparing the proposed model with other extract-then-generate methodologies. This feedback is somewhat helpful as it points out areas where the authors need to provide more context and comparison to establish the significance and novelty of their work. However, the comment could be more helpful if it offered specific suggestions or guidance on how to address these issues, such as recommending additional experiments or literature reviews. Therefore, the comment is rated as somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a concern about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not provide explicit guidance on how the authors should address this issue or incorporate the suggested alternative approach into their work. The action is implicit and vague, as it leaves the authors to infer the necessary steps. Therefore, the comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment raises concerns about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment does not specify which part of the paper this issue relates to, such as a specific section or methodology. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in its suggestions, the absence of explicit grounding makes it weakly grounded. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a concern about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes an alternative approach involving unlabeled data or constraints to improve model stability. However, the comment lacks specific examples or references to support the claim about the computational cost or the effectiveness of the alternative approach. Without detailed reasoning or evidence, the claim is difficult to verify, making it borderline verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': \"The review comment raises a concern about the computational cost of training 30-40 models for burn-in, suggesting it is not appealing. It also proposes an alternative approach involving unlabeled data or constraints to improve model stability. While the comment identifies a potential issue with the current methodology, it does not provide specific guidance or suggestions on how to address this concern or implement the alternative approach. The feedback is somewhat helpful as it highlights an area for improvement, but it lacks depth and actionable advice, making it only somewhat helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a specific issue with the authors\\' draft, noting that they did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. While the comment identifies a gap in the authors\\' work, it does not provide explicit guidance on how the authors should address this issue or what specific measurements they could consider. The action is implicit, as the authors need to infer that they should include a quantitative analysis to address the identified gap. However, the comment lacks concrete details on how to implement this suggestion, making it somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the issue of quantitative measurement regarding occupation bias relative to real distributions in society, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the missing aspect, which is the lack of quantitative measurement for occupation bias. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the authors did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This is a subjective claim that suggests a gap in the authors\\' work. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. Without additional context or evidence, the claim is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a specific gap in the authors\\' work, noting that they did not propose any quantitative measurement to address the extent of occupation bias relative to real distributions in society. This feedback is clear and actionable, as it highlights a critical area for improvement that could enhance the rigor and depth of the paper. However, the comment could be more helpful if it provided suggestions or guidance on how the authors might approach this quantitative measurement. Despite this, the comment is mostly helpful as it directs the authors to a specific area that needs attention, allowing them to make meaningful improvements to their draft.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, it does not provide explicit instructions or detailed guidance on how to implement these suggestions, such as which specific parts of the paper need to be revised or what specific analyses should be conducted. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, the comment does not specify which part of the paper this suggestion relates to, such as the experimental setup or the results section. This lack of grounding makes it difficult for the authors to understand which part of the paper needs revision. While the comment is specific about the type of image and dataset, it does not provide detailed guidance on how to implement these suggestions. Therefore, the comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests using DICOM images instead of PNG images for experiments and recommends the FastMRI challenge dataset. It also mentions the need to compare inference speeds between different methods. However, the comment lacks specific reasoning or examples to support why these changes are necessary or beneficial. It does not provide references or detailed explanations to justify the recommendation, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment provides specific suggestions for improving the experimental setup by recommending the use of DICOM images instead of PNG images and suggesting the FastMRI challenge dataset. It also mentions the importance of comparing inference speeds between different methods. However, the comment lacks detailed guidance on how to implement these suggestions or what specific analyses should be conducted to compare the inference speeds. While it offers a clear direction for improvement, the lack of actionable steps limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While it implies that the authors should consider optimizing and validating their approach, the comment does not provide explicit guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer the specific steps needed for optimization and validation. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"ProtPainter,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the binder design, noting that ProtPainter only provides an empirical conformation estimation and requires further optimization and validation. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that ProtPainter provides an empirical conformation estimation for binder design but lacks further optimization and validation. While the comment suggests that further optimization and validation are required, it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of detailed justification makes it difficult for the authors to understand the basis of the claim and how it impacts their work. Therefore, the comment is considered borderline verifiable, as it provides some support but lacks sufficient detail to be fully verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment identifies a specific issue with the binder design in ProtPainter, noting that it only provides an empirical conformation estimation and lacks further optimization and validation. This feedback is clear and actionable, as it highlights a gap in the methodology that could be addressed to improve the robustness and reliability of the results. However, the comment could be more helpful if it provided suggestions on how to optimize or validate the approach, such as specific techniques or additional experiments that could be conducted. Overall, the comment is mostly helpful as it points out a significant area for improvement, but it could be more comprehensive with additional guidance.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review point poses a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it raises an interesting point, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this scenario or what changes could be made to their draft to account for it. Without specific instructions or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it lacks explicit references to specific sections, tables, or figures. Additionally, it does not provide specific guidance or suggestions on how to address the question or incorporate it into the paper. Therefore, this comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. However, it does not provide any claim, judgment, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors improve their work. Therefore, it is classified as \"No\" for verifiability.', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about a specific scenario involving the association of a CAD model with spatially-varying BRDF maps. While it prompts the authors to consider this scenario, it does not provide any guidance or suggestions on how to address it or incorporate it into their draft. The comment lacks depth and specificity, leaving the authors without actionable feedback on how to improve their work. Therefore, it is barely helpful, as it identifies a potential area for consideration but does not offer constructive advice or suggestions. This aligns with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It also provides a reference to support the claim that initialization should play a role, such as pre-training. However, the comment does not explicitly instruct the authors to revise the statement or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to rephrase the statement to be more precise. Therefore, this comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"Initialization\" and its role in the context of Natural Gradient Descent (NGD) and Natural Gradient Flow (NGF). It references a specific paper, which provides context and support for the claim. The comment is also specific because it clearly specifies what needs to be addressed: the statement about initialization should be more carefully stated. This allows the authors to understand exactly what part of the paper requires revision. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It provides a reference to support this claim, referencing a specific paper that discusses the limitations of the empirical Fisher approximation for natural gradient descent. The comment is mostly verifiable as it provides a clear reference and logical reasoning to support the claim, but it could be strengthened by including more detailed examples or explanations of how the reference relates to the specific issue. Therefore, the comment is rated as 4: Mostly Verifiable.', 'verifiability_label': '4', 'helpfulness_rationale': 'The review comment identifies a specific issue with the paper, noting that the statement about initialization playing a role in NGD being a discretization of NGF should be more carefully stated. It provides a reference to support the claim, referencing a paper that discusses the limitations of the empirical Fisher approximation for natural gradient descent. This feedback is somewhat helpful as it highlights a need for clarification and provides a reference for further context. However, the comment could be more helpful if it offered specific suggestions on how to rephrase the statement or provide additional context. Overall, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights two issues: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to improve readability. While the comment explicitly mentions the need for clarification regarding the extraction process, it does not provide specific guidance on how to achieve this. The suggestion for English proofreading is clear and actionable, as it indicates a specific step the authors should take. However, the lack of detailed guidance on how to improve the extraction process makes the comment somewhat actionable. Therefore, it aligns with a score of 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the need for clarification regarding the extraction of named entities from the datasets, allowing the authors to accurately identify the part of the paper being addressed. It also suggests that English proofreading would improve readability, which is a specific and actionable suggestion. Therefore, the comment is fully grounded and specific, aligning with a score of 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that it is not clear how named entities were extracted from the datasets and suggests that English proofreading would improve readability. While the suggestion for proofreading is logical and practical, the claim about the lack of clarity in named entity extraction is not substantiated with specific examples or references. This makes the claim somewhat verifiable, as it lacks detailed evidence or examples to support the assertion. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies two key areas for improvement: the lack of clarity in the extraction of named entities from the datasets and the need for English proofreading to enhance readability. While the comment highlights these issues, it does not provide specific guidance or suggestions on how to address them. The feedback is somewhat helpful as it points out areas that need attention, but it lacks depth and actionable advice, which could be expanded to offer more comprehensive guidance. Therefore, the comment aligns with a score of 3: Somewhat Helpful.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the inversion of matrix determination or the number of samples, specifically in the context of equations. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what changes might be necessary. Without specific instructions or suggestions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the inversion of matrix determination or the number of samples, specifically in the context of equations. However, it does not specify which part of the paper this question pertains to, such as a particular section or equation number. This lack of grounding makes it difficult for the authors to pinpoint the exact issue and address it effectively. Additionally, the comment does not provide specific guidance on how to resolve the issue or what changes might be necessary. As a result, the comment is not grounded and lacks specificity, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the inversion of matrix determination or the number of samples in the context of equations, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors are left without a basis to understand or address the issue. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the inversion of matrix determination or the number of samples in the context of equations, specifically mentioning \"W4 \u2013 Mistakes in Eqs.\" However, it does not provide any guidance or suggestions on how the authors might address this issue or what changes could be made to improve the accuracy of their equations. The comment lacks depth and specificity, leaving the authors without actionable feedback on how to enhance their work. As a result, the comment is barely helpful, aligning with a score of 2.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies areas where the authors could provide more clarity, it does not explicitly instruct the authors on how to address these issues or what specific actions they should take. The actions are implicit and somewhat vague, as the authors need to infer how to improve the draft based on the feedback. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not specify which part of the paper addresses these issues, making it weakly grounded. The questions are specific and provide clear guidance on what needs to be addressed, but without explicit references to sections or figures, the authors must infer the parts of the paper being discussed. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises questions about the motivation of the task, specifically regarding the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also asks about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. However, the comment does not provide any specific examples, reasoning, or references to support these claims. The questions are logical and inferable, but without detailed justification or evidence, they are considered borderline verifiable. Therefore, the comment is rated as 2: Borderline Verifiable.', 'verifiability_label': '2', 'helpfulness_rationale': 'The review comment raises important questions about the motivation of the task, particularly concerning the difficulty of predicting the state of occluded objects and the lack of guarantee in annotation quality. It also inquires about potential downstream applications or benefits of amodal tracking and how uncertainty in predictions might be handled. While the comment identifies a key area for clarification, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to consider the practical implications and potential applications of their work, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This is an explicit action that the authors can directly implement by adding experiments with GPT-3.5. The comment is specific in its suggestion, providing a clear direction for improvement. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests including experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of the proposed approach. However, it does not specify which part of the paper this suggestion relates to, such as a specific section or methodology. The authors may infer that it pertains to the experimental setup or results, but the lack of explicit mention makes it weakly grounded. The comment is specific in its suggestion to include GPT-3.5 experiments, but the lack of grounding makes it weakly grounded and specific. Therefore, this comment aligns with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the authors should include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. While the suggestion is logical and aligns with the idea of cost-effectiveness, it lacks specific examples or references to support the claim. The authors may infer that this suggestion is based on common practices in the field, but without detailed reasoning or evidence, the claim is somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the authors should include experiments with GPT-3.5, a more affordable option, to provide a more comprehensive evaluation of their proposed approach. This feedback is clear and actionable, as it directly addresses a potential limitation in the experimental setup. By suggesting the inclusion of GPT-3.5 experiments, the reviewer provides a concrete and practical improvement that could enhance the robustness and comprehensiveness of the evaluation. This feedback is mostly helpful as it offers a specific and actionable suggestion, but it could be further enhanced by providing more details on how the inclusion of GPT-3.5 experiments would impact the evaluation. Therefore, the comment is rated as mostly helpful.', 'helpfulness_label': '4'} "}
{"generated_text": "{'actionability_rationale': 'The review comment expresses confusion about the term \"confident\" in the context of applying ceterus paribus convexity, specifically questioning whether it refers to model confidence or human interpretability. While the comment identifies a potential point of confusion for the authors, it does not provide explicit guidance on how to address this issue or what specific changes should be made to the text. The action is implicit, as the authors need to infer that they should clarify the meaning of \"confident\" in the paper. However, the comment lacks concrete details on how to implement this clarification, making it somewhat actionable. Therefore, the comment is rated as 3: Somewhat Actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions the part of the paper where the confusion arises, allowing the authors to accurately identify the section being addressed. It specifies what the authors are unsure about, namely the meaning of \"confident\" in the context of ceterus paribus convexity, whether it refers to model confidence or human interpretability. This level of detail provides clear guidance on what needs to be clarified, making the comment fully grounded and specific. Therefore, the comment aligns with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point expresses confusion about the term \"confident\" in the context of applying ceterus paribus convexity, specifically questioning whether it refers to model confidence or human interpretability. The comment suggests that the authors should clarify this term, but it does not provide any specific examples, references, or reasoning to support the claim that this confusion is significant or needs clarification. Without additional context or justification, the claim is difficult to verify, making it unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': \"The review comment identifies a potential point of confusion for the authors regarding the term 'confident' in the context of applying ceterus paribus convexity. It suggests that the authors might be unsure whether 'confident' refers to model confidence or human interpretability. While the comment highlights a specific area of ambiguity, it does not provide detailed guidance or suggestions on how to clarify this point. The feedback is somewhat helpful as it points out a potential issue that could affect the clarity of the paper, but it lacks depth and actionable advice to fully address the concern. Therefore, the comment is rated as 3: Somewhat Helpful.\", 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights several issues with the figures and empirical results, such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to improve the figures and empirical results. The feedback is somewhat vague and lacks concrete details, making it difficult for the authors to know exactly how to proceed. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment addresses issues with the figures and empirical results, specifically mentioning the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. However, it does not specify which figures or sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the problems with the empirical results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point claims that there is a lack of polishing of figures and empirical results, which impedes clarity and confidence in the empirical findings. It provides specific examples such as missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. These examples offer some level of support for the claim, but the comment could be more detailed by providing references or specific guidance on how to improve the figures and empirical results. Therefore, the claim is somewhat verifiable, aligning with a score of 3.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment identifies several areas for improvement in the paper, specifically focusing on the figures and empirical results. It highlights issues such as the lack of polishing, missing axis labels, randomly masked out portions of curves, single seed experiments, and the use of small scale datasets and a single architecture type. These observations provide the authors with specific feedback on what needs to be addressed to enhance the clarity and confidence in their empirical findings. However, the comment could be more helpful if it offered suggestions on how to improve the figures or empirical results, such as providing guidance on how to ensure consistent labeling or how to conduct more robust experiments. Overall, the comment is somewhat helpful as it points out areas for improvement but lacks detailed guidance, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. It suggests that the authors should provide additional feedback to improve the paper. However, the comment does not explicitly instruct the authors on how to address this question or what specific feedback to provide. The action is implicit, as the authors need to infer that they should clarify the rationale behind their metric choice. The action is somewhat vague, as it lacks concrete guidance on how to improve the paper. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. This lack of grounding makes it difficult for the authors to identify the exact area that needs attention. While the comment is specific in questioning the metric choice, the absence of explicit grounding makes it challenging for the authors to understand the context. Therefore, this comment is weakly grounded and specific, aligning with category 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. However, it does not provide any justification or reasoning to support this claim. The comment lacks specific examples or references to substantiate the assertion, making it difficult for the authors to understand the basis of the question. Without additional context or evidence, the claim remains unverifiable. Therefore, the comment is rated as 1: Unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment raises a question about the choice of metrics, specifically questioning why the number of weight updates is considered a better metric than the number of network updates. It prompts the authors to provide additional feedback to improve the paper. However, the comment lacks specificity and does not offer any suggestions or guidance on how to address the question or improve the paper. The feedback is somewhat vague and does not provide actionable advice, making it difficult for the authors to understand how to respond effectively. Therefore, the comment is rated as somewhat helpful, as it identifies an area for improvement but does not provide sufficient detail or direction for the authors to act upon.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any explicit or implicit suggestions or actions for the authors to take in response to this question. The comment lacks guidance on how the authors might address this question or what aspects of their work could be improved to clarify this point. As a result, the authors are left without any actionable feedback, making the comment unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section or context. The comment is not grounded as it does not provide explicit references or guidance on where to find the relevant information. Additionally, it does not specify what needs to be addressed or how the authors might approach this question. Therefore, the comment is not grounded and not specific, aligning with a score of 1.', 'grounding_specificity_label': '1', 'verifiability_rationale': 'The review point raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. However, it does not provide any claim, assertion, or suggestion that requires verification or justification. The comment is purely descriptive and does not offer any insight or guidance that would help the authors understand or address the question. Therefore, it is classified as \"No\".', 'verifiability_label': 'X', 'helpfulness_rationale': 'The review comment raises a question about the real-world scenarios where the proposed adversarial prediction accuracy is relevant compared to classical prediction accuracy. This question highlights a potential gap in the paper's discussion of the practical implications of the proposed method. However, the comment does not provide any suggestions or guidance on how the authors might address this question or what aspects of their work could be improved to clarify this point. Without actionable feedback or suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it identifies a potential area for improvement but lacks depth and direction.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review point highlights a potential issue with the contrastive learning framework used in the paper, suggesting that it is the same as SimCLR. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what changes they should consider making to their framework. Without specific suggestions or instructions, the authors are left without a clear path to improve their draft. Therefore, this comment is unactionable.', 'actionability_label': '1', 'grounding_specificity_rationale': 'The comment suggests that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not specify which part of the paper this comparison is being made, nor does it provide any context or explanation for why this comparison is relevant. The authors cannot confidently determine which section or aspect of the paper is being addressed, making the comment weakly grounded. Additionally, the comment lacks specificity, as it does not detail what aspects of the framework or SimCLR are being compared or how this comparison might impact the paper. Therefore, this comment is weakly grounded and not specific, aligning with a score of 2.', 'grounding_specificity_label': '2', 'verifiability_rationale': 'The review point claims that the contrastive learning framework used in the paper is the same as SimCLR. However, it does not provide any evidence, reasoning, or references to support this claim. Without additional context or justification, the authors are left to question the validity of this assertion, making it difficult to address or verify. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment points out that the contrastive learning framework used in the paper is the same as SimCLR, which is a specific and relevant observation. However, it lacks actionable guidance or suggestions for the authors to address this issue. Without further clarification or recommendations, the authors may not know how to proceed or what changes to make to their work. Therefore, the comment is barely helpful, as it identifies a potential issue but does not provide sufficient guidance for improvement.', 'helpfulness_label': '2'} "}
{"generated_text": "{'actionability_rationale': 'The review comment suggests that the paper could be improved by making comparisons more systematic with respect to the tuning of each method, specifically by comparing the best performance of each. However, it does not provide explicit guidance on how to achieve this, leaving the authors to infer the necessary steps. The action is implicit and somewhat vague, as it does not specify which parts of the paper need to be revised or how to conduct the systematic comparisons. Therefore, the comment is somewhat actionable.', 'actionability_label': '3', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the most closely related work of Zemel et al. (2013)\" and suggests improvements by making comparisons more systematic with respect to the tuning of each method. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the systematic comparison of the best performance of each method. Therefore, this comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point claims that the paper could be improved by making comparisons more systematic with respect to the tuning of each method, specifically by comparing the best performance of each. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or logical arguments to substantiate the suggestion, making it difficult for the authors to understand and implement the proposed improvement. Therefore, the comment is considered unverifiable.', 'verifiability_label': '1', 'helpfulness_rationale': 'The review comment identifies a potential area for improvement in the paper by suggesting that the comparisons with the most closely related work of Zemel et al. (2013) could be more systematic, particularly by comparing the best performance of each method. This feedback is somewhat helpful as it points out a specific aspect that could enhance the paper's rigor and clarity. However, the comment lacks depth and does not provide detailed guidance on how to achieve this systematic comparison, leaving the authors with limited actionable advice. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
{"generated_text": "{'actionability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This provides a clear and explicit action for the authors to take, as they need to estimate the time complexity to support the claim about scalability. The comment is specific in its suggestion, detailing what needs to be done to substantiate the claim. Therefore, this comment is highly actionable.', 'actionability_label': '5', 'grounding_specificity_rationale': 'The comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. However, it does not specify which part of the paper this issue is related to, such as a specific section or table. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific in its suggestion, the lack of grounding makes it challenging for the authors to understand which part of the paper to address. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.', 'grounding_specificity_label': '3', 'verifiability_rationale': 'The review point suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This claim is somewhat verifiable as it provides a logical reasoning for why the estimation of time complexity is important for demonstrating scalability. However, it lacks specific examples or references to support the claim, which could make it less robust. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment suggests that the time complexity of the learning algorithm should be explicitly estimated to prove the scalability properties. This feedback is clear and actionable, as it provides a specific and concrete suggestion for the authors to improve their draft. By estimating the time complexity, the authors can better substantiate their claims about the scalability of their learning algorithm. This feedback is detailed and constructive, offering a clear direction for improvement. Therefore, the comment is highly helpful, aligning with a score of 5.', 'helpfulness_label': '5'} "}
{"generated_text": "{'actionability_rationale': 'The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, specifically referencing Chapter 4 of Steinwart and Christmann. While it prompts the authors to explore this connection, it does not provide explicit guidance on how to address it or what specific aspects of the connection should be investigated. The action is implicit and somewhat vague, as the authors are left to infer the necessary steps. Therefore, this comment is barely actionable.', 'actionability_label': '2', 'grounding_specificity_rationale': 'The comment is fully grounded as it explicitly mentions \"the third point of definition one,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring the connection between the third point and the properties of universal kernels, referencing a specific chapter in a relevant work. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.', 'grounding_specificity_label': '5', 'verifiability_rationale': 'The review point raises a question about the connection between the third point of definition one and the properties of universal kernels, referencing Chapter 4 of Steinwart and Christmann. While the comment provides a specific reference to a relevant work, it does not offer detailed reasoning or examples to support the claim that exploring this connection would be beneficial. The authors are left to infer the relevance and importance of this connection, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.', 'verifiability_label': '3', 'helpfulness_rationale': 'The review comment raises a specific question about the connection between the third point of definition one and the properties of universal kernels, referencing a relevant work by Steinwart and Christmann. This feedback is valuable as it prompts the authors to consider a potential link that could enhance the depth and rigor of their analysis. However, the comment could be more helpful if it provided additional guidance on how to explore this connection or what specific aspects of the connection should be investigated. Without further elaboration, the authors may find it challenging to fully address the feedback. Therefore, the comment is somewhat helpful, aligning with a score of 3.', 'helpfulness_label': '3'} "}
