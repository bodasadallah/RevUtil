{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the choice of operators used in the paper, specifically questioning why the authors did not consider the \\\"and\\\" operator or element-wise max. It suggests that these operators might correspond to the ideas of union and intersection from the \\\"or\\\" operator and element-wise min, and it is unclear why the chosen options were better. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so or provide guidance on how to incorporate them into their work. The action is implicit and somewhat vague, as the authors need to infer that they should explore these alternatives and understand why their current choices are preferable. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines, \\\"261&272,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of operators used in the paper, suggesting that the \\\"and\\\" operator or element-wise max might correspond to the ideas of union and intersection from the \\\"or\\\" operator and element-wise min. The comment provides a clear rationale for why the chosen options might be better, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the choice of operators used in the paper, specifically the \\\"and\\\" operator or element-wise max, and suggests that they might correspond to the ideas of union and intersection from the \\\"or\\\" operator and element-wise min. The reviewer provides a logical reasoning by comparing the chosen operators to their counterparts and questioning why the chosen options are better. However, the comment lacks specific examples or references to support the claim that the chosen operators are indeed better. This makes the claim somewhat verifiable, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area of confusion regarding the choice of operators used in the paper. It questions why the authors did not consider the \\\"and\\\" operator or element-wise max, suggesting that these might correspond to the ideas of union and intersection from the \\\"or\\\" operator and element-wise min. This feedback is clear and actionable, as it prompts the authors to reconsider their choice of operators and potentially provide a rationale for their selection. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how these alternative operators might be used. Overall, the comment is mostly helpful as it directs the authors' attention to a potential weakness in their methodology and encourages them to clarify their choices, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a potential inconsistency in the description of the data selection process, specifically between lines 226-238 and lines 242-244. It suggests that the data selected is a subset of Li et al. (2019a)'s dataset and recommends revising the description to mention Li et al. (2019a) earlier for clarity and precision. The comment provides a clear and explicit action for the authors to take, which is to revise the description and mention Li et al. (2019a) earlier. This guidance is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific line numbers (226-238 and 242-244), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistency in the description of the data selection process and suggests a clear and precise revision involving the mention of Li et al. (2019a) earlier. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the description of the data selection process, specifically questioning the consistency between lines 226-238 and 242-244. The reviewer suggests that the data selected is a subset of Li et al. (2019a)'s dataset and recommends revising the description for clarity. While the comment identifies a potential inconsistency, it lacks detailed reasoning or evidence to fully substantiate the claim. The suggestion to mention Li et al. (2019a) earlier provides some direction, but without further elaboration or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential inconsistency in the description of the data selection process, specifically between lines 226-238 and 242-244. It suggests that the data selected is a subset of Li et al. (2019a)'s dataset and recommends revising the description to mention Li et al. (2019a) earlier for clarity and precision. This feedback is clear and actionable, providing the authors with a specific suggestion to improve the clarity of their manuscript. By addressing this inconsistency, the authors can enhance the accuracy and readability of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the purpose of the average duration reported in Table 1 and asks for an explanation. It also inquires whether the reported duration includes time spent by the user waiting for the model to generate a response. While the comment highlights an area that requires clarification, it does not provide explicit instructions or suggestions on how to address the issue. The authors can infer that they need to provide an explanation for the reported duration, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the purpose of the average duration reported in the table and asks for an explanation. The comment further specifies what needs to be addressed by questioning whether the reported duration includes time spent by the user waiting for the model to generate a response. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the purpose and content of the average duration reported in Table 1. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the purpose of the average duration reported in Table 1, indicating that there is no supporting explanation provided. It also asks whether the reported duration includes time spent by the user waiting for the model to generate a response. This feedback is somewhat helpful as it identifies a gap in the explanation of the table's content, prompting the authors to clarify this aspect of their work. However, the comment could be more helpful if it suggested ways to address this issue or provided examples of how to improve the explanation. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison between Chinese MOS-Q and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOS-V. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should provide additional explanations, interpretations, or analyses to address these questions. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the interpretation of the results in Table 3, particularly the comparison between Chinese MOS-Q and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOS-V. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the interpretation of results presented in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises questions about the interpretation of results presented in Table 3, specifically regarding the comparison between Chinese MOS-Q and GT Mel A, and the overlapping 95% confidence intervals for Chinese and English MOS-V. While the comment identifies areas where the authors may need to provide additional clarification or interpretation, it does not offer specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it points out potential areas of confusion, but it lacks depth and actionable advice, leaving the authors with only a general direction for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting the presence or absence of spaces between accuracy and standard deviation. This observation implies that the authors should ensure consistency in the formatting of these tables to improve the visual appeal and readability of the paper. However, the comment does not explicitly instruct the authors to make this change or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should standardize the formatting but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 2\\\" and \\\"Table 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of inconsistent spacing between accuracy and standard deviation, which affects the visual appeal and readability of the tables. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that there is an inconsistency in the presentation of data in Table 2 and Table 3, specifically noting the presence or absence of spaces between accuracy and standard deviation. This observation is a factual statement about the formatting of the tables and does not express an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \\\"No\\\".\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the formatting of data in Table 2 and Table 3, noting the inconsistency in the presence or absence of spaces between accuracy and standard deviation. This feedback is clear and actionable, as it points out a minor but noticeable detail that affects the visual appeal and readability of the tables. By addressing this issue, the authors can improve the presentation of their results, which is a valuable contribution to the clarity and professionalism of their work. However, the comment could be more helpful if it provided suggestions on how to standardize the formatting or why this inconsistency might be problematic. Overall, the comment is mostly helpful, as it effectively directs the authors to a specific area for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies two specific issues: a missing antecedent in the phrase \\\"both tasks\\\" and a need to check the references for format, including capitalization and bibliographic details. The comment provides explicit actions for the authors to take, such as correcting the antecedent and ensuring the references are formatted correctly. These instructions are clear and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the line \\\"both tasks\\\" and the need to check references for format, providing specific guidance on what needs to be addressed. It also mentions specific references, such as \\\"Grice, Sorower et al\\\" and \\\"verbnet,\\\" which helps the authors identify the exact parts of the paper that require attention. This level of detail provides clear guidance on what needs to be corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point identifies two specific issues: a missing antecedent in the phrase \\\"both tasks\\\" and a need to check the references for format, including capitalization and bibliographic details. These claims are specific and provide clear guidance on what needs to be corrected, making them verifiable. The comment is mostly verifiable as it highlights precise areas for improvement, but it could be further strengthened by providing examples or additional context. Therefore, the comment aligns with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies two specific issues: a missing antecedent in the phrase \\\"both tasks\\\" and a need to check the references for format, including capitalization and bibliographic details. These are actionable suggestions that can help the authors improve the clarity and professionalism of their manuscript. By addressing these points, the authors can enhance the accuracy and presentation of their work. However, the comment could be more helpful if it provided examples of how to correct the antecedent or detailed guidance on formatting the references. Overall, the feedback is mostly helpful as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly suggests that the explanations for features in Section 3.2 are confusing and recommends organizing the section more coherently by using separate paragraphs for lexical features and sentence-level features. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve the clarity and organization of the section. The comment is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 3.2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the somewhat intertwined nature of the explanations for features, and suggests a specific improvement: organizing the section with separate paragraphs for lexical features and sentence-level features. This provides clear guidance on how to enhance the clarity and coherence of the section. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the explanations for features in Section 3.2 are somewhat intertwined and confusing, suggesting that the section would be more coherent with separate paragraphs for lexical features and sentence-level features. However, the comment does not provide specific examples or detailed reasoning to support why the current organization is confusing or how the suggested reorganization would improve clarity. Without concrete evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient detail to fully substantiate the claim.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the clarity and organization of the explanations for features in Section 3.2. It suggests that the section would be more coherent if it were organized with separate paragraphs for lexical features and sentence-level features. This feedback is clear and actionable, providing the authors with a concrete way to improve the readability and structure of their paper. By addressing this suggestion, the authors can enhance the clarity of their explanations, making it easier for readers to understand the content. However, the comment could be more helpful if it included examples of how the current organization is confusing or suggested specific ways to improve the coherence. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment acknowledges that the abstract is well-written and suggests that it could be improved by providing an example of the inconsistency between \\\"evaluating with gold answers\\\" and human evaluation. The comment explicitly states that an example of the inconsistency, such as models being ranked differently, should be included. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to enhance the abstract. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a way to improve the abstract by providing an example of the inconsistency between \\\"evaluating with gold answers\\\" and human evaluation. The comment specifies what needs to be addressed, namely the inclusion of an example of the inconsistency. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point acknowledges that the abstract is well-written and suggests that it could be improved by providing an example of the inconsistency between \\\"evaluating with gold answers\\\" and human evaluation. However, the comment does not provide any specific examples or detailed reasoning to support the claim that the inconsistency exists or how it could be illustrated. This lack of explicit examples or references makes the claim somewhat verifiable, as the authors would need to infer the specific inconsistency and how to demonstrate it. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges that the abstract is well-written and suggests a potential improvement by providing an example of the inconsistency between \\\"evaluating with gold answers\\\" and human evaluation. This feedback is actionable as it offers a specific suggestion for enhancing the abstract by illustrating the inconsistency with an example. However, the comment could be more helpful if it provided multiple examples or further elaborated on the inconsistency. Overall, the comment is mostly helpful as it guides the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with additional details or examples.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit actions for the authors to take. It instructs them to discuss the results for the task of inferring knowledge on objects and to include results for model (B). Additionally, it suggests using the same terminology for the model in Tables 1 and 2. The comment also questions the use of \\\"latent in verbs\\\" and suggests that objects should be mentioned. These instructions are clear and provide concrete guidance on how to improve the draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific line numbers (681 and 778), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, such as discussing the results for the task of inferring knowledge on objects and including results for model (B). Additionally, it suggests using the same terminology for the model in Tables 1 and 2 and questions the use of \\\"latent in verbs.\\\" This level of detail provides clear guidance on what needs to be revised, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of two parts: a request for additional discussion and results for a specific task, and a question about terminology. The first part is a suggestion for improvement, not a claim, and does not require verification. The second part is a question seeking clarification, which is also not a claim. Therefore, the review point is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by requesting the authors to discuss the results for the task of inferring knowledge on objects and to include results for model (B). It also suggests using consistent terminology for the model in Tables 1 and 2, which is a clear and practical improvement. Additionally, the comment questions the use of \\\"latent in verbs\\\" and suggests that objects should be mentioned, prompting the authors to clarify their terminology. This feedback is detailed and constructive, offering the authors clear directions for enhancing the clarity and completeness of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a specific issue with a sentence in the paper, pointing out that it is not strictly correct and suggesting a more accurate phrasing. The reviewer provides a clear and explicit action for the authors to take, which is to revise the sentence to accurately reflect the intended meaning. This feedback is concrete, as it specifies exactly what needs to be changed and why, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 212,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the incorrect phrasing of the sentence and suggests a more accurate alternative. The comment provides clear guidance on what needs to be revised, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the sentence in line 212 is not strictly correct and suggests an alternative phrasing. The reviewer provides a logical reasoning by pointing out the discrepancy between the sentence and the information presented in Figure 2, which supports the claim. However, the comment lacks specific examples or references to substantiate the claim further. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with a sentence in the paper, pointing out that it is not strictly correct and suggesting a more accurate phrasing. By providing a clear and actionable suggestion, the comment helps the authors improve the precision and clarity of their writing. This feedback is valuable as it directs the authors to refine their language and ensure accuracy in their descriptions. However, the comment could be more helpful if it explained why the suggested phrasing is better or provided additional context on the implications of the error. Overall, the comment is mostly helpful as it offers a clear and constructive suggestion for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests that the authors should compare their work to specific baseline models, namely Campos et al. (2020) and other domain adaptation methods cited in Section 8. Additionally, it corrects a grammatical error in the text. These suggestions are clear and actionable, providing the authors with specific steps to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines and sections, such as \\\"Line 277\\\" and \\\"Section 8,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the baseline models, including the lack of comparison to Campos et al. (2020) and other domain adaptation methods. Additionally, it provides a correction for a grammatical error. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the adopted baseline models are weak and suggests that the authors should compare their work to specific models, such as Campos et al. (2020) and other domain adaptation methods. The comment provides specific references to other works, which supports the claim by indicating what additional comparisons are needed. However, the comment could be strengthened by providing more detailed reasoning or examples of how these comparisons would improve the paper. As it stands, the claim is mostly verifiable due to the specific references provided, but it could benefit from further elaboration. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the choice of baseline models used in the paper, suggesting that they are weak and lacking in comparison to relevant works. It specifically points out the omission of a comparison to Campos et al. (2020) and other domain adaptation methods, which are cited in the paper. Additionally, it corrects a grammatical error in the text. This feedback is clear and actionable, providing the authors with specific areas to address in order to strengthen their work. However, the comment could be more helpful if it offered suggestions on how to select or compare the baseline models more effectively. Overall, the comment is mostly helpful as it directs the authors to important areas for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the y-axis label in Figure 5 could be changed to \\\"Exact Match ratio\\\" directly. This is an explicit suggestion, providing a clear action for the authors to take. The comment is specific in its recommendation, leaving no ambiguity about what needs to be done to improve the figure. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"figure 5,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the y-axis label could be changed to \\\"Exact Match ratio\\\" directly. This provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment suggests a change to the y-axis label in Figure 5, recommending the use of \\\"Exact Match ratio\\\" directly. However, it does not provide any justification or reasoning for why this change is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion regarding the labeling of the y-axis in Figure 5. It recommends using \\\"Exact Match ratio\\\" directly, which is a clear and precise recommendation that can help improve the clarity and accuracy of the figure. This feedback is valuable as it directly addresses a potential issue with the presentation of data in the paper. However, the comment could be more helpful if it explained why this change is necessary or how it impacts the interpretation of the results. Despite this, the comment is mostly helpful as it offers a concrete step for the authors to take in improving their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly requests the authors to justify the choice of baselines in Table 3, specifically mentioning that MCNC should have many strong baselines that are not compared here, such as those in reference [1]. This direct request provides a clear action for the authors to take, which is to provide a justification for their baseline selection. The comment is specific and leaves no ambiguity about what the authors need to address, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of strong baselines for MCNC that are not compared in the table, and requests a justification for this choice. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the choice of baselines in Table 3, specifically mentioning that MCNC should have many strong baselines that are not compared here, such as those in reference [1]. The comment requests a justification for this choice. While the comment highlights a potential gap in the comparison, it does not provide specific reasoning or evidence to support why the baselines in reference [1] are considered strong or why their absence is a significant issue. The lack of detailed justification or examples makes the claim somewhat verifiable, as it requires the authors to infer the importance of the missing baselines and provide their own reasoning. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Table 3, noting that MCNC should have many strong baselines that are not compared in the table, such as those mentioned in reference [1]. It requests a justification for this choice, which is a clear and actionable suggestion for the authors to improve their draft. By highlighting the need for a more comprehensive comparison, the comment provides the authors with a concrete direction to enhance the rigor and comprehensiveness of their work. However, the comment could be more helpful if it offered additional guidance on how to select or incorporate these baselines. Overall, the feedback is mostly helpful as it directs the authors to a specific area for improvement and provides a clear request for justification.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests adding information about the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al., and clarifies the source language or language of the mentions in Figure 3. These suggestions are clear and specific, giving the authors direct guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 2.3\\\" and \\\"Figure 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as adding information about the use of word embeddings and clarifying the source language or language of the mentions in Figure 3. This level of detail provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should clarify the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al., and asks for clarification on whether the KNs in Figure 3 are in the source language or in English. The comment is mostly verifiable as it provides a logical suggestion for improvement and asks for clarification, which can be addressed by providing additional information or corrections. However, it lacks specific examples or references to fully substantiate the claim, making it somewhat verifiable. The authors can address the feedback by providing the requested clarification, thus making the comment fully verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by suggesting that the authors clarify the use of word embeddings in the Bi-LSTM-CRF model, similar to Lample et al. It also asks for clarification on whether the KNs in Figure 3 are in the source language or in English, given that mentions have been translated to English. This feedback is clear and constructive, guiding the authors on how to improve the clarity and accuracy of their presentation. However, the comment could be more helpful if it included additional suggestions or examples of how to address these issues. Overall, the comment is mostly helpful as it provides valuable insights for improving the draft, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that lines 102-106 are misleading because the term \\\"such distribution\\\" cannot refer to the discussion in the preceding lines. However, it does not provide specific guidance on how to revise this section or clarify the intended meaning. The feedback identifies a potential issue but lacks actionable details, such as suggesting alternative phrasing or providing examples of how to improve the clarity. As a result, the authors are left with a general understanding of the problem but without clear steps to address it. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Lines 102-106,\\\" allowing the authors to accurately identify the part of the paper being addressed. It specifies the issue by pointing out that the term \\\"such distribution\\\" is misleading and cannot refer to the discussion in the preceding lines. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that lines 102-106 are misleading because the term \\\"such distribution\\\" cannot refer to the preceding discussion. However, the comment does not provide any specific reasoning or examples to support this claim. Without detailed justification or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the text in lines 102-106, noting that the term \\\"such distribution\\\" is misleading and cannot refer to the preceding discussion. This feedback is clear and actionable, as it points out a potential source of confusion in the manuscript. By addressing this issue, the authors can improve the clarity and accuracy of their writing. However, the comment could be more helpful if it provided suggestions on how to revise the text or clarified the intended meaning of \\\"such distribution.\\\" Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that certain claims from the paper would benefit from more in-depth analysis. However, it does not specify which claims need further analysis or provide guidance on how to conduct this analysis. The action is implicit and vague, as the authors are left to infer that they need to perform more detailed analysis but are not given specific instructions on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that certain claims from the paper would benefit from more in-depth analysis. However, it does not specify which claims are being referred to, nor does it provide details on what aspects of the analysis are lacking or how they could be improved. Without specific references or guidance, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that certain claims in the paper would benefit from more in-depth analysis. However, it does not provide specific examples of which claims are lacking or how they could be improved. Without detailed reasoning or examples, the claim remains vague and lacks sufficient support, making it difficult for the authors to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment suggests that certain claims in the paper would benefit from more in-depth analysis. However, it lacks specificity and does not identify which claims are problematic or how they could be improved. Without detailed guidance or examples, the authors are left without clear direction on how to enhance their analysis. This lack of actionable feedback makes the comment barely helpful, as it points out an area for improvement but does not provide sufficient detail to guide the authors in making those improvements.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides explicit and concrete actions for the authors to take. It asks for clarification on the pooling method used for embedding features, specifically referencing line 397. Additionally, it questions the clarity of Equation (7) in line 472, asking whether E_i represents the type or identity of AC i, and suggests that the left-hand side of the equation should be a conditional probability. These points are clear and specific, giving the authors direct guidance on what needs to be clarified or defined in their paper. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (397 and 472), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the pooling method used for embedding features and the clarity of Equation (7), including whether E_i represents the type or identity of AC i and whether the left-hand side of the equation should be a conditional probability. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the clarity of the presentation in the paper, specifically regarding the pooling method used for embedding features and the interpretation of Equation (7). The reviewer questions whether E_i represents the type or identity of AC i and suggests that the left-hand side of the equation should be a conditional probability. While the comment identifies specific areas of confusion, it lacks detailed reasoning or references to support the claims. The authors would need to make a significant effort to understand and address the issues raised, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on two key areas of the paper: the presentation of the model and the clarity of Equation (7). It asks for clarification on the pooling method used for embedding features, which is important for understanding the methodology. Additionally, it questions the interpretation of Equation (7), suggesting that the left-hand side should be a conditional probability. This feedback is clear and constructive, guiding the authors to improve the clarity and precision of their presentation. By addressing these points, the authors can enhance the comprehensibility of their work, making the comment highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights that the paper raises two hypotheses about multilinguality and country/language-specific bias but notes that these hypotheses are not studied or discussed further in the paper. The reviewer suggests that the paper should at least explore these topics more deeply. While the comment implies that the authors should expand on these hypotheses, it does not provide specific guidance on how to do so or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to address the issue but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the lines \\\"078-086,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the hypotheses are not studied or discussed further, despite being raised. The comment suggests that the paper should delve deeper into these topics, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point critiques the paper for not studying or discussing the hypotheses raised about multilinguality and country/language-specific bias, despite mentioning them. The reviewer suggests that the paper should explore these topics further, indicating that the current approach is misleading and lacks depth. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to explore these topics further is somewhat verifiable, as it provides a direction for improvement but does not offer concrete evidence or references to support the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the paper, noting that while it raises two hypotheses about multilinguality and country/language-specific bias, these hypotheses are not studied or discussed further in the paper. The reviewer acknowledges the valuable nature of the underlying ideas but suggests that the paper should at least explore these topics more deeply. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by expanding on the hypotheses and their implications. However, the comment could be more helpful if it offered suggestions on how to approach this deeper exploration or provided examples of what aspects to focus on. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides a specific suggestion for an experiment: to add a baseline smaller PCFG with a state size of r, where certain parameters are directly parameterized as learned matrices. This suggestion is explicit and provides concrete details on how to implement the change, making it clear what the authors should do to improve their draft. The comment also explains the rationale behind the suggestion, which is to ensure that parsing F-1 is not directly comparable, but perplexity can still be compared. This level of detail and clarity makes the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests adding a baseline smaller PCFG with a specific parameterization, which provides a clear direction for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment. The authors can infer that it relates to the methodology or experimental setup, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests adding a baseline smaller PCFG with specific parameterizations to compare parsing F-1 with perplexity. However, it does not provide any supporting evidence, reasoning, or references to justify why this baseline would be beneficial or how it would improve the comparison. The lack of detailed explanation or examples makes it difficult for the authors to understand the rationale behind the suggestion, rendering the claim unverifiable. Therefore, the comment is classified as 1: Unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific suggestion for an experiment, proposing to add a baseline smaller PCFG with a particular parameterization. This feedback is actionable and offers a clear direction for the authors to enhance their work by comparing parsing F-1 with perplexity. However, the comment could be more helpful if it explained why this baseline is important or how it might impact the results. Despite this, the suggestion is valuable and provides a concrete step for the authors to consider, making the comment mostly helpful. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly suggests that the authors should state the maximum number of tasks done by any annotator. This is a direct and concrete action that the authors can take to improve their draft. The comment provides clear guidance on what needs to be added, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"241,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely stating the maximum number of tasks done by any annotator. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment suggests that the authors should state the maximum number of tasks done by any annotator. However, it does not provide any reasoning or evidence to support why this information is necessary or how it would benefit the paper. Without additional context or justification, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improvement by recommending that the authors state the maximum number of tasks done by any annotator. This feedback is clear and directly addresses a potential gap in the paper, which could be important for understanding the scope and limitations of the study. By implementing this suggestion, the authors can enhance the transparency and comprehensiveness of their work. However, the comment could be more helpful if it explained why this information is important or how it might impact the interpretation of the results. Despite this, the feedback is mostly helpful as it offers a concrete step for the authors to take in improving their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a clear and direct action for the authors to take, providing concrete guidance on how to enhance their draft. The suggestion is specific and leaves no ambiguity about what needs to be done to improve the table. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of the hard prompt baseline to observe the performance increase of each method. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a suggestion for improvement rather than a claim or opinion, as it does not express an opinion or judgment about the current approach. It is a request for additional information that could enhance the analysis. Therefore, it is classified as \\\"No\\\".\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment suggests including the hard prompt baseline in Table 1 to observe the performance increase of each method. This is a specific and actionable suggestion that can help the authors enhance their analysis and provide a more comprehensive comparison of their methods. By incorporating this baseline, the authors can offer a clearer understanding of the effectiveness of their approach relative to a standard prompt. However, the comment could be more helpful if it explained why this baseline is important or how it might impact the interpretation of the results. Despite this, the feedback is mostly helpful as it provides a clear direction for improvement. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights the absence of numerical results and suggests that the reviewer is interested in seeing how the proposed method can be applied to popular algorithms and how its performance compares to existing DP algorithms. While the comment implies that the authors should include numerical results and comparisons, it does not explicitly instruct them to do so. The action is clear but stated implicitly, and the authors can infer that they need to add numerical results and comparisons. However, the comment does not provide specific guidance on which algorithms to test or how to structure the comparisons, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment highlights the lack of numerical results and suggests that the reviewer is interested in seeing how the proposed method can be applied to popular algorithms and compared with existing DP algorithms. However, it does not specify which part of the paper should include these numerical results or which algorithms should be considered. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of numerical results and comparisons, but without clear grounding, it aligns with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims a \\\"lack of numerical results\\\" and suggests that the reviewer is interested in seeing how the proposed method can be applied to popular algorithms and compared with existing DP algorithms. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant gap in the paper, specifically the lack of numerical results. It suggests that the authors should provide numerical results to demonstrate the application of their method to popular algorithms and compare its performance with existing DP algorithms. This feedback is clear and actionable, as it directs the authors to include specific types of results that would strengthen their paper. However, the comment could be more helpful if it provided examples of popular algorithms or suggested specific metrics for comparison. Overall, the comment is mostly helpful as it highlights a critical area for improvement and offers a clear direction for the authors to follow.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the experimental comparisons are insufficient and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2x) and ResNet50 (4x), which are used by other methods like MoCo and SimCLR. This feedback provides a clear and explicit action for the authors to take, specifying exactly what additional experiments should be conducted to strengthen the paper. The suggestion is concrete, as it outlines the specific backbones to test with, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment addresses the experimental comparisons, suggesting that the authors should test their proposed method, InvP, with wider backbones like ResNet50 (2x) and ResNet50 (4x), which are used by other methods like MoCo and SimCLR. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental results or comparisons section. The suggestion is specific, as it clearly outlines what additional experiments should be conducted to enhance the paper. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the experimental comparisons are insufficient, suggesting that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2x) and ResNet50 (4x), similar to other methods like MoCo and SimCLR. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, pointing out a potential gap in the experimental setup. However, it lacks specific examples or references to support the claim fully, such as detailing how these wider backbones would impact the results or why they are important. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the experimental comparisons, noting that the proposed method, InvP, is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x), which are used by other methods like MoCo and SimCLR. It suggests that including these wider backbones would provide a more comprehensive evaluation of the proposed method. This feedback is clear and actionable, as it guides the authors to expand their experimental comparisons to include these additional backbones, potentially strengthening the validity and impact of their results. However, the comment could be more helpful if it provided specific reasons why these wider backbones are important or how they might affect the results. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their experimental design.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It specifies that the callout to Table 5 should be moved to Table 3 and points out an issue with the callout for Figure 6 in the last paragraph of Section 5. These instructions are clear and leave no ambiguity about what needs to be corrected, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"table 5\\\" and \\\"table 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the callout for Figure 6 in the last paragraph of Section 5, providing clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual corrections regarding the placement of callouts in the paper. It does not contain any subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback regarding the placement of callouts in the paper. It identifies two distinct issues: the incorrect placement of the callout for Table 5 and the improper directing of the callout for Figure 6. By pointing out these errors, the comment helps the authors correct the formatting and ensure clarity in their manuscript. This level of detail and specificity makes the feedback highly helpful, as it directly guides the authors on how to improve the presentation of their work. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a significant concern regarding the experiments, specifically noting that the paper only reports self-comparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue and provides a potential solution, it does not offer detailed guidance on how to conduct these comparisons or what specific aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to address the issue of self-comparisons but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the experiments section, specifically mentioning the issue of only reporting self-comparisons and the lack of explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the experiments section. The comment is specific in detailing what needs to be addressed, such as the need for comparisons with SketchRNN. However, since it does not explicitly mention the section, it is weakly grounded but specific. Therefore, this comment aligns with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the experiments, specifically noting that the paper only reports self-comparisons and lacks an explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to compare with SketchRNN is a logical step, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant concern regarding the experiments section, specifically noting that the paper only reports self-comparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting, which would strengthen the paper's motivation and provide a more comprehensive evaluation. While the comment highlights a critical issue and offers a potential solution, it could be more helpful by providing specific guidance on how to conduct these comparisons or what aspects to focus on. Nonetheless, the feedback is mostly helpful as it directs the authors to a key area for improvement and provides a constructive suggestion for enhancing the paper's experimental section. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that more analysis and comments are needed on the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3. It also disagrees with the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity. The reviewer provides specific observations from Figure 3, such as the DeiT-B models not outperforming DeiT-T and DeiT-S on certain datasets, and notes that CNNs show more consistent improvements. However, while the comment identifies areas for further analysis, it does not provide explicit instructions on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the need for additional analysis and determine the specific areas to address. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the performance trends of increasing the number of parameters for ViT (DeiT) and disagrees with the authors' viewpoint regarding the benefits of increased model capacity. The comment further specifies the discrepancies observed in the performance of DeiT models compared to CNNs on various datasets. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the authors' claim that both CNNs and ViTs benefit similarly from increased model capacity. It provides specific observations from Figure 3, noting that DeiT-B does not outperform DeiT-T and DeiT-S on certain datasets, while CNNs show more consistent improvements. This detailed analysis and comparison with specific datasets provides a robust basis for the claim, making it fully verifiable. The comment effectively supports the argument with precise data and comparisons, aligning with a score of 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides a detailed analysis of the performance trends of increasing the number of parameters for ViT (DeiT) in Figure 3, offering specific observations and comparisons with CNNs. It challenges the authors' viewpoint that both CNNs and ViTs benefit similarly from increased model capacity, noting discrepancies in the performance of DeiT models on various datasets. This feedback is clear and actionable, as it directs the authors to conduct a more thorough analysis of their results and to reconsider their claims about model capacity. The comment is mostly helpful, as it provides a solid foundation for the authors to improve their draft by addressing the inconsistencies observed in their data. However, it could be further improved by suggesting specific analyses or metrics to focus on, which would enhance its helpfulness. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that don't. This is an explicit suggestion, providing a clear action for the authors to take. However, the comment does not specify how to implement this distinction or what specific aspects should be highlighted. While the action is explicit, the lack of detailed guidance on execution makes it somewhat vague. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Line 148,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a distinction between hard prompt work updates the frozen model and those that don't, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should make a distinction between hard prompt work updates the frozen model and those that don't. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this distinction is necessary or beneficial. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific suggestion for improving the clarity of the paper by recommending a distinction between hard prompt work updates the frozen model and those that don't. This feedback is actionable and offers a clear direction for enhancing the draft, allowing the authors to make a concrete improvement to their work. However, the comment could be more helpful if it included additional context or examples of how this distinction might impact the paper's overall clarity or coherence. Despite this, the suggestion is valuable and provides a clear path for improvement, making the comment mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to conduct an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also specifies a particular experiment of interest, the performance of ATT(+H) as shown in Figure 4 left, and asks for the results if the proposed model did not consider relevant attention retrieval from the attention memory. This feedback provides clear and concrete actions for the authors to take, including specific experiments to conduct and the results to focus on. The explicit nature of the instructions and the detailed guidance on how to implement the suggested actions make this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions conducting an ablation study on the visDial dataset, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular experiment of interest, the performance of ATT(+H) as shown in Figure 4 left, and asks for the results if the proposed model did not consider relevant attention retrieval from the attention memory. This provides clear guidance on what needs to be addressed and why. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests conducting an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also raises a specific interest in the performance of ATT(+H) as shown in Figure 4 left, questioning the impact of not considering relevant attention retrieval from the attention memory. While the comment provides a clear suggestion for an additional experiment, it lacks specific reasoning or evidence to support why this ablation study is necessary or how it would enhance the validation of the model. The claim is somewhat verifiable, as it points out a potential area for improvement but does not provide detailed justification or examples to fully substantiate the need for the suggested experiment. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the paper by recommending an ablation study on the visDial dataset to further validate the proposed visual reference resolution model. It also highlights a particular experiment of interest, the performance of ATT(+H) as shown in Figure 4 left, and asks for the results if the proposed model did not consider relevant attention retrieval from the attention memory. This feedback is clear and constructive, offering the authors a concrete way to enhance the robustness and credibility of their model's validation. By addressing these points, the authors can significantly improve the depth and impact of their work. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should provide an explanation of why the WPA (White Paper Attack) works, particularly with np.ones input, and what the model predicts in this scenario. It also questions whether any input could serve as a white paper and notes that Figure 2 suggests Gaussian noise input does not perform as well as WPA. The reviewer emphasizes the need for insights into how WPA works, as this could be valuable for future research. While the comment implies that the authors should provide additional analysis or explanation, it does not explicitly instruct them to do so. The action is clear but stated indirectly, making this comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and suggestions for improvement, such as explaining why WPA works, what the model predicts with np.ones input, and why Gaussian noise input does not perform as well as WPA. The comment also emphasizes the need for insights into how WPA works, which could be valuable for future research directions. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should provide an explanation of why WPA works, particularly with np.ones input, and what the model predicts in this scenario. It also questions the effectiveness of Gaussian noise input compared to WPA and emphasizes the lack of insights into how WPA functions, which could be valuable for future research. The comment is somewhat verifiable as it raises valid questions and points out a gap in the paper's analysis. However, it lacks specific examples or references to support the claims, such as suggesting alternative inputs or providing a theoretical basis for the observed differences. This makes it challenging for the authors to fully understand and address the critique without additional guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment is mostly helpful as it identifies a critical gap in the paper's analysis: the lack of explanation regarding why WPA works, particularly with np.ones input, and what the model predicts in this scenario. It also questions the effectiveness of Gaussian noise input compared to WPA and emphasizes the need for insights into how WPA functions. This feedback is valuable as it highlights an area where the authors could provide more depth and clarity, potentially sparking future research directions. However, the comment could be more helpful if it offered specific suggestions or examples on how to address these issues. Overall, the feedback is clear and actionable, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a gap in the experimental section regarding the setting and sensitivity of two important parameters: the minimum cluster size and the conductance threshold. While it points out that these parameters are not discussed or analyzed in the experimental section, it does not provide explicit instructions on how the authors should address this issue. The authors are left to infer that they need to include a discussion on how these parameters are set and their impact on performance, but the comment lacks concrete guidance on how to implement this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"end of Sec. 2\\\" and the \\\"experimental section (Sec. 3),\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of discussion or mention of how the two important parameters (minimum cluster size and conductance threshold) are set and how sensitive the performance is with respect to these parameters. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point highlights a gap in the experimental section regarding the setting and sensitivity of two important parameters: the minimum cluster size and the conductance threshold. The claim is somewhat verifiable as it points out the absence of discussion on these parameters in the experimental section, which is a logical observation. However, the comment lacks specific examples or references to support the claim, such as suggesting how these parameters might affect performance or providing examples of similar studies. This makes it challenging for the authors to fully understand and address the issue, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the paper regarding the experimental section, noting that two important parameters (minimum cluster size and conductance threshold) are not discussed or analyzed in terms of how they are set and their impact on performance. This feedback is clear and actionable, as it directs the authors to address this omission, which could significantly improve the comprehensiveness and robustness of their experimental analysis. However, the comment could be more helpful if it provided suggestions on how to set these parameters or discussed potential methods for sensitivity analysis. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a clear direction for the authors to follow.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the potential weakness of using reinforcement learning for a static Visual Question Answering (VQA) task, suggesting that it may make the approach less data-efficient and harder to train models using gradient descent. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or improve their approach. Without specific suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it may make the approach less data-efficient and harder to train models using gradient descent. However, it does not specify which part of the paper this concern pertains to, such as a particular section or experiment where reinforcement learning is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the approach but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the potential weakness of using reinforcement learning for a static VQA task, suggesting that it may make the approach less data-efficient and harder to train models using gradient descent. However, the comment lacks specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it provides an initial rationale but lacks sufficient detail to fully substantiate the claim.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the potential weakness of using reinforcement learning for a static Visual Question Answering (VQA) task, suggesting that it may make the approach less data-efficient and harder to train models using gradient descent. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions about the implementation of the bilinear layer, asking for clarification on how it differs from other approaches that use bilinear pooling. It specifically inquires about the differences in dimensionality of embeddings, the swapping out of the bilinear layer with Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still applied. While the comment highlights areas that need clarification, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer the specific changes or clarifications required. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L290,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the differences between the implemented bilinear layer and other approaches, asking for clarification on the dimensionality of embeddings and the swapping out of the bilinear layer with Hadamard product and MCB approaches. Additionally, it inquires about the compression of representations using Equation (3). This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the implementation of the bilinear layer and its differences from other approaches. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises several questions about the implementation of the bilinear layer, specifically asking for clarification on how it differs from other approaches that use bilinear pooling. It inquires about the differences in dimensionality of embeddings, the swapping out of the bilinear layer with Hadamard product and MCB approaches, and whether the compression of representations using Equation (3) is still applied. While the comment identifies areas that need clarification, it does not provide specific suggestions or guidance on how the authors might address these questions. The feedback is somewhat helpful as it prompts the authors to clarify their methodology, but it could be more beneficial with additional context or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the results of the latter loss term of Eqn 13, suggesting that since the preactivation values of two networks are the same membrane potentials, their output cosine similarity will be very high. The reviewer implies that the authors should directly illustrate the results of the latter loss term. However, the comment does not explicitly instruct the authors to make this change or provide detailed guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should illustrate the results of the latter loss term. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Fig. 3 e,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning why the results of the latter loss term of Eqn 13 are not directly illustrated, given that the preactivation values of two networks are the same membrane potentials. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the rationale behind illustrating the results of the latter loss term of Eqn 13, given that the preactivation values of two networks are the same membrane potentials. The comment suggests that the output cosine similarity will be very high, implying that illustrating the latter loss term might be redundant. However, the comment lacks specific reasoning or evidence to support this claim, such as examples or references to similar situations where illustrating the latter loss term might be unnecessary. This makes the claim somewhat verifiable, as it provides a logical basis but lacks detailed justification or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the results presented in Figure 3, specifically regarding the output cosine similarity of two networks with identical preactivation values. It suggests that illustrating the latter loss term of Eqn 13 might be redundant given the high cosine similarity. While the comment identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their presentation. The feedback is somewhat helpful as it prompts the authors to reconsider their approach to illustrating results, but it lacks depth and actionable advice. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a gap in the paper's analysis by pointing out the lack of comparison with test-time adaptation (TTA) methods. It suggests that these methods, which aim to adapt to out-of-distribution data, should be considered for comparison. The reviewer also questions the superiority of data processing over model parameter adjustment and recommends a comparison based on experimental results. While the comment implies that the authors should include a comparison with TTA methods, it does not provide specific guidance on how to conduct this comparison or what metrics to use. The action is implicit and somewhat vague, as the authors need to infer the steps to take to address the feedback. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the issue of robustness in video action recognition and the lack of comparison with test-time adaptation (TTA) methods. It provides specific guidance by suggesting a comparison with methods like [A-B] and questions the superiority of data processing over model parameter adjustment. This gives the authors clear direction on what needs to be addressed and why. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a claim about the lack of comparison with test-time adaptation (TTA) methods in the paper, which is relevant to the issue of robustness in video action recognition. The reviewer provides a logical reasoning by explaining that TTA methods aim to adapt to out-of-distribution data when the input data is disturbed by noise, and questions the superiority of data processing over model parameter adjustment. However, the comment does not provide specific examples or references to support the claim, such as the methods [A-B] mentioned. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further explore and understand the basis of the critique to address it effectively.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a gap in the paper's analysis by pointing out the lack of comparison with test-time adaptation (TTA) methods, which are relevant to the issue of robustness in video action recognition. It suggests that these TTA methods, which aim to adapt to out-of-distribution data, should be considered for comparison. The comment also questions the superiority of data processing over model parameter adjustment, prompting the authors to justify their approach. While the feedback is clear and highlights an important area for improvement, it could be more helpful by providing specific suggestions on how to conduct the comparison or what metrics to use. Nonetheless, the comment offers valuable insights and direction for enhancing the paper, making it mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly identifies an error in Section 3.2.1, specifically pointing out that the first expression for J (\u03b8) is incorrect and should be Q (s_t^0, \u03c0_\u03b8 (s_t^0)). This direct feedback provides the authors with a clear and concrete action to correct the expression in their draft. The comment is specific and leaves no ambiguity about what needs to be changed, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 3.2.1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the first expression for J (\u03b8) and provides the correct expression. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the first expression for J (\u03b8) in Section 3.2.1 is incorrect and should be Q (s_t^0, \u03c0_\u03b8 (s_t^0)). This claim is supported by a specific correction, providing a clear and precise indication of what needs to be changed. The comment is fully verifiable as it offers a direct and actionable suggestion for improvement, making it a clear and robust justification. Therefore, the comment is classified as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment is highly helpful as it provides a specific and actionable correction to the manuscript. It identifies an error in Section 3.2.1, where the first expression for J (\u03b8) is incorrectly stated and should be corrected to Q (s_t^0, \u03c0_\u03b8 (s_t^0)). This feedback is clear and directly addresses a factual inaccuracy, allowing the authors to make a precise correction to improve the accuracy and clarity of their work. The specificity and directness of the comment make it highly beneficial for the authors in refining their draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It identifies specific issues with the manuscript, such as the need to correct capitalization in various words within the references and to specify the publication venues for certain works. The comment also points out a specific issue with the manuscript's formatting, such as the need to correct capitalization in the references. These instructions are clear and actionable, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \\\"p.8\\\" and \\\"references,\\\" allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the need to correct capitalization in various words within the references and to specify the publication venues for certain works. Additionally, it provides specific examples of words that need capitalization and lists the publications for Dusenberry et al., Osawa et al., and Swiatkowski et al. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a series of observations and corrections regarding the manuscript's formatting and capitalization. It does not contain any subjective claims or opinions that require justification or evidence. The comment is factual and descriptive, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on several aspects of the manuscript. It identifies issues with capitalization in various words within the references, such as \\\"ai\\\" in Amodei et al. (2016), \\\"bayesian\\\" in many papers, and \\\"Advances in neural information processing systems\\\" in several papers. Additionally, it points out the need to specify the publication venues for certain works, such as Dusenberry et al. (2020) and Osawa et al. (2019). These comments are clear and detailed, offering the authors precise guidance on how to improve the accuracy and professionalism of their manuscript. The feedback is highly helpful as it directly addresses multiple areas for enhancement, ensuring that the authors can make significant improvements to their draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises questions about the model parameters for task 1 and the choice of the Boltzmann policy parameter lambda. It also asks how the parameters were chosen, specifically questioning whether maximum likelihood estimates were used. While the comment implies that the authors should provide these details, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks concrete guidance on how to present this information. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment raises questions about the model parameters for task 1 and the choice of the Boltzmann policy parameter lambda. It also asks how the parameters were chosen, specifically questioning whether maximum likelihood estimates were used. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in detailing what information is missing or needs clarification regarding the model parameters and their selection process. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the model parameters and their selection process. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the lack of information regarding model parameters, specifically asking for the model parameters for task 1 and the choice of the Boltzmann policy parameter lambda. It also questions how these parameters were chosen, suggesting that maximum likelihood estimates might have been used. This feedback is somewhat helpful as it identifies a gap in the paper's presentation of parameter details, which is crucial for reproducibility and understanding the methodology. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of what information should be included. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the performance of the model when Conditional Batch Norm (CBN) is applied to different layers, specifically questioning why performance deteriorates when CBN is applied to layer 2 in addition to layers 3 and 4 compared to applying it only to layers 4 and 3. The reviewer explicitly asks the authors to provide an explanation for this observation. While the action is clear, it lacks concrete guidance on how the authors should address this issue or what specific aspects to investigate. The authors are given a direct request for clarification but are not provided with detailed steps on how to proceed. Therefore, the comment is somewhat actionable, as it identifies an area for further exploration but lacks detailed guidance on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of performance deterioration when applying Conditional Batch Norm (CBN) to layer 2 in addition to layers 3 and 4, compared to applying it only to layers 4 and 3. The comment further requests clarification on why this might be happening, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a question about the performance of the model when applying Conditional Batch Norm (CBN) to different layers. It suggests that the performance deteriorates when CBN is applied to layer 2 in addition to layers 3 and 4, compared to applying it only to layers 4 and 3. However, the comment does not provide any supporting evidence, reasoning, or references to explain why this might be the case. The lack of detailed justification or explanation makes the claim unverifiable, as it does not provide enough information for the authors to understand or address the issue effectively. Therefore, the comment is rated as 1: Unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the performance of the model when applying Conditional Batch Norm (CBN) to different layers. It points out that performance deteriorates when CBN is applied to layer 2 in addition to layers 3 and 4, compared to applying it only to layers 4 and 3. The comment requests clarification on why this might be happening, which is a valuable question that could guide the authors in understanding and addressing potential issues in their methodology. However, the comment does not provide suggestions or guidance on how the authors might investigate or resolve this performance issue. While it highlights an important area for further exploration, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a similarity between spurious features in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns appearing only a few times in the training set. It references examples from Chen et al. (2017) and Gu et al. (2019) to illustrate this point. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. It lacks actionable details, such as recommending ways to mitigate the impact of these spurious features or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 3.1 and 3.2,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by comparing the spurious features in these sections to backdoor triggers, providing examples from Chen et al. (2017) and Gu et al. (2019) to illustrate the point. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the spurious features in Section 3.1 and 3.2 are similar to backdoor triggers, noting that both are artificial patterns appearing only a few times in the training set. The reviewer supports this claim by referencing examples from Chen et al. (2017) and Gu et al. (2019), which use random noise patterns and single-pixel/simple patterns as triggers, respectively. This provides a logical basis for the claim, as it compares the observed patterns to known examples of backdoor triggers. However, the comment could be strengthened by providing more detailed comparisons or additional references to further substantiate the claim. As it stands, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a similarity between the spurious features discussed in Section 3.1 and 3.2 and backdoor triggers, noting that both are artificial patterns that appear only a few times in the training set. It provides references to relevant works, such as Chen et al. (2017) and Gu et al. (2019), to support the claim. This feedback is somewhat helpful as it highlights a potential issue with the paper's discussion of spurious features and provides context from existing literature. However, it lacks specific suggestions on how the authors might address this issue or improve their analysis. While it points out an area for further exploration, it does not offer actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests renaming a column in Table 1 to clarify the distinction between fully supervised and semi-supervised training, and proposes a more detailed approach by specifying the data used to train different parts of each model. The reviewer offers specific suggestions for renaming the column and suggests a more comprehensive way to present the information, such as using two columns labeled 'Mixture training data' and 'Single source data.' This level of detail provides clear guidance on how to improve the clarity and organization of the paper, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1\\\" and suggests renaming a column to clarify the distinction between fully supervised and semi-supervised training. It also provides specific suggestions for improving the clarity of the table by specifying the data used to train different parts of each model. This level of detail allows the authors to accurately identify the part of the paper being addressed and understand the specific issues that need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should clarify the distinction between fully supervised and semi-supervised training, particularly in Table 1. The reviewer provides a specific example of renaming a column to improve clarity and offers a more detailed suggestion by proposing two columns labeled 'Mixture training data' and 'Single source data.' This feedback is mostly verifiable as it provides a clear rationale for the suggestion and offers a concrete example of how to improve the presentation of the data. However, it could be further strengthened by explaining why this distinction is important or how it impacts the understanding of the proposed method. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides clear and actionable feedback on improving the clarity of the paper, specifically regarding the distinction between fully supervised and semi-supervised training. It suggests renaming a column in Table 1 to better reflect the training approach and proposes a more detailed approach by specifying the data used to train different parts of each model. This guidance is specific and offers a concrete way for the authors to enhance the clarity and organization of their work, making it highly helpful. The comment effectively empowers the authors to make significant improvements to their draft, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights an issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where the dependency tree and RL are not used. While the comment identifies a specific issue, it does not provide explicit guidance on how to address it. The authors can infer that they need to include the missing cases in the tables, but the comment lacks concrete instructions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"ablation experiment\\\" and the \\\"two tables,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the performance without reinforcement learning dropped lower than without the dependency tree and notes that the tables do not list the cases where the dependency tree and RL are not used. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes a claim about the ablation experiment, stating that the performance without reinforcement learning dropped lower than without the dependency tree. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. The comment also mentions that the two tables do not list the cases where the dependency tree and RL are not used, but it does not elaborate on why this is an issue or how it affects the results. Without additional context or explanation, the claim is not verifiable, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1: Unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the ablation experiment, noting that the performance without reinforcement learning dropped lower than without the dependency tree. It also points out that the two tables do not list the cases where the dependency tree and RL are not used. This feedback is somewhat helpful as it highlights a potential gap in the experimental results and suggests that the authors should include these cases in their analysis. However, the comment could be more helpful if it provided suggestions on how to address this issue or why it is important to include these cases. Overall, the comment offers some insight into a potential weakness but lacks detailed guidance, making it somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section, which only considers the CIFAR-10 dataset and does not include evaluations on other datasets from Federated learning benchmarks. The reviewer suggests that the authors should consider additional datasets, such as those from the LEAF benchmark, and references relevant works like FedProx and FedMAX for guidance on different datasets and model types. While the comment provides a clear direction for expanding the experimental evaluation, it lacks specific guidance on which datasets to include or how to integrate the suggested references into the paper. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"experiments section,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limited scope of the experiments, focusing only on the CIFAR-10 dataset and not considering other datasets from Federated learning benchmarks. The comment further provides suggestions for improvement by recommending the inclusion of relevant works like FedProx and FedMAX for details on different datasets and model types. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the main weakness of the paper is the limited scope of the experiments section, which only considers the CIFAR-10 dataset and does not include evaluations on other datasets from Federated learning benchmarks. The reviewer supports this claim by suggesting relevant works, such as FedProx and FedMAX, which provide details on different datasets and model types. This reference to external works provides a solid foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by providing more specific examples or detailed comparisons with the suggested datasets, which would enhance the verifiability of the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant weakness in the paper, specifically the limited scope of the experiments section, which only considers the CIFAR-10 dataset. It suggests that the authors should broaden their experimental evaluation to include other datasets from Federated learning benchmarks, such as those available in the LEAF benchmark. The comment also provides references to relevant works, like FedProx and FedMAX, which could guide the authors in selecting appropriate datasets and model types for their experiments. This feedback is clear, actionable, and offers specific suggestions for improvement, making it highly helpful for the authors to enhance their draft. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the construction of clean exemplar manifolds for non-stochastic networks and how the denominator of Figure 2.c is computed for specific networks. While the comment highlights a potential inconsistency or lack of clarity in the paper, it does not provide explicit instructions or suggestions for the authors to address this issue. The authors can infer that they need to clarify this aspect, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions lines 182-183 and Figure 2.c, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning how clean exemplar manifolds are constructed for non-stochastic networks and how the denominator of Figure 2.c is computed for specific networks. This level of detail provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the construction of clean exemplar manifolds and the computation of the denominator in Figure 2.c. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a specific question about the construction of clean exemplar manifolds for non-stochastic networks and the computation of the denominator in Figure 2.c. This feedback highlights a potential inconsistency or lack of clarity in the paper, prompting the authors to clarify their methodology or provide additional details. While the comment identifies an area that needs further explanation, it does not offer specific suggestions or guidance on how to address the issue. The authors are left with a clear question but without detailed direction on how to resolve it. Therefore, the comment is somewhat helpful, as it provides insight but lacks comprehensive guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a specific issue with the notation used in the paper, particularly the explicit split between \\\"static\\\" and temporal features into two variables, S and Xt. The reviewer suggests that this split requires more information than is currently provided in the paper. While the comment highlights a potential area for improvement, it does not explicitly instruct the authors on how to address this issue or provide guidance on what additional information should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details about the variables S and Xt. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the notation and the explicit split between \\\"static\\\" and temporal features into two variables, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for more information about what S and Xt represent. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the notation and the explicit split between \\\"static\\\" and temporal features into two variables (S and Xt) are confusing. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this split is confusing or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the notation used in the paper, particularly the explicit split between \\\"static\\\" and temporal features into two variables, S and Xt. It highlights that this split is confusing and requires more information than is currently provided. While the comment points out a potential area for improvement, it lacks detailed guidance or suggestions on how the authors might clarify or improve the notation. The feedback is somewhat helpful as it directs the authors' attention to a specific area that needs clarification, but it could be more beneficial with additional guidance or examples. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not straightforward and clear. It notes that the paper states the choice is empirical but lacks motivation for this specific form. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the clarity of the motivation. The feedback is vague and lacks concrete steps for the authors to follow, leaving them uncertain about how to enhance the clarity of their explanation. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Theorem 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$, noting that the paper states the choice is empirical but lacks motivation for this specific form. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3 is not straightforward and clear. The reviewer notes that the paper states the choice is empirical but lacks motivation for this specific form. While the comment identifies a potential issue, it does not provide specific examples or detailed reasoning to support the claim that the motivation is lacking. This makes the claim somewhat verifiable, as it highlights a gap but requires further elaboration for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the motivation for the choice of $\\\\theta = \\\\frac{\\\\pi}{2}(1-h)$ from Theorem 3. It points out that the paper states the choice is empirical but lacks a clear and detailed explanation of why this particular form was chosen. This feedback is somewhat helpful as it highlights a gap in the paper's justification, prompting the authors to provide more context or reasoning for their choice. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or motivation of this aspect. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights the absence of an ablation study, which could cause confusion and extra experimentation for practitioners. It specifically mentions the importance of analyzing the role of \\\\(\\\\sigma\\\\) in the RBF kernel and suggests exploring the effects of \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7) on performance. While the comment provides explicit actions for the authors to take, such as conducting ablation studies and analyzing the parameters, it lacks concrete guidance on how to implement these analyses. The authors are given a clear direction but may need to determine the specifics of the experiments themselves. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the need for an ablation study and provides specific examples of parameters that should be analyzed, such as \\\\(\\\\sigma\\\\) in the RBF kernel and \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7). This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed, namely the inclusion of an ablation study and the analysis of the mentioned parameters. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that an ablation study is missing, which could cause confusion and extra experimentation for practitioners. It highlights the importance of analyzing the role of \\\\(\\\\sigma\\\\) in the RBF kernel and suggests exploring the effects of \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7) on performance. While the comment identifies specific areas that could be improved, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for an ablation study is logical, but the comment could be strengthened with more explicit justification or references to similar studies. Therefore, the comment is somewhat verifiable, aligning with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area for improvement by pointing out the absence of an ablation study, which could be confusing for practitioners. It highlights the importance of analyzing the role of \\\\(\\\\sigma\\\\) in the RBF kernel and suggests exploring the effects of \\\\(\\\\eta\\\\) and \\\\(\\\\tau\\\\) in equation (7) on performance. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. However, the comment could be more helpful if it offered specific suggestions on how to conduct these analyses or provided examples of similar studies. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention and offers a clear path for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment questions the claim made in section 2 regarding the per-data-instance operation of INRs, suggesting that it is not an advantage. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 2\\\" and the specific claim about INRs operating on a per-data-instance basis. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it questions the claim's validity as an advantage, suggesting that a model handling only a single time series is almost useless. This provides clear guidance on what the authors need to consider or address in their paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the claim that INRs operate on a per-data-instance basis, suggesting that this is not an advantage. The reviewer provides a logical reasoning by stating that a model capable of handling only a single time series is almost useless. However, the comment lacks specific examples or references to support the claim that such a model is indeed useless or to provide a more detailed explanation of why this is the case. This makes the claim somewhat verifiable, as it provides a rationale but requires additional evidence or examples to fully substantiate the argument.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment questions the claim made in section 2 regarding INRs operating on a per-data-instance basis, suggesting that this is not an advantage. While the comment identifies a potential issue with the paper's argument, it does not provide specific suggestions or guidance on how the authors might address this concern or improve their draft. The feedback is somewhat helpful as it prompts the authors to reconsider their claims, but it lacks actionable advice or detailed guidance, making it less comprehensive. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies a limitation in the experiments, noting that most are conducted using only the RoBERTa-base model. It suggests that the authors should investigate the generalizability of the results to other models, such as those with learnable APEs, and consider differences in model size, objective function, and architecture. The comment specifically requests additional analysis and discussion, particularly for GPT-2, and mentions including results for Figure 2 for GPT-2. This feedback provides clear and concrete actions for the authors to take, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"most of the experiments\\\" and \\\"Section 4.1.1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the generalizability of the results to other models with learnable APEs, and suggests including more analysis and discussion for GPT-2, particularly for Figure 2. This provides clear guidance on what additional experiments or analyses should be conducted. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the limited scope of the experiments, noting that most are conducted using only the RoBERTa-base model. It suggests that the results may not be generalizable to other models with learnable APEs and proposes additional analysis and discussion for models like GPT-2. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim about generalizability. The suggestion to include results for GPT-2 is a logical step, but without further justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the scope of the experiments, noting that most are conducted using only the RoBERTa-base model. It suggests that the results may not be generalizable to other models with learnable APEs and proposes additional analysis and discussion for models like GPT-2. This feedback is clear and actionable, as it provides specific directions for expanding the experimental scope and enhancing the generalizability of the findings. By recommending the inclusion of results for GPT-2 and other models, the comment offers valuable guidance for improving the robustness and applicability of the research. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the generalizability of the parameters and models presented in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs. While the comment suggests a potential direction for improvement, it does not explicitly instruct the authors to conduct these experiments or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should test the method on different architectures and tasks. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear concern about the generalizability of the parameters and models presented in the table, suggesting that the authors should explore applying the same principles to other research areas such as NLP or simpler models like CNNs. This provides a clear direction for the authors to consider in order to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the generalizability of the parameters and models presented in Table 1, suggesting that they might be specific to image data and ViT. The reviewer implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs. While the comment raises a valid concern about the scope of the study, it lacks specific examples or references to support the claim that the method should be tested on different architectures and tasks. The suggestion to test on other areas is logical, but without detailed justification or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a valid concern about the generalizability of the parameters and models presented in Table 1, suggesting that they might be specific to image data and ViT. It implies that the authors should explore applying the same principles to other research areas, such as NLP or simpler models like CNNs, to demonstrate the method's broader applicability. This feedback is clear and actionable, as it encourages the authors to test their method on different architectures and tasks, which could significantly enhance the paper's impact and demonstrate its versatility. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these additional experiments. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors evaluate their TTA methods on more conditions of natural distribution shift, specifically mentioning WILDS [9] as an example. While the suggestion is explicit, it lacks concrete details on how to implement this evaluation or what specific aspects of TTA should be considered. The authors are given a clear direction to expand their evaluation, but the comment does not provide detailed guidance on how to achieve this. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but lacks detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"Performance of TTA methods\\\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests evaluating TTA methods on more conditions of natural distribution shift, such as WILDS [9], which provides a clear direction for improvement. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes an observation about the performance of TTA methods when using non-standard benchmarks, suggesting that this observation could be strengthened by evaluating TTA methods on more conditions of natural distribution shift, such as WILDS [9]. While the comment provides a logical suggestion for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The reference to WILDS [9] is helpful, but the comment could be more robust with additional context or evidence. Therefore, the claim is somewhat verifiable, as it provides a direction for improvement but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies an interesting observation regarding the performance of TTA methods when using non-standard benchmarks, noting that it breaks popular TTA methods. It suggests that evaluating TTA methods on more conditions of natural distribution shift, such as WILDS [9], could strengthen the paper. This feedback is clear and actionable, providing a specific direction for the authors to enhance their work by expanding the evaluation of their TTA methods. However, the comment could be more helpful if it offered additional guidance on how to implement this evaluation or what specific aspects of TTA should be considered. Overall, the comment is mostly helpful as it provides a clear path for improvement but could be more comprehensive with additional details.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should use a more convincing setting for their experiments, specifically by directly sampling unlabeled data from millions of reviews, as done in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al. This feedback provides a clear and explicit action for the authors to take, which is to adopt a different approach for handling unlabeled data. The suggestion is concrete, as it specifies a particular method to implement, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the use of the \\\"preprocessed Amazon review dataset (Blitzer version)\\\" and the specific issue with the \\\"unlabeled data (2000)\\\" being perfectly balanced. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it suggests using a more convincing setting, referencing the approach used in \\\"Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification\\\" by He et al., EMNLP 2018. This provides clear guidance on what the authors should consider to improve their work. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the use of perfectly balanced unlabeled data from the Blitzer version of the Amazon review dataset is impractical in real-world applications. The reviewer suggests that a more convincing setting, as used in Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification by He et al., EMNLP 2018, should be adopted. This claim is supported by logical reasoning, as it highlights the practical limitations of the current approach and references a specific method from another study. However, the comment could be strengthened by providing more detailed comparisons or examples from the referenced work to fully substantiate the claim. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the use of unlabeled data from the Blitzer version of the Amazon review dataset, noting that it is perfectly balanced and impractical for real-world applications. It suggests that the authors should consider a more convincing setting, as demonstrated in the Adaptive Semi-supervised Learning for Cross-domain Sentiment Classification paper by He et al., EMNLP 2018. This feedback is clear and actionable, providing the authors with a concrete suggestion to improve the practicality and relevance of their experimental setup. By referencing a specific paper, the comment offers a clear direction for enhancing the draft, making it highly helpful for the authors. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances may perform better with one modality over another. It questions how Equation 3 handles this issue by removing the modal subset of all instances. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or modify their approach. The action is implicit and vague, as it lacks concrete steps or details on how to resolve the issue. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses a specific issue related to the contribution of different modalities and instances, particularly in the context of Equation 3. It highlights a potential problem with the equation's approach to handling different modalities. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with Equation 3 and the need to address the issue of different modalities, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the contribution of different modalities and instances, suggesting that some instances may perform better with one modality over another. It questions how Equation 3 handles this issue by removing the modal subset of all instances. However, the comment lacks specific examples, detailed reasoning, or references to support the claim. Without these elements, the authors may find it challenging to understand and address the issue effectively. Therefore, the comment is considered borderline verifiable, as it provides some insight but lacks sufficient evidence or detail to fully substantiate the claim.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the contribution of different modalities and instances, suggesting that some instances may perform better with one modality over another. It questions how Equation 3 handles this issue by removing the modal subset of all instances. While the comment highlights a relevant concern, it lacks specific suggestions or guidance on how the authors might address this problem or improve their approach. The feedback is somewhat helpful as it points out a potential weakness in the methodology, but it could be more beneficial with additional details or recommendations for improvement. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a confusing aspect of the description of the MFDA setting in the Method Section, specifically regarding the notation for the target domain \\\\(\\\\tau\\\\) and the use of unlabeled data in source domains. The reviewer points out that the problem setting description differs significantly from the original MFDA paper (Yue et al., 2021a). However, the comment does not provide explicit guidance on how to clarify these points or suggest specific actions for the authors to take. The feedback highlights an issue but lacks actionable steps or concrete suggestions for improvement, leaving the authors uncertain about how to address the confusion. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"first paragraph of the Method Section,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the confusion regarding the description of the MFDA setting, particularly the notation for the target domain \\\\(\\\\tau\\\\) and the use of unlabeled data in source domains. The comment references the original MFDA paper (Yue et al., 2021a) to highlight the discrepancy, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the confusion in the description of the MFDA setting in the Method Section, specifically regarding the notation for the target domain \\\\(\\\\tau\\\\) and the use of unlabeled data in source domains. The reviewer references the original MFDA paper (Yue et al., 2021a) to highlight the discrepancy, providing a clear comparison point. This reference to an external source supports the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples from the original paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the description of the MFDA setting in the Method Section, noting confusion regarding the notation for the target domain and the use of unlabeled data in source domains. It highlights a discrepancy with the original MFDA paper (Yue et al., 2021a), which could lead to misunderstandings. While the comment points out a critical area for clarification, it does not provide detailed suggestions or guidance on how to resolve the confusion or improve the description. The feedback is somewhat helpful as it directs the authors to a specific area needing clarification, but it could be more beneficial with additional guidance on how to address the issue. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that epoch-wise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It provides specific examples, such as investigating the effect of batch size or different sampling strategies with respect to the progress of the algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis between deterministic and stochastic methods. While the comment provides a clear direction for the authors to consider, it does not offer detailed guidance on how to conduct this analysis or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests that epoch-wise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It provides specific examples, such as investigating the effect of batch size or different sampling strategies with respect to the progress of the algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis between deterministic and stochastic methods. However, the comment does not explicitly mention which part of the paper this analysis should be included in, making it weakly grounded. Despite this, the comment is specific in detailing what could be explored through epoch-wise analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that epoch-wise analysis could provide insights into the behavior of optimization algorithms, particularly in finite sum settings. It provides specific examples, such as investigating the effect of batch size or different sampling strategies with respect to the progress of the algorithms after every full pass of data. Additionally, it mentions the potential for comparative analysis between deterministic and stochastic methods. While the comment offers logical reasoning and examples, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a constructive suggestion for enhancing the paper by proposing epoch-wise analysis, particularly in the context of finite sum settings. It highlights the potential benefits of this approach, such as investigating the effects of batch size and different sampling strategies on the progress of optimization algorithms. Additionally, it suggests that this analysis could facilitate a comparative study between deterministic and stochastic methods. While the comment identifies a valuable area for improvement and offers a clear direction for exploration, it could be more helpful by providing specific guidance on how to implement this analysis or by suggesting particular aspects to focus on. Despite this, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises concerns about the clarity of distinguishing between the three classes of extreme speech, specifically questioning the differentiation between derogatory and exclusionary extreme speech. It provides a specific example from the sample data file to illustrate the confusion and asks for clarification on the local regulation mentioned in the paper. The reviewer also questions whether this regulation affects zero-shot cross-country classification. While the comment highlights areas of confusion and seeks clarification, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to clarify the definitions and provide more detailed explanations, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"Paper Summary\\\" and provides specific examples from the sample data file, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of differentiating between the three classes of extreme speech, particularly the confusion between derogatory and exclusionary extreme speech. The comment further questions the role of local regulation in annotations and its impact on zero-shot cross-country classification. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the clarity of distinguishing between the three classes of extreme speech, specifically questioning the differentiation between derogatory and exclusionary extreme speech. The reviewer provides a specific example from the sample data file to illustrate the confusion, which adds some level of verifiability. However, the comment lacks further detailed reasoning or references to support the claim that the distinction is difficult to differentiate. While the example is helpful, the overall claim could be strengthened with more comprehensive evidence or references. Therefore, the comment is categorized as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the clarity of distinguishing between the three classes of extreme speech, particularly the confusion between derogatory and exclusionary extreme speech. It provides a concrete example from the sample data file to illustrate the problem, which is valuable for the authors to understand the issue. The comment also questions the role of local regulation in annotations and its impact on zero-shot cross-country classification, prompting the authors to consider these aspects in their analysis. While the comment highlights important areas for improvement, it could be more helpful by offering suggestions on how to address the clarity issue or by providing additional examples or references. Overall, the feedback is mostly helpful as it directs the authors' attention to critical areas needing clarification and further exploration.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a limitation in the study regarding the effect of noise accumulation in sequential ensembling, particularly in the context of homomorphic encryption. However, it does not provide explicit guidance or suggestions on how the authors should address this limitation or improve their study. The comment implies that the authors should consider this limitation but does not offer concrete steps or recommendations for how to do so. As a result, the action is implicit and vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses a specific limitation related to sequential ensembling and noise accumulation in the context of homomorphic encryption. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the limitation and its implications for using deep neural networks on homomorphically encrypted data. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that studying the effect of noise accumulation in sequential ensembling is important for homomorphic encryption, which limits the use of deep neural networks on homomorphically encrypted data. However, the comment does not provide specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific limitation in the study related to sequential ensembling and noise accumulation in the context of homomorphic encryption. It highlights that this limitation prevents the use of even single deep neural networks on homomorphically encrypted data. While the comment points out an important area for consideration, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this limitation or improve their study. The feedback is somewhat helpful as it directs the authors' attention to a critical issue, but it could be more beneficial with additional context or recommendations for improvement. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly suggests including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This provides a clear and direct action for the authors to take, as it specifies exactly what additional information should be added to the figure. The suggestion is concrete, as it outlines the specific comparison that should be made, allowing the authors to directly implement the change. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"fig 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including a learning curve for a model without mean teacher or pi regularization for comparison, providing clear guidance on what additional information should be added to the graph. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests including a learning curve for a model without mean teacher or pi regularization in Figure 3 to assess the impact of mean teacher on learning. While the suggestion is logical and could provide valuable insights, the comment lacks specific reasoning or evidence to support why this comparison is necessary or how it would impact the understanding of the results. The absence of detailed justification or references makes the claim somewhat verifiable, as it provides a direction for improvement but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the paper. It recommends including a learning curve for a model without mean teacher or pi regularization in the left graph of Figure 3. This addition would allow the authors to compare the learning curves and assess the impact of mean teacher on learning speed. The feedback is clear and constructive, offering a concrete step for the authors to enhance their analysis and results presentation. By addressing this suggestion, the authors can provide a more comprehensive understanding of their model's performance. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the parameters of the transformation \\\\(\\\\phi\\\\) and the shared model \\\\(\\\\theta_S\\\\). It points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how the authors should address this issue or what specific aspects should be clarified. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the parameter count comparison with prior work. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq. 2 in line 128,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of discussion regarding the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019). This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point highlights a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the parameters of the transformation \\\\(\\\\phi\\\\) and the shared model \\\\(\\\\theta_S\\\\). The comment points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This claim is somewhat verifiable as it identifies a gap in the discussion but lacks detailed reasoning or specific examples to fully substantiate the claim. The authors would need to further explore and clarify this point themselves, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the proposed objective equation (Eq. 2) in line 128, noting that it requires optimization over both the parameters of the transformation \\\\(\\\\phi\\\\) and the shared model \\\\(\\\\theta_S\\\\). It points out that the effect on the number of parameters compared to prior work, such as AlignFlow (Grover et al., 2019), has not been discussed clearly. This feedback is somewhat helpful as it highlights a potential gap in the paper's discussion and encourages the authors to address this issue. However, the comment could be more helpful if it provided specific suggestions on how to clarify or discuss the parameter count comparison with prior work. Overall, the comment offers a direction for improvement but lacks detailed guidance, making it somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the relationship between Eq. 4 and Eq. 3, suggesting that if Eq. 4 holds, it might imply that the u^l in Eq. 3 tends to be 1. This is an explicit question that requires the authors to clarify or address this relationship. Additionally, the comment notes that the improvement of the designed solutions in Table 5 is not significant on some datasets, providing specific examples like the OfficeHome dataset where the improvement is marginal. This feedback is explicit and provides concrete details on what the authors need to address, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq. 4\\\" and \\\"Eq. 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the relationship between these equations and noting that the improvement in Table 5 is not significant on some datasets, providing specific examples like the OfficeHome dataset. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of two parts. The first part is a question seeking clarification about the relationship between equations, which is a request for information and not a claim. The second part makes a claim about the significance of the improvement in Table 5, noting that the improvement on some datasets is marginal. This claim is somewhat verifiable as it provides specific examples (OfficeHome dataset) to illustrate the point, but it lacks detailed reasoning or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment addresses two distinct points. First, it raises a question about the relationship between Eq. 4 and Eq. 3, prompting the authors to clarify the implications of Eq. 4 on Eq. 3. This is a clear and actionable suggestion that can help the authors improve the clarity and coherence of their theoretical framework. Second, the comment notes that the improvement in the designed solutions in Table 5 is not significant on some datasets, providing specific examples like the OfficeHome dataset. This feedback is valuable as it highlights areas where the authors need to strengthen their results or provide more robust evidence. However, the comment could be more helpful if it offered suggestions on how to address the lack of significant improvement or alternative approaches to demonstrate the effectiveness of the proposed solution. Overall, the comment is mostly helpful as it identifies specific areas for improvement and provides some guidance, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies missing state-of-the-art references in the face recognition experiment, specifically mentioning \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding\\\"\\\" and its reported results. The reviewer provides specific details about the work's findings, such as the use of triplet loss and the achieved accuracy on the LFW dataset. This feedback is highly actionable because it directly instructs the authors to include these references and compare their results with the mentioned work. The explicit nature of the suggestion and the detailed information provided make it clear what the authors need to do to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"experiment of face recognition\\\" and provides specific references, such as \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\\\"\\\" which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it details the missing references and compares the results with those reported in the paper, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that certain state-of-the-art references are missing in the face recognition experiment, specifically mentioning \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\\\"\\\" and its reported results. The comment provides specific details about the work's findings, such as the use of triplet loss and the achieved accuracy on the LFW dataset, which is better than the results in Table 3 of the paper. This detailed comparison and reference to a specific work provide a robust basis for the claim, making it fully verifiable. The authors can clearly understand the basis of the claim and how it relates to their work, thus justifying a score of 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the literature review by pointing out missing state-of-the-art references in the face recognition experiment. It provides a concrete example of a relevant work, \\\"Baidu' work \\\"Targeting Ultimate Accuracy: Face Recognition via Deep Embedding,\\\"\\\" and highlights its reported results, which are better than those in the paper. This feedback is actionable as it directs the authors to include these references and compare their results with the mentioned work, potentially enhancing the paper's credibility and comprehensiveness. However, the comment could be more helpful if it suggested how these references could be integrated into the discussion or what specific aspects of the comparison should be emphasized. Overall, the comment is mostly helpful as it provides clear guidance on how to improve the draft, but it could be more comprehensive with additional suggestions.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights that the range of ID and OOD does not change much by sparsification, as shown in Figure 4, and that Lemma 2 requires approximately identical means as an assumption. It notes that these conditions are crucial for DICE but are not well discussed, specifically asking how to ensure DICE meets these conditions. While the comment identifies areas that need further discussion, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should expand the discussion on these conditions and their implications for DICE. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 4\\\" and \\\"Lemma 2,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the range of ID and OOD not changing much by sparsification and the requirement for approximately identical means in Lemma 2. The comment further specifies the need for a discussion on how to ensure DICE meets these conditions. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes a claim that the range of ID and OOD does not change much by sparsification, as shown in Figure 4, and that Lemma 2 requires approximately identical means as an assumption. The comment suggests that these conditions are crucial for DICE but are not well discussed, specifically questioning how to ensure DICE meets these conditions. While the comment provides some context and identifies areas that need further discussion, it lacks specific examples or references to substantiate the claim fully. The reasoning is somewhat verifiable, as it points out a potential gap in the discussion but does not provide detailed evidence or examples to support the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the paper, noting that the range of ID and OOD does not change much by sparsification, as shown in Figure 4. It also points out that Lemma 2 requires approximately identical means as an assumption, which is crucial for DICE but not well discussed. The comment highlights a gap in the discussion regarding how to ensure DICE meets these conditions. While the comment effectively identifies areas that need further exploration and clarification, it lacks specific suggestions or guidance on how the authors might address these issues. This limits the comment's helpfulness, as it provides insight but not actionable steps for improvement. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the update process, suggesting that it might need to integrate over all possible environments. It also provides a suggestion to break out the bolded sections in page 6 into separate paragraphs to improve readability. The comment is explicit in its request for clarification and provides a concrete action for improving the presentation of the text. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"page 6\\\" and the \\\"bolded sections,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the bolded sections, suggesting that they should be broken out into separate paragraphs to improve readability. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of two parts. The first part is a question about the update process, which does not contain a claim or opinion. The second part suggests that the bolded sections in page 6 should be broken out into separate paragraphs, which is a factual observation about the presentation of the text. Both parts are factual statements and do not require verification, so \\\"No\\\" is the appropriate label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the update process, suggesting that it might need to integrate over all possible environments. This is a relevant point that could impact the understanding and applicability of the method. Additionally, the comment provides a specific suggestion to improve the presentation of the text by breaking out the bolded sections in page 6 into separate paragraphs. This feedback is actionable and offers a clear way to enhance the readability and clarity of the paper. However, the comment could be more helpful if it provided additional context or explanation about the implications of the update process or why breaking out the bolded sections is necessary. Overall, the comment is mostly helpful as it identifies an area for improvement and provides a specific suggestion, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises several concerns about the strength and fairness of the experiments, including the use of position kernels for all baselines and the absence of certain baselines related to BO with discrete and categorical variables. It also points out the lack of discussion on the limitations or societal impacts of the proposed approach. While the comment identifies specific areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to adjust their experimental setup and include additional comparisons and discussions, but without detailed guidance, the actions remain somewhat vague. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises several concerns about the experiments, including the use of position kernels for all baselines, the absence of certain baselines related to BO with discrete and categorical variables, and the lack of discussion on limitations or societal impacts. However, it does not specify which part of the paper these concerns pertain to, such as specific sections or experiments. The authors can infer that it relates to the experimental setup and results sections, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be addressed regarding the experiments and the discussion of limitations and societal impacts, but it lacks full grounding. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises concerns about the strength and fairness of the experiments, questioning the use of position kernels for all baselines and suggesting that default settings from the literature should be used. It also mentions the absence of certain baselines related to BO with discrete and categorical variables and the lack of discussion on limitations or societal impacts. While the comment provides some reasoning for its claims, it lacks specific examples or references to support the assertion that the experiments are weak or unfair. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the points raised by the reviewer. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises several concerns about the strength and fairness of the experiments, questioning the use of position kernels for all baselines and suggesting that default settings from the literature should be used. It also points out the absence of certain baselines related to BO with discrete and categorical variables and notes the lack of discussion on limitations or societal impacts. While the comment identifies specific areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The feedback provides some direction for enhancing the paper, but it could be more actionable and comprehensive with additional details or examples. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly points out that the derivation from Equation 3 to Equation 4 is missing the temperature \\\\( \\\\tau \\\\), and it suggests that \\\\( \\\\tau \\\\) should be shown in a rigorous way or that the paper should mention it. This feedback provides a clear and direct action for the authors to take, specifying exactly what is missing and how it should be addressed. The comment is explicit and concrete, giving the authors a precise understanding of what needs to be done to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eqn. 3\\\" and \\\"Eqn. 4,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing\\u2014the temperature \\\\( \\\\tau \\\\) should be shown in a rigorous way or mentioned in the paper. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the derivation from Equation 3 to Equation 4 is missing the temperature \\\\( \\\\tau \\\\), and suggests that it should be shown in a rigorous way or mentioned in the paper. This claim is somewhat verifiable as it points out a specific omission in the derivation, which is a logical observation. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the omission is significant or how it affects the results. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the derivation from Equation 3 to Equation 4, noting that the temperature \\\\( \\\\tau \\\\) is missing. It suggests that \\\\( \\\\tau \\\\) should be shown in a rigorous way or mentioned in the paper. This feedback is clear and actionable, providing the authors with a precise point of improvement that can enhance the rigor and clarity of their work. By addressing this issue, the authors can improve the comprehensiveness and accuracy of their derivation. However, the comment could be more helpful if it offered additional guidance on how to present \\\\( \\\\tau \\\\) rigorously or mentioned specific ways to incorporate it into the derivation. Overall, the comment is mostly helpful as it directs the authors to a critical area needing attention, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to add a citation on differential privacy, specifically mentioning a standard work like [2]. This provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Line 156,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding a citation on differential privacy, providing a clear direction for improvement. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests adding a citation on differential privacy to improve the reader's understanding. However, it does not provide any justification or reasoning for why this addition would be beneficial or necessary. The comment lacks specific examples or references to support the claim, making it difficult for the authors to understand the importance of the suggestion. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion by recommending the addition of a citation on differential privacy, referencing a standard work like [2]. This feedback is clear and directly guides the authors on how to enhance the credibility and comprehensibility of their work by providing relevant background information. By addressing this point, the authors can improve the reader's understanding of the context and significance of their work. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides two specific observations and suggests corrections. First, it questions the claim about the methodology requiring significant additional assumptions, suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural for many machine learning settings. Second, it points out an error in the inequality on line 310, suggesting that it should be compared to the inequality on line 227. These comments are explicit and provide concrete actions for the authors to take, such as revising the claim or correcting the inequality. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"first para of Section 3.2\\\" and the specific lines (310 and 227), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the claim about additional assumptions and points out a specific error in the inequality. The comment clearly specifies what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the claim that \\\"this methodology requires significant additional assumptions\\\" by suggesting that the only additional assumption is that the test set be drawn from the same distribution as the query set, which is a common assumption in many machine learning settings. The reviewer provides a logical reasoning by explaining that this assumption is natural and often made in machine learning contexts. Additionally, the comment points out an error in the inequality on line 310, which further supports the claim. This detailed explanation and logical reasoning make the comment fully verifiable, as it provides a clear rationale for the claim and identifies specific issues that need attention. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides two specific pieces of feedback. First, it challenges the claim that the methodology requires significant additional assumptions, suggesting that the assumption of the test set being drawn from the same distribution as the query set is natural for many machine learning settings. This feedback prompts the authors to reconsider the strength of their claim and potentially revise it for accuracy. Second, the comment points out a specific error in the inequality on line 310, suggesting that it should be compared to the inequality on line 227. This detailed and actionable feedback provides clear guidance on how the authors can improve the accuracy and clarity of their paper. Overall, the comment is highly helpful as it offers both critical evaluation and constructive suggestions for improvement.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies several writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed guidance on how to address these issues. The authors are left with a general understanding of the problems but without concrete steps to improve the writing quality. The comment lacks explicit instructions or concrete details, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment identifies several writing issues, such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not specify which sections or parts of the paper these issues are found in, making it difficult for the authors to pinpoint the exact areas needing revision. Additionally, the comment lacks specificity regarding what particular grammatical errors or mathematical symbol abuses are present, or how the sentences could be clarified. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the paper contains \\\"severe writing issues\\\" such as grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it does not provide specific examples or detailed explanations to support this claim. Without concrete examples or references to specific instances, the authors may find it challenging to identify and address the writing issues. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies several writing issues in the paper, including grammatical errors, abuses of mathematical symbols, and unclear sentences. However, it lacks specificity and does not provide examples or detailed guidance on how to address these issues. Without concrete examples or actionable suggestions, the authors are left with a general understanding of the problems but no clear path to improvement. Therefore, the comment is barely helpful, as it points out areas needing attention but does not offer sufficient direction for the authors to make meaningful improvements.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It instructs them to run experiments and add results for untrained networks to the figures and Table 1, as well as to clarify the use of random data in Figures 3c and 3. Additionally, it suggests showing examples of random data in the appendix. These instructions are clear and specific, giving the authors a direct path to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"mentioned above,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues that need to be addressed, such as running experiments for untrained networks and clarifying the use of random data in Figures 3c and 3. Additionally, it suggests showing examples of random data in the appendix. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of requests for additional experiments and clarifications regarding the figures and data presented in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The comment is purely factual and descriptive, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback regarding the presentation of results in the paper. It suggests running experiments for untrained networks and adding them to the figures and Table 1, which would enhance the comprehensiveness of the results. Additionally, it requests clarification on the use of random data in Figures 3c and 3, and suggests showing examples of random data in the appendix. These suggestions are clear and detailed, offering the authors a concrete way to improve the clarity and completeness of their paper. The comment is highly helpful as it directly guides the authors on how to enhance their draft, making it a valuable piece of feedback.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the meaning of \\\"100 steps\\\" in the context of search models comparison. While it does not explicitly instruct the authors to clarify this aspect, the question implies that the authors should provide an explanation or clarification regarding the meaning of \\\"100 steps.\\\" The action is implicit but concrete, as it clearly identifies what needs to be clarified. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Search models comparison 5.1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the meaning of \\\"100 steps\\\" in the context of the comparison, prompting the authors to clarify whether it refers to 100 sampled strategies. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding the meaning of \\\"100 steps\\\" in the context of search models comparison. It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and seeks additional information, so \\\"No\\\" is the appropriate label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a specific question about the meaning of \\\"100 steps\\\" in the context of search models comparison. This question highlights a potential area of confusion or lack of clarity in the paper, prompting the authors to provide a more detailed explanation. While the comment identifies a specific issue, it does not offer suggestions or guidance on how to address it, such as recommending a particular way to clarify the term or providing examples. This limits the comment's helpfulness, as it points out a problem but does not fully support the authors in resolving it. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors should repeat their experiments and conduct statistical significance analysis on the results to address concerns about the small improvement over previous methods and the lack of reported mean and standard deviation. While the comment provides a clear action\\u2014repeating experiments and conducting statistical significance analysis\\u2014it does not specify how many times to repeat the experiments or what specific statistical tests should be used. This leaves some ambiguity in the execution of the suggested actions. However, the overall guidance is explicit and concrete, making this comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1\\\" and \\\"Fig. 5,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the results, such as the small improvement over previous methods and the lack of reporting of mean and standard deviation, as well as the difficulty in determining statistical significance. Additionally, the comment provides a clear suggestion to repeat the experiments and conduct statistical significance analysis. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the improvement over previous methods is small, specifically mentioning a range of 0.2% to 1%. It also notes that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess statistical significance. The reviewer suggests repeating the experiments and conducting statistical significance analysis. While the comment provides some reasoning and suggests improvements, it lacks specific examples or references to support the claim of limited novelty and marginal improvement. This makes the claim somewhat verifiable, as the authors would need to further investigate and address the issues themselves.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the paper's claims of improvement over previous methods, noting that the improvement is marginal, typically between 0.2% and 1%. It also points out that the results in Table 1 and Fig. 5 do not report the mean and standard deviation, making it difficult to assess the statistical significance of the results. The reviewer provides a clear and actionable suggestion to repeat the experiments and conduct statistical significance analysis to address these concerns. This feedback is highly helpful as it not only identifies specific weaknesses but also offers a concrete and constructive approach for the authors to improve their draft. By following this guidance, the authors can strengthen the validity and impact of their findings. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly states that the approach section is missing from the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. This feedback provides a clear and direct action for the authors to take, which is to include the approach section in the main paper and reconsider the role of the supplementary material. The comment is specific and actionable, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"approach section\\\" and the \\\"supplementary material,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the inappropriate use of the supplementary material as an extension to the paper rather than additional information. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the approach section is missing from the main paper and suggests that the supplementary material should be used as additional information rather than an extension to the paper. However, the comment does not provide specific reasoning or examples to support why the approach section is missing or why the supplementary material should be treated as additional information. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the paper's structure, specifically pointing out the absence of the approach section in the main paper. It also critiques the use of the supplementary material, suggesting that it should be treated as additional information rather than an extension to the paper. This feedback is clear and actionable, as it provides the authors with specific guidance on how to improve the organization and presentation of their work. However, the comment could be more helpful if it offered suggestions on how to integrate the supplementary material or what specific content should be included in the main paper. Despite this, the feedback is mostly helpful as it directs the authors' attention to important structural and content issues that need addressing.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the statement in the introduction regarding the biological plausibility of backpropagation is weak and suggests that it is widely accepted that backpropagation is biologically implausible. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to strengthen the statement. The feedback lacks concrete suggestions or actionable steps, leaving the authors uncertain about how to improve their draft. Since the comment is vague and does not offer a clear path for action, it is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly refers to the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the statement regarding the biological plausibility of backpropagation, suggesting that it is widely accepted as biologically implausible. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the statement in the introduction regarding the biological plausibility of backpropagation is weak, suggesting that it is widely accepted that backpropagation is biologically implausible. This claim is somewhat verifiable as it references a common understanding in the field, but it lacks specific references or detailed reasoning to fully substantiate the claim. The comment provides a logical basis for the assertion but could benefit from more explicit evidence or examples to strengthen the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the statement in the introduction regarding the biological plausibility of backpropagation. It points out that the statement is weak and suggests that it is widely accepted that backpropagation is biologically implausible. This feedback is valuable as it highlights a potential weakness in the paper's introduction and encourages the authors to reconsider or revise their statement to better reflect the established understanding in the field. However, the comment could be more helpful if it provided suggestions on how to strengthen the statement or offered examples of more appropriate phrasing. Overall, the comment is somewhat helpful as it directs the authors' attention to an important aspect of their draft that needs clarification or revision.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how the authors should address this concern. The authors are left to infer that they need to clarify or provide evidence regarding the connection between memorization and generalization, but the comment lacks concrete steps or specific actions to take. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed guidance on how to implement it.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises a concern about the implications of overparameterization on generalization performance, specifically questioning whether the constructions of ReLU networks for robust memorization would lead to robust generalization. However, it does not specify which part of the paper this concern is based on, nor does it provide detailed guidance on how to address the issue. The authors might infer that it relates to sections discussing generalization or robustness, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, and it is not specific in detailing what needs to be addressed. This aligns with a score of 2.\",\n    \"grounding_specificity_label\": \"2\",\n    \"verifiability_rationale\": \"The review point raises a concern about the implications of overparameterization on generalization performance, specifically questioning whether constructions of ReLU networks for robust memorization would lead to robust generalization. The reviewer acknowledges that this is acknowledged in the conclusion, suggesting that the paper does not clearly address this issue. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim. This makes the claim somewhat verifiable, as it provides a logical basis for the concern but requires more detailed evidence or examples to fully support the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a critical question about the implications of overparameterization on generalization performance, specifically questioning whether constructions of ReLU networks for robust memorization would lead to robust generalization. It acknowledges that the authors have addressed this in the conclusion but suggests that this is a significant concern that needs further exploration. While the comment identifies an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue or what additional analyses or experiments could be conducted to clarify the relationship between memorization and generalization. The feedback is somewhat helpful as it highlights a key area of concern but does not provide actionable steps for improvement. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment acknowledges the interesting aspect of the OOD experiments and suggests that the paper should mention recent findings on untrained neural networks (like deep image prior) that can solve inverse problems across a wide class of images. It also recommends placing the current method in context and ideally comparing it with these methods. While the comment provides a clear direction for improvement, it does not specify how to integrate these comparisons or where in the paper they should be included. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"OOD experiments\\\" and suggests placing the current method in context with recent findings on untrained neural networks, such as the deep image prior. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides a clear suggestion to mention and compare with recent findings on untrained neural networks, offering a concrete direction for improvement. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point acknowledges the interesting aspect of the OOD experiments and suggests that the paper should mention recent findings on untrained neural networks, such as the deep image prior, which can solve inverse problems across a wide class of images. The comment provides a logical reasoning by referencing specific recent work, which supports the suggestion to include these findings in the paper. However, it lacks specific examples or detailed comparisons with these methods, which would strengthen the claim. Therefore, the comment is mostly verifiable, as it provides a clear direction for improvement but could benefit from more detailed evidence or references.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the interesting aspect of the OOD experiments and suggests that the paper should mention recent findings on untrained neural networks, such as the deep image prior, which can solve inverse problems across a wide class of images. It provides a clear and actionable suggestion to place the current method in context and ideally compare it with these methods. This feedback is valuable as it guides the authors to enhance the paper's relevance and comprehensiveness by situating their work within the broader landscape of recent advancements in neural networks. However, the comment could be more helpful if it provided specific examples or references to these recent works. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be more comprehensive with additional details.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, which would align it with the subproblem in Algorithm 1. This implies that the authors should consider this reformulation to improve their prox-linear algorithms for solving the stochastic problem in Eq.(1). However, the comment does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq.(1)\\\" and \\\"Algorithm 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the prox-linear subproblem can be reformulated using the conjugate function, which would align it with the subproblem in Algorithm 1. This provides clear guidance on what needs to be addressed to clarify the motivation of Algorithm 1. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the prox-linear subproblem in Eq.(1) can be reformulated using the conjugate function, aligning it with the subproblem in Algorithm 1. This claim is based on logical reasoning, as reformulating the subproblem could indeed clarify the motivation of Algorithm 1. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore and verify the details themselves, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the motivation of Algorithm 1, suggesting that the prox-linear subproblem in Eq.(1) could be reformulated using the conjugate function to align with the subproblem in Algorithm 1. This insight highlights a possible improvement in the paper's logic and could help the authors clarify their approach. However, the comment lacks specific guidance or suggestions on how to implement this reformulation or why it would improve the motivation of Algorithm 1. While it points out a potential area for enhancement, it does not provide actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it offers a direction for improvement but lacks depth and specificity.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly asks the authors to provide an explanation for the degradation in performance when using additional information about missing/wrong/redundant data. This is a direct and specific request for clarification, giving the authors a clear action to take. The comment is highly actionable because it provides a precise and concrete direction for the authors to address in their draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"FBN results (table 5),\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it asks for clarification on why the performance degrades when using additional information about missing/wrong/redundant data. This provides clear guidance on what the authors need to address or clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a request for clarification regarding the performance degradation observed in the FBN results when additional information is used. It does not contain any subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment requests clarification on why the performance degrades when additional information about missing/wrong/redundant data is used. This is a specific and actionable question that can help the authors identify and address potential issues in their methodology or results. By prompting the authors to explain this phenomenon, the comment encourages them to provide a deeper analysis of their findings, which could lead to improvements in the paper. However, the comment could be more helpful if it suggested ways to investigate or resolve this issue. Overall, the feedback is somewhat helpful as it directs the authors to a critical area for further exploration, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides concrete examples of where the explanations are unclear, such as the conversion of a stacked LSTM to a sequential LSTM and the sentences in lines 43 and 96. The reviewer explicitly asks for clarification on these points, providing clear guidance on what needs to be addressed. This feedback is explicit and concrete, giving the authors a direct action to take to improve the clarity of their draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the explanations are unclear, such as the conversion of a stacked LSTM to a sequential LSTM and the sentences in lines 43 and 96. The comment clearly specifies what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the first two sections of the paper are difficult to read due to unclear explanations of previous approaches. It provides specific examples, such as the conversion of a stacked LSTM to a sequential LSTM and the sentences in lines 43 and 96, to illustrate the lack of clarity. However, the comment does not offer detailed reasoning or references to support why these explanations are unclear or how they could be improved. While the examples provide some context, the lack of further elaboration or evidence makes the claim somewhat verifiable. The authors would need to make a significant effort to understand and address the issues raised, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies specific areas where the paper's clarity is lacking, particularly in the first two sections. It provides detailed examples of unclear explanations, such as the conversion of a stacked LSTM to a sequential LSTM and the sentences in lines 43 and 96. By pinpointing these specific issues, the comment offers clear and actionable feedback that can help the authors improve the readability and understanding of their work. The detailed examples and specific references to lines in the paper make this feedback highly helpful, as it guides the authors on how to enhance the clarity of their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a gap in the paper's analysis regarding the flatness of the minima found by the proposed method. It explains that while the paper argues for finding flat minima, the analysis about flatness is missing. The reviewer points out that minimizing the averaged loss across noise-injected models does not guarantee flatness and suggests that an analysis on the losses of the noise-injected models after training is necessary to support the claim. This feedback provides a clear and explicit action for the authors to take, which is to conduct an analysis on the losses of the noise-injected models to substantiate their claim about flatness. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the analysis of flatness, the loss used for training the base model, and the convergence analysis on this loss. It also references \\\"Eq (3),\\\" allowing the authors to accurately identify the part of the paper being addressed. The comment is specific because it clearly specifies what needs to be addressed, namely the analysis on the losses of the noise-injected models after training to support the claim about flatness. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper's argument about finding flat minima is not supported by an analysis of flatness. The reviewer provides a logical reasoning by explaining that minimizing the averaged loss across noise-injected models does not guarantee flatness. They suggest that an analysis on the losses of the noise-injected models after training is necessary to substantiate the claim about the minima found by minimizing the loss in Eq (3). This reasoning is clear and provides a specific suggestion for improvement, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or references to support the claim, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical gap in the paper's analysis, specifically the lack of analysis regarding the flatness of the minima found by the proposed method. It points out that while the paper argues for finding flat minima, the analysis on this aspect is missing. The comment provides a clear rationale for why the current analysis is insufficient and suggests that an analysis on the losses of the noise-injected models after training is necessary to support the claim about the minima found by minimizing the loss in Eq (3). This feedback is highly helpful as it offers a specific and actionable suggestion for the authors to enhance the rigor and validity of their claims. By addressing this point, the authors can significantly improve the comprehensiveness and credibility of their work.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the model is complicated and its presentation in section 4 requires careful reading. It advises the authors to improve the presentation by replacing some of the natural language descriptions with notation and adding breakout diagrams to illustrate the attention mechanisms. While the comment provides a general direction for improvement, it lacks specific guidance on which parts of the presentation need attention or how to effectively use the suggested methods. The action is implicit and somewhat vague, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the complexity of the model's presentation and suggests ways to improve it, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the model is complicated and its presentation in section 4 requires careful reading. It recommends improving the presentation by replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. While the comment provides some guidance on how to improve the presentation, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use notation and diagrams is logical, but without concrete examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the complexity of the model's presentation in section 4, suggesting that it requires careful reading. It provides actionable feedback by recommending ways to improve the presentation, such as replacing natural language descriptions with notation and adding breakout diagrams to illustrate attention mechanisms. These suggestions are clear and offer a concrete path for the authors to enhance the clarity and accessibility of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the feedback is mostly helpful as it provides valuable insights and actionable steps for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a question about Figure 3, specifically asking for clarification on the source of the test data and whether there is a ground truth. While the comment implies that the authors should provide more information or clarification regarding these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the source of the test data and whether there is a ground truth, providing specific guidance on what needs to be clarified or addressed in the figure. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding Figure 3, specifically about the source of the test data and whether there is a ground truth. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a specific question about Figure 3, asking for clarification on the source of the test data and whether there is a ground truth. This feedback is somewhat helpful as it identifies a potential area of confusion in the paper, prompting the authors to clarify their methodology or data presentation. However, the comment does not provide suggestions or guidance on how to address the issue, such as recommending a specific explanation or additional information to include. While it highlights an important aspect that needs clarification, the lack of actionable advice limits its usefulness. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises concerns about the paper's goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, is necessary. It also implies that if the claim is to establish a foundation model, a clearer justification and demonstration of future applications are needed. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these concerns. The authors can infer that they need to include comparisons and justifications, but the lack of specific guidance makes the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises concerns about the paper's goal and suggests that a comparison with existing DAS earthquake detectors, such as PhaseNet-Das, is necessary. It also implies that if the claim is to establish a foundation model, a clearer justification and demonstration of future applications are needed. However, the comment does not specify which part of the paper discusses the goal or the comparison with existing detectors, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of comparison and justification. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the paper's goal, specifically questioning the need for a comparison with existing DAS earthquake detectors like PhaseNet-Das. The reviewer suggests that if the claim is to establish a foundation model, a clearer justification and demonstration of future applications are necessary. While the comment identifies a potential gap in the paper's evaluation, it lacks specific examples or references to support the claim that a comparison is missing. The suggestion for clearer justification and demonstration of future applications is somewhat verifiable, as it provides a logical direction for improvement but lacks detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the paper's goal, specifically questioning the necessity of a comparison with existing DAS earthquake detectors like PhaseNet-Das. It suggests that if the claim is to establish a foundation model, a clearer justification and demonstration of future applications are needed. This feedback is somewhat helpful as it highlights a significant gap in the paper's evaluation and provides a direction for improvement by suggesting the need for comparisons and future applications. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of potential applications. Overall, the comment provides valuable insights but lacks detailed guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises questions about the alignment of results in Table 6 with Table 1 (MCT-pair) and inquires about the ablation studies of MCT without adaptive metrics. While these questions highlight areas of concern, they do not provide explicit actions or suggestions for the authors to take. The authors can infer that they need to address the alignment issue and conduct ablation studies, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 6\\\" and \\\"Table 1 (MCT-pair),\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning why the results in Table 6 do not align with Table 1 and asks about the ablation studies of MCT without adaptive metrics. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the results in Table 6 and the ablation studies of MCT without adaptive metrics. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the alignment of results between Table 6 and Table 1 (MCT-pair), suggesting a potential inconsistency in the data presented. Additionally, it inquires about the ablation studies of MCT without adaptive metrics, indicating a need for further exploration or clarification in the experimental setup. While the comment identifies specific areas that require attention, it lacks detailed guidance or suggestions on how the authors might address these issues or what specific analyses should be conducted. The feedback is somewhat helpful as it points out potential weaknesses in the paper, but it could be more beneficial with additional context or recommendations for improvement. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the possibility of including and learning AccNet as part of a larger predictor, such as for semantic segmentation, that utilizes similar operators. While the comment implies that the authors should consider this suggestion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete details on how to implement this suggestion or why it would be beneficial. Therefore, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 126\\\" and the \\\"black line in the input,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also raises a specific question about the possibility of including and learning AccNet as part of a larger predictor, such as for semantic segmentation. This provides clear guidance on what the authors need to consider or address in their work. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a factual statement about a specific line in the paper and a question asking for clarification or suggestion. It does not contain any subjective opinions, judgments, or claims that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides a specific question regarding the inclusion and learning of AccNet as part of a larger predictor, such as for semantic segmentation. This feedback is actionable as it prompts the authors to consider a potential extension of their work, which could lead to new insights or improvements in their methodology. However, the comment could be more helpful if it provided additional context or rationale for why this extension might be beneficial. Despite this, the feedback is mostly helpful as it directs the authors to a meaningful area for further exploration and enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies specific issues with the manuscript, such as undefined abbreviations and delayed definition of superscript notation, which can hinder understanding. It provides explicit actions for the authors to take, such as defining abbreviations like \\\"NE\\\" and clarifying the superscript notation in Equation 6. Additionally, it references external works, which may provide context or examples for the authors to consider. The comment is explicit and provides concrete guidance on how to improve the draft, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (L73 and L166) and equations (Eq 6), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as undefined abbreviations and delayed definition of superscript notation, which hinder understanding. Additionally, the comment references external works, providing further context. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point identifies specific issues with the manuscript, such as undefined abbreviations and delayed definition of superscript notation, which can hinder understanding. The comment provides examples of where these issues occur, such as \\\"NE\\\" on L73 and the superscript notation in Eq 6. Additionally, it references external works, which may provide context or examples for the authors to consider. However, the comment does not explicitly explain why these issues are problematic or how they affect the understanding of the paper. While the references provide some support, the lack of detailed reasoning or explanation makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies specific issues with the manuscript, such as undefined abbreviations and delayed definition of superscript notation, which can hinder understanding. It provides clear and actionable feedback by pointing out where these problems occur in the text, allowing the authors to make precise improvements. Additionally, the comment references external works, which may provide context or examples for the authors to consider. This feedback is mostly helpful as it directs the authors to specific areas needing clarification and offers a clear path for improvement. However, it could be more helpful if it included suggestions on how to address these issues or provided more detailed guidance on how to improve the clarity of the manuscript. Therefore, the comment is rated as mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides specific feedback on two distinct issues. First, it critiques the accuracy of a statement in the Related Work section regarding the Walkman algorithm, suggesting that it is not accurate to claim that all works are based on simple SGD for decentralized optimization. This feedback is explicit and provides a clear action for the authors to revise their statement. Second, it points out a lack of clarity in Section 3, where the term \\\"it\\\" is used without a clear reference, making it difficult for the authors to understand the context. Both points are explicit and provide concrete guidance on how to improve the draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections of the paper, namely \\\"Page 2, second paragraph in Related Work\\\" and \\\"Section 3, first paragraph.\\\" This allows the authors to accurately identify the parts of the paper being addressed. Additionally, the comment is specific as it provides detailed feedback on the inaccuracies in the statements regarding the Walkman algorithm and the reference to \\\"it\\\" in Section 3. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the accuracy of a statement in the Related Work section regarding the Walkman algorithm, suggesting that it is not accurate to claim that all works are based on simple SGD for decentralized optimization. The reviewer provides specific reasoning by mentioning the two versions of the Walkman algorithm (solving a local optimization problem and a gradient approximation) and how this contradicts the statement. Additionally, the comment points out a lack of clarity in Section 3 regarding the reference \\\"it,\\\" which could be clarified with a specific reference. This detailed critique provides a clear rationale for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on two distinct issues. First, it challenges the accuracy of a statement in the Related Work section regarding the Walkman algorithm, pointing out that it is not accurate to claim that all works are based on simple SGD for decentralized optimization. This feedback is valuable as it prompts the authors to reconsider and correct their statement, ensuring the accuracy of their literature review. Second, the comment highlights a lack of clarity in Section 3, where the term \\\"it\\\" is used without a clear reference, making it difficult for readers to understand the context. This feedback is clear and actionable, guiding the authors to improve the clarity and precision of their writing. Overall, the comment is highly helpful as it provides detailed guidance on how to enhance the draft's accuracy and clarity.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly suggests that the authors should present the average results on the test set with clearly defined error bars under different random seeds. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the paper. The suggestion is direct and leaves no ambiguity about how to implement the change, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Tables 1 and 2,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the presentation of average results on the test set with clearly defined error bars under different random seeds. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the validity of the results presented in Tables 1 and 2, suggesting that reporting the best results on the development set with hyper-parameter search and model selection on the development set is insufficient. The reviewer strongly recommends presenting average results on the test set with clearly defined error bars under different random seeds. This suggestion is based on logical reasoning that testing on the test set is necessary for generalizability and robustness. However, the comment lacks specific examples or references to support the claim that the current approach is inadequate. While the reasoning is sound, the absence of detailed evidence or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the presentation of results in the paper, specifically noting that the best results are reported on the development set with hyper-parameter search and model selection also on the development set. This approach is insufficient for demonstrating the generalizability of the findings. The comment provides a clear and actionable suggestion to present the average results on the test set with clearly defined error bars under different random seeds. This feedback is highly helpful as it offers a specific and constructive approach for the authors to improve the robustness and credibility of their results. By addressing this point, the authors can significantly enhance the quality and impact of their paper. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to conduct a more comprehensive ablation study on the parameter \\\\(\\\\alpha\\\\). It specifies the current values used (1e-4, 1e-1, 5e-1) and suggests including additional values such as 1e-2 and 1e-3. This feedback provides clear and concrete guidance on how to improve the draft by expanding the range of values tested for \\\\(\\\\alpha\\\\). The authors know exactly what changes to make to enhance the study's comprehensiveness. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 5.4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the insufficient ablation study on \\\\(\\\\alpha\\\\) and the recommendation to include more values such as 1e-2 and 1e-3. This provides clear guidance on how to improve the study. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the ablation study on \\\\(\\\\alpha\\\\) is insufficient, noting that \\\\(\\\\alpha\\\\) is only set to a few values (1e-4, 1e-1, 5e-1) with a large gap between 1e-4 and 1e-1. The reviewer suggests including more values, such as 1e-2 and 1e-3, to provide a more comprehensive study. While the comment identifies a gap in the study, it lacks specific reasoning or evidence to fully substantiate the claim. The suggestion to include additional values is logical, but the comment could be strengthened with more detailed justification or examples of why these additional values are necessary. Therefore, the comment is somewhat verifiable, as it provides a basis for improvement but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific weakness in the paper, namely the insufficient ablation study on the parameter \\\\(\\\\alpha\\\\). It points out that \\\\(\\\\alpha\\\\) is only set to a few values (1e-4, 1e-1, 5e-1) with a large gap between the first two, suggesting that more values should be included, such as 1e-2 and 1e-3. This feedback is clear and actionable, providing the authors with a direct suggestion to enhance the comprehensiveness of their study. By addressing this point, the authors can improve the robustness and reliability of their results. However, the comment could be more helpful if it explained why these additional values are important or how they might impact the study's conclusions. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions about the dataset and its characteristics, such as the number of topics, how topic-word parameters were obtained, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions imply that the authors should provide more detailed information about the dataset in the main paper. While the actions are not explicitly stated, they are clear and concrete, as the authors can infer that they need to include specific details about the dataset. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment raises several questions about the dataset, including the number of topics, how topic-word parameters were obtained, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions are specific and provide clear guidance on what information is missing or needs clarification in the paper. However, the comment does not explicitly mention which part of the paper these questions pertain to, making it weakly grounded. The authors can infer that it relates to the dataset description or experimental setup, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the dataset and its characteristics. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises several important questions about the dataset used in the paper, specifically regarding the number of topics, how topic-word parameters were obtained, the size of the AG news dataset, and the number of documents in the training and testing sets, as well as the vocabulary size. These questions highlight areas where the paper lacks clarity and detail, prompting the authors to provide more comprehensive information about their dataset. By addressing these points, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or emphasized the importance of these details. Overall, the feedback is somewhat helpful as it identifies key areas for improvement but lacks depth and actionable guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. It also notes a difference from Figure 4, where the discriminator is co-adapting with the generator, which might lead to a local optimum. This comment provides a clear and specific action for the authors to take, detailing what needs to be done to validate the claim. The explicit nature of the suggestion and the concrete details provided make this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the need to train a discriminator on generations from the learned model to confirm the claim of reducing exposure bias, similar to Figure 1. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it details the need for a discriminator and highlights a difference from Figure 4, where the discriminator is co-adapting with the generator. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that training a discriminator on generations from the learned model is necessary to confirm the claim of reducing exposure bias. It references Figure 1 as a similar approach and notes a difference from Figure 4, where the discriminator is co-adapting with the generator. While the comment provides some reasoning and a reference to a similar approach, it lacks detailed explanation or evidence to fully substantiate the claim. The suggestion is based on logical reasoning but could be strengthened with more specific examples or references to similar studies. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the evaluation of the paper's claim regarding reducing exposure bias. It recommends training a discriminator on generations from the learned model, similar to Figure 1, to confirm the claim. The comment also highlights a potential issue with Figure 4, where the discriminator is co-adapting with the generator, which might lead to a local optimum. This feedback is clear and offers a concrete step for the authors to take in order to strengthen their evaluation and address a potential limitation in their current approach. However, the comment could be more helpful if it provided additional guidance on how to implement this suggestion or discussed the implications of the co-adaptation issue in more detail. Overall, the comment is mostly helpful as it provides a clear direction for improvement but could be expanded to be fully comprehensive.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that while the style design is clean, the organization of the prompts in Tables 6 and 7 is not well-organized, with sentences squeezed together. This feedback implies that the authors should reorganize the prompts to improve readability. However, it does not provide specific guidance on how to achieve this, such as suggesting ways to better structure the tables or examples of improved organization. The action is implicit and somewhat vague, as the authors know they need to improve the organization but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 6\\\" and \\\"Table 7,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the organization of the prompts, noting that all sentences are squeezed together, which affects readability. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the prompts in Tables 6 and 7 are not well-organized, with sentences squeezed together. This is a somewhat verifiable claim as it provides a specific observation about the formatting of the tables. However, it lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the current organization is problematic or how it affects readability. The authors might need to infer the implications of this observation themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the organization of prompts in Tables 6 and 7, noting that the sentences are squeezed together, which affects readability. This feedback is clear and actionable, as it points out a concrete area for improvement in the presentation of the paper. By addressing this issue, the authors can enhance the clarity and professionalism of their work. However, the comment could be more helpful if it provided suggestions on how to reorganize the prompts or examples of better formatting. Overall, the comment is mostly helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies issues with the clarity of the figures, specifically mentioning that the relationship between the sub-figures in Figure 2 is confusing and that certain modules, such as CMAF, L_BT, and VoLTA, are not labeled. This feedback provides clear and concrete actions for the authors to take, such as improving the labeling and clarifying the relationships between the sub-figures. The authors know exactly what needs to be done to address the issues raised in the comment, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"figure 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figures, such as the confusion in the relationship between the sub-figures and the lack of labeling for certain modules like CMAF, L_BT, and VoLTA. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the figures are unclear, specifically mentioning confusion in the relationship between sub-figures in Figure 2 and the lack of labeling for certain modules. While the comment identifies specific issues, it does not provide detailed reasoning or examples to fully substantiate the claim. The authors might find it challenging to address the issue without further elaboration or visual examples. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks comprehensive support.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies specific issues with the clarity of the figures, particularly in Figure 2, where the relationship between sub-figures is confusing. It also points out the lack of labeling for certain modules, such as CMAF, L_BT, and VoLTA. This feedback is clear and actionable, as it provides the authors with concrete areas to improve the presentation of their figures. By addressing these issues, the authors can enhance the readability and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to improve the labeling or clarify the relationships between the sub-figures. Overall, the comment is mostly helpful, as it effectively directs the authors toward specific improvements in their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the use of perplexity as a measure of semantic information retention after fine-tuning, suggesting that domain drift could be a separate issue from catastrophic forgetting. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or control for domain drift. The comment implies that the authors should consider these factors, but it lacks concrete steps or details on how to implement such considerations. As a result, the action is implicit and vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment raises concerns about the use of perplexity as a measure of semantic information retention after fine-tuning, suggesting that domain drift could be a separate issue from catastrophic forgetting. However, it does not specify which part of the paper discusses these design choices, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its critique of the design choices, it lacks grounding as it does not reference a particular section or figure in the paper. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the use of perplexity as a measure of semantic information retention after fine-tuning, suggesting that domain drift could be a separate issue from catastrophic forgetting. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that perplexity alone is insufficient to capture domain drift. This lack of explicit evidence or justification makes the claim somewhat verifiable, as the authors would need to infer the potential issues and address them without clear guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the use of perplexity as a measure of semantic information retention after fine-tuning, suggesting that domain drift could be a separate issue from catastrophic forgetting. It questions how these factors are controlled in the study. While the comment identifies a potential weakness in the methodology, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback is somewhat helpful as it prompts the authors to consider additional factors that could influence their results, but it could be more beneficial with more detailed guidance or examples. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to provide a more comprehensive overview of existing methods and their limitations in the Related Work section, specifically focusing on long-context language models. It lists several specific methods, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, which the authors should discuss. This feedback is explicit and provides concrete guidance on what needs to be included in the Related Work section, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"Related Work section\\\" and the paragraph on \\\"long-context language models,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed guidance on what needs to be included, such as discussing sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods. This level of detail provides clear direction on how to improve the section. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the Related Work section lacks details and suggests that it should provide a more comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. The reviewer supports this claim by listing specific methods, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, which should be discussed. This detailed list of methods provides a robust foundation for the claim, making it mostly verifiable. However, the comment could be further strengthened by providing references to the sources mentioned (e.g., [1, 2, 3, 4, 5, 6, 7]) to ensure the authors have specific guidance on where to include these discussions. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area for improvement in the Related Work section, noting that it lacks details and a comprehensive overview of existing methods and their limitations, particularly in the context of long-context language models. It provides clear and actionable suggestions by listing specific methods, such as sparse-attention mechanisms, segmentation-based approaches, memory-enhanced segmentation strategies, and recursive methods, that should be discussed. This feedback is highly helpful as it guides the authors on how to enhance the Related Work section, ensuring that it provides a more thorough and informative overview of the relevant literature. The detailed suggestions and examples make this feedback highly beneficial for improving the draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which points are unclear or provide guidance on how to improve the writing. The feedback lacks explicit instructions or concrete suggestions, leaving the authors uncertain about what specific changes are needed to enhance clarity. As a result, the comment is vague and lacks actionable details, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it does not specify which sections or points are unclear, making it difficult for the authors to identify the exact areas that need revision. Additionally, the comment lacks specificity regarding what aspects of the writing are unclear or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that \\\"the writing should be improved\\\" and that \\\"some points in the paper are unclear.\\\" However, it does not provide any specific examples or detailed reasoning to support these claims. Without concrete examples or explanations of which points are unclear or how the writing could be improved, the comment lacks verifiability. The authors are left without guidance on how to address the issue, making it difficult to understand and address the feedback effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the writing needs improvement and that some points in the paper are unclear. However, it lacks specificity and does not provide any detailed guidance or examples on which points are unclear or how the writing could be improved. Without actionable feedback or specific suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the writing and annotations are difficult to follow, but it does not provide specific guidance on how to improve the clarity or organization of the writing and annotations. Without explicit instructions or concrete suggestions, the authors are left without a clear understanding of what changes are needed to address the issue. As a result, the comment is vague and lacks actionable details, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the writing and annotations are difficult to follow, but it does not specify which sections or parts of the paper are problematic. Without explicit references to specific sections, figures, or annotations, the authors cannot confidently determine which parts need improvement. Additionally, the comment lacks specificity regarding what aspects of the writing or annotations are unclear or difficult to follow. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the writing and annotations are difficult to follow, but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the writing and annotations are difficult to follow, but it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular sections or aspects of the writing that are problematic, the authors are left without guidance on how to enhance the clarity or organization of their draft. This lack of detail and constructive advice makes the comment barely helpful, as it does not assist the authors in making meaningful improvements to their work.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises two issues: the limited number of SOTA performances in Table 2 and a question about the proposed method's performance under a specific setting. However, it does not provide explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should address these issues, improve the table, or provide further analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that only 8 out of 14 evaluation metrics achieve SOTA performances for the proposed method. Additionally, it raises a specific question about the performance under the \\\"Twitter-2017 $\\\\rightarrow$ Twitter-2015\\\" setting, asking why the proposed method achieves the best overall F1 score but not the best F1 in all single types. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual observations about the performance of the proposed method in Table 2 and a question about the results under a specific setting. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the results presented in Table 2, noting that only 8 out of 14 evaluation metrics achieve state-of-the-art (SOTA) performances for the proposed method. This observation highlights a potential weakness in the paper's evaluation. Additionally, the comment raises a question about the performance under the \\\"Twitter-2017 $\\\\rightarrow$ Twitter-2015\\\" setting, specifically why the proposed method achieves the best overall F1 score but not the best F1 in all single types. While the comment points out areas for improvement, it lacks detailed suggestions or guidance on how the authors might address these issues or improve their analysis. The feedback is somewhat helpful as it provides insights into potential weaknesses and areas for further exploration, but it could be more beneficial with additional guidance or suggestions. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the proposed solution is an incremental step based on a relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvements, additional analyses, or specific changes to make. The comment lacks any guidance on how the authors might enhance their work or address the incremental nature of their contribution. As a result, the authors are left without any actionable steps to follow, making this comment unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment mentions that the proposed solution is an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the solution are considered incremental or how they relate to Guzman et al.'s work. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the proposed solution is an incremental step based on a relaxation proposed by Guzman et al. However, it does not provide any specific details or references to support this claim, nor does it explain how the proposed solution is incremental or how it relates to Guzman et al.'s work. Without additional context or evidence, the claim lacks verifiability, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the proposed solution is an incremental step based on a relaxation proposed by Guzman et al. However, it lacks specificity and does not provide any actionable suggestions or guidance for the authors to improve their work. Without additional context or detailed feedback, the authors are left without a clear understanding of how to enhance their contribution or address the incremental nature of their solution. As a result, the comment is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides explicit and concrete suggestions for improving the results presentation. It specifically mentions that the y-axis label in Figures 2 and 3 is ambiguous and suggests using a scatter plot with runtime and performance as axes to aid understanding. Additionally, it advises highlighting the best results in tables. These suggestions are clear and actionable, giving the authors specific guidance on how to enhance their draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2 and 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as labeling the y-axis as \\\"performance\\\" and using a scatter plot to represent runtime and performance. Additionally, it suggests highlighting the best results in tables. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests improvements in the presentation of results, specifically mentioning that the y-axis label in Figures 2 and 3 is ambiguous and that runtime is not represented. The reviewer proposes using a scatter plot to better illustrate the results and highlights the best results in tables. While the comment provides specific suggestions for improvement, it lacks detailed reasoning or examples to fully substantiate why these changes would be beneficial. The suggestion to use a scatter plot is logical, but the comment could be strengthened with more explanation or references to similar practices in the literature. Therefore, the comment is somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on improving the presentation of results. It identifies issues with the labeling of the y-axis in Figures 2 and 3, suggesting that it is ambiguous and that runtime is not represented. The comment proposes using a scatter plot with runtime and performance as axes to aid in understanding and interpretation. Additionally, it suggests highlighting the best results in tables. These suggestions are clear and provide the authors with concrete steps to enhance the clarity and interpretability of their results. The comment is mostly helpful as it offers detailed guidance on how to improve the presentation, but it could be further improved by explaining why these changes are necessary or how they would benefit the reader. Overall, the comment is rated as mostly helpful, consistent with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point questions the \\\"Unsupervised Online Adaptation\\\" setting, suggesting that it is not truly unsupervised because it requires annotations in the training set. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the setting of Unsupervised Online Adaptation, specifically questioning whether it is truly unsupervised due to the requirement of annotations in the training set. It references \\\"Sec 3.1,\\\" which provides full grounding by directing the authors to the specific section of the paper being discussed. The comment is also specific as it clearly identifies the issue with the claim of unsupervised adaptation, providing a detailed explanation of the concern. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the claim of \\\"Unsupervised Online Adaptation\\\" by pointing out that the model requires annotations in the training set, which contradicts the definition of unsupervised learning. The comment provides a logical reasoning by referencing Sec 3.1, which describes the training set requirements. However, it lacks specific examples or detailed explanations to fully substantiate the claim. This makes the comment somewhat verifiable, as it provides a basis for the critique but requires additional detail to be fully convincing. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the claim of \\\"Unsupervised Online Adaptation\\\" by pointing out that the model requires annotations in the training set, which contradicts the definition of unsupervised learning. This feedback is valuable as it challenges the authors to reconsider their terminology or provide clarification on their methodology. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their draft. While it highlights a critical point, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the results are presented in a convoluted manner, specifically noting that the safety violations of the agent in the first 1000 episodes are disregarded. It also mentions that the reason for this presentation is unclear. However, the comment does not provide explicit guidance on how to improve the clarity or presentation of the results. The authors are left to infer that they should address the issue of disregarding safety violations and clarify the rationale behind the presentation. While the action is implied, it lacks concrete details on how to implement these changes, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the presentation of results, specifically mentioning the disregard of safety violations in the first 1000 episodes. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify what needs to be addressed, namely the disregard of safety violations and the unclear reason for this presentation. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the results are presented in a convoluted manner, specifically noting the disregard of safety violations in the first 1000 episodes. However, the comment lacks detailed reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the critique. The absence of specific evidence or explanation results in the comment being classified as \\\"1: Unverifiable,\\\" as it does not provide sufficient justification for the claim.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the presentation of results, noting that the safety violations of the agent in the first 1000 episodes are disregarded. It also points out that the reason for this presentation is unclear. While the comment highlights a potential problem with the clarity and completeness of the results, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback provides some insight into the problem but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies specific writing errors in the paper, such as \\\"informative informative\\\" on page 5 and \\\"performance\\\" on page 1, which lacks a title. This feedback provides explicit actions for the authors to correct these errors, making it clear what needs to be addressed. The comment is specific and actionable, as it directly points out the errors and their locations, allowing the authors to make precise revisions. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific locations in the paper, such as \\\"page 5\\\" and \\\"page 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the writing errors, such as \\\"informative informative\\\" and the lack of a title for \\\"performance,\\\" providing clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that there are writing errors in the paper, specifically mentioning \\\"informative informative\\\" on page 5 and \\\"performance\\\" on page 1, which lacks a title. This claim is somewhat verifiable as it points out specific instances of writing errors, which can help the authors identify and correct them. However, the comment lacks further explanation or context about why these errors are problematic or how they impact the paper's overall quality. Providing more detailed reasoning or examples would enhance the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies specific writing errors in the paper, such as the repeated word \\\"informative\\\" and the lack of a title for \\\"performance.\\\" This feedback is clear and actionable, as it points out exact instances where the authors can improve the draft. By addressing these errors, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it provided additional guidance on how to correct these errors or explained the impact of these errors on the overall quality of the paper. Despite this, the feedback is mostly helpful as it directs the authors to specific areas needing attention. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides a specific observation about the statement on line 134, noting that it is only true for the standard sigmoid function and depends on the maximum slope. It also suggests that elaborating on Theorem 4.1 in the main text would be beneficial, particularly by explaining why the RNN converges to the nearest fixed point (FP) compared to the URNN. While the comment implies that the authors should provide more explanation, it does not explicitly instruct them to do so. The action is clear but stated indirectly, making this comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 134\\\" and \\\"Theorem 4.1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the need for elaboration on why the statement holds, particularly in the context of the RNN converging to the nearest fixed point compared to the URNN. This provides clear guidance on what needs to be addressed in the main text. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual statements and a request for elaboration. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific statement on line 134, which is only true for the standard sigmoid function and depends on the maximum slope. It also suggests that elaborating on Theorem 4.1 in the main text would be beneficial, particularly by explaining why the RNN converges to the nearest fixed point (FP) compared to the URNN. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors elaborate on the theoretical basis of their claim. However, the comment could be more helpful if it offered additional guidance on how to effectively explain this concept. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification and provides a rationale for the suggestion.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a limitation of the plan-based method, noting that it requires manual design based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as shown in Table 2. The comment suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. However, it does not provide explicit guidance on how the authors should address these issues or improve the generalizability of their method. The feedback is somewhat actionable as it identifies a problem but lacks specific instructions on how to resolve it, leaving the authors with a general idea of what needs to be improved but without detailed steps on how to do so.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the plan-based method and its reliance on manually designed plans based on ground truth, which is unrealistic in real-world scenarios. It also mentions the comparison between learned plan methods and predefined plans, as shown in Table 2, and suggests that the proposed method may struggle to generalize to new datasets without ground truth summaries. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing the issue with the plan-based method and its generalizability. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the plan-based method requires manual design based on ground truth, which is unrealistic in real-world scenarios. It also suggests that the learned plan methods are not comparable to those with predefined plans, as indicated by Table 2. The comment further implies that the proposed method may struggle to generalize to new datasets without ground truth summaries. While the comment provides some logical reasoning and references a table, it lacks specific examples or detailed explanations to fully substantiate the claims. This makes the comment somewhat verifiable, as the authors would need to further explore the reasoning to fully understand and address the critique.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant limitation of the plan-based method, noting that it requires manual design based on ground truth, which is unrealistic in real-world scenarios. It also points out that the learned plan methods are not comparable to those with predefined plans, as shown in Table 2. This observation highlights a potential issue with the generalizability of the proposed method to new datasets without ground truth summaries. While the comment effectively identifies a critical weakness, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the generalizability of their method. Therefore, the feedback is somewhat helpful, as it provides insight into a key area for improvement but does not offer detailed, actionable advice.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should report results for multiple held-out test sets instead of just one, as this is the standard practice in many papers on Gaussian Processes (GPs). The reviewer acknowledges that this might take a long time due to dataset size but encourages the authors to carry out this exercise. The comment provides a clear and explicit action for the authors to take, which is to report results for multiple test sets. However, it does not provide specific guidance on how to implement this change or what specific aspects to focus on. While the action is explicit, the lack of detailed instructions on execution makes it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the issue of reporting results for a single held-out test set, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the use of multiple train/test splits or folds to provide a more accurate illustration of the method's performance. The comment also acknowledges the potential time constraints involved in conducting this additional analysis. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that reporting results for a single held-out test set is not standard practice in many papers on Gaussian Processes (GPs) and recommends using multiple train/test splits or folds for a more accurate illustration of the method's performance. The comment provides logical reasoning by pointing out the common practice in the field and acknowledges the potential time constraints involved in conducting this additional analysis. However, it lacks specific references or examples from other papers to fully substantiate the claim. Therefore, the comment is mostly verifiable, as it provides a reasonable suggestion but could benefit from more detailed evidence or references.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the experimental methodology, noting that results are reported for a single held-out test set, which is not standard practice in many papers on Gaussian Processes (GPs). It suggests that using multiple train/test splits or folds would provide a more accurate illustration of the method's performance. The comment acknowledges the potential time constraints involved in conducting this additional analysis but encourages the authors to carry out the exercise. This feedback is clear and actionable, offering a specific suggestion for improvement that could enhance the robustness and credibility of the results. However, it could be more helpful if it provided guidance on how to implement this suggestion or discussed the implications of using multiple splits. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the method appears more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide explicit guidance or suggestions on how the authors could simplify the method or identify the simpler principle. The feedback lacks specificity and actionable steps, leaving the authors uncertain about how to address the concern. Since the comment is vague and does not offer a clear path for action, it is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the method seems overly complex and implies that there might be a simpler underlying principle driving the quality gains. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the method are considered complex or what simpler principle might be involved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that the method appears more complex than necessary and implies that there might be a simpler underlying principle driving the quality gains. However, the comment lacks specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment suggests that the method seems overly complex and implies that there might be a simpler underlying principle driving the quality gains. However, it does not provide specific feedback or suggestions on how the authors could simplify the method or identify the simpler principle. Without actionable guidance or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the use of \\\"s_n\\\" instead of \\\"s_t\\\" in Algorithm 1 Line 8, suggesting a potential error. It also asks for the asymptotic performance of the proposed method and requests average return results with more environment steps. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The actions are somewhat clear but inferred, and the request for additional results is concrete. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 1 Line 8,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the use of \\\"s_n\\\" instead of \\\"s_t,\\\" providing a clear direction for the authors to address. Additionally, the comment raises questions about the asymptotic performance and requests average return results with more environment steps, offering specific guidance on what needs to be clarified or improved. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a question about a potential error in Algorithm 1 Line 8, suggesting the use of \\\"s_n\\\" instead of \\\"s_t.\\\" It also raises questions about the asymptotic performance of the proposed method and requests average return results with more environment steps. The comment does not make any subjective claims or judgments but rather seeks clarification and additional information. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a specific question about a potential error in Algorithm 1 Line 8, suggesting that \\\"s_n\\\" should be used instead of \\\"s_t.\\\" This is a clear and actionable point that the authors can address to improve the accuracy of their algorithm. Additionally, the comment expresses curiosity about the asymptotic performance of the proposed method and requests average return results with more environment steps. This request for additional data and analysis is valuable, as it could provide insights into the method's long-term behavior and robustness. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the feedback is mostly helpful as it identifies a specific issue and suggests an area for further exploration, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests toning down a specific statement about the neural network memorizing critical points, which is a clear and actionable recommendation. Additionally, it advises compressing the method section to focus on essential definitions, which is another concrete suggestion. The comment also mentions the need to double-check for grammatical errors, particularly with plurals and articles, providing a specific example (\\\"l.\\\"). This level of detail and clarity makes the comment highly actionable, as it gives the authors precise guidance on how to improve their draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions a specific phrase \\\"to force the neural network to memorize them\\\" and provides a reference to TopoNet [24], allowing the authors to accurately identify the part of the paper being addressed. It also suggests compressing the method section and points out grammatical errors, providing specific guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the statement about the neural network memorizing critical points is overstated and provides a reference to TopoNet [24] to support this claim. However, the comment does not elaborate on how TopoNet's approach differs from the one being criticized, leaving the authors to infer the details. Additionally, the comment mentions grammatical errors but does not specify which ones, making it difficult for the authors to address them effectively. Overall, the claim is somewhat verifiable due to the reference to TopoNet, but the lack of detailed explanation and specific examples makes it challenging for the authors to fully understand and address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on several aspects of the paper. It suggests toning down a particular statement about the neural network memorizing critical points, referencing TopoNet [24] to support this suggestion. Additionally, it points out that the method section is wordy and could be compressed to focus on essential definitions. The comment also highlights the presence of grammatical errors, particularly with plurals and articles, and suggests double-checking these. This feedback is clear and constructive, offering the authors concrete steps to improve the clarity, conciseness, and grammatical accuracy of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors update the statement about uncertainty to clarify that epistemic model uncertainty is represented in the prior distribution, which is updated to a posterior distribution upon observing data. This feedback provides a clear and explicit action for the authors to take, specifying exactly what change is needed to improve the clarity of the text. The comment is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the sentence \\\"The uncertainty is defined based on the posterior distribution,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the authors update the statement to clarify that epistemic model uncertainty is represented in the prior distribution and can be updated to a posterior distribution upon observing data. This provides detailed guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the statement about uncertainty could be clearer by specifying that epistemic model uncertainty is represented in the prior distribution and updated to a posterior distribution upon observing data. This claim is somewhat verifiable as it provides a logical suggestion for improving clarity, but it lacks specific examples or references to support the need for this clarification. The comment does not provide detailed reasoning or evidence to fully substantiate the claim, making it challenging for authors to fully understand the necessity of the suggested change. Therefore, the comment is classified as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion to improve the clarity of the paper by clarifying the definition of uncertainty. It suggests updating the statement to specify that epistemic model uncertainty is represented in the prior distribution and can be updated to a posterior distribution upon observing data. This feedback is clear and constructive, offering the authors a concrete way to enhance the understanding of their methodology. By addressing this point, the authors can improve the comprehensibility of their work, making the comment highly helpful. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point critiques the claim of parameter efficiency for COCO-LM by suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It raises a question about the experimental setup, specifically why the authors switched the types of BPE vocabulary (uncased and cased) and whether this change affects performance variance. While the comment implies that the authors should address these questions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation for the BPE vocabulary change and its impact on performance. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the comparison with Megatron and COCO-LM, suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency and asks for clarification on the experimental setup, specifically regarding the switch in BPE vocabulary types. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the experimental setup or results sections. The comment is specific in detailing what needs to be addressed regarding the comparison and the BPE vocabulary switch. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the comparison with Megatron is overrated, suggesting that the performance of Megatron and COCO-LM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides examples of these related works to support the claim, which helps in understanding the context and validity of the assertion. However, the comment could be strengthened by providing more detailed comparisons or references to specific studies that demonstrate the similarity in performance. As it stands, the claim is mostly verifiable due to the inclusion of examples, but it lacks comprehensive evidence or detailed reasoning, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment critiques the claim of parameter efficiency for COCO-LM by suggesting that its performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the validity of the claim, which is a relevant point for the authors to address. Additionally, the comment raises a question about the experimental setup, specifically why the authors switched the types of BPE vocabulary (uncased and cased) and whether this change affects performance variance. This feedback is somewhat helpful as it prompts the authors to reconsider their claims and provides a specific area for further exploration in their experimental setup. However, it could be more helpful if it offered suggestions on how to address these issues or provided more detailed guidance on how to improve the draft. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment critiques the analysis from line 128 to 149, noting that it is not convincing enough. It provides specific observations from the histogram in Fig 3, where the GS-P-50 model has a smaller class selectivity score, suggesting that GS-P-50 shares more features and ResNet-50 learns more class-specific features. The reviewer also mentions a hypothesis about additional context allowing the network to reduce dependency. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the analysis. While it highlights a potential area for improvement, it lacks concrete suggestions or actions for the authors to take. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but does not offer detailed guidance on how to implement it.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed critique of the analysis, including observations from the histogram in Fig 3 and a hypothesis about class selectivity. The comment further references external works, which could provide additional context or support for the analysis. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point critiques the analysis from line 128 to 149, suggesting that it is not convincing enough. The reviewer provides specific observations from the histogram in Fig 3, noting that the GS-P-50 model has a smaller class selectivity score, implying it shares more features and that ResNet-50 learns more class-specific features. The reviewer also references external works, such as \\\"Squeeze-and-Excitation Networks\\\" by J. Hu, L. Shen, and G. Sun (CVPR, 2018) and \\\"Understanding the Effective Receptive Field in Deep Convolutional Neural Networks\\\" by W. Luo et al. (NIPS, 2016), to support the claim. This detailed reasoning and reference to external sources provide a solid foundation for the critique, making the claim fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from line 128 to 149 is not convincing enough. It provides a detailed critique by referencing the histogram in Fig 3, which suggests that the GS-P-50 model shares more features and that ResNet-50 learns more class-specific features. The reviewer also offers a hypothesis about how additional context might allow the network to reduce its dependency. The comment further supports its point by referencing external works, which could provide additional context or support for the analysis. This feedback is mostly helpful as it provides a clear critique and suggests a potential area for improvement, but it could be more helpful if it offered specific suggestions on how to strengthen the analysis or address the identified issue. Therefore, the comment is rated as mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that some conclusions in the paper are not convincing, specifically mentioning the claim about continuous learning with unlabeled data accumulating noise. It suggests that the results might be due to limited exploration of combination methods and provides references to recent works that employ feature-replay methods, such as [R1] and [R2], as well as a more recent work [R3]. While the comment identifies areas that need further exploration and references recent works, it does not provide explicit guidance on how the authors should address these issues or what specific actions they should take to strengthen their conclusions. The action is implicit and somewhat vague, as the authors need to infer that they should consider the suggested references and potentially expand their exploration of combination methods. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions a specific claim in the paper, \\\"We believe that continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed critique of the claim, suggesting that the results might be due to limited exploration of combination methods and referencing recent works that employ feature-replay methods, such as [R1] and [R2], as well as a more recent work [R3]. This level of detail provides clear guidance on what needs to be addressed or improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that some conclusions are not convincing, specifically questioning the assertion that \\\"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\\\" The reviewer supports this claim by suggesting that the results might be due to limited exploration of combination methods. They provide references to recent works, such as [R1] and [R2], which employ feature-replay methods, and a more recent work [R3] that also uses feature replay to continually adjust the feature space. This detailed comparison with existing literature provides a robust foundation for the claim, making it fully verifiable. The inclusion of specific references and logical reasoning supports the reviewer's assertion, ensuring that the authors can understand and address the critique effectively.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific claim in the paper as unconvincing, namely the assertion that \\\"continuous learning with unlabeled data accumulates noise, which is detrimental to representation quality.\\\" It suggests that the results might be due to limited exploration of combination methods and provides references to recent works that employ feature-replay methods, such as [R1] and [R2], as well as a more recent work [R3] that also uses feature replay. This feedback is mostly helpful as it points out a potential weakness in the paper's conclusions and offers a clear direction for the authors to explore and address this issue by referencing relevant literature. However, the comment could be more helpful if it included specific suggestions on how to incorporate these references or how to strengthen the analysis. Overall, the comment provides valuable insights and references that can guide the authors in improving their draft, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions and suggests potential improvements, but it lacks explicit instructions or concrete actions for the authors to take. The comment implies that the authors should consider other bit operations, provide more explanations for Figure 5a, and analyze energy consumption as reference [15] did. However, it does not specify which bit operations to consider, how to improve the explanation for Figure 5a, or how to analyze energy consumption. The actions are implicit and vague, leaving the authors without clear guidance on how to address these points. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is partially grounded as it mentions specific elements like \\\"Fig. 5 a\\\" and \\\"reference[15],\\\" which allows the authors to identify the parts of the paper being addressed. However, it lacks specificity in detailing what needs to be addressed or improved in these sections. The comment raises questions about other bit operations, the explanation of Figure 5a, and the handling of DVS input, but it does not provide specific guidance or suggestions on how to address these issues. Therefore, the comment is weakly grounded and not specific, aligning with a score of 2.\",\n    \"grounding_specificity_label\": \"2\",\n    \"verifiability_rationale\": \"The review point consists of a mix of observations and suggestions. It acknowledges the positive aspect of point 11 but raises questions about other bit operations and the explanation of Figure 5a. The suggestion to analyze energy consumption is presented as a potential improvement. However, the comment lacks specific reasoning or evidence to support the claims about the bit operations or the energy consumption analysis. The questions are more of requests for clarification rather than claims requiring verification. Therefore, the review point is somewhat verifiable, as it provides some context but lacks detailed justification or examples.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises several points of interest and suggests potential improvements. It acknowledges the positive aspect of point 11 but questions the applicability of other bit operations and asks for more explanations regarding Figure 5a. Additionally, it inquires about how the authors handled DVS input and suggests analyzing energy consumption, referencing a previous work for comparison. While the comment identifies areas for improvement and provides some direction, it lacks specific guidance or actionable steps for the authors to follow. The suggestions are somewhat helpful as they prompt the authors to consider additional analyses and explanations, but they could be more detailed and comprehensive. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the first two bullet points about contributions, located at the end of the introduction, can be combined together. This is an explicit suggestion that provides a clear action for the authors to take. However, it does not specify how these two points should be combined or what specific aspects should be integrated, leaving some room for interpretation. Despite this, the action is direct and concrete, making the comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"first two bullets about contributions\\\" at the end of the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a concrete action: combining these two bullet points. This provides clear guidance on what needs to be revised or improved in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the first two bullet points about contributions at the end of the introduction can be combined. However, it does not provide any justification or reasoning for why this combination would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the rationale behind this suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion to improve the organization of the introduction by combining the first two bullet points about contributions. This feedback is clear and directly addresses a structural issue in the paper, which can help the authors enhance the clarity and coherence of their draft. However, the comment could be more helpful if it explained why combining these points would be beneficial or how it would improve the overall flow of the introduction. Despite this, the feedback is mostly helpful as it offers a concrete step for the authors to take in revising their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to define the dashed lines in figures 2A-B and 4B. This is a direct and clear action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be addressed, leaving no ambiguity about the task. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"fig. 2A-B\\\" and \\\"fig. 4B,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, defining the dashed lines in these figures. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point is a request for clarification regarding the figures in the paper, specifically asking to define the dashed lines in figures 2A-B and 4B. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual request for information, so \\\"No\\\" is the appropriate label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment is somewhat helpful as it identifies a specific area for clarification in the paper, namely the dashed lines in figures 2A-B and 4B. By asking the authors to define these lines, the comment highlights a potential issue with the clarity of the figures, which is important for understanding the content. However, the comment does not provide any suggestions on how to define these lines or why they are important, limiting its helpfulness. While it points out a specific area for improvement, it lacks depth and actionable guidance, making it somewhat helpful but not comprehensive.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should focus more on the unsupervised pretraining method in the main paper, as it appears to be a key factor in performance gain, as indicated by the data in Table 4. The reviewer also compares the importance of unsupervised pretraining with the ablation study in Table 5, implying that it is more significant than other modules discussed in the paper. While the comment provides a clear direction for the authors to focus on the pretraining method, it does not offer specific guidance on how to incorporate this discussion into the main paper. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 4\\\" and \\\"Table 5,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of detailed discussion on unsupervised pretraining in the main paper and suggests that it is more important than other modules presented in the paper. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that unsupervised pretraining is a key factor in performance gain, as indicated by data in Table 4. However, it also notes the lack of detailed discussion on unsupervised pretraining in the main paper. The reviewer compares the importance of unsupervised pretraining with the ablation study in Table 5, suggesting it is more significant than other modules. This reasoning is somewhat verifiable as it provides a logical comparison between the data in Table 4 and the ablation study in Table 5, but it lacks specific examples or references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a key issue in the paper, noting that the unsupervised pretraining method is crucial for performance gains, as indicated by data in Table 4. However, it points out that there is no detailed discussion of this aspect in the main paper. The reviewer suggests that the authors should focus more on the pretraining method, as it appears to be more important than other modules discussed in the paper. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by emphasizing the importance of the unsupervised pretraining method. However, the comment could be more helpful if it offered suggestions on how to integrate this discussion into the main paper or provided examples of what aspects of the pretraining method should be highlighted. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not provide specific examples of where the writing is unclear or how it could be improved. The feedback lacks explicit instructions or concrete details on how to simplify the writing, leaving the authors uncertain about the exact changes needed to improve clarity. As a result, the comment is vague and lacks actionable guidance, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not specify which sections or parts of the paper are particularly challenging to understand, nor does it provide details on what aspects of the writing could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing revision. As a result, the comment lacks both grounding and specificity, making it not grounded at all.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the writing is difficult to follow in many places and suggests that it can be simplified. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of where the writing is unclear, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a general issue with the writing, stating that it is difficult to follow in many places and suggests that it can be simplified. However, it lacks specificity and does not provide detailed guidance or examples on which parts of the writing are unclear or how they could be improved. Without actionable feedback or specific suggestions, the authors are left with a vague understanding of what needs to be addressed. This limits the utility of the comment, making it barely helpful. Therefore, it aligns with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors should provide some intuition about the proof of Theorem 1. It also raises questions about the invertible function $f^*$ and its dependence on the fixed $P^*$, asking whether certain distributions $P^*$ make it easier to determine $f^*$. Additionally, it inquires about how to determine which $P^*$ to fix in practice. While the comment implies that the authors should provide more explanation and context, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address these points. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Theorem 1\\\" and the invertible function $f^*$, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises several questions and suggestions for improvement, such as providing intuition about the proof of Theorem 1, discussing the dependence of $f^*$ on $P^*$, and asking about practical considerations for determining $P^*$. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the paper would benefit from providing intuition about the proof of Theorem 1 and discusses the invertible function $f^*$ and its dependence on the fixed $P^*$. It raises questions about whether certain distributions $P^*$ make it easier to determine $f^*$ and how to practically determine which $P^*$ to fix. While the comment highlights areas for improvement, it does not provide specific examples or references to support the need for this additional information. The lack of detailed justification or evidence makes the claim somewhat verifiable, as the authors would need to infer the importance of these points and how to address them. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment suggests that the paper would benefit from providing more intuition about the proof of Theorem 1. It also raises questions about the invertible function $f^*$ and its dependence on the fixed $P^*$, asking whether certain distributions $P^*$ make it easier to determine $f^*$ and how to practically determine which $P^*$ to fix. While the comment identifies areas for improvement and prompts the authors to consider additional explanations and practical considerations, it lacks specific suggestions or guidance on how to address these points. The feedback is somewhat helpful as it highlights important aspects that could enhance the paper, but it could be more actionable with detailed advice or examples. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the use of different variables (X and H^(1)) in equations (7) and (10), suggesting that they should be analogous. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks actionable details, such as recommending a specific change or providing examples of how to make the equations more analogous. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eqs. (7) and (10),\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the use of different variables (X and H^(1)) in these equations and asks why they are not analogous, providing clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a question asking for clarification about the use of different variables in equations (7) and (10). It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the use of different variables in equations (7) and (10), specifically questioning why they are not analogous. This feedback prompts the authors to clarify the rationale behind the use of different variables, which could help improve the clarity and coherence of their equations. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending a particular approach or explanation. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies specific issues with Section 4.2, particularly the mismatch between the description and the equation, and the lack of clarity regarding the question representation and the meaning of \\u03c3 in the equation. The reviewer explicitly asks for clarification on these points, providing a clear and concrete action for the authors to take. The comment also suggests that the authors should clarify whether \\u03c3 represents the sigmoid activation and address potential issues with numerical stability. This level of detail and explicit guidance makes the comment highly actionable, as it provides clear steps for the authors to follow to improve their draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Sec. 4.2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the description in Section 4.2 not matching the equation, the lack of a term for r^q, and the unclear meaning of \\u03c3 in the equation. The comment further suggests clarifying these points and addresses potential numerical stability issues. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the clarity of how a question is used to learn an attention on image features, specifically questioning the mismatch between the description in Section 4.2 and the equation provided. The reviewer points out the absence of a term for r^q in the equation and the unclear meaning of \\u03c3, suggesting that it might represent the sigmoid activation. This feedback is somewhat verifiable as it identifies specific areas of confusion and suggests potential issues, but it lacks detailed reasoning or references to fully substantiate the claims. The authors would need to make a significant effort to address these points, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment is highly helpful as it identifies specific areas of confusion in the paper, particularly in Section 4.2. It points out a mismatch between the description and the equation, specifically noting the absence of a term for r^q, which is the question representation. The comment also questions the meaning of \\u03c3 in the equation and suggests that it might represent the sigmoid activation. Additionally, it raises a concern about potential numerical instability due to multiplying two sigmoid activations. This feedback is clear, actionable, and provides detailed guidance on how the authors can improve the clarity and accuracy of their explanation. By addressing these points, the authors can significantly enhance the comprehensibility of their work, making this comment highly beneficial.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies a potential conflict between the second rule in Lemma 2, specifically Eq. (7), and the definition of minimal conditional dependence. It highlights a specific scenario where taking Z' as the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. However, the comment does not provide explicit guidance on how the authors should address this conflict or suggest a resolution. The action is implicit, as the authors need to infer that they should investigate and resolve the inconsistency, but it remains vague without concrete steps on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Lemma 2\\\" and \\\"Eq (7),\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue by pointing out a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence. The comment provides a clear explanation of the conflict, making it specific. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims a conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically referencing Eq. (7). The reviewer provides a logical reasoning by explaining the potential inconsistency when Z' is taken as the empty set, suggesting that x and y should be independent given W, but Eq. (7) contradicts this. This detailed explanation and logical reasoning provide a robust foundation for the claim, making it fully verifiable. The comment effectively supports the claim with clear reasoning and specific references to the lemma and equation, aligning with a score of 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential conflict between the second rule in Lemma 2 and the definition of minimal conditional dependence, specifically referencing Eq. (7). It provides a clear explanation of the issue by highlighting a scenario where taking Z' as the empty set should result in x and y being independent given W, but Eq. (7) contradicts this. This feedback is valuable as it points out a specific inconsistency that the authors need to address, which could significantly improve the accuracy and clarity of their theoretical framework. However, the comment could be more helpful if it offered suggestions on how to resolve the conflict or provided guidance on how to clarify the definitions. Despite this, the comment is mostly helpful as it directs the authors to a critical area needing attention and provides a clear basis for further investigation.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the update of archetype positions after initialisation in Algorithm 2. It explicitly asks the authors to comment on this aspect, providing a clear and direct action for the authors to take. However, the comment does not provide specific guidance on how the authors should address this issue or what information they should include in their response. While the action is explicit, the lack of detailed instructions on how to implement the feedback makes it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity on how the archetype positions are updated after initialisation. The comment requests clarification on this aspect, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a factual statement about Algorithm 2 and the query Q, followed by a request for clarification on how the archetype positions are updated. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area of confusion regarding Algorithm 2, particularly the update of archetype positions after initialisation. It requests clarification from the authors on this aspect, which is a clear and actionable suggestion for improvement. By prompting the authors to provide additional details, the comment helps them address a potential gap in their explanation, thereby enhancing the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered specific suggestions or examples of how to clarify this aspect. Overall, the feedback is mostly helpful as it directs the authors to a critical area needing clarification, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies several missing pieces of information that should be included in the supplement, such as recording parameters for the MRI, preprocessing steps, the condition under which the resting-state was recorded (eyes-open or eyes-closed), and a brief explanation of the harmonization technique. Additionally, it suggests mentioning the number of regions in the parcellation in the main text. These suggestions are clear and provide concrete guidance on what specific information needs to be added, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the need for additional information in the supplement, such as recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded. It also suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that important information about the empirical study is missing and should be included in the supplement. It lists specific details that are absent, such as recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded. Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support why these omissions are significant. The authors would need to infer the importance of these details themselves, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies several important omissions in the empirical study that should be included in the supplement. It specifically mentions the need for recording parameters for the MRI, preprocessing steps, and the condition under which the resting-state was recorded (eyes-open or eyes-closed). Additionally, it suggests including a brief explanation of the harmonization technique and mentioning the number of regions in the parcellation in the main text. These suggestions are clear and actionable, providing the authors with specific guidance on how to enhance the completeness and clarity of their manuscript. The feedback is detailed and constructive, making it highly helpful for the authors to improve their draft. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a significant risk associated with methods that exploit relationships between action units, noting that these relationships can vary across datasets. It provides a specific example, such as the co-occurrence of AU6 in different contexts, and suggests that cross-dataset experiments would be a good way to test the generalization of such work. The comment explicitly states the need for cross-dataset experiments, providing a clear and concrete action for the authors to take. This guidance leaves no ambiguity about what the authors should do to improve their draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of differing relationships between action units across datasets and suggests a solution by performing cross-dataset experiments. The comment provides a clear rationale for the need for such experiments, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the risk of methods exploiting relationships between action units, noting that these relationships can vary across datasets. The reviewer provides a specific example, such as AU6 occurring in both pain and happiness contexts, and highlights the differences in co-occurrence across datasets like SEMAINE and UNBC pain dataset. This example is used to illustrate the potential issue, and the suggestion to perform cross-dataset experiments is a logical recommendation to test the generalization of the work. The claim is well-supported by a clear example and a logical suggestion, making it mostly verifiable. However, the comment could be further strengthened by providing more detailed reasoning or references to similar studies, which would elevate it to a fully verifiable status. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant risk associated with methods that exploit relationships between action units, specifically highlighting the variability of these relationships across different datasets. It provides a concrete example, such as the co-occurrence of AU6 in different contexts, and suggests a practical solution by recommending cross-dataset experiments to test the generalization of the work. This feedback is clear, actionable, and offers a specific direction for the authors to enhance their study, making it highly helpful. The comment effectively guides the authors in addressing a critical aspect of their research, thereby contributing significantly to the improvement of their draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the statement regarding over-parametrization and its impact on performance, suggesting that over-parameterization can be beneficial in practice. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this concern or incorporate additional information or references. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 47 - 48,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the statement about over-parameterization and its impact on performance, suggesting that over-parameterization can be beneficial in practice and referencing theoretical work that supports this view. This provides clear guidance on what aspect of the statement needs reconsideration or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the statement that \\\"over-parametrization invariably overfits the data and results in worse performance.\\\" It counters this claim by suggesting that over-parameterization can be beneficial in practice and references theoretical work that supports this view. The comment provides a logical reasoning and references external sources, making the claim mostly verifiable. However, it could be strengthened by including specific examples or detailed references to the theoretical work mentioned. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment challenges a statement in the paper regarding over-parameterization, suggesting that it may not always lead to worse performance as claimed. It provides a counterpoint by highlighting the benefits of over-parameterization in practice and references theoretical work that supports this view. This feedback is somewhat helpful as it prompts the authors to reconsider their statement and potentially revise it to align with more accurate or nuanced understanding. However, the comment could be more helpful if it offered specific suggestions on how to integrate or revise the statement to reflect the benefits of over-parameterization. Overall, the comment provides valuable insight but lacks detailed guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides several explicit actions for the authors to take, making it highly actionable. It suggests adding more sentences to explain the experimental setting for continual learning, which is a clear and direct request. Additionally, it asks for an explanation of the correspondence between the learning curves and M-PHATE, which is another explicit action. The comment also poses questions about the purpose of looking at the learning curves, the potential structural collapse, and the accuracy numbers, which implies that the authors should provide these details. Each of these points is concrete and provides clear guidance on how to improve the draft, ensuring that the authors know exactly what needs to be done to address the feedback.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Fig 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as adding more sentences to explain the experimental setting for continual learning, explaining the correspondence between learning curves and M-PHATE, and asking specific questions about the accuracy numbers. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a series of questions and requests for clarification, rather than making subjective claims or opinions. It does not express any personal opinions, judgments, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides a mix of suggestions and questions that could help the authors improve their draft. It suggests adding more sentences to explain the experimental setting for continual learning, which is a clear and actionable recommendation. Additionally, it asks for an explanation of the correspondence between the learning curves and M-PHATE, which could help clarify the paper's content. The comment also poses questions about the purpose of examining the learning curves and the accuracy numbers, prompting the authors to provide more context and detail. However, the comment could be more helpful if it offered specific guidance on how to address these issues or provided examples of what additional information might be beneficial. Overall, the feedback is somewhat helpful as it identifies areas for improvement but lacks depth and specificity in its guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It suggests that if the compared methods were not initialized with the same pre-trained model, the proposed method's performance without SSL might be inferior. However, the comment does not provide explicit guidance on how the authors should address this issue, such as suggesting a specific approach to ensure fair comparisons or recommending additional experiments. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and potentially adjust their experimental setup. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the experimental comparison with other methods, specifically mentioning the pre-training stage and the initialization of models. It references Table 1, which provides full grounding by indicating the exact part of the paper being discussed. The comment is specific in its critique, as it questions the fairness of the comparison and highlights the performance of the proposed method without SSL compared to other methods. This provides clear guidance on what aspect of the experimental setup needs attention. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. The comment provides a logical reasoning by referencing Table 1, which shows that the proposed method without SSL performs inferior to most compared methods. This provides a basis for the claim, but the comment could be strengthened by providing more detailed evidence or examples of how the initialization of models might affect the results. Therefore, the comment is mostly verifiable, as it offers a reasonable basis for the claim but lacks comprehensive support.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment raises a valid concern about the fairness of the experimental comparison, specifically questioning whether the compared methods were initialized with the same or similar pre-trained models as the proposed method. It points out that if the compared methods were not initialized with the same pre-trained model, the proposed method's performance without SSL might be inferior. This feedback is clear and actionable, as it highlights a potential flaw in the experimental setup that could affect the validity of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a specific approach to ensure fair comparisons. Overall, the comment is mostly helpful, as it identifies a critical area for improvement and provides a clear direction for the authors to consider.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment acknowledges the use of \\\"attribute\\\" as meta-data for zero-shot learning on the CUB dataset, which is considered fair for comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring the performance of the proposed method with these options, referencing a specific paper. The comment provides a clear and explicit action for the authors to take, which is to update their experiments with better meta-data embeddings. This guidance is concrete, as it specifies exactly what the authors need to do to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 3 page 7\\\" and the \\\"CUB dataset,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests exploring better meta-data embeddings options, referencing a specific paper (\\\"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016\\\") for guidance. This provides clear direction on what the authors need to consider or improve in their work. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the use of \\\"attribute\\\" as meta-data for zero-shot learning on the CUB dataset is fair for comparison but implies that better meta-data embeddings options are available. The reviewer references a specific paper, \\\"Learning Deep Representations of Fine-Grained Visual Descriptions, Reed et al, CVPR 2016,\\\" to support the claim that better options are available. This reference provides a basis for the suggestion, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed examples or comparisons from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the use of \\\"attribute\\\" as meta-data for zero-shot learning on the CUB dataset, which is considered fair for comparison. However, it suggests that better meta-data embeddings options are available and recommends exploring the performance of the proposed method with these options, referencing a specific paper for guidance. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work by considering alternative meta-data embeddings. The comment also acknowledges the authors' response, indicating that the paper is acceptable for NIPS. Overall, the comment is mostly helpful as it offers a specific and actionable suggestion for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors include a plot with sparsity on the x-axis and performance on the y-axis to compare the flexibility of SGC with LoRA. This feedback provides a clear and explicit action for the authors to take, specifying exactly what needs to be done to improve the paper. The suggestion is concrete, as it outlines a specific visualization technique that could help demonstrate the practical benefits of SGC's fine-grained control. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly addresses the claim made in the paper regarding the flexibility and fine-grained control offered by SGC. It suggests including a plot with sparsity on the x-axis and performance on the y-axis to compare SGC with LoRA, providing a clear direction for improvement. The comment is also specific, as it outlines a particular visualization technique that could be used to demonstrate the practical benefits of SGC's control. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that while SGC offers a more flexible, fine-grained tradeoff, PEFT methods like LoRA are typically suited for compute-constrained scenarios where such granular control may require extra tuning, thus reducing practicality. The reviewer suggests including a plot with sparsity on the x-axis and performance on the y-axis to compare SGC with LoRA, which would provide a more intuitive demonstration of SGC's practical benefits. This claim is mostly verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim about PEFT methods' limitations. The suggestion for a plot is clear, but the overall claim could be strengthened with more detailed evidence or references. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the paper's claim regarding the flexibility and fine-grained control offered by SGC, suggesting that PEFT methods like LoRA are more suited for compute-constrained scenarios. It provides a clear and actionable suggestion to include a plot with sparsity on the x-axis and performance on the y-axis to directly compare SGC with LoRA. This visualization could help demonstrate whether SGC's fine-grained control offers practical performance benefits at different sparsity levels. The feedback is specific and offers a concrete way for the authors to address the issue, making it highly helpful for improving the draft. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the training time for the German and Law school dataset in the context of the Gerrymandering experiment compared to the Independent experiment. It suggests that the main advantage of the method is its computation time and implies that the code should be published. While the comment implies that the authors should consider publishing the code, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to address the question about training time. The action is implicit and somewhat vague, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the experiments section, specifically mentioning the German and Law school dataset and the comparison with the Independent experiment. It raises a question about the training time and suggests that the code should be published. However, it does not specify which part of the experiments or results this question pertains to, making it weakly grounded. The comment is specific in its request for the code to be published, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a question about the training time for the German and Law school dataset in the context of the Gerrymandering experiment compared to the Independent experiment. It suggests that the main advantage of the method is its computation time and implies that the code should be published. However, the comment lacks specific reasoning or evidence to support the claim about the training time or the necessity of publishing the code. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the training time for the German and Law school dataset in the context of the Gerrymandering experiment compared to the Independent experiment. It suggests that the main advantage of the method is its computation time and implies that the code should be published. While the comment identifies a potential area for clarification and suggests a specific action (publishing the code), it lacks detailed guidance or examples on how to address the question about training time or why publishing the code would be beneficial. The feedback is somewhat helpful as it points out a potential issue and offers a suggestion, but it could be more comprehensive with additional context or reasoning. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a discrepancy between the human baseline's performance and the model's performance, noting that the human baseline is weaker due to the limited amount of speech recordings. It also points out a misleading statement in the abstract regarding the human baseline's performance. However, the comment does not provide explicit guidance on how the authors should address these issues, such as suggesting ways to improve the human baseline or revising the abstract statement. The feedback is implicit and lacks concrete steps for the authors to follow, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the human baseline and the specific issue with the amount of speech recordings used, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the discrepancy between the human baseline's performance and the model's performance, as well as the misleading statement in the abstract. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the human baseline is weaker than the model baseline due to the limited amount of speech recordings (1 hour vs. 15 hours) and other factors mentioned in Section 4.1. The comment supports this claim by referencing the abstract's statement about the human baseline's performance. However, the comment lacks specific examples or detailed reasoning from Section 4.1 to fully substantiate the claim. While the reasoning is logical, the absence of explicit references or detailed evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the human baseline in the paper, noting that the human baseline is weaker due to the limited amount of speech recordings (1 hour) compared to the model baseline (15 hours). It also points out a misleading statement in the abstract regarding the human baseline's performance. This feedback is clear and actionable, as it highlights a critical area for improvement in the paper's presentation and results. By addressing this issue, the authors can enhance the credibility and accuracy of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the human baseline or how to revise the abstract statement. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions and requests for clarification regarding the synthetic data, the meaning of \\\"support data\\\" and \\\"predicted training count data\\\" in Figure 1, and the explicit model used. These questions imply that the authors should provide examples and clarify these aspects in their draft. While the actions are not explicitly stated, they are concrete and can be inferred from the reviewer's questions. The authors know what needs to be addressed to improve their draft, making this comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and requests for clarification, such as providing examples of synthetic data, explaining the meaning of \\\"support data\\\" and \\\"predicted training count data,\\\" and suggesting the explicit model used. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the synthetic data and the model used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises several questions and requests for clarification regarding the synthetic data, the meaning of \\\"support data\\\" and \\\"predicted training count data\\\" in Figure 1, and the explicit model used. These questions are specific and actionable, prompting the authors to provide examples and clarify their methodology. By addressing these points, the authors can improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to present this information or provided examples of what kind of data or model descriptions would be most beneficial. Overall, the comment is mostly helpful as it identifies areas for improvement and provides some direction, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should provide more detail on the EEG topography plots presented in Figure 3, particularly regarding the EEG token quantization process. It also recommends understanding the role of the spatial arrangement of EEG sensors in this process. While the comment implies that the authors should elaborate on these aspects, it does not explicitly instruct them to do so. However, the suggestion is concrete, as it specifies what additional information should be included to clarify the interpretation of the plots. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors elucidate the EEG topography plots for both input and output during the EEG token quantization process, and it recommends understanding the role of the spatial arrangement of EEG sensors in this process. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that Figure 3 presents EEG topography plots for both input and output during the EEG token quantization process, which leads to ambiguity in interpretation. The reviewer recommends that the authors elucidate this procedure in greater detail, specifically questioning the role of the spatial arrangement of EEG sensors. While the comment identifies a potential issue and suggests a way to address it, it lacks specific examples or references to support the claim about ambiguity. The reasoning is somewhat verifiable, as it provides a logical suggestion for improvement but does not fully substantiate the claim with detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Figure 3, noting that the EEG topography plots for both input and output during the EEG token quantization process lead to ambiguity in interpretation. It suggests that the authors provide more detail on this procedure, particularly regarding the role of the spatial arrangement of EEG sensors. This feedback is clear and actionable, as it guides the authors on how to enhance the clarity and interpretability of their results. By addressing this point, the authors can improve the comprehensiveness and understanding of their methodology. However, the comment could be more helpful if it offered specific suggestions on how to elucidate the procedure or provided examples of what additional details might be beneficial. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the authors use the complexity of checking on the Witness oracle, which is described as \\\"polynomial time\\\" in the tabular case. The reviewer suggests that this approach does not directly address the problem. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The feedback lacks specificity and actionable steps, leaving the authors uncertain about how to respond to the critique. Since the comment is vague and does not offer a clear path for action, it is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the complexity of checking on the Witness oracle, which is described as \\\"polynomial time\\\" in the tabular case. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment does specify the concern about the approach not directly addressing the problem, which adds some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the authors' approach of using the complexity of checking on the Witness oracle, described as \\\"polynomial time\\\" in the tabular case, does not directly address the problem. However, the comment lacks specific reasoning or examples to support this claim. It does not provide detailed justification or references to substantiate why this approach is insufficient or how it fails to address the problem directly. As a result, the claim is not verifiable due to the absence of supporting evidence or detailed explanation, making it difficult for the authors to understand and address the critique effectively. Therefore, the feedback is categorized as 1: Unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment points out a potential issue with the authors' approach, specifically the use of the complexity of checking on the Witness oracle, which is described as \\\"polynomial time\\\" in the tabular case. The reviewer suggests that this approach does not directly address the problem, which implies that the authors may need to reconsider their methodology or provide a clearer justification for their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies a specific section of the paper (lines 22-30) where the discussion on distributional RL lacks relevant literature on using moment matching instead of quantile regression. It suggests that this should be discussed when talking about various approaches to DRL. The comment provides a clear action for the authors to take, which is to include a discussion on moment matching in the context of distributional RL. However, it does not provide detailed guidance on how to integrate this discussion or what specific aspects to focus on. Therefore, while the action is explicit, it lacks concrete details on execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions a specific section of the paper, \\\"lines 22-30,\\\" where the discussion on distributional RL lacks relevant literature. It also specifies the issue by suggesting the inclusion of a discussion on moment matching, referencing a specific work (Nguyen-Tang et al AAAI\u201921, \u201cDistributional Reinforcement Learning via Moment Matching\u201d). This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically referencing Nguyen-Tang et al. (AAAI\u201921) as an example. This claim is supported by providing a specific reference to an external work, which helps substantiate the assertion. However, the comment could be strengthened by explaining how this reference is relevant to the paper's discussion or by providing additional examples of relevant literature. As it stands, the claim is mostly verifiable due to the inclusion of a specific reference, but it could benefit from further elaboration. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the literature review regarding the use of moment matching for distributional reinforcement learning (DRL), suggesting that the paper should include relevant references, such as the work by Nguyen-Tang et al. (AAAI\u201921). This feedback is clear and actionable, as it directs the authors to incorporate a discussion on moment matching in the context of DRL, even though the paper currently uses quantile regression. By addressing this suggestion, the authors can enhance the comprehensiveness and depth of their literature review, which is crucial for situating their work within the broader field. However, the comment could be more helpful if it provided additional guidance on how to integrate this discussion or what specific aspects of moment matching should be highlighted. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the second paragraph of the introduction discusses modelling curves but does not clearly specify what is being modelled, such as tumor growth. While the comment identifies an area of confusion, it does not provide explicit guidance on how the authors should clarify this aspect. The action is implicit, as the authors need to infer that they should add more detail about what is being modelled. However, the comment does not offer concrete steps on how to achieve this clarification, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"second paragraph of the introduction,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of clarity regarding what is being modelled in the context of modelling curves. The comment suggests that the authors should clarify what is being modelled, such as tumor growth, to improve the clarity of the introduction. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the second paragraph of the introduction discusses modelling curves but does not specify what is being modelled, such as tumor growth. This is a somewhat verifiable claim as it highlights a lack of clarity in the introduction. However, it does not provide specific examples or detailed reasoning to support the claim, making it challenging for the authors to fully understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue in the introduction, noting that the second paragraph discusses modelling curves but does not clearly specify what is being modelled, such as tumor growth. This feedback is somewhat helpful as it highlights a lack of clarity in the introduction, which is crucial for understanding the context and purpose of the paper. However, the comment does not provide detailed suggestions or guidance on how the authors might clarify this aspect, such as by explicitly stating the model being used or providing examples. To be more helpful, the comment could include specific suggestions for improvement. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the paper should analyze the quality of the local minima found by Algorithm 1, specifically by examining the approximation ratio of these local minima under certain assumptions. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions or detailed guidance on how to perform it. The action is inferred and somewhat vague, as the authors need to determine the specific assumptions and methods to use for the analysis. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 1\\\" and the issue of analyzing the quality of local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the approximation ratio of these local minima under certain assumptions, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the paper should analyze the quality of the local minima found by Algorithm 1, specifically by examining the approximation ratio under certain assumptions. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that this analysis is necessary or how it would enhance the paper. The suggestion is based on logical reasoning but is not fully substantiated with evidence or detailed guidance, making it somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area for improvement by suggesting that the paper should analyze the quality of the local minima found by Algorithm 1, particularly focusing on the approximation ratio under certain assumptions. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their analysis. By addressing this point, the authors could significantly improve the depth and rigor of their work. However, the comment could be more helpful if it included specific assumptions or methodologies to consider in the analysis. Overall, the comment is mostly helpful as it provides a clear and actionable suggestion for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises questions about how information redundancy is built into the Fill, Propagate, Decode algorithms and references a specific sentence in the paper. While it highlights areas of interest, it does not provide explicit actions or suggestions for the authors to take. The comment lacks concrete guidance on how the authors might address these questions or improve their draft. As a result, the authors are left without clear direction on how to respond to the feedback. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment raises questions about the integration of information redundancy into the Fill, Propagate, Decode algorithms and references a specific sentence in the paper. This provides full grounding as the authors can accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed regarding the integration of information redundancy and the robustness of the model. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the integration of information redundancy into the Fill, Propagate, Decode algorithms and a statement about the robustness of the model. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No\\\".\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises questions about the integration of information redundancy into the Fill, Propagate, and Decode algorithms, as well as a specific sentence in the paper. While it identifies areas that may need clarification, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address these questions or improve their draft. The comment is somewhat helpful as it points out specific areas of interest, but it does not offer a clear path for improvement. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to include experimental results that exclude the mixup technique from the proposed method. This direct request provides a clear action for the authors to take, ensuring they understand exactly what needs to be done to address the concern raised. The comment is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Sec. 4.2\\\" and the experiments on \\\"SplitCIFAR-100 and SplitTiny-ImageNet,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experimental results that exclude the mixup technique from the proposed method to demonstrate its pure contribution. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should include experimental results of excluding the mixup technique from their proposed method to demonstrate its pure contribution. This claim is based on the observation that the mixup technique is adopted in the experiments, implying that its absence would provide a clearer demonstration of the method's contribution. However, the comment lacks specific reasoning or evidence to support why this exclusion is necessary or how it would impact the results. Without detailed justification or examples, the claim is somewhat verifiable, as it provides a logical suggestion but lacks comprehensive support. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area for improvement by suggesting that the authors include experimental results of excluding the mixup technique from their proposed method. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper's demonstration of the method's pure contribution. By addressing this point, the authors can better substantiate their claims and provide a more comprehensive evaluation of their work. The comment is mostly helpful as it offers a concrete step for the authors to take, but it could be further improved by explaining why this exclusion is necessary or how it would impact the results. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between the RSPs and FDs. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or verify the calibration steps. The comment implies that the authors should investigate or correct the calibration steps, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section III of the 'Recognition and Velocity Computation of Large Moving Objects in Images' paper,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning potential errors in the initial calibration steps that might explain the observed speed disparities between the RSPs and FDs. This provides clear guidance on what aspect of the algorithm needs further investigation or clarification. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between the RSPs and FDs. However, the comment does not provide specific evidence or reasoning to support the claim that such errors occurred. It lacks detailed analysis or examples that would help the authors understand the basis of the concern. As a result, the claim is somewhat verifiable, as it requires more detailed evidence or explanation to fully substantiate the argument. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about potential errors in the initial calibration steps of the algorithm, which might explain the observed speed disparities between the RSPs and FDs. This feedback is valuable as it prompts the authors to investigate and verify the accuracy of their calibration steps, which could significantly impact the validity of their results. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending specific checks or analyses to perform. While it identifies a potential area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, it is rated as somewhat helpful, as it provides insight but not comprehensive guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly asks the authors to clarify the labels for each dataset in section 4.1, specifically questioning the source of these labels. It suggests that the labels are either from the dataset itself or from generated parts, but it raises a specific concern about \\\"cas-peal-r1\\\" and \\\"mugshot.\\\" This direct request for clarification provides a clear action for the authors to take, ensuring they know exactly what information needs to be added or clarified in their draft. The comment is explicit and concrete, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 4.1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the labels for each dataset and their source, particularly questioning the labels for \\\"cas-peal-r1\\\" and \\\"mugshot.\\\" This provides clear guidance on what the authors need to clarify or address in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the labels for each dataset in section 4.1. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the criteria for a \\\"No\\\" label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment is mostly helpful as it identifies a specific area of confusion regarding the labels for each dataset in section 4.1. It raises a question about the source of these labels, particularly for \\\"cas-peal-r1\\\" and \\\"mugshot,\\\" which suggests that the authors need to clarify this aspect in their paper. This feedback is clear and actionable, as it directs the authors to provide additional information that would enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of what kind of clarification might be needed. Overall, the comment provides valuable guidance for improving the draft, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several concerns about the sensitivity of performance and sample efficiency to the \\\\( \\\\lambda \\\\) parameters and questions the process of calculating \\\\( \\\\lambda \\\\). It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues. The feedback lacks actionable details, such as recommending specific analyses or clarifications, making it difficult for the authors to know what steps to take to improve their draft. As a result, the comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections of the paper, such as \\\"Page 9, lines 310-313\\\" and \\\"Page 8 lines 281-285,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the process of calculating the \\\\( \\\\lambda \\\\) parameter and expressing confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. Additionally, the comment references external works, which could provide further context or comparison. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the sensitivity of performance and sample efficiency to the \\\\( \\\\lambda \\\\) parameters and questions the process of calculating \\\\( \\\\lambda \\\\). It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The mention of external works ([1] to [3]) does not directly address the issues raised in the review point, making it difficult for the authors to understand the basis of the critique. As a result, the claim is somewhat verifiable, as it provides some context but lacks sufficient detail to fully substantiate the concerns.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises several important points regarding the sensitivity of performance and sample efficiency to the \\\\( \\\\lambda \\\\) parameters and questions the process of calculating \\\\( \\\\lambda \\\\). It also expresses confusion about the explanation of why ELLA does not increase sample efficiency in a COMBO environment. While the comment identifies areas of potential weakness and seeks clarification, it lacks specific suggestions or guidance on how the authors might address these issues. The inclusion of references to external works could provide some context, but the comment itself does not offer actionable advice. Overall, the feedback is somewhat helpful as it highlights critical areas for improvement but could be more comprehensive with detailed guidance. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises concerns about the effectiveness of the lower bound double q-learning, particularly in MsPacman where Clipped DDQN shows a slight performance decrease. It also notes that in some environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone, the algorithms converge to the same solutions. Additionally, the reviewer suggests that the algorithm may overestimate the true maximum value. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their work. The feedback lacks actionable details, such as recommending specific modifications or additional experiments to test the algorithms. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2\\\" and specific environments like \\\"MsPacman,\\\" \\\"WizardOfWor,\\\" \\\"Zaxxon RoadRunner,\\\" and \\\"BattleZone,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the effectiveness of the lower bound double q-learning, noting the slight performance decrease in MsPacman and the convergence of algorithms in other environments. Additionally, it points out the potential overestimation of the true maximum value. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the effectiveness of the lower bound double q-learning is doubtful, providing specific examples from Figure 2 and other environments like \\\"WizardOfWor,\\\" \\\"Zaxxon RoadRunner,\\\" and \\\"BattleZone\\\" where the algorithms converge to the same solutions. Additionally, it suggests that the algorithm may overestimate the true maximum value. While the comment provides some evidence and observations, it lacks detailed reasoning or references to support the claim fully. The authors would need to further explore these observations to understand the basis of the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires additional detail to be fully substantiated.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises concerns about the effectiveness of the lower bound double q-learning, particularly in the context of MsPacman and other environments like WizardOfWor, Zaxxon RoadRunner, and BattleZone. It points out that the algorithms converge to the same solutions in these environments and suggests that the algorithm may overestimate the true maximum value. While the comment identifies potential issues with the algorithm's performance and convergence, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their approach. The feedback provides some insight into the problem but does not offer actionable steps for the authors to take, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as shown in Figure 3-4. The reviewer expresses an expectation that the performance should approach vanilla methods from above but from below. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or clarify the discrepancy. The action is implicit, as the authors can infer that they need to explain or justify the observed performance difference, but the comment lacks concrete details on how to do so. Therefore, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"fig.3-4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the unexpected performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, and the reviewer's expectation of the performance approaching vanilla methods from above but from below. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a question about the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as shown in Figure 3-4. The reviewer expresses an expectation that the performance should approach vanilla methods from above but from below. However, the comment lacks specific reasoning, examples, or references to support the claim or to explain why the performance is expected to behave in this manner. Without additional context or justification, the claim remains unverifiable, as it does not provide enough information for the authors to understand or address the issue. Therefore, the comment is rated as 1: Unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the performance of DNN+MMA becoming worse than vanilla DNN when lambda becomes small, as shown in Figure 3-4. It expresses an expectation that the performance should approach vanilla methods from above but from below. This feedback is somewhat helpful as it points out a potential discrepancy in the results that the authors need to address. However, the comment lacks depth and does not provide suggestions or guidance on how the authors might investigate or resolve this issue. To be more helpful, the comment could include specific questions or hypotheses for further exploration. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point notes that the paper does not compare its results with some earlier research work from 2020 and mentions that the authors have explained their reasons for not doing so. However, it does not provide explicit guidance on how the authors should address this issue or what specific comparisons should be made. The comment lacks actionable details, such as suggesting which earlier works should be compared or how to structure the comparison. As a result, the authors are left without clear steps to take in response to this feedback. Therefore, the comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment highlights a lack of comparison with earlier research work from 2020, specifically mentioning the comparison with systems like Taghipour and Ng (2016). However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in pointing out the need for comparisons with earlier work, but it lacks detailed guidance on how to incorporate these comparisons or which specific systems should be included. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the paper does not compare its results with earlier research work from 2020, specifically mentioning the comparison with systems like Taghipour and Ng (2016). However, the comment does not provide detailed reasoning or evidence to support why these comparisons are necessary or how they would impact the paper's conclusions. The mention of the authors' explanation in the author response about the systems not being state-of-the-art adds some context, but it does not fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a starting point but lacks comprehensive justification or examples.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment points out a gap in the paper's comparison with earlier research work from 2020, specifically mentioning the comparison with systems like Taghipour and Ng (2016). While the authors have explained their reasons for not including these comparisons, the comment highlights the importance of such comparisons for contextualizing the paper's contributions. However, the feedback lacks specific guidance on how the authors might address this gap or what additional comparisons would be most beneficial. It provides some insight but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors elaborate on the explanation regarding Hoeffding's bound and its applicability to stochastic algorithms. The action is explicit, as it directly instructs the authors to provide further elaboration. However, while the comment identifies the area that needs elaboration, it does not specify exactly what aspects should be expanded upon or how the authors should approach this elaboration. This makes the comment somewhat actionable, as the authors know they need to add more detail but may not be entirely sure of the specific content to include.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Line 124-125,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with Hoeffding's bound and its applicability to stochastic algorithms, suggesting that the authors elaborate on this point. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the authors should elaborate on the applicability of Hoeffding's bound to stochastic algorithms. The comment provides a logical reasoning by explaining that Hoeffding's bound holds true under certain conditions, such as independent samples, and that stochastic algorithms further guarantee its validity. However, the comment lacks specific examples or references to support the claim, making it somewhat verifiable. The authors would need to infer the details themselves, which limits the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area in the paper where the authors could provide more elaboration, particularly regarding the applicability of Hoeffding's bound to stochastic algorithms. It highlights the importance of explaining how stochastic algorithms guarantee the validity of the inequality, which is a crucial aspect for the paper's theoretical foundation. However, the comment does not offer detailed guidance or suggestions on how the authors might elaborate on this point, which limits its helpfulness. While it points out an area for improvement, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights that certain representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared in the paper. While it implicitly suggests that these models should be included in the comparison, it does not explicitly instruct the authors to do so. Additionally, the comment lacks concrete guidance on how to incorporate these models into the comparison or what specific aspects should be focused on. The action is inferred and somewhat vague, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that certain representative panoptic segmentation models, like PanopticFPN and Mask2Former, are not compared in the paper. However, it does not specify which part of the paper this comparison should be included in, making it weakly grounded. The comment is specific in identifying the models that are missing from the comparison, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that certain representative panoptic segmentation models, like PanopticFPN and Mask2Former, are not compared in the paper. However, the comment does not provide any reasoning or evidence to support why these models should be included or why their absence is a significant issue. Without additional context or justification, the authors may find it challenging to understand the importance of these models in the context of the paper. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific omission in the paper, noting that certain representative panoptic segmentation models, such as PanopticFPN and Mask2Former, are not compared. This feedback is clear and actionable, as it directs the authors to include these models in their comparisons to provide a more comprehensive evaluation of their work. By addressing this point, the authors can enhance the comprehensiveness and robustness of their study. However, the comment could be more helpful if it provided additional context or rationale for why these specific models are important to include. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to proofread the paper and fix all language problems, including specific examples such as \\\"we typically considers,\\\" \\\"two permutation,\\\" and \\\"until converge.\\\" This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed. The explicit nature of the instructions and the specific examples make this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific instances in the paper, such as \\\"(7),\\\" \\\"Theorem 1,\\\" and \\\"(14),\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also provides specific feedback on language usage, such as correcting \\\"we typically considers\\\" to \\\"we typically consider,\\\" \\\"two permutation\\\" to \\\"two permutations,\\\" and \\\"until converge\\\" to \\\"until convergence.\\\" This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of minor comments on language usage and a request for proofreading. It does not contain any subjective claims, opinions, or suggestions that require verification. The comments are factual and descriptive, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a minor issue with language usage, providing specific examples of where the language could be improved. It also includes a general suggestion to proofread the paper and fix all language problems. While the comment is specific in its language usage critique, it lacks depth and does not provide actionable guidance on how to address the language issues or improve the overall quality of the paper. The feedback is somewhat helpful as it points out areas for improvement, but it could be more comprehensive with additional suggestions or examples. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. The reviewer expresses reservations about the method's broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not provide explicit guidance on how the authors should address this limitation or suggest specific ways to expand the framework. The action is implicit and vague, as the authors are left to infer that they need to broaden the scope of their evaluation, but without concrete steps or suggestions on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the evaluative framework, specifically mentioning the limitation in scope due to the restriction to three Question-Answering tasks and two language models. It raises concerns about the method's broader applicability and suggests considering other reasoning or generation tasks or more advanced models like vicunna or alpaca. However, the comment does not explicitly mention which part of the paper discusses the evaluative framework, making it weakly grounded. The comment is specific in detailing the limitations and potential areas for broader applicability, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the evaluative framework is limited in scope, restricting it to only three Question-Answering tasks and two language models. The reviewer expresses reservations about the method's broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. While the comment provides a logical reasoning for the limitation, it lacks specific examples or references to support the claim fully. The suggestion to consider other tasks or models is a reasonable point, but without detailed evidence or examples, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the scope of the evaluative framework, noting that it is restricted to only three Question-Answering tasks and two language models. This observation raises concerns about the method's broader applicability and suggests that it may not generalize to other reasoning or generation tasks or more advanced models like vicunna or alpaca. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this limitation or expand the scope of their evaluation. The feedback is somewhat helpful as it points out a potential weakness, but it could be more beneficial with actionable advice or examples. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly states that the experiments are insufficient and suggests that more empirical experiments or toy experiments should be conducted to demonstrate the validity of the model relaxations and the consistency of the theoretical analysis with empirical results. It also mentions citing the result in Kaplan et al. 2020. This feedback provides a clear and direct action for the authors to take, specifying the need for additional experiments and referencing a relevant work. The authors know exactly what changes to make to improve their draft, making this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the experiments are insufficient and recommends conducting more empirical or toy experiments to validate the model relaxations and the consistency of the theoretical analysis with empirical results. However, it does not specify which part of the paper this critique pertains to, such as specific sections or experiments that need improvement. The authors might infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting additional experiments but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the experiments are insufficient and suggests that more empirical or toy experiments are needed to validate the model relaxations and the consistency of the theoretical analysis with empirical results. The comment references Kaplan et al. 2020, which provides some support for the claim. However, the comment lacks specific examples or detailed reasoning about why the current experiments are inadequate or how the additional experiments would address these issues. This makes the claim somewhat verifiable, as it provides a direction for improvement but lacks comprehensive justification or examples.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant limitation in the experimental section, noting that the experiments are insufficient to fully validate the model relaxations and the consistency of the theoretical analysis with empirical results. It suggests that additional empirical or toy experiments should be conducted to address this gap. The comment also references Kaplan et al. 2020, providing a specific example of work that could be considered for comparison or citation. This feedback is clear and actionable, offering a concrete direction for the authors to enhance the robustness and credibility of their experimental validation. However, it could be more helpful if it provided specific suggestions on how to design these additional experiments or what aspects to focus on. Overall, the comment is mostly helpful as it effectively guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests a specific approach to present the performance of the method as a function of the distance of initialization to the ground-truth. It provides a clear and concrete action by specifying how to vary the distance and report the performance. The comment also includes an expectation about how the mean error and variance might change with decreasing initialization quality. This feedback is explicit and provides detailed guidance on how to implement the suggested analysis, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests a specific approach to present the performance of the method as a function of the distance of initialization to the ground-truth. It provides a clear and detailed suggestion on how to vary the distance and report the performance, including the expected changes in mean error and variance. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a method for improvement. This aligns with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests a method to present the performance of the method as a function of the distance of initialization to the ground-truth. It provides a logical reasoning by suggesting that the mean error and variance should increase as the quality of initialization decreases. However, the comment lacks specific examples or references to support this claim, making it somewhat verifiable. The authors would need to further explore and validate this suggestion themselves, which limits the verifiability of the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the presentation of the paper's results. It suggests presenting the performance as a function of the distance of initialization to the ground-truth, which could offer valuable insights into the sensitivity of the method to initialization. The comment also includes a logical reasoning for why this approach might be beneficial, suggesting that the mean error and variance should increase as the quality of initialization decreases. This feedback is clear and constructive, guiding the authors on how to enhance their analysis and potentially improve the understanding of their method's robustness. However, it could be more helpful if it included specific examples or further details on how to implement this suggestion. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be expanded with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the absolute value operation in the definition of the Frobenius norm in line 77 is not necessary because tensor entries are real numbers. This feedback is explicit and provides a clear action for the authors to remove the absolute value operation. The suggestion is concrete, as it specifies exactly what needs to be changed to improve the draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 77,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the removal of the absolute value operation in the definition of the Frobenius norm. This provides clear guidance on what needs to be revised. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the absolute value operation in the definition of the Frobenius norm is unnecessary because tensor entries are real numbers. This claim is based on a logical reasoning that real numbers do not require absolute value operations for their definition. However, the comment does not provide specific references or examples to support this assertion, making it somewhat verifiable. The authors would need to infer the reasoning themselves, which limits the clarity and support provided. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a minor issue in the paper regarding the use of the absolute value operation in the definition of the Frobenius norm. It points out that since tensor entries are real numbers, the absolute value operation is not necessary. This feedback is clear and actionable, as it provides a specific correction that the authors can make to improve the accuracy and clarity of their mathematical formulation. By addressing this point, the authors can enhance the precision of their work. However, the comment could be more helpful if it explained why this omission is significant or how it affects the overall understanding of the paper. Overall, the comment is mostly helpful, as it provides a clear and actionable suggestion for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. This provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is specific and actionable, giving the authors a concrete step to enhance their evaluation methodology. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests using DinoV2 Frechet Distances in addition to the widely used FID metric for comparisons. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or table where these comparisons are discussed. The authors can infer that it relates to the evaluation or results section, but this inference is not as direct as it could be. The suggestion is specific in terms of what alternative metric should be used, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that while FIDs are still widely used for evaluation, there are clear flaws associated with them and the Inception network. It suggests using DinoV2 Frechet Distances as an alternative. The comment provides a logical reasoning by referencing the potential flaws of FIDs and the Inception network, and it suggests a specific alternative metric. However, it lacks specific examples or references to substantiate the claims about the flaws of FIDs and the Inception network. This makes the claim somewhat verifiable, as the authors would need to further explore the referenced work to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the evaluation methodology by recommending the use of DinoV2 Frechet Distances in addition to the widely used FID metric. This feedback is clear and offers a concrete step for the authors to enhance the robustness and comprehensiveness of their evaluation. By addressing the potential flaws associated with FIDs and the Inception network, the comment guides the authors towards a more reliable and comprehensive evaluation approach. However, it could be more helpful if it explained why these flaws exist or provided more context on the advantages of using DinoV2 Frechet Distances. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that Figure 6C implies negative rates, which is not accurate, and recommends using a second y-axis or another visualization for better accuracy. This feedback provides a clear and explicit action for the authors to take, specifying the issue with the current figure and offering a concrete solution to improve its accuracy. The suggestion is direct and leaves no ambiguity about how to address the issue, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"figure 6C,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely that it implies negative rates, which is not physically accurate. The comment provides a concrete suggestion for improvement by recommending the use of a second y-axis or another visualization for better accuracy. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that Figure 6C implies negative rates, which is not physically accurate. The reviewer suggests using a second y-axis or another visualization for better accuracy. While the comment identifies a potential issue with the figure, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion for improvement is logical, but the absence of concrete evidence or references makes the claim somewhat verifiable. Authors may need to infer the specific issue with the figure's representation of rates. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Figure 6C, noting that it implies negative rates, which is not physically accurate. It provides a clear and actionable suggestion to use a second y-axis or another visualization to better represent the data. This feedback is precise and offers a concrete solution to improve the clarity and accuracy of the figure, making it highly helpful for the authors to enhance their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment questions a statement in the supplemental section D.4, suggesting that the claim about smaller architectures being necessary for the LM compared to the GAN model is questionable. The reviewer provides an example from Zaremba et al. (2014) to challenge the statement. Additionally, the reviewer asks whether dropout is applied to the hidden states, implying that this information is missing or unclear in the paper. The comment is explicit in identifying a specific issue and suggests that the authors provide additional details or clarification. However, it does not offer concrete steps on how to address the issue, such as recommending specific changes or additional experiments. Therefore, the comment is somewhat actionable, as it identifies an area for improvement but lacks detailed guidance on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"supplemental section D.4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the statement about smaller architectures being necessary for the LM compared to the GAN model, providing an example from Zaremba et al. (2014) to challenge the claim. Additionally, the comment asks whether dropout is applied to the hidden states, suggesting a potential issue with the regularization of the baseline models. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions a statement in the supplemental section D.4, suggesting that the claim about smaller architectures being necessary for the LM compared to the GAN model is questionable. The reviewer provides a counterexample from Zaremba et al. (2014) to challenge the statement, which adds some level of verifiability. However, the comment does not explicitly reference Zaremba et al. (2014) or provide detailed reasoning about the implications of this counterexample. Additionally, the reviewer raises a question about whether dropout is applied to the hidden states, which could further clarify the issue. While the comment is mostly verifiable due to the counterexample, it could be strengthened with more detailed references or explanations. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment questions a statement in the supplemental section D.4, suggesting that the claim about smaller architectures being necessary for the LM compared to the GAN model is questionable. It provides a counterexample from Zaremba et al. (2014) to challenge the statement, which is a valuable insight for the authors to consider. Additionally, the comment raises a specific question about whether dropout is applied to the hidden states, prompting the authors to clarify their methodology. This feedback is clear and actionable, as it identifies a potential issue with the paper's claims and encourages the authors to provide additional details or corrections. However, it could be more helpful if it offered suggestions on how to address the issue or provided more context on the implications of the counterexample. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the clarity and accuracy of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point makes a statement about the contribution of multilingual chain-of-thought being incremental compared to the villa chain-of-thought. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the authors' work, nor are there suggestions for improvement or further exploration. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment makes a claim about the contribution of multilingual chain-of-thought being incremental compared to the villa chain-of-thought. However, it does not specify which part of the paper this comparison is based on, nor does it provide details on what aspects of the contribution are considered incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment makes a claim that the contribution of multilingual chain-of-thought is incremental compared to the villa chain-of-thought. However, it does not provide any context, evidence, or reasoning to support this claim, nor does it offer any suggestions for improvement or further exploration. Without additional information or actionable feedback, the authors are left without guidance on how to address this observation or enhance their work. As a result, the comment is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a concern regarding the comparability of G-effect values across different unlearning objectives and approaches, given that the study examines each learning objective in isolation. However, it does not provide explicit guidance or suggestions on how the authors might address this concern or improve the comparability of their results. The comment lacks actionable details, such as recommending specific analyses or comparisons that could be made to address the issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the concern regarding the comparability of G-effect values across various unlearning objectives and approaches. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the comparability of G-effect values across different unlearning objectives and approaches, given that the study examines each learning objective in isolation. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered borderline verifiable, as it highlights a potential issue but lacks sufficient justification or evidence to fully substantiate the claim.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the study's methodology, specifically the concern regarding the comparability of G-effect values across different unlearning objectives and approaches. It highlights that the paper examines each learning objective in isolation, which may affect the validity of comparisons. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the comparability of their results. While it points out a critical area for consideration, the feedback lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the consistency of the advantage of UNIFORM over other procedures, noting that the tables show UNIFORM does not always offer a clear advantage, particularly in the 1-shot setting. The reviewer asks if the authors have a theory explaining why the method is not as effective in the 1-shot setting. While the comment implies that the authors should provide a theoretical explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the tables and the 1-shot setting, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the advantage of UNIFORM over other procedures and asks for a theoretical explanation for the method's ineffectiveness in the 1-shot setting. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables showing that UNIFORM does not always offer a clear advantage, especially in the 1-shot setting. The reviewer asks for a theory explaining why the method is not as effective in the 1-shot setting. While the comment provides some evidence and a question, it lacks detailed reasoning or specific examples to fully substantiate the claim. The request for a theory is a suggestion for improvement, but without further elaboration, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the consistency of the advantage of UNIFORM over other procedures, noting that the results in the tables do not always show a clear advantage, particularly in the 1-shot setting. It asks the authors to provide a theory explaining why the method is not as effective in this setting. This feedback is clear and actionable, as it prompts the authors to investigate and explain the observed inconsistencies, which could lead to a deeper understanding of their method's limitations. However, the comment could be more helpful if it provided suggestions on how to approach this theoretical explanation or offered insights into potential factors contributing to the observed results. Overall, the comment is mostly helpful as it directs the authors to a critical area for improvement and encourages them to explore the underlying reasons for the observed inconsistencies.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors consider the reason why information value is a stronger predictor for dialogue, specifically in the context of complementarity discussed on page 7 or in the discussion on page 8. It implies that the authors should explore existing linguistic theories that could explain this phenomenon and consider adding such theories to strengthen their paper. While the comment does not explicitly instruct the authors to do so, the action is clear and concrete, as it specifies the need to investigate and potentially incorporate existing linguistic theories. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections of the paper, namely \\\"Complementarity in page 7\\\" and \\\"discussion in page 8,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests exploring existing linguistic theories that could explain the reason why information value is a stronger predictor for dialogue. This provides clear guidance on what the authors need to consider or address in their work. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should consider the reason why information value is a stronger predictor for dialogue, specifically in the context of complementarity discussed on page 7 or in the discussion on page 8. The comment implies that there might be existing linguistic theories that could explain this phenomenon and suggests that incorporating such theories could strengthen the paper. However, the comment does not provide specific references or examples of existing theories, making it somewhat verifiable. The authors would need to explore and potentially reference relevant literature to fully address the suggestion, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential area for improvement by questioning the authors' consideration of why information value is a stronger predictor for dialogue, specifically in the context of complementarity discussed on page 7 or in the discussion on page 8. It suggests that the authors explore existing linguistic theories that could explain this phenomenon and consider adding such theories to strengthen their paper. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their work by connecting their findings to established theories in linguistics. However, the comment could be more helpful if it provided examples of relevant theories or suggested how to integrate them into the paper. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights an inconsistency in the paper, noting that the term \\\"T_a(t)\\\" is used in Section 3.1 but is only defined in Section 4. This implies that the authors should ensure that all terms and notations are defined before they are used in the paper. While the comment does not explicitly instruct the authors to redefine the term earlier, the action is clear and concrete, as it points out a specific issue that needs to be addressed. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"T_a(t)\\\" and its usage in Section 3.1, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the inconsistency in the definition of \\\"T_a(t)\\\" being used before it is defined, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment points out an inconsistency in the paper, noting that the term \\\"T_a(t)\\\" is used in Section 3.1 but is only defined in Section 4. This is a factual observation about the structure and content of the paper, and it does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The comment identifies a specific issue with the paper, noting that the term \\\"T_a(t)\\\" is used in Section 3.1 but is only defined in Section 4. This is a clear and actionable piece of feedback that can help the authors improve the clarity and consistency of their paper. By pointing out this inconsistency, the reviewer provides the authors with a concrete step to take, ensuring that all terms and notations are defined before they are used. However, the comment could be more helpful if it suggested how to address this issue, such as recommending a specific way to reorganize the sections or provide a more detailed explanation in Section 3.1. Overall, the comment is mostly helpful as it highlights a critical issue that needs attention, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the clarity of the empirical analysis in Figure 3 and asks for additional clarification on how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. It also inquires about the effectiveness of these adjustments in enhancing the model's performance. Additionally, the reviewer points out issues with the spacing in Equations (9) and (10). The comment provides explicit actions for the authors to take, such as clarifying the adjustments and explaining their effectiveness, as well as addressing the spacing issue. These instructions are concrete and specific, giving the authors clear guidance on how to improve their draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a specific concern about the clarity of the empirical analysis in Figure 3 and asks for additional clarification on how adjustments to the amplitudes of the input series and forecasting target affect model prediction accuracy. Additionally, it questions the effectiveness of these adjustments in enhancing the model's performance. The comment also points out issues with the spacing in Equations (9) and (10). Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the clarity of the empirical analysis in Figure 3, specifically questioning how adjustments to the amplitudes of the input series and forecasting target, based on the Frequency Stability score, affect model prediction accuracy. The reviewer requests additional clarification on the effectiveness of these adjustments. Additionally, the comment points out issues with the spacing in Equations (9) and (10). While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claims. The reference to Liu et al. (2022) provides some context, but the comment could be strengthened with more detailed explanations or examples. Therefore, the claim is somewhat verifiable, as it provides a basis for the critique but requires further elaboration to be fully actionable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the empirical analysis in Figure 3, questioning its clarity and the effectiveness of adjustments to the amplitudes of the input series and forecasting target based on the Frequency Stability score. It requests additional clarification on how these adjustments affect model prediction accuracy and why they are effective. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and potentially improve the clarity of their analysis. Additionally, the comment points out issues with the spacing in Equations (9) and (10), which is another actionable suggestion for improvement. The inclusion of a reference to Liu et al. (2022) provides a context for the discussion, although it could be more integrated into the feedback. Overall, the comment is mostly helpful as it identifies key areas for improvement and provides specific guidance on how to enhance the draft, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly suggests that the authors should compare their work with CoCoOp, a recent related work, in the experiments. While it mentions that CoCoOp is a CVPR'22 work published after the NeurIPS deadline, it still implies that the authors should include it in their comparisons. The action is clear and concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the authors should compare their work with CoCoOp, a recent related work, in the experiments. It mentions that CoCoOp is a CVPR'22 work published after the NeurIPS deadline, which adds context to the suggestion. However, the comment does not specify which part of the paper should include this comparison, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed\\u2014comparing with CoCoOp\\u2014but lacks detailed guidance on how to incorporate this comparison into the experiments. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should compare their work with CoCoOp, a recent related work, in the experiments. The comment provides a logical reasoning by mentioning that CoCoOp is a CVPR'22 work published after the NeurIPS deadline, implying that it is relevant and necessary for comparison. However, the comment lacks specific details or references to substantiate the claim fully. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is classified as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the experimental comparisons by pointing out that the recent related work CoCoOp is not included in the experiments. It provides a clear rationale for why this comparison is necessary, noting that CoCoOp is a CVPR'22 work published after the NeurIPS deadline, despite being an extended version of CoOp. This feedback is actionable and constructive, as it guides the authors to enhance their experimental section by including a comparison with CoCoOp. However, the comment could be more helpful if it offered additional suggestions on how to integrate this comparison into the existing framework or highlighted specific aspects of CoCoOp that are relevant to the study. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that Figure 1 could be improved to better illustrate the processing pipeline, specifically mentioning the need to show prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. While the comment provides a clear direction for improvement, it does not specify how to implement these changes or what specific elements should be included in the figure. The action is explicit but somewhat vague, as the authors know they need to enhance the figure but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Fig. 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on what needs to be improved regarding the figure, such as showing the processing pipeline, prompt generation, manual check, demonstration selection, ground truth scores, and automatic scoring. This level of detail provides clear guidance on how to enhance the figure. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that Figure 1 could be improved to better illustrate the processing pipeline, including specific elements like prompt generation, manual check, demonstration selection, and automatic scoring. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific elements are important or how they would enhance the figure. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on improving Figure 1 by suggesting that it could be enhanced to better illustrate the processing pipeline. It lists several key elements that should be included, such as prompt generation, manual check, demonstration selection with ground truth scores, and automatic scoring. This detailed guidance helps the authors understand exactly what aspects of the figure need improvement and how to present the information more effectively. By offering clear and constructive suggestions, the comment empowers the authors to make significant improvements to their draft, making it highly helpful. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to remove abbreviations like \\\"MoCo\\\" from the section header, as a reader might not know what it means. This is a clear and direct action that the authors can take to improve the clarity and accessibility of their paper. The comment provides specific guidance on how to implement the change, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"(136),\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is the presence of abbreviations like \\\"MoCo\\\" in the section header, which might not be familiar to readers. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that abbreviations like \\\"MoCo\\\" should not appear in the section header because a reader might not know what it means. This is a straightforward observation and does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual, making \\\"No\\\" the appropriate label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the clarity and accessibility of the paper. By recommending that abbreviations like \\\"MoCo\\\" should not appear in the section header, the reviewer is helping the authors ensure that readers unfamiliar with the abbreviation can understand the content without confusion. This feedback is clear and directly addresses a potential issue with the presentation of information, making it highly helpful for the authors to enhance their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment states that the technical contribution is unclear and that most of the analysis is quite standard. However, it does not provide any specific guidance or suggestions on how the authors could clarify the technical contribution or improve the analysis. The comment lacks actionable details, such as recommending ways to enhance the technical contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to address the feedback. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the technical contribution of the paper is unclear and that most of the analysis is standard. However, it does not specify which parts of the paper are being referred to or provide details on what aspects of the analysis are considered standard. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that \\\"the technical contribution is unclear\\\" and that \\\"most of the analysis is quite standard.\\\" However, it does not provide any specific examples, references, or detailed reasoning to support these claims. Without additional context or justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out a lack of clarity in the technical contribution and suggests that most of the analysis is standard. However, it does not provide specific details or examples to help the authors understand what aspects of their work are unclear or how they might improve the technical contribution. Without actionable feedback or suggestions, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach and implies that more substantial evidence or arguments are needed to establish this as a significant contribution to the field. However, the comment does not provide specific guidance on what kind of evidence or arguments are needed, nor does it offer concrete suggestions on how to strengthen the contribution. The action is implicit and vague, leaving the authors uncertain about how to address the feedback effectively. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach and implies the need for more substantial evidence or arguments to establish this as a significant contribution. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what kind of evidence or arguments are needed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the paper's primary contribution is an incremental advancement in efficiency over the TACTiS approach and suggests that more substantial evidence or arguments are needed to establish this as a significant contribution. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without such supporting information, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a potential weakness in the paper, suggesting that the primary contribution is an incremental advancement in efficiency over the TACTiS approach. It implies that more substantial evidence or arguments are needed to establish this contribution as significant. However, the comment lacks specificity and does not provide actionable guidance or suggestions on how the authors might strengthen their contribution or what kind of evidence or arguments are necessary. Without detailed feedback or examples, the authors are left with a general sense of the issue but without clear direction on how to address it. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the S2D structure, specifically questioning why the number of parameters does not change despite the kernel height/width remaining the same, which would typically lead to an increase in depth and parameters. The reviewer acknowledges the potential for efficiency improvement but emphasizes the need for more details regarding parameters. While the comment implies that the authors should provide additional information or clarification on the parameter count, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add more details about the parameter count. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"S2D structure,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about why the number of parameters does not change despite the kernel height/width remaining the same, which would typically lead to an increase in depth and parameters. The comment further specifies the need for more details regarding parameters, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the claim that the number of parameters does not change in the S2D structure, suggesting that if the kernel height/width remains the same, the depth would increase, resulting in more parameters. The reviewer acknowledges the potential for efficiency improvement but emphasizes the need for more details regarding parameters. This comment is mostly verifiable as it provides a logical reasoning for the claim, but it lacks specific examples or references to support the assertion about parameter changes. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the S2D structure, questioning why the number of parameters does not change despite the kernel height/width remaining the same. It acknowledges the potential for efficiency improvement but emphasizes the need for more details regarding parameters. This feedback is clear and actionable, as it prompts the authors to provide additional information or clarification on the parameter count, which could enhance the understanding and robustness of their work. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of what additional details might be relevant. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful improvement in their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the presentation of the simulation study is not effective and specifically notes the lack of discussion on why the GPC (benchmark) performs better than BPC (the authors' method). It suggests that the authors should reiterate the reason for this performance difference, which is attributed to the use of bandit feedback rather than information about the cost function's form. While the comment identifies a specific area for improvement, it does not provide detailed guidance on how to address the issue or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the presentation. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"simulation study\\\" and the comparison between \\\"GPC (benchmark)\\\" and \\\"BPC (their method),\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of discussion on why GPC performs better than BPC and the need to reiterate that this is due to bandit feedback rather than information about the cost function's form. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the presentation of the simulation study is not effective and specifically notes the lack of discussion on why the GPC (benchmark) performs better than BPC (the authors' method). The reviewer suggests that this difference is due to the use of bandit feedback rather than information about the cost function's form. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion about the performance difference. This makes the claim somewhat verifiable, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the presentation of the simulation study, noting that the authors do not adequately explain why the GPC (benchmark) performs better than BPC (their method). It suggests that the authors should clarify that this performance difference is due to the use of bandit feedback rather than information about the cost function's form. This feedback is clear and actionable, as it provides a specific area for improvement and offers a rationale for the observed performance difference. By addressing this point, the authors can enhance the clarity and depth of their presentation. However, the comment could be more helpful if it included suggestions on how to effectively communicate this distinction. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors quantify and clarify the claim about ReLU's performance in deep or convolutional networks. It also references the AlexNet paper, which used ReLU in a deep and convolutional context, to provide context. While the comment implies that the authors should provide a more detailed analysis or evidence to support their claim, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to quantify or clarify the claim. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests quantifying and clarifying the claim about ReLU's performance in deep or convolutional networks. It references the AlexNet paper, which used ReLU in a deep and convolutional context, to provide context. However, the comment does not specify which part of the paper this claim is made, making it weakly grounded. The suggestion to quantify and clarify the claim is specific, as it provides a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the claim \\\"ReLU does not work very well in very deep or in convolutional networks\\\" might be inaccurate, as ReLUs were used in the AlexNet paper, which was considered deep and convolutional. This claim is somewhat verifiable as it provides a specific reference to the AlexNet paper, which could be used to challenge the claim. However, the comment lacks detailed reasoning or additional evidence to fully substantiate the critique, such as specific examples or comparisons. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment suggests that the authors quantify and clarify the claim about ReLU's performance in deep or convolutional networks. It provides a specific reference to the AlexNet paper, which used ReLU in a deep and convolutional context, to challenge the claim. This feedback is somewhat helpful as it identifies a potential inconsistency in the paper's claims and provides a concrete example to consider. However, the comment could be more helpful if it offered suggestions on how to quantify or clarify the claim, such as proposing specific metrics or analyses to support the argument. Overall, the comment provides some direction for improvement but lacks detailed guidance, making it somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the reported perplexities in Figure 1, noting that they appear high and contradict better BLEU scores. The reviewer asks how the perplexity was calculated, implying that the authors should clarify this aspect. While the comment does not explicitly instruct the authors to provide this information, the action is clear and concrete, as it points to a specific area needing clarification. The authors can infer that they need to explain their calculation of perplexity to address the reviewer's concern. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reported perplexities, which are over 30, and contrasts them with the better BLEU scores observed by the reviewer. The comment further asks for clarification on how the perplexity was calculated, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the reported perplexities in Figure 1, noting that they appear high and contradict better BLEU scores. The reviewer questions the calculation of perplexity, suggesting that the authors should clarify this aspect. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that high perplexity contradicts better BLEU scores. The reasoning is somewhat verifiable, as it points out a discrepancy that requires further explanation, but it does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the reported perplexities in Figure 1, noting that they appear high and contradict better BLEU scores. This observation is valuable as it highlights a discrepancy that the authors should address to improve the clarity and credibility of their results. The comment also prompts the authors to clarify how perplexity was calculated, which is a specific and actionable suggestion for improvement. By addressing these points, the authors can enhance the transparency and validity of their findings. However, the comment could be more helpful if it provided additional guidance on how to resolve the discrepancy or suggested alternative metrics for evaluation. Overall, the feedback is mostly helpful as it directs the authors to a critical area needing clarification and improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the paper should provide more explanations on the consistency between training and inference, particularly in the context of the smoothness of neural models. While the comment implies that additional explanation is needed, it does not explicitly instruct the authors to add this information or specify where in the paper this explanation should be included. The action is implicit and somewhat vague, as the authors need to infer that they should expand on this topic but may not be entirely sure of the exact content or structure of the additional explanation. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (Line 95-97 and Line 308-310), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that more explanations are needed regarding the consistency between training and inference due to the smoothness of neural models. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the paper should provide more explanations on the consistency between training and inference due to the smoothness of neural models. However, the comment does not provide specific examples or detailed reasoning to support why this explanation is necessary or how it would enhance the paper. Without such justification, the claim remains vague and lacks sufficient evidence, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is considered borderline verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area where the paper could be improved by suggesting that more explanations are needed regarding the consistency between training and inference, particularly in the context of the smoothness of neural models. This feedback is actionable as it provides a clear direction for the authors to enhance their draft by adding additional explanations or examples. However, the comment could be more helpful if it included specific suggestions on how to present these explanations or examples. Overall, the comment is mostly helpful as it highlights a critical area for improvement and provides a general direction for enhancement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should include some failure cases and related discussion in their paper. While the action is explicit, it lacks concrete details on what specific failure cases should be discussed or how the discussion should be structured. The authors are given a clear direction to include failure cases but are left without specific guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests including some failure cases and related discussion, which is a specific suggestion for improvement. However, it does not specify which part of the paper should include this discussion or where the failure cases should be discussed. This lack of explicit reference to a specific section or part of the paper makes it weakly grounded. The comment is specific in its suggestion to include failure cases and related discussion, but without clear grounding, the authors may struggle to identify where to make these improvements. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests including some failure cases and related discussion in the paper. However, it does not provide any specific examples, reasoning, or evidence to support why this would be beneficial or necessary. The comment lacks detailed justification or context, making it difficult for the authors to understand the importance of this suggestion or how it could improve the paper. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests including some failure cases and related discussion in the paper. This feedback is somewhat helpful as it identifies a potential area for improvement that could enhance the comprehensiveness and depth of the paper. However, the comment lacks specificity and does not provide detailed guidance on what types of failure cases should be discussed or how the discussion should be structured. Without this level of detail, the authors may find it challenging to effectively incorporate the suggested improvements. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the introduction of \\\\(\\\\epsilon\\\\) should be clarified when discussing equation (11), as it is not used in equation (10). This feedback provides a clear and explicit action for the authors to take, which is to introduce \\\\(\\\\epsilon\\\\) when discussing equation (11). The comment is specific and concrete, giving the authors a direct instruction on how to improve the clarity of their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 4.1\\\" and \\\"equation (10)\\\" and \\\"equation (11),\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the introduction of \\\\(\\\\epsilon\\\\) when discussing equation (11). This provides clear guidance on how to improve the clarity of the paper. Therefore, this comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the introduction of \\\\(\\\\epsilon\\\\) should be clarified when discussing equation (11), as it is not used in equation (10). This claim is somewhat verifiable as it points out a potential inconsistency or lack of clarity in the presentation of the equations. However, the comment does not provide detailed reasoning or examples to fully substantiate why introducing \\\\(\\\\epsilon\\\\) at this point would improve clarity. The authors might need to infer the reasoning behind this suggestion, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out that the introduction of \\\\(\\\\epsilon\\\\) is not consistent between equation (10) and equation (11), and suggests that it might be clearer to introduce \\\\(\\\\epsilon\\\\) when discussing equation (11). This feedback is precise and directly addresses a potential issue in the manuscript, offering the authors a clear path to enhance the readability and coherence of their work. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to address the issue of computational complexity by adding the upper bounds of counting homomorphomorphisms and elaborating on empirical runtimes. This feedback provides a clear and concrete action for the authors to take, specifying exactly what needs to be added to improve the paper. The comment is direct and offers specific guidance on how to enhance the draft, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions line 145, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a detailed discussion on the computational complexity of counting homomorphisms and the suggestion to add upper bounds and elaborate on empirical runtimes. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the authors do not adequately discuss the computational complexity of counting homomorphisms, providing a brief statement as evidence. The reviewer suggests that adding upper bounds and elaborating on empirical runtimes would be beneficial. While the comment identifies a gap in the discussion, it lacks detailed reasoning or references to support the claim fully. The suggestion for improvement is logical, but the absence of specific examples or evidence makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area where the paper could be improved, namely the discussion of computational complexity related to counting homomorphisms. It acknowledges that the authors make brief statements about the efficiency of computing homomorphism counts but suggests that adding explicit upper bounds and elaborating on empirical runtimes would be beneficial. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their draft. By addressing this point, the authors can improve the comprehensiveness and depth of their analysis, making the comment highly helpful. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides specific corrections to the text, such as changing \\\"f\\\" to \\\"g\\\" in line 108 and removing an extra period in line 115. These are explicit actions that the authors can directly implement. Additionally, the comment raises a question about the convergence of networks in the baseline MCL with deep learning, suggesting that cutting learners early might affect ensemble performance. While this question implies an action, it is not explicitly stated, making it somewhat vague. Overall, the comment is mostly actionable due to the explicit corrections and the clear question prompting further consideration.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (line 108 and line 115), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the incorrect use of \\\"f\\\" instead of \\\"g\\\" and the extra period in the sentence. Additionally, it raises a question about the convergence of networks in the baseline MCL with deep learning, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual corrections and a question. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by correcting a typographical error in the text and questioning the methodology regarding the convergence of networks in the baseline MCL with deep learning. The correction of the typo is straightforward and easily implementable, which is helpful for the authors. The question about ensuring convergence is insightful, prompting the authors to consider the impact of early learner cutting on ensemble performance. However, the comment could be more helpful if it offered suggestions on how to address the convergence issue or provided additional context on the implications of early cutting. Overall, the feedback is mostly helpful as it identifies specific areas for improvement and raises an important question, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises specific questions about the proof of Theorem A.3, questioning the use of two indices for the input x and suggesting a correction to the equation involving the sum of squared weights. The reviewer explicitly asks for clarification on these points, providing concrete guidance on what needs to be addressed. The feedback is clear and specific, leaving no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Theorem A.3 proof,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two distinct questions: one about the use of two indices for the input x and another about the equation involving the sum of squared weights. These questions provide clear guidance on what needs to be clarified or corrected in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the proof of Theorem A.3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by questioning the proof of Theorem A.3, particularly regarding the use of two indices for the input x and suggesting a correction to the equation involving the sum of squared weights. This detailed critique helps the authors identify and address potential inaccuracies or ambiguities in their theoretical framework, which is crucial for the validity and clarity of their work. By pinpointing these issues, the comment empowers the authors to make precise improvements to their draft, making it highly helpful. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises concerns about the use of terms like \\\"somewhat\\\" and \\\"good generative ability\\\" in sections 4.3 and 4.4, questioning the reliability of the results. It specifically asks about the percentage of correct entities and relationships when no ground truth is available. While the comment highlights a potential issue, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit, as the authors need to infer that they should clarify or provide additional information about the reliability of their results. However, the comment lacks concrete steps or suggestions on how to achieve this, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions sections 4.3 and 4.4, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the reliability of the results, particularly regarding the use of terms like \\\"somewhat\\\" and \\\"good generative ability.\\\" The comment further elaborates on the concern about the accuracy of the results when relationships and entities are replaced, asking for clarification on the percentage of correct entities and relationships when no ground truth is available. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the reliability of the results in sections 4.3 and 4.4, specifically questioning the accuracy of the generated logical forms when using beam search. The reviewer provides a specific example, noting that only 77% of the results contain the ground truth logical forms. This observation is a factual statement and does not express an opinion or claim that requires verification. The comment is a request for clarification and does not contain subjective opinions or judgments. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a valid concern about the reliability of the results presented in sections 4.3 and 4.4. It questions the accuracy of the generated logical forms, particularly when using beam search, and highlights the issue of only 77% of the results containing the ground truth logical forms. The comment also inquires about the accuracy of entities and relationships when no ground truth is available, prompting the authors to clarify how they ensure the correctness of the plugged-in entities and relationships. This feedback is clear and actionable, as it identifies a specific area of concern and encourages the authors to provide additional information or clarification to address the issue. However, the comment could be more helpful if it offered suggestions on how to improve the evaluation or analysis of the results. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point acknowledges the reliance of FedPCL on the selection of different pre-trained models and its impact on applications. It also mentions that the authors have developed a lightweight federated learning framework to reduce computation and communication costs and integrated pre-trained models for federated aggregation. However, the comment does not provide explicit guidance or suggestions for improvement. It lacks specific actions or concrete details on how the authors might address the limitations or enhance their framework. As a result, the authors are left without clear direction on how to apply this feedback to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment discusses the performance of FedPCL and its reliance on the selection of different pre-trained models, as well as its sensitivity to these models. It references Table 4 to support the claim about model accuracy sensitivity. However, it does not specify which part of the paper this discussion is based on, making it weakly grounded. The comment is specific in detailing the issue of reliance on pre-trained models and the sensitivity of model accuracy, but it lacks explicit references to sections or figures. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the performance of FedPCL is heavily dependent on the selection of different pre-trained models, which limits its applicability to broader areas. It supports this claim by referencing Table 4, which shows the sensitivity of model accuracy to the choice of pre-trained models. The comment also acknowledges the authors' efforts in addressing this limitation by developing a lightweight federated learning framework and integrating pre-trained models for federated aggregation. While the comment provides some evidence and reasoning, it lacks detailed examples or specific references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the reliance of FedPCL on the selection of different pre-trained models, which limits its applicability to a broader range of areas. It also notes that the model accuracy is sensitive to the choice of pre-trained models, as shown in Table 4. The comment praises the authors' efforts in addressing this limitation by developing a lightweight federated learning framework to reduce computation and communication costs and integrating pre-trained models for federated aggregation. However, the comment lacks specific suggestions or actionable steps for the authors to further improve their work. While it provides a positive assessment of the authors' contributions, it does not offer detailed guidance on how to enhance the framework or address the identified limitations. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and actionable feedback.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete suggestions for improving the organization and clarity of the paper. It advises the authors to separate the description of the two types of attention for deep VAEs into a dedicated section, which would help in better structuring the content. Additionally, it suggests that tricks like normalization or feature scaling should be referenced in a separate section. These suggestions are clear and provide specific guidance on how to enhance the draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections, such as sections 2.3 and 2.4, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the scattered description of the layer-wise attention mechanism and the suggestion to separate the description of the two types of attention for deep VAEs. Additionally, it suggests referencing tricks like normalization or feature scaling in a separate section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the paper could be improved by separating the description of the two types of attention for deep VAEs into a dedicated section, and by referencing tricks like normalization or feature scaling in a separate section. While the comment provides a logical suggestion for improving the organization and clarity of the paper, it lacks specific examples or references to support the claim that this separation would enhance the paper. The suggestion is based on common practices in academic writing but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a reasonable suggestion but lacks comprehensive justification.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on how to improve the organization and clarity of the paper. It suggests separating the description of the two types of attention for deep VAEs into a dedicated section, which would help in better structuring the content. Additionally, it recommends referencing tricks like normalization or feature scaling in a separate section. These suggestions are clear and provide the authors with concrete steps to enhance the readability and coherence of their draft. While the comment could be more helpful if it included examples or further details on how to implement these changes, it still offers valuable guidance for improving the draft. Therefore, the comment is mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that in section 4, \\\"X\\\" should be a multiset instead of a set, as this would allow the histogram to accurately represent graphs with repeated vertex or edge labels. The comment provides a clear and explicit action for the authors to take, specifying that they should consider using a multiset and explaining why this change is necessary. The suggestion is concrete, as it outlines the specific change needed to improve the representation of the data. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the suggestion that \\\"X\\\" should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. This provides clear guidance on what aspect of the section needs revision. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that in section 4, \\\"X\\\" should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. The reviewer provides a logical reasoning by explaining that including the multiplicities of labels is necessary for the histogram to represent such graphs. This explanation is clear and provides a solid basis for the claim, making it mostly verifiable. However, the comment could be strengthened by referencing specific examples or external sources that support this reasoning. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion regarding the content of section 4. It points out that the term \\\"X\\\" should be a multiset instead of a set to accurately represent graphs with repeated vertex or edge labels. This feedback is clear and offers a concrete way for the authors to improve the accuracy and representation of their data in the paper. By addressing this point, the authors can enhance the clarity and correctness of their methodology. The comment is highly helpful as it directly guides the authors on how to refine their draft, making it a valuable piece of feedback.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \\\"questions of all the wrong demonstrations fall into the same frequent-error cluster\\\" and asks for clarification on the selection criteria in section 4.2. While the comment provides explicit actions for the authors to take, such as drawing a table and clarifying assumptions, it lacks concrete guidance on how to implement these suggestions. The authors are given a general direction but without detailed instructions on how to execute the improvements. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the need for a table to compare different CoT prompting methods across different dimensions, allowing the authors to identify the specific section where improvements are suggested. It also raises specific questions about the assumption regarding the frequent-error cluster and the selection criteria in section 4.2, providing clear guidance on what needs to be addressed. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the writing could be improved by drawing a table to compare different CoT prompting methods across different dimensions. It also questions the assumption that \\\"questions of all the wrong demonstrations fall into the same frequent-error cluster\\\" and asks for clarification on the selection criteria in section 4.2. While the comment identifies areas for improvement, it lacks specific examples or detailed reasoning to support the claims. The questions posed are more of requests for clarification rather than claims requiring verification. Therefore, the comment is somewhat verifiable, as it provides some direction but lacks comprehensive justification.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the paper's organization and writing quality, noting that most content is clear. It identifies specific areas for improvement, such as suggesting the inclusion of a table to compare different CoT prompting methods across various dimensions. Additionally, it questions the assumption that \\\"questions of all the wrong demonstrations fall into the same frequent-error cluster\\\" and asks for clarification on the selection criteria in section 4.2. This feedback is mostly helpful as it provides actionable suggestions for enhancing the paper's clarity and rigor, offering the authors a clear direction for improvement. However, it could be more helpful if it provided more detailed guidance or examples on how to implement these suggestions. Overall, the comment is rated as mostly helpful, consistent with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a significant issue with the manuscript, noting that the title, abstract, introduction, and discussion fail to specify that the results are for unsupervised random forests. This omission could lead to misinterpretations by casual readers. The reviewer explicitly states that this must be fixed for publication and suggests that it would be straightforward to address. However, the comment does not provide specific guidance on how to revise the manuscript to include this information or what changes are necessary. While the action is explicit, it lacks concrete details on execution, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the title, abstract, introduction, and discussion, allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issue by pointing out the omission of explaining that the results are for unsupervised random forests, which is a critical oversight that could lead to misinterpretations. The comment also provides a suggestion for improvement, indicating that it would be straightforward to fix this issue. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the manuscript fails to specify that the results are for unsupervised random forests, which is a significant oversight that could lead to misinterpretations. The reviewer suggests that this omission is critical and must be addressed for publication. However, the comment lacks specific examples or references to support the claim, such as instances where readers might misinterpret the results. While the reasoning is logical, the absence of detailed evidence or examples makes the claim somewhat verifiable. The authors would need to infer the impact of this omission, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical omission in the manuscript, specifically that the title, abstract, introduction, and discussion fail to specify that the results are for unsupervised random forests. This is a significant issue that could lead to misinterpretations by readers, including casual ones. The comment emphasizes the importance of correcting this omission for publication, which is a valuable piece of feedback. However, the comment does not provide specific guidance on how to address this issue, such as suggesting ways to clarify the methodology or results. Additionally, it acknowledges the reviewer's limited time to review multiple manuscripts, which may impact the depth of feedback. While the comment highlights a crucial area for improvement, it could be more helpful with additional guidance or suggestions. Therefore, it is rated as somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a lack of significance testing to support claims about the differences between methods, such as the conversational ability of ChatGPT and GPT-4. It provides specific examples, like the scores mentioned in line 486, and suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary. The comment is explicit in its request for significance testing and provides concrete examples of where this testing should be applied. This guidance is clear and actionable, giving the authors a direct path to improve their draft by addressing the lack of statistical validation. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 486,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of lacking significance testing to support claims about the differences between methods, providing examples of the scores mentioned in the paper. The comment suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to validate the claims. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the authors' claims about the differences between methods are not supported by significance testing. It provides specific examples, such as the scores for different methods, to illustrate the minimal differences and the need for proper testing. The comment logically explains why significance testing is necessary to substantiate the claims, making the claim mostly verifiable. However, it could be further strengthened by referencing specific statistical tests or providing more detailed examples of how to conduct the testing. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue in the paper, specifically the lack of significance testing to support claims about the differences between methods. It provides a concrete example from line 486, where the authors make a claim about the conversational ability of ChatGPT and GPT-4, but fail to provide statistical evidence to support it. The comment suggests that proper testing, including checking the distribution and accounting for multiple comparisons, is necessary to substantiate these claims. This feedback is clear, actionable, and provides a specific direction for the authors to improve their draft by incorporating significance testing. The detailed nature of the suggestion makes it highly helpful, as it empowers the authors to enhance the rigor and validity of their claims.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that Figure 5 is difficult to comprehend and requests more details about the two baselines presented in the figure. It also notes that the authors only study CATER for English-centric datasets and suggests extending CATER to other languages in the future. While the comment implies that the authors should provide more details about the baselines and consider extending their study to other languages, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks specific guidance on how to enhance the comprehensibility of Figure 5 or how to extend CATER to other languages. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 5,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the comprehensibility of Figure 5 and the need for more details about the two baselines presented in it. Additionally, the comment suggests extending CATER to other languages, providing a clear direction for potential future work. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that Figure 5 is difficult to comprehend and requests more details about the two baselines presented in it. The reviewer also notes that the authors only study CATER for English-centric datasets and suggests extending CATER to other languages. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim about comprehensibility and the need for more details. The suggestion to extend CATER to other languages is based on a logical assumption but lacks specific evidence or references to support the claim. Therefore, the comment is somewhat verifiable, as it provides some direction but requires more detailed justification to be fully actionable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Figure 5, noting that it is difficult to comprehend and requesting more details about the two baselines presented in the figure. It also points out that the authors only study CATER for English-centric datasets, suggesting that the widespread text generation APIs are for translation, which supports multiple languages. The comment implies that the authors could extend CATER to other languages in the future. This feedback is somewhat helpful as it highlights areas for improvement and suggests a potential direction for future work. However, it lacks detailed guidance or specific suggestions on how to enhance the comprehensibility of Figure 5 or how to extend CATER to other languages. Therefore, the comment provides some insight but not comprehensive guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a need for improvement in the literature review section, specifically pointing out that the paper does not clearly articulate the main contribution of the proposed method and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. While the feedback highlights areas for improvement, it does not provide specific guidance on how to enhance the literature review or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors know they need to improve the literature review but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment identifies a specific issue with the literature review, noting that it is unclear what the main contribution of the proposed method is and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. However, it does not specify which part of the literature review section this issue is in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing a more explicit and comparative analysis of related work. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the literature review is unclear and lacks explicitness in articulating the main contribution of the proposed method and its distinction from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. However, the comment does not provide specific examples or references to support the claim, making it somewhat verifiable. The authors would need to make a significant effort to understand and address the critique without additional guidance or detailed examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical area for improvement in the paper, specifically the literature review. It points out that the paper does not clearly articulate the main contribution of the proposed method and how it distinguishes itself from existing work, particularly in relation to the utilization of GFlowNet for sequence generation. The comment suggests that the paper should provide a more explicit and comparative analysis of related work. While the feedback highlights a significant weakness, it lacks specific guidance or examples on how the authors might improve the literature review. This limits the comment's helpfulness, as it provides a general direction for improvement but without detailed actionable steps. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that section 3.2 can be eliminated, implying that readers are presumed to know about the Gumbel-Softmax/Concrete distribution at this point. However, it does not provide explicit guidance on how to implement this change or what specific content should be removed. The action is implicit and vague, as the authors are left to infer that they should remove the section without detailed instructions on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment explicitly mentions \\\"section 3.2,\\\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It suggests that this section can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution at this point. However, the comment does not specify why this section is considered unnecessary or how it could be improved, making it under-specific. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.\",\n    \"grounding_specificity_label\": \"4\",\n    \"verifiability_rationale\": \"The review point suggests that section 3.2 can be eliminated because readers are presumed to know about the Gumbel-Softmax/Concrete distribution at this point. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment suggests that section 3.2 can be eliminated, implying that readers are presumed to know about the Gumbel-Softmax/Concrete distribution at this point. While this feedback identifies a potential area for simplification, it lacks depth and does not provide specific guidance on how to determine if the section is indeed unnecessary or how to restructure the paper to achieve this. The comment is somewhat helpful as it offers a suggestion for streamlining the paper, but it does not fully address the authors' needs for improvement. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to provide more details about the formula in the text, specifically mentioning $\\\\ell_{BCE}$. This direct request leaves no ambiguity about what the authors need to do to improve their draft. The action is concrete, as it specifies exactly what needs to be added to the text. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the formula $\\\\ell_{BCE}$, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely providing more details about the formula in the text. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that more details about the formula $\\\\ell_{BCE}$ should be provided in the text. However, it does not offer any justification or reasoning for why this is necessary or how it would improve the paper. The comment lacks supporting evidence or examples, making it difficult for the authors to understand the importance of this suggestion. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion by recommending that the authors include more details about the formula $\\\\ell_{BCE}$ in the text. This feedback is clear and directly addresses a potential gap in the paper, which is the lack of detailed explanation of the formula. By providing this guidance, the comment empowers the authors to enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it included additional context or examples of how to present the formula more effectively. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides two explicit actions for the authors to take. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a clear and direct request for improvement. Second, it instructs the authors to include labels for subfigures in Figures 3 and 4, rather than just stating them in the captions. Both actions are specific and provide clear guidance on how to implement the changes, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions Figures 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues that need to be addressed, such as explaining the link between IP and terms/equations more explicitly and prominently, and including labels for subfigures. This provides clear guidance on what needs to be improved. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, and it recommends including labels for subfigures in Figures 3 and 4. While the comment identifies specific areas for improvement, it does not provide any supporting evidence or reasoning to justify why these changes are necessary or how they would enhance the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim unverifiable. Therefore, the comment is rated as 1: Unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on two fronts. First, it suggests that the link between IP and the terms/equations should be explained more explicitly and prominently, which is a clear and direct request for improvement. This guidance helps the authors enhance the clarity and accessibility of their work. Second, the comment advises including labels for subfigures in Figures 3 and 4, rather than just stating them in the captions. This is a precise suggestion that can improve the visual presentation and readability of the figures. Both points are constructive and offer clear directions for improvement, making the comment mostly helpful. However, the comment could be more helpful if it provided additional context or examples of how to improve the explanations. Overall, the feedback is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should provide ablation experiments to validate the model performance further, given that several modifications were mentioned in Section 3.4. While the action is explicit, it lacks concrete details on how to conduct these ablation experiments or what specific aspects should be tested. The authors are given a clear direction to perform additional experiments, but the comment does not specify the methodology or criteria for these experiments. Therefore, the comment is somewhat actionable, as it provides a clear action but lacks detailed guidance on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 3.4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that ablation experiments should be provided to validate the model performance further, given the modifications mentioned in that section. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that ablation experiments should be conducted to validate the model performance further, given the modifications mentioned in Section 3.4. However, the comment does not provide specific reasoning or evidence to support why these experiments are necessary or how they would enhance the validation of the model's performance. Without detailed justification or examples, the claim lacks verifiability, making it difficult for the authors to understand the necessity of the suggested experiments. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests that the authors should conduct ablation experiments to validate the model performance further, given the modifications mentioned in Section 3.4. This feedback is clear and actionable, as it provides a specific recommendation for improving the paper by testing the impact of the modifications. However, the comment could be more helpful if it included details on which aspects of the modifications should be tested or how the ablation experiments should be designed. Despite this, the suggestion is valuable and provides a clear direction for enhancing the paper's rigor and validity. Therefore, the comment is mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights two issues: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that Proposition B.1 might merely illustrate the classic partitioning principle of K-means and points out the absence of a \\\"proof.\\\" While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to fill in Appendix A and clarify the purpose of Proposition B.1, but the lack of detailed guidance on how to do so makes the action somewhat vague. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Appendix A\\\" and \\\"Appendix B,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the blank nature of Appendix A and the unclear purpose of Proposition B.1, as well as the absence of a \\\"proof.\\\" This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises two claims: that Appendix A is left blank and that the purpose of Proposition B.1 in Appendix B is unclear. The reviewer suggests that Proposition B.1 might merely illustrate the classic partitioning principle of K-means and points out the absence of a \\\"proof.\\\" While the comment provides some reasoning, it lacks specific examples or references to substantiate the claim about the purpose of Proposition B.1. The mention of the \\\"proof\\\" being missing is also not elaborated upon. This makes the claims somewhat verifiable, as the authors would need to further investigate and understand the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies two specific issues with the paper: the blank Appendix A and the unclear purpose of Proposition B.1 in Appendix B. It suggests that Proposition B.1 might merely illustrate the classic partitioning principle of K-means, which is a well-known concept in machine learning. Additionally, it points out the absence of a \\\"proof,\\\" which is a significant oversight. While the comment highlights these weaknesses, it does not provide detailed guidance or suggestions on how to address them. The authors are informed of the issues but are left without clear steps to improve the draft. Therefore, the comment is somewhat helpful, as it points out areas for improvement but lacks depth and actionable advice.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a concern about the approximations introduced by the authors, noting that they leave loose ends and that the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107-110 needs to be expanded to reassure readers. The comment implies that the authors should address this vulnerability, but it does not explicitly instruct them to do so. The action is clear but stated indirectly, making the comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the approximations (i-iii) introduced by the authors, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the possible vulnerability due to the assumption of attacks being in the feasible set only in lines 107-110, suggesting that this needs to be expanded to reassure readers. This provides clear guidance on what aspect of the paper requires attention and how to address it. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the approximations introduced by the authors, noting that they leave loose ends and that the assumption of attacks being in the feasible set only in lines 107-110 could be a vulnerability. The reviewer suggests that this vulnerability needs to be expanded to reassure readers. However, the comment lacks specific examples or detailed reasoning to substantiate the claim about the vulnerability. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered somewhat verifiable, as it provides a general critique but lacks detailed justification or examples.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the approximations introduced by the authors, noting that while these approximations are necessary for deriving clean results, they may leave loose ends. The reviewer highlights a specific concern regarding the assumption of attacks being in the feasible set only in lines 107-110, suggesting that this vulnerability needs to be expanded to reassure readers. This feedback is clear and actionable, as it points out a specific area that requires further explanation or justification to address potential concerns. However, the comment could be more helpful if it provided suggestions on how to expand this explanation or examples of how to address the vulnerability. Overall, the comment is mostly helpful, as it directs the authors to a critical area needing clarification and provides a basis for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve the contribution of their work. The feedback lacks actionable details, such as recommending ways to enhance the model's contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment provides a general critique of the paper's contribution and the proposed model, stating that they appear limited and incremental. However, it does not specify which parts of the paper these concerns pertain to, nor does it offer specific details on what aspects of the contribution or model are considered limited or incremental. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the contribution of the paper is somewhat limited and that the proposed model is incremental. However, it does not provide any specific reasoning, examples, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental. However, it lacks specificity and does not provide any constructive feedback or suggestions for improvement. Without identifying particular weaknesses or offering guidance on how to enhance the contribution or model, the comment does not assist the authors in improving their draft. As a result, it is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a discrepancy between the experimental setup and the figures presented, noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. The reviewer explicitly asks for comments on these differences, providing a clear and direct action for the authors to take. However, the comment does not offer specific guidance on how to address these differences or what aspects should be highlighted. While the action is explicit, it lacks concrete details on how to implement the suggested feedback, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 4\\\" and \\\"Figure 5,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the differences between the two sets of evaluation methods and requesting comments on these differences. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point highlights a discrepancy between the experimental setup and the figures presented, noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand the basis of the issue or how to address it. The lack of explicit evidence or detailed explanation renders the claim borderline verifiable, as it provides some insight but lacks the necessary support to be fully actionable. Therefore, the comment is rated as 2: Borderline Verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a discrepancy between the experimental setup and the figures presented, noting that the different methods in the two sets of benchmarks are quite different in terms of OPE methods. It suggests that the authors provide comments on these differences, which is a clear and actionable piece of feedback. However, the comment could be more helpful if it offered specific suggestions on how to address these differences or what aspects should be highlighted. While it points out an area for improvement, it lacks detailed guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to discuss the iteration cost (computational budget) of the proposed method and to include a discussion of the iteration cost for all related methods, including baseline methods. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be addressed and how to implement it. The comment is specific and actionable, ensuring that the authors know precisely what changes to make to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the authors should discuss the iteration cost (computational budget) of the proposed method and include a discussion of the iteration cost for all related methods, including baseline methods. However, it does not specify which part of the paper should include this discussion, making it weakly grounded. The comment is specific in its request for additional information on iteration costs, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should discuss the iteration cost (computational budget) of their proposed method and include a discussion of the iteration cost for all related methods, including baseline methods. While the comment identifies a specific area for improvement, it lacks detailed reasoning or evidence to support why this discussion is necessary or how it would benefit the paper. The suggestion is based on a logical expectation that such information would enhance the paper's comprehensiveness, but without specific examples or references, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area for improvement by suggesting that the authors discuss the iteration cost (computational budget) of their proposed method. It further recommends including a discussion of the iteration cost for all related methods, including baseline methods. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing the comprehensiveness and depth of their analysis. By addressing this point, the authors can provide valuable insights into the efficiency and practicality of their method compared to others. However, the comment could be more helpful if it offered specific guidance on how to present this information or examples of what to include. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides several explicit actions for the authors to take. It suggests that the experimental section should report average results over multiple runs, which is a clear and concrete action. Additionally, it implies that a discussion on the decision boundaries in Section 3.1 would be interesting, providing a specific area for improvement. Lastly, it asks for clarification on the information presented in Figure 9, which is also a concrete suggestion. Each point is clear and provides specific guidance on how to improve the draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The review point is fully grounded as it explicitly mentions specific sections of the paper, such as \\\"Experimental section,\\\" \\\"Sec. 3.1,\\\" and \\\"Sec. 3.3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed in each part: reporting average results over multiple runs, discussing decision boundaries, and clarifying the information in Figure 9. This level of detail provides clear guidance on what needs to be improved, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a series of observations and requests for clarification. It does not contain any subjective claims, opinions, or suggestions that require justification or evidence. The statements are factual and descriptive, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on several aspects of the paper. It suggests that the experimental section should report average results over multiple runs to better differentiate between methods, which is a clear and practical recommendation. Additionally, it points out the need for a discussion on the decision boundaries in Section 3.1, which could provide valuable insights into the model's behavior. The comment also asks for clarification on the information presented in Figure 9, which is a direct request for additional explanation. These points collectively offer clear guidance on how to enhance the paper's clarity and depth, making the comment mostly helpful. However, it could be more helpful if it included suggestions on how to present the information or discuss the decision boundaries. Therefore, it is rated as mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the use of the center correlation metric, noting that it was deemed not insightful for discriminating model defenses but was used in Figure 4 A&B. The reviewer is asking for clarification on why it was found useful in this context and what the authors meant by their statement on lines 80-82. While the comment implies that the authors should clarify their reasoning and provide an explanation for the use of the metric, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the question of why the metric was used and what it means. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions lines 80-82 and Figure 4 A&B, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the use of the center correlation metric, asking why it was found useful in Figure 4 A&B despite being deemed not insightful for discriminating model defenses elsewhere. This provides clear guidance on what the authors need to address or clarify in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the use of the center correlation metric, stating that it was deemed not insightful for discriminating model defenses but was used in Figure 4 A&B. The reviewer seeks clarification on why the metric was found useful in this context and what the authors meant by their statement. While the comment raises a valid point about the inconsistency in the use of the metric, it lacks specific examples or references to support the claim that the metric was not insightful. This makes the claim somewhat verifiable, as the authors would need to provide more detailed reasoning or evidence to address the reviewer's concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential inconsistency in the paper regarding the use of the center correlation metric. It questions why the metric was deemed not insightful for discriminating model defenses but was still used in Figure 4 A&B. This feedback highlights a specific area of confusion that the authors need to address, prompting them to clarify their reasoning and provide an explanation for the use of the metric. However, the comment does not offer specific suggestions or guidance on how to resolve this issue, which limits its helpfulness. While it points out a critical area for clarification, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides several explicit and concrete actions for the authors to take. It highlights that the paper claims a distinction in the \\\"picking\\\" step but does not ablate it, suggesting that this aspect should be addressed. Additionally, it points out that the comparison on CIFAR is not convincing, noting that the continual learning literature has extensive experiments on this dataset. The reviewer further suggests that the authors should use the same setup as in the DEN paper to ensure a fair and correct comparison. Each of these points is clear and provides specific guidance on how to improve the paper, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The review point is fully grounded as it explicitly mentions specific sections of the paper, such as \\\"Experimental Evaluation 2.1. Ablations 2.1.1,\\\" \\\"2.2. Experiments on CIFAR,\\\" and \\\"2.2.2. It is unclear if DEN is correctly used/evaluated.\\\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issues with the ablation study, the comparison on CIFAR, and the evaluation of DEN, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes several claims regarding the experimental evaluation, specifically questioning the lack of ablation for the \\\"picking\\\" step and the unconvincing nature of the comparison on CIFAR. The reviewer supports these claims by referencing the continual learning literature and suggesting that the authors use the same setup as in the DEN paper for a fairer comparison. While the comment provides logical reasoning and references to external literature, it could be strengthened by providing specific examples or detailed comparisons from the literature. Therefore, the comment is mostly verifiable, as it provides a solid foundation for the claims but lacks complete detail.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on several aspects of the paper's experimental evaluation. It points out that the paper claims a distinction in the \\\"picking\\\" step but does not ablate it, suggesting that this aspect should be addressed. Additionally, it critiques the comparison on CIFAR, noting that the paper only compares to one approach (DEN) and that the setup is not consistent with the original paper. The comment also suggests that the authors should use the same setup as in the DEN paper to ensure a fair and correct comparison. This feedback is clear and constructive, offering the authors specific areas to improve their experimental evaluation and ensuring a more robust and fair comparison. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that using \\\"above/below diagonal\\\" instead of \\\"above/below 45 degree\\\" would be easier to interpret. This is an explicit suggestion, providing a clear action for the authors to take. However, it does not offer detailed guidance on how to implement this change or why it would be easier to interpret. While the action is explicit, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests a change in terminology for clarity, specifically recommending \\\"above/below diagonal\\\" instead of \\\"above/below 45 degree.\\\" However, it does not specify which part of the paper this suggestion pertains to, such as a particular figure or table where these terms are used. The authors can infer that it relates to the presentation of data or a plot, but the lack of explicit grounding makes it difficult to pinpoint the exact section. The comment is specific in suggesting a change to improve clarity but lacks grounding. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that using \\\"above/below diagonal\\\" is easier to interpret than \\\"above/below 45 degree,\\\" providing a logical reasoning for the suggestion. However, it lacks specific examples or references to support why the former is more effective. The comment is somewhat verifiable as it offers a rationale but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It suggests using \\\"above/below diagonal\\\" instead of \\\"above/below 45 degree\\\" to enhance interpretability, which is a clear and constructive piece of feedback. This guidance can help the authors make their presentation more accessible and easier to understand for readers. However, the comment could be more helpful if it explained why the suggested change is beneficial or provided examples of how it would improve the clarity. Overall, the comment is mostly helpful as it offers a clear direction for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about the lack of clarity regarding the scientific insight gained from the model and formalism compared to prior task-optimized approaches. It questions whether the model provides any additional explanation for how nonlinear models attain solutions through optimization on a task. However, the comment does not offer specific guidance or suggestions on how the authors could address this issue or improve the clarity of their work. The feedback lacks explicit instructions or concrete details on how to enhance the explanation or provide additional insights. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 2.3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the scientific insight gained from the model and formalism compared to prior task-optimized approaches, particularly regarding the model's role as a prototype approximation to nonlinear RNN models with emergent behavior. The comment provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the scientific insight gained from the model and formalism compared to prior task-optimized approaches. It highlights a specific concern regarding the model's role as a prototype approximation to nonlinear RNN models with emergent behavior. However, the comment lacks detailed reasoning or examples to support the claim that the model does not provide additional explanation. Without specific evidence or references, the authors may find it challenging to address the critique effectively. Therefore, the comment is considered somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully substantiated.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a critical question about the scientific insight provided by the model and formalism compared to prior task-optimized approaches. It highlights a specific concern regarding the model's role as a prototype approximation to nonlinear RNN models with emergent behavior, questioning whether the work offers any additional explanation for how these nonlinear models attain solutions through optimization. This feedback is valuable as it prompts the authors to clarify and justify the scientific contribution of their work, which is crucial for understanding the novelty and impact of their research. However, the comment could be more helpful if it provided suggestions on how to address these concerns or offered examples of how to enhance the explanation. Overall, the comment is somewhat helpful as it identifies a significant area for improvement but lacks detailed guidance for the authors.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the construction of groundtruths and the network's ability to predict keypoints. It implies that the authors should clarify how the groundtruths are built and how the network can predict all keypoints of the pose. While the comment does not explicitly instruct the authors to make these clarifications, the action is clear and concrete. The authors can infer that they need to provide more details on the groundtruth construction and the network's prediction capabilities. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq.2 of the supplementary material,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the construction of groundtruths and the network's ability to predict keypoints. The comment provides a clear request for clarification on how the groundtruths are built and how the network can predict all keypoints of the pose. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions and requests for clarification regarding the construction of groundtruths and the network's ability to predict keypoints. It does not contain subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a specific question about the construction of groundtruths and the network's ability to predict keypoints. It points out a potential inconsistency in the description of how O_{up} is trained and seeks clarification on the groundtruth construction. This feedback is somewhat helpful as it identifies a potential area of confusion and encourages the authors to clarify their methodology. However, it lacks detailed suggestions or guidance on how to address the issue, which limits its helpfulness. Providing more specific questions or suggestions for improvement would enhance its utility. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides several explicit actions for the authors to take, making it highly actionable. It clearly instructs the authors to improve the readability of the figures, clarify the derivation of equation 5 from equation 4, explain the role of \\\\(\\\\theta^{t+1/2}\\\\), and define the parameters \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\). Each of these points is specific and provides concrete guidance on how to address the issues, ensuring the authors know exactly what needs to be done to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The review comment is fully grounded as it explicitly mentions specific issues with the figures, equations, and parameters, allowing the authors to accurately identify the parts of the paper being addressed. It provides detailed feedback on each issue, including the small size and readability of the figures, the unclear derivation of equation 5 from equation 4, the unclear role of \\\\(\\\\theta^{t+1/2}\\\\), and the improper definition of \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\). The comment also points out a specific issue with the definition of \\\\(S^{\\\\sim}\\\\) in line 163. This level of detail and clarity makes the comment fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of several observations and requests for clarification. It does not make any subjective claims or judgments that require verification. Instead, it provides factual observations about the figures, equations, and parameters, which are verifiable through direct examination of the paper. Therefore, the classification \\\"No\\\" is appropriate.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides several specific and actionable feedback points that can help the authors improve their draft. It highlights issues with the figures, suggesting they are small and almost unreadable, which is a clear and actionable suggestion for improvement. Additionally, it points out a lack of clarity in the derivation of equation 5 from equation 4, as well as the role of \\\\(\\\\theta^{t+1/2}\\\\). The comment also identifies a critical issue with the definition of \\\\(S^{*}\\\\) and \\\\(S^{\\\\sim}\\\\), noting that the definition in line 163 is not proper and is cyclic. By addressing these points, the authors can significantly enhance the clarity and comprehensibility of their paper. The detailed nature of the feedback makes it highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests that the text in legends and axis labels should be larger, and it specifies the exact location where this change is needed (at the beginning of page 6). Additionally, it provides clear guidance on how to address the confusion between \\\"Proposition (1)\\\" and \\\"Equation 1\\\" by suggesting the use of \\\"Proposition 1.\\\" The comment also specifies that captions and legends' font should be larger in Figures 2 and 3, similar to the text size. This level of detail and clarity makes the comment highly actionable, as it provides precise instructions on how to improve the draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific locations in the paper, such as \\\"at the beginning of page 6\\\" and \\\"Fig. 2 and 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for larger text in legends and axis labels, and the confusion between \\\"Proposition (1)\\\" and \\\"Equation 1.\\\" Additionally, it provides clear guidance on how to address these issues. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes several claims regarding the size of text in legends and axis labels, the clarity of Proposition (1), and the font size in captions and legends. These claims are based on straightforward observations and logical reasoning. The comment does not provide specific examples or references to support these claims, but the reasoning is clear and easy to follow. Therefore, the claims are mostly verifiable, as they are based on logical observations but lack detailed evidence or references. This aligns with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on several aspects of the paper. It suggests that the text in legends and axis labels should be larger, which is a clear and straightforward improvement that can enhance readability. Additionally, it points out a potential confusion between \\\"Proposition (1)\\\" and \\\"Equation 1,\\\" offering a solution by suggesting the use of \\\"Proposition 1.\\\" The comment also recommends that captions and legend font sizes in Figures 2 and 3 should be larger, similar to the text size. These suggestions are detailed and provide clear guidance on how to improve the draft, making the comment highly helpful for the authors.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments, specifically mentioning Figure 2 of [1] which demonstrates a larger effect of removing high-scoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback provides a clear and explicit action for the authors to take, as it specifies the comparison to be made and references a specific figure for guidance. The comment is concrete, as it outlines exactly what needs to be done to improve the draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"counterfactual experiments\\\" and refers to \\\"Journey TRAK\\\" and \\\"Figure 2\\\" from a specific reference, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular comparison to make, namely against Journey TRAK, and highlights a specific aspect of the comparison that is not addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should include a comparison against Journey TRAK in their counterfactual experiments, referencing Figure 2 of a specific work that demonstrates a larger effect of removing high-scoring images according to Journey TRAK compared to CLIP cosine similarity. This claim is somewhat verifiable as it provides a specific reference and a comparison point, which could help the authors understand the basis of the suggestion. However, the comment could be strengthened by providing more detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the paper by recommending a comparison against Journey TRAK in the counterfactual experiments. It highlights a particular aspect of the comparison that is not addressed in the paper, referencing Figure 2 of a specific work that demonstrates a larger effect of removing high-scoring images according to Journey TRAK compared to CLIP cosine similarity. This feedback is clear and constructive, offering the authors a concrete way to enhance their experimental analysis and potentially strengthen their findings. By addressing this suggestion, the authors can provide a more comprehensive evaluation of their approach. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a potential issue with the placement of adaptive convolutions, noting that ACNN-v3 performed worse than ACNN-v2 in Table-3. It suggests that the placement of adaptive convolutions is important but lacks analysis or comments on this aspect. The reviewer implies that the authors should provide an analysis or discussion on the importance of adaptive convolution placement. While the comment identifies an area for improvement, it does not explicitly instruct the authors on how to conduct this analysis or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table-3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the placement of adaptive convolutions, noting that ACNN-v3 performed worse than ACNN-v2 and suggesting that the placement of adaptive convolutions is important. The comment further specifies what needs to be addressed, which is the lack of analysis or comments on the importance of adaptive convolution placement. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that replacing normal convolutions with adaptive convolutions is not always beneficial, as evidenced by the results in Table-3 where ACNN-v3 performed worse than ACNN-v2. The comment provides specific experimental results to support the claim, making it mostly verifiable. However, it could be further strengthened by including additional analysis or references to similar findings in the literature. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the experimental results, specifically noting that replacing normal convolutions with adaptive convolutions is not always beneficial. It points out that ACNN-v3 performed worse than ACNN-v2, suggesting that the placement of adaptive convolutions is important. The comment highlights a gap in the analysis, as there is no discussion or comments on the importance of adaptive convolution placement. This feedback is clear and actionable, as it directs the authors to provide an analysis or discussion on the placement of adaptive convolutions to strengthen their experimental findings. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful, as it provides a clear direction for improvement but could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point discusses the trade-off between computation time and information richness in the proposed method compared to a reference method. It raises a question about the amount of information encoded in an ancestral graph compared to a DAG. However, it does not provide explicit guidance or suggestions on how the authors could address this issue or improve their draft. The comment lacks actionable details, such as recommending ways to quantify or compare the information content or suggesting modifications to the method. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment discusses the trade-off between computation time and information richness in the proposed method compared to a reference method. It mentions the reduction of the search space to ancestral graphs and the resulting loss of information compared to the richer search space of DAGs. However, the comment does not specify which part of the paper this discussion pertains to, such as specific sections or experiments where this trade-off is addressed. While the authors might infer that it relates to sections discussing the method's performance or results, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in detailing the trade-off and the implications of this choice, but it is not grounded because it does not specify where in the paper this discussion should be placed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point discusses the trade-off between computation time and information richness in the proposed method compared to a reference method. It highlights that reducing the search space to ancestral graphs results in less information compared to the richer search space of DAGs. The comment questions the amount of information encoded in an ancestral graph. While the claim is based on logical reasoning and provides a clear explanation of the trade-off, it lacks specific examples or references to substantiate the claim fully. Therefore, the comment is mostly verifiable, as it provides a reasonable argument but could benefit from additional evidence or references to be fully verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment highlights a trade-off between computation time and information richness in the proposed method compared to a reference method. It points out that while the proposed method achieves faster computation by reducing the search space to ancestral graphs, it results in less information compared to the richer search space of DAGs. The comment raises an important question about the amount of information encoded in an ancestral graph, which could be valuable for the authors to consider. However, the comment lacks specific suggestions or guidance on how the authors might address this trade-off or improve their method. While it identifies a relevant issue, it does not provide actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors include a brief discussion on the empirical motivation for using time-varying Q^t and S^t, as opposed to a fixed approach as in Section 4.2. It provides specific questions to consider, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S^t vary with time. This feedback is explicit and provides concrete guidance on what the authors should include in their discussion, making it highly actionable. The authors know exactly what additional information to add and how to structure it, ensuring they can effectively improve their draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"discussion\\\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including a brief discussion on the empirical motivation for using time-varying Q^t and S^t, as opposed to a fixed approach. The comment further specifies what needs to be addressed by asking about the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S^t vary with time. This provides clear guidance on what the authors need to consider and improve in their discussion. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests including a discussion on the empirical motivation for using time-varying Q^t and S^t, as opposed to a fixed approach. It provides specific questions to consider, such as the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals. While the comment highlights areas for improvement, it lacks detailed reasoning or evidence to support why these changes are necessary or how they would impact the results. The suggestions are somewhat verifiable, as they provide a direction for improvement but require further elaboration or justification to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the discussion section by recommending the inclusion of a brief discussion on the empirical motivation for using time-varying Q^t and S^t, as opposed to a fixed approach. It raises important questions about the effect on the volatility of \u03b1_t and the average lengths of the predictive intervals when Q^t and S^t vary with time. This feedback is clear and constructive, guiding the authors to enhance their discussion by addressing these specific aspects, which could lead to a more comprehensive and insightful analysis. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises doubts about the definitions in Table 1, specifically questioning the difference between anchor-based regression and regression in RepPoints, and mentions that in RetinaNet and ATSS, regression methods do not significantly influence the results. The reviewer suggests that the method of directly regressing [w, h] to the center point is sufficient and that RepPoints regressing distance to the location of feature maps does not show a clear difference. The comment explicitly requests clarification on this issue and expresses concern about the lack of solid motivation. While the action is clear\\u2014clarifying the definitions and motivations\\u2014it lacks concrete guidance on how to address the issue or what specific aspects need clarification. Therefore, the comment is somewhat actionable, as it provides a clear direction but lacks detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the definitions in Table 1, particularly the difference between anchor-based regression and regression in RepPoints, and provides context by referencing RetinaNet and ATSS. The comment further suggests that the motivations are not solid enough and requests clarification. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises doubts about the definitions in Table 1, specifically questioning the difference between anchor-based regression and regression in RepPoints. The reviewer provides some context by mentioning RetinaNet and ATSS, where regression methods are considered less influential. However, the comment lacks specific references or detailed explanations to fully substantiate the claim that there is no obvious difference between the two methods. While the reviewer offers some logical reasoning, the absence of concrete evidence or examples makes the claim somewhat verifiable. The authors would need to further explore the references and reasoning provided to fully understand and address the concern. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the definitions in Table 1, specifically questioning the difference between anchor-based regression and regression in RepPoints. It provides some context by mentioning RetinaNet and ATSS, where regression methods are considered less influential. The reviewer suggests that the method of directly regressing [w, h] to the center point is sufficient and that RepPoints regressing distance to the location of feature maps does not show a clear difference. The comment explicitly requests clarification on this issue and expresses concern about the lack of solid motivation. While the comment identifies a potential weakness and provides some context, it lacks specific suggestions or guidance on how the authors might address the issue or clarify the definitions. Therefore, the feedback is somewhat helpful, as it prompts the authors to clarify their work but does not offer detailed guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to correct a specific error in the text, where it mentions that \\\"Fig. 1\\\" should be used instead of \\\"Fig. 5.1.\\\" Additionally, it provides a concrete suggestion for LaTeX formatting, recommending that the \\\"\\\\label\\\" command be placed after the \\\"\\\\caption\\\" command. This feedback is clear and provides specific guidance on how to correct the error and improve the formatting of the document. The authors know exactly what changes to make to address the issue, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 205\\\" and \\\"Fig. 1\\\" and \\\"Fig. 5.1,\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the figure reference and the LaTeX formatting issue. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point is a factual correction regarding the figure reference and LaTeX formatting. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by correcting a factual error in the manuscript, where it points out that \\\"Fig. 1\\\" should be used instead of \\\"Fig. 5.1.\\\" Additionally, it offers a clear suggestion for LaTeX formatting, recommending that the \\\"\\\\label\\\" command be placed after the \\\"\\\\caption\\\" command. This feedback is precise and directly addresses a minor but important issue, ensuring that the manuscript adheres to standard formatting practices. By providing these corrections, the comment empowers the authors to improve the accuracy and professionalism of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides two explicit actions for the authors to take. First, it recommends adding a reference next to baseline names in tables, such as placing a citation next to \\\"FF Positional\\\" if it refers to a paper method. This is a clear and direct suggestion that the authors can implement. Second, it points out that $\\\\Omega$ is not explicitly defined in Corollary 1, although it is not difficult to infer what it means. While the authors can deduce the meaning, the comment does not provide specific guidance on how to define it. Overall, the comment is mostly actionable as it provides clear instructions for one action and a suggestion for another, with some guidance on how to address the second point.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Corollary 1\\\" and \\\"$\\\\Omega$,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed: adding a reference next to baseline names in tables and explicitly defining $\\\\Omega$ in Corollary 1. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of two parts: a suggestion to add a reference next to baseline names in tables and a comment about the lack of explicit definition for $\\\\Omega$ in Corollary 1. The first part is a suggestion for improvement and does not contain a claim or opinion, so it is classified as \\\"No.\\\" The second part points out a lack of explicit definition, which is a factual observation rather than a claim. Therefore, the entire review point is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides two specific and actionable suggestions for improving the paper. First, it recommends adding a reference next to baseline names in tables, such as placing a citation next to \\\"FF Positional\\\" if it refers to a paper method. This is a clear and practical recommendation that can enhance the clarity and credibility of the paper. Second, it points out that $\\\\Omega$ is not explicitly defined in Corollary 1, despite being relatively straightforward to infer. This feedback highlights a specific area where the authors can improve the clarity and precision of their writing. Both suggestions are constructive and provide the authors with clear directions for enhancing their draft, making the comment mostly helpful. However, the comment could be more helpful if it offered additional guidance on how to define $\\\\Omega$ or provided examples of similar definitions in other works. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to correct the caption for Figure 7, specifying that it should be \\\"Edge Dynamics\\\" instead of \\\"Node Dynamics.\\\" This is a clear and direct action that the authors can take to improve their draft. The comment provides concrete guidance on what needs to be changed, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 7,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely changing the caption from \\\"Node Dynamics\\\" to \\\"Edge Dynamics.\\\" Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point is a factual correction regarding the caption of Figure 7. It does not contain any subjective opinions, judgments, or suggestions that require verification or justification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment is highly helpful as it provides a specific and actionable suggestion for correcting the caption of Figure 7. By identifying the incorrect caption and recommending the correct one, the reviewer offers clear guidance that the authors can easily implement to improve the accuracy and clarity of their manuscript. This level of detail and specificity empowers the authors to make a precise correction, enhancing the quality of their work. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to clarify which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be addressed in the experimental section. The comment is specific and actionable, as it gives the authors a concrete task to perform, ensuring they know precisely how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"experimental section of the paper,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of not providing standard deviation after multiple experiments and suggests clarifying which effects are within the range of standard deviation fluctuations and which are improvements brought by the SoRA method. This provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the improvement brought by SoRA compared to the baseline is limited due to random fluctuations, as standard deviation after multiple experiments is not provided. The reviewer suggests that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are improvements due to SoRA. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim about the limited improvement. The suggestion to clarify the effects within the standard deviation is logical, but without further evidence or detailed reasoning, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue in the experimental section of the paper, noting that the standard deviation after multiple experiments is not provided. It also points out that the improvement brought by SoRA compared to the baseline may be due to random fluctuations. The comment suggests that the authors should clarify which effects fall within the range of standard deviation fluctuations and which are improvements due to the SoRA method. This feedback is clear and actionable, providing the authors with a concrete direction for improving their draft by addressing the issue of standard deviation and clarifying the results. However, it could be more helpful if it offered additional guidance on how to present this information effectively. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies several issues with the organization and presentation of the paper, such as the small font size of annotations in Figures 1 and 2, the lack of explicitness in the figures, incorrect placement of Table 2, and formatting errors on page 6. These observations are explicit and provide concrete guidance on what needs to be addressed. The authors know exactly what aspects of the paper require revision and how to improve them, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific elements of the paper, such as Figure 1, Figure 2, Table 2, and page 6, allowing the authors to accurately identify the parts being addressed. It is also specific because it details the issues, such as the small font size of annotations, the lack of explicitness in the figures, and the incorrect placement of Table 2. Additionally, it points out the formatting errors on page 6. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper is not well organized and that the layout is rushed, providing specific examples such as the small font size of annotations in Figures 1 and 2, the lack of explicitness in the figures, and incorrect placement of Table 2. These examples offer a clear indication of the issues, making the claim mostly verifiable. However, the comment could be strengthened by providing more detailed reasoning or additional examples to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies several specific issues with the organization and presentation of the paper, such as the small font size of annotations in Figures 1 and 2, the lack of explicitness in the figures, incorrect placement of Table 2, and formatting errors on page 6. These observations are actionable and provide clear guidance on how the authors can improve the clarity and professionalism of their paper. By addressing these issues, the authors can enhance the readability and overall quality of their work. The specificity and actionable nature of the feedback make this comment highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights an issue with the notation used in the paper, specifically the use of the notation \\u03c0 with a subscript without being defined. This feedback is explicit in pointing out a missing definition, which provides a clear action for the authors to take. However, it does not specify which instances of the notation should be defined or how the authors should go about defining them. While the action is explicit, the lack of detailed guidance on execution makes it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the section where the notation \\u03c0 with a subscript is used multiple times without being defined. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of definition for the notation \\u03c0 with a subscript. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point highlights a factual observation about the notation used in the paper, specifically the use of the notation \\u03c0 with a subscript without being defined. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No\\\".\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the notation used in the paper, noting that the notation \\u03c0 with a subscript is used multiple times without being defined. This feedback is clear and actionable, as it points out a lack of clarity in the manuscript that could hinder understanding. By addressing this issue, the authors can improve the readability and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to define the notation or why it is important to do so. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It points out specific grammatical errors, such as the incorrect spelling of \\\"know\\\" instead of \\\"known\\\" at line 148. It also requests a definition for the symbol \\\\(\\\\gamma_0^{***}\\\\) at line 156 and asks for clarification on the meaning of colors in Figure 1, both in the caption and the text. These instructions are clear and specific, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific line numbers (l148, l156) and Figure 1, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear instructions on what needs to be addressed: correcting a grammatical error, defining a symbol, and specifying the meaning of colors in a figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual corrections and requests for clarification, such as correcting a grammatical error and defining a symbol. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No\\\".\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on several aspects of the paper. It points out a grammatical error at line 148, where \\\"known\\\" should be used instead of \\\"know.\\\" It also requests a definition for the symbol \\\\(\\\\gamma_0^{***}\\\\) at line 156, which is a clear and direct request for clarification. Additionally, it suggests specifying the meaning of colors in Figure 1, both in the caption and the text, which is another actionable suggestion for improving the clarity of the paper. These specific and constructive comments offer clear guidance on how the authors can enhance the quality and readability of their draft. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several concerns about the clarity and explanation of certain terms and concepts in the paper. It explicitly asks for clarification on \\\"the upper faces of the convex hull\\\" and the need for better explanation of the dual subdivision and projection \\u03c0. Additionally, it points out that the variable 'p' is not explicitly defined, which is problematic given its extensive use in the paper. The reviewer suggests moving the definition of 'p' to clarify the text. While the comment identifies specific areas that need clarification and provides a suggestion for improvement, it does not offer detailed guidance on how to address these issues. The actions are explicit but somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific elements of the paper, such as \\\"the upper faces of the convex hull,\\\" \\\"dual subdivision and projection \\u03c0,\\\" and the variable 'p.' This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, including the need for better explanation of the dual subdivision and projection \\u03c0, and the need for a clearer definition of the variable 'p.' Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions and requests for clarification regarding specific terms and concepts in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies several areas where the paper lacks clarity and precision. It specifically asks for clarification on the term \\\"upper faces of the convex hull\\\" and the need for better explanation of the dual subdivision and projection \\u03c0. Additionally, it points out that the variable 'p' is not explicitly defined, which is problematic given its extensive use throughout the paper. The comment suggests moving the definition of 'p' to clarify the text. While the feedback highlights important areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. The authors are informed of the problems but are not provided with specific steps to resolve them. Therefore, the comment is somewhat helpful, as it identifies weaknesses but does not fully support the authors in making improvements.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that since the approach follows a detection-parsing paradigm, it would be beneficial to evaluate the components separately to support the claim. While the comment implies that the authors should conduct separate evaluations, it does not provide explicit instructions or detailed guidance on how to perform these evaluations. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment identifies two major components of the proposed method: the generative shape model and the word parsing model. It questions which component contributes to the performance gain and suggests evaluating the components separately to support the claim. However, it does not specify which part of the paper discusses these components, making it weakly grounded. The comment is specific in its request for separate evaluations to support the claim, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests evaluating the components separately to support the claim, implying that the current evaluation does not adequately demonstrate the contribution of each component. However, the comment does not provide specific examples or detailed reasoning to substantiate why separate evaluation is necessary or how it would improve the understanding of the method's performance. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of the suggestion without explicit guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that since the approach follows a detection-parsing paradigm, it would be beneficial to evaluate the components separately to support the claim. This feedback is clear and actionable, as it provides a specific direction for the authors to improve their analysis and evaluation of the method. However, the comment could be more helpful if it offered additional guidance on how to conduct these separate evaluations or what specific metrics to consider. Overall, the comment is mostly helpful as it directs the authors to a meaningful enhancement of their draft, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point poses questions about the rationale behind specific design choices in Figure 1, such as the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. While these questions imply that the authors should provide explanations for these choices, they do not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add explanations but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the rationale behind having a separate timbre encoder module and the input of content encoder outputs into SADTW. This provides clear guidance on what needs to be clarified or explained in the paper. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the rationale behind specific design choices in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises questions about the rationale behind specific design choices in Figure 1, specifically regarding the use of a separate timbre encoder module and the input of content encoder outputs into SADTW. While it identifies areas that may need further explanation, it does not provide specific suggestions or guidance on how the authors might address these questions or improve their explanation. The comment is somewhat helpful as it prompts the authors to clarify their design choices, but it lacks depth and actionable feedback that would guide the authors in making improvements. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly states that Table 4 is incomplete and should include results for all four datasets. This provides a clear and direct action for the authors to take, specifying exactly what needs to be added to the table. The feedback is specific and leaves no ambiguity about how to improve the draft, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment explicitly mentions \\\"Table 4,\\\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. It also specifies the issue by stating that the table should include results for all four datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that \\\"Table 4 is incomplete\\\" and should include results for all four datasets. However, it does not provide any reasoning or evidence to support why the table is considered incomplete or why it should include results for all four datasets. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Table 4, noting that it is incomplete and should include results for all four datasets. This feedback is clear and actionable, as it directly points out a missing element that the authors need to address to improve the completeness and accuracy of their results. By providing a precise suggestion, the comment empowers the authors to make a straightforward improvement to their draft. However, the comment could be more helpful if it explained why the inclusion of all four datasets is important or how it impacts the overall findings. Despite this, the feedback is mostly helpful as it directs the authors to a clear area for enhancement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the writing or presentation is \\\"jumbled at times,\\\" but it does not provide specific examples or guidance on how to improve the clarity or organization of the text. Without explicit instructions or concrete suggestions, the authors are left without a clear understanding of what needs to be revised or how to address the issue. As a result, the comment lacks actionability, leaving the authors without direction on how to improve their draft. Therefore, this comment is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the writing or presentation is \\\"jumbled at times,\\\" but it does not specify which parts of the paper or sections are problematic. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the writing or presentation is \\\"jumbled at times,\\\" but it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment lacks verifiability and is rated as \\\"1: Unverifiable.\\\"\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the writing or presentation is \\\"jumbled at times,\\\" but it does not provide any specific examples or detailed feedback on which parts of the paper are problematic or how they could be improved. Without actionable guidance or specific suggestions, the authors are left without a clear understanding of how to address the issue. This lack of detail and specificity makes the comment unhelpful, as it does not offer a path for improvement. Therefore, the comment aligns with a score of 1, indicating that it is not helpful at all.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the importance of the annealing scheme in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. It suggests that this could introduce a bias that might outweigh the bias reductions achieved by using IWAE. However, the comment does not provide explicit guidance or suggestions on how the authors should address this concern or what specific actions they should take to mitigate the potential bias. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the concern. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 4\\\" and the \\\"last paragraph,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern regarding the importance of the annealing scheme, particularly when $\\\\alpha$ is not decreased to $0$, and suggests that this could introduce a bias that might outweigh the bias reductions achieved by using IWAE. This provides clear guidance on what aspect of the annealing scheme needs further consideration. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the importance of the annealing scheme in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. The reviewer suggests that this could introduce a bias that might outweigh the bias reductions achieved by using IWAE. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the bias could be significant. Without these elements, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides an initial rationale but lacks sufficient detail to be fully substantiated.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the importance of the annealing scheme in Section 4, particularly when $\\\\alpha$ is not decreased to $0$. It suggests that this could introduce a bias that might outweigh the bias reductions achieved by using IWAE. While the comment identifies a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or mitigate the potential bias. The feedback provides some insight into a possible weakness but does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out an inaccuracy in the authors' description of the base IOI circuit, specifically regarding the primary attention of the Induction, Duplicate Token, and Previous Token heads to the S2 token. The reviewer explicitly states that this is incorrect according to Section 3 of Wang et al., 2023, and provides a clear correction. This feedback is explicit and provides concrete guidance on what the authors need to revise, making it highly actionable. The authors know exactly what needs to be corrected and how to implement the change.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the specific claim made by the authors regarding the base IOI circuit and the attention of certain heads to the S2 token. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is incorrect in the authors' description, pointing out that the heads are active at the S2 token but do not primarily attend to it. This provides clear guidance on what needs to be corrected. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the authors' claim about the base IOI circuit, specifically regarding the primary attention of certain heads to the S2 token. The reviewer references Section 3 of Wang et al., 2023, providing a specific external source to support the claim that the heads are active at the S2 token but do not primarily attend to it. This reference offers a clear and robust justification for the claim, making it fully verifiable. The detailed reasoning and external reference provide a strong foundation for the reviewer's critique, allowing the authors to understand and address the issue effectively.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific inaccuracy in the authors' description of the base IOI circuit, particularly regarding the primary attention of certain heads to the S2 token. It references a specific section of Wang et al., 2023, providing a clear and actionable critique that the authors can address. By pointing out this discrepancy, the comment helps the authors correct their understanding and improve the accuracy of their paper. The feedback is precise and provides a concrete suggestion for improvement, making it highly helpful for the authors. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment claims that the contribution of the work is incremental and suggests that the proposed pipeline is not impressive or novel, merely a collection of tricks to improve defense evaluation. However, it does not provide any specific guidance or suggestions on how the authors could address this critique or enhance the novelty of their work. The comment lacks actionable details, such as recommending ways to make the contribution more significant or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the technical contribution of the work, describing it as incremental and suggesting that the proposed pipeline is merely a collection of tricks to improve defense evaluation. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the pipeline are considered unimpressive or lacking novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the contribution of the work is incremental and suggests that the proposed pipeline is merely a collection of tricks to improve defense evaluation. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or a clear explanation of why the contribution is considered incremental, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment critiques the technical contribution of the work, describing it as incremental and suggesting that the proposed pipeline is merely a collection of tricks to improve defense evaluation. While it identifies a potential weakness in the originality and impact of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their contribution. The lack of actionable feedback limits the utility of the comment for the authors, making it somewhat helpful as it highlights an area for improvement but does not offer a clear path for addressing it.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides specific feedback on the vagueness of certain statements in the paper, particularly regarding the use of RNNs for natural language reasoning tasks and the reinforcement learning-agent analogy. It suggests that the authors should clarify these points and consider using examples from the literature on natural language inference or the SNLI leaderboard to support their claims. Additionally, it advises that the reinforcement learning-agent analogy might be out-of-place and suggests that generalization capabilities are better illustrated by examples later in the paper. While the comment provides explicit suggestions for improvement, it lacks detailed guidance on how to implement these changes, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (L15, L16-18) and provides context by referencing the literature on natural language inference and the SNLI leaderboard. It also specifies the issue with the reinforcement learning-agent analogy, suggesting that it might be out-of-place and that generalization capabilities are better illustrated by examples later in the paper. This level of detail allows the authors to accurately identify the parts of the paper being addressed and understand the specific issues that need to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that certain RNNs work well for specific natural language reasoning tasks and provides a reference to the literature on natural language inference and the SNLI leaderboard. This reference offers a specific example to support the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed examples or explanations of how the RNNs perform on these tasks. Additionally, the second part of the comment suggests that the reinforcement learning-agent analogy might be out-of-place, but it does not provide specific examples or reasoning to support this claim. Therefore, the overall comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides specific feedback on the vagueness of certain statements in the paper, particularly regarding the use of RNNs for natural language reasoning tasks and the reinforcement learning-agent analogy. It suggests that the authors should clarify these points and provide references to relevant literature, such as the SNLI leaderboard, to support their claims. Additionally, it points out that the reinforcement learning-agent analogy might be out-of-place and suggests that generalization capabilities are better illustrated by examples later in the paper. This feedback is clear and actionable, offering the authors specific guidance on how to improve the clarity and relevance of their paper. However, it could be more helpful if it included more detailed suggestions on how to integrate the references or examples into the text. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights two issues: the lack of significant difference between the proposed sensitive-layer selection and randomized selection in Figure 5, and the absence of mathematical or theoretical justification for the proposed Algorithm 1. While the comment identifies areas that need attention, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they should provide a more detailed analysis or justification, but without specific instructions on how to do so, the action remains vague. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Fig.5\\\" and the \\\"third figure,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by pointing out the lack of significant difference between the proposed sensitive-layer selection and randomized selection in terms of StableDiffusion, and the absence of mathematical or theoretical justification for the proposed Algorithm 1. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes two claims: first, that the proposed sensitive-layer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and second, that there is a lack of mathematical or theoretical justification for the proposed Algorithm 1. The first claim is supported by the observation in Fig. 5, but lacks detailed explanation or evidence to substantiate the claim fully. The second claim is more verifiable as it points out the absence of justification, but it does not provide specific examples or references to support the lack of justification. Overall, the comment is somewhat verifiable, as it provides some support for the claims but lacks detailed evidence or references to fully substantiate the arguments.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies two specific areas for improvement in the paper. First, it points out that the proposed sensitive-layer selection does not make a significant difference compared to randomized selection in terms of StableDiffusion, and the authors do not discuss this observation further. This feedback highlights a gap in the analysis and suggests that the authors should provide a more detailed discussion or explanation of this aspect. Second, the comment notes the lack of mathematical or theoretical justification for the proposed Algorithm 1, indicating that this is an area that needs further exploration and explanation. By addressing these points, the authors can significantly enhance the depth and clarity of their work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of how to strengthen the justification. Overall, the feedback is mostly helpful as it directs the authors to important areas for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides a specific suggestion for improving the clarity of the notation used in the paper. It suggests that triples denoted as $(e_1, r, e_2)$ should be represented as tuples instead of sets to better illustrate their tuple-like structure. This feedback is explicit and concrete, as it directly instructs the authors on how to enhance the presentation of their work. The authors know exactly what change to make to improve the clarity of their notation. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 122,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement: representing triples as tuples instead of sets to better illustrate their tuple-like structure. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that triples denoted as $(e_1, r, e_2)$ should be represented as tuples instead of sets to better illustrate their tuple-like structure. However, the comment does not provide any reasoning or evidence to support why this change would be beneficial or necessary. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the clarity of the notation used in the paper. By recommending that triples denoted as $(e_1, r, e_2)$ should be represented as tuples instead of sets, the comment offers a clear way to enhance the presentation of the paper. This feedback is precise and directly addresses a potential area of confusion, making it highly helpful for the authors to improve their draft. Therefore, the comment deserves a score of 5, indicating it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies a specific issue with the statement that \\\"every kernel can be described by a feature space parameterized by a neural network,\\\" noting that this is not true, particularly for RBF kernels. It suggests that the limitation should be made clearer. While the comment highlights a problem and provides a specific example (RBF kernels and their RKHS), it does not offer explicit guidance on how to address this issue or suggest specific changes to the text. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the limitation but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions line \\\"104,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement about kernels and neural networks, providing a clear example of the limitation with RBF kernels and their RKHS. The comment suggests that the limitation should be made clearer, providing a specific area for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the statement that \\\"every kernel can be described by a feature space parameterized by a neural network,\\\" providing a counterexample with RBF kernels and their infinite-dimensional RKHS. The reviewer explains that representing such kernels with neural networks would require an infinite width, which is practically impossible. This reasoning is logical and well-supported by the properties of RBF kernels and their RKHS, making the claim mostly verifiable. However, the comment could be strengthened by referencing specific literature or studies that discuss the limitations of neural networks in representing certain kernels. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the paper's statement that \\\"every kernel can be described by a feature space parameterized by a neural network.\\\" It points out that this statement is not entirely accurate, particularly for RBF kernels, where the Reproducing Kernel Hilbert Space (RKHS) is infinite-dimensional. The reviewer provides a clear example of the limitation, explaining that representing such kernels with neural networks would require an infinite width, which is practically impossible. This feedback is valuable as it highlights a potential misunderstanding or oversimplification in the paper and suggests that the authors should clarify this limitation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided additional examples of kernels that might pose similar challenges. Overall, the comment is mostly helpful as it directs the authors to a specific area needing clarification, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions and suggestions regarding Figure 4 and the GPI approach. It asks whether GPI with noise added could reproduce the data similarly well and suggests exploring other measures to demonstrate that GPI cannot have as good a fit with behavioral data, such as behavioral trajectories or time to goal. Additionally, it suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. While the comment implies actions, such as conducting additional analyses or discussing the approach's applicability, it does not provide explicit instructions or concrete steps for the authors to take. The actions are somewhat clear but inferred, making the comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Fig. 4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues by questioning the possibility of GPI with noise added reproducing the data similarly well and suggests exploring other measures to demonstrate that GPI cannot have as good a fit with behavioral data. Additionally, it provides a suggestion for discussion on the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises questions about the potential of GPI with noise added to reproduce data similarly well and suggests exploring other measures to demonstrate that GPI cannot have as good a fit with behavioral data. It also mentions the suitability of the approach for modeling pattern separation tasks and suggests discussing this. While the comment poses questions and suggests areas for further exploration, it does not provide specific evidence or references to support the claims made. The lack of detailed justification or examples makes it somewhat verifiable, as the authors would need to make a significant effort to address the questions raised. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises several points that could help improve the paper. It questions the potential of GPI with noise added to reproduce the data similarly well, suggesting that additional measures could be used to demonstrate that GPI cannot have as good a fit with behavioral data. It also suggests discussing the suitability of the approach for modeling pattern separation tasks, given the availability of behavioral data. While the comment identifies areas for improvement and provides some direction, it lacks specific suggestions or detailed guidance on how to address these points. The feedback is somewhat helpful as it prompts the authors to consider additional analyses or discussions, but it could be more comprehensive with more detailed guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point notes that the performance gains are not very high, with most metrics showing a difference between the baseline and the best approach that is less than 1%. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. There is no guidance on potential modifications, additional experiments, or alternative approaches that could be explored to enhance the performance gains. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the performance gains in the paper, specifically noting that the difference between the baseline and the best approach is less than 1% for most metrics. However, it does not specify which part of the paper this observation pertains to, such as specific sections or tables where the performance metrics are discussed. This lack of explicit reference makes it weakly grounded. The comment is specific in detailing the issue of low performance gains, but without clear grounding, the authors may struggle to identify where to focus their improvements. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the performance gains are not very high, as the difference between the baseline and the best approach is less than 1% for most metrics. This claim is somewhat verifiable as it provides a specific numerical threshold (less than 1%) to support the assertion. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as specific metrics or data points where this observation is evident. This makes it challenging for the authors to fully understand and address the issue, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment points out that the performance gains reported in the paper are not very high, with most metrics showing a difference between the baseline and the best approach that is less than 1%. This observation highlights a potential weakness in the paper's results, suggesting that the improvements achieved by the proposed method are marginal. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises questions about the impact of specific information on the feedback network's performance. It asks about the performance without each type of information and with only natural language feedback. While the comment implies that the authors should conduct experiments to evaluate the impact of these information types, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested analysis. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises questions about the impact of specific information on the feedback network's performance, specifically asking about the performance without each type of information and with only natural language feedback. However, it does not specify which part of the paper these questions pertain to, such as a particular section or experiment where this information is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed regarding the performance evaluation of the feedback network. Therefore, this comment is weakly grounded and specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the impact of specific information on the feedback network's performance. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises an important question about the impact of specific information on the feedback network's performance. It asks how much the information about incorrect phrases, corrected phrases, and the type of mistake contributes to the feedback network's effectiveness. Additionally, it inquires about the performance without each of these types of information and with only natural language feedback. This feedback is somewhat helpful as it prompts the authors to consider the importance of different information sources in their model and to evaluate their impact on performance. However, the comment could be more helpful if it provided suggestions on how to conduct these evaluations or offered insights into potential methodologies. Overall, the comment identifies a relevant area for improvement but lacks detailed guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the performance boost due to additional parameters, specifically comparing LinearTop and NLTop with Unary, which uses a different neural network. It questions whether a better Unary baseline would still result in a performance boost. While the comment highlights an area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The authors are left to infer that they might need to conduct further analysis or experiments to explore the impact of the baseline on performance. The action is implicit and somewhat vague, as it lacks concrete steps for the authors to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Tab 1, 2, 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the performance boost due to additional parameters, particularly comparing LinearTop and NLTop with Unary, which uses a different neural network. The comment suggests considering a better Unary baseline to determine if there is still a performance boost. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the performance boost due to additional parameters, specifically comparing LinearTop and NLTop with Unary, which uses a different neural network. The reviewer references a specific paper ([14]) to support the claim that Unary performs worse, suggesting that a better baseline might still yield a performance boost. This reference provides a basis for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more detailed comparisons or additional evidence from the referenced paper to fully substantiate the claim. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment raises a pertinent question about the performance boost attributed to additional parameters, specifically comparing LinearTop and NLTop withUnary, which uses a different neural network. It questions whether a better Unary baseline would still result in a performance boost. This feedback is somewhat helpful as it prompts the authors to reconsider their baseline comparisons and potentially conduct further analysis or experiments to address the concern. However, the comment could be more helpful if it provided specific suggestions on how to approach this analysis or what additional experiments might be necessary. Overall, the comment offers a direction for improvement but lacks detailed guidance, making it somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly asks for the final learning rates used for the deep models, specifically mentioning CIFAR-10 and CIFAR-100. It also notes that the authors only searched for 4 different learning rates, suggesting that the optimal learning rate for the baseline might be outside the tested interval, which could affect the results. This feedback provides a clear and direct action for the authors to take, which is to provide the final learning rates used in their experiments. The comment is specific and leaves no ambiguity about what needs to be addressed, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it specifically mentions the \\\"final used learning rates for the deep models,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to provide the final learning rates used for the deep models, particularly for CIFAR-10 and CIFAR-100. The comment also raises a concern about the potential impact of the learning rate search interval on the results. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the learning rates used for the deep models, specifically mentioning CIFAR-10 and CIFAR-100. The reviewer notes that the authors only searched for 4 different learning rates, which could lead to suboptimal results if the optimal learning rate for the baseline is outside the tested interval. While the comment highlights a potential issue, it lacks specific examples or references to support the claim that the results might be affected. The reasoning is somewhat verifiable, as it logically points out a potential problem, but it could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a pertinent concern about the learning rates used for the deep models, specifically mentioning CIFAR-10 and CIFAR-100. It points out that the authors only searched for 4 different learning rates, which could lead to suboptimal results if the optimal learning rate for the baseline is outside the tested interval. This feedback is valuable as it highlights a potential issue with the experimental setup that could affect the validity of the results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending a broader search interval or additional experiments to validate the findings. Overall, the comment is somewhat helpful as it identifies a critical area for improvement but lacks detailed guidance on how to implement the suggested changes.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies a problem with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. The reviewer suggests that additional experiments or more in-depth analysis are necessary to better justify the claims made in the paper. While the comment clearly states the need for further analysis, it does not provide specific guidance on how to conduct these additional experiments or what aspects of the analysis should be focused on. The action is explicit but somewhat vague in terms of execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the results presented in the table, noting that the proposed approaches only outperform the baselines in one setup out of three and that there is no consistent trend in the results. The comment further suggests that additional experiments or more in-depth analysis are necessary to better justify the claims made in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the results in Table 2 are insufficient to prove the benefits of the proposed methods, as the proposed approaches only outperform the baselines in one out of three setups and there is no consistent trend. The reviewer supports this claim by stating that additional experiments or more in-depth analysis are necessary to justify the claims. However, the comment lacks specific examples or references to support the need for additional experiments or analysis, making it somewhat verifiable. The authors would need to infer the specific areas where more analysis is required, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the results presented in Table 2, noting that the proposed approaches only outperform the baselines in one out of three setups and that there is no consistent trend in the results. This observation highlights a significant weakness in the paper's claims, as the results do not sufficiently support the benefits of the proposed methods. The comment suggests that additional experiments or more in-depth analysis are necessary to better justify the claims made in the paper. This feedback is clear and actionable, providing the authors with a specific direction for improving their draft by enhancing the robustness and clarity of their experimental findings. However, the comment could be more helpful if it offered specific suggestions on how to conduct additional experiments or what aspects of the analysis should be focused on. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a specific issue with the figures, noting that some figures are not self-explanatory and providing an example of Figure 4 where the lines \\\"No adapt\\\" or \\\"Finetune\\\" are covered by other lines without additional explanation. This feedback implies that the authors should provide additional explanations or clarify these figures to make them more understandable. While the action is not explicitly stated, it is clear and concrete, as the authors know exactly what needs to be done to improve the clarity of the figures. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, noting that the lines \\\"No adapt\\\" or \\\"Finetune\\\" are covered by other lines without additional explanation. This provides clear guidance on what needs to be addressed to improve the figure's clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that some figures are not self-explanatory, specifically mentioning Figure 4 where the lines \\\"No adapt\\\" or \\\"Finetune\\\" are covered by other lines without additional explanation. This claim is somewhat verifiable as it provides a specific example of an issue, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact nature of the problem and how it affects the figure's clarity. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the figures, noting that some are not self-explanatory and providing an example of Figure 4 where the lines \\\"No adapt\\\" or \\\"Finetune\\\" are covered by other lines without additional explanation. This feedback is clear and actionable, as it points out a clear area for improvement in the presentation of the figures. By addressing this issue, the authors can enhance the clarity and accessibility of their figures, which is crucial for effective communication of their findings. However, the comment could be more helpful if it provided suggestions on how to improve the figures or explained the specific problem in more detail. Overall, the comment is mostly helpful, as it effectively directs the authors to a critical area needing attention, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights the importance of the sampling method for convergence to the optimum but notes that it is not experimentally evaluated carefully on the proposed benchmarks, except for Table 1 in the supplementary material. While the comment implies that the authors should conduct more thorough experiments to evaluate the sampling method, it does not explicitly instruct them to do so or provide guidance on how to conduct these experiments. The action is implicit and somewhat vague, as the authors need to infer that they should perform additional experiments but lack specific instructions on how to proceed. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment highlights the importance of the sampling method for convergence to the optimum and notes that it is not experimentally evaluated carefully on the proposed benchmarks, except for Tab. 1 in the supplementary material. This provides a clear indication of what needs to be addressed, specifically the lack of experimental evaluation of the sampling method. However, the comment does not specify which part of the paper should include this evaluation or how it should be conducted, making it weakly grounded. The comment is specific in detailing what is missing, but without clear guidance on where to address it, it aligns with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the sampling method is important for convergence to the optimum but notes that it is not experimentally evaluated carefully on the proposed benchmarks, except for Tab. 1 in the supplementary material. This claim is somewhat verifiable as it provides a specific reference to the supplementary material and highlights a gap in the experimental evaluation. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the supplementary material to understand the full context of the claim.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment highlights an important aspect of the paper, specifically the sampling method used to obtain different initializations, which is crucial for convergence to the optimum. It points out that this aspect is not experimentally evaluated carefully on the proposed benchmarks, except for a comparison in Table 1 of the supplementary material. This feedback is valuable as it identifies a gap in the experimental evaluation that could impact the validity and robustness of the results. However, the comment could be more helpful if it provided suggestions on how to conduct a more thorough evaluation or what specific aspects of the sampling method should be examined. Overall, the comment is somewhat helpful as it directs the authors' attention to an important area for improvement, but it lacks detailed guidance on how to address the issue.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with methods [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with only one of the methods. While the comment highlights areas of confusion and lack of discussion, it does not provide explicit actions or suggestions for the authors to address these issues. The authors can infer that they need to clarify the logic and provide further discussion on the comparisons, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with methods [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with only one of the methods. While the comment does not explicitly mention specific sections, the authors can infer that it relates to the methodology or results sections where these comparisons are discussed. The comment is specific in detailing what needs to be addressed regarding the logic and comparisons, but it lacks full grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of a series of questions and observations about the logic and comparisons made in the paper. It does not present any subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises several questions about the logic and comparisons made in the paper, specifically regarding the proposed method and its comparison with methods [9] and [16]. It questions the rationale behind the order of comparisons and the focus on computational cost with only one of the methods. The comment highlights a potential issue with the paper's presentation and suggests that the authors should provide further discussion on the computational cost. While the comment identifies areas of confusion and suggests a need for clarification, it lacks specific guidance or actionable steps for the authors to address these issues. The feedback is somewhat helpful as it points out areas for improvement but does not offer detailed suggestions for enhancement. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point poses a question about the comparison between the PL condition used in the paper and the PL conditions proposed in a specific reference. While the question implies that the authors should provide a comparison, it does not explicitly instruct them to do so. Additionally, the comment lacks concrete guidance on how to conduct this comparison or what specific aspects should be considered. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment raises a question about the comparison between the PL condition used in the paper and the PL conditions proposed in a specific reference. However, it does not specify which part of the paper this comparison should be made, making it weakly grounded. The comment is specific in its request for a comparison with the referenced work, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of a question asking for a comparison between the PL condition used in the paper and those proposed in a specific reference. It does not contain any subjective claims, opinions, or suggestions that require verification. The statement is factual and seeks clarification, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the comparison between the PL condition used in the paper and those proposed in a specific reference. This is a relevant point that could help the authors contextualize their work within the existing literature. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this comparison or what aspects should be considered. While it points out an area for improvement, it does not offer actionable feedback, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a gap in the discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline. While the comment clearly identifies the need for additional analysis, it does not specify which aspects of the analysis should be included or how to conduct it. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment highlights a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It suggests providing this analysis for a fair comparison with the baseline. However, the comment does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the impact of additional parameters and computational effort. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that there is a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. The reviewer suggests that this analysis should be provided for a fair comparison with the baseline. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim. This lack of explicit evidence or justification makes the claim somewhat verifiable, as the authors would need to infer the importance of this analysis without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant gap in the paper regarding the discussion of the impact of adding additional parameters and computational effort due to the multi-stage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that could enhance the validity and comprehensiveness of their findings. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment is mostly helpful as it highlights an important area for improvement and offers a clear direction for the authors to follow.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a lack of clarity in the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clear across different model architectures and notes the absence of theoretical evidence to support the correlation. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the analysis. The feedback is vague and lacks concrete steps for the authors to follow, leaving them uncertain about how to enhance their draft. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, indicating that the analysis is underwhelming. It points out that the trend is not clear across different model architectures and notes the absence of theoretical evidence to support the correlation. However, the comment does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for theoretical evidence and consideration of different model architectures. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, noting that the trend is not clear across different model architectures and lacks theoretical evidence. While the comment identifies a potential issue, it does not provide specific examples or detailed reasoning to support the claim. The lack of explicit evidence or references makes it challenging for the authors to fully understand and address the critique. Therefore, the comment is somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area of concern in the paper, namely the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the trend is not clear across different model architectures and notes the absence of theoretical evidence to support the correlation. This feedback is somewhat helpful as it highlights a potential weakness in the analysis and suggests that the authors should provide more comprehensive evidence or theoretical support for their claims. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to strengthen the analysis. Overall, the comment provides some direction for improvement but lacks detailed guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about potential information leakage in the experiments conducted with AutoAugment, noting that its policy is derived from supervised training on ImageNet. It also questions the implications of this for self-supervised learning (SSL) algorithms that aim to learn more generic representations. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks actionable details, such as recommending specific analyses or modifications to mitigate the potential issues. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 4.2\\\" and \\\"L114,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It raises a specific concern about potential information leakage in the experiments conducted with AutoAugment, noting that its policy is obtained through supervised training on ImageNet. The comment also questions the implications of this for self-supervised learning (SSL) algorithms that aim to learn more generic representations. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about potential information leakage in the experiments conducted with AutoAugment, noting that its policy is derived from supervised training on ImageNet. The reviewer questions whether this could be a setback for self-supervised learning (SSL) algorithms that aim to learn more generic representations. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim of information leakage or its implications for SSL algorithms. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully support the argument.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about potential information leakage in the experiments conducted with AutoAugment, noting that its policy is derived from supervised training on ImageNet. It questions whether this could be a disadvantage for self-supervised learning (SSL) algorithms that aim to learn more generic representations. The comment also references a specific conclusion in the paper regarding the importance of matching datasets for linear classification. However, the comment lacks actionable suggestions or guidance on how the authors might address these concerns or improve their draft. While it identifies potential issues, it does not provide a clear path for the authors to resolve them, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the empirical version of the objective (3) might be appropriate to include in the supplementary materials. This is an explicit suggestion, as it directly instructs the authors to consider moving this content to the supplementary materials. However, the comment does not provide further guidance on why this might be beneficial or how it could improve the draft. While the action is clear, the lack of additional context or rationale makes it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests moving the empirical version of the objective (3) to the supplementary materials. However, it does not specify which part of the paper discusses this objective, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding why this change would be beneficial or how it would improve the paper. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that the empirical version of the objective (3) might be appropriate to include in the supplementary materials. However, it does not provide any justification or reasoning for why this suggestion is necessary or beneficial. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is classified as \\\"1: Unverifiable.\\\"\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests that the empirical version of the objective (3) might be appropriate to include in the supplementary materials. This feedback is somewhat helpful as it provides a specific suggestion for improving the organization of the paper, which could enhance clarity and accessibility for readers. However, the comment lacks depth and does not explain why this change would be beneficial or how it might impact the overall understanding of the paper. Additionally, it does not provide any guidance on what specific aspects of the empirical version of the objective should be included in the supplementary materials. Therefore, while the comment offers a direction for improvement, it is incomplete and could be more actionable, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides a specific observation about the content of lines 180-182, noting that Corollary 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily imply that uncertainty sampling is not minimizing the expected convex surrogate. However, the comment does not offer any explicit or implicit suggestions for how the authors should address this observation or improve their draft. There is no guidance on whether this observation is a concern, if it needs to be clarified, or how the authors might address it. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (ln. 180--182) and a particular corollary (Corollary 10), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the claim that uncertainty sampling moves in descent directions of the expected 0-1 loss and how this does not necessarily mean that uncertainty sampling is not minimizing the expected convex surrogate. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes a claim that Corollary 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily imply that uncertainty sampling is not minimizing the expected convex surrogate. This claim is somewhat verifiable as it provides a logical reasoning based on the content of Corollary 10. However, it lacks specific examples or references to further substantiate the claim, which would make it easier for the authors to understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific observation about a particular claim in the paper, noting that Corollary 10 only demonstrates that uncertainty sampling moves in descent directions of the expected 0-1 loss, which does not necessarily imply that uncertainty sampling is not minimizing the expected convex surrogate. This feedback is valuable as it highlights a potential misunderstanding or misinterpretation in the paper's claims. However, the comment does not offer suggestions on how the authors might clarify or address this issue, which limits its helpfulness. While it points out an area for improvement, it lacks actionable guidance, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the performance improvement of the proposed methods, as shown in Figure 3, is not significant, with the largest improvement in the bank dataset being approximately 0.02. It also recommends using tables to directly show key improvements, which would be more intuitive and detailed. While the comment provides a clear suggestion to use tables for presenting improvements, it does not specify which specific improvements should be highlighted or how the tables should be structured. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"figure 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the performance improvement of the proposed methods is not significant, with the largest improvement in the bank dataset being approximately 0.02. Additionally, the comment suggests using tables to directly show key improvements, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the performance improvement of the proposed methods is not significant, as evidenced by the largest improvement in the bank dataset being approximately 0.02. This claim is supported by a reference to Figure 3, which provides a visual representation of the performance improvements. However, the comment does not provide specific data or detailed analysis from the figure to substantiate the claim fully. Additionally, it suggests using tables to show key improvements, which is a logical suggestion but not a claim requiring verification. Therefore, the comment is mostly verifiable, as it provides some support for the claim but lacks detailed evidence or references.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a concern regarding the significance of the performance improvement of the proposed methods, as shown in Figure 3. It specifically mentions that the largest improvement in the bank dataset is only approximately 0.02. The comment suggests that using tables to directly show key improvements would be more intuitive and detailed. This feedback is clear and actionable, as it provides a specific observation about the results and offers a constructive suggestion for improving the presentation of the data. By recommending the use of tables, the comment helps the authors enhance the clarity and impact of their results. However, it could be more helpful if it included additional guidance on how to effectively use tables or what specific improvements should be highlighted. Overall, the comment is mostly helpful, as it provides valuable insights and actionable feedback for improving the draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights several issues with the experimental validation, including the use of only shallow networks and the lack of description of the optimization strategy, including the grid search for hyperparameters. It also points out a minor issue regarding the positioning with respect to related works, specifically mentioning the consideration of layer redundancy in network pruning. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they need to expand their experimental validation and provide more details on the optimization strategy and related work. The action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses multiple issues related to the experimental validation, including the use of only shallow networks and the lack of description of the optimization strategy, including the grid search for hyperparameters selection. It also mentions a minor issue regarding the positioning with respect to related works, specifically mentioning the consideration of layer redundancy in network pruning. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it pertains to the experimental validation and related work sections. The comment is specific in detailing what needs to be addressed, such as the types of networks considered and the optimization strategy. However, since it does not explicitly mention the sections, it is weakly grounded but specific. Therefore, this comment aligns with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the experimental validation is not convincing, citing the use of only shallow networks and the lack of description of the optimization strategy, including the grid search for hyperparameters selection. The comment also points out a minor issue regarding the positioning with respect to related works, specifically mentioning the consideration of layer redundancy in network pruning. While the comment provides some reasoning and references a specific paper, it lacks detailed explanations or examples to fully substantiate the claims. The mention of the paper on layer redundancy provides a starting point, but more comprehensive evidence or examples would strengthen the claim. Therefore, the comment is somewhat verifiable, as it provides some support but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies several weaknesses in the experimental validation, specifically noting the use of only shallow networks and the lack of description of the optimization strategy, including the grid search for hyperparameters selection. It also points out a minor issue regarding the positioning with respect to related works, mentioning the consideration of layer redundancy in network pruning. While the comment highlights these areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The authors are informed of the weaknesses but are not provided with actionable steps to enhance their experimental validation or improve the positioning of their work. Therefore, the comment is somewhat helpful, as it provides some insight but lacks depth and specificity in its feedback.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment states that the technical contribution is limited, specifically noting the absence of significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the technical contribution are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the technical contribution is limited, specifically noting the absence of significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without such supporting evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out a significant issue with the paper's technical contribution, stating that it lacks significant technical contribution and extension based on a typical model for the cross-domain recommendation setting. However, it does not provide any specific suggestions or guidance on how the authors might address this issue or improve their work. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. While the suggestion is explicit, it lacks concrete details on how to implement this addition or what specific aspects should be highlighted. The authors are given a clear direction to include baselines, but the comment does not provide detailed guidance on how to execute this action effectively. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests adding fully-supervised baselines for small models in Table 1 to understand the gap between full supervision and SSL for these models. However, it does not specify which part of Table 1 should include these baselines, making it weakly grounded. The suggestion is specific in terms of what needs to be addressed\\u2014adding baselines to understand the gap between full supervision and SSL. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and SSL for these models. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this addition would be beneficial or how it would enhance the understanding of the gap. Without such justification, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests adding fully-supervised baselines for small models in Table 1 to better understand the gap between full supervision and self-supervised learning (SSL) for these models. This feedback is clear and actionable, as it provides a specific suggestion for improving the analysis and understanding of the models' performance. By including these baselines, the authors can gain a clearer picture of the effectiveness of SSL compared to full supervision. However, the comment could be more helpful if it provided additional context or rationale for why these baselines are important or how they might impact the interpretation of the results. Overall, the comment is mostly helpful as it offers a concrete step for the authors to enhance their draft, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point critiques the novelty of the approach, noting that the components used, such as the weak predictor (MLP, Regression Tree, or Random Forest) and the sampling strategy, are not novel and have been used in previous works. It also mentions that the results of the proposed WeakNAS are similar to those of BRP-NAS. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these concerns or improve the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the originality of the paper. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific components of the approach, such as the weak predictor (MLP, Regression Tree, or Random Forest) and the sampling strategy, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that these components are not novel and have been used in previous works, such as [2,3,7] and BRP-NAS[5]. Additionally, it references Table 2 in Appendix C to support the claim about the similarity of results. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the components of the approach are not novel, specifically mentioning the use of MLP, Regression Tree, or Random Forest as weak predictors, which have been used in previous works. It also notes that the sampling strategy is similar to epsilon-greedy and exactly the same as that in BRP-NAS. The comment further supports its claim by referencing specific works [2,3,7] and BRP-NAS[5], and by pointing out that the results of the proposed WeakNAS are almost the same as BRP-NAS. This detailed comparison and reference to existing literature provide a robust foundation for the claim, making it fully verifiable. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment points out that the components of the approach, such as the weak predictor and sampling strategy, are not novel and have been used in previous works. It specifically mentions that the weak predictor is similar to those used in NAS performance prediction and that the sampling strategy is exactly the same as in BRP-NAS. Additionally, it notes that the results of the proposed WeakNAS are almost the same as BRP-NAS. This feedback is somewhat helpful as it identifies a lack of novelty in the approach and provides references to previous works, which could guide the authors in understanding and addressing the issue. However, it does not offer specific suggestions or actionable steps for the authors to enhance the novelty or differentiate their work. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions about the OT sample selection process and the training steps, specifically asking whether the process runs once or iteratively. It suggests that adding more details and a flow chart would help readers understand the whole process. Additionally, it inquires about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection. While the comment implies that the authors should provide more details and a flow chart, it does not explicitly instruct them to do so. The action is concrete but communicated indirectly, making this comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"2.4.3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions about the OT sample selection process, the training steps, and the runtime for solving the entropic regularized discrete OT problem. The comment suggests adding more details and a flow chart to clarify the process, which provides clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the OT sample selection process and the training steps. It does not contain subjective opinions, judgments, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises important questions about the OT sample selection process and the training steps, specifically asking whether the process runs once or iteratively. It suggests that adding more details and a flow chart would help readers understand the entire process, which is a valuable suggestion for improving clarity. Additionally, the comment inquires about the runtime for solving the entropic regularized discrete OT problem and the runtime for OT sample selection, which are relevant details for understanding the computational aspects of the method. While the comment identifies key areas for clarification and improvement, it could be more helpful by providing specific suggestions on how to present this information. Overall, the feedback is mostly helpful as it directs the authors to enhance the clarity and comprehensiveness of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a gap in the experimental section, noting that while the authors discuss how KG handles continuous tasks, there are no experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization derived in Section 7 of the appendix and asks how their empirical performance compares to ConBO. The comment implies that the authors should include experiments with continuous tasks and compare the empirical performance of the mentioned methods. While the action is implicit, it is concrete because it specifies what needs to be done\\u2014adding experiments and comparisons. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the discussion of how KG handles continuous tasks and the derivation of entropy methods for conditional optimization in Section 7 of the appendix. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific as it raises questions about the lack of experiments with continuous tasks and the comparison of empirical performance with ConBO. It clearly specifies what needs to be addressed, providing the authors with clear guidance on how to improve their draft. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the absence of experiments with continuous tasks, despite the authors' discussion of how KG handles such tasks. It also questions the inclusion of entropy methods for conditional optimization derived in Section 7 of the appendix and asks for a comparison of their empirical performance with ConBO. The comment is somewhat verifiable as it raises valid questions about the experimental setup and the inclusion of specific methods, but it lacks detailed reasoning or references to support the claims. The authors would need to make a significant effort to understand and address the concerns raised, making the comment somewhat verifiable. Therefore, it aligns with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a gap in the experimental section, noting that while the authors discuss how KG handles continuous tasks, there are no experiments with continuous tasks. It also questions the inclusion of entropy methods for conditional optimization derived in Section 7 of the appendix and asks for a comparison of their empirical performance with ConBO. This feedback is clear and actionable, as it prompts the authors to include experiments with continuous tasks and to compare the empirical performance of the mentioned methods. By addressing these points, the authors can significantly enhance the comprehensiveness and impact of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises two specific questions: how the precision/recall/F1-score was calculated for the 4-class classification of breast density, and whether providing AUC results would be more informative for comparing model performance. The first question implies that the authors should clarify their methodology for calculating these metrics. The second question suggests that including AUC results could enhance the evaluation of the model. While the actions are implied, they are relatively clear and direct, providing the authors with specific areas to address. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment raises two specific questions: one about the calculation of precision/recall/F1-score for a 4-class classification of breast density and another about the suggestion to include AUC results for breast cancer detection. However, it does not specify which part of the paper these questions pertain to, such as a particular section or table where these calculations or results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be clarified or improved. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the methodology used for calculating precision/recall/F1-score and suggests an alternative evaluation metric (AUC) for comparing model performance. It does not contain any subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises two specific questions regarding the methodology used in the paper. First, it asks how the precision/recall/F1-score was calculated for the 4-class classification of breast density, which could help clarify the methodology and ensure transparency. Second, it suggests that providing AUC results would be more informative for comparing model performance, as is common practice in the field of breast cancer detection. This feedback is clear and actionable, as it directs the authors to consider additional metrics and clarify their methodology, which could enhance the comprehensiveness and comparability of their results. However, the comment could be more helpful if it provided specific guidance on how to incorporate these suggestions into the paper. Overall, the comment is mostly helpful, as it offers valuable insights and directions for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment critiques the novelty of using a transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also mentions that the authors' modification, specifically the cross-layer aspect, does not provide significant insight into machine learning. The reviewer further points out that the ablation study shows limited improvement from self-cross attention, suggesting that the main improvements come from using a naive transformer rather than the proposed modification. While the comment provides some critique and observation, it does not offer explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to enhance the novelty or significance of the work, nor are there suggestions for additional experiments or analyses that could be conducted. As a result, the comment lacks actionability, leaving the authors without clear steps to improve their draft. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the use of a transformer and the ablation study (table4 and 5), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it critiques the novelty of using a transformer in the field, questions the significance of the cross-layer modification, and points out the limited improvement from self-cross attention. The comment provides clear guidance on what needs to be addressed, such as the lack of novelty and the need for more significant improvements. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point critiques the novelty of using a transformer in the context of NLP and vision tasks, noting that it is no longer novel. It also questions the significance of the proposed modification, specifically the cross-layer aspect, and points out that the ablation study shows limited improvement from self-cross attention. The comment suggests that the main improvements come from using a naive transformer rather than the proposed modification. While the comment provides some reasoning and observations, it lacks specific references or detailed examples to fully substantiate the claims. This makes the comment somewhat verifiable, as it provides a basis for the critique but requires additional evidence or references for full verification.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a critical evaluation of the paper's approach, particularly regarding the use of a transformer in the context of NLP and vision tasks. It questions the novelty of the transformer's adoption in these fields and critiques the significance of the proposed modification, specifically the cross-layer aspect. The comment also points out that the ablation study shows limited improvement from self-cross attention, suggesting that the main improvements come from using a naive transformer rather than the proposed modification. This feedback is somewhat helpful as it identifies potential weaknesses in the paper's approach and highlights areas for improvement. However, it lacks specific suggestions or actionable steps for the authors to address these concerns, such as recommending alternative approaches or providing more detailed analysis. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly suggests that the authors should conduct experiments on more types of sentence pair tasks, specifically mentioning MNLI and RTE as examples. This provides a clear and direct action for the authors to take, as well as concrete guidance on which tasks to include. The feedback is specific and actionable, giving the authors a clear path to enhance their experimental evaluation. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the experiments conducted by the authors, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the limitation of the experiments being limited to sentence similarity tasks and open domain QA tasks, and suggests conducting experiments on more types of sentence pair tasks, such as MNLI and RTE. This provides clear guidance on what additional experiments should be included. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the experiments are limited, specifically mentioning that the authors only conduct evaluations on sentence similarity tasks and open domain QA tasks. It suggests that there are other tasks involving sentence pairs, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. The comment provides a logical reasoning by identifying specific tasks that are not covered, which supports the claim. However, it lacks references to these tasks or detailed explanations of why they are important, making the claim somewhat verifiable. The authors would benefit from more detailed justification or references to fully understand and address the critique.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the scope of the experiments conducted by the authors, noting that they only evaluate on sentence similarity tasks and open domain QA tasks. It suggests that there are other tasks involving sentence pairs, such as sentence inference tasks like MNLI and RTE, which are common in the NLP field. By recommending the inclusion of these additional tasks, the comment provides clear and actionable feedback that can help the authors enhance the comprehensiveness and generalizability of their experimental evaluation. This guidance is valuable for improving the draft, making the comment mostly helpful. However, it could be further improved by offering more detailed suggestions on how to incorporate these tasks or by explaining the potential benefits of doing so. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to include the prompt in the appendix or supplement, suggesting that it might have been overlooked. This is a clear and direct action for the authors to take. However, the comment does not provide specific guidance on how to present the prompt or where exactly it should be placed in the appendix or supplement. While the action is explicit, the lack of detailed instructions on execution makes it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the appendix or supplement, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the absence of the prompt in the appendix or supplement, and suggests that it might have been overlooked. Additionally, the minor comments provide further guidance on improving the abstract and figure clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a request for clarification regarding the inclusion of the prompt in the appendix or supplement, along with minor comments about the abstract and figure clarity. These are factual observations and requests for information, not claims or opinions that require verification. Therefore, the classification \\\"No\\\" is appropriate.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment is somewhat helpful as it identifies a specific issue regarding the inclusion of the prompt in the appendix or supplement, suggesting that it might have been overlooked. This feedback is actionable, as it directs the authors to a particular area that needs attention. However, the comment lacks depth and does not provide further guidance or suggestions on how to address the issue, such as specific reasons why the prompt is important or alternative placements. Additionally, the minor comments about the abstract and figure clarity are not actionable, as they do not offer constructive feedback for improvement. Overall, the comment provides some value but could be more comprehensive and detailed to be fully helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a potential misunderstanding in the introduction regarding the claim that \\\"these shape constraints do not require tuning a free parameter.\\\" It suggests that while the constraints themselves might not involve a free parameter, the choice of using a convex or concave constraint, or an increasing/decreasing constraint, can be considered a hyperparameter that needs to be chosen or tuned. However, the comment does not provide explicit guidance or suggestions on how the authors should address this point or clarify their claims. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the introduction, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the claim about shape constraints not requiring tuning a free parameter, suggesting that the choice of using convex or concave constraints, or increasing/decreasing constraints, can be considered a hyperparameter that needs to be chosen or tuned. This provides clear guidance on what aspect of the claim is being critiqued. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point challenges the claim made in the introduction regarding the absence of tuning a free parameter for shape constraints. It argues that while the constraints themselves might not involve a free parameter, the choice of using convex or concave constraints, or increasing/decreasing constraints, can be considered a hyperparameter that needs to be chosen or tuned. This reasoning is logical and provides a clear explanation of why the claim might be misleading. However, the comment could be strengthened by providing specific examples or references to support the argument further. As it stands, the claim is mostly verifiable due to the logical reasoning provided, but it lacks detailed evidence or references, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential misunderstanding in the introduction regarding the claim that \\\"these shape constraints do not require tuning a free parameter.\\\" It points out that while the constraints themselves might not involve a free parameter, the choice of using convex or concave constraints, or increasing/decreasing constraints, can be considered a hyperparameter that needs to be chosen or tuned. This feedback is clear and actionable, as it highlights a specific area where the authors' explanation could be improved for clarity and accuracy. By addressing this point, the authors can enhance the precision of their claims and improve the overall quality of their draft. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment critiques the triviality of the convergence proof and suggests that it lacks substantial novelty and rigor. It points out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, and that modifications can trivially adapt previous theorems. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the proof. The feedback lacks concrete suggestions or specific actions for the authors to take, leaving them uncertain about how to enhance the theoretical contribution of their work. As a result, the comment is vague and unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the theoretical proof for convergence, specifically mentioning Assumption 4.1 and the implications of $X$ being i.i.d. leading to a clear covariance matrix for $Z$. It also references Modification 1 in Appendix C, suggesting that previous theorems can be adapted with straightforward modifications. This provides a clear indication of the specific part of the paper being discussed, making the comment fully grounded. Additionally, it specifies the issue with the proof's triviality and lack of novelty and rigor, offering a clear direction for improvement. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the theoretical proof for convergence is trivial and lacks substantial novelty and rigor. It supports this claim by pointing out that Assumption 4.1 indicates that $X$ is i.i.d., leading to a clear covariance matrix for $Z$. The reviewer further suggests that modifications can trivially adapt previous theorems, implying that the proof is not novel. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the reasoning to fully understand and address the critique.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the theoretical proof for convergence, noting that it appears trivial and lacks substantial novelty and rigor. It points out that the assumption of $X$ being i.i.d. leads to a clear covariance matrix for $Z$, and that modifications can trivially adapt previous theorems. This feedback is valuable as it highlights a critical weakness in the paper's theoretical foundation, prompting the authors to reconsider and strengthen their proof. However, the comment could be more helpful if it provided specific suggestions on how to enhance the proof's novelty or rigor, or offered guidance on alternative approaches. Overall, the comment is somewhat helpful as it directs the authors' attention to a key area needing improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies a potential conflict between two statements regarding the multi-environment model: one claims an inevitable performance loss, while the other claims outperformance due to knowledge sharing. The reviewer explicitly asks for clarification, which provides a clear and direct action for the authors to take. However, the comment does not offer specific guidance on how to resolve this conflict or what aspects need clarification. While the action is explicit, it lacks concrete details on how to address the issue, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the statements regarding the multi-environment model, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue of conflicting statements regarding performance loss and outperformance due to knowledge sharing. The comment requests clarification on these conflicting statements, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point identifies a potential conflict between two statements regarding the multi-environment model: one claims an inevitable performance loss, while the other claims outperformance due to knowledge sharing. The comment requests clarification on this apparent contradiction. While the comment highlights a potential issue, it does not provide any supporting evidence or reasoning to substantiate the claim of conflict. The authors are left to infer the basis of the conflict, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential conflict between two statements regarding the multi-environment model: one claims an inevitable performance loss, while the other claims outperformance due to knowledge sharing. By pointing out this inconsistency, the comment highlights a critical area that requires clarification in the paper. However, while it identifies the issue, it does not provide specific suggestions or guidance on how the authors might address this conflict or clarify the statements. The feedback is somewhat helpful as it directs the authors' attention to an important aspect of their work, but it could be more beneficial with additional guidance on how to resolve the conflict. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a lack of motivation for the applications of the proposed algorithms and notes that the datasets used are static, which limits the paper's usefulness. While it identifies a gap in the motivation, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to motivate the applications and consider dynamic datasets, but the comment does not offer concrete steps or suggestions on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses two main issues: the lack of motivation for the applications of the algorithms and the use of static datasets instead of streaming datasets. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding motivation and dataset choice, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks motivation for the applications of the algorithms and that the datasets used are static, which limits the paper's usefulness. The comment provides some reasoning by pointing out the absence of motivation for the applications and the use of static datasets. However, it does not provide specific examples or references to support the claim about the lack of motivation or the limitations of using static datasets. This makes the claim somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the paper's motivation and applicability. It points out that while the paper aims to design fast label aggregation algorithms for a streaming setting, it lacks motivation for the applications in which such algorithms are needed. Additionally, it notes that the datasets used in the empirical analysis are static, which limits the paper's usefulness. The comment highlights the need for a clear motivation and suggests that the problem should be better defined to enhance the paper's relevance and impact. However, it does not provide specific suggestions or guidance on how to address these issues, such as recommending particular applications or datasets. While the feedback is valuable in identifying areas for improvement, it could be more helpful with additional guidance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights that the scope of the study is under-specified and suggests that the work focuses on injecting a CoT-based approach to small-scale Language Models. It implies that additional relevant CoT baselines for in-context learning of Large Language Models (for text-003 and ChatGPT) are missing in Table 2 and 3. However, the comment does not explicitly instruct the authors to include these baselines or provide guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should add the missing baselines and determine how to do so. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 2 and 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the scope of the study is under-specified and suggests that additional relevant CoT baselines for in-context learning of Large Language Models are missing. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the scope of the study is under-specified and suggests that the work focuses on injecting a CoT-based approach to small-scale Language Models. It further implies that additional relevant CoT baselines for in-context learning of Large Language Models are missing in Table 2 and 3. However, the comment lacks specific examples or references to support the claim about the missing baselines, making it somewhat verifiable. The authors would need to infer the missing baselines and understand the reasoning behind the claim, which requires additional effort to address the feedback. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the paper's scope, noting that it is under-specified and appears to focus on a small-scale Language Model. It suggests that additional relevant CoT baselines for in-context learning of Large Language Models, such as text-003 and ChatGPT, are missing in Tables 2 and 3. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the comprehensiveness and relevance of their study. By addressing this point, the authors can improve the clarity and depth of their work. However, the comment could be more helpful if it included suggestions on how to incorporate these baselines or why they are important. Overall, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \\\"nice\\\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. However, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this observation should be addressed, clarified, or expanded upon in the paper. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \\\"nice\\\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This provides clear guidance on what aspect of the introduction needs further clarification or connection to recent findings. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a question asking for clarification about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \\\"nice\\\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the connection between the statement in the introduction regarding the difficulty of tensor decomposition in the symmetric case and recent findings about the \\\"nice\\\" landscape of the objective function associated with the decomposition of symmetric (orthogonal) order-4 tensors. This question prompts the authors to clarify or expand on their discussion, which could enhance the depth and relevance of their introduction. However, the comment does not provide specific suggestions or guidance on how to address this connection, making it somewhat helpful. It identifies an area for improvement but lacks actionable advice, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the scalability of the performance as the maximum number of identities increases, as shown in Table 3(a). It suggests that the capacity should be preset to a small number, such as 10, and questions how to scale up without compromising performance. While the comment implies that the authors should consider scalability issues, it does not provide explicit guidance or concrete steps on how to address this concern. The action is implicit and somewhat vague, as the authors need to infer that they should explore scalability solutions without specific instructions. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 3 (a),\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of performance degradation with increasing numbers of identities and suggests a potential solution by presetting the capacity to a small number. The comment further questions how to scale up without compromising performance, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the scalability of the performance as the maximum number of identities increases, as shown in Table 3(a). The reviewer suggests that the capacity should be preset to a small number, such as 10, and questions how to scale up without compromising performance. While the comment provides a logical reasoning based on the observed performance degradation, it lacks specific examples or references to support the claim about scalability. The suggestion to preset the capacity to a small number is a reasonable hypothesis, but the comment does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it requires further elaboration to fully validate the argument.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the scalability of the performance as the maximum number of identities increases, as shown in Table 3(a). It highlights a potential limitation in the capacity presetting and questions how to scale up without compromising performance. This feedback is valuable as it prompts the authors to consider the scalability of their approach and explore potential solutions. However, the comment could be more helpful if it provided specific suggestions or strategies for addressing the scalability issue. While it offers a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is rated as mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment questions the authors' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or improve their draft. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to clarify or rectify the issue. Without specific advice or direction, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment questions the authors' claim about their work being one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not specify which part of the paper this claim is made, nor does it provide details on what aspects of the approach are not NLP-specific. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point questions the authors' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not provide any supporting evidence, reasoning, or examples to justify why the approach is not NLP-specific. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment questions the authors' claim that their work is one of the preliminary works discussing the application of LLP to NLP tasks. However, it does not provide any specific feedback or suggestions on how the authors might address this concern or clarify their approach. Without actionable guidance or detailed critique, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that several curriculum learning methods have been discussed in Section 1 but does not justify the need for designing a new curriculum learning method for text graphs. It also notes that the research gap, such as why existing methods cannot be applied, is not discussed. While the comment highlights areas that need attention, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to justify the need for a new method and discuss the research gap, but the comment lacks concrete suggestions on how to do so. Therefore, the action is implicit and somewhat vague, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of justification for designing a new curriculum learning method for text graphs and the absence of a discussion on the research gap, such as why existing methods cannot be applied. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the need for designing a new curriculum learning method for text graphs is not justified, and it highlights the lack of discussion on the research gap, such as why existing methods cannot be applied. While the comment identifies a potential gap in the paper, it does not provide specific examples or references to support the claim. The reasoning is somewhat verifiable, as it points out a logical gap in the argument, but it lacks detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a gap in the paper regarding the justification for designing a new curriculum learning method for text graphs. It points out that while several curriculum learning methods have been discussed, the need for a new method is not adequately justified, and the research gap, such as why existing methods cannot be applied, is not discussed. This feedback is somewhat helpful as it highlights a critical area that the authors need to address to strengthen their argument. However, it lacks specific suggestions or guidance on how to justify the need for a new method or how to discuss the research gap. Providing more detailed feedback or examples would make the comment more actionable and helpful for the authors. Therefore, it is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the writing could be improved in certain areas, specifically pointing out a difficulty in interpreting definition 2.1 regarding \\\"relevant\\\" auxiliary model weights. While the comment identifies a specific issue, it does not provide explicit guidance on how to improve the writing or clarify the definition. The action is implicit, as the authors can infer that they need to revise the explanation, but it remains vague because it lacks concrete steps or suggestions on how to achieve this improvement. Therefore, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"definition 2.1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the difficulty in interpreting the definition regarding \\\"relevant\\\" auxiliary model weights, providing clear guidance on what needs to be clarified. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the writing could be improved, specifically mentioning difficulty in interpreting definition 2.1 regarding \\\"relevant\\\" auxiliary model weights. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the current definition is difficult to interpret. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area where the writing could be improved, pointing out that definition 2.1 is difficult to interpret due to the unclear explanation of \\\"relevant\\\" auxiliary model weights. This feedback is somewhat helpful as it highlights a particular issue that the authors can address to enhance the clarity of their paper. However, the comment lacks depth and does not provide suggestions or guidance on how to improve the explanation or make it more accessible. To be more helpful, the comment could include specific suggestions or examples of how to clarify the definition. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the quantitative evaluation results, noting that they only reflect middle outputs rather than the final outputs. It suggests that the current evaluations are not convincing enough to confirm ModelAngelo's superiority over competitors. The reviewer explicitly asks whether a quantitative comparison on the final outputs is possible. This direct question implies that the authors should consider including such a comparison to strengthen their evaluation. The action is explicit and concrete, as it clearly instructs the authors on what additional analysis to conduct. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3\\\" and \\\"Figure 4,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the quantitative evaluation results, noting that they only reflect middle outputs rather than final outputs, and suggests that a quantitative comparison on the final outputs would be more convincing. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the validity of the quantitative evaluation results, noting that they only reflect middle outputs rather than final outputs. The reviewer suggests that a comparison on final outputs would be more convincing. While the comment raises a valid concern about the evaluation's comprehensiveness, it lacks specific examples or references to support the claim that the current evaluations are insufficient. The suggestion to include final outputs is logical, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the quantitative evaluation results, noting that they only reflect middle outputs rather than final outputs. It also points out that Figure 4 compares final results with a single data sample, which may not be sufficient to confirm ModelAngelo's superiority over competitors. The comment suggests that a quantitative comparison on the final outputs would be more convincing. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a more comprehensive evaluation. However, it could be further enhanced by offering additional guidance on how to conduct this comparison or by suggesting specific metrics to consider. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their evaluation methodology.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies several issues with the paper, including the qualitative nature of the explanations, minimal or missing procedures for simulation or experiment-based evidence, confusing figures (e.g., \\\"sample count\\\" in Figure 2), and the lack of error bars or p-values in statistical inferences. The reviewer explicitly suggests adding more details to the paper and/or supplementary information to clarify the procedures and statistical inferences. While the comment provides a clear direction for improvement, it lacks specific guidance on how to address each issue, such as what additional details should be included or how to present the figures more clearly. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"fig. 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the explanations, the minimal or missing procedures for simulations or experiments, and the confusion regarding the \\\"sample count\\\" in Figure 2. Additionally, it suggests adding more details to the paper and/or supplementary information to clarify the procedures and statistical inferences, including the need for error bars and/or p-values. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the explanations in the paper are qualitative and that the procedures for simulations or experiments are described minimally or not at all. It also mentions that some figures are confusing, such as the \\\"sample count\\\" in Figure 2, and suggests adding more details to the paper or supplementary information. Additionally, it points out the absence of error bars or p-values in statistical inferences. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The suggestion to add more details and clarify figures is logical, but the lack of specific examples or references makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies several areas for improvement in the paper, specifically focusing on the qualitative nature of the explanations and the lack of detail in the procedures for simulations or experiments. It points out that some figures are confusing and suggests adding more details to clarify the procedures. Additionally, it highlights the absence of error bars or p-values in statistical inferences, which are crucial for understanding the results. The comment provides clear and actionable feedback, guiding the authors on how to enhance the clarity and rigor of their paper. However, it could be more helpful by offering specific suggestions on how to improve the explanations or figures. Overall, the comment is mostly helpful, as it effectively directs the authors toward significant improvements in their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback provides a clear and explicit action for the authors to take, which is to include specific settings and comparisons with existing work. The suggestion is concrete, as it outlines exactly what needs to be done to enhance the paper. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to provide a single review of the various advances in the area, which adds clarity to the feedback. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the paper could be improved by explicitly showing the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. However, the comment does not provide specific examples or detailed reasoning to support why this would be beneficial or how it would help the community. The lack of explicit examples or references makes it difficult for the authors to understand the basis of the suggestion and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient detail to be fully actionable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment suggests a specific improvement by recommending that the paper explicitly show the settings for the various knobs of the algorithm to mimic prior work, such as Dagger and searn. This feedback is actionable and provides a clear direction for enhancing the paper's contribution to the community by offering a single review of the advances in the area. However, the comment could be more helpful if it included specific examples or guidance on how to implement these suggestions. Overall, the feedback is mostly helpful as it identifies a meaningful area for improvement and offers a constructive suggestion, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights an area of uncertainty regarding the generalizability of the biases discussed in the paper, specifically in section 3.2 and Theorem 1. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the clarity of their presentation. The comment lacks actionable guidance, leaving the authors without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 3.2\\\" and \\\"Theorem 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the lack of clarity regarding the generalizability of the biases discussed, which is a specific concern. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the clarity of the paper regarding the generalizability of biases discussed in specific sections and theorems. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment lacks detailed justification or references that would help the authors understand the basis of the concern or how to address it. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area of confusion regarding the generalizability of biases discussed in the paper, particularly in section 3.2 and Theorem 1. It highlights that while the paper acknowledges the potential for bias, it lacks clarity on how common these situations are. This feedback is somewhat helpful as it points out a critical area that needs further elaboration or clarification in the paper. However, it does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing additional analysis or examples to demonstrate the generalizability of the biases. Therefore, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that Section 3.1 on 3D Gaussian generation appears to follow the previous work, Luciddreamer, and questions whether there is any additional novel effort in this section. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their work. The comment lacks actionable guidance, such as recommending ways to differentiate the current work from the previous one or suggesting additional novel contributions. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Sec. 3.1 for 3D Gaussians generation,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether there is any additional novel effort in this section, as it seems to follow the previous work, Luciddreamer. This provides clear guidance on what aspect of the section needs further clarification or differentiation. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that Section 3.1 on 3D Gaussian generation appears to follow the previous work, Luciddreamer, and questions whether there is any additional novel effort in this section. However, the comment does not provide any specific details or references to support this claim, such as examples of how the current work aligns with or differs from Luciddreamer. Without further elaboration or evidence, the claim remains vague and difficult for the authors to verify or address. Therefore, the comment is considered borderline verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment points out that Section 3.1 on 3D Gaussian generation appears to follow the previous work, Luciddreamer, and questions whether there is any additional novel effort in this section. While it identifies a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work from the previous one. The comment lacks actionable feedback, leaving the authors with only a vague indication of a problem to consider. Therefore, the comment is barely helpful, as it highlights an area for improvement but does not offer concrete steps for the authors to take.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights several issues with the use of MMD DRO, including the lack of a tractable exact equivalent reformulation, the crude upper bound in Theorem 3.1, and the restrictive assumption about the loss function \\\\(\\\\ell_f\\\\) belonging to the RKHS. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how to improve the tractability of MMD DRO, how to refine the upper bound, or how to address the restrictive assumption about the loss function. As a result, the authors are left without any actionable steps to follow, making the comment unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses specific issues related to the use of MMD DRO, including the lack of a tractable exact equivalent reformulation, the crude upper bound in Theorem 3.1, and the restrictive assumption about the loss function \\\\(\\\\ell_f\\\\) belonging to the RKHS. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the problems with MMD DRO and the issues with the upper bound and assumptions. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises several claims about the limitations of MMD DRO, including the lack of a tractable exact equivalent reformulation, the crude upper bound in Theorem 3.1, and the restrictive assumption about the loss function \\\\(\\\\ell_f\\\\) belonging to the RKHS. The reviewer provides logical reasoning by explaining why these are drawbacks, such as the impact of dropping the nonnegative constraint and the need for further approximation. However, the comment lacks specific references or detailed examples to fully substantiate these claims, making it somewhat verifiable. The authors would need to further explore these points to fully understand and address them, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies several significant issues with the use of MMD DRO, including the lack of a tractable exact equivalent reformulation, the crude upper bound in Theorem 3.1, and the restrictive assumption about the loss function \\\\(\\\\ell_f\\\\) belonging to the RKHS. These points are clearly articulated and provide the authors with specific areas to consider for improvement. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of alternative approaches. Despite this, the feedback is mostly helpful as it highlights critical weaknesses that the authors should consider, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly states that the Appendix H section should be reorganized to improve its readability. This is a clear and direct action for the authors to take, providing them with a specific goal to achieve. However, the comment does not provide detailed guidance on how to reorganize the section, such as suggesting specific changes or restructuring elements. While the action is explicit, the lack of concrete details on how to implement it makes it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment explicitly mentions \\\"Appendix H section,\\\" allowing the authors to accurately identify the part of the paper being addressed, which provides full grounding. However, the comment lacks specificity as it does not detail what aspects of the section are difficult to follow or how they should be reorganized. Without specific guidance on what needs to be reorganized, the authors may struggle to address the issue effectively. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.\",\n    \"grounding_specificity_label\": \"4\",\n    \"verifiability_rationale\": \"The review point claims that the Appendix H section should be reorganized to improve readability. However, it does not provide any specific reasoning or examples to support why the current organization is difficult to follow. Without detailed justification or evidence, the claim remains vague and lacks verifiability. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a specific issue with the Appendix H section, noting that it is difficult to follow. This feedback is actionable as it provides a clear direction for the authors to reorganize the section to improve its readability. However, the comment lacks detailed guidance on how to reorganize the section or what specific aspects are problematic. While it highlights an area for improvement, it does not offer comprehensive suggestions or examples, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a significant issue with the paper's reproducibility, noting that while it provides an intuitive understanding, it lacks the necessary technical details for reproduction. The reviewer explicitly states that more details, such as the number of units in the RNN implementation, are missing from both the paper and the supplementary material. This feedback provides a clear and concrete action for the authors to take, which is to include the missing technical details to enhance the paper's reproducibility. The comment is highly actionable because it specifies exactly what needs to be added to improve the draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment addresses the issue of reproducibility, specifically mentioning the lack of technical details required to reproduce the work. It highlights the need for details such as the number of units in the RNN implementation, which are not provided in the paper or supplementary material. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the methodology or results sections where these details would typically be found. The comment is specific in detailing what is missing, making it specific. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the paper lacks sufficient technical details for reproducibility, even with the provided pseudocode. The reviewer supports this claim by specifying what is missing, such as details about the RNN implementation (e.g., number of units) and other technical details. This provides a clear rationale for the claim, making it mostly verifiable. However, the comment could be strengthened by providing more specific examples or references to similar works that include such details. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the paper's reproducibility, noting that while it provides an intuitive understanding of the work, it lacks the necessary technical details for reproduction. The reviewer specifically mentions the absence of details about the RNN implementation, such as the number of units, and other technical aspects that are crucial for replicating the results. This feedback is clear and actionable, as it directs the authors to include the missing details to enhance the paper's reproducibility. However, the comment could be more helpful if it provided specific examples or suggestions on what additional details are needed. Overall, the comment is mostly helpful, as it effectively highlights a significant area for improvement but could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that Figure 1 would be improved by including error bars and/or conducting more random trials to potentially eliminate random fluctuations in the results. While the action is explicit, it lacks concrete details on how to implement these changes, such as specifying which error bars to include or how many additional random trials should be conducted. The authors are given a clear direction but without detailed guidance on execution, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the inclusion of error bars and/or more random trials to potentially eliminate random fluctuations in the results. This provides clear guidance on how to improve the figure. Therefore, this comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that Figure 1 would be stronger with error bars and more random trials to potentially eliminate random fluctuations in the results. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that error bars and more trials would effectively address the issue. The reasoning is somewhat verifiable, as it is based on common practices in data visualization and statistical analysis, but it could be strengthened with additional evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by suggesting improvements to Figure 1. It recommends adding error bars and conducting more random trials to potentially eliminate random fluctuations in the results. This guidance is clear and directly addresses a potential weakness in the presentation of the data, offering the authors a concrete way to enhance the clarity and robustness of their findings. By implementing these suggestions, the authors can improve the quality and reliability of their results. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors provide a brief introduction to energy models in the related work section, which is an explicit and concrete action. Additionally, it points out that Figure 1 lacks clarity regarding which points correspond to different learning rates and steps, which is also an explicit and concrete action. The reviewer also provides references, which could guide the authors in understanding the context. The combination of these explicit and concrete actions makes the comment highly actionable, as the authors know exactly what needs to be done to improve their draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests providing a brief introduction to energy models in the related work section, which is a specific suggestion for improvement. It also points out a lack of clarity in Figure 1 regarding the correspondence of points to different learning rates and steps. The comment is fully grounded as it explicitly mentions the \\\"related work section\\\" and \\\"Figure 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as clarifying the correspondence in Figure 1. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors provide a brief introduction to energy models in the related work section and points out a lack of clarity in Figure 1 regarding the correspondence of points to different learning rates and steps. The comment is somewhat verifiable as it identifies specific areas for improvement, such as the introduction of energy models and the clarity in Figure 1. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to infer the importance of these suggestions and how they could improve the paper.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by suggesting that the authors include a brief introduction to energy models in the related work section. This is a clear and constructive suggestion that can help improve the comprehensibility and context of the paper. Additionally, the comment points out a specific issue with Figure 1, where it is unclear which points correspond to different learning rates and steps. This feedback is valuable as it directs the authors to clarify a particular aspect of their work, which can enhance the reader's understanding. However, the comment could be more helpful if it provided additional guidance on how to effectively introduce energy models or clarify the figure. Overall, the comment is mostly helpful as it identifies key areas for improvement and offers clear suggestions, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies a problem with the first paragraph of the Introduction, noting that it is devoted to a general introduction of DNNs without mentioning drift. The reviewer suggests that this paragraph is not central to the paper's focus on detecting drift types and magnitude, and that it provides little valuable information to readers. This feedback provides a clear and direct action for the authors to take: they should revise the introduction to better align with the paper's core focus. However, the comment does not specify how to restructure the paragraph or what specific content should be included to address the issue. While the action is explicit, the lack of detailed guidance on how to implement it makes the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"first paragraph of the Introduction,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the paragraph is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper's focus. The comment provides clear guidance on what needs to be addressed, namely, the relevance and focus of the introduction. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the first paragraph of the Introduction is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper's focus. The reviewer argues that this paragraph provides little valuable information to readers. While the comment logically points out the mismatch between the introduction and the paper's focus, it lacks specific examples or references to support the claim that the paragraph is not central or valuable. This makes the claim somewhat verifiable, as the authors would need to infer the relevance and importance of the paragraph themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the introduction section, noting that it is devoted to a general introduction of DNNs without mentioning drift, which is central to the paper's focus. This feedback is clear and actionable, as it provides a direct suggestion for improving the draft by aligning the introduction with the paper's core focus. By recommending that the introduction should better reflect the paper's main contributions, the comment offers valuable guidance for the authors to enhance the coherence and relevance of their work. However, it could be more helpful if it provided specific suggestions on how to integrate drift-related information into the introduction. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly suggests improving the distinguishability of the curves in Figure 2 by using styles like dashed lines or adding color. This feedback provides a clear and concrete action for the authors to take, specifying exactly how they can enhance the figure's clarity. The authors know precisely what changes to make to improve the visual presentation of their data. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2 right,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a concrete way to improve the distinguishability of the curves by using styles like dashed lines or adding color. This provides clear guidance on how to enhance the figure's clarity. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests improving the distinguishability of curves in Figure 2 by using styles like dashed lines or adding color. However, it does not provide any supporting evidence or reasoning to justify why this change would be beneficial or necessary. The comment lacks detailed explanation or examples that would help the authors understand the impact of such changes on the figure's clarity. As a result, the claim is unverifiable due to the absence of supporting information or justification.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the clarity of Figure 2 by recommending the use of styles like dashed lines or adding color to distinguish between the different curves. This feedback is clear and directly addresses a potential issue with the figure's presentation, offering a concrete way for the authors to enhance the visual clarity of their results. By implementing this suggestion, the authors can improve the readability and interpretability of their figure, which is valuable for the overall quality of the paper. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to tone down the introduction and avoid calling the task \\\"language learning,\\\" instead recommending that it be described as \\\"feedback-driven QA in the form of a dialog.\\\" This provides a clear and direct action for the authors to take, specifying exactly what needs to be changed in the introduction. The comment is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment addresses the introduction section, providing a specific critique of the claims made there. It suggests that the authors should tone down the language learning aspect and instead describe the task as feedback-driven question answering in the form of a dialog. This provides clear guidance on what needs to be revised in the introduction. However, the comment does not specify which parts of the introduction are problematic, making it weakly grounded. Despite this, the comment is specific in detailing what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the claims made in the introduction are not aligned with the tasks and models evaluated, specifically suggesting that the task should be described as \\\"feedback-driven QA in the form of a dialog\\\" rather than \\\"language learning.\\\" This claim is somewhat verifiable as it provides a logical reasoning for the discrepancy between the introduction's claims and the actual evaluation. However, it lacks specific examples or references to support the assertion that the current description is inaccurate. The authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a clear critique of the introduction, pointing out that the claims made do not align with the tasks and models evaluated. It suggests that the authors should tone down the language learning aspect and instead describe the task as feedback-driven question answering in the form of a dialog. This feedback is actionable and offers a specific direction for revising the introduction to better reflect the actual content of the paper. By providing a clear and constructive suggestion, the comment empowers the authors to make significant improvements to their draft, making it highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of recent models and their performance metrics. However, it does not offer any explicit or implicit suggestions for improvement or guidance on how the authors might address this issue. The comment lacks actionable details, such as recommending ways to improve the performance or suggesting additional experiments or analyses. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 4,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear comparison of the performance on REC and RES with more recent models, such as GLaMM and UNINEXT, and their respective performance metrics. This level of detail helps the authors understand what needs to be addressed in the table. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the performance on REC and RES in Table 4 is behind more recent models, providing specific examples of recent models and their performance metrics. This claim is supported by explicit references to GLaMM and UNINEXT, along with their respective performance metrics, which adds credibility to the assertion. The detailed comparison with specific models and metrics makes the claim mostly verifiable, as it provides a clear basis for the authors to understand and address the issue. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the performance of the models presented in Table 4, noting that the results for REC and RES are behind more recent models. It provides specific references to recent models, GLaMM and UNINEXT, and their performance metrics, which helps the authors understand the context and the gap in their results. However, the comment does not offer suggestions on how to address this issue or improve the performance of the models. While it highlights a weakness, it lacks actionable guidance, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the term \\\"evidence\\\" used in the paper is too strong and recommends using a more appropriate term like \\\"Fig.\\\" However, the comment does not specify what exactly should be changed or how the authors should revise the text to improve clarity. The feedback is vague and lacks explicit instructions, leaving the authors uncertain about the exact changes needed to address the concern. As a result, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment refers to \\\"5,\\\" which suggests it is addressing a specific part of the paper, making it fully grounded. However, the comment lacks specificity as it does not provide details on what is meant by \\\"evidence\\\" or how it relates to the content of the paper. The suggestion to use \\\"Fig.\\\" instead of \\\"evidence\\\" is a minor point, but without further context or explanation, it does not provide clear guidance on what needs to be addressed. Therefore, this comment is fully grounded but under-specific, aligning with a score of 4.\",\n    \"grounding_specificity_label\": \"4\",\n    \"verifiability_rationale\": \"The review point suggests that the term \\\"evidence\\\" used in the paper is too strong and recommends using a more appropriate term like \\\"Fig.\\\" However, the comment does not provide any supporting reasoning or examples to justify why \\\"evidence\\\" is too strong or how \\\"Fig.\\\" would be a better alternative. This lack of detailed explanation or justification makes the claim unverifiable, as it does not provide sufficient information for the authors to understand or address the issue effectively. Therefore, the comment is classified as 1: Unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out a potential issue with the use of the term \\\"evidence\\\" in the paper, suggesting that it may be too strong and recommending a more appropriate term like \\\"Fig.\\\" However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or what alternative terms could be used. Without detailed suggestions or examples, the feedback is limited in its usefulness to the authors, making it barely helpful. Therefore, the comment aligns with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point states that the implementation of kernels uses OpenAI's Triton instead of CUDA and suggests that a full-page explanation is unnecessary due to well-known engineering improvements. While the comment provides a rationale for why a full-page explanation might be redundant, it does not explicitly instruct the authors to remove or reduce the explanation. The action is implied and somewhat vague, as the authors need to infer that they should consider the level of detail required for their explanation. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the implementation of kernels using OpenAI's Triton instead of CUDA and suggests that a full-page explanation is unnecessary due to well-known engineering improvements. However, it does not specify which part of the paper this observation pertains to, such as a specific section or figure where the explanation is located. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting that a full-page explanation is unnecessary, but without clear grounding, it does not provide detailed guidance on what needs to be revised. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the implementation of kernels uses OpenAI's Triton instead of CUDA and suggests that a full-page explanation is unnecessary due to well-known engineering improvements. However, the comment lacks specific references or detailed reasoning to support the claim about the necessity of a full-page explanation. Without concrete examples or evidence, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered borderline verifiable, as it provides some reasoning but lacks sufficient detail to be fully actionable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment points out that the implementation of kernels uses OpenAI's Triton instead of CUDA and suggests that a full-page explanation is unnecessary due to well-known engineering improvements. While this observation is relevant, the comment does not provide specific guidance on how the authors might address this issue or what aspects of the explanation could be reduced. It lacks actionable suggestions or detailed feedback that would help the authors improve their draft. As a result, the comment is somewhat helpful, as it identifies a potential area for simplification but does not offer comprehensive guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the analysis of neural networks contributes less, as the extension from linear models to wide fully-connected neural networks is considered trivial due to the existing NTK theorem. It also notes that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fully-connected neural networks. However, the comment does not provide any explicit or implicit suggestions for how the authors could address these issues or improve their analysis. There is no guidance on potential modifications, alternative approaches, or additional analyses that could be conducted to enhance the contribution of the work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections of the paper, \\\"Section 3.2\\\" and \\\"3.3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the analysis of neural networks contributes less and that the extension from linear models to wide fully-connected neural networks is trivial due to the existing NTK theorem. This provides clear guidance on what aspect of the analysis is lacking and why it is considered trivial. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the analysis of neural networks contributes less due to the trivial extension from linear models to wide fully-connected neural networks, as supported by the existing NTK theorem. This claim is somewhat verifiable as it provides a logical reasoning based on the existing NTK theorem, which is a well-established concept in the field. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it somewhat verifiable. The authors would need to further explore the implications of this reasoning to fully understand and address the critique.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential weakness in the paper's analysis of neural networks, noting that the extension from linear models to wide fully-connected neural networks is considered trivial due to the existing NTK theorem. It also points out that the work bypasses the core problem of overparametrized neural networks and only considers easy wide fully-connected neural networks. While the comment highlights an area that may need further exploration or justification, it lacks specific suggestions or guidance on how the authors might address these issues or improve their analysis. The feedback provides some insight into the limitations of the current approach but does not offer actionable steps for improvement. Therefore, the comment is somewhat helpful, as it identifies areas for potential enhancement but lacks depth and specificity.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment notes the absence of results with larger models like ResNet101/152, given that there are good performance results with ResNet50/34/18 on ImageNet classification. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include results with larger models, but it lacks concrete instructions on how to implement this suggestion or why these larger models are important. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the performance on ImageNet classification with ResNet50/34/18, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing\\u2014results with larger models like ResNet101/152. This provides clear guidance on what additional information or results the authors should include. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that there are no results with larger models like ResNet101/152, despite good performance with ResNet50/34/18 on ImageNet classification. This claim is somewhat verifiable as it highlights a gap in the results presented, but it lacks specific reasoning or examples to support why larger models are important or expected to perform differently. The authors might need to infer the significance of this omission, making the claim somewhat verifiable. Therefore, the comment aligns with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment points out a gap in the results presented in the paper, specifically the absence of performance results with larger models like ResNet101/152, despite good performance with ResNet50/34/18 on ImageNet classification. This feedback is somewhat helpful as it identifies a specific area where the paper could be improved by including results with larger models. However, the comment does not provide detailed guidance or suggestions on how to address this gap or why including these results would be beneficial. While it highlights an important aspect of the paper, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a potential issue with the clarity of the abstract and introduction, specifically regarding the terms \\\"relatively inexpensive\\\" and \\\"expensive to evaluate.\\\" However, it does not provide explicit guidance on how to address this confusion or suggest specific changes to improve clarity. The comment implies that the authors should clarify these terms, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"multi-fidelity framework and sequential design\\\" and the \\\"abstract\\\" and \\\"first line of the introduction,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the terminology used, pointing out the confusion between \\\"relatively inexpensive\\\" and \\\"expensive to evaluate.\\\" This provides clear guidance on what needs to be clarified or revised. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the clarity of terminology used in the abstract and introduction, specifically regarding the terms \\\"relatively inexpensive\\\" and \\\"expensive to evaluate.\\\" The reviewer provides a reference to a related work, Assessing Fire Safety using Complex Numerical Models with a Bayesian Multi-fidelity Approach (Stroh et al. 2017), which could help the authors understand the context and potentially address the confusion. However, the comment lacks a detailed explanation or direct comparison of how the terminology is used in the current paper versus the referenced work. This makes the claim somewhat verifiable, as it provides a starting point for the authors to address the issue but requires further elaboration to be fully actionable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the clarity of terminology used in the abstract and the introduction, specifically regarding the terms \\\"relatively inexpensive\\\" and \\\"expensive to evaluate.\\\" It provides a reference to a related work, which could help the authors understand the context and potentially address the confusion. However, the comment lacks specific suggestions on how to clarify these terms or improve the overall clarity of the paper. While it points out a specific area for improvement, it does not offer detailed guidance or actionable steps for the authors to take. Therefore, the comment is somewhat helpful, as it highlights an area for improvement but lacks depth and specificity.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to compare their results on the official COOC leader board using the blind test set, rather than relying on some not official test set or dev set. It also suggests that the paper should at least compare to other approaches that have been proposed since the related work was evaluated, referencing specific publications. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what changes to make to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"captioning experiment\\\" and the need to compare results on the official COOC leader board using the blind test set. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it provides detailed guidance on what needs to be addressed, including the need to compare results on the official COOC leader board and to consider other approaches that have improved since the related work was evaluated. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the paper's comparison to related work is insufficient, suggesting that the final results should be evaluated on the official COOC leader board using the blind test set. The reviewer provides specific references to the COOC challenge and its results, as well as mentions that other approaches have improved since the related work was evaluated. This detailed reference to external sources and specific results makes the claim fully verifiable, as it provides a clear and robust basis for the critique. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback regarding the captioning experiment. It highlights the need to compare results on the official COOC leader board using the blind test set, rather than relying on other datasets. The comment also suggests that the paper should at least compare to other approaches that have improved since the related work was evaluated, referencing specific publications. This guidance is clear and constructive, offering the authors a concrete direction for enhancing the rigor and comprehensiveness of their experimental comparisons. By addressing these points, the authors can significantly improve the quality and credibility of their work. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a concern about the reliability of the experimental results, specifically noting that the MSE is significantly smaller than the MAE in Table 1, which raises concerns about their validity. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the reliability of their results. There is no guidance on potential modifications, alternative analyses, or additional experiments that could be conducted to validate the findings. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results, noting that the MSE is significantly smaller than the MAE, which raises concerns about their validity. This provides clear guidance on what aspect of the results needs attention. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the experimental results are unreliable, particularly in Table 1, where the Mean Squared Error (MSE) is significantly smaller than the Mean Absolute Error (MAE). This claim is somewhat verifiable as it highlights a specific discrepancy in the results that could raise concerns about their validity. However, the comment lacks detailed reasoning or references to support why this discrepancy is problematic or how it affects the reliability of the results. Providing more context or examples would strengthen the claim, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the experimental results, noting that the Mean Squared Error (MSE) is significantly smaller than the Mean Absolute Error (MAE) in Table 1. This observation raises concerns about the validity of the results, which is a critical aspect of the paper's findings. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the reliability of their results. While it highlights a potential weakness, it lacks actionable advice, making it somewhat helpful but incomplete. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out a lack of novelty in the methodology, stating that the proposed meta algorithm is a direct extension of existing methods. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or enhance the novelty of their work. There is no guidance on potential modifications, alternative approaches, or additional elements that could be added to differentiate the methodology. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the novelty of the methodology, specifically mentioning that the proposed meta algorithm is a direct extension of existing methods. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the methodology lack novelty or how they could be improved. Without explicit references to sections, figures, or specific elements of the methodology, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the methodology lacks novelty, stating that the proposed meta algorithm is a direct extension of existing methods. However, the comment does not provide specific examples or references to existing methods that are being extended, nor does it offer detailed reasoning or evidence to support the claim of limited novelty. This lack of supporting information makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment points out a lack of novelty in the methodology, specifically noting that the proposed meta algorithm is a direct extension of existing methods. While this feedback identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or detailed critique, the authors are left with only a general understanding of the problem but no clear path to improvement. Therefore, the comment is barely helpful, aligning with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out a lack of clarity in the paper regarding the use of terms like \\\"wrong\\\" explanation. It suggests that the authors should clarify what these terms mean before using them. While the comment identifies an area that needs clarification, it does not provide specific guidance on how to address the issue or what specific aspects should be clarified. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the terms but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L248,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the meaning of \\\"wrong\\\" in the context of explanations and suggests that the paper should clarify what constitutes a good, bad, or wrong explanation. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the meaning of \\\"wrong\\\" in the context of an explanation, suggesting that the paper should clarify what constitutes a good, bad, or wrong explanation. However, the comment does not provide specific examples or references to support the claim that the explanation is unclear. While it identifies a potential issue, the lack of detailed justification or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is somewhat verifiable, as it highlights a potential issue but lacks sufficient evidence or reasoning to fully substantiate the claim.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific point of confusion in the paper regarding the use of the term \\\"wrong\\\" in relation to explanations. It suggests that the authors should clarify what constitutes a good, bad, or wrong explanation before using these terms. This feedback is clear and actionable, as it directs the authors to address a potential ambiguity in their language, which could improve the clarity and precision of their writing. However, the comment could be more helpful if it provided examples or suggestions on how to clarify these terms. Overall, the comment is mostly helpful as it highlights an area for improvement and provides a direction for the authors to enhance their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, especially concerning occupant comfort and energy efficiency. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the activities should be highlighted. The action is implicit, as the authors need to infer that they should expand on this topic, and it is somewhat vague because it lacks concrete steps on how to implement the suggested changes. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment highlights a specific area that the authors have not adequately covered, namely the types of activities captured in the datasets and their importance in smart homes, particularly from the perspective of occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in identifying what needs to be addressed regarding the types of activities and their importance, providing clear guidance on what the authors need to address. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand which aspects are missing or how to address the issue. The absence of detailed justification or evidence results in the comment being classified as \\\"1: Unverifiable,\\\" as it does not provide sufficient support for the claim.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a gap in the paper regarding the types of activities captured in the datasets and their importance in smart homes, particularly concerning occupant comfort and energy efficiency. This feedback is valuable as it highlights an area where the authors could enhance their work by providing more context and analysis. However, the comment lacks specific suggestions or guidance on how the authors might address this gap, such as recommending particular activities to focus on or how to present this information effectively. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a specific issue in Section 5.3, noting that a generator equipped with a standard R-GCN as a discriminator tends to collapse, while the proposed module does not. The reviewer explicitly states that the reason behind this difference is essential and should be shown to demonstrate how the proposed method differs from previous ones. The comment implies that the authors should provide an explanation or analysis of why the proposed module prevents the generator from collapsing. While the action is not explicitly stated, it is clear and concrete, as the authors know exactly what needs to be added to address the issue. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Sec 5.3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of the generator collapsing with a standard R-GCN discriminator and the proposed module not collapsing, highlighting the importance of explaining the mechanism behind this difference. The comment provides clear guidance on what needs to be addressed, making it fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the proposed module prevents a generator from collapsing, contrasting it with a standard R-GCN discriminator. The reviewer suggests that this difference is crucial and should be explained to demonstrate the mechanism of the proposed method. However, the comment lacks specific examples, detailed reasoning, or references to support the claim about the generator's behavior. Without these elements, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a general direction for improvement but lacks sufficient detail to be fully actionable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue in Section 5.3, noting that a generator equipped with a standard R-GCN as a discriminator tends to collapse, while the proposed module does not. It highlights the importance of explaining the mechanism behind this difference, which is essential for demonstrating how the proposed method differs from previous approaches. The comment is clear and actionable, as it directs the authors to provide an explanation or analysis of why the proposed module prevents the generator from collapsing. However, it could be more helpful if it offered suggestions on how to present this explanation or examples of similar analyses in other works. Overall, the comment is mostly helpful as it provides a clear direction for improvement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the originality of the article's reasoning and writing logic, noting similarities to a previous study. However, it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern, such as suggesting ways to differentiate their work or providing additional context. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment raises concerns about the originality of the article's reasoning and writing logic, comparing it to a previous study. However, it does not specify which parts of the article are similar to the mentioned study, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the reasoning or writing logic are similar to the previous study, or how the authors might address the originality concerns. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point raises a concern about the originality of the article's reasoning and writing logic, suggesting similarities to a previous study. However, it does not provide specific details or references to the previous study or the aspects of the current work that are similar. This lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. As a result, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment raises a concern about the originality of the article's reasoning and writing logic, noting similarities to a previous study. It questions whether the work is merely an extension of the previous study or if it introduces novel contributions. While this feedback highlights a potential issue, it lacks specific suggestions or guidance on how the authors might address this concern or differentiate their work. Without actionable advice or detailed insights, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the theoretical comparisons to adaptive learning of GPRGNN are unclear, but it does not provide any specific guidance or suggestions on how the authors should clarify these comparisons. The comment lacks explicit instructions or concrete details on what aspects of the comparisons are unclear or how the authors might address this issue. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the theoretical comparisons to adaptive learning of GPRGNN are unclear, but it does not specify which part of the paper this issue pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the comparisons are unclear or how they could be clarified. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that \\\"theoretical comparisons to adaptive learning of GPRGNN are not clear.\\\" However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a specific area of the paper that is unclear, namely the theoretical comparisons to adaptive learning of GPRGNN. However, it lacks depth and does not provide any guidance or suggestions on how the authors might clarify these comparisons or improve the clarity of the theoretical aspects. Without actionable feedback or specific examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is barely helpful, as it points out an issue but does not offer sufficient direction for improvement.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies a gap in the experiments section, specifically regarding the missing components of ablation studies related to different queries used in spatio-temporal representation. It suggests that the authors should include experiments and explanations for spatial, temporal, and summary queries, as these are key differences from VideoChatGPT and other works. The comment also poses a question about what would happen if only spatial, temporal, or summary queries were used. This feedback provides a clear and concrete action for the authors to take, specifying exactly what additional experiments and explanations are needed. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"Experiments - Ablation\\\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of experiments and explanations regarding the different queries used in spatio-temporal representation (spatial, temporal, and summary). The comment further suggests exploring scenarios with only spatial, temporal, or summary queries, providing clear guidance on what additional information is needed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the experiments section lacks a detailed explanation of the different queries used in spatio-temporal representation, specifically spatial, temporal, and summary queries. It implies that the absence of these components is a significant gap, as it is crucial for differentiating the work from VideoChatGPT and other similar studies. However, the comment does not provide specific examples or references to support this claim, nor does it explain why these components are important or how their inclusion would enhance the study. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to infer the importance of these components themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the experiments section, particularly regarding the missing components of ablation studies related to different queries used in spatio-temporal representation. It highlights the importance of spatial, temporal, and summary queries, which are key differentiators from VideoChatGPT and other works. The comment suggests exploring scenarios with only spatial, temporal, or summary queries, providing a clear direction for the authors to enhance their experimental analysis. This feedback is actionable and offers a concrete way for the authors to improve their draft by addressing a critical aspect of their work. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should mention the potential social impact of their work, specifically the risks associated with increased automation or the dual use of their method. While the comment implies that the authors should include a discussion on social impact, it does not provide explicit instructions or detailed guidance on how to incorporate this into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should address the social impact and determine the specific aspects to cover. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 379,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the authors' claim about the lack of negative social impacts and suggests that the authors could discuss the potential social impact of increased automation or the risks from the dual use of their method. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the authors' claim about the lack of negative social impacts of their work, suggesting that the authors should consider the potential risks associated with increased automation or the dual use of their method. The comment implies that the authors should address these potential impacts, but it does not provide specific examples or references to support the claim that there could be negative social impacts. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to further develop the rationale themselves. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment addresses a potential oversight in the paper regarding the societal impact of the work. It questions the authors' claim that there are no negative social impacts and suggests that the authors could discuss the potential risks associated with increased automation or the dual use of their method. This feedback is somewhat helpful as it prompts the authors to consider and address a critical aspect of their work that may have implications for its real-world application. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate this discussion into the paper. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out an inconsistency in the notation used in the paper, specifically regarding the use of \\\\(\\\\hat v^*_t\\\\). It notes that the \\\\(\\\\hat\\\\) symbol is typically used for empirical estimates elsewhere in the paper, but here it refers to something else. This feedback implies that the authors should clarify or correct the notation to avoid confusion. However, the comment does not provide explicit instructions on how to address this issue or suggest a specific alternative notation. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the notation but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L434,\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue with the notation used, noting that the \\\\(\\\\hat v^*_t\\\\) seems strange and inconsistent with its usage elsewhere in the paper. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the notation used in the paper, specifically the use of \\\\(\\\\hat v^*_t\\\\), which appears to be inconsistent with its usage elsewhere. The comment suggests that the notation is strange and potentially confusing, but it does not provide any supporting evidence or reasoning to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the notation used in the paper, pointing out that the notation \\\\(\\\\hat v^*_t\\\\) seems inconsistent with its usage elsewhere in the paper. This feedback is clear and actionable, as it directs the authors to clarify or correct the notation to avoid confusion. By addressing this specific issue, the authors can improve the clarity and consistency of their paper. However, the comment could be more helpful if it provided suggestions on how to resolve the inconsistency or offered examples of alternative notations. Overall, the comment is mostly helpful as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a lack of information regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. While it identifies a gap in the paper, it does not provide explicit instructions or suggestions on how the authors should address this issue. The action is implicit, as the authors can infer that they need to provide more details on the estimation process and reliability, but the comment does not offer concrete guidance on how to do so. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Equation 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the lack of information on how the function for the optimal sequence length was estimated and the reliability of the model. However, it does not provide any supporting evidence, reasoning, or references to justify why this information is important or how it impacts the paper's conclusions. Without additional context or explanation, the authors may find it challenging to understand the significance of this omission. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a specific gap in the paper regarding the estimation of the function for the optimal sequence length (Equation 1) and the reliability of the model. By pointing out the lack of information on how this function was estimated and the expected reliability, the reviewer highlights an area that requires clarification or additional explanation. This feedback is clear and actionable, as it directs the authors to provide more details on the methodology and its robustness, which is crucial for the paper's credibility and understanding. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of what additional information might be relevant. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to correct the phrase \\\"thousands\\\" in line 006, suggesting that it should be \\\"on the subword level\\\" instead. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed. The comment is specific and leaves no ambiguity about the required correction, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L006,\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is the inaccuracy of the phrase \\\"thousands\\\" and suggests a possible correction by adding \\\"on the subword level.\\\" This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests a correction to a phrase in the paper, stating that \\\"thousands\\\" is not accurate and recommending that it be replaced with \\\"on the subword level.\\\" This is a factual correction and does not involve any subjective claims or opinions. It is purely descriptive and does not require verification, making it a normal statement. Therefore, the appropriate label is \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion to correct a phrase in the paper, noting that \\\"thousands\\\" is not accurate and recommending that it be replaced with \\\"on the subword level.\\\" This feedback is clear and directly addresses a potential error in the manuscript, allowing the authors to make a precise correction. By offering a concrete change, the comment empowers the authors to improve the accuracy and clarity of their work. However, the comment could be more helpful if it explained why the correction is necessary or provided additional context. Overall, the comment is mostly helpful, as it effectively guides the authors toward a specific improvement in their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several concerns and suggests areas for improvement. It explicitly mentions that certain hyperparameters, such as regularization, are not specified, indicating an action for the authors to provide these details. Additionally, it questions the normalization of the y-axis in the latent path figures, specifically asking if it is normalized to zero at x=0. This implies that the authors should clarify this aspect in their description. Lastly, the comment suggests further analysis using interpolations, providing a concrete action for the authors to consider. Each point is explicit and provides clear guidance on how to address the issues, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific elements of the paper, such as \\\"hyperparameters\\\" and \\\"latent path figures\\\" (e.g., Fig 3), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the lack of specification of hyperparameters and the need for clarification on the y-axis values in the latent path figures. Additionally, it suggests further analysis using interpolations, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of observations and requests for clarification. It does not contain subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies several areas for improvement in the paper. It points out the omission of specifying certain hyperparameters, such as regularization, which is crucial for reproducibility and understanding the model's behavior. Additionally, it questions the normalization of the y-axis in the latent path figures, specifically asking if it is normalized to zero at x=0. This feedback is clear and actionable, prompting the authors to provide these details. The comment also suggests further analysis using interpolations, which could offer deeper insights into the model's behavior. Overall, the feedback is mostly helpful as it highlights specific areas needing clarification and suggests a potential avenue for further exploration, providing the authors with clear directions for improvement. However, it could be more helpful if it offered more detailed guidance on how to conduct the suggested analysis or provided examples of what kind of insights might be gained. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor, specifically in terms of epsilon. While the comment highlights an area of uncertainty, it does not provide explicit guidance or suggestions for the authors to address this issue. The authors are left to infer that they might need to clarify or provide an error bound related to epsilon, but the comment lacks concrete steps or details on how to do so. Therefore, the action is implicit and vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly refers to the mention of rounding core tensors to smaller ranks with a given accuracy, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it raises a clear question about the effect on the approximation error in the full tensor and whether there is an error bound in terms of epsilon. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a factual statement about the paper's content regarding the rounding of core tensors and the potential effect on approximation error. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area of the paper that lacks clarity, namely the effect of rounding core tensors to smaller ranks on the approximation error in the full tensor. It raises a pertinent question about whether there is an error bound in terms of epsilon, which is crucial for understanding the theoretical implications of the method. However, the comment does not provide suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. While it points out an important area for clarification, the feedback could be more helpful if it offered specific advice or examples on how to enhance the discussion. Therefore, the comment is somewhat helpful, as it highlights a critical area needing attention but lacks detailed guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a gap in the results presented in Table 1, noting that it only shows results for the discriminative setting, while there are two test settings in visual dialog. The reviewer explicitly asks for the results on the generative setting. This comment provides a clear and direct action for the authors to take, which is to include the results for the generative setting in their analysis. The feedback is specific and actionable, as it clearly indicates what additional information is needed to improve the draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1\\\" and the \\\"discriminative setting,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the results on the \\\"generative setting\\\" in the context of visual dialog. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the results presented in Table 1, noting that it only shows results for the discriminative setting while there are two test settings in visual dialog. The reviewer questions the applicability of the discriminative setting to real applications and asks for results on the generative setting. This claim is somewhat verifiable as it highlights a gap in the results but lacks specific examples or references to support the need for results on the generative setting. The comment provides a logical reasoning for the concern but could be strengthened with more detailed justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific gap in the results presented in Table 1, noting that it only shows results for the discriminative setting while there are two test settings in visual dialog. It raises a valid concern about the applicability of the discriminative setting to real-world applications and asks for results on the generative setting. This feedback is clear and actionable, as it prompts the authors to include results for the generative setting, which would provide a more comprehensive evaluation of their work. However, the comment could be more helpful if it offered suggestions on how to present or analyze these results. Overall, the comment is mostly helpful as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that more should be done to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not provide specific guidance on how to achieve this or what additional information or evidence should be included to support the claim. The comment is vague and lacks explicit instructions, leaving the authors uncertain about how to address the feedback. As a result, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that more should be done to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what additional information or evidence should be included to support the claim. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point suggests that more should be done to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests that more should be done to convince the reader that a query of the type SEARCH is feasible in a realistic scenario. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how to address this issue. It also includes an incomplete statement, \\\"One other little thing,\\\" which does not contribute to the overall feedback. Without clear guidance or detailed advice, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is not helpful at all, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to describe the form of \\\"p\\\" near line 135. It also mentions that the assumption is a Gaussian distribution, but it is not explicitly stated. This provides a clear and direct action for the authors to take, specifying where the description should be included and what form \\\"p\\\" is assumed to take. The comment is specific and provides concrete guidance on how to improve the draft, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 135,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states what needs to be addressed, namely the description of the form of \\\"p\\\" near line 135. The comment implies that the assumption is a Gaussian distribution, but it is not explicitly stated, providing clear guidance on what needs to be clarified. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the form of \\\"p\\\" should be described near line 135, implying that it is assumed to be a Gaussian distribution but not explicitly stated. This claim is somewhat verifiable as it points out a missing element in the paper, which could impact clarity. However, the comment lacks specific reasoning or examples to fully substantiate why this omission is significant or how it affects the paper's content. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion by pointing out that the form of \\\"p\\\" should be described near line 135. It acknowledges the reviewer's assumption that \\\"p\\\" is a Gaussian distribution but notes that this is not explicitly stated in the paper. This feedback is clear and directly guides the authors on where to add crucial information, which can improve the clarity and completeness of the paper. However, the comment could be more helpful if it explained why this information is important or how it affects the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing clarification. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the discussion on regret, specifically questioning whether the prediction error over the entire horizon T cannot be sublinear. While the comment implies that the authors should clarify their discussion on regret, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the clarification. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"lines 32 - 37,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the discussion on regret and the proof of achieving T^{1/2} regret, suggesting a potential misunderstanding or misstatement in the paper. This level of detail provides clear guidance on what needs to be clarified or corrected, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a question seeking clarification about the discussion on regret. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the discussion on regret, specifically questioning whether the prediction error over the entire horizon T cannot be sublinear. This feedback prompts the authors to clarify their discussion on regret, which is a critical aspect of their work. However, the comment does not provide specific suggestions or guidance on how to address this issue or improve the clarity of the discussion. While it identifies a potential area of confusion, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies specific issues with the explanation of the forward-prediction model, particularly noting that Figure 2(b) does not accurately represent the schematic of the model and that it is difficult to connect the text, figure, and equations. The comment explicitly instructs the authors to redraw Figure 2(b) and suggests that the details of the model should be better explained. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be revised and how to do it. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2(b),\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the lack of a schematic representation of the forward prediction model and the difficulty in connecting the text, figure, and equations. This provides clear guidance on what needs to be improved. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the details of the forward-prediction model are not well explained, specifically pointing out issues with Figure 2(b) and the connection between the text, figure, and equations. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the exact issues with the figure and the connection between the text and equations, making the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the explanation of the forward-prediction model, noting that Figure 2(b) does not accurately represent the schematic of the model. It also points out the difficulty in connecting the text, figure, and equations, which suggests that the authors need to improve the clarity and accuracy of their presentation. This feedback is clear and actionable, providing the authors with a direct way to enhance the clarity and coherence of their manuscript. However, the comment could be more helpful if it offered suggestions on how to improve the figure or the text-figure connection. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights several issues with the baseline methods and the lack of discussion on limitations. It suggests that the authors should discuss the similarity and difference between their work and reinforcement learning (RL) and consider the generalizability of the results to RL settings. While the comment provides some direction, it lacks specific guidance on how to address these issues or what specific aspects should be discussed. The authors are left with a general sense of what needs to be improved but without detailed instructions on how to implement the changes. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses multiple issues related to the baseline methods, the lack of discussion on limitations, and the potential direction for the conclusion regarding the similarity and difference with reinforcement learning (RL). However, it does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as discussing the limitations and the generalizability of the results to RL settings. Therefore, the comment is weakly grounded but specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the baseline methods are weak and not state-of-the-art, and it lacks a discussion on limitations. It also suggests that the authors should address the difference between their work and reinforcement learning (RL) and discuss the generalizability of the results to RL settings. While the comment identifies areas for improvement, it does not provide specific examples or references to support the claim that the baseline methods are weak or to substantiate the need for a discussion on limitations. This lack of detailed justification makes the claim somewhat verifiable, as the authors would need to make a significant effort to understand and address the issues raised. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies several areas for improvement in the paper. It points out that the baseline methods are weak and not state-of-the-art, suggesting that the authors should include more robust comparisons. Additionally, it notes the absence of a discussion on limitations, which is crucial for understanding the scope and applicability of the work. The comment also suggests a possible direction for the conclusion, recommending a discussion on the similarity and difference between the work and reinforcement learning (RL), as well as the generalizability of the results to RL settings. While the comment provides some actionable feedback, it could be more helpful by offering specific suggestions or examples on how to address these issues. Overall, the comment is somewhat helpful as it highlights important areas for improvement but lacks detailed guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises two main concerns. First, it suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help determine if the benefits are from a better generative model or better inference. This is an explicit suggestion, but it lacks concrete guidance on how to implement this change or what specific results to look for. Second, it provides a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. This is also an explicit suggestion, but again, it lacks detailed guidance on how to execute it. Overall, the comment provides explicit actions but lacks concrete details on how to implement them, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The review point raises two main concerns. First, it suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help determine if the benefits are from a better generative model or better inference. This part is not grounded as it does not specify which section of the paper discusses the doubly stochastic construction or VGAE, making it difficult for the authors to pinpoint the exact part that needs attention. However, it is specific in suggesting a potential improvement. The second part is fully grounded as it refers to \\\"Figure 3,\\\" allowing the authors to identify the specific figure being discussed. It also provides a specific suggestion to keep the generative model fixed and optimize only the inference part for comparison. Overall, the comment is a mix of weakly grounded and specific for the first part and fully grounded and specific for the second part, aligning with a score of 4.\",\n    \"grounding_specificity_label\": \"4\",\n    \"verifiability_rationale\": \"The review point raises two main concerns. The first suggestion is about running VGAE with a vamp prior to better match the doubly stochastic construction, which could help determine if the benefits are from a better generative model or inference. This claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim fully. The second part of the comment is a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. This is a logical suggestion but lacks detailed justification or references, making it somewhat verifiable. Overall, the review point provides some reasoning but lacks comprehensive support, aligning with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides two main points. First, it suggests running VGAE with a vamp prior to better match the doubly stochastic construction in the work, which could help determine if the benefits are from a better generative model or better inference. This is a valuable suggestion that could guide the authors in refining their model and understanding its performance. However, the comment lacks specific guidance on how to implement this suggestion or what specific results to look for, making it somewhat helpful. Second, the comment offers a minor point about Figure 3, suggesting that keeping the generative model fixed and optimizing only the inference part would allow for a clearer comparison of representations. This is a constructive suggestion that could improve the clarity of the results. However, the comment could be more helpful if it provided more detailed guidance on how to implement these suggestions. Overall, the comment is somewhat helpful as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the paper should include a discussion about the necessity of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation. It acknowledges that the example in Table 3 shows this happening but questions whether it is fully required. The reviewer implies that there should be a discussion about the potential trade-offs or complexities involved. However, the comment does not provide explicit guidance on how to conduct this discussion or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the example of semantic segmentation and refers to \\\"table 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the necessity of learning long-range dependencies and suggests a discussion about the potential trade-offs or complexities involved, particularly regarding the encoding of locality in the graph structure and its impact on prediction depending on image size. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that learning long-range dependencies is important for powerful predictors, particularly in semantic segmentation, as evidenced by visualizations in Table 3. However, the reviewer expresses uncertainty about whether this is fully required and suggests that the truth might lie somewhere between the extremes. The comment implies a need for a discussion on the necessity of long-range dependencies and the potential impact of locality in the graph structure. While the comment provides some reasoning and an example, it lacks specific references or detailed evidence to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further elaboration to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the importance of learning long-range dependencies for powerful predictors, particularly in the context of semantic segmentation, as evidenced by the visualizations in Table 3. However, it expresses uncertainty about whether this is fully required and suggests that the truth might lie somewhere between the extremes. The comment implies a need for a discussion on the necessity of long-range dependencies and the potential impact of locality in the graph structure. While the feedback identifies a potential area for improvement and suggests a direction for further exploration, it lacks specific guidance or actionable steps for the authors to address this concern. The comment is somewhat helpful as it prompts the authors to consider a deeper discussion on the topic, but it could be more beneficial with additional details or suggestions on how to incorporate this into the paper. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several concerns about the paper, including the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data. It also notes that the performance is more quickly getting worse than standard random features, suggesting a potential weakness in the proposed approaches or theoretical results. However, the comment does not provide explicit actions or suggestions for the authors to address these issues. It lacks concrete guidance on how to clarify the definition of $e_l$ or how to improve the theoretical results. As a result, the authors are left without clear direction on how to respond to these points, making the comment unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq. (3),\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the definition of $e_l$ and discusses the exponential dependence on the diameter $M$ of the domain of data, providing specific observations about the results and their implications. This level of detail and clarity makes the comment fully grounded and specific, corresponding to a score of 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises several claims regarding the paper's content, including the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data. The reviewer provides logical reasoning by explaining how this dependence affects the constant factor of the required feature size and notes that the performance is more quickly getting worse than standard random features. However, the comment lacks specific examples or references to substantiate these claims, making it somewhat verifiable. The authors would need to further explore these points to fully understand and address them, thus justifying a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a detailed analysis of several aspects of the paper, including the definition of $e_l$ in Eq. (3) and the exponential dependence on the diameter $M$ of the domain of data. It highlights a potential weakness in the proposed approaches or theoretical results, noting that while the performance may decrease as the required amount of error $\\\\varepsilon$ decreases, the dependence on $M$ affects the constant factor of the required feature size. The comment also references Figure 1 to illustrate the performance issues. While the feedback is clear and identifies specific areas for improvement, it could be more helpful by offering suggestions on how to address these issues or improve the theoretical results. Overall, the comment is mostly helpful as it provides valuable insights into potential weaknesses and areas for enhancement, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about whether the model collapses less than other methods and asks for a demonstration or result related to this phenomenon. It also inquires about the common occurrence of gradients becoming zero and collapsing, and whether the authors observed this in their experiments. While the comment implies that the authors should provide evidence or observations related to model collapse, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional information or results to address the question. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 159,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the model collapses less than other methods and asks for a demonstration or result related to this phenomenon. Additionally, it inquires about the common occurrence of gradients becoming zero and collapsing, and whether the authors observed this in their experiments. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the model's behavior and its collapse. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the model's behavior, specifically whether it collapses less than other methods, and mentions a point about gradients becoming zero and collapsing. It asks for clarification on whether this is a common occurrence and if the authors have observed it in their experiments. While the comment identifies an area of interest and seeks clarification, it lacks specific suggestions or guidance on how the authors might address this issue or what additional experiments or analyses could be conducted to provide more insight. The feedback is somewhat helpful as it prompts the authors to consider and clarify an important aspect of their model, but it could be more actionable with additional guidance. Therefore, it is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors should include results for linear scalarization combined with Concorde, as it is a state-of-the-art heuristic solver, for a better comparison. This is an explicit suggestion, providing a clear action for the authors to take. However, while the suggestion is explicit, it lacks concrete details on how to implement this comparison or what specific aspects should be highlighted. Therefore, the comment is somewhat actionable, as it identifies a specific area for improvement but does not provide detailed guidance on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the experimental results and the comparison between learning-based and heuristic-based solvers, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including results for linear scalarization combined with Concorde, a state-of-the-art heuristic solver, for a better comparison. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the learning-based solvers outperform heuristic-based solvers, but suggests that for the single objective TSP, the state-of-the-art heuristic solver (e.g., Concorde) usually performs better. The reviewer provides a logical reasoning by referencing the Pareto front's non-convexity and suggesting that including results for linear scalarization + Concorde would enhance the comparison. This reasoning is supported by the mention of Concorde as a state-of-the-art heuristic solver and the observation about the Pareto front's characteristics. However, the comment could be strengthened by providing specific references or examples of how Concorde typically performs in similar scenarios. As it stands, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area for improvement by suggesting the inclusion of results for linear scalarization combined with Concorde, a state-of-the-art heuristic solver. This is a constructive suggestion that could enhance the paper's comparative analysis, particularly for the single objective TSP. By addressing this point, the authors could provide a more comprehensive evaluation of their learning-based solvers. However, the comment could be more helpful if it included additional guidance on how to integrate these results or why they are important. Overall, the feedback is mostly helpful as it directs the authors toward a meaningful enhancement of their draft, but it could be more comprehensive with further details.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that providing glosses in Figure 2 would be helpful. While the action is explicit, it lacks concrete details on what specific glosses should be included or how they should be structured. The authors are given a clear direction to add glosses, but the comment does not specify what exactly needs to be included, leaving some ambiguity in execution. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of glosses in Figure 2. This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that providing glosses in Figure 2 would be helpful. However, it does not provide any justification or reasoning for why this would be beneficial or how it would improve the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment suggests adding glosses to Figure 2, which could enhance the clarity and accessibility of the figure. This feedback is specific and actionable, providing a clear direction for improvement. However, it could be more helpful if it explained why these glosses are necessary or how they would benefit the reader. Despite this, the comment is mostly helpful as it offers a concrete suggestion for enhancing the draft, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point poses a question about considering finer grouping for quantization instead of per-tensor and per-channel. While it implies that the authors should explore this possibility, it does not explicitly instruct them to do so. The action is implicit and lacks concrete guidance on how to implement this suggestion, such as which finer grouping methods to consider or how to evaluate their effectiveness. As a result, the comment is somewhat actionable, as it provides a direction for improvement but lacks detailed guidance on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises a question about considering finer grouping for quantization instead of per-tensor and per-channel. However, it does not specify which part of the paper this question pertains to, such as a particular section or experiment where quantization is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting an alternative approach to quantization, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of a question asking for clarification or consideration of an alternative approach to quantization. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about considering finer grouping for quantization instead of per-tensor and per-channel. While it identifies a potential area for improvement, it lacks specificity and does not provide any guidance or suggestions on how the authors might explore this alternative approach. The comment does not offer actionable advice or examples, leaving the authors with only a vague idea of what might be improved. As a result, the feedback is barely helpful, as it points out a potential area for exploration but does not fully support the authors in making improvements to their draft.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the definition of \\\"active vertices\\\" in line 135, which implies that the authors should clarify this term. While the comment does not explicitly instruct the authors to provide a definition, it clearly identifies an area that needs clarification. The action is implicit but concrete, as it points to a specific line where the definition is lacking. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"line 135,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the definition of \\\"active vertices,\\\" providing clear guidance on what needs to be clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding the definition of \\\"active vertices\\\" in line 135. It does not contain an opinion, judgment, or suggestion that requires verification. It is a factual inquiry, fitting the \\\"No\\\" label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific point of confusion in the paper, asking for clarification on the definition of \\\"active vertices\\\" as mentioned in line 135. This feedback is clear and actionable, as it directs the authors to a particular area where their explanation could be improved. By addressing this question, the authors can enhance the clarity and precision of their writing, making the paper easier to understand. However, the comment could be more helpful if it provided suggestions on how to define \\\"active vertices\\\" or examples of how this definition might be used. Overall, the comment is mostly helpful as it highlights a specific area for improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights two main issues: the lack of acknowledgment of the theoretical limitation regarding the applicability of the theory to the used model and the vagueness of unspecified structural assumptions. It suggests that the authors should provide more elaboration on the potential negative societal impact of graph neural networks in general. While the comment identifies areas for improvement, it does not provide explicit instructions or concrete steps on how to address these issues. The authors are left to infer that they need to expand on these points, but the feedback lacks specific guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not offer detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the limitations section and the use of graph neural networks, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the applicability of the theory to the model and the vagueness of unspecified structural assumptions. Additionally, it suggests elaborating on the potential negative societal impact of graph neural networks in general. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the applicability of the theory to the model used in the paper and the vagueness of unspecified structural assumptions. The reviewer suggests that the authors may be underestimating the use of graph neural networks in industry and recommends elaborating on potential negative societal impacts. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claims about the theory's applicability or the societal impact. The suggestion to elaborate on negative impacts is a logical suggestion but does not provide concrete examples or evidence. Therefore, the comment is somewhat verifiable, as it provides a basis for the claims but requires further elaboration to be fully substantiated.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the paper, specifically the lack of acknowledgment of the theoretical limitation regarding the applicability of the theory to the used model. It also points out the vagueness of unspecified structural assumptions, which makes the theoretical limitation difficult to identify. The comment suggests that the authors may be underestimating the use of graph neural networks in industry and recommends elaborating on the potential negative societal impact of graph neural networks in general. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, it could be more helpful if it offered detailed suggestions on how to elaborate on the societal impact or provided examples of potential negative impacts. Overall, the comment is mostly helpful, as it effectively guides the authors toward enhancing the depth and relevance of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a question about which part of the framework is vital for using CLIP to guide weakly supervised learning. It suggests that a discussion is necessary to clarify this aspect and distinguish the paper from related work. However, the comment does not provide explicit guidance on how to conduct this discussion or what specific points should be addressed. The action is implicit, as the authors need to infer that they should include a discussion, and it is vague because it lacks concrete steps or details on how to implement this suggestion. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment raises a question about which part of the framework is vital for using CLIP to guide weakly supervised learning. It suggests that a discussion is necessary to clarify this aspect and distinguish the paper from related work. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a discussion and its purpose, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point consists of a question and a suggestion for improvement. It does not contain any subjective claims, opinions, or suggestions that require verification. The question is factual, and the suggestion is a request for clarification, fitting the \\\"No\\\" label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a pertinent question about the importance of different parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion is necessary to clarify this aspect and distinguish the paper from related work. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this discussion or what aspects should be highlighted. The feedback is somewhat helpful as it points out a critical area for improvement, but it could be more actionable with additional detail or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out a perceived weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is weak and that the decomposition/integration steps do not closely connect with Fourier analysis as claimed. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the analogy. There is no guidance on potential modifications, alternative approaches, or additional analysis that could be conducted to strengthen the analogy. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the analogy between HOI analysis and Harmonic analysis, specifically pointing out that the link is weak and that the decomposition/integration steps do not closely connect with Fourier analysis as claimed. However, it does not specify which part of the paper this analogy is discussed in, making it weakly grounded. The comment is specific in detailing the perceived weakness in the analogy and the lack of connection with Fourier analysis. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the analogy between HOI analysis and Harmonic analysis is weak, specifically noting that the decomposition/integration steps do not closely connect with Fourier analysis. This claim is somewhat verifiable as it provides a logical reasoning for the weakness, but it lacks specific examples or references to substantiate the claim fully. The comment could be strengthened by providing more detailed evidence or examples of how the analogy is weak, making it easier for the authors to understand and address the issue. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a perceived weakness in the analogy between HOI analysis and Harmonic analysis, noting that the link is weak and that the decomposition/integration steps do not closely connect with Fourier analysis as claimed. This feedback is somewhat helpful as it highlights a potential issue with the paper's theoretical framework, prompting the authors to reconsider the strength of their analogy. However, the comment lacks specific suggestions or guidance on how the authors might address this weakness or improve the analogy. Without actionable advice or detailed critique, the authors are left with a general understanding of the problem but no clear path to resolve it. Therefore, the comment is rated as somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the generalization of the focusing distance shown in Figure 8, specifically asking whether the model generalizes well to focusing distances not present in the training data. While the comment implies that the authors should consider or discuss the generalization of the model to other focusing distances, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the issue or what specific aspects to focus on. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"fig 8,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the generalization of the focusing distance shown in the figure, specifically asking whether the model generalizes well to focusing distances not present in the training data. This provides clear guidance on what aspect of the figure needs further consideration or discussion. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a question asking for clarification about the generalization of focusing distances not present in the training data. It does not contain any subjective claims, opinions, or suggestions that require verification. The statement is factual and seeks clarification, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a pertinent question about the generalization of the focusing distance shown in Figure 8. It points out that the figure only displays 1m and 5m focusing distances, both of which are present in the training data. The reviewer inquires whether the model generalizes well to other focusing distances not included in the training data. This feedback is somewhat helpful as it prompts the authors to consider the limitations of their model's generalization capabilities. However, the comment could be more helpful if it provided suggestions on how to address this issue or explored the implications of the observed generalization. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should define content and style more broadly in the context of their specific neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the meaning of \\\"style\\\" in the context of a non-sequential model that does not capture temporal dynamics. While the comment provides a general direction for broadening the definitions, it lacks specific guidance on how to implement these changes or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the authors should define content and style more broadly in the context of their specific neural application, referencing Gabbay & Hosehn (2018) as an example. It also questions the meaning of \\\"style\\\" in the context of a non-sequential model that does not capture temporal dynamics. While the comment provides a specific suggestion for broadening definitions, it does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. However, the comment is specific in detailing what needs to be addressed regarding the definitions of content and style. Therefore, this comment is weakly grounded and specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should define content and style more broadly in the context of their neural application, referencing Gabbay & Hosehn (2018) as an example. The comment questions the meaning of \\\"style\\\" in the context of a non-sequential model that does not capture temporal dynamics. While the reference to Gabbay & Hosehn (2018) provides some support, the comment lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to further explore the implications of this suggestion to understand its full impact. Therefore, the comment is somewhat verifiable, as it provides a starting point but requires additional detail to be fully actionable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for the authors to consider defining content and style more broadly in the context of their neural application. It references Gabbay & Hosehn (2018) as an example, which offers a framework for understanding how style can be instance-specific and content can be transferable. The comment also questions the meaning of \\\"style\\\" in the context of a non-sequential model that does not capture temporal dynamics, prompting the authors to clarify their definitions. This feedback is clear and constructive, offering a concrete direction for improving the clarity and precision of the paper. However, it could be more helpful if it provided additional guidance on how to implement these changes or examples of how to define content and style in their specific application. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides a detailed critique of the analysis of vit quantification, pointing out specific issues with the paper's claims and comparisons. It highlights that the proposed approach does not improve upon the information distortion issue and provides examples to support this claim. Additionally, it references other works that have observed similar issues with quantization in transformers, suggesting that the problem is not unique to the ViT model. While the comment does not explicitly instruct the authors to address these issues, the detailed analysis and references provide clear guidance on what needs to be clarified or improved in the paper. The authors can infer that they need to provide a more in-depth analysis and address the specific issues raised. Therefore, the comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines and figures (Line 45, Fig1(b), Fig5(b), and Block.3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the analysis of vit quantification, including the claim that a direct quantization method leads to information distortion and the comparison of variance differences between the proposed approach and existing methods. Additionally, it references other works that have observed similar issues with quantization in transformers, providing a broader context for the critique. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point critiques the analysis of vit quantification, providing specific examples and comparisons to support its claims. It references Line 45 and compares the variance differences between the proposed approach and existing methods, such as Q-BERT and Q8BERT, to illustrate the issue. The mention of other works that have observed similar issues with quantization in transformers adds further support to the claim. This detailed analysis and comparison make the comment fully verifiable, as it provides clear evidence and references to substantiate the critique. Therefore, the comment is rated as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides a detailed critique of the analysis of vit quantification, pointing out specific issues with the paper's claims and comparisons. It highlights that the proposed approach does not improve upon the information distortion issue and provides examples to support this claim. Additionally, it references other works that have observed similar issues with quantization in transformers, suggesting that the problem is not unique to the ViT model. This feedback is clear and actionable, offering the authors specific areas to address and improve their analysis. However, it could be more helpful if it included suggestions on how to enhance the analysis or provided guidance on how to address the identified issues. Overall, the comment is mostly helpful as it directs the authors' attention to critical areas needing clarification and improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a main weakness in the paper regarding its technical novelty compared to spatial transformer networks (STN) and the lack of comparison to existing works that apply STN in a local pixel neighborhood. It also mentions that the proposed X-transformation is similar to STN but applied locally. The comment suggests that the authors should include empirical or conceptual comparisons to STN, which is important for establishing the novelty of their work. While the comment highlights the issue and provides some direction, it does not offer specific guidance on how to conduct these comparisons or what aspects to focus on. The action is implicit and somewhat vague, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment identifies a main weakness in the paper regarding its technical novelty compared to spatial transformer networks (STN) and the lack of comparison to existing works that apply STN in a local pixel neighborhood. It also mentions that the proposed X-transformation is similar to STN but applied locally. The comment is fully grounded as it clearly addresses the technical novelty aspect and provides specific references to existing works, such as PointNet, which use a variant of STN. This allows the authors to pinpoint the areas that need attention. The comment is also specific, as it outlines the issues with the novelty and the lack of comparison, providing clear guidance on what needs to be addressed. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the work lacks technical novelty compared to spatial transformer networks (STN) and does not include a comparison to existing works that apply STN in a local pixel neighborhood. The reviewer provides specific references to existing works, such as PointNet, which use a variant of STN in their network architecture. This detailed comparison and reference to existing literature support the claim, making it fully verifiable. The comment provides a clear rationale and evidence, allowing the authors to understand and address the issue effectively.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant weakness in the paper regarding its technical novelty, particularly in comparison to spatial transformer networks (STN). It points out that the proposed X-transformation appears similar to STN but applied locally, and notes the existence of existing works that apply STN in a local pixel neighborhood. Additionally, it mentions that PointNet uses a variant of STN in its architecture, further highlighting the limited novelty of the work. The comment also emphasizes the absence of empirical or conceptual comparisons to STN, which is crucial for establishing the paper's contribution. While the feedback is clear and identifies key areas for improvement, it could be more helpful by suggesting specific ways to address the novelty issue or how to better position the work within the existing literature. Nonetheless, the comment provides valuable insights that can guide the authors in enhancing their draft, making it mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests that the authors mention \\\"|Y_t - Y_{t-1}| \\\\leq c_t almost surely\\\" at line 384 and correct \\\"\\\\mu_t\\\" to \\\"\\\\tilde \\\\mu_t\\\" at line 431. These instructions are clear and specific, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific line numbers (L384 and L431), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies what needs to be addressed, such as mentioning the condition \\\"|Y_t - Y_{t-1}| \\\\leq c_t almost surely\\\" and correcting \\\"\\\\mu_t\\\" to \\\"\\\\tilde \\\\mu_t.\\\" This provides clear guidance on what needs to be revised or clarified in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual statements and requests for clarification. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \\\"No\\\".\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by pointing out two instances where the manuscript could be improved. It suggests that the authors mention \\\"|Y_t - Y_{t-1}| \\\\leq c_t almost surely\\\" at line 384 and correct \\\"\\\\mu_t\\\" to \\\"\\\\tilde \\\\mu_t\\\" at line 431. These corrections are clear and precise, offering the authors a straightforward way to enhance the accuracy and clarity of their manuscript. By addressing these specific points, the authors can make targeted improvements to their draft, making the comment highly helpful. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a confusing aspect of Eq. 12 and asks for clarification on the source of the reward at each trial. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. Additionally, it provides references to other works that might be relevant. The comment is explicit in its request for clarification and explanation, and it provides concrete suggestions for improvement by recommending the inclusion of equations to enhance clarity. The references, while not directly actionable, offer context and potentially related work. Overall, the comment is highly actionable as it provides clear guidance on what needs to be addressed and how to improve the draft.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Eq. 12,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the confusion regarding the source of the reward at each trial and the need for an explanation of the network model in Sec. 4.2 with equations. Additionally, the comment provides references to other works, which could be relevant for the authors to consider. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that \\\"Eq. 12 is confusing\\\" and questions the source of the reward at each trial. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. However, the comment does not provide specific reasoning or examples to support why Eq. 12 is confusing or how the suggested explanation would enhance clarity. The references provided are not directly related to the confusion about Eq. 12, making it difficult for the authors to understand the basis of the claim. As a result, the comment is somewhat verifiable, as it lacks detailed justification or examples to fully substantiate the claim.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Eq. 12, noting that the source of the reward at each trial is unclear. It suggests that explaining the network model in Sec. 4.2 with equations would improve clarity. This feedback is clear and actionable, as it directly points out a need for clarification and provides a constructive suggestion for improvement. However, the comment could be more helpful if it offered specific guidance on how to explain the network model or what aspects of the reward mechanism are confusing. Despite this, the feedback is mostly helpful as it directs the authors to a critical area needing clarification and provides a general direction for improvement. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It identifies a specific error in the text, where \\\"Fig.7\\\" should be \\\"Fig.12,\\\" and suggests that each theorem and corollary in the main paper should be linked to its corresponding proof for better readability. These instructions are clear and actionable, giving the authors precise guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Row 821 in Supp. Page 31\\\" and \\\"Fig.7\\\" should be \\\"Fig.12,\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It also provides specific feedback on the need to attach each theorem and corollary to its corresponding proof link for better readability. Additionally, the comment outlines the primary concerns regarding motivation, methodology soundness, and experiment persuasion, which adds further specificity. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a factual correction regarding a figure reference and a suggestion for improving the paper's structure by linking theorems and corollaries to their proofs. The latter part of the comment expresses positive feedback about the paper's novelty, theoretical guarantees, and empirical results. However, the claim about the paper being \\\"qualified\\\" is subjective and lacks supporting evidence or references. The rest of the comment is factual and descriptive, fitting the \\\"No\\\" label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback, identifying a minor error in the text and suggesting a more structured approach to referencing theorems and corollaries. By recommending that each theorem and corollary should be linked to its corresponding proof, the reviewer offers a clear way to improve the paper's readability and accessibility for readers. Additionally, the comment acknowledges the strengths of the paper, such as its novelty, theoretical guarantees, and empirical results, which provides a positive perspective on the work. While the comment could be more helpful by offering additional suggestions on how to enhance the motivation, methodology, or experiments, it still provides valuable guidance for improving the draft. Therefore, the comment is mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions about specific sections of the paper, such as the missing determiner in the definition, the selection of 50 classes, the tagging of action verbs, and the concept of \\\"action frames.\\\" While these questions highlight areas that need clarification, they do not provide explicit actions or suggestions for the authors to take. The authors can infer that they need to address these questions by providing more details or clarifications, but the comment lacks concrete guidance on how to do so. Therefore, the comment is somewhat actionable, as it identifies areas needing improvement but does not offer detailed instructions on how to address them.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific line numbers (248 and 306ff), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the missing determiner in the definition, the selection of 50 classes, the tagging of action verbs, and the concept of \\\"action frames.\\\" This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a series of questions and requests for clarification regarding specific sections of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and aim to seek clarification, making it a normal statement. Therefore, it should be labeled as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises several questions about specific sections of the paper, such as the missing determiner in a definition, the selection of 50 classes, and the tagging of action verbs. It also questions the concept of \\\"action frames\\\" and how they are picked. While these questions highlight areas that may be unclear or require further explanation, the comment does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it points out potential areas of confusion, but it lacks actionable advice or detailed guidance, making it less comprehensive. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly identifies a minor grammatical error, noting that \\\"Empiically\\\" should be \\\"Empirically.\\\" This direct suggestion provides a clear and concrete action for the authors to correct the typo. The comment is specific and leaves no ambiguity about what needs to be done, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Ln 32 on Page 1,\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect spelling of \\\"Empiically\\\" as \\\"Empirically.\\\" Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point is a minor grammatical correction, specifically pointing out the misspelling of \\\"Empiically\\\" as \\\"Empirically.\\\" This is a factual correction and does not involve any subjective claims, opinions, or suggestions. Therefore, it fits the criteria for a normal statement, and the appropriate label is \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a minor grammatical error in the manuscript, specifically pointing out that \\\"Empiically\\\" should be \\\"Empirically.\\\" This is a straightforward and actionable suggestion that can be easily corrected by the authors. While the comment is brief, it provides clear guidance on improving the draft's accuracy and professionalism. However, it does not offer broader insights or suggestions for other potential issues, which could enhance its helpfulness. Overall, the comment is somewhat helpful as it addresses a specific, minor issue but lacks depth and broader applicability.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a concern about the generalizability of the model to different numbers of entities, as illustrated in Figure 3 of INs. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the model's generalizability. The comment lacks actionable details, such as recommending specific methods or experiments to test the model's adaptability to varying entity counts. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"figure 3 of INs,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the number of entities is fixed and questions how the model can be generalized to different numbers of entities. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the generalizability of the model to different numbers of entities, referencing Figure 3 of INs. However, the comment lacks specific details or examples from the paper that illustrate the issue or how it could be addressed. Without additional context or explanation, the claim remains vague and difficult for the authors to verify or address effectively. Therefore, the comment is considered borderline verifiable, as it provides some indication of a problem but lacks sufficient detail to be fully actionable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential limitation in the paper regarding the generalizability of the model to different numbers of entities. It points out that the number of entities is fixed and questions how the model can be adapted to handle varying entity counts, as illustrated in Figure 3 of INs. While the comment highlights an important area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to consider the generalizability of their model, but it could be more beneficial with additional details or recommendations for improvement. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment states that the novelty of the idea is insufficient and that both the new metric and method are straightforward. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or improve the metric and method. The feedback lacks actionable details, such as recommending ways to make the idea more novel or suggesting modifications to the metric and method. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment critiques the novelty of the idea and the straightforwardness of the new metric and method. However, it does not specify which part of the paper these assessments are based on, nor does it provide details on what aspects of the metric and method are considered straightforward. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the novelty of the idea is insufficient and that both the new metric and method are straightforward. However, the comment does not provide specific examples, detailed reasoning, or references to support these claims. Without concrete evidence or elaboration, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment criticizes the novelty of the idea and suggests that both the new metric and method are straightforward. However, it lacks specificity and does not provide actionable feedback or suggestions for improvement. Without detailed guidance on how the authors might enhance the novelty or address the perceived simplicity of their approach, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the framing of the paper overstates the method, making the contribution less clear. However, it does not provide specific guidance on how to address this issue or what aspects of the framing should be revised. The comment lacks explicit instructions or concrete details on how to improve the framing, leaving the authors uncertain about what changes are needed to make the contribution clearer. As a result, the comment is vague and unactionable, as it does not offer a clear path for the authors to follow. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the framing of the paper overstates the method, making the contribution less clear. However, it does not specify which part of the paper this issue pertains to, nor does it provide details on what aspects of the framing are problematic or how they could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is not grounded and highly unspecific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the framing of the paper overstates the method, making the contribution less clear. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment suggests that the framing of the paper overstates the method, making the contribution less clear. However, it lacks specificity and does not provide actionable feedback or examples to help the authors understand or address the issue. Without detailed guidance on how to revise the framing or clarify the contribution, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is barely helpful.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table to enhance clarity. While the comment provides some guidance on how to improve the model description, it lacks specific instructions on how to implement these changes. The suggestion to use a notation table is more concrete, but the overall feedback is somewhat vague. The authors know they need to make improvements but may not be entirely sure of the exact steps to take. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests improvements to the model description, specifically mentioning the generative process and the use of too many symbols and a notation table. However, it does not specify which part of the paper this feedback pertains to, such as a particular section or figure. The authors can infer that it relates to the model description, but the lack of explicit grounding makes it weakly grounded. The comment is specific in suggesting improvements, such as presenting the generative process in separate steps and using a notation table, but without clear grounding, it remains weakly grounded and specific. Therefore, this comment aligns with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the model description could be improved by presenting the generative process in separate steps and using a notation table. However, the comment lacks specific examples or detailed reasoning to support why these changes would enhance understanding. Without concrete evidence or references, the claim is somewhat verifiable, as it provides a general suggestion but lacks the necessary detail to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies specific areas for improvement in the model description, suggesting that the generative process could be better presented in separate steps to enhance understanding. It also points out the excessive use of symbols and the need for a notation table to improve clarity. While the comment provides actionable feedback, it lacks detailed guidance on how to implement these changes or examples of what the improved presentation might look like. This limits the comment's helpfulness, as the authors are given a general direction but without specific steps to follow. Therefore, the comment is somewhat helpful, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides a critique of the paper's organization and clarity, specifically mentioning that Figure 2 is cluttered and the \\\"bold\\\" text is difficult to see. It suggests that using another color or a bigger font could improve the highlighting of human identified rationales. While the comment identifies specific issues with the figure and provides a concrete suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit but clear, making this comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the figure, noting that it is cluttered and the \\\"bold\\\" text is difficult to see. The comment suggests a specific improvement by recommending the use of another color or a bigger font to highlight the human identified rationales better. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that identifying rationales is not a simple problem, particularly for complex NLP tasks like machine translation. However, the comment does not provide specific examples or detailed reasoning to support this claim. While it acknowledges that the paper is well-organized and easy to follow, it critiques Figure 2 for being cluttered and the \\\"bold\\\" text being difficult to see. This critique is somewhat verifiable as it points out a specific issue with the figure's presentation, but it lacks a broader justification for the initial claim about the complexity of identifying rationales. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a mix of observations and suggestions. It acknowledges that the paper is well-organized and easy to follow, which is a positive aspect. However, it also points out a specific issue with Figure 2, noting that it is cluttered and the \\\"bold\\\" text is difficult to see. The comment suggests a potential solution by recommending the use of another color or a bigger font to improve the clarity of the figure. While the comment identifies a specific area for improvement, it lacks broader guidance or suggestions for other potential issues or improvements in the paper. Overall, the feedback is somewhat helpful as it provides a clear and actionable suggestion for enhancing the presentation of the paper, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should further verify the effectiveness and universality of the Flipped-QA framework by applying it to non-LLM-based models like HiTeA and InternVideo. While the comment implies that the authors should conduct additional experiments or analyses, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for further exploration. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the Flipped-QA framework, which is described as general for various generative VideoQA models, should be tested on non-LLM-based models like HiTeA and InternVideo to verify its effectiveness and universality. However, it does not specify which part of the paper discusses the Flipped-QA framework or where the authors have applied it, making it weakly grounded. The comment is specific in its suggestion to test the framework on additional models, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the Flipped-QA framework, which is described as general for various generative VideoQA models, should be tested on non-LLM-based models like HiTeA and InternVideo to verify its effectiveness and universality. While the comment provides a logical suggestion for further validation, it lacks specific examples or references to support the claim that these models would demonstrate the framework's effectiveness. The reasoning is somewhat verifiable, as it suggests a potential area for improvement but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential limitation in the scope of the study, noting that the Flipped-QA framework is only applied to LLM-based models and suggesting that it would be beneficial to test its effectiveness and universality on non-LLM-based models like HiTeA and InternVideo. This feedback is clear and actionable, as it provides a specific direction for the authors to expand their analysis and potentially strengthen the generalizability of their findings. However, the comment could be more helpful if it included suggestions on how to conduct these additional experiments or what specific aspects to focus on. Overall, the comment is mostly helpful, as it guides the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment acknowledges that the proposed method primarily combines existing methods and lacks significant theoretical novelty. The reviewer explicitly states that they are willing to improve their score if the authors can address these concerns. However, the comment does not provide specific guidance on how the authors might address these concerns or what aspects of the theoretical novelty could be improved. The action is implicit and vague, as the authors are left to infer that they need to enhance the theoretical contribution of their work but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the proposed method's reliance on existing methods, specifically mentioning Clopper-Pearson intervals and Gaussian elimination. However, it does not specify which part of the paper this assessment is based on, making it weakly grounded. The comment does specify the issue of lacking theoretical novelty, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the proposed method lacks significant theoretical novelty because it primarily combines existing methods, specifically Clopper-Pearson intervals and Gaussian elimination. The reviewer supports this claim by referencing existing literature, which provides a basis for the assertion. However, the comment could be strengthened by providing more detailed explanations or examples of how the combination of these methods results in a lack of novelty. As it stands, the claim is mostly verifiable due to the references provided, but it could benefit from additional context or elaboration. Therefore, the comment aligns with a label of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment acknowledges that the proposed method primarily combines existing methods, such as Clopper-Pearson intervals and Gaussian elimination, and notes a lack of significant theoretical novelty. The reviewer expresses a willingness to improve their score if the authors can address these concerns. While the comment identifies a potential weakness in the paper, it does not provide specific suggestions or guidance on how the authors might enhance the theoretical novelty or differentiate their work from existing methods. The feedback is somewhat helpful as it highlights an area for improvement but lacks actionable advice or detailed guidance, leaving the authors with a general direction but no clear path to follow. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point poses a question about whether the text input is concatenated by the four text elements of an object. While it raises a potential concern or clarification needed, it does not provide explicit instructions or suggestions for the authors to address this question. The authors can infer that they might need to clarify this aspect in their paper, but the comment lacks concrete guidance on how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment raises a question about the concatenation of text input by the four text elements of an object. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs clarification. Additionally, the comment lacks specificity as it does not provide details on what is unclear or how the authors might address the question. Therefore, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point is a question asking for clarification about the concatenation of text input by the four text elements of an object. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks information, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the concatenation of text input by the four text elements of an object. While it identifies a potential area of confusion or lack of clarity in the paper, it does not provide any specific guidance or suggestions on how the authors might address this issue. The comment lacks depth and actionable feedback, leaving the authors with only a vague understanding of what needs to be clarified or improved. Therefore, the comment is barely helpful, aligning with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the sentence in lines 12-17 of the abstract is cumbersome and can be made clearer. While it identifies an issue with the sentence's clarity, it does not provide specific guidance on how to rephrase or simplify it. The action is explicit in that it requests clearer wording, but it is vague because it lacks concrete suggestions for improvement. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the abstract and the specific lines (12-17), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is the cumbersome nature of the sentence and suggests making it clearer. This provides clear guidance on what needs to be revised. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the sentence in lines 12-17 of the abstract is cumbersome and suggests it can be made clearer. However, the comment does not provide any specific examples or reasoning to support why the sentence is cumbersome or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the abstract, noting that the sentence describing the dataset is cumbersome and could be clearer. This feedback is actionable as it provides a direct suggestion for improvement, which can help the authors refine their writing to enhance clarity and readability. However, the comment could be more helpful if it offered specific suggestions on how to rephrase the sentence or provided examples of clearer alternatives. Despite this, the feedback is mostly helpful as it directs the authors' attention to an area needing improvement and offers a clear path for enhancement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a significant issue with the proposed approach, noting that it does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also points out that the trade-off between head and tail categories has not been fully investigated for the baselines, suggesting that by adjusting hyper-parameters in Decouple [Kang et al.], the tail accuracy could be improved while slightly decreasing the head accuracy. The comment explicitly encourages the authors to continue this line of work for future submission. While the action is clear, it lacks specific guidance on how to address the trade-off issue or which hyper-parameters to adjust. Therefore, the comment is somewhat actionable, as it provides a direction but lacks detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"3)\\\" and \\\"Table 5,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the proposed approach not outperforming or being worse than Decouple [Kang et al.], and it highlights the trade-off between head and tail categories. The comment further suggests that similar trade-offs have not been fully investigated for the baselines and provides an example of how hyper-parameters could be adjusted to improve tail accuracy. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also mentions that Table 5 shows a trade-off between head and tail categories but notes that similar trade-offs have not been fully investigated for the baselines. The reviewer suggests that by adjusting hyper-parameters in Decouple [Kang et al.], the tail accuracy could be improved while slightly decreasing the head accuracy. This claim is supported by logical reasoning and a specific example, making it mostly verifiable. However, the comment could be strengthened by providing more detailed evidence or references to support the claim about the trade-off and hyper-parameter adjustments. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment provides a critical evaluation of the paper's performance, noting that the proposed approach does not outperform or is even worse than Decouple [Kang et al.] for overall performance. It also highlights a trade-off between head and tail categories, which has not been fully investigated for the baselines. The reviewer suggests that by adjusting hyper-parameters in Decouple [Kang et al.], the tail accuracy could be improved while slightly decreasing the head accuracy. This feedback is clear and actionable, as it identifies a significant weakness in the paper and provides a constructive suggestion for improvement. However, it could be more helpful if it offered specific guidance on how to adjust the hyper-parameters or suggested additional experiments to explore the trade-off. Overall, the comment is mostly helpful, as it directs the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises questions about the intuition behind the specific choice of $\\\\lambda_t$ in the proposed E2W algorithm and suggests exploring the impact of not including the exploration parameter $\\\\epsilon$. It also questions the use of $\\\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\\\lambda_s$ in Equation (7). While these questions imply that the authors should provide further explanation or justification for their choices, they do not explicitly instruct the authors to make any changes or improvements. The actions are implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"proposed E2W algorithm\\\" and \\\"Equation (7),\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises detailed questions about the intuition behind the choice of $\\\\lambda_t$, the inclusion of the exploration parameter $\\\\epsilon$, and the use of $\\\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\\\lambda_s$. These questions provide clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the intuition behind specific choices in the E2W algorithm and the use of certain parameters. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises several questions about the intuition behind the specific choice of $\\\\lambda_t$ in the proposed E2W algorithm and suggests exploring the impact of not including the exploration parameter $\\\\epsilon$. It also questions the use of $\\\\sum_a N(s, a)$ instead of $N(s, a)$ for $\\\\lambda_s$ in Equation (7). While these questions highlight areas of potential confusion or lack of clarity in the paper, they do not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to clarify their choices and reasoning, but it lacks actionable advice or detailed guidance on how to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that this evaluation may be unreliable. It also mentions that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. While the comment identifies areas for improvement, it does not provide explicit instructions on how to incorporate these additional scenarios or how to conduct the ablation studies. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to address the feedback. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Fig 4(5),\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the limitation of the evaluation, which is mostly based on four OCR QA datasets, and suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. This provides clear guidance on what needs to be addressed to improve the evaluation. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the evaluation is limited, primarily relying on four OCR QA datasets, and suggests that this may be unreliable. The reviewer supports this claim by referencing Figure 4(5), which indicates that the evaluation may be unreliable. Additionally, the comment suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. While the comment provides some reasoning and a reference to a figure, it lacks detailed justification or specific examples to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires more detailed evidence or examples to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation in the evaluation section, noting that it primarily relies on four OCR QA datasets. It acknowledges that this evaluation may be unreliable and suggests that more scenarios, such as the LLaVA benchmark, would be expected, especially in ablation studies. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the robustness and comprehensiveness of their evaluation. By recommending additional benchmarks and scenarios, the comment offers valuable guidance on how to improve the paper's evaluation section. However, it could be more helpful if it included specific examples or suggestions on how to incorporate these additional scenarios. Overall, the comment is mostly helpful, as it effectively directs the authors toward meaningful improvements in their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests adding a clarification about the function pi, which is described as a function from R^m to \\\\Delta^{K+1}. Additionally, it questions the dimensions in equation (2) and suggests an alternative approach by assuming the first column of X_t is always 0. These suggestions are clear and provide specific guidance on how to improve the draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L75\\\" and \\\"(2)\\\" in the paper, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues by questioning the dimensions in equation (2) and suggesting an alternative approach by assuming the first column of X_t is always 0. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a request for clarification and a question about the dimensions in equation (2). It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by pointing out a potential issue with the dimensions in equation (2) and suggesting an alternative approach by assuming the first column of X_t is always 0. This feedback is clear and offers a concrete suggestion for improving the clarity and consistency of the paper. By addressing this point, the authors can enhance the precision of their mathematical formulation. However, the comment could be more helpful if it included additional context or explanation about why this change is necessary or how it impacts the overall understanding of the paper. Despite this, the feedback is mostly helpful as it directs the authors to a specific area needing clarification and offers a constructive suggestion for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the evaluation of weak supervision could be improved by considering the realism of the evaluated tweets. It highlights specific issues, such as the requirement for all structured elements for perspectives to be present in the generated tweets and the unrealistic nature of the authors' generation process. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions to improve the evaluation. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the evaluation of weak supervision and raises concerns about the realism of the evaluated tweets and the generation process. It provides specific examples, such as the requirement for all structured elements for perspectives to be present in the generated tweets and the unrealistic nature of the authors' generation process. However, it does not explicitly mention which part of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the issues with the evaluation and the generation process. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises concerns about the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. The reviewer provides specific examples, such as the requirement for all structured elements for perspectives to be present in the generated tweets and the unrealistic nature of the authors' generation process. These examples offer some support for the claim, but the comment could be strengthened with more detailed reasoning or references to similar studies. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some support but lacks comprehensive justification.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the evaluation of weak supervision, specifically questioning the realism of the evaluated tweets and the generation process. It highlights a specific concern about the requirement for all structured elements for perspectives to be present in the generated tweets, which may not reflect real-world scenarios. Additionally, it points out an unrealistic aspect of the authors' generation process, where \\\"[author] embeddings are initialized by averaging the corresponding artificial tweets.\\\" While the comment raises important questions about the evaluation's validity, it lacks specific suggestions or guidance on how the authors might address these concerns or improve the realism of their approach. This limits the comment's usefulness, making it somewhat helpful as it provides insight but not comprehensive guidance for improvement.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to include keypoint detection results in the experiments section. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific suggestion on where to incorporate the results, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests including keypoint detection results in the experiments section. However, it does not specify which part of the experiments section this should be included in, making it weakly grounded. The comment is specific in its request for the inclusion of keypoint detection results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that keypoint detection results should be included in the experiments section. However, it does not provide any justification or reasoning for why this inclusion is necessary or how it would benefit the paper. Without supporting evidence or explanation, the claim lacks verifiability, making it difficult for the authors to understand the importance or necessity of including these results. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion by recommending that keypoint detection results should be included in the experiments section. This feedback is clear and directly guides the authors on what additional information to incorporate, which can enhance the comprehensiveness and depth of their experimental analysis. However, the comment could be more helpful if it explained why including these results is important or how they might impact the overall findings. Despite this, the suggestion is clear and actionable, making the comment mostly helpful. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to compare their proposed model with existing models where answers are also used as inputs, specifically mentioning \\\"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\\\" This direct request provides a clear and concrete action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is highly actionable because it offers specific guidance on how to address the issue, making it easy for the authors to implement the suggested comparison.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests comparing the proposed model with existing models where answers are used as inputs, specifically mentioning \\\"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\\\" However, it does not specify which part of the paper should include this comparison, making it weakly grounded. The comment is specific in its request for a comparison with a particular existing model, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that ternary potential is a key factor in the performance improvement of the proposed model and recommends comparing it with existing models that use answers as inputs. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would benefit the evaluation. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion and address it effectively. Therefore, the claim is considered borderline verifiable, as it provides some direction but lacks sufficient support to be fully actionable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a key factor in the performance improvement of the proposed model, which is the use of ternary potential. It suggests that the authors compare their model with existing models that also use answers as inputs, specifically mentioning \\\"Revisiting Visual Question Answering Baselines (Jabri et al., ECCV16).\\\" This feedback is clear and actionable, providing a specific direction for the authors to enhance their work by including a relevant comparison. However, the comment could be more helpful if it explained why this comparison is important or how it might impact the evaluation of the proposed model. Despite this, the suggestion is valuable and offers a concrete step for the authors to improve their draft, making the comment mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the discourse relations in Table A2, suggesting that there might be an artifact of colloquial language or that \\\"discourse\\\" is used for things not considered discourse in other languages in UD. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this observation or clarify the use of \\\"discourse.\\\" Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table A2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the presence of a large number of discourse relations and whether this is due to colloquial language or a specific choice in the treebank. This provides clear guidance on what aspect of the table needs further clarification or explanation. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a question about the discourse relations in Table A2, suggesting that there might be an artifact of colloquial language or a specific choice in the treebank. However, it does not provide any supporting evidence, reasoning, or references to justify the claim or question. The comment lacks detailed explanation or examples that would help the authors understand the issue or address it effectively. As a result, the claim is unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the discourse relations in Table A2, suggesting that there might be an artifact of colloquial language or a specific choice in the treebank. This feedback prompts the authors to clarify or justify their use of \\\"discourse\\\" in their analysis, which could help improve the transparency and accuracy of their work. However, the comment lacks specific suggestions or guidance on how to address this issue, such as recommending a particular approach or providing examples. While it identifies a potential area for clarification, it does not offer actionable steps for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises concerns about the use of soft labels and the results presented, suggesting that the authors may be using subpar hyperparameters. However, it does not provide explicit guidance or concrete steps on how the authors should address these concerns or improve their draft. The feedback lacks specificity and actionable details, leaving the authors uncertain about how to respond to the critique. As a result, the comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses specific issues related to the use of soft labels and the results presented, particularly concerning the iNaturalist19 dataset and the potential use of a higher beta value. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment does specify what needs to be addressed, such as the use of subpar hyperparameters and the potential extension of curves, providing some level of specificity. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point makes a claim about the use of soft labels and the results presented, suggesting that the authors may be using subpar hyperparameters. However, the comment lacks specific evidence or detailed reasoning to support this claim. It does not provide examples or references to substantiate the assertion that the results are \\\"fairly impressive\\\" or that the authors are using subpar hyperparameters. This makes the claim borderline verifiable, as it provides some initial reasoning but lacks the necessary detail to fully substantiate the critique. Therefore, the comment is rated as 2: Borderline Verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment raises concerns about the use of soft labels and the results presented, suggesting that the authors may be using subpar hyperparameters. It points out that the results appear impressive but questions the choice of hyperparameters, particularly in relation to the iNaturalist19 dataset. However, the comment lacks specific guidance or actionable suggestions on how the authors might address these concerns or improve their draft. While it identifies potential issues, it does not provide detailed feedback or examples that would help the authors make improvements. Therefore, the comment is somewhat helpful, as it highlights areas for consideration but lacks depth and specificity.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should expand their evaluation of the simple/traditional experiment for unseen characters, specifically by including translations in Figure 6 for those who do not speak Chinese. This feedback provides a clear and explicit action for the authors to take, which is to enhance the evaluation by adding translations. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 6,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests adding translations to Figure 6 for those who do not speak Chinese, indicating a clear need for additional evaluation in this direction. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the presentation of the simple/traditional experiment for unseen characters is underdeveloped and recommends expanding the evaluation, specifically by including translations in Figure 6. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that more evaluation is needed. The suggestion to add translations is clear, but the overall claim is somewhat verifiable due to the need for more detailed justification or evidence to fully substantiate the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the positive aspect of the simple/traditional experiment for unseen characters but points out that it is presented as an afterthought. It suggests expanding the evaluation by including translations in Figure 6, which would benefit readers who do not speak Chinese. This feedback is clear and actionable, providing a specific direction for enhancing the paper's accessibility and comprehensiveness. However, the comment could be more helpful if it offered additional suggestions or examples of how to effectively incorporate translations into the evaluation. Overall, the comment is mostly helpful as it identifies a specific area for improvement and provides a constructive suggestion, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It clearly states that the text in Table 1 is too small and hard to read, suggesting that the authors should adjust the font size or layout for better readability. Additionally, it points out a missing gradient symbol in Algorithm 1, line 4, indicating that this should be corrected. The comment also lists specific references, which may be related to the paper's content or related work. These explicit and concrete actions provide clear guidance on how the authors can improve their draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"table 1\\\" and \\\"Algorithm 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the text in Table 1 being too small and hard to read, and it points out the missing gradient symbol in Algorithm 1. Additionally, it provides references, which could be relevant to the context of the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual observations and requests for clarification. It does not contain subjective claims, opinions, or suggestions that require justification or evidence. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on two distinct issues. First, it points out that the text in Table 1 is too small and hard to read, suggesting that the authors should adjust the font size or layout for better readability. This is a clear and direct suggestion that can help improve the presentation of the paper. Second, the comment identifies a missing gradient symbol in Algorithm 1, line 4, indicating that this should be corrected. This is a precise and actionable piece of feedback that can help the authors enhance the accuracy and clarity of their algorithm description. Additionally, the comment includes references, which may be relevant to the context of the paper. Overall, the feedback is clear, specific, and actionable, providing the authors with concrete steps to improve their draft. Therefore, it is highly helpful.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should render Figure 1 more naturally by using bracketed arguments as described in the citation (Wright et al., 1934). It also questions the compatibility of this approach with hyperref. While the comment provides a specific suggestion for improving the rendering of the figure, it does not explicitly instruct the authors on how to implement this change. The action is implicit, as the authors need to infer that they should use the bracketed arguments, and it is somewhat vague because it does not provide detailed guidance on how to integrate this with hyperref. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the use of bracketed arguments as described in the citation (Wright et al., 1934) and questions the compatibility with hyperref. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the rendering of Figure 1 could be improved by using bracketed arguments as described in the citation (Wright et al., 1934). However, the comment does not provide specific reasoning or evidence to support why this approach would enhance the rendering or how it interacts with hyperref. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the suggestion and address it effectively. Therefore, the comment is considered borderline verifiable, as it provides an idea but lacks sufficient support to be fully actionable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment suggests a specific improvement to the rendering of Figure 1 by recommending the use of bracketed arguments as described in the citation (Wright et al., 1934). It also raises a question about the compatibility of this approach with hyperref, which is a relevant concern for the authors to consider. While the comment provides a clear and actionable suggestion for improving the presentation of the figure, it could be more helpful by explaining why this approach is beneficial or how it might impact the overall clarity of the paper. Despite this, the feedback is mostly helpful as it guides the authors toward a specific enhancement that could improve the draft. Therefore, it aligns with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a gap in the discussion of computational aspects, particularly regarding the applicability of the proposed methods to high-dimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. The reviewer notes that the experiments are conducted on small-scale datasets, which may not reflect the practical usefulness of the methods in high dimensions. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the discussion. The feedback is somewhat actionable as it identifies a key area for improvement but lacks concrete steps or suggestions for the authors to follow.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment highlights a lack of detailed discussion on computational aspects, particularly in the context of high-dimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. The comment also notes that the experiments are performed on small-scale datasets, which may not reflect the practical usefulness of the methods in high dimensions. However, the comment does not specify which sections or parts of the paper should include this discussion, making it weakly grounded. The comment is specific in identifying the issue with computational aspects and the limitations of the experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the lack of detailed discussion on computational aspects, particularly regarding the applicability of the proposed methods to high-dimensional data. The reviewer highlights that the algorithm involves solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. This is supported by the observation that the experiments are conducted on small-scale datasets, which may not reflect the practical usefulness of the methods in high dimensions. While the comment provides a logical reasoning and some context, it lacks specific examples or references to fully substantiate the claim. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but requires further detail to be fully convincing.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a gap in the discussion of computational aspects, particularly regarding the applicability of the proposed methods to high-dimensional data. It points out that the algorithm involves solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. The reviewer notes that the experiments are conducted on small-scale datasets, which may not reflect the practical usefulness of the methods in high dimensions. This feedback is somewhat helpful as it highlights an important area for improvement and provides a specific observation about the limitations of the experiments. However, it lacks detailed suggestions or guidance on how the authors might address these issues or improve the discussion on computational aspects. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take regarding the equations in the paper. It specifies the exact changes needed, such as correcting the signs in the equation below Line 502 and in the definition of B under Line 503. Additionally, it suggests a specific change in Line 504. These detailed instructions give the authors clear guidance on how to improve their draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines (Line 502, Line 503, and Line 504), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the exact errors and corrections needed, such as changing the '+' sign to a '-' sign in the equation below Line 502, and providing a specific suggestion for Line 504. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a series of claims regarding specific errors in the equations presented in the paper. These claims are based on direct observation and correction of the signs in the equations. The comment provides precise and specific feedback, making it fully verifiable. The authors can easily verify the claims and apply the suggested corrections, ensuring the accuracy of the equations in the paper. Therefore, the comment is classified as 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by identifying and correcting errors in the equations presented in the paper. It points out the incorrect signs in the equations below Line 502 and in the definition of B under Line 503, as well as in Line 504. By offering clear and precise corrections, the comment empowers the authors to make accurate changes to their draft, enhancing the clarity and correctness of their work. This level of detail and specificity makes the comment highly helpful, as it directly addresses a critical aspect of the paper that needs improvement.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests that comparing to a deeper ResNet with parameter sharing could be an interesting baseline, equivalent to an ODE net with a fixed time-step Euler integrator. While the comment implies that the authors should consider this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement this suggestion. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"section 7.1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the ResNet shares parameters between residual blocks and suggests a potentially interesting baseline for comparison. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a question and a suggestion for an additional experiment. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a pertinent question about whether the ResNet in the experiments shares parameters between residual blocks. It suggests an interesting baseline for comparison, which would be a deeper ResNet with parameter sharing, equivalent to an ODE net with a fixed time-step Euler integrator. This feedback is clear and actionable, as it provides a specific suggestion for an additional experiment that could enhance the paper's contribution and provide valuable insights. By addressing this point, the authors could improve the depth and comprehensiveness of their work. However, the comment could be more helpful if it included a rationale for why this comparison is important or how it might impact the results. Overall, the comment is mostly helpful, as it offers a clear direction for improvement but could be expanded with additional context.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out an odd design choice in the paper, specifically the trimming of questions after the first 10, and suggests that this choice is questionable, especially since the question model is a bag of words, which is not expensive to encode longer sequences. However, the comment does not provide explicit guidance on how the authors should address this issue or what alternative approaches might be considered. The action is implicit and vague, as it lacks concrete steps for the authors to take. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L254,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue with the design choice of trimming questions after the first 10, particularly in the context of a bag-of-words question model. This provides clear guidance on what aspect of the design choice is problematic. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the design choice of trimming questions after the first 10, particularly in the context of a bag-of-words question model. The reviewer suggests that this choice is questionable because the model is not expensive to encode longer sequences. However, the comment lacks specific reasoning or evidence to support why this design choice is problematic or how it affects the model's performance. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some reasoning but lacks sufficient detail to be fully verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific design choice in the paper, namely the trimming of questions after the first 10, and questions its rationale, especially in the context of a bag-of-words question model. This feedback is somewhat helpful as it prompts the authors to reconsider their design choice and potentially justify it in their paper. However, the comment does not provide suggestions or alternative approaches to address the issue, which limits its helpfulness. To be more beneficial, the comment could include specific reasons why the design choice is problematic or how it might affect the model's performance. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about the clarity of Figure 1, specifically questioning how the proposed method produces the explanation that \\\"mutagens contain the NO2 group.\\\" The reviewer suggests that this analysis might require additional post-analysis to extract shared motifs. However, the comment does not provide explicit guidance on how the authors should address this issue or improve the clarity of the figure. The action is implicit, as the authors need to infer that they should clarify the explanation in Figure 1, and it is vague because it lacks concrete steps on how to achieve this. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of how the proposed method produces the explanation in Figure 1, particularly regarding the \\\"mutagens contain the NO2 group.\\\" The comment suggests that additional post-analysis might be necessary to extract shared motifs, providing a clear direction for improvement. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the clarity of Figure 1 regarding the explanation of the proposed method, specifically regarding the presence of the NO2 group in mutagens. The reviewer suggests that this analysis might require additional post-analysis to extract shared motifs, implying that the proposed method could simplify this process. However, the comment lacks specific examples or detailed reasoning to support the claim that the analysis is necessary or how it could be improved. This makes the claim somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Figure 1, questioning the clarity of how the proposed method produces the explanation that \\\"mutagens contain the NO2 group.\\\" It suggests that this analysis might require additional post-analysis to extract shared motifs, implying that the proposed method could simplify this process. However, the comment does not provide detailed guidance or suggestions on how the authors might address this issue or improve the clarity of the figure. While it points out a potential weakness, it lacks actionable advice, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point makes a statement about the potential issue of non-convexity in the context of SGD convergence, suggesting that it may not be a problem if the function Z has certain properties. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the authors' work, nor are there suggestions for further exploration or improvement. As a result, the comment lacks actionability, leaving the authors without direction on how to apply this information to enhance their draft. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions lines 182-184, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the potential non-convexity of the function Z and its implications for SGD convergence. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes a claim about the potential issue of non-convexity in the context of SGD convergence, suggesting that it may not be a problem if the function Z has certain properties. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered borderline verifiable, as it provides some insight but lacks sufficient justification or examples.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment provides a statement about the potential issue of non-convexity in the context of SGD convergence, suggesting that it may not be a problem if the function Z has certain properties. However, the comment lacks depth and does not offer any actionable feedback or suggestions for improvement. It does not specify how the authors might address this issue or what additional information could be included to clarify the point. As a result, the comment is not particularly helpful in guiding the authors toward enhancing their draft. Therefore, it aligns with a score of 1, indicating that the comment is not helpful at all.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights several issues with the paper, including the lack of comparison with models other than GPT2, confusing sections, and missing citations and references. While it identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues. The authors can infer that they need to add comparisons, clarify confusing sections, and correct the missing citations and references, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is somewhat actionable, as it identifies areas for improvement but does not provide detailed instructions on execution.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines and sections of the paper, such as Line 99, section 3.1, Line 165, section 3.4, and the comparison with models other than GPT2. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issues with the paper, including the lack of comparison with other models, confusing sections, missing citations, and unreferenced notation. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of several claims: the lack of comparison with models other than GPT2, confusing sections, missing citations, and unreferenced notation. Each of these claims is supported by specific references to lines and sections in the paper, such as Line 99, section 3.1, and Line 165, section 3.4. This provides clear and precise evidence for each claim, making it fully verifiable. The detailed references and specific examples allow the authors to understand and address the issues effectively, justifying a score of 5: Fully Verifiable.\",\n    \"verifiability_label\": \"5\",\n    \"helpfulness_rationale\": \"The review comment identifies several areas for improvement in the paper. It points out the lack of comparison with models other than GPT2, which could provide a broader context for the study. Additionally, it highlights confusing sections and missing citations, which are important for clarity and completeness. The comment also notes the absence of a reference for the notation \\u0303D(c) in section 3.4. While these points are valuable, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of what additional comparisons or references might look like. Overall, the feedback is somewhat helpful as it directs the authors to areas needing improvement, but it lacks detailed guidance for making those improvements.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point poses a question about the meaning of a specific expression in Equation (2). While it highlights a potential area of confusion, it does not provide explicit guidance or suggestions for the authors to address this issue. The authors can infer that they need to clarify the meaning of the expression, but the comment does not specify how they should do so. The action is implicit and vague, leaving the authors without clear direction on how to improve their draft. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Equation (2),\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the meaning of the expression \\\"$\\\\sigma_t^2=\\\\alpha_t-\\\\alpha_t^2$\\\" in the equation. This provides clear guidance on what the authors need to clarify or explain in their paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a request for clarification regarding the meaning of a specific expression in Equation (2). It does not contain an opinion, judgment, or suggestion that requires verification. It is purely factual and seeks information, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the meaning of a specific expression in Equation (2), which could indicate a lack of clarity or potential misunderstanding in the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or clarify the expression. Without actionable feedback or specific advice, the authors are left without a clear path to improve their draft. Therefore, the comment is barely helpful, as it identifies a potential area of confusion but does not offer any actionable advice.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly identifies specific lines in the SuppMat that need to be corrected, providing clear and concrete actions for the authors to take. It specifies the exact lines and the correct color, symbol, and reference for each correction. This level of detail ensures that the authors know exactly what changes to make, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific lines in the SuppMat (L502, L507, and L509), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, such as the color of the lines, the symbols, and the references. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of factual observations about the content of the SuppMat, specifically pointing out discrepancies in the color, symbols, and references. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback by identifying discrepancies in the SuppMat, such as incorrect color, symbols, and references. It clearly points out the exact lines that need correction, offering the authors a precise way to improve the accuracy and clarity of their supplementary material. This level of detail and clarity makes the comment highly helpful, as it empowers the authors to make targeted improvements to their draft. Therefore, the comment aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a concern about the lack of comparison between the proposed method and online learning approaches, as well as reinforcement learning (RL). It questions why online learning is overlooked and asks for clarification on the practical considerations and challenges associated with online learning. The comment implies that the authors should provide a comparison against online learning approaches and RL, but it does not explicitly instruct them to do so. Additionally, it raises specific questions about the retraining cost and challenges of including online learning in the evaluation. While the action is implicit, it is somewhat concrete as it provides specific questions that the authors can address to improve their draft. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors discuss the online learning formulation and its limitations. It also specifies the issue by questioning the lack of comparison against online learning approaches and RL, and asks for clarification on the practical considerations and challenges associated with online learning. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the lack of comparison between the proposed method and online learning approaches, as well as reinforcement learning (RL). It questions the practical considerations and challenges associated with online learning, such as retraining cost, and asks for clarification on why it is discarded. The comment is somewhat verifiable as it provides logical reasoning and questions that highlight the need for a more comprehensive comparison. However, it lacks specific examples or references to substantiate the claim fully, making it somewhat verifiable. The authors would need to further explore these questions to address the critique effectively.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant gap in the paper regarding the lack of comparison between the proposed method and online learning approaches, as well as reinforcement learning (RL). It questions the practical considerations and challenges associated with online learning, such as retraining cost, and asks for clarification on why it is discarded. This feedback is clear and actionable, as it prompts the authors to provide a more comprehensive comparison and address the practical considerations of online learning. However, the comment could be more helpful if it offered specific suggestions on how to conduct this comparison or what aspects to focus on. Overall, the comment is mostly helpful as it directs the authors to a critical area needing improvement, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly identifies missing references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encode-decoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works. This feedback provides a clear and concrete action for the authors to take, namely, to add these references and conduct a comparison. The explicit nature of the suggestion and the specific references make this comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the missing references, GFF[1] and EfficientFCN[2], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending a comprehensive comparison with these works, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encode-decoder architecture. The reviewer encourages a comprehensive comparison with these works. The comment is mostly verifiable as it provides specific references and suggests a comparison, which allows the authors to understand the basis of the claim. However, it could be further strengthened by explaining why these references are relevant or how they relate to the current work. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant omission in the paper by pointing out the absence of important references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encode-decoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works, which is a clear and actionable suggestion. Additionally, the comment notes that the societal impact is discussed on the last page of the manuscript, which is a relevant observation. This feedback is mostly helpful as it provides specific guidance on how to enhance the paper's literature review and comparison, but it could be more helpful if it offered additional suggestions on how to integrate these references into the discussion. Overall, the comment is rated as mostly helpful.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point questions the claim made by the authors regarding the effectiveness of their proposed prompts, suggesting that the slight improvement observed in Table 6 and Table 7 does not support this claim. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve their draft. Without specific suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 6\\\" and \\\"Table 7,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the claim that \\\"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\\\" given the slight improvement observed in the tables. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the claim that \\\"Experimental results across various language pairs and domains proved the effectiveness of our proposed prompts,\\\" based on the slight improvement observed in Table 6 and Table 7. However, the comment does not provide any specific reasoning, examples, or references to support why this slight improvement is insufficient to substantiate the claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment questions the claim made by the authors regarding the effectiveness of their proposed prompts, suggesting that the slight improvement observed in Table 6 and Table 7 does not support the claim. While the comment identifies a potential issue with the claim, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or strengthen their argument. The feedback is somewhat helpful as it prompts the authors to reconsider their claims, but it could be more beneficial with additional context or suggestions for improvement. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the analysis of the Cycle FC is insufficient and implies that there could be many different designs for it. It provides a specific example of exploring different sampling intervals and sample sizes. However, the comment does not explicitly instruct the authors to conduct these analyses or provide detailed guidance on how to implement them. The action is implicit and somewhat vague, as the authors need to infer that they should explore these aspects but may not be entirely sure of the exact steps to take. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses the Cycle FC and suggests that the analysis is insufficient, implying that there could be many different designs. It provides a specific example of exploring different sampling intervals and sample sizes. However, it does not explicitly mention which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in suggesting additional experiments or analyses, providing clear guidance on what could be improved. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the analysis of the Cycle FC is insufficient and suggests that there could be many different designs. However, it does not provide specific examples or detailed reasoning to support this claim. The suggestion to explore different sampling intervals and sample sizes is a potential improvement, but without further elaboration or evidence, the claim remains vague. Therefore, the comment is considered borderline verifiable, as it provides some direction but lacks sufficient justification or examples to fully substantiate the claim.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the analysis of the Cycle FC, noting that it aligns features at different spatial locations to the same channel, but the analysis is insufficient. It suggests that there could be many different designs and provides a specific example of exploring different sampling intervals and sample sizes. This feedback is somewhat helpful as it points out a specific area for improvement and offers a direction for further exploration. However, it lacks detailed guidance or suggestions on how to conduct these analyses or what specific aspects to focus on, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about the practical performance of the proposed algorithms, specifically noting the use of a Vandermonde matrix, which is known to be ill-conditioned and numerically unstable. The reviewer expresses concern that the algorithm may fail in practice, especially for moderate sizes of $n$, $k$, and $L$. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. While the comment implies that the authors should include experimental results, it does not explicitly instruct them to do so. The action is clear but stated implicitly, and the authors can infer that they need to conduct and present experimental results. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 1\\\" and discusses the use of a Vandermonde matrix, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the concern about the algorithm's practical performance, particularly its numerical instability due to the ill-conditioned Vandermonde matrix, and suggests providing experimental results to address this issue. Therefore, this comment is labeled as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the practical performance of the proposed algorithms, specifically questioning the use of a Vandermonde matrix in Algorithm 1. The reviewer provides a logical reasoning by explaining that Vandermonde matrices are known to be ill-conditioned and numerically unstable, especially for large $n$ and small $\\\\alpha$. They also mention that $\\\\alpha$ can be as small as $1/k^2L^2$, which further supports their concern. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. This reasoning is mostly verifiable, as it provides a clear explanation of the issue and suggests a way to address it, but it could be strengthened with specific references or examples of similar issues in the literature. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment raises a significant concern about the practical performance of the proposed algorithms, specifically focusing on the use of a Vandermonde matrix in Algorithm 1. It highlights the known issues with Vandermonde matrices being ill-conditioned and numerically unstable, especially for large values of $n$ and small values of $\\\\alpha$. The reviewer expresses concern that the algorithm may fail in practice even for moderate sizes of $n$, $k$, and $L$. The comment suggests that the paper would be more convincing if the authors provided experimental results for the proposed algorithms. This feedback is clear and actionable, as it identifies a critical area for improvement and provides a specific suggestion for addressing the concern. However, it could be more helpful if it offered additional guidance on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights the absence of standard deviations in the results, which raises concerns about the reliability of the best-performing method. However, it does not provide explicit guidance on how to address this issue, such as suggesting the inclusion of standard deviations or explaining why they are important. The action is implicit, as the authors can infer that they should include standard deviations, but it remains vague because it lacks concrete steps on how to implement this change. Therefore, the comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment highlights the absence of standard deviations in the results, which raises concerns about the reliability of the best-performing method. However, it does not specify which part of the paper this issue pertains to, such as specific tables, figures, or sections where standard deviations should be included. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in identifying the issue of missing standard deviations, it is weakly grounded because it does not direct the authors to a specific section or part of the paper. Therefore, this comment is weakly grounded and specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the lack of standard deviations in the results, suggesting that it is unclear whether the best method is truly the best or if other configurations have comparable performances. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment identifies a specific issue with the presentation of results, noting the absence of standard deviations. This is a relevant point, as the inclusion of standard deviations would provide a clearer understanding of the variability in the results and help determine if the best-performing method is truly superior to others. However, the comment lacks depth and does not offer suggestions on how to incorporate standard deviations or discuss their importance in the context of the study. While it points out a potential weakness, it does not provide actionable guidance for improvement, making it somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point poses a question about the choice of p < 0.4 in Algorithm 1. While it highlights a potential area of interest, it does not provide any explicit or implicit action for the authors to take. The comment lacks guidance on whether this choice is critical, if it needs justification, or if it should be modified. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of p < 0.4, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The comment is a question asking for clarification about the choice of p < 0.4 in Algorithm 1. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and seeks information, making \\\"No\\\" the correct label.\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the choice of p < 0.4 in Algorithm 1, suggesting that the authors may need to provide more context or justification for this choice. While the comment identifies a potential area of interest, it lacks specificity and does not offer any guidance or suggestions on how the authors might address this issue. The feedback is somewhat helpful as it prompts the authors to consider the rationale behind their choice, but it does not provide actionable steps or detailed insights to improve the draft. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to provide explanations or analyses for Figures 1, 2, and 3, specifically addressing the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and provides concrete guidance on what the authors need to do to improve their draft. The authors know exactly what is expected of them, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 5\\\" and the figures \\\"Figure 1, Figure 2, and Figure 3,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of explanations or analysis for the figures, particularly the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the authors fail to provide explanations or analysis for Figures 1, 2, and 3, specifically questioning the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. While the comment identifies specific areas lacking explanation, it does not provide any supporting evidence or reasoning to justify why these figures are problematic or how they should be interpreted. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered borderline verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the presentation of figures in Section 5, noting that the authors fail to provide explanations or analyses for Figures 1, 2, and 3. It highlights the need to clarify the presence of negative numbers in Figure 1 and the implications of Figures 2 and 3. This feedback is clear and actionable, as it directs the authors to address a critical gap in their manuscript by providing necessary explanations and analyses for the figures. By doing so, the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present these figures or what specific aspects to focus on in the explanations. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point notes that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, as shown in Table 2. It raises a question about whether RLCD or RLCD-Rescore can scale to larger language models that are better at differentiating responses near the decision boundary. While the comment highlights an area of interest, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Tab. 2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B. The comment further raises a question about whether RLCD or RLCD-Rescore can scale to larger language models, which are better at differentiating responses near the decision boundary. This provides clear guidance on what the authors need to consider or address in their work. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, as shown in Table 2. However, the comment does not provide specific data or examples from Table 2 to support this claim, nor does it offer a detailed explanation of why this trend might occur. Without explicit evidence or reasoning, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2: Borderline Verifiable, as it provides some insight but lacks sufficient detail to be fully verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment observes that the advantage of RLCD over RLAIF diminishes as the model size increases from 7B to 30B, as shown in Table 2. It raises a pertinent question about whether RLCD or RLCD-Rescore can scale to larger language models that are better at differentiating responses near the decision boundary. This feedback is somewhat helpful as it identifies a potential limitation in the scalability of the proposed method and prompts the authors to consider its applicability to larger models. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address this issue or what aspects of the method might need adjustment for larger models. Overall, the comment offers some insight but lacks detailed actionable advice, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to large-scale datasets, such as ImageNet, and suggests that addressing the scalability issue is crucial for the paper's practical contribution. However, the comment does not provide explicit guidance or suggestions on how to address the scalability issue. The authors are left to infer that they need to consider scalability, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the scalability issue of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be applied to large-scale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper's practical contribution. However, the comment does not specify which part of the paper discusses the NC measure or the scalability issue, making it weakly grounded. The comment is specific in identifying the scalability issue as a potential limitation, but without clear grounding, the authors may struggle to pinpoint where to address this concern. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. The reviewer questions how this method can be applied to large-scale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper's practical contribution. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about scalability. Without these elements, the claim is somewhat verifiable, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a critical concern about the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be applied to large-scale datasets like ImageNet and suggests that addressing the scalability issue is essential for the paper's practical contribution. While the comment identifies a significant limitation, it does not provide specific suggestions or solutions for how to address the scalability challenge. This limits the comment's helpfulness, as the authors are left with a clear problem to address but without actionable guidance on how to resolve it. Therefore, the comment is somewhat helpful, as it highlights an important area for improvement but lacks depth and specificity in its guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the complexity of the proposed CoNO model, specifically questioning which component (the fractional transform or the UNet operation) contributes to the claimed performance boost. The reviewer suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains. This feedback provides a clear and explicit action for the authors to take, which is to conduct comparisons with UNets. The suggestion is concrete, as it specifies the type of comparison needed and provides references to relevant works (Raonic et al. or Gupta et al.) that could serve as a basis for the comparison. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment addresses the proposed CoNO model and its use of a complex UNet part after the fractional transform. It raises a specific concern about the source of the claimed performance boost, questioning whether it is due to the fractional transform or the UNet operation. The reviewer suggests that comparisons to UNets are necessary, especially given the strong performance of UNets on regular gridded domains. This feedback is specific as it clearly identifies the issue and provides a rationale for the need for comparisons. However, the comment does not explicitly mention which part of the paper discusses the CoNO model, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point questions the source of the claimed performance boost in the proposed CoNO model, specifically whether it is due to the fractional transform or the UNet operation. The reviewer suggests that comparisons to UNets are necessary, especially since UNets have shown strong performance on regular gridded domains. This claim is supported by references to Raonic et al. and Gupta et al., which provide evidence for the strong performance of UNets. The comment is mostly verifiable as it provides a logical reasoning and references to support the need for comparisons, but it could be strengthened by including more specific examples or detailed explanations of the performance differences. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the proposed CoNO model, specifically questioning the source of the claimed performance boost. It suggests that the complexity of the model, with its fractional transform and UNet operation, makes it difficult to determine which component contributes to the performance. The comment provides a clear and actionable suggestion by recommending comparisons to UNets, especially since UNets have shown strong performance on regular gridded domains. This feedback is constructive and offers a specific direction for the authors to improve their draft by conducting additional comparisons. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights that the proposed PSA method requires more computation than baselines and suggests that the comparison of computation complexity should be included in the experiment part. While the comment implies that the authors should add a comparison of computation complexity, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to conduct this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Algorithm 1\\\" and the specific issue of computation complexity, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the comparison of computation complexity in the experiment part. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the proposed PSA method requires more computation than baselines and suggests that a comparison of computation complexity should be included in the experiment part. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim about the increased computational requirements. Without such evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is considered borderline verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the proposed PSA method, noting that it requires more computation than the baselines. It highlights a potential area for improvement by suggesting that a comparison of computation complexity should be included in the experiment part. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their method that could impact its practicality and efficiency. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific metrics should be considered. Overall, the comment is mostly helpful as it points out a significant area for improvement and offers a clear direction for the authors to follow.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point provides explicit and concrete actions for the authors to take. It suggests specific changes to the figures, such as increasing the font size for certain elements like V_mem, Th_i, U_i^t, and the words in the grey box. It also recommends using a table to better emphasize the data and justify the improved accuracy. Additionally, it points out the lack of details comparison with other state-of-the-art Transformer designs, such as epochs and the number of parameters. These suggestions are clear and actionable, providing the authors with specific guidance on how to improve their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific figures (Fig 1 and Fig 2), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues with the fonts and the need for larger fonts in certain elements, as well as the lack of details comparison with other state-of-the-art Transformer designs. The suggestion to use a table for better emphasis on the data is also specific. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point makes several claims regarding the figures, such as the need for larger fonts and specific elements to be larger, and the lack of details comparison with other state-of-the-art Transformer designs. While the comment provides some specific observations about the figures, it lacks detailed reasoning or references to support the need for these changes. The suggestion to use a table for better emphasis is also not substantiated with evidence or examples. Overall, the claims are somewhat verifiable, as they provide some guidance but require more detailed justification or examples to fully substantiate the suggestions. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on the presentation of figures, suggesting that the fonts in certain elements could be larger for better readability. It also points out the need for larger fonts in specific elements and suggests using a table to better emphasize the data and justify the improved accuracy. Additionally, it highlights the lack of details comparison with other state-of-the-art Transformer designs, such as epochs and the number of parameters. This feedback is clear and constructive, offering the authors concrete steps to improve the clarity and comprehensiveness of their paper. However, it could be more helpful if it included suggestions on how to present the data in the table or examples of what kind of details should be included. Overall, the comment is mostly helpful, as it provides valuable guidance for enhancing the draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to rewrite a specific sentence that is unclear in meaning. This direct request provides a clear action for the authors to take, ensuring they know exactly what needs to be done to improve the draft. The comment is specific and provides concrete guidance on how to address the issue, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"P. 5, p. 3, l,\\\" allowing the authors to accurately identify the specific part of the paper being addressed. It also specifies the issue, which is the unclear meaning of the sentence \\\"While a smaller j to simulate more accumulate errors along with the inference steps,\\\" and suggests rewriting it. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a request for clarification and a suggestion to rewrite a sentence. It does not contain any subjective claims, opinions, or judgments that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the clarity of a sentence in the paper, which is a valuable piece of feedback. By pointing out the ambiguity of the sentence \\\"While a smaller j to simulate more accumulate errors along with the inference steps,\\\" the reviewer highlights a potential source of confusion for readers. The suggestion to rewrite the sentence is actionable and can help improve the clarity and readability of the paper. However, the comment could be more helpful if it provided additional context or suggestions on how to rewrite the sentence effectively. Overall, the feedback is somewhat helpful as it directs the authors to a specific area needing improvement, but it could be more comprehensive with further guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment raises a concern about the clarity of the main contribution, noting that the performance gain appears to be primarily due to PBSD. It questions the motivation for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, the comment does not provide explicit guidance or suggestions on how the authors should clarify their contribution or address the concerns raised. The feedback lacks actionable details, such as recommending specific analyses or comparisons to improve the clarity of the contribution. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is unactionable.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment addresses the main contribution of the paper and raises a question about the clarity of the contribution, specifically mentioning the ablation study and the performance gain attributed to PBSD. It also questions the motivation for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, the comment does not specify which part of the paper discusses the main contribution or the ablation study, making it weakly grounded. The comment is specific in its inquiry about the motivations for PBSD, but without clear grounding, the authors may struggle to identify the exact sections needing attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point questions the clarity of the main contribution, suggesting that the performance gain is primarily due to PBSD. It also questions the motivation for PBSD beyond improving the discriminative ability of the learned representation on tail classes. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the contribution is unclear or that the motivation for PBSD is insufficient. This makes the claim somewhat verifiable, as it provides a general critique but lacks the depth needed for full verification. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises a concern about the clarity of the main contribution, noting that the performance gain appears to be primarily due to PBSD. It questions the motivation for PBSD beyond improving the discriminative ability of the learned representation on tail classes. While the comment identifies a potential weakness in the paper's contribution, it lacks specific suggestions or guidance on how the authors might clarify or strengthen their contribution. The feedback prompts the authors to reconsider their motivation and the significance of PBSD, but without actionable advice, it remains somewhat helpful. Therefore, the comment aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about the tester for the spread parameter and whether it can yield an (\u03f5, \u03b4)-identity tester. It also asks how the tester handles specific pairs (\u03c0, \u03d5) where \u03d5 = \u03d50, but dK(\u03c00, \u03c0) is large. While the comment highlights areas of potential confusion or lack of clarity, it does not provide explicit guidance or suggestions on how the authors should address these issues. The action is implicit and vague, as the authors need to infer that they should clarify these aspects in their paper. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"2,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the tester for the spread parameter and its potential to yield an (\u03f5, \u03b4)-identity tester. The comment further specifies the issue by asking how the tester handles specific pairs (\u03c0, \u03d5) where \u03d5 = \u03d50, but dK(\u03c00, \u03c0) is large. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions seeking clarification about the tester for the spread parameter and its potential to yield an (\u03f5, \u03b4)-identity tester. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a question about the tester for the spread parameter and its potential to yield an (\u03f5, \u03b4)-identity tester. It also asks how the tester handles specific pairs (\u03c0, \u03d5) where \u03d5 = \u03d50, but dK(\u03c00, \u03c0) is large. While the comment identifies a potential area of confusion or lack of clarity in the paper, it does not provide specific suggestions or guidance on how the authors might address these issues. The feedback is somewhat helpful as it prompts the authors to clarify their methodology, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as somewhat helpful.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment questions the authors' claim about using active learning in step 2 and asks whether the \\\"active learning pipeline\\\" method is the same as traditional active learning. It suggests that if the method is different, the description could mislead readers. While the comment implies that the authors should clarify their method or provide a more detailed explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the clarification request. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment addresses a specific claim made by the authors regarding the use of active learning in step 2. It questions whether the \\\"active learning pipeline\\\" method is the same as traditional active learning, which selects informative samples for labeling. This provides a clear indication of what aspect of the paper needs clarification, making the comment specific. However, it does not explicitly mention which part of the paper discusses this claim, leaving the authors to infer that it relates to the methodology or results sections. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in its request for clarification. This aligns with a score of 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point questions the authors' claim about using active learning in step 2 and asks whether the \\\"active learning pipeline\\\" method is the same as traditional active learning. This is a request for clarification rather than a subjective claim or suggestion. It does not contain any opinions, judgments, or judgments that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises a critical question about the authors' claim regarding the use of active learning in step 2. It specifically asks whether the \\\"active learning pipeline\\\" method is the same as traditional active learning, which selects informative samples for labeling. This feedback is valuable as it prompts the authors to clarify their methodology and ensure that their description does not mislead readers. By addressing this question, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it provided suggestions on how to clarify the method or offered examples of what constitutes traditional active learning. Overall, the comment is mostly helpful as it identifies a potential issue and encourages the authors to enhance the clarity of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the proposed method requires annotated labels for learning semantic tokens, which limits its application to supervised training. It proposes that a self-supervised pretraining approach without annotations could be more appealing. While the comment implies that the authors should consider a self-supervised approach, it does not explicitly instruct them to do so or provide detailed guidance on how to implement such a change. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the requirement for annotated labels in the proposed method, which limits its application to supervised training. It suggests that a self-supervised pretraining approach could be more appealing. However, the comment does not specify which part of the paper discusses the annotated labels or the proposed method, making it weakly grounded. The suggestion for a self-supervised approach is specific, as it provides a clear alternative to consider. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the proposed method requires annotated labels for learning semantic tokens, limiting its application to supervised training. It suggests that a self-supervised pretraining approach could be more appealing. However, the comment lacks specific examples or references to support the claim about the limitations of the proposed method or to justify the suggestion for a self-supervised approach. This makes the claim somewhat verifiable, as it provides a logical reasoning but requires more detailed evidence or examples to fully substantiate the argument.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a limitation of the proposed method, specifically its reliance on annotated labels for learning semantic tokens, which restricts its applicability to supervised training. It suggests an alternative approach, a self-supervised pretraining method, which could be more appealing. This feedback is clear and actionable, as it provides a specific direction for the authors to consider, potentially broadening the applicability of their method. However, the comment could be more helpful if it offered additional guidance on how to implement the self-supervised approach or discussed the potential benefits and challenges of such a change. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides explicit and concrete actions for the authors to take. It suggests that the abstract should include a more specific statement about expressivity, referencing a change in linear regions in output space after a citation. Additionally, it recommends including learning curves for all experiments, at least in an appendix. These suggestions are clear and provide specific guidance on how to improve the draft, making the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the abstract include a more detailed statement about expressivity, referencing a change in linear regions in output space after a citation. Additionally, it suggests including learning curves for all experiments, at least in an appendix. This provides clear guidance on what needs to be addressed. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the abstract should include a more specific statement about expressivity, referencing a change in linear regions in output space after a citation. This claim is somewhat verifiable as it provides a logical suggestion for improvement, but it lacks specific references or examples to fully substantiate the need for this change. The suggestion to include learning curves for all experiments is also a reasonable suggestion, but without detailed justification or examples, it remains somewhat verifiable. Overall, the comment provides some direction but lacks comprehensive support, aligning with a score of 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides specific and actionable feedback on two fronts. First, it suggests a more precise wording for the abstract, recommending that it include a reference to the change in linear regions in output space after a citation. This addition would provide a clearer and more detailed explanation of the paper's contribution. Second, the comment suggests including learning curves for all experiments, at least in an appendix, which would enhance the comprehensiveness of the results and allow for a more thorough evaluation of the paper's findings. Both suggestions are clear and offer concrete steps for improvement, making the comment highly helpful for the authors. Therefore, it aligns with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a lack of clarity regarding the paper's motivation and application, specifically questioning the relevance of the proposed method for domain adaptation. The reviewer suggests that the paper would benefit from demonstrating the methodology's use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide such demonstrations, it does not explicitly instruct them to do so. The action is clear but communicated indirectly, making the comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment addresses the lack of clarity regarding the paper's motivation and application, specifically questioning the relevance of the proposed method for domain adaptation. It suggests that the paper should demonstrate the methodology's use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or motivation sections. The comment is specific in detailing what needs to be addressed, namely the lack of clarity and the need for demonstration on actual tasks. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point questions the motivation and application of the paper's proposed method, specifically regarding its relevance to domain adaptation. The reviewer highlights the lack of clarity in the paper's application and suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. While the comment raises a valid concern, it does not provide specific examples or references to support the claim that the application is unclear. The suggestion for demonstration on actual tasks is a logical recommendation, but without further elaboration or evidence, the claim remains somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant gap in the paper's motivation and application, specifically questioning the relevance of the proposed method for domain adaptation. It highlights the lack of clarity regarding the practical use of the method and suggests that demonstrating its application on actual tasks involving domain adaptation would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the paper by clarifying its purpose and demonstrating its utility in real-world scenarios. However, the comment could be more helpful if it included examples of potential applications or tasks where the method could be used. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving the draft by addressing a critical aspect of the paper's contribution.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to clarify the comparison against other models in the experiments by omitting the value of the used ranks for all models. It further suggests that to demonstrate the superiority of TW over TT and TR, the authors should compare tensor completion results for all models while ensuring they have the same number of model parameters. The comment provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the fairness of the comparison. This level of detail makes the comment highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly addresses the comparison against other models in the experiments, allowing the authors to identify the specific part of the paper being discussed. It is also specific because it details the issue with the omission of the value of the used ranks for all models, which affects the fairness of the comparison. The comment further specifies the need to compare tensor completion results for all models with the same number of model parameters, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the fairness of comparisons in the experiments, specifically noting the omission of the value of the used ranks for all models. The reviewer suggests that to demonstrate the superiority of TW over TT and TR, the authors should compare tensor completion results for all models with the same number of model parameters. This claim is mostly verifiable as it provides a logical reasoning for the issue and suggests a specific method to address it. However, it lacks detailed examples or references to support the claim fully, which would enhance its verifiability. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the experimental comparisons in the paper, specifically the omission of the value of the used ranks for all models. This omission makes it difficult to ensure a fair comparison, which is crucial for demonstrating the superiority of TW over TT and TR. The comment provides clear and actionable feedback by suggesting that the authors should compare tensor completion results for all models while ensuring they have the same number of model parameters. This guidance is constructive and offers a specific direction for improving the experimental design and results section of the paper. The detailed nature of the feedback makes it highly helpful for the authors in enhancing their draft.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the proposed method should be compared to \\\"ATA\\\" in Table 2, as it is reported to be better than \\\"FP\\\" in Table 1. This feedback provides a clear and explicit action for the authors to take, which is to include \\\"ATA\\\" in the comparison. The suggestion is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 2\\\" and the specific setting \\\"leave one out,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the inclusion of \\\"ATA\\\" in the comparison with \\\"+LFP.\\\" This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the proposed method should be compared to \\\"ATA\\\" in Table 2, as it is reported to be better than \\\"FP\\\" in Table 1. This claim is somewhat verifiable as it provides a logical reasoning based on the results presented in Table 1. However, the comment lacks specific references or detailed evidence from Table 1 to fully substantiate the claim. The suggestion to include \\\"ATA\\\" in the comparison is based on the observed performance differences, but more detailed analysis or examples would strengthen the justification. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the paper. It points out that the proposed method is only compared to \\\"+LFP\\\" in Table 2 under the leave-one-out setting, and suggests including \\\"ATA\\\" in the comparison since it is reported to be better than \\\"FP\\\" in Table 1. This feedback is clear and constructive, as it guides the authors on how to enhance the comprehensiveness and credibility of their results. By addressing this suggestion, the authors can provide a more robust comparison, which could strengthen the validity of their findings. Therefore, the comment is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several concerns, including the apparent inconsistency in the normalization module between two versions, the need for standardization of pictograms in figures, and minor issues with the text. The comment explicitly mentions the need for standardization of pictograms and points out a specific issue with Figure 4, where symbols overlap in the 0/50 latency range. However, it does not provide detailed guidance on how to address these issues or suggest specific changes. The minor problems with the text are mentioned but not elaborated upon, leaving the authors with only a vague sense of what needs to be improved. Overall, the comment provides some actionable feedback but lacks detailed instructions, making it somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Fig. 4\\\" and the \\\"0/50 latency range,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues, such as the need for standardization of pictograms and the overlapping symbols in Figure 4. Additionally, it points out minor problems with the text, such as the issue after equation on page 4. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises concerns about the normalization module and the figures, suggesting that the normalization module appears different in two versions despite textual descriptions. It also points out a specific issue with Figure 4, where symbols overlap in the 0/50 latency range. The comment suggests that standardization of pictograms is needed and mentions a minor problem with the text. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claims about the normalization module and the figures. The suggestion for standardization is logical, but the lack of comprehensive justification makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies several areas for improvement in the paper. It points out a potential inconsistency in the normalization module between two versions, despite textual descriptions suggesting they are the same. This is a critical observation that could impact the paper's credibility and clarity. Additionally, the comment highlights the need for standardization of pictograms in figures, which is important for providing a clear understanding of the system's workings. It also notes a specific issue with Figure 4, where symbols overlap in the 0/50 latency range, which could confuse readers. The comment also mentions minor problems with the text, such as an issue after equation on page 4. While the comment identifies several areas for improvement, it lacks detailed guidance or suggestions on how to address these issues. Overall, the feedback is somewhat helpful as it points out specific weaknesses but could be more actionable with additional guidance.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point questions the claim made by the authors regarding the usefulness of subdivision splines for decision boundaries and the goal of pruning. It highlights a lack of detail in the theoretical part regarding how the proposed algorithm removes subdivision splines and whether it incurs extra computational costs. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the algorithm's implementation and computational costs. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the claim made by the authors regarding the usefulness of subdivision splines and the goal of pruning. It also references the theoretical part of the paper, allowing the authors to accurately identify the sections being addressed. The comment is specific because it questions the lack of detail in the theoretical part regarding the proposed algorithm and its computational costs. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the claim made by the authors regarding the usefulness of subdivision splines and the goal of pruning. It highlights a lack of detail in the theoretical part regarding how the proposed algorithm removes subdivision splines and whether it incurs extra computational costs. While the comment raises a valid concern, it does not provide specific examples or references to support the claim or the need for more detail. This makes the comment somewhat verifiable, as it points out an area for improvement but lacks comprehensive justification or evidence. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a discrepancy between the authors' claim about the usefulness of subdivision splines and the lack of detail in the theoretical part regarding how the proposed algorithm removes these splines. It raises a valid question about the computational cost associated with the space partition building process. This feedback is somewhat helpful as it highlights a gap in the paper's explanation and prompts the authors to provide more detail on their methodology. However, it could be more helpful if it offered specific suggestions on how to address this issue or provided examples of similar approaches in the literature. Overall, the comment provides some insight into a potential weakness but lacks depth and actionable guidance, aligning with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions and concerns about the paper, including the lack of benefit from output-side layers, unclear illustration of Figure 4, unclear presentation of Pixel-shuffle details, and the absence of limitations and societal impact. While the comment highlights areas that need clarification or improvement, it does not provide explicit instructions or concrete suggestions on how to address these issues. The authors can infer that they need to clarify these points, but the lack of specific guidance makes the comment somewhat vague. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises several specific concerns about the paper, including the lack of benefit from output-side layers, unclear illustration of Figure 4, unclear presentation of Pixel-shuffle details, and the absence of limitations and societal impact. Each of these points is grounded, as the reviewer explicitly mentions specific elements like \\\"Figure 4\\\" and \\\"Pixel-shuffle,\\\" allowing the authors to identify the parts of the paper being addressed. The comment is also specific, detailing what needs to be clarified or addressed in each area. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of a series of questions and observations regarding the paper's content. It does not make any subjective claims or judgments but rather seeks clarification and additional information. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment raises several important questions and concerns about the paper, which could guide the authors in improving their draft. It questions the lack of benefit from output-side layers, the clarity of Figure 4, and the details of the Pixel-shuffle operation. Additionally, it points out the absence of limitations and potential negative societal impacts of the work. While the comment identifies key areas for improvement, it lacks specific suggestions or guidance on how to address these issues. The feedback is somewhat helpful as it highlights critical areas needing clarification, but it could be more beneficial with detailed advice or examples. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a concern about the clarity of the experimental methodology, specifically questioning the use of the 300W-LP dataset for training the model and its implications for the fairness of the comparison with baselines. The reviewer explicitly asks whether the 300W-LP dataset is used in all experiments or just some, suggesting that if it is used in all, it could provide an unfair advantage to the proposed method. This feedback provides a clear and explicit action for the authors to clarify the experimental setup and address the potential unfair advantage. The comment is specific and actionable, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the use of \\\"300W-LP\\\" in the experimental methodology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental methodology, questioning the fairness of the comparison with baselines if the same procedure is used for all experiments. The comment provides a clear direction for the authors to address the potential unfair advantage provided by the use of the 300W-LP dataset. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a concern about the experimental methodology, specifically questioning the use of the 300W-LP dataset for training the model and its implications for fairness in comparisons with baselines. The comment provides a logical reasoning by pointing out that most baselines do not use the 300W-LP dataset, suggesting that its use could provide an unfair advantage. However, the comment lacks specific examples or references to substantiate the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the experimental methodology, specifically questioning the use of the 300W-LP dataset for training the model and its implications for fairness in comparisons with baselines. It highlights a potential unfair advantage that the proposed method might have if the same procedure is used for all experiments. This feedback is clear and actionable, as it prompts the authors to clarify their experimental setup and address the potential bias in their results. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending alternative datasets or methods for comparison. Overall, the comment is mostly helpful as it directs the authors to a significant concern in their methodology, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point highlights a potential issue with the formulation introduced by the authors, suggesting that the data might be aggregated by procedures other than averaging over the support $v$. It provides examples of alternative aggregation methods, such as simple summation or population-weighted average, and mentions that disease incident data are often available in count or rate per the number of residents. However, the comment does not explicitly instruct the authors to revise their formulation or provide guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should consider alternative aggregation methods and potentially revise their formulation. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Equation (1),\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the formulation assumes observations are obtained by averaging over the support $v$, while the data might be aggregated by other procedures like simple summation or population-weighted average. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is fully grounded and specific, corresponding to label 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the formulation introduced by the authors assumes a specific aggregation method (averaging over the support $v$), while the data might be aggregated by other procedures such as simple summation or population-weighted average. The reviewer supports this claim by referencing existing literature, specifically mentioning \\\"bag observation model\\\" and \\\"spatial aggregation process\\\" from [Law et al., NeurIPS'18] and [4]. This provides a basis for the claim, but the comment could be strengthened by providing more detailed examples or references to specific data types or aggregation methods commonly used in the field. Therefore, the comment is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a potential issue with the formulation introduced by the authors, specifically regarding the aggregation of data. It points out that the formulation assumes observations are obtained by averaging over the support $v$, while the data might be aggregated by other procedures, such as simple summation or population-weighted average. The comment provides a clear observation and suggests that the authors should consider alternative aggregation methods, particularly given that disease incident data are often available in count or rate per the number of residents. This feedback is actionable and offers a specific direction for the authors to enhance the robustness and applicability of their formulation. However, it could be more helpful if it included suggestions on how to address this issue or examples of alternative aggregation methods. Overall, the comment is mostly helpful, as it provides valuable insights and guidance for improvement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies specific areas where the paper lacks mathematical definitions, particularly regarding multi-head attention. It questions the presence of a split arrow in Figure 2 and asks for clarification on whether the same vectors are used for keys and values. The reviewer explicitly suggests that a formal definition would help readers understand the architecture. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to improve the draft. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 2 right, bottom right,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the lack of mathematical definition for architectural details, such as multi-head attention, and questions the presence of a split arrow in the figure. The comment further asks for clarification on whether the same vectors are used for keys and values, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the lack of mathematical definition for architectural details, such as multi-head attention, and seeks clarification on the presence of a split arrow in Figure 2. The reviewer assumes that the split arrow represents inputs for the attention layer, specifically query, keys, and values, and asks for clarification on whether the same vectors are used for keys and values. While the comment raises valid questions, it does not provide specific examples or references to support the claim that these details are lacking. The authors would need to infer the importance of these details and address the questions themselves. Therefore, the comment is somewhat verifiable, as it provides a basis for the claim but lacks detailed justification or evidence.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area where the paper lacks clarity, particularly in the mathematical definition of architectural details like multi-head attention. It points out a specific element in Figure 2 that requires clarification, specifically the split arrow and its relation to the attention layer. The comment also asks for clarification on whether the same vectors are used for keys and values, which is crucial for understanding the architecture. By highlighting these areas of confusion and suggesting a formal definition, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their work. This level of detail and guidance makes the comment highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a potential issue with the proposed algorithm, specifically questioning the assumption that each individual's data is independently and identically distributed (iid) from the same distribution. The reviewer explains that this assumption is necessary for the \\\\sqrt{m} argument in Section 5.1 and the application of Theorem 6 to prove Theorem 7. The comment finds this assumption unjustifiable, as it contradicts practical scenarios where users' preferences for emojis are different. However, the comment does not provide explicit guidance on how the authors should address this issue or suggest alternative assumptions or modifications to the algorithm. The action is implicit and vague, as the authors are left to infer that they need to reconsider or justify this assumption. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Section 5.1\\\" and \\\"Theorem 6\\\" and \\\"Theorem 7,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the assumption that each individual's data is iid drawn from the same distribution, explaining how this assumption affects the \\\\sqrt{m} argument and the application of Theorem 6 to prove Theorem 7. The comment further specifies the concern with the assumption's justification in practice. Therefore, this comment is labeled as fully grounded and specific.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the assumption that each individual's data is independently and identically distributed (iid) from the same distribution, which is crucial for the \\\\sqrt{m} argument in Section 5.1 and the application of Theorem 6 to prove Theorem 7. The reviewer provides a logical reasoning by explaining how this assumption affects the validity of the argument and theorems. However, the comment lacks specific examples or references to support the claim that this assumption is unjustifiable in practice. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical assumption in the paper, specifically that each individual's data is independently and identically distributed (iid) from the same distribution. It questions the validity of this assumption, particularly in the context of the \\\\sqrt{m} argument in Section 5.1 and the application of Theorem 6 to prove Theorem 7. The reviewer provides a logical explanation of why this assumption is problematic, noting that in practice, users' preferences for emojis are likely different. This feedback is valuable as it highlights a potential flaw in the paper's theoretical framework and encourages the authors to reconsider or justify this assumption. However, the comment could be more helpful if it offered suggestions on how to address this issue or alternative assumptions that might be more realistic. Overall, the comment is mostly helpful as it directs the authors' attention to a significant concern that needs addressing, but it could be more comprehensive with additional guidance.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point suggests that the authors should consider making the policy non-fixed to explore more complex tasks, as described in the last paragraph of the paper. It also recommends comparing the current approach with a reinforcement learning algorithm baseline. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these changes or which reinforcement learning algorithms to consider. The action is explicit but somewhat vague in terms of execution details, making the comment somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment suggests that the authors should consider making the policy non-fixed to explore more complex tasks, as described in the last paragraph of the paper. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare with a reinforcement learning algorithm baseline, providing a clear direction for improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests that the current setting, with a fixed policy, is a subset of reinforcement learning and proposes that tasks could be made more complex to allow for a non-fixed policy. It recommends comparing the current approach with a reinforcement learning algorithm baseline. However, the comment lacks specific examples or references to support the claim that tasks could get more complicated or to justify the need for a non-fixed policy. Without detailed reasoning or evidence, the claim is not fully verifiable, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 2: Borderline Verifiable.\",\n    \"verifiability_label\": \"2\",\n    \"helpfulness_rationale\": \"The review comment suggests that the current setting, with a fixed policy, is a subset of reinforcement learning and proposes that tasks could be made more complex to allow for a non-fixed policy. It recommends comparing the current approach with a reinforcement learning algorithm baseline. This feedback is somewhat helpful as it identifies a potential area for improvement and provides a direction for further exploration. However, it lacks specific guidance on how to implement these changes or which reinforcement learning algorithms to consider, which would make it more actionable. Therefore, the comment is rated as somewhat helpful, consistent with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights a concern that the experiments primarily focus on presenting results rather than thoroughly analyzing the method itself and its experimental outcomes. It questions the extent to which the performance improvement can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending specific analyses or experiments to conduct. The feedback is implicit and lacks concrete details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment highlights a concern about the comprehensiveness of the analyses of the method itself and the experimental outcomes, noting that the experiments primarily focus on presenting results. It questions the extent to which the performance improvement can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the comprehensiveness of the analyses and the attribution of performance improvement. Therefore, the comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the experiments primarily focus on presenting results rather than analyzing the method itself and its outcomes comprehensively. It questions the extent to which the performance improvement can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. While the comment raises a valid concern, it lacks specific examples or detailed reasoning to support the claim. The absence of concrete evidence or references makes it somewhat verifiable, as the authors would need to further develop the rationale themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical area for improvement in the paper, noting that the experiments primarily focus on presenting results rather than thoroughly analyzing the method itself and its outcomes. It questions the extent to which the performance improvement can be attributed to the authors' claim of moving code-switched pretraining from the word level to the sense level. This feedback is valuable as it prompts the authors to provide a more comprehensive analysis of their method and its impact, which could lead to a deeper understanding of the contributions and limitations of their approach. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is somewhat helpful, as it highlights an important area for improvement but lacks detailed guidance on how to address it.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the literature review overlooks relevant papers, specifically mentioning \\\"VR-MARINA for online problems from [1]\\\" and \\\"DASHA-MVR from [2]\\\" as examples. It suggests that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment does not provide explicit instructions on how to incorporate these references into the literature review or how to address the comparison with QSGD. The action is implicit and somewhat vague, as the authors need to infer that they should include these references and consider the comparison, but the lack of concrete guidance makes it barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the \\\"next section\\\" and the literature review, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the literature review overlooks relevant papers, such as \\\"VR-MARINA for online problems from [1]\\\" and \\\"DASHA-MVR from [2],\\\" which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This provides clear guidance on what needs to be addressed in the literature review. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the literature review overlooks relevant papers, specifically mentioning \\\"VR-MARINA for online problems from [1]\\\" and \\\"DASHA-MVR from [2]\\\" as examples. The reviewer supports this claim by stating that these papers satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. However, the comment lacks specific references to these papers or detailed explanations of how they relate to the current work, making it somewhat verifiable. The authors would need to further explore these references to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the literature review, noting that it overlooks relevant papers that should be included. It provides examples of papers, \\\"VR-MARINA for online problems from [1]\\\" and \\\"DASHA-MVR from [2],\\\" which satisfy Assumption 2 and have a better rate than QSGD in the stochastic regime. This feedback is clear and actionable, as it directs the authors to expand their literature review to include these relevant works. However, the comment could be more helpful if it explained why these papers are relevant or how they relate to the current work, providing additional context for the authors to consider. Overall, the comment is mostly helpful, as it effectively guides the authors to improve their literature review, but it could be more comprehensive with additional context.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment indicates that the presentation of the paper is difficult to follow, but it does not provide specific guidance or suggestions on how to improve the clarity or organization of the paper. Without explicit instructions or concrete details on what aspects of the presentation are problematic, the authors are left without a clear understanding of what steps to take to enhance their draft. As a result, the comment lacks actionability, leaving the authors without direction on how to address the issue. Therefore, it is rated as a 1 on the actionability scale.\",\n    \"actionability_label\": \"1\",\n    \"grounding_specificity_rationale\": \"The comment indicates that the presentation of the paper is difficult to follow, but it does not specify which parts of the paper are problematic or provide details on what aspects are unclear. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it not grounded at all. Therefore, this comment aligns with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point states that \\\"the presentation of this paper is hard to follow for the reviewer.\\\" However, it does not provide any specific examples, reasoning, or suggestions to support this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The comment indicates that the presentation of the paper is difficult to follow, but it does not provide any specific details or suggestions on how to improve the clarity or organization of the paper. Without identifying particular sections or aspects that are problematic, the authors are left without actionable guidance on how to enhance their draft. This lack of specificity and constructive feedback limits the utility of the comment, making it barely helpful. Therefore, it aligns with a score of 2.\",\n    \"helpfulness_label\": \"2\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors provide a more detailed presentation of the compared models, specifically mentioning the differences between KVAE and DMM/DVBF. It highlights the simplicity of KVAE due to its linear state space transition but notes the requirement for computing time-dependent LGSSM parameters \\\\(\\\\gamma\\\\). The reviewer asks for a comment on the computation requirements of the three methods compared in Table 1. While the comment implies that the authors should provide more details, it does not explicitly instruct them to do so. The action is clear but stated implicitly, and the authors can infer that they need to elaborate on the computation requirements. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 1,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, a more detailed presentation of the compared models, particularly focusing on the computation requirements of the three methods. The comment provides a clear direction for improvement by highlighting the need for additional details on the computation requirements of KVAE, DMM, and DVBF. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the paper could benefit from a more detailed presentation of the compared models, specifically mentioning the differences between KVAE and DMM/DVBF. The reviewer provides some reasoning by noting that KVAE is simpler due to its linear state space transition but requires the computation of time-dependent LGSSM parameters \\\\(\\\\gamma\\\\). However, the comment lacks specific examples or detailed comparisons that would fully substantiate the claim. While it provides some context, it does not offer enough detail to be fully verifiable. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides some reasoning but lacks comprehensive support.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the reviewer's understanding of the differences between the compared models (DMM, DVBF, and KVAE) but suggests that a more detailed presentation of these models would be beneficial. It specifically points out the simplicity of KVAE due to its linear state space transition and the requirement for computing time-dependent LGSSM parameters \\\\(\\\\gamma\\\\). The comment requests clarification on the computation requirements of the three methods compared in Table 1. This feedback is clear and actionable, as it directs the authors to provide additional details that could enhance the clarity and comprehensiveness of their paper. However, it could be more helpful if it offered specific suggestions on how to present this information or examples of what additional details might be included. Overall, the comment is mostly helpful, as it effectively guides the authors toward improving their draft by addressing a specific area for enhancement.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. While the comment implies that additional experiments are needed, it does not explicitly instruct the authors to perform these experiments. The action is clear but stated indirectly, making the comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the experiments conducted on T5, PaLM, and GPT series LLMs, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that more experiments on different famous LLMs like LLaMA and Falcon are needed to serve as benchmark baselines. This provides clear guidance on what additional experiments should be conducted. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the authors should conduct more experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. While the comment identifies a potential area for improvement, it lacks specific reasoning or evidence to support why these additional experiments are necessary or how they would enhance the study. The suggestion is based on a general expectation that more diverse experiments would strengthen the paper, but without detailed justification or examples, the claim remains somewhat vague. Therefore, the comment is categorized as 3: Somewhat Verifiable, as it provides a direction for improvement but lacks sufficient detail to be fully actionable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific area for improvement by suggesting that the authors conduct additional experiments on different famous LLMs like LLaMA and Falcon to serve as benchmark baselines. This feedback is clear and actionable, as it provides a concrete suggestion for expanding the experimental scope to include more diverse models. By doing so, the authors can strengthen the validity and generalizability of their findings. However, the comment could be more helpful if it included specific reasons or benefits of including these additional models, or if it offered guidance on how to integrate these experiments into the current study. Overall, the comment is mostly helpful as it directs the authors toward a meaningful enhancement of their work.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that in Table 3, besides the number of queries, it would be beneficial to compare the real search cost, such as in terms of GPU days. This feedback provides a clear and explicit action for the authors to take, specifying exactly what additional information should be included in the table. The suggestion is concrete, as it gives the authors a specific metric to consider for comparison. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Table 3,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a particular improvement: comparing the real search cost, such as in terms of GPU days, in addition to the number of queries. This provides clear guidance on what needs to be added or improved in the table. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that Table 3 should include a comparison of the real search cost, such as in terms of GPU days, in addition to the number of queries. This claim is somewhat verifiable as it provides a logical suggestion for improvement, but it lacks specific examples or references to support why this additional information would be beneficial. The authors might need to infer the importance of this suggestion without further guidance. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the presentation of results in Table 3. It recommends including a comparison of the real search cost, such as in terms of GPU days, in addition to the number of queries. This feedback is clear and directly addresses a potential gap in the information provided, offering the authors a concrete way to enhance the comprehensiveness and utility of their results. By following this suggestion, the authors can provide a more detailed analysis of their findings, which could be valuable for readers. Therefore, the comment is mostly helpful, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to correct a typographical error in the phrase \\\"for 'in-between' uncertainty,\\\" specifically mentioning that the first quotation mark on 'in-between' should be a forward mark rather than a backward mark. This feedback is clear and provides a specific action for the authors to take, ensuring they know exactly what needs to be changed. The comment is direct and concrete, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions a specific phrase \\\"for 'in-between' uncertainty\\\" and provides a clear correction regarding the quotation mark used. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the exact issue with the quotation mark, providing clear guidance on what needs to be corrected. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point is a factual correction regarding the typographical error in the phrase \\\"for 'in-between' uncertainty.\\\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable correction regarding a typographical error in the manuscript. It clearly identifies the issue with the quotation mark used in the phrase \\\"for 'in-between' uncertainty\\\" and suggests the correct mark should be a forward mark. This feedback is precise and directly addresses a minor but important aspect of the manuscript, ensuring clarity and accuracy in the final version. By offering a clear and concise correction, the comment empowers the authors to improve the quality of their draft. Therefore, it is rated as highly helpful, consistent with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises several questions and requests for clarification regarding the content of the paper. It asks why Omega is not explicitly defined, suggests that OMD is a family of algorithms and might benefit from more explicitness, and questions the link function and specific theorem referenced. These questions imply that the authors should provide more detailed explanations and definitions in their draft. While the actions are implicit, they are concrete and specific, as they clearly indicate what needs to be clarified or expanded upon. Therefore, this comment is mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"L178,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises several questions and requests for clarification, such as why Omega is not explicitly defined, the need for more explicitness regarding OMD, and the specific link function and theorem referenced. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point consists of questions and requests for clarification regarding the content of the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment factual and descriptive. Therefore, it should be labeled as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies specific areas where the paper could be improved by asking for clarification and additional details. It points out that the term \\\"Omega\\\" is not explicitly defined, suggesting that the authors should provide this information. It also notes that OMD is a family of algorithms and suggests that the authors should be more explicit about this. Additionally, the comment questions the link function and specific theorem referenced for the regret guarantee, indicating a need for clarification. While the comment highlights important areas for improvement, it does not provide detailed suggestions or examples on how to address these issues, which limits its helpfulness. Therefore, the comment is somewhat helpful, as it provides some guidance but lacks depth and specificity.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of using the Hamming distance over the entire sequence as a scoring loss in the context of CRF. The reviewer suggests that this approach is uncommon and recommends pointing out some references. While the comment implies that the authors should provide references, it does not explicitly instruct them to do so. The action is clear but stated indirectly, making the comment mostly actionable.\",\n    \"actionability_label\": \"4\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Example 2\\\" and the context of CRF, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the use of the Hamming distance over the entire sequence as a scoring loss and suggests that this approach is uncommon, recommending references. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the use of the Hamming distance over the entire sequence as a scoring loss in the context of CRF, suggesting that this approach is uncommon and contrasting it with node-wise Hamming loss. The reviewer provides a specific example of a common practice and suggests that the authors should point out references to support their approach. This claim is mostly verifiable as it provides a logical reasoning based on common practices and suggests a specific area for further clarification. However, it could be strengthened by providing more detailed references or examples of works that use the Hamming distance over the entire sequence. Therefore, the comment is rated as 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the usefulness of the sequence example but expresses surprise at the mention of using the Hamming distance over the entire sequence as a scoring loss in the context of CRF. It suggests that this approach is uncommon and recommends pointing out references to support the use of this method. This feedback is clear and actionable, as it directs the authors to provide additional context and references for their approach, which could enhance the credibility and understanding of their work. However, the comment could be more helpful if it provided specific references or examples of works that use the Hamming distance in this manner. Overall, the comment is mostly helpful, as it effectively guides the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment provides explicit and concrete suggestions for improving the draft. It recommends changing the name of the \\\"Evaluation\\\" element to \\\"Metrics\\\" to avoid ambiguity, as \\\"evaluation\\\" can have a broader meaning. Additionally, it suggests removing the corresponding sections and briefly mentioning the metrics along with the datasets or in the captions of the tables, as most metrics are standard practice. This feedback is clear and actionable, giving the authors specific guidance on how to revise their draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment suggests changing the name of the \\\"Evaluation\\\" element to \\\"Metrics\\\" and recommends removing corresponding sections, instead mentioning metrics along with datasets or in table captions. This provides specific guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper this suggestion pertains to, leaving the authors to infer that it relates to sections discussing evaluation or metrics. Therefore, the comment is weakly grounded but specific, aligning with the label 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point suggests changing the name of the \\\"Evaluation\\\" element to \\\"Metrics\\\" and recommends removing corresponding sections, instead mentioning metrics along with datasets or in table captions. The claim is based on the idea that \\\"evaluation\\\" can have a more general meaning, and that metrics are well-known and standard practice. However, the comment lacks specific examples or references to support the claim that changing the name would improve clarity or precision. While the suggestion is logical, the absence of detailed justification or evidence makes the claim somewhat verifiable. The authors would need to make an effort to understand and implement the suggestion without extensive guidance.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides clear and actionable feedback by suggesting a change in terminology from \\\"Evaluation\\\" to \\\"Metrics\\\" to avoid ambiguity. It also offers a practical suggestion to remove corresponding sections and mention metrics along with datasets or in table captions, as most metrics are standard practice. This guidance is specific and constructive, helping the authors improve the clarity and focus of their paper. By addressing these points, the authors can enhance the readability and coherence of their work. Therefore, the comment is highly helpful, aligning with a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly instructs the authors to use more objective terms instead of \\\"remarkable\\\" when describing the accuracy improvement. It provides a specific example, \\\"and remarkable accuracy improvement with same size of networks,\\\" and suggests that the improvement is difficult to characterize as remarkable. This feedback is clear and provides a concrete action for the authors to take, making it highly actionable. The authors know exactly what change to make to improve the objectivity of their language.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"[218],\\\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting the use of more objective terms instead of \\\"remarkable\\\" when describing the accuracy improvement. The comment provides a clear rationale for the suggestion, explaining that the improvement is difficult to characterize as remarkable due to the squished axes. This level of detail provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point suggests that the term \\\"remarkable\\\" is subjective and not appropriate for describing the accuracy improvement. It provides a specific example, \\\"and remarkable accuracy improvement with same size of networks,\\\" and explains that the improvement is difficult to characterize as remarkable due to the squished axes. This reasoning is somewhat verifiable as it offers a logical explanation for why the term might be subjective, but it lacks detailed evidence or references to support the claim fully. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment provides a specific and actionable suggestion for improving the language used in the paper. It advises the authors to use more objective terms instead of subjective ones like \\\"remarkable,\\\" which can be misleading. The comment also offers a rationale for this suggestion by pointing out that the improvement is difficult to characterize as remarkable due to the squished axes. This feedback is clear and constructive, helping the authors refine their language to enhance the objectivity and clarity of their results. However, it could be more helpful if it included additional guidance on how to achieve this objective or provided examples of more appropriate terms. Overall, the comment is mostly helpful as it directs the authors toward improving the quality of their writing.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point acknowledges the paper's interesting idea and extensive experiments but notes that the results are not perfect and seem to handle subtle motion. It suggests that the authors could explore longer video sequences by running the LSTM over many time steps. However, the comment does not provide explicit instructions or concrete steps on how to implement this suggestion or address the issues with the current results. The action is implicit and somewhat vague, as the authors need to infer that they should consider longer video sequences and may not know exactly how to do so. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the issue with short video sequences and provides specific examples of problems observed in the synthesized results for UCF-101, such as inconsistent motion, changing color, or object disappearing over time. It also suggests exploring longer video sequences by running the LSTM over many time steps. Additionally, the comment acknowledges the paper's interesting idea and extensive experiments, noting that the results are not perfect but show improved results over the previous state-of-the-art. This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, the comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point acknowledges the paper's interesting idea and extensive experiments but notes that the results are not perfect and seem to handle subtle motion. It suggests exploring longer video sequences by running the LSTM over many time steps. The claim is somewhat verifiable as it provides a logical reasoning for the suggestion, but it lacks specific examples or references to support the claim about the limitations of the current results. The suggestion to explore longer sequences is based on common practices in the field, but the comment could be strengthened with more detailed evidence or examples. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment acknowledges the paper's interesting idea and extensive experiments but notes that the results are not perfect and seem to handle subtle motion. It suggests exploring longer video sequences by running the LSTM over many time steps, which could potentially address the issues observed in the synthesized results. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement the suggestion or address the limitations of the current results. The feedback is somewhat helpful as it identifies an area for enhancement but could be more comprehensive with detailed suggestions or examples. Therefore, it aligns with a score of 3.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment highlights two issues: the lack of convincing numerical evaluation due to the use of synthetic data and the unfair comparison with method [5] because of the different problem complexity. However, it does not provide explicit guidance on how to address these issues. The authors are left to infer that they might need to include evaluations on real-world data or adjust the comparison to account for the differences in problem complexity. The action is implicit and somewhat vague, as it lacks concrete steps or suggestions for improvement. Therefore, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment addresses the numerical evaluation of the method, specifically mentioning that it is only evaluated on synthetic data. It also critiques the comparison with method [5], noting that [5] is designed for a more complex problem, such as not knowing the camera pose parameters. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it difficult for the authors to pinpoint the exact areas needing revision. While the authors might have an idea of where these evaluations are discussed, the comment lacks full grounding. It is specific about the issues with the evaluation and comparison but does not provide detailed guidance on how to address them. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point claims that the numerical evaluation is not fully convincing because the method is only tested on synthetic data. It also criticizes the comparison with method [5], stating that it is unfair due to the different problem complexity. The comment provides some reasoning by highlighting the limitations of the evaluation and the comparison, but it lacks specific examples or detailed explanations to fully substantiate the claims. This makes the comment somewhat verifiable, as the authors would need to further explore the reasoning themselves to fully understand and address the critique. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a significant issue with the numerical evaluation of the method, noting that it is only tested on synthetic data, which may not accurately reflect real-world performance. It also points out a potential unfairness in the comparison with method [5], which is designed for a more complex problem. While the comment highlights important weaknesses, it lacks specific suggestions or guidance on how the authors might address these issues, such as recommending additional datasets or methods for comparison. This limits the comment's usefulness, making it somewhat helpful as it provides insight into areas for improvement but does not fully support the authors in making those improvements.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point raises a question about whether the authors studied the impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that this experiment could strengthen the paper, implying that the authors should consider conducting this experiment. However, the comment does not explicitly instruct the authors to perform this experiment or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should conduct the experiment and may not know exactly how to proceed. Therefore, this comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment raises a question about the study of the number of bits in logits and its impact on robustness against a larger epsilon in the PGD attack. It suggests that this experiment could strengthen the paper, implying that it is relevant to the section discussing robustness or adversarial attacks. However, the comment does not explicitly mention a specific section or part of the paper, making it weakly grounded. The comment is specific in suggesting that the experiment could strengthen the paper, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is weakly grounded and specific, aligning with category 3.\",\n    \"grounding_specificity_label\": \"3\",\n    \"verifiability_rationale\": \"The review point raises a question about the study of the number of bits in logits and its impact on robustness against a larger epsilon in the PGD attack. The reviewer provides a logical reasoning by suggesting that having a 32-bit logit should improve robustness against a more powerful adversary. However, the comment lacks specific evidence or references to support this claim, making it somewhat verifiable. The authors would need to further explore and substantiate the claim themselves, which limits the verifiability of the comment. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment raises an interesting question about the impact of the number of bits in logits on robustness against a larger epsilon in the PGD attack. It suggests that this experiment could strengthen the paper, providing a potential avenue for further exploration. However, the comment lacks specific guidance or suggestions on how to conduct this experiment or what specific aspects to focus on. While it identifies a potential area for improvement, it does not offer actionable steps or detailed insights, making it somewhat helpful. The authors are given a direction to consider, but the feedback could be more comprehensive to be fully beneficial.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment notes that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how the authors might achieve these enhancements or what aspects of the work could be improved. The comment lacks explicit instructions or concrete details on how to address the issue, leaving the authors uncertain about what steps to take to improve their draft. Since the action is implicit and vague, this comment is barely actionable.\",\n    \"actionability_label\": \"2\",\n    \"grounding_specificity_rationale\": \"The comment mentions the observed performance enhancements being modest, suggesting room for further refinement. However, it does not specify which part of the paper discusses these enhancements, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the performance enhancements are modest or how they could be improved. As a result, the comment is not grounded and not specific, aligning with a score of 1.\",\n    \"grounding_specificity_label\": \"1\",\n    \"verifiability_rationale\": \"The review point claims that the observed performance enhancements are modest, suggesting room for further refinement. However, it does not provide any specific examples, data, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment acknowledges that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue or improve their work. Without detailed guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is not particularly helpful in terms of providing actionable advice, aligning with a score of 1.\",\n    \"helpfulness_label\": \"1\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point explicitly instructs the authors to provide references for two specific passages in Section 3.2, lines 230-234 and 234-235. It also asks for clarification on what \\\"MLP\\\" stands for in Figure 2, indicating that it is not described in the paper. These instructions are clear and specific, providing the authors with direct actions to take to improve their draft. The feedback is concrete and leaves no ambiguity about what needs to be addressed, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions specific sections and lines of the paper, allowing the authors to accurately identify the parts being addressed. It also specifies what needs to be addressed, including providing references for two passages and clarifying what \\\"MLP\\\" stands for in Figure 2. This level of detail provides clear guidance on what needs to be revised, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point requests references for specific passages and clarification on a term used in a figure. It does not contain subjective claims or opinions that require verification. The request for references and clarification is factual and descriptive in nature, fitting the classification of \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment is mostly helpful as it identifies specific areas in the paper that require clarification or additional information. It requests references for two passages in Section 3.2, which is crucial for situating the work within the existing literature. Additionally, it points out that the term \\\"MLP\\\" in Figure 2 is not described in the paper, prompting the authors to clarify this aspect. While the comment is clear and actionable, it could be more helpful if it provided suggestions on how to effectively incorporate these references or clarify the term \\\"MLP.\\\" Overall, the feedback is valuable for improving the draft's clarity and completeness, aligning with a score of 4.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review point identifies a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. The reviewer suggests that if the output patches are indeed just masked versions, Figure 1 is misleading and proposes that zooming on the region of interest using bilinear sampling could provide better results. This feedback provides a clear and explicit action for the authors to take, specifically addressing the discrepancy and suggesting a potential improvement. The comment is concrete, as it outlines the issue and offers a specific solution, making it highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"eq. 9\\\" and \\\"Figure 1,\\\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the discrepancy between the equation and the figure, questioning whether the output patches are cropped parts of the input image or just masked versions. The comment further suggests that if the output patches are indeed just masked versions, Figure 1 is misleading and proposes using bilinear sampling for better results. This provides clear guidance on what needs to be addressed and improved in the paper. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a claim about a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. The reviewer provides a logical reasoning by explaining the potential issue with Figure 1 being misleading if the output patches are indeed just masked versions. However, the comment lacks specific examples or references to substantiate the claim fully. While the reasoning is sound, the absence of detailed evidence or examples makes the claim somewhat verifiable. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a discrepancy between equation 9 and Figure 1, questioning whether the output patches are cropped parts of the input image or just masked versions. It provides a clear and actionable suggestion by proposing that if the output patches are indeed just masked versions, Figure 1 is misleading. The comment further suggests that using bilinear sampling for zooming on the region of interest could potentially provide better results. This feedback is highly helpful as it not only points out a specific issue but also offers a constructive suggestion for improvement, guiding the authors on how to enhance the clarity and accuracy of their presentation. Therefore, the comment deserves a score of 5.\",\n    \"helpfulness_label\": \"5\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment points out that the statement about training time reduction being less drastic than parameter reduction is not revisited in the Discussion section. It suggests that if the authors choose to keep this statement, they should revise it to reflect its current status. The comment is explicit in its request to update the Discussion section, providing a clear action for the authors to take. However, it does not specify how the statement should be revised or what changes are needed, leaving some room for interpretation. Therefore, the comment is somewhat actionable.\",\n    \"actionability_label\": \"3\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Pg.5\\\" and the specific sentence about training time reduction, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue, which is that the statement about training time reduction not being revisited in the Discussion section is incorrect. The comment suggests that if the authors choose to keep this statement, they should revise it to reflect its current status. This provides clear guidance on what needs to be addressed, making the comment fully grounded and specific. Therefore, this comment aligns with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point claims that the statement about training time reduction being less drastic than parameter reduction is not revisited in the Discussion section. However, the comment does not provide any supporting evidence or reasoning to justify why this statement should be revisited or how it impacts the overall discussion. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered unverifiable.\",\n    \"verifiability_label\": \"1\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with the text on page 5, noting that the statement about training time reduction being less drastic than parameter reduction is not revisited in the Discussion section. It suggests that if the authors choose to keep this statement, they should revise it to reflect its current status. This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending a revision to the text. However, the comment could be more helpful if it offered additional guidance on how to revise the statement or why it is important to update it. Overall, the comment is mostly helpful as it directs the authors to a specific area needing attention and provides a clear action to take.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment explicitly identifies an issue with Figure 6, specifically noting that the font size is too small. This provides a clear and direct action for the authors to take, which is to increase the font size in the figure. The comment is specific and concrete, leaving no ambiguity about what needs to be done to improve the draft. Therefore, this comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 6,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point is a factual observation about the font size in Figure 6. It does not contain any subjective claims, opinions, or suggestions that require verification or justification. Therefore, it is classified as \\\"No.\\\"\",\n    \"verifiability_label\": \"X\",\n    \"helpfulness_rationale\": \"The review comment identifies a specific issue with Figure 6, noting that the font size is too small. This is a clear and actionable piece of feedback that the authors can easily address by adjusting the font size in the figure. However, the comment does not provide further context or suggestions on how this might affect the overall presentation or interpretation of the figure. While it highlights a minor issue, the feedback is limited in scope and does not offer a comprehensive guide for improvement. Therefore, the comment is somewhat helpful, as it provides a clear direction for improvement but lacks depth and broader context.\",\n    \"helpfulness_label\": \"3\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms like Hogwild. This feedback provides a clear and explicit action for the authors to take, specifying the type of problems they should consider and why. The suggestion is concrete, as it offers a specific direction for improvement. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions the introduction and the second paragraph, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the goal of the paper, the examples chosen, and suggests an alternative focus on problems where the loss function does not decompose as the sum of sample losses. The comment offers a clear direction for improvement by recommending specific areas to focus on. Therefore, this comment is fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point questions the clarity of the paper's goal in the introduction and suggests that the examples provided do not effectively demonstrate the need for significant inter-process communication. The reviewer offers a specific alternative focus, recommending the authors consider problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms like Hogwild. This suggestion is based on logical reasoning and provides a clear direction for improvement. However, the comment could be strengthened by providing more detailed examples or references to support the claim about the examples not being convincing. As it stands, the claim is mostly verifiable, aligning with a score of 4: Mostly Verifiable.\",\n    \"verifiability_label\": \"4\",\n    \"helpfulness_rationale\": \"The review comment identifies a lack of clarity in the paper's goal, as expressed in the introduction. It questions the examples provided and suggests that they do not effectively demonstrate the need for significant inter-process communication. The reviewer offers a specific alternative focus, recommending the authors consider problems where the loss function does not decompose as the sum of sample losses and other ERM-based distributed algorithms like Hogwild. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and relevance of their paper. However, the comment could be more helpful if it included additional examples or detailed guidance on how to implement the suggested focus. Overall, the comment is mostly helpful, as it effectively directs the authors toward a meaningful enhancement of their draft.\",\n    \"helpfulness_label\": \"4\"\n}"}
{"generated_text": "{\n    \"actionability_rationale\": \"The review comment identifies a lack of fairness in the comparison between CPEF and PMEF, noting that PMEF lacks a pre-training module. The reviewer suggests that to ensure fairness, CPEF should be compared with another pre-trained model, such as ExpertBert, to highlight the advantage of CPEF's innovative pre-training module design. This feedback provides a clear and explicit action for the authors to take, specifically recommending a comparison with a pre-trained model like ExpertBert. The suggestion is concrete, as it specifies which model to use for comparison and what aspect to focus on. Therefore, the comment is highly actionable.\",\n    \"actionability_label\": \"5\",\n    \"grounding_specificity_rationale\": \"The comment is fully grounded as it explicitly mentions \\\"Figure 3\\\" and the specific lines \\\"line 529-lin534,\\\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a fair comparison between CPEF and PMEF due to PMEF's lack of a pre-training module. The comment suggests a specific alternative for comparison, ExpertBert, to ensure fairness. Therefore, this comment is categorized as fully grounded and specific, aligning with category 5.\",\n    \"grounding_specificity_label\": \"5\",\n    \"verifiability_rationale\": \"The review point raises a claim about the lack of a fair comparison between CPEF and PMEF, suggesting that PMEF's absence of a pre-training module makes the comparison unfair. The reviewer recommends comparing CPEF with another pre-trained model, such as ExpertBert, to demonstrate the advantage of CPEF's innovative pre-training module design. This claim is somewhat verifiable as it provides a logical reasoning for the unfair comparison and suggests a specific alternative for a fairer comparison. However, the comment could be strengthened by providing more detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is rated as 3: Somewhat Verifiable.\",\n    \"verifiability_label\": \"3\",\n    \"helpfulness_rationale\": \"The review comment identifies a critical issue with the fairness of the comparison between CPEF and PMEF, noting that PMEF lacks a pre-training module, which makes the comparison unfair. It provides a clear and actionable suggestion to address this issue by recommending a comparison with another pre-trained model, such as ExpertBert, to demonstrate the advantage of CPEF's innovative pre-training module design. This feedback is highly helpful as it offers a specific and constructive approach for the authors to improve the fairness and validity of their experimental comparisons. By following this suggestion, the authors can enhance the credibility and impact of their work.\",\n    \"helpfulness_label\": \"5\"\n}"}
