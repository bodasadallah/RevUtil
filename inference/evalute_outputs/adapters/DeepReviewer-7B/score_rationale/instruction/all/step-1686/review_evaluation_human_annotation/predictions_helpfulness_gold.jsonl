{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential inconsistency in the description of the data selection process, specifically between lines 226238 and lines 242244. It suggests that the data selected is a subset of Li et al. (2019a)\"s dataset and recommends revising the description to mention Li et al. (2019a) earlier for clarity and precision. The comment provides a clear and explicit action for the authors to take, which is to revise the description to include a reference to Li et al. (2019a). This guidance is concrete, as it specifies exactly what needs to be done to improve the draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific line ranges (226238 and 242244), allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue, which is the potential inconsistency in the description of the data selection process, and suggests a specific revision to improve clarity and precision by mentioning Li et al. (2019a) earlier. This provides clear guidance on what needs to be revised, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the description of the data selection process, specifically questioning the consistency between lines 226238 and lines 242244. The reviewer suggests that the data selected is a subset of Li et al. (2019a)\"s dataset and recommends revising the description to mention Li et al. (2019a) earlier for clarity. This claim is 4 as it provides a logical reasoning for the inconsistency and suggests a specific way to improve the clarity of the description. However, it lacks detailed examples or references to fully substantiate the claim, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential inconsistency in the description of the data selection process, specifically between lines 226238 and lines 242244. It points out that the data selected appears to be a subset of Li et al. (2019a)\"s dataset, and suggests that the description could be revised for clarity and precision by mentioning Li et al. (2019a) earlier. This feedback is clear and actionable, providing the authors with a specific suggestion to improve the clarity of their manuscript. By addressing this issue, the authors can enhance the precision of their description, which is crucial for the reader\"s understanding. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies two specific areas that need improvement in the presentation of the model. First, it asks for clarification on the pooling method used for embedding features, specifically referencing line 397. Second, it points out that Equation (7) in line 472 is unclear and requests clarification on whether E_i represents the type or identity of AC i, as well as defining both terms. Additionally, the comment suggests that the lefthand side (LHS) of equation (7) should be a conditional probability. These points provide clear and explicit actions for the authors to take, making the comment 5. The authors know exactly what needs to be clarified and how to address the issues raised, ensuring they can make the necessary improvements to their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (397 and 472) and equations, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the pooling method used for embedding features and the clarification of Equation (7), including the definition of E_i and the nature of the LHS. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises two specific issues regarding the presentation of the model: the pooling method used for embedding features and the clarity of Equation (7). The comment provides detailed questions and requests for clarification, such as whether E_i represents the type or identity of AC i, and whether the lefthand side (LHS) of equation (7) should be a conditional probability. While the comment highlights areas needing clarification, it does not provide external references or detailed reasoning to support the need for these clarifications. The authors can follow the suggestions to improve clarity, but the claim is 3 due to the need for additional explanation or evidence to fully substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 5 as it provides specific and actionable feedback on two key areas of the paper: the presentation of the model. It identifies a need for clarification regarding the pooling method used for embedding features, specifically asking for the details in line 397. Additionally, it points out that Equation (7) in line 472 is unclear and requests clarification on whether E_i represents the type or identity of AC i, as well as defining both terms. The comment also suggests that the lefthand side (LHS) of equation (7) should be a conditional probability. This feedback is clear, precise, and provides concrete steps for the authors to improve the clarity and accuracy of their presentation, making it highly beneficial for enhancing the draft. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not provide explicit guidance or suggestions on how the authors could clarify these aspects or improve the presentation of their results. The feedback lacks actionable details, such as recommending specific analyses or visualizations to enhance clarity. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment does not specify which part of the paper this issue pertains to, such as specific sections or figures where the analysis is unclear. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for clarity in the presentation of results and analyses, but without grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point expresses difficulty in understanding the overall picture of the empirical results and analyses presented in the paper. It questions what the experiments reveal about the underlying research question and the specific hypothesis tested. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the paper is difficult to follow. Without concrete evidence or suggestions for improvement, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that while it presents many empirical results and analyses, it lacks clarity in understanding what these results reveal about the underlying research question and the specific hypothesis tested. The reviewer questions how the different pieces of the puzzle presented in the paper fit together and what insights they provide. While the comment highlights an important area for improvement, it does not offer specific suggestions or guidance on how the authors might clarify these aspects or improve the coherence of their presentation. This limits the comment\"s helpfulness, as it provides insight into a problem but lacks actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experimental comparisons are insufficient and recommends testing the proposed method, InvP, with wider backbones like ResNet50 (2x) and ResNet50 (4x), which are used by other methods like MoCo and SimCLR. This feedback provides a clear and explicit action for the authors to take, specifying exactly what additional experiments should be conducted to strengthen the paper. The suggestion is concrete, as it outlines the specific backbones to test with, making it 5.", "grounding_specificity_rationale": "The comment addresses the experimental comparisons and suggests testing the proposed method, InvP, with wider backbones like ResNet50 (2x) and ResNet50 (4x), which are used by other methods like MoCo and SimCLR. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental results or methodology section. The suggestion is specific, as it clearly outlines what additional experiments should be conducted to enhance the paper. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the experimental comparisons are insufficient and suggests that the proposed method, InvP, should be tested with wider backbones like ResNet50 (2x) and ResNet50 (4x), similar to other methods like MoCo and SimCLR. This claim is 3 as it provides a logical suggestion for expanding the experimental comparisons to include wider backbones. However, the comment lacks specific examples or references to the results of MoCo and SimCLR with these wider backbones, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental comparisons, noting that the proposed method, InvP, is not tested with wider backbones like ResNet50 (2x) and ResNet50 (4x), which are used by other methods like MoCo and SimCLR. It suggests that including these wider backbones would provide a more comprehensive evaluation of the proposed method. This feedback is clear and actionable, as it guides the authors to expand their experimental comparisons to include additional configurations, which could strengthen the validity and generalizability of their results. However, the comment could be more helpful if it provided specific reasons why these wider backbones are important or how they might impact the results. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their experimental evaluation."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the probabilistic connection in the paper is not formal enough and could be considered motivational rather than substantiated. The reviewer explicitly recommends that the authors either formalize this connection or adjust the language to clarify it. This feedback provides a clear and explicit action for the authors to take, specifying the need for either formalization or language adjustment. The comment is concrete in its guidance, making it 5.", "grounding_specificity_rationale": "The comment critiques the probabilistic connection in the paper, suggesting that it is not formal enough and could be considered motivational. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where probabilistic connections are discussed, the comment lacks full grounding. It is specific in suggesting that the connection should be formalized or the language adjusted for clarity, but without clear grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the probabilistic connection is not formal enough and could be considered motivational rather than substantiated. The reviewer suggests that the authors either formalize the connection or adjust the language to clarify it. However, the comment lacks specific examples or detailed reasoning to support the claim that the connection is not formal enough. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific issue with the probabilistic connection in the paper, suggesting that it is not formal enough and could be considered motivational rather than substantiated. It provides a clear and actionable suggestion by recommending that the authors either formalize the connection or adjust the language to clarify it. This feedback is valuable as it guides the authors on how to strengthen the theoretical foundation of their work, making the comment 4. However, it could be more helpful if it included specific examples or suggestions on how to formalize the connection or adjust the language. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a significant concern regarding the experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a specific issue and provides a potential solution, it does not offer detailed guidance on how to implement the suggested comparison or why it would be beneficial. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional comparisons and understand the reasoning behind the current approach. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically mentioning the issue of only reporting selfcomparisons and the lack of explanation for this choice. It suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment does not explicitly mention a specific section, the authors can infer that it pertains to the experiments section. The comment is specific in detailing what needs to be addressed, such as the need for comparisons with SketchRNN. However, since it does not explicitly mention the experiments section, it is weakly grounded but specific. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a concern about the experiments, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. The reviewer suggests that comparisons with SketchRNN could be performed in a generative setting. While the comment identifies a potential issue and provides a suggestion for improvement, it lacks specific examples or references to substantiate the claim that selfcomparisons are insufficient. The suggestion to compare with SketchRNN is logical, but the lack of detailed justification or evidence makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the experiments section, specifically noting that the paper only reports selfcomparisons and lacks an explanation for this choice. It highlights the poor motivation problem and suggests that comparisons with SketchRNN could be performed in a generative setting. This feedback is clear and actionable, as it points out a specific area for improvement and provides a concrete suggestion for enhancing the experimental section. However, the comment could be more helpful if it included additional guidance on how to conduct these comparisons or why they are necessary. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment provides a critique of the paper\"s contributions, noting that they are small and similar to previous methods like NCNet and Sparse NCNet. However, it does not offer any explicit or implicit suggestions for improvement or guidance on how the authors might address these concerns. The comment lacks actionable details, such as recommending ways to enhance the contributions or differentiate the work from its predecessors. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the paper\"s contributions, mentioning NCNet and Sparse NCNet as previous methods. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the contributions are small or similar to predecessors. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contributions of the paper are small and similar to previous methods, specifically NCNet and Sparse NCNet. However, the comment lacks specific evidence or detailed comparisons to substantiate this claim. It mentions that the contributions are mostly engineeringbased and perform similarly in practice, but without further elaboration or references, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully support the claim.", "helpfulness_rationale": "The review comment critiques the paper\"s contributions, noting that they are small and similar to previous methods like NCNet and Sparse NCNet. It also mentions that the work seems to be mostly engineeringbased and performs similarly in practice. However, the comment lacks specific suggestions or actionable feedback on how the authors might address these concerns or differentiate their work from its predecessors. Without detailed guidance or constructive advice, the comment does not provide the authors with a clear path for improvement. Therefore, it is rated as 2, as it identifies a potential issue but does not offer sufficient direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the ecological validity of the vulnerability discovery methodology, noting that the authors consider a single vulnerability at a time. It suggests that previous work has considered multiple vulnerabilities simultaneously and reports on the presence of such vulnerabilities. The reviewer is uncertain whether the authors are arguing that identifying one vulnerability at a time is an intended use case. The comment also mentions that the results are difficult to interpret or only show marginal improvements. While the comment raises important questions about the methodology and results, it does not provide explicit guidance on how the authors should address these concerns or improve their draft. The action is implicit and vague, as the authors need to infer that they should consider multiple vulnerabilities and provide a clearer interpretation of their results. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the vulnerability discovery methodology, specifically questioning the ecological validity of considering a single vulnerability at a time. It references previous work that considers multiple vulnerabilities simultaneously, suggesting a potential gap in the current study. However, the comment does not specify which part of the paper discusses this methodology, making it weakly grounded. The comment is specific in its critique of the methodology and the interpretation of results, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the ecological validity of the vulnerability discovery methodology, suggesting that considering a single vulnerability at a time may not be representative of realworld scenarios. The reviewer references previous work that considers multiple vulnerabilities simultaneously, providing a basis for their critique. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim about ecological validity. While the reference to previous work adds some support, the comment could be strengthened with more explicit examples or data to fully verify the claim. Therefore, the comment is categorized as 3, as it provides some support but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment raises a critical question about the ecological validity of the vulnerability discovery methodology, suggesting that considering a single vulnerability at a time may not be representative of realworld scenarios. It references previous work that considers multiple vulnerabilities simultaneously, providing a basis for the critique. The comment also questions the ecological validity of the study and notes that the results are difficult to interpret. While the comment identifies a potential weakness in the study\"s approach, it lacks specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it prompts the authors to reconsider their approach and provides some context, but it could be more actionable with additional guidance or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the originality of the paper is limited because the main idea of variable splitting and the algorithm are not new. However, it does not provide any guidance or suggestions on how the authors could address this issue or enhance the originality of their work. The comment lacks actionable details, such as recommending ways to differentiate the work from existing literature or suggesting novel applications of the variable splitting method. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the originality of the paper by stating that the main idea of variable splitting and the algorithm are not new. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the originality are lacking or how they could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing revision. As a result, the comment lacks both grounding and specificity, making it 1 at all. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point claims that the originality of the paper is limited because the main idea of variable splitting and the algorithm are not new. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without specific examples or comparisons to existing work, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a lack of originality in the paper, specifically noting that the main idea of variable splitting and the algorithm are not new. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or differentiate their work from existing literature. Without actionable advice or specific guidance, the comment does not assist the authors in improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments are limited to toy data and suggests that it would be interesting to show the performance of the method on real data where barycenters can be used. While the comment implies that the authors should include experiments with real data, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to select or design these real data experiments. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a limitation in the experiments, noting that they are limited to toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used. However, the comment does not specify which part of the paper discusses the experiments or where the authors should include these additional experiments. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in suggesting the inclusion of real data experiments, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited to toy data and suggests that it would be beneficial to show performance on real data where barycenters can be used. However, the comment lacks specific examples or references to real data scenarios where barycenters are applicable, making it difficult for the authors to understand the basis of the suggestion. The claim is 3 as it provides a logical reasoning for the suggestion, but it lacks detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the experiments are limited to toy data. It suggests that the method\"s performance should be evaluated on real data where barycenters can be used, which is an interesting and relevant area for further exploration. This feedback is 3 as it points out a potential gap in the experimental validation and encourages the authors to consider broader applications of their method. However, the comment could be more helpful if it provided specific examples of real data scenarios or suggested how to incorporate these into the study. Overall, the comment offers a direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies specific issues with the clarity of the first two sections of the paper, particularly regarding the explanation of previous approaches. It provides concrete examples of where the explanation is lacking, such as the conversion of a stacked LSTM to a sequential LSTM and the interpretation of sentences in lines 43 and 96. The reviewer explicitly asks for clarification on these points, providing clear guidance on what needs to be addressed. This feedback is explicit and concrete, giving the authors a clear understanding of where and how to improve the clarity of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the first two sections of the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it provides detailed examples of where the explanation is lacking, such as the conversion of a stacked LSTM to a sequential LSTM and the interpretation of sentences in lines 43 and 96. The comment clearly specifies what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the first two sections of the paper are difficult to read due to unclear explanations of previous approaches. It provides specific examples, such as the conversion of a stacked LSTM to a sequential LSTM and the interpretation of sentences in lines 43 and 96, to illustrate the issues. However, the comment does not offer detailed reasoning or references to support why these explanations are unclear or how they could be improved. While the examples provide some context, the lack of further elaboration or evidence makes the claim 3. The authors would need to make a significant effort to understand and address the issues raised, thus justifying a score of 3.", "helpfulness_rationale": "The review comment identifies specific areas where the paper\"s clarity is lacking, particularly in the first two sections. It provides detailed examples of unclear explanations, such as the conversion of a stacked LSTM to a sequential LSTM and the interpretation of sentences in lines 43 and 96. By pinpointing these specific issues, the comment offers clear and actionable feedback that can help the authors improve the readability and understanding of their work. However, the comment could be more helpful if it included suggestions on how to clarify these points or provided additional context. Overall, the feedback is 4 as it directs the authors to specific areas needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the evaluation is weak and that the baselines used in the paper are not designed for fair classification. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the evaluation or select more appropriate baselines. Without specific suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation section of the paper, stating that the baselines used are not designed for fair classification. However, it does not specify which part of the evaluation section this critique is based on, nor does it provide details on what aspects of the baselines are problematic or how they could be improved. Without explicit references to specific sections, figures, or tables, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the evaluation is weak because the baselines used in the paper are not designed for fair classification. However, the comment does not provide specific examples or references to support this claim. Without detailed justification or evidence, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a significant issue with the evaluation section of the paper, specifically noting that the baselines used are not designed for fair classification. This is a critical observation that could impact the validity and fairness of the results presented in the paper. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the evaluation. Without actionable feedback or detailed advice, the authors are left with only a general understanding of the problem but no clear path to resolve it. Therefore, the comment is 3, as it highlights an important area for improvement but lacks the depth needed to be fully beneficial."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the proposed solution is an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any explicit or implicit actions for the authors to take. There are no suggestions for improvements, further analysis, or additional experiments that could be conducted. The comment lacks any guidance on how the authors might enhance their work or address the incremental nature of their contribution. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment mentions that the proposed solution is an incremental step considering the relaxation proposed by Guzman et al. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the solution are considered incremental or how they relate to Guzman et al.\"s work. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point claims that the proposed solution is an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any specific details, examples, or references to support this claim. The lack of supporting evidence or reasoning makes it difficult for the authors to understand the basis of the claim and how it relates to the paper\"s content. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges that the proposed solution is an incremental step based on the relaxation proposed by Guzman et al. However, it does not provide any specific feedback or suggestions for improvement. The mention of minor suggestions is vague and lacks detail, leaving the authors without clear guidance on how to enhance their work. Without actionable advice or constructive critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the hGRU architecture appears to be adhoc and not wellmotivated. However, it does not provide any specific guidance or suggestions on how the authors could address this issue or improve the motivation behind the architecture. The comment lacks actionable details, such as recommending ways to enhance the motivation or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the hGRU architecture as being adhoc and not wellmotivated. However, it does not specify which part of the paper discusses the hGRU architecture, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the hGRU architecture are adhoc or poorly motivated, providing no guidance on how to address these issues. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the hGRU architecture appears to be adhoc and not wellmotivated. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the hGRU architecture appears to be adhoc and not wellmotivated, which is a valid concern that could impact the paper\"s credibility and understanding. However, the comment lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this issue or improve the motivation behind the architecture. Without detailed feedback or constructive advice, the authors are left with only a vague understanding of the problem, making the comment 2. Therefore, it aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the claim of parameter efficiency for COCOLM by suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the authors\" claim of parameter efficiency and asks for an explanation regarding the switch in BPE vocabulary types (uncased and cased) in the experimental setup. The reviewer also raises a question about whether the change in BPE vocabulary causes variance in performance. While the comment implies that the authors should provide additional justification or analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the questions raised. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison with Megatron and COCOLM, suggesting that the performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the claim of parameter efficiency and asks for clarification on the experimental setup, specifically regarding the switch in BPE vocabulary types. While the comment does not explicitly mention a specific section, the authors can infer that it relates to the experimental setup or results sections. The comment is specific in its critique of the claim and the questions it raises, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that the comparison with Megatron is overrated, suggesting that the performance of Megatron and COCOLM is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. The reviewer provides examples of other models with similar sizes, which supports the claim that the performance is not as distinct as claimed. However, the comment lacks specific references or detailed comparisons to substantiate the claim fully. While the reasoning is somewhat logical, the absence of explicit evidence or references makes it 3. The authors would need to further explore the provided examples to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the claim of parameter efficiency for COCOLM by suggesting that its performance is similar to other approaches like RoBERTa, ELECTRA, and DeBERTa. It questions the authors\" claim of parameter efficiency and asks for clarification on the experimental setup, specifically regarding the switch in BPE vocabulary types. This feedback is 3 as it prompts the authors to reconsider their claims and provides a specific area for further exploration. However, it lacks detailed suggestions or guidance on how to address the issue or improve the draft. The comment could be more helpful if it offered specific recommendations or examples of how to strengthen the argument or clarify the claims. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the analysis from line 128 to 149, noting that it is not convincing enough. It provides a specific observation from the histogram in Fig 3, where the GSP50 model has a smaller class selectivity score, suggesting that GSP50 shares more features and ResNet50 learns more classspecific features. The reviewer also references a hypothesis about additional context allowing the network to reduce dependency. However, the comment does not explicitly instruct the authors on how to improve the analysis or what specific changes should be made to make it more convincing. While the authors can infer that they need to strengthen their analysis and provide a clearer explanation, the comment lacks concrete guidance on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis from line 128 to 149, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a detailed critique of the analysis, explaining the observation from the histogram in Fig 3 and the hypothesis about GSP50 and ResNet50. The comment further references external works to support the analysis, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the analysis from line 128 to 149, suggesting it is not convincing enough. The reviewer provides a specific observation from the histogram in Fig 3, where the GSP50 model has a smaller class selectivity score, implying that GSP50 shares more features and ResNet50 learns more classspecific features. The reviewer also references a hypothesis about additional context allowing the network to reduce dependency. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as specific examples or further analysis. The reference to external works provides some context, but the comment could be strengthened with more detailed explanations or comparisons. Therefore, the claim is 3, as it provides a basis for the critique but requires additional detail to be fully convincing.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis presented in the paper, noting that the analysis from line 128 to 149 is not convincing enough. It provides a detailed explanation of the observation from the histogram in Fig 3, where the GSP50 model has a smaller class selectivity score, suggesting that GSP50 shares more features and ResNet50 learns more classspecific features. The reviewer also references a hypothesis about additional context allowing the network to reduce dependency. While the comment highlights a potential weakness in the analysis, it does not offer specific suggestions or guidance on how the authors might address this issue or improve the analysis. The reference to external works provides some context, but the comment could be more helpful by offering actionable advice or alternative approaches. Overall, the comment is 3 as it identifies a specific area for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point notes that some observations and design decisions might be hardware and software dependent. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how this observation should influence the paper, nor are there suggestions for addressing this dependency. As a result, the authors are left without any actionable steps to improve their draft based on this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment suggests that some observations and design decisions might be hardware and software dependent. However, it does not specify which observations or design decisions are being referred to, nor does it provide any context or examples from the paper. This lack of specificity and grounding makes it difficult for the authors to identify and address the issue effectively. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it does not provide any specific examples, reasoning, or evidence to support this claim. Without detailed justification or examples, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment makes a general observation about the potential dependence of observations and design decisions on hardware and software. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without identifying particular areas where this dependency might be an issue or offering guidance on how to address it, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the weak recovery problem studied is primarily of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the practical impact of their work. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the practical relevance of the study. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the weak recovery problem studied in the paper and questions its practical utility, particularly for nonGaussian problems. However, it does not specify which part of the paper discusses this issue, making it weakly grounded. The comment is specific in its critique of the practical impact of the AMP algorithm, but without clear grounding, the authors may struggle to identify the exact sections that need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the weak recovery problem studied is primarily of theoretical interest and questions the practical utility of the AMP algorithm for nonGaussian problems. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the practical impact is limited. Without these elements, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment identifies a limitation in the paper regarding the practical utility of the weak recovery problem studied, particularly in the context of nonGaussian problems. It questions whether the AMP algorithm is useful for such scenarios, suggesting that the practical impact may be limited. While the comment highlights an important area for consideration, it lacks specific suggestions or guidance on how the authors might address this limitation or enhance the practical relevance of their work. Without actionable feedback or detailed advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to perform ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be done to improve their draft. The comment is specific and concrete, offering a precise method for comparison that the authors can follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests performing ablation experiments to compare the proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where these comparisons should be made. This lack of explicit reference makes it weakly grounded. The comment is specific in detailing what needs to be addressed\u2014performing ablation experiments and comparing methods based on learnable parameters and GFLOPs. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. While the comment provides a clear direction for improvement, it lacks specific examples or references to support the claim that such comparisons are necessary. The suggestion is based on a logical reasoning that comparing methods based on these metrics would provide valuable insights, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for the authors to perform ablation experiments to compare their proposed method with other methods, such as TubeR, in terms of the number of learnable parameters and GFLOPs. This feedback is specific and offers a concrete way for the authors to enhance their experimental evaluation and demonstrate the effectiveness of their method. By addressing this suggestion, the authors can provide a more comprehensive comparison and strengthen the validity of their claims. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a plot illustrating how different weights of the model change after unlearning, specifically focusing on which layers are most affected. This feedback is explicit in its request for a specific type of plot and provides a clear action for the authors to take. The suggestion is concrete, as it specifies exactly what kind of analysis should be conducted and how it should be presented. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests providing a plot to illustrate how different weights of the model change after unlearning, specifically focusing on which layers are most affected. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where such an analysis could be included. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a particular type of analysis, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide a plot illustrating how different weights of the model change after unlearning, specifically focusing on which layers are most affected. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such a plot would be beneficial. The suggestion is based on a general idea of analyzing weight changes, but without detailed justification or evidence, it remains somewhat vague. Therefore, the comment is categorized as 3, as it provides a reasonable suggestion but lacks comprehensive support.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending the inclusion of a plot that illustrates how different weights of the model change after unlearning. This feedback is clear and offers a concrete way for the authors to enhance their analysis and provide insights into the impact of unlearning on different layers of the model. By addressing this suggestion, the authors can offer a more comprehensive understanding of their method\"s behavior. However, the comment could be more helpful if it included additional guidance on how to create the plot or what specific aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly states that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions being too close to the figures. It further explains that this issue effectively violates the 9page paper limit, justifying rejection. The comment provides a clear and direct action for the authors to take, which is to address the whitespace issue to meet the page limit. The feedback is specific and actionable, giving the authors a precise task to perform. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of whitespace reduction throughout the paper, specifically pointing out that equations are crammed together and captions are too close to the figures. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies the issue with the layout and how it violates the 9page paper limit, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have reduced whitespace throughout the paper, resulting in equations being crammed together and captions too close to the figures. This issue is presented as a violation of the 9page paper limit, which is a standard constraint in academic publishing. The comment provides a logical reasoning by pointing out the specific formatting issues that lead to a potential violation of the page limit. However, it lacks specific examples or references to support the claim of whitespace reduction, making it 3. The authors would need to further investigate the paper to verify the claim, thus justifying a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the formatting of the paper, noting that the authors have reduced whitespace, causing equations to be crammed together and captions to be too close to the figures. This observation is significant because it points out a potential violation of the 9page paper limit, which is a critical constraint in academic publishing. The comment is clear and actionable, providing the authors with a direct and verifiable issue to address. However, it could be more helpful if it offered suggestions on how to improve the layout or formatting to meet the page limit. Despite this, the feedback is 4 as it highlights a critical issue that the authors need to address to ensure compliance with publication standards."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides a clear and explicit suggestion for improving the paper by recommending the inclusion of a plot with sparsity on the xaxis and performance on the yaxis. This would allow for a direct comparison of the flexibility of SGC with LoRA, offering a more intuitive demonstration of its practical performance benefits at different sparsity levels. The comment is specific and provides concrete guidance on how to implement the suggested change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the claim about SGC\"s flexibility and suggests including a plot with sparsity on the xaxis and performance on the yaxis. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it provides a clear suggestion for improvement by recommending a visualization to compare SGC with LoRA. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that PEFT methods typically target computeconstrained scenarios, where finegrained control may require extra tuning, thus reducing practicality. The reviewer suggests including a plot with sparsity on the xaxis and performance on the yaxis to compare SGC with LoRA. This claim is 3 as it provides a logical reasoning for the limitation of PEFT methods and suggests a specific visualization to address the issue. However, the comment lacks detailed examples or references to support the claim about PEFT methods\" limitations, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s claim regarding the flexibility and finegrained control offered by SGC, suggesting that PEFT methods may be more practical in computeconstrained scenarios. It provides a clear and actionable suggestion to include a plot with sparsity on the xaxis and performance on the yaxis to directly compare SGC with LoRA. This visualization could help illustrate whether SGC\"s finegrained control offers practical performance benefits at different sparsity levels. The feedback is specific and offers a concrete way for the authors to address the issue, making it 5 for improving the draft. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly identifies a specific area in the paper where relevant literature on using moment matching for distributional reinforcement learning (DRL) is lacking. It suggests that this should be discussed when talking about various approaches to DRL, even though the paper currently uses quantile regression. The comment provides a clear action for the authors to take, which is to include a discussion of the mentioned literature. However, it does not provide detailed guidance on how to integrate this information into the paper or what specific aspects should be highlighted. Therefore, the comment is 3, as it identifies an area for improvement but lacks detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific paragraph from lines 2230, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of relevant literature on using moment matching for distributional reinforcement learning (DRL) and suggests discussing this when talking about various approaches to DRL. The comment provides a specific reference to external work (NguyenTang et al AAAI\u201921) and suggests how the discussion should be expanded. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks relevant literature on using moment matching for distributional reinforcement learning (DRL), specifically referencing NguyenTang et al. (AAAI\u201921) as an example. This claim is supported by providing a specific reference to external work, which helps substantiate the argument. However, the comment could be strengthened by explaining how this literature is relevant to the paper\"s discussion or by providing additional examples of relevant works. As it stands, the claim is 4 due to the inclusion of a specific reference, but it could benefit from further elaboration. Therefore, the comment aligns with a label of 4.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper\"s literature review regarding the use of moment matching for distributional reinforcement learning (DRL). It suggests that the paper should discuss this approach, even though it currently uses quantile regression. By pointing out a relevant omission, the comment provides the authors with a clear direction for expanding their literature review. However, the comment could be more helpful if it offered additional guidance on how to integrate this discussion into the paper or why it is important. Overall, the feedback is 3 as it highlights an area for improvement but lacks detailed suggestions for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should analyze the quality of the local minima found by Algorithm 1, specifically by examining the approximation ratio of these local minima under certain assumptions. While the comment implies that the authors should conduct this analysis, it does not provide explicit instructions or detailed guidance on how to perform it. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of Algorithm 1\"s convergence to permutations as local minima, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests analyzing the quality of these local minima, such as their approximation ratio under certain assumptions. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should analyze the quality of the local minima found by Algorithm 1, specifically by examining their approximation ratio under certain assumptions. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that this analysis is necessary or how it would enhance the paper. The suggestion is based on logical reasoning but lacks detailed justification or evidence, making it 3. The authors would need to make a significant effort to understand and implement the suggested analysis without further guidance.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the analysis of the quality of local minima found by Algorithm 1. It suggests that the authors should explore the approximation ratio of these local minima under certain assumptions, which could provide valuable insights into the effectiveness of the algorithm. This feedback is clear and actionable, offering a concrete direction for enhancing the paper\"s analysis and potentially improving its contribution. However, the comment could be more helpful if it provided specific examples or methodologies for conducting this analysis. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises important questions about the use of morphologic segmentation across domains and how it should be conducted differently for different domains. It suggests that the paper lacks insight into this aspect and assumes morphologic segmentation will be invariant. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address these questions or what specific actions they should take to improve their draft. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details or insights on morphologic segmentation across domains. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the use of morphologic segmentation across domains and how it should be conducted differently for different domains. It suggests that the paper lacks insight into this aspect and assumes morphologic segmentation will be invariant. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about the need for more insight into morphologic segmentation across domains, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the use of morphologic segmentation across domains and how it should be conducted differently for different domains. It suggests that the paper assumes morphologic segmentation will be invariant, which is a claim that requires further justification. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the assumption is problematic or necessary. This lack of supporting evidence makes the claim 3, as the authors would need to make a significant effort to understand and address the issue raised. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper regarding the use of morphologic segmentation across domains and questions whether it should be conducted differently for different domains. It highlights the assumption that morphologic segmentation will be invariant, which is a significant oversight given the task of domain adaptation. The comment suggests that the paper lacks insight into this aspect, which is crucial for the authors to address. While the feedback is clear in pointing out a specific area for improvement, it could be more helpful by offering suggestions on how to explore or address this issue. Overall, the comment is 4 as it directs the authors to a key area needing clarification and improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the analysis of experimental results is insufficient, specifically mentioning that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. While the comment identifies a specific area that needs improvement, it does not explicitly instruct the authors on how to conduct this analysis or what aspects to focus on. The action is implicit and somewhat vague, as the authors know they need to provide more analysis but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of experimental results and the scope prompting method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of analysis regarding the poor performance of the scope prompting method on GPT3.5turbo, suggesting that the authors should provide an explanation for this outcome. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of experimental results is insufficient, specifically mentioning that the authors only note the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This claim is 3 as it highlights a specific gap in the analysis, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the specific aspects of the analysis that are missing, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the insufficient analysis of experimental results. It points out that the authors only mention the poor performance of the scope prompting method on GPT3.5turbo without providing any analysis of the underlying reasons. This feedback is clear and actionable, as it directs the authors to expand their analysis and provide a deeper understanding of the results. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the novelty of interpreting the prediction of deep neural networks using a linear model is limited, as this approach is not new. However, it does not provide any explicit or implicit suggestions for how the authors could address this issue or enhance the novelty of their work. There is no guidance on potential improvements, alternative approaches, or additional experiments that could be conducted to differentiate the work. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the approach, specifically mentioning that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not specify which part of the paper this critique is based on, nor does it provide details on how the approach is presented or where it might be lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of interpreting the prediction of deep neural networks using a linear model is limited, as this approach is not new. However, the comment does not provide any supporting evidence, references, or detailed explanation to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a perceived limitation in the novelty of the paper, specifically noting that interpreting the prediction of deep neural networks using a linear model is not a new approach. However, it does not provide any constructive feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without actionable advice or specific guidance, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments should be more comprehensive and general, specifically mentioning that the model size is limited and the baselines are restrictive for both the language modeling task and image classification task. While the comment identifies areas for improvement, it does not provide explicit guidance on how to expand the experiments or which specific aspects should be addressed. The action is implicit and somewhat vague, as the authors can infer that they need to broaden their experiments but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments should be more comprehensive and general, specifically mentioning the limitations in model size and baselines for both the language modeling task and image classification task. However, it does not specify which parts of the paper these issues pertain to, such as specific sections or experiments where these limitations are evident. The authors might infer that this relates to the experimental setup or results sections, but the lack of explicit references makes it weakly grounded. The comment is specific in identifying the need for more comprehensive experiments and general baselines, but without clear grounding, it aligns with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are limited in scope and generality, specifically mentioning that the model size is restricted and the baselines are not comprehensive for both the language modeling task and image classification task. However, the comment lacks specific examples or references to support these claims, such as which baselines are considered restrictive or how the model size is limited. This makes the claim 3, as the authors would need to make a significant effort to understand and address the critique without additional context or evidence. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experimental setup, specifically noting that the experiments are limited in scope and generality. It points out that the model size is restricted and the baselines are not comprehensive for both the language modeling task and image classification task. This feedback is valuable as it highlights areas where the authors can improve their experimental design to provide a more robust evaluation of their model. However, the comment could be more helpful if it offered specific suggestions on how to expand the experiments or which additional baselines or model sizes should be considered. Despite this, the feedback is 4 as it directs the authors\" attention to important aspects of their experimental design that need enhancement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of an ablation study that explains the choice of prompt, specifically mentioning the potential benefit of using fewshot examples for CoT to improve performance. While the comment implies that the authors should conduct an ablation study, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to design or execute the ablation study. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and determine how to implement it. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the lack of an ablation study to explain the choice of prompt, particularly the use of fewshot examples for CoT. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the prompt choice is discussed. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the need for an ablation study but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study to justify the choice of prompt, specifically mentioning the potential benefit of using fewshot examples for CoT to improve performance. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific gap in the paper, namely the lack of an ablation study to justify the choice of prompt, particularly the use of fewshot examples for CoT. It suggests that such an ablation study could potentially improve performance, providing a clear direction for the authors to enhance their work. However, the comment does not offer detailed guidance on how to conduct the ablation study or what specific aspects to focus on, which limits its helpfulness. While it points out an important area for improvement, the feedback could be more actionable with additional suggestions or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experiments are insufficient and suggests that more empirical or toy experiments should be conducted to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. It also mentions citing the result in Kaplan et al. 2020. While the comment provides a clear direction for improvement, it lacks specific guidance on what kind of additional experiments should be conducted or how to effectively demonstrate the validity of the model relaxations. The action is explicit but somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the need for more empirical experiments or toy experiments to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments that need improvement. The authors might infer that it relates to the experimental section, but this inference is not direct. The comment is specific in suggesting the need for additional experiments but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments are insufficient and suggests that more empirical or toy experiments are needed to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. The comment provides some support by mentioning the need for additional experiments and referencing Kaplan et al. 2020. However, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to cite Kaplan et al. 2020 is a starting point but does not provide a comprehensive explanation of how the additional experiments would address the concerns. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant limitation in the experimental section, noting that the experiments are insufficient to validate the model relaxations and ensure consistency between theoretical analysis and empirical results. It suggests that additional empirical or toy experiments should be conducted to address this gap. The comment also references Kaplan et al. 2020, indicating that the authors should consider citing this work. This feedback is clear and actionable, providing the authors with a specific direction for expanding their experimental validation. However, it could be more helpful if it offered suggestions on how to design these additional experiments or what specific aspects to focus on. Overall, the comment is 4 as it highlights a critical area for improvement and provides a starting point for the authors to enhance their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests conducting an experiment where the image is occluded, with half of the image randomly blacked out. It provides two reasons for this suggestion: (a) to simulate the irregularity often present in neural/behavioral data, such as keypoint detection failures, and (b) to allow the inspection of the model\"s longrange inference capacity. The comment also acknowledges that these experiments should be reasonably easy to run and suggests they should be included in the final version, unless the authors can convince them otherwise. The feedback is explicit and provides concrete guidance on what experiments to include, making it 5.", "grounding_specificity_rationale": "The comment suggests conducting an experiment where the image is occluded, providing specific reasons for this suggestion. It mentions simulating irregularity in neural/behavioral data and inspecting the model\"s longrange inference capacity. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what additional experiments should be included, providing clear guidance on how to enhance the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting an experiment where the image is occluded to simulate irregularity in neural/behavioral data and to inspect the model\"s longrange inference capacity. The claim is supported by logical reasoning, as it connects the suggested experiment to realworld scenarios where such irregularities occur, such as keypoint detection failures. The comment also provides a clear rationale for why this experiment would be beneficial, aligning with the authors\" goals. However, the comment could be strengthened by providing specific examples or references to similar studies where such experiments have been successful. Overall, the claim is 4 due to its logical reasoning and clear connection to the paper\"s objectives, but it could benefit from additional evidence or references. Therefore, it is rated as 4.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by proposing an experiment where the image is occluded. This suggestion is relevant as it simulates realworld scenarios where data irregularities are common, such as keypoint detection failures in neural/behavioral data. By conducting this experiment, the authors could better assess the model\"s longrange inference capacity, which is a valuable contribution to the study. The comment is clear and offers a concrete way to enhance the paper\"s experimental section, making it 5 for the authors. Therefore, it deserves a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the specificity of the proposed methodology to bimanual manipulation, suggesting that robotic manipulation could be more appropriate. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or clarify the methodology\"s specificity. The comment lacks actionable details, such as recommending specific changes or providing examples of how to make the methodology more general or specific. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the specificity of the proposed methodology to bimanual manipulation, suggesting that robotic manipulation could be more appropriate. However, it does not specify which part of the paper this concern pertains to, such as a particular section, figure, or discussion. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting that the methodology might not be specific to bimanual manipulation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the specificity of the proposed methodology to bimanual manipulation, suggesting that robotic manipulation could be more appropriate. However, the comment lacks any supporting evidence, reasoning, or references to justify why robotic manipulation would be more appropriate or how the current methodology fails to be specific to bimanual manipulation. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a concern about the specificity of the proposed methodology to bimanual manipulation, suggesting that robotic manipulation could be more appropriate. However, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or clarify the methodology\"s applicability. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the consistency of the advantage of UNIFORM over other procedures, noting that the tables do not always show a clear advantage, particularly in the 1shot setting. It asks the authors to provide a theory for why the method is not as effective in this setting. While the comment implies that the authors should investigate and explain this inconsistency, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to address this issue or what specific aspects to focus on. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the tables and the 1shot setting, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it points out the inconsistency in the advantage of UNIFORM over other procedures, particularly in the 1shot setting, and asks for a theory to explain this. The comment also acknowledges the clarity and design of the experiments and results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the advantage of UNIFORM over other procedures is not consistent, as evidenced by the tables showing that UNIFORM does not always offer a clear advantage, especially in the 1shot setting. The reviewer suggests that the authors provide a theory to explain why the method is less effective in this setting. While the comment identifies a potential issue and asks for further explanation, it lacks specific examples or detailed reasoning to support the claim. The suggestion to provide a theory is a reasonable request, but without additional context or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the consistency of the advantage of UNIFORM over other procedures, particularly noting that the tables do not always show a clear advantage, especially in the 1shot setting. It suggests that the authors provide a theory to explain why the method is less effective in this setting. This feedback is clear and actionable, as it prompts the authors to investigate and address a potential weakness in their methodology. However, the comment could be more helpful if it offered suggestions on how to approach this investigation or provided examples of similar issues in the literature. Overall, the comment is 4 as it directs the authors\" attention to a critical area needing further exploration and provides a clear direction for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the proposed method, noting that it lacks a sparsity constraint in the number of factors used by subsequent tasks. This could lead to an increase in the number of factors and computation as more tasks are added. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to mitigate this problem. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the proposed method, highlighting the lack of a sparsity constraint in the number of factors used by subsequent tasks. This provides a clear indication of what needs to be addressed, making the comment specific. However, the comment does not explicitly mention which part of the paper discusses this aspect, leaving the authors to infer that it relates to the methodology or results sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method lacks a sparsity constraint, which could lead to an increase in the number of factors and computation as more tasks are added. This claim is based on logical reasoning, as the absence of a sparsity constraint would indeed incentivize the model to use more factors. However, the comment does not provide specific examples or references to support this claim, such as comparisons with other models or detailed explanations of how the lack of sparsity affects performance. Therefore, the claim is 3, as it provides a logical basis but lacks detailed evidence or references to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed method, specifically the lack of a sparsity constraint in the number of factors used by subsequent tasks. This observation is important as it could lead to an increase in the number of factors and computation as more tasks are added, potentially affecting the model\"s efficiency and scalability. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their method. While it highlights a relevant concern, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should reproduce the main features of previous models to ensure a fair comparison. It implies that the current approach of applying regularization to both LN models and GLMs might not be the most appropriate way to compare them. However, the comment does not provide explicit instructions on how to reproduce the main features of previous models or which specific features should be reproduced. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of regularization applied to both LN models and GLMs, suggesting that the comparison might not be fair. It references the work of pillow et al. and mentions specific aspects of their model, such as the use of L1 regularization and lowrank approximation. However, the comment does not explicitly mention which part of the paper discusses the regularization or the models being compared, making it weakly grounded. The comment is specific in detailing what needs to be addressed regarding the comparison and the reproduction of features from previous models. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the fairness of the comparison between the LN model and the GLM, suggesting that the GLM presented by pillow et al. did not use cropping but instead employed L1 regularization and a lowrank approximation. The reviewer provides a specific reference to pillow et al.\"s work, which supports the claim and offers a clear rationale for why the comparison might not be fair. This detailed reasoning and reference make the claim 5, as it provides a solid foundation for the critique. Therefore, the comment is classified as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental setup, specifically the application of regularization to both LN models and GLMs. It suggests that the comparison might not be fair due to differences in how previous models were handled. The comment provides a specific reference to the work of pillow et al., which is helpful in understanding the context and potential discrepancies in the models being compared. However, the comment could be more helpful if it offered suggestions on how to address this issue or how to ensure a fair comparison. While it provides some insight into the problem, it lacks detailed guidance or actionable steps for the authors to improve their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors include supervised baselines in their experiments, particularly for datasets of a certain scale. It provides a rationale for this suggestion by explaining that full annotation is available for datasets of this scale in practice, and even if it isn\"t, it would be informative to compare selfsupervised methods to a fully supervised pretrained network. The comment is explicit in its request for the inclusion of supervised baselines and provides a clear rationale for why this would be beneficial. However, it does not specify which datasets or methods should be included as baselines, leaving some room for interpretation. Despite this, the action is concrete and directly actionable, making the comment 4.", "grounding_specificity_rationale": "The comment suggests the inclusion of supervised baselines in the experiments, particularly for datasets of a certain scale. It provides a rationale for this suggestion by explaining that full annotation is available for datasets of this scale in practice, even if it isn\"t always the case. However, the comment does not specify which part of the paper should include these baselines, making it weakly grounded. The suggestion is specific in terms of what is missing\u2014the inclusion of supervised baselines\u2014but lacks grounding in the paper\"s structure or sections. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the absence of supervised baselines is a reasonable assumption for datasets of a certain scale, where full annotation is available. It provides a logical reasoning by explaining that even if full annotation isn\"t available, it would be informative to compare selfsupervised methods to a fully supervised pretrained network. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning themselves to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out the absence of supervised baselines in the experiments. It provides a clear rationale for including these baselines, explaining that for datasets of a certain scale, full annotation is available, and even if it isn\"t, it would be informative to compare selfsupervised methods to a fully supervised pretrained network. This feedback is actionable and offers a specific direction for improvement, helping the authors enhance the comprehensiveness of their experimental evaluation. However, the comment could be more helpful if it suggested specific datasets or methods to consider as baselines. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to average results over multiple runs to determine statistical significance. This is a clear and direct action that the authors can take to improve their draft. The comment provides a specific and concrete suggestion, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the results should be averaged over multiple runs to determine statistical significance. However, it does not specify which part of the paper this suggestion pertains to, such as specific experiments or results sections. Without explicit references, the authors cannot confidently determine which parts need revision or improvement. The lack of grounding makes it difficult for the authors to address the feedback effectively. Additionally, the comment lacks specificity regarding which results or experiments should be averaged or how this averaging would impact the conclusions. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that results should be averaged over multiple runs to determine statistical significance. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would impact the results. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion or how to implement it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the statistical rigor of the results by recommending that they be averaged over multiple runs to determine statistical significance. This feedback is clear and offers a concrete step for the authors to enhance the reliability and validity of their findings. However, the comment could be more helpful if it included additional guidance on how to implement this suggestion or why averaging over multiple runs is crucial for the study\"s conclusions. Despite this, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental. However, it does not provide any specific guidance or suggestions on how the authors could address these concerns or improve the paper. The feedback lacks actionable details, such as recommending ways to enhance the contribution or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the limited contribution and incremental nature of the proposed model. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the contribution or model are considered limited or incremental. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point claims that the contribution of the paper is somewhat limited and that the proposed model is incremental. However, the comment does not provide any supporting evidence, reasoning, or examples to justify these claims. Without specific details or references, the authors may find it difficult to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses an opinion that the contribution of the paper is limited and that the proposed model is incremental. However, it does not provide any specific details or suggestions on how the authors might address these concerns or improve the contribution of their work. Without actionable feedback or guidance, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the regularization term appears adhoc and lacks theoretical support. It implies that the authors should provide a more rigorous theoretical justification for their choice of regularization. Additionally, it questions why certain statistics, such as the median, were not considered as alternatives to the mean and standard deviation in the regularization. While the comment highlights areas for improvement, it does not provide explicit instructions on how to address these issues or suggest specific theoretical frameworks or alternative statistics to consider. The action is implicit and somewhat vague, as the authors need to infer the need for theoretical support and explore alternative statistics without clear guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the regularization term in the paper, suggesting that it appears adhoc and lacks theoretical support. It provides some context by mentioning that the author has provided an intuitive explanation but lacks theoretical backing. The comment also suggests considering other statistics, such as the median, as alternatives to the mean and standard deviation in the regularization. However, it does not specify which part of the paper discusses the regularization term, making it weakly grounded. The comment is specific in its critique and suggestions for improvement, as it points out the need for theoretical support and explores alternative statistical measures. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point claims that the regularization term appears adhoc and lacks theoretical support. It suggests that other statistics, such as the median, could be used instead of the mean and standard deviation. However, the comment does not provide specific examples or references to support the claim that the current approach is adhoc or lacks theoretical support. The suggestion to consider the median as an alternative is also not substantiated with evidence or reasoning. This lack of detailed justification makes the claim 3, as the authors would need to further explore and understand the basis of the critique to address it effectively.", "helpfulness_rationale": "The review comment identifies a potential issue with the regularization term, suggesting that it appears adhoc and lacks theoretical support. It acknowledges the intuitive explanation provided by the authors but points out the absence of theoretical backing. The comment also suggests considering alternative statistics, such as the median, as replacements for the mean and standard deviation in the regularization. This feedback is 3 as it highlights a specific area for improvement and provides a potential direction for exploration. However, it lacks detailed guidance or specific suggestions on how to address the theoretical gap or implement the alternative statistics. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit and concrete actions for the authors to take. It suggests that the text in legends and axis labels should be larger, and it specifies the exact location where this change is needed, at the beginning of page 6. Additionally, it provides clear guidance on how to address the confusion with Proposition (1) and suggests that captions and legends\" font should be larger in Figures 2 and 3. Each of these points is specific and actionable, giving the authors clear instructions on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific parts of the paper, such as the legends and axis labels, the beginning of page 6, and Figures 2 and 3. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it provides clear guidance on what needs to be addressed, such as increasing the font size in legends and axis labels, correcting the confusion with Proposition (1), and ensuring the font size in captions and legends is similar to the text size. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point makes several claims regarding the size of text in legends and axis labels, the clarity of Proposition (1), and the font size in captions and legends. However, it does not provide any supporting evidence, reasoning, or references to justify these claims. The comment lacks detailed explanation or examples that would help the authors understand the issues or how to address them. As a result, the claims are 1, making it difficult for the authors to act on the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper. It suggests that the text in legends and axis labels should be larger, which is a clear and straightforward improvement that can enhance readability. Additionally, it points out a potential confusion with Proposition (1) and suggests that the captions and legend\"s font should be larger in Figures 2 and 3. These suggestions are precise and offer concrete steps for the authors to improve the clarity and presentation of their work. By addressing these points, the authors can make significant improvements to their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF, given confidence levels. While the comment implies that the authors should include such results, it does not explicitly instruct them to do so. The action is concrete but stated indirectly, making this comment 4.", "grounding_specificity_rationale": "The comment suggests improvements to the theoretical discussions, specifically mentioning the need for sample complexitytype results for not returning NSF. However, it does not specify which part of the paper this feedback pertains to, making it weakly grounded. The comment is specific in its suggestion for improvement, as it outlines a particular area for enhancement related to sample complexity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the theoretical discussions could be improved by providing sample complexitytype results for not returning NSF. The reviewer provides a specific example of what is expected, mentioning the need for results related to confidence levels and sufficient training data points. This reasoning is 3 as it offers a clear direction for improvement, but it lacks detailed justification or references to support the expectation of such results. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the theoretical discussions, suggesting that they could be enhanced by providing sample complexitytype results for not returning NSF. It provides a clear expectation for the authors to include results related to confidence levels and sufficient training data points. This feedback is actionable and offers a concrete direction for the authors to enhance their theoretical analysis, making it 4. However, it could be more helpful if it included additional guidance or examples on how to achieve these improvements. Therefore, the comment aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include case studies and error studies to demonstrate the effectiveness of each proposed component. It provides a specific example of a case study from another paper, which can serve as a reference for the authors. While the comment does not explicitly instruct the authors to add these studies, it provides a clear direction on what additional analysis could be included to strengthen the paper. The action is concrete but stated implicitly, making this comment 4.", "grounding_specificity_rationale": "The comment suggests including case studies and error studies to demonstrate the effectiveness of the proposed components. It provides a specific example of a case study from another paper, which can guide the authors in understanding what kind of analysis might be beneficial. However, the comment does not explicitly mention which part of the paper should include these studies, making it weakly grounded. The suggestion is specific, as it outlines a particular approach to enhance the paper\"s credibility. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including case studies and error studies would strengthen the paper\"s claims about the effectiveness of the proposed components. The reviewer provides a specific example of a case study from another paper, which serves as a reference for the authors. This example helps to substantiate the claim, making it 4. However, the comment could be further strengthened by explaining how these case studies would specifically demonstrate the effectiveness of the proposed components. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending the inclusion of case studies and error studies to demonstrate the effectiveness of the proposed components. It acknowledges the paper\"s mention of the Elementlevel Graph Pretraining and highlights the need for empirical evidence to support the claims. The comment also provides a specific example of a case study from another paper, which can guide the authors in conducting similar analyses. This feedback is clear, actionable, and offers a concrete approach to enhance the paper\"s credibility and impact. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the clarity of which component of the proposed method contributes to the performance gain. It suggests evaluating the proposed approach separately against baseline detection or parsing techniques to better support the claim. While the comment implies that the authors should conduct additional evaluations, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on how to perform the evaluation or which baselines to use. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method, specifically mentioning the two major components: the generative shape model and the word parsing model. It highlights the lack of clarity regarding which component contributes to the performance gain and suggests evaluating the proposed approach separately against baseline detection or parsing techniques. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The suggestion is specific, as it provides a clear direction for improvement by recommending separate evaluation against baseline techniques. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the clarity of which component of the proposed method contributes to the performance gain. It suggests evaluating the approach separately against baseline detection or parsing techniques to better support the claim. While the comment identifies a potential issue, it lacks specific examples or references to substantiate the claim that the evaluation is insufficient. The suggestion for evaluation is logical, but without detailed reasoning or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, specifically the lack of clarity regarding which component of the proposed method contributes to the performance gain. It suggests that the authors should evaluate their approach separately against baseline detection or parsing techniques to better support their claims. This feedback is clear and actionable, providing a specific direction for the authors to enhance the rigor and clarity of their experimental evaluation. By addressing this point, the authors can strengthen the validity of their claims and improve the overall quality of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve the clarity of their explanation. The comment lacks actionable guidance, leaving the authors uncertain about what steps to take to enhance their draft. Without specific instructions or examples, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not specify which part of the paper this issue pertains to, such as a particular section, figure, or discussion. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs attention. Additionally, the comment does not provide specific guidance on how to address this issue or what aspects should be clarified. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about the clarity of the method\"s behavior without the Lipschitz Hessian assumption. However, it does not provide any supporting evidence, reasoning, or examples to justify why this assumption is critical or how its absence affects the method\"s behavior. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper regarding the clarity of the method\"s behavior without the Lipschitz Hessian assumption. This is a relevant point that could impact the understanding and applicability of the method. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their explanation. Without actionable feedback or detailed advice, the authors are left with only a vague understanding of what needs to be improved. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the authors\" choice of using a transformer model without locality bias, suggesting that neighborhood agents should naturally influence each other more than distant nodes. The reviewer explicitly asks the authors to explain why the lack of locality in the transformer model is not a concern. This request is clear and provides a direct action for the authors to take, which is to provide an explanation. However, the comment does not offer specific guidance on how to address this concern or what aspects of the transformer model should be considered. Therefore, while the action is explicit, it lacks concrete details on how to implement it, making the comment 3.", "grounding_specificity_rationale": "The comment questions the choice of using a transformer model without locality bias, suggesting that neighborhood agents should naturally influence each other more than distant nodes. However, it does not specify which part of the paper this critique is based on, such as a particular section or experiment where this choice is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the transformer model\"s locality bias but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the authors\" choice of using a transformer model without locality bias, suggesting that neighborhood agents should naturally influence each other more than distant nodes due to the limited speed of information propagation. The reviewer expresses a concern about the lack of locality in the transformer model and requests an explanation. While the comment raises a valid point, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors would need to make a significant effort to understand and address the concern, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the authors\" choice of using a transformer model without locality bias, suggesting that neighborhood agents should naturally influence each other more than distant nodes due to the limited speed of information propagation. The reviewer explicitly asks the authors to explain why the lack of locality in the transformer model is not a concern. This feedback is 3 as it prompts the authors to provide a rationale for their choice, which could lead to a more robust justification in their paper. However, the comment could be more helpful if it offered specific suggestions or examples of how the authors might address this concern or what aspects of the model\"s locality should be considered. Overall, the comment provides a direction for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a perceived issue with the method ODA, noting that it has learned to imitate the problemsolving method but does not clearly explain how the presented method improves performance and computation speed compared to using ODA. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their explanation. The action is implicit and vague, as it lacks concrete steps for the authors to take to clarify the improvement of their method. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the method ODA, which is a specific method used in the paper. However, it does not explicitly mention which part of the paper discusses ODA, making it weakly grounded. The comment does specify the issue, which is that the method did not clearly suggest how it improved performance and computation speed compared to using ODA. This provides some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method ODA, which is used to solve the MOIP problem, has learned to imitate the problemsolving method but does not clearly explain how the presented method improves performance and computation speed compared to using ODA. However, the comment lacks specific examples, detailed reasoning, or references to support this claim. Without such evidence, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a perceived issue with the method ODA, noting that it has learned to imitate the problemsolving method but does not clearly explain how the presented method improves performance and computation speed compared to using ODA. This feedback highlights a gap in the explanation of the method\"s advantages, which could be crucial for understanding its contribution. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their explanation. While it points out an area for improvement, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap in the discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It explicitly instructs the authors to provide this analysis for a fair comparison with the baseline. While the comment clearly identifies an area that needs attention, it does not offer specific guidance on how to conduct this analysis or what aspects to focus on. The action is explicit but somewhat vague in terms of execution, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests providing this analysis for a fair comparison with the baseline. However, the comment does not specify which part of the paper should include this analysis, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the analysis of the impact of additional parameters and computational effort. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of discussion regarding the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. The reviewer suggests that this analysis should be provided for a fair comparison with the baseline. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim. The lack of explicit evidence or detailed explanation makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it highlights an area for improvement but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the lack of discussion on the impact of adding additional parameters and computational effort due to the multistage training and multiple discriminators. It suggests that the authors should provide this analysis for a fair comparison with the baseline. This feedback is clear and actionable, as it directs the authors to a specific area that needs further exploration and analysis. By addressing this point, the authors can strengthen their work and provide a more comprehensive evaluation of their approach. However, the comment could be more helpful if it offered specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern with the analysis of the correlation between dataset size and the Frobenius norm and singular values, noting that it is underwhelming and lacks theoretical evidence. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the analysis. The comment implies that the authors should provide more theoretical evidence or explore the correlation across different model architectures, but it does not offer concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the analysis of the correlation between dataset size and the Frobenius norm and singular values, indicating that the analysis is underwhelming. It suggests that the trend may not hold across different model architectures and that theoretical evidence is lacking. However, the comment does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the need for theoretical evidence and exploration across different model architectures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the analysis of the correlation between dataset size and the Frobenius norm and singular values is underwhelming, suggesting that the trend may not hold across different model architectures and that theoretical evidence is lacking. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or detailed explanation makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or evidence.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the analysis of the correlation between dataset size and the Frobenius norm and singular values. It points out that the analysis is underwhelming and questions whether the observed trend holds across different model architectures. Additionally, it notes the lack of theoretical evidence to support the correlation. While the comment highlights important weaknesses, it does not provide specific suggestions or guidance on how the authors might address these issues or improve their analysis. This limits the comment\"s helpfulness, as it offers insight but lacks actionable advice for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the definition of approximation error, which is described as the gap between objective values, is ambiguous without seeing the values in the table. The reviewer recommends providing a mathematical characterization to clarify this definition. While the comment implies that the authors should add a mathematical description, it does not explicitly instruct them to do so. However, the suggestion is concrete, as it specifies what kind of additional information should be included. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the definition of approximation error and its relation to the objective values, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it suggests providing a mathematical characterization to clarify the definition, which would help in understanding the concept better. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the definition of approximation error is ambiguous without seeing the values in the table and suggests providing a mathematical characterization. While the comment identifies a potential issue with the clarity of the definition, it lacks specific examples or references to support the claim. The suggestion to provide a mathematical characterization is logical, but without further elaboration or examples, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the definition of approximation error, noting that it is ambiguous without seeing the values in the table. It suggests providing a mathematical characterization to clarify the definition. This feedback is clear and actionable, as it points out a specific area where the paper could be improved by offering a more precise and understandable definition. However, the comment could be more helpful if it provided examples or further guidance on how to implement the mathematical characterization. Overall, the comment is 4 as it directs the authors to a specific area needing clarification and improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. It also points out that the model is simplistic, as only edges connected to the changing node are altered. However, the comment does not provide any explicit or implicit suggestions for how the authors might address these limitations or improve the model. There is no guidance on potential modifications, alternative approaches, or additional features that could be considered to enhance the model\"s dynamics or complexity. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses specific aspects of the proposed model, such as the reassignment probability and the simplicity of the evolution model. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the limitations of the model, such as the slow dynamics and the simplicity of the evolution model. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model produces only one node changing cluster per time step due to the reassignment probability being 1/n, which results in slow dynamics. It also states that the model is simplistic, as only edges connected to the changing node are altered. The comment provides a logical reasoning based on the reassignment probability and the nature of the model, making the claim 4. However, it lacks specific examples or references to support the claim fully, which would enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific limitation of the proposed model, noting that it produces only one node changing cluster per time step on average due to the reassignment probability being 1/n. This results in slow dynamics, which the reviewer considers a drawback. Additionally, the comment points out that the model is simplistic, as only edges connected to the changing node are altered. While the comment highlights these weaknesses, it does not provide suggestions or guidance on how the authors might address these issues or improve the model. The feedback is 3 as it points out areas for improvement, but it lacks actionable advice, leaving the authors with only a general understanding of the problem. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the technical contribution is limited and lacks significant technical contribution and extension based on a typical model for the crossdomain recommendation setting. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might enhance their technical contribution or what specific aspects need improvement. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, stating that it is limited and lacks significant technical contribution and extension based on a typical model for the crossdomain recommendation setting. However, it does not specify which part of the paper this assessment is based on, nor does it provide details on what aspects of the technical contribution are lacking. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the technical contribution is limited, stating that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a perceived limitation in the technical contribution of the paper, suggesting that there is no significant technical contribution or extension based on a typical model for the crossdomain recommendation setting. However, it lacks specificity and does not provide any actionable feedback or suggestions for improvement. Without detailed guidance or examples, the authors are left without a clear understanding of how to enhance their work. As a result, the comment is not particularly helpful in guiding the authors toward improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which aspects of the discussion are lacking or suggest how the authors should expand their discussion. The comment lacks explicit guidance or concrete details on what specific areas need to be addressed or how to improve the discussion. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment indicates that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not specify which part of the paper this issue pertains to, nor does it provide details on what aspects of the discussion are lacking or how they could be improved. Without specific references or guidance, the authors cannot effectively identify the areas needing improvement. As a result, the comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point claims that the authors have not provided a comprehensive discussion of previous work on the topic. However, it does not offer any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a lack of comprehensive discussion of previous work on the topic, which is a critical aspect of academic writing. However, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of previous work should be included. Without actionable feedback or detailed advice, the authors are left with only a general indication of a problem that needs attention. Therefore, the comment is 2, as it highlights an area for improvement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing, as automatic evaluation metrics can be misleading. While the comment implies that the authors should conduct a human evaluation, it does not explicitly instruct them to do so. Additionally, it lacks concrete guidance on how to implement this suggestion, such as specifying the criteria for human evaluation or the number of evaluators to involve. The action is implicit and somewhat vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests that a human evaluation for caption generation would be more convincing, as automatic evaluation metrics can be misleading. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or experiment where automatic metrics are used. The authors might infer that it relates to the evaluation or results section, but this inference is not direct. The comment is specific in suggesting the use of human evaluation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that a human evaluation for caption generation would be more convincing, as automatic evaluation metrics can be misleading. This claim is 3 because it provides a logical reasoning that automatic metrics may not accurately reflect the quality of caption generation. However, the comment lacks specific examples or references to support the claim, such as studies or examples where automatic metrics have been shown to be misleading. This makes it challenging for the authors to fully understand and address the suggestion, thus justifying a score of 3.", "helpfulness_rationale": "The review comment suggests that a human evaluation for caption generation would be more convincing, as automatic evaluation metrics can be misleading. This feedback is clear and actionable, as it provides a specific suggestion for improving the evaluation process. By recommending a human evaluation, the comment offers a concrete way for the authors to enhance the credibility and accuracy of their results. However, the comment could be more helpful if it included additional details, such as how to conduct the human evaluation or what criteria should be used. Despite this, the feedback is 4 as it directs the authors toward a meaningful enhancement of their evaluation methodology."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of motivation for the applications of the proposed algorithms and notes that the datasets used are static, which limits the paper\"s usefulness. While it identifies a gap in the motivation, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to provide more context and motivation for their work, but the comment does not offer concrete steps on how to achieve this. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses two main issues: the lack of motivation for the applications of the algorithms and the use of static datasets instead of streaming datasets. However, it does not specify which sections of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as providing motivation for the applications and using streaming datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for the applications of the algorithms and uses static datasets instead of streaming datasets. While it identifies a potential gap in the paper\"s motivation, it does not provide specific examples or references to support the claim that the applications are not wellmotivated. The comment suggests that the problem should be better motivated, but it lacks detailed reasoning or evidence to fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s motivation by pointing out that while the paper aims to design fast label aggregation algorithms for a streaming setting, it does not adequately motivate the applications where such algorithms are needed. Additionally, it notes that the datasets used in the empirical analysis are static, which limits the paper\"s usefulness. The comment suggests that the problem should be better motivated, providing a clear direction for improvement. However, it lacks specific suggestions or examples on how to enhance the motivation or address the issue of using static datasets. While the feedback is valuable in highlighting areas for improvement, it could be more helpful with additional guidance or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors analyze the domain gap between datasets and discusses the potential impact of this analysis on the method\"s effectiveness. It also implies that if the method can finetune a pretrained model on synthetic data, its value would be higher. While the comment provides a general direction for improvement, it lacks specific guidance on how to conduct the analysis or what aspects of the domain gap should be considered. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests analyzing the domain gap between datasets and discusses the potential impact of this analysis on the method\"s effectiveness. It also mentions the possibility of finetuning a pretrained model on synthetic data to enhance the method\"s value. However, the comment does not specify which part of the paper should include this analysis or where the discussion about the domain gap should be placed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing what needs to be addressed regarding the domain gap and the potential benefits of finetuning on synthetic data. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point suggests analyzing the domain gap between datasets and discusses the potential impact of this analysis on the method\"s effectiveness. It also mentions the possibility of finetuning a pretrained model on synthetic data to enhance the method\"s value. While the comment provides some reasoning about the importance of analyzing the domain gap, it lacks specific examples or references to support the claim. The suggestion to finetune on synthetic data is also not substantiated with evidence or examples. This makes the claim 3, as it provides a general direction but lacks detailed justification or evidence to fully support the argument.", "helpfulness_rationale": "The review comment suggests analyzing the domain gap between datasets, which is a relevant and important aspect for understanding the generalizability of the method. It provides a specific suggestion to discuss the gap between datasets and mentions that some datasets may be closer to each other, potentially reducing the need for adaptation. Additionally, the comment highlights the potential value of finetuning a pretrained model on synthetic data. While the comment identifies important areas for improvement, it lacks detailed guidance or specific examples on how to conduct the analysis or implement the suggested improvements. This limits its helpfulness, as the authors are given a direction but without comprehensive instructions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point identifies several specific areas where the paper lacks detail, making it difficult to reproduce the results. It explicitly asks for clarification on the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and how shape invariance is achieved. These questions provide clear and concrete actions for the authors to take, ensuring they know exactly what information is missing and how to address it. The explicit nature of the questions and the detailed guidance on what needs to be clarified make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of detail regarding the techniques used, making it difficult to reproduce the results. It provides specific examples of what is unclear, such as the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and how shape invariance is achieved. This level of detail allows the authors to identify the specific areas needing clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks detail regarding the techniques used, making it difficult to reproduce the results. It provides specific examples of areas where more information is needed, such as the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and how shape invariance is achieved. These examples offer a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or references to support these claims. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s lack of detail regarding the techniques used, which hinders the reproducibility of the results. It provides specific examples of areas where clarification is needed, such as the sparsification process, the generation of landmarks on the edge, the decision on the number of landmarks used, the type of image features, the fixed radius with different scales, and how shape invariance is achieved. By pinpointing these specific areas of confusion, the comment offers clear and actionable feedback that can guide the authors in improving the clarity and completeness of their draft. This level of detail and constructive guidance makes the comment 5, as it empowers the authors to significantly enhance their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the FIITED approach, specifically the reliance on utility scores for eviction decisions, which could introduce biases. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or mitigate the potential biases. The comment lacks actionable details, such as recommending alternative methods for determining chunk significance or suggesting ways to evaluate the impact of these biases. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the core of the FIITED approach, specifically the utilitybased approach to determine chunk significance. It highlights a potential issue with relying solely on utility scores for eviction decisions, which could introduce biases. However, the comment does not specify which part of the paper discusses the FIITED approach or where the utilitybased approach is detailed, making it weakly grounded. The comment is specific in identifying the potential bias introduced by the utilitybased approach, but without clear grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the FIITED approach, specifically the reliance on utility scores for determining chunk significance. The reviewer provides a logical reasoning by explaining how this approach could introduce biases, such as premature evictions of valuable chunks due to temporary high utility scores. However, the comment lacks specific examples or references to support the claim of potential biases, making it 3. The authors would need to further explore the reasoning themselves to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the FIITED approach, specifically the reliance on utility scores for determining chunk significance. It highlights a concern that this approach might introduce biases, such as premature evictions of valuable chunks due to temporary high utility scores. While the comment raises an important point about a potential flaw in the methodology, it lacks specific suggestions or guidance on how the authors might address or mitigate this issue. The feedback is 3 as it points out a critical area for consideration, but it could be more beneficial with additional details or recommendations for improvement. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the performance and contribution of different parts of the framework, both in terms of methodology and experimental results. It points out the absence of quantitative experiments, comparisons between algorithms, or detailed explanations of the framework\"s components. The reviewer explicitly suggests that the authors should provide these details to clarify the performance of the framework and its individual parts. While the comment clearly identifies the need for additional information, it does not specify exactly what kind of quantitative experiments or comparisons should be included. This makes the action somewhat clear but somewhat vague, as the authors know they need to add more information but may not be entirely sure of the exact details to include. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the methodology and experimental aspects of the paper, specifically pointing out the lack of clarity regarding the performance and contribution of different parts of the framework. It mentions the absence of quantitative experiments, comparisons between algorithms, or detailed explanations, which provides some level of specificity. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the results or discussion sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding the performance and contribution of different parts of the framework, both in terms of methodology and experimental results. The reviewer notes that while the results section shows promising visual stimuli, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations. This claim is 3 as it highlights specific areas where the paper is lacking, but it does not provide detailed examples or references to support the need for these additions. The authors would need to infer the specific aspects that require clarification, making the comment 3. Therefore, the score is 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the clarity of how different parts of the framework perform and contribute to the final results. It points out that while the results section shows promising visual stimuli, it lacks quantitative experiments, comparisons between algorithms, or detailed explanations of the framework\"s components. This feedback is clear and actionable, as it directs the authors to provide more comprehensive experimental analysis and detailed explanations to enhance the understanding of the framework\"s performance. However, the comment could be more helpful if it offered specific suggestions on how to conduct these analyses or comparisons. Overall, the comment is 4, as it effectively highlights areas for improvement and guides the authors toward a more thorough evaluation of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point notes that kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this observation is a concern that needs addressing or if it is merely a factual statement. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a specific observation about the implementation of kernels using OpenAI\"s Triton instead of CUDA. It suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, the comment does not explicitly mention which part of the paper this observation pertains to, such as a specific section or figure where the implementation details are discussed. The authors can infer that it relates to the methodology or implementation section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in detailing the observation about the implementation. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that kernels are implemented with OpenAI\"s Triton, not CUDA, and suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. However, the comment lacks specific references or detailed reasoning to support the claim about the engineering improvements. Without concrete examples or evidence, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some support but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment provides a factual observation about the implementation of kernels using OpenAI\"s Triton instead of CUDA. It suggests that a fullpage explanation is unnecessary due to wellknown engineering improvements. While this observation is accurate, the comment does not offer any actionable feedback or suggestions for improvement. It lacks depth and does not guide the authors on how to address this observation or whether it impacts the paper\"s content. As a result, the comment is not particularly helpful in assisting the authors to enhance their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of sufficient experimental demonstration of the contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The reviewer explicitly states that this comparison is necessary to prove the superiority of the schema searched by ELF (the author\"s method) over the schema in MVF. While the comment clearly identifies the need for additional comparisons, it does not provide specific guidance on how to conduct these comparisons or what specific aspects to focus on. The action is explicit but somewhat vague, as the authors know they need to include comparisons but may not be entirely sure of the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for a comparison with the image classification results of Mid Vision Feedback (MVF), allowing the authors to identify the specific part of the paper being addressed. It is also specific because it clearly specifies what is missing\u2014a comparison with the image classification results of MVF to demonstrate the superiority of the schema searched by ELF. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient experimental demonstration of its contribution points, specifically noting the absence of a comparison with the image classification results of Mid Vision Feedback (MVF). The reviewer provides a logical reasoning by pointing out the lack of comparison, which is necessary to substantiate the claim that the schema searched by ELF is better than that in MVF. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental demonstration of the paper\"s contribution points. It highlights the lack of a comparison with the image classification results of Mid Vision Feedback (MVF), which is crucial for validating the superiority of the schema searched by ELF (the author\"s method). This feedback is clear and actionable, as it directs the authors to include a specific comparison that would strengthen their experimental validation. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it effectively directs the authors toward a meaningful enhancement of their experimental section."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, especially regarding occupant comfort and energy efficiency. While the comment identifies a specific area that needs attention, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the activities should be highlighted. The action is implicit, as the authors need to infer that they should expand on this topic, and it is somewhat vague because it lacks concrete steps or suggestions on how to incorporate this information into the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific area that the authors have not adequately covered, namely the types of activities captured in the datasets and their importance in smart homes, particularly regarding occupant comfort and energy efficiency. However, it does not specify which part of the paper this issue pertains to, such as a particular section or dataset description. The authors can infer that it relates to the discussion or analysis of datasets, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in identifying the issue of insufficient coverage of activity types and their importance. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that the authors have not adequately covered the types of activities captured in the datasets and their importance in smart homes, particularly regarding occupant comfort and energy efficiency. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to specific datasets or studies, the authors may find it challenging to understand and address the issue. Therefore, the claim is 3, as it provides a general critique but lacks the necessary detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a specific area where the paper could be improved, namely the lack of coverage on the types of activities captured in the datasets and their importance in smart homes, particularly regarding occupant comfort and energy efficiency. This feedback is 3 as it points out a gap in the paper that the authors need to address. However, it lacks detailed guidance or suggestions on how to incorporate this information into the paper or what specific aspects of the activities should be highlighted. Providing more concrete examples or actionable steps would make the feedback more helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspects should be detailed. However, it does not provide specific guidance on what aspects of the innovation should be elaborated upon or how the authors should present this information. The action is implicit and vague, as the authors are left to infer that they need to provide more detail on the innovative aspects of their work. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed FRM, which is described as a simple combination of channel attention and spatial attention. However, it does not specify which part of the paper this assessment is based on, making it weakly grounded. The comment does specify that the innovative aspects should be detailed, providing some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed FRM is a simple combination of channel attention and spatial attention and suggests that the innovative aspects should be detailed. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why the FRM is considered simple or how the innovative aspects should be detailed. Without additional context or explanation, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the proposed FRM is described as a simple combination of channel attention and spatial attention. It suggests that the innovative aspects should be detailed, which is a relevant point for the authors to consider. However, the comment lacks specificity and does not provide detailed guidance on what aspects of the innovation should be elaborated upon or how the authors might enhance their explanation. While it points out an area for improvement, the feedback could be more actionable and comprehensive to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the applicability of the methods to realworld problems due to strong assumptions about camera parameters and object segmentation. However, it does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their methods. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to enhance the applicability. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the methods to realworld problems, specifically mentioning the strong assumptions made about camera parameters (extrinsics and intrinsics) and object segmentation. However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment is specific in identifying the limitations related to these assumptions, providing clear guidance on what aspect of the paper needs attention. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the applicability of the methods to realworld problems is limited due to strong assumptions about camera parameters and object segmentation. However, the comment does not provide specific examples or references to support these assumptions or explain why they are problematic. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient support to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the applicability of the methods to realworld problems, specifically due to strong assumptions about camera parameters and object segmentation. This is a relevant observation that could help the authors understand the scope and limitations of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address these limitations or improve the applicability of their methods. While it highlights an important area for consideration, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether running VGAE with a vamp prior could more accurately match the doubly stochastic construction in the work. This suggests a potential improvement in understanding the source of benefits, whether from a better generative model or better inference. However, the comment does not provide explicit instructions or concrete steps on how to implement this suggestion. Additionally, it mentions a minor point about Figure 3, suggesting that it might be beneficial to keep the generative model fixed and optimize only the inference part for comparison. While the suggestion is 3, it lacks detailed guidance on how to execute the proposed changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about running VGAE with a vamp prior to better match the doubly stochastic construction in the work, suggesting it could help determine if benefits are from a better generative model or inference. This part of the comment is fully grounded as it clearly identifies the context of the discussion, allowing the authors to pinpoint the relevant section. Additionally, it provides specific guidance on what could be done to address the issue, such as comparing representations by fixing the generative model and optimizing only the inference part. This makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the possibility of using a vamp prior with VGAE to better match the doubly stochastic construction in the work. It suggests that this could help determine if the benefits are from a better generative model or better inference. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it could be implemented. The minor point about Figure 3 is also not substantiated with any reasoning or evidence. As a result, the claims in the review point are not verifiable due to the lack of supporting information or justification. Therefore, the feedback is categorized as 1.", "helpfulness_rationale": "The review comment raises an interesting question about the possibility of using a vamp prior with VGAE to better match the doubly stochastic construction in the work. This could help determine whether the observed benefits are due to a better generative model or better inference. The comment provides a specific suggestion for further exploration, which could guide the authors in refining their analysis. However, the comment could be more helpful if it offered additional guidance or examples on how to implement this suggestion. Additionally, the minor point about Figure 3 is not addressed in the comment, which could have provided further insight into the analysis. Overall, the comment is 3 as it identifies a potential area for improvement and offers a specific suggestion, but it lacks depth and actionable guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that the poor performance could be due to oversmoothing, referencing a specific phenomenon observed in deep graph networks. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or incorporate the suggested phenomenon into their analysis or discussion. The feedback lacks actionable steps or concrete recommendations, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of poor longrange modelling ability in DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that the poor performance could be due to oversmoothing, referencing a specific phenomenon observed in deep graph networks. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. While it provides some specificity by mentioning the phenomena of oversquashing, vanishing/exploding gradients, and oversmoothing, it lacks detailed guidance on how these issues are addressed or resolved in the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the poor longrange modelling ability of DGNs is attributed to oversquashing and vanishing/exploding gradients, but it also suggests that the poor performance could be due to oversmoothing. The comment references a specific phenomenon observed in deep graph networks, providing a logical basis for the claim. However, it lacks detailed evidence or examples to fully substantiate the connection between oversmoothing and the observed performance issues. This makes the claim 3, as it provides a starting point for the authors to explore but requires further elaboration to be fully convincing.", "helpfulness_rationale": "The review comment identifies a potential issue with the longrange modelling ability of DGNs, attributing it to oversquashing and vanishing/exploding gradients. It also suggests that the poor performance could be due to oversmoothing, referencing a specific phenomenon observed in deep graph networks. This feedback is 3 as it points out a potential area of concern and provides a reference to a relevant phenomenon that could be considered in the analysis. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or incorporate the referenced phenomenon into their work. To be more helpful, the comment could offer specific steps or methodologies for investigating or mitigating the oversmoothing issue. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss their proposed method in relation to existing methods that use topological reasoning, generalized Voronov graphs, semantic maps, pose graphs in SLAM, and curiositydriven exploration. While the comment implies that the authors should include a discussion on these methods, it does not provide specific guidance on how to integrate this discussion into the paper or what aspects should be highlighted. The action is implicit and somewhat vague, as the authors need to infer the specific areas to address and the level of detail required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should discuss the proposed method in relation to existing methods that use topological reasoning, generalized Voronoi graphs, semantic maps, pose graphs in SLAM, and curiositydriven exploration. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion or comparison of methods sections. The comment is specific in detailing what aspects of the proposed method need to be addressed in relation to these existing methods. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point claims that some general ideas in the proposed method are already present in other methods, specifically mentioning topological reasoning, generalized Voronoi graphs, semantic maps, pose graphs in SLAM, and curiositydriven exploration. The reviewer supports this claim by providing specific examples of existing methods that capture these ideas, such as those using generalized Voronoi graphs or semantic maps, and referencing the graphbased SLAM appendix section. This detailed comparison provides a solid foundation for the claim, making it 4. However, the comment could be further strengthened by including specific references to these methods, which would enhance the verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential overlap between the proposed method and existing methods in the field, specifically mentioning topological reasoning, generalized Voronoi graphs, semantic maps, pose graphs in SLAM, and curiositydriven exploration. It suggests that the paper should discuss these methods in relation to the proposed approach. This feedback is clear and actionable, as it provides the authors with a specific area to address in their manuscript, prompting them to contextualize their work within the existing literature. However, the comment could be more helpful if it offered specific guidance on how to integrate this discussion or what aspects of these methods should be highlighted. Overall, the comment is 4, as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the importance of different parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion is necessary to clarify this aspect and distinguish the paper from related work. However, the comment does not provide explicit guidance on what specific aspects should be discussed or how the authors should address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to include a discussion but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the importance of different parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion is necessary to clarify this aspect and distinguish the paper from related work. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for a discussion on the importance of different parts of the framework, but without clear grounding, the authors may struggle to identify where to address this feedback. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of different parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion is necessary to clarify this aspect and distinguish the paper from related work. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that a discussion is needed. This lack of explicit evidence or justification makes the claim 3, as the authors would need to infer the necessity of the discussion without clear guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a pertinent question about the importance of different parts of the framework in using CLIP to guide weakly supervised learning. It suggests that a discussion is necessary to clarify this aspect and distinguish the paper from related work. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the framework should be discussed. The feedback is 3 as it points out a gap in the paper\"s discussion, but it could be more beneficial with additional details or actionable advice. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point critiques the depth of the analysis of vit quantification and provides specific examples to support its claims. It highlights that the paper\"s argument about information distortion due to direct quantization methods is not substantiated by the proposed approach. Additionally, it points out that the quantization of MHSA introduces a large loss of precision, which has been observed in other models like QBERT and Q8BERT. While the comment identifies areas for improvement, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to enhance the analysis. The feedback is 3 as it highlights areas needing more explanation but lacks detailed instructions on how to improve them.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines and figures (Line 45, Fig1(b), Fig5(b), and Block.3), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the analysis of vit quantification, including the argument about information distortion and the comparison of variance differences between the proposed approach and existing methods. Additionally, it references the quantization of MHSA and its impact on precision, providing a clear critique of the paper\"s claims. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point critiques the depth of the analysis of vit quantification, providing specific examples to support its claims. It references Line 45 and compares the variance differences between the proposed approach and existing methods, such as QBERT and Q8BERT, to substantiate the argument about information distortion. The mention of the quantization of MHSA and its impact on precision further strengthens the critique by referencing established findings in the NLP domain. This detailed comparison and reference to external work make the claim 5, as it provides a robust foundation for the critique. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment provides a detailed critique of the analysis of vit quantification, highlighting specific issues with the paper\"s claims. It points out that the paper\"s argument about information distortion due to direct quantization methods is not supported by the proposed approach, as evidenced by the variance differences in the figures. Additionally, it references the quantization of MHSA and its impact on precision, drawing parallels with findings in other models like QBERT and Q8BERT. This feedback is 4 as it identifies key areas where the paper\"s analysis is lacking and provides specific examples and references to support the critique. However, it could be more helpful if it offered suggestions on how to address these issues or improve the analysis. Overall, the comment provides valuable insights for the authors to enhance their draft, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the novelty of the idea is insufficient and that both the new metric and method are straightforward. However, it does not provide any specific guidance or suggestions on how the authors could enhance the novelty or improve the complexity of their approach. The feedback lacks actionable details, such as recommending ways to make the metric or method more innovative or suggesting alternative approaches. As a result, the authors are left without a clear understanding of what steps to take to address the concern about novelty. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the idea and the straightforwardness of the new metric and method. However, it does not specify which part of the paper discusses these aspects, making it difficult for the authors to pinpoint where improvements are needed. Additionally, the comment lacks specificity regarding what aspects of the metric and method are considered straightforward or how they could be improved. Without clear references or detailed feedback, the authors cannot effectively address the critique. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the idea is insufficient and that both the new metric and method are straightforward. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without concrete evidence or explanation, it is difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a concern about the novelty of the idea and suggests that both the new metric and method are straightforward. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance the novelty or complexity of their work. Without detailed guidance or examples, the authors are left without a clear path to address the issue. Therefore, the comment is not particularly helpful in improving the draft, aligning with a score of 1: The comment is 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is an explicit and concrete action for the authors to take. However, it does not provide detailed guidance on how to conduct this study or what specific aspects to focus on. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting an ablation study on the number of layers versus performance, which is a specific suggestion for improvement. However, it does not explicitly mention which part of the paper this suggestion pertains to, such as a specific section or experiment. The authors can infer that it relates to the experimental setup or results, but this inference is not direct. Therefore, the comment is weakly grounded because it does not specify the exact part of the paper being addressed, but it is specific in suggesting a potential improvement. This aligns with a score of 3.", "verifiability_rationale": "The review point suggests conducting an ablation study on the number of layers versus performance, which is a suggestion for improvement. However, it does not provide any supporting evidence, reasoning, or references to justify why this ablation study would be beneficial or necessary. The comment lacks detailed explanation or context, making it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The review comment suggests conducting an ablation study on the number of layers versus performance, which is a specific and actionable suggestion for improving the paper. This feedback provides the authors with a clear direction for enhancing their experimental design and analysis. However, the comment is 3 because it lacks detailed guidance on how to conduct the ablation study or what specific aspects to focus on. While it identifies a potential area for improvement, it does not fully support the authors in executing this suggestion. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the discussion of computational aspects, particularly regarding the applicability of the proposed methods to highdimensional data. It points out that the algorithm requires solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. The reviewer notes that the experiments are conducted on smallscale datasets, which may not reflect the practical utility of the methods in high dimensions. However, the comment does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the discussion. The feedback is implicit and lacks concrete steps for the authors to follow, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of detailed discussion on computational aspects, particularly regarding the applicability of the proposed methods to highdimensional data. It points out that the algorithm requires solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. The comment also notes that the experiments are conducted on smallscale datasets, which may not reflect the practical utility of the methods in high dimensions. However, the comment does not specify which sections or parts of the paper should include this discussion, making it weakly grounded. The comment is specific in identifying the issue with computational aspects and the limitations of the experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the computational aspects of the proposed methods, particularly in high dimensions. It highlights that the algorithm requires solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. The reviewer notes that the experiments are conducted on smallscale datasets, which may not reflect the practical utility of the methods in high dimensions. While the comment provides some logical reasoning and identifies a potential issue, it lacks specific examples or references to support the claim fully. This makes the comment 3, as it provides a basis for the claim but requires more detailed evidence or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a gap in the discussion of computational aspects, particularly regarding the applicability of the proposed methods to highdimensional data. It points out that the algorithm requires solving several linear programs (LPs) in high dimensions, with a parameter that is not easily calculable. The reviewer notes that the experiments are conducted on smallscale datasets, which may not reflect the practical utility of the methods in high dimensions. This feedback is 3 as it highlights an important area for improvement and provides a specific observation about the limitations of the experiments. However, it lacks detailed suggestions or guidance on how the authors might address these issues or improve the discussion of computational aspects. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions about the online learning formulation and its comparison with other approaches, such as RL. It asks for clarification on why online learning is overlooked, the challenges of including it in the evaluation, and how retraining costs are considered. While the comment implies that the authors should provide a more detailed comparison and justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as it lacks concrete guidance on how to address the questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract and other parts of the paper where the authors discuss the online learning formulation. This allows the authors to accurately identify the sections being addressed. The comment is also specific because it raises several questions about the comparison with online learning approaches and RL, as well as the challenges of including online learning in the evaluation. It seeks clarification on why online learning is overlooked and how retraining costs are considered. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the online learning formulation and its comparison with other approaches, such as RL. It questions the rationale behind overlooking key practical considerations and asks for a comparison against online learning approaches and RL. The comment seeks clarification on why online learning is discarded and what challenges exist in including it in the evaluation. While the comment highlights potential issues and questions, it lacks specific examples or references to support the claims. This makes the claim 3, as the authors would need to further explore and address the questions raised by the reviewer to fully understand and address the concerns. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s approach to online learning formulation, specifically noting that it overlooks key practical considerations. It highlights the absence of a proper comparison against online learning approaches and RL, which is essential for understanding why online learning is not considered. The comment raises several questions about the challenges and considerations involved in including online learning in the evaluation, such as retraining costs and incremental updates. This feedback is clear and actionable, as it prompts the authors to provide a more comprehensive comparison and justification for their approach. However, it could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to conduct the comparison. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to clarify in the main text that there are additional experiments in the supplement and to summarize their results. This is a clear and direct action that the authors can take to improve their draft. However, the comment does not specify which additional experiments are being referred to or how the results should be summarized, leaving some details to be inferred. Despite this, the action is explicit and concrete, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the main text should clarify the presence of additional experiments in the supplement and summarize their results. However, it does not specify which part of the main text should address this, making it weakly grounded. The comment is specific in its request for clarity and summarization, but without explicit references to sections or experiments, the authors may struggle to identify the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the main text should clarify the presence of additional experiments in the supplement and summarize their results. However, it does not provide any specific examples, reasoning, or evidence to support why this clarification is necessary or how it would improve the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the importance of this suggestion and how to address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the main text should clarify the presence of additional experiments in the supplement and summarize their results. This feedback is actionable, as it provides a clear direction for the authors to enhance the clarity and comprehensiveness of their manuscript. However, the comment could be more helpful if it included specific examples or guidance on how to effectively summarize the results of the additional experiments. Despite this, the feedback is 4 as it directs the authors\" attention to an important aspect of their draft that needs clarification and summarization."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies missing references, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encodedecoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works. This feedback provides a clear and concrete action for the authors to take, namely, to add these references and conduct a comparison. The explicit nature of the suggestion and the detailed guidance on what needs to be done make this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the missing references, GFF[1] and EfficientFCN[2], allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending a comprehensive comparison with these works, providing clear guidance on what needs to be addressed. Additionally, the comment mentions the societal impact being shown on the last page of the manuscript, which further grounds the feedback. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important references are missing, specifically mentioning GFF[1] and EfficientFCN[2], which both aim to implement a fast semantic segmentation method in an encodedecoder architecture. The reviewer encourages a comprehensive comparison with these works. The comment provides specific references and suggests a comparison, which supports the claim by offering concrete examples. However, it could be further strengthened by explaining why these references are relevant or how they relate to the paper\"s content. As it stands, the claim is 4 due to the explicit references provided, but it lacks detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper by pointing out the absence of important references, specifically mentioning GFF and EfficientFCN, which both aim to implement a fast semantic segmentation method in an encodedecoder architecture. The reviewer encourages the authors to include a comprehensive comparison with these works, which is a clear and actionable suggestion. Additionally, the comment highlights the societal impact of the work, which is mentioned on the last page of the manuscript. This feedback is 4 as it provides specific guidance on how to enhance the paper\"s literature review and comparison, but it could be more helpful if it offered additional insights or suggestions on how to integrate these references into the manuscript. Overall, the comment is rated as 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be learned and applied to largescale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper\"s practical contribution. While the comment highlights a potential issue, it does not provide explicit guidance or suggestions on how to address the scalability challenge. The authors are left to infer that they need to consider scalability improvements, but without concrete steps or examples, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. It questions how this method can be applied to largescale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper\"s practical contribution. However, the comment does not explicitly mention a specific section of the paper, leaving the authors to infer that it relates to the methodology or results sections. This makes the comment weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in detailing the scalability issue and its potential impact on the paper\"s contribution. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed NC measure, which takes the whole training and test datasets as input. The reviewer questions how this method can be applied to largescale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper\"s practical contribution. While the comment highlights a potential limitation, it lacks specific examples, references, or detailed reasoning to fully substantiate the claim. The authors may find it challenging to understand and address the scalability issue without further elaboration. Therefore, the comment is 3, as it provides a logical basis for the concern but requires additional detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the scalability of the proposed NC measure, which takes the entire training and test datasets as input. It questions how this method can be applied to largescale datasets like ImageNet and suggests that addressing the scalability issue is crucial for the paper\"s practical contribution. While the comment highlights an important limitation, it does not provide specific suggestions or solutions for addressing the scalability challenge. This limits the comment\"s helpfulness, as the authors are left with a clear issue to address but without detailed guidance on how to resolve it. Therefore, the comment is 3, as it points out a critical area for improvement but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding the paper\"s motivation and application, specifically questioning the relevance of the proposed method in domain adaptation. The reviewer suggests that the paper would benefit from demonstrating the methodology\"s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment implies that the authors should provide such demonstrations, it does not explicitly instruct them to do so. The action is concrete but communicated indirectly, making this comment 4.", "grounding_specificity_rationale": "The comment addresses the lack of clarity regarding the paper\"s motivation and application, specifically questioning the relevance of the proposed method in domain adaptation. It suggests that the paper should demonstrate the methodology\"s use on actual tasks involving domain adaptation, such as adapting a model trained on a synthetic dataset to a real dataset. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the introduction or motivation sections. The comment is specific in detailing what needs to be addressed, namely the lack of clarity and the need for demonstration on actual tasks. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point questions the motivation and application of the paper\"s proposed method, specifically regarding its relevance to domain adaptation. The reviewer highlights the lack of clarity in the paper\"s application and suggests that demonstrating the methodology on actual tasks involving domain adaptation would be beneficial. While the comment raises a valid concern, it does not provide specific examples or references to support the claim that the application is unclear. The suggestion for demonstration on actual tasks is a logical recommendation but lacks detailed justification or evidence. Therefore, the comment is 3, as it provides a reasonable critique but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s motivation and application, specifically questioning the relevance of the proposed method in domain adaptation. It highlights the lack of clarity regarding the practical use of the method and suggests that demonstrating its application on actual tasks involving domain adaptation would be beneficial. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance the paper by including demonstrations on realworld tasks. However, the comment could be more helpful if it offered suggestions on how to effectively demonstrate the method\"s utility or provided examples of relevant tasks. Overall, the comment is 4, as it effectively guides the authors toward improving the practical relevance of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the comparison with some baselines is unfair because these baselines lack prior knowledge of users or language embedding computation. It implies that a better comparison should be considered, but it does not provide specific guidance on how to achieve this. The action is implicit and vague, as the authors are left to infer that they need to adjust their comparison methodology but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the comparison with some baselines, suggesting that it is unfair due to the lack of prior knowledge of users or language embedding computation. However, it does not specify which baselines are being referred to or where in the paper this comparison is made, making it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the authors might have an idea of where the baselines are discussed, the comment lacks full grounding. It is specific about the issue of unfair comparison but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison with some baselines is unfair due to the lack of prior knowledge of users or language embedding computation. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to substantiate the assertion, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison with some baselines, specifically noting that these baselines lack prior knowledge of users or language embedding computation. This feedback is 3 as it highlights a critical aspect of the experimental setup that could affect the validity of the results. However, the comment does not provide specific suggestions or guidance on how to address this issue, such as recommending alternative baselines or methods to ensure a fair comparison. Without actionable advice, the authors are left with a general idea of the problem but no clear path to resolve it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should include and compare their work to specific related studies, such as the one by Li et al. (2017) on endtoend taskcompletion neural dialogue systems and the one by He et al. (2015) on deep reinforcement learning with a natural language action space. The comment provides explicit actions for the authors to take, namely, to include these works in their discussion and compare them conceptually. Additionally, it suggests a broader discussion on how the current work differs from other chatbox research works. The feedback is clear and provides concrete guidance on how to enhance the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests including and comparing the current work to specific related studies, such as the one by Li et al. (2017) and the one by He et al. (2015). It also recommends a broader discussion on how the work differs from other chatbox research works. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the overall discussion or comparison sections. The suggestion is specific, as it outlines particular works to consider and areas for discussion. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point suggests that the work should include and compare to specific related studies, such as the one by Li et al. (2017) and the one by He et al. (2015). The comment provides specific references to these works, which serve as a basis for the claim that these studies are important to include and compare to. This explicit reference to external works supports the claim, making it 5. The detailed references provide a clear rationale for the suggestion, ensuring that the authors understand the basis of the recommendation.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include and compare their work to relevant studies, such as the endtoend taskcompletion neural dialogue systems by Li et al. (2017) and the deep reinforcement learning with a natural language action space by He et al. (2015). It also recommends a broader discussion on how the current work differs from other chatbox research works. This guidance is clear and constructive, offering the authors a concrete way to enhance the context and relevance of their work by situating it within the existing literature. The comment is 5 as it provides detailed suggestions for improvement, empowering the authors to significantly enhance their draft."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the experimental strengths of the proposed approach, suggesting that running the proposed algorithm for 40 different networks from the training phase is not necessary. It proposes an alternative approach: running vanilla Adam on the final network with 40 random initial points, where one of these restarts would reach the global minimum. While the comment provides a clear alternative approach, it does not explicitly instruct the authors to implement this change. The action is implicit but concrete, as the authors can infer that they should consider the suggested alternative. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment questions the experimental strengths of the proposed approach, specifically mentioning the need to run a descent procedure for 40 different networks from the training phase. It contrasts this with a simpler approach of running vanilla Adam on the final network with 40 random initial points. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental setup or results section. The comment is specific in its critique of the experimental approach and provides a clear alternative suggestion. Therefore, the comment is weakly grounded but specific, aligning with the label 3.", "verifiability_rationale": "The review point questions the experimental strengths of the proposed approach by suggesting an alternative method: running vanilla Adam on the final network with 40 random initial points, where one of these restarts would reach the global minimum. The reviewer provides a logical reasoning by comparing the proposed method with a simpler alternative, highlighting the potential inefficiency of the proposed approach. However, the comment lacks specific references or detailed evidence to fully substantiate the claim. While the reasoning is sound, the absence of concrete examples or external references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment questions the experimental strengths of the proposed approach, suggesting that running the algorithm for 40 different networks from the training phase is not necessary. It proposes an alternative approach: running vanilla Adam on the final network with 40 random initial points, where one of these restarts would reach the global minimum. This feedback is 3 as it challenges the authors to reconsider their experimental setup and provides a potential alternative approach. However, it lacks detailed guidance or specific suggestions on how to implement this alternative or why the proposed method might be insufficient. The comment could be more helpful if it offered a deeper analysis or comparison with the proposed method. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide specific guidance on how the authors should explore the dataset further or what aspects should be emphasized. The action is implicit, as the authors need to infer that they should expand their discussion on the dataset, and it is vague because it lacks concrete details on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments where DRRI could be integrated or discussed. The authors might infer that it relates to the dataset section or the results section, but this inference is not direct. Additionally, the comment lacks specificity regarding what aspects of DRRI should be explored or how it could be integrated into the paper. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it does not provide any specific reasoning or evidence to support why this exploration is necessary or how it would benefit the paper. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the suggestion. As a result, the claim is 1.", "helpfulness_rationale": "The comment suggests that the new proposed dataset, DRRI, could have been explored more in the paper. However, it lacks specificity and does not provide any guidance on how the authors might explore the dataset further or what aspects should be emphasized. Without detailed suggestions or examples, the authors are left without clear direction on how to improve their draft. This lack of actionable feedback makes the comment 2, as it points out a potential area for improvement but does not offer sufficient guidance for the authors to act upon."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment notes that the observed performance enhancements are modest and suggests that there is room for further refinement in the future. However, it does not provide specific guidance or suggestions on how the authors might achieve these enhancements or what aspects of the work could be improved. The feedback lacks explicit instructions or concrete details, leaving the authors uncertain about how to address the comment. Since the action is implicit and vague, this comment is barely actionable.", "grounding_specificity_rationale": "The comment provides a general observation about the observed performance enhancements being modest and suggests that there is room for further refinement. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the performance enhancements are considered modest or how they could be improved. Without specific references or detailed feedback, the authors cannot effectively identify the areas needing attention or improvement. As a result, the comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point claims that the observed performance enhancements are modest and suggests that there is room for further refinement. However, it does not provide any specific examples, data, or reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the observed performance enhancements as modest and suggests that there is room for further refinement in the future. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their work. Without detailed guidance or examples, the authors are left without a clear path to enhance their draft. Therefore, the comment is not particularly helpful, aligning with a score of 1: The comment is 1."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises concerns about the experimental results on the last two datasets, noting that the performance is similar to IRM and questioning whether this is due to problems mentioned above. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve the validation of their method. The comment lacks actionable details, such as recommending specific analyses, additional experiments, or modifications to the current approach. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper discusses the experimental results on the last two datasets. It mentions the similarity in performance to IRM but does not provide enough context for the authors to pinpoint the exact section being referred to. The comment is specific in that it questions the validity of the experimental results and suggests that the performance is similar to IRM, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM. However, the comment lacks specific details or references to support the claim that the results are not convincing enough. It does not provide a clear explanation of why the performance is similar to IRM or what specific problems might be causing this issue. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment raises a concern about the experimental results on the last two datasets, noting that the performance is similar to IRM and questioning the validity of the proposed method. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the validation of their method. Without detailed feedback or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not offer sufficient direction for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is a lack of empirical validation and suggests that the authors should include experiments to validate the bounds. This feedback provides a clear and direct action for the authors to take, specifying that they need to conduct experiments to validate their theoretical bounds. The comment is specific and leaves no ambiguity about what the authors need to do to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the lack of empirical validation and suggests that the authors should include experiments to validate the bounds. However, it does not specify which part of the paper lacks empirical validation or where the experiments should be conducted. This makes it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where empirical validation is typically discussed, the comment lacks full grounding. It is specific about the need for empirical validation but does not provide detailed guidance on how to achieve it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of empirical validation, specifically suggesting that the authors should include experiments to validate the bounds. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper, specifically the lack of empirical validation for the theoretical bounds discussed. It suggests that the authors should include experiments to validate these bounds, which is a clear and actionable piece of feedback. By recommending empirical validation, the comment provides the authors with a concrete direction for improving their draft, enhancing the practical applicability and credibility of their work. However, the comment could be more helpful if it offered specific suggestions on how to design these experiments or what aspects to focus on. Overall, the feedback is 4 as it highlights a critical area for improvement and provides a clear path for the authors to follow, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should focus on problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This feedback provides a clear and explicit action for the authors to take, specifying the type of problems they should consider and why. The suggestion is concrete, as it offers a specific direction for improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed feedback on the goal of the paper, the examples chosen, and suggests an alternative focus on problems where the loss function does not decompose as the sum of sample losses. The comment offers a clear suggestion for improvement by recommending the authors focus on specific types of problems. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the paper\"s goal in the introduction, suggesting that the examples provided do not effectively demonstrate the need for significant interprocess communication. The reviewer offers a specific example, mentioning that samplingbased Bayesian methods are already embarrassingly parallel, which contradicts the paper\"s claims. The suggestion to focus on problems where the loss function does not decompose as the sum of sample losses is a logical and verifiable point, providing a clear rationale for the critique. However, the comment could be strengthened by providing more detailed examples or references to support the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper\"s goal, as expressed in the introduction. It questions the examples provided and suggests that they do not effectively demonstrate the need for significant interprocess communication. The reviewer offers a specific critique and provides an alternative focus for the paper, recommending the authors consider problems where the loss function does not decompose as the sum of sample losses and other ERMbased distributed algorithms like Hogwild. This feedback is clear and actionable, offering the authors a concrete direction for improving the focus and relevance of their work. However, the comment could be more helpful if it included additional examples or detailed guidance on how to implement the suggested focus. Overall, the comment is 4 as it provides valuable insights and suggestions for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null}
