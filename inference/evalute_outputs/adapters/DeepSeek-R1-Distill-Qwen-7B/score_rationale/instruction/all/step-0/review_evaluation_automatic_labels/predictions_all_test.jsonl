{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would benefit from a revision, particularly in terms of clarifying the precise steps of the methodology. However, it does not explicitly instruct the authors to provide detailed explanations or examples of these steps. The action is implicit, as the authors can infer that they need to clarify the methodology, but it lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a revision, particularly in terms of clarifying the precise steps of the methodology. However, it does not specify which part of the paper this revision should address, such as the methodology section or specific results. The authors might infer that it relates to the methodology, but the comment lacks full grounding. It is specific in suggesting that the paper would benefit from a revision, but it does not provide detailed guidance on what aspects need clarification. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper would benefit from a revision due to the lack of clarity in the precise steps of the methodology. However, the comment does not provide specific examples or detailed reasoning to support this claim. It lacks sufficient evidence or references to justify the assertion that the methodology is unclear or difficult to train. As a result, the claim is considered 2, as it provides some indication of a problem but lacks the depth and specificity needed for full verification.", "helpfulness_rationale": "The review comment acknowledges the difficulty of training and getting a minmax optimization, especially for PDEs with advective terms, and notes that while the methodology seems to perform better than the baselines, the lack of clarity in the precise steps suggests that the paper could benefit from a revision. However, the comment does not provide specific suggestions or guidance on how to improve the clarity or address the challenges mentioned. While it identifies an area for improvement, the feedback is 3 as it highlights a potential weakness but lacks actionable advice for the authors to follow. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the practical use of a modified TD learning algorithm compared to the original proposal. It does not explicitly instruct the authors to make a change or provide a specific action to take, but it does imply that the authors should consider the practical implications of using the modified algorithm versus the original one. The action is implicit and somewhat vague, as the authors need to infer that they should evaluate the practicality of the modified algorithm. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 5.1\" and \"Algorithm 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the practical use of a modified TD learning algorithm compared to the original proposal, prompting the authors to consider the implications of their theoretical analysis in practice. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the practical use of a modified TD learning algorithm compared to the original proposal. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the practical use of a modified TD learning algorithm compared to the original proposal. It prompts the authors to consider the implications of their theoretical analysis in practice, which is a valuable point for improving the paper. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the practical use should be emphasized. While it identifies an important area for consideration, it does not provide actionable feedback that would help the authors make significant improvements to their draft. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the practical utility of the diversity coefficient as a data quality metric, noting that the paper does not empirically validate this claim. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to include empirical validation of the diversity coefficient, but the comment does not specify how to conduct this validation or what specific data or experiments should be used. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the practical utility of the diversity coefficient as a data quality metric, which is a specific concern. However, it does not explicitly mention which part of the paper discusses this metric, making it weakly grounded. The comment is specific in identifying the need for empirical validation of the diversity coefficient, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not empirically validate the practical utility of the diversity coefficient as a data quality metric. This claim is 3 as it highlights a gap in the paper\"s empirical validation, but it lacks specific examples or references to support the assertion. The comment suggests that the authors should provide empirical evidence to substantiate the claim, but it does not offer detailed guidance on how to do so. Therefore, the comment is rated as 3, as it provides a general direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the practical utility of the diversity coefficient as a data quality metric. It points out that the paper does not empirically validate this claim, which is crucial given the emphasis on Task2Vec and model diversity in the paper. This feedback is clear and actionable, as it directs the authors to include empirical validation to strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to conduct this validation or examples of how to measure the diversity coefficient. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that using canary clients is less efficient than using canary examples, implying that more resources might be needed. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve efficiency. The comment lacks concrete suggestions or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that using canary clients is less efficient than using canary examples, implying that more resources might be needed. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what specific inefficiencies or resource allocations are being referred to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that using canary clients is less efficient than using canary examples, suggesting that more resources might be needed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that using canary clients is less efficient than using canary examples, implying that more resources might be needed. While it identifies a potential inefficiency, it lacks specific details or suggestions on how the authors might address this issue or improve the efficiency of their approach. The comment provides a general observation but does not offer actionable guidance or detailed feedback, making it 3. The authors may gain some insight into the need for resource optimization but would require further clarification or suggestions to fully benefit from the feedback. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer implies that the authors should clarify why \"Carefl\" is relevant to their work. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue, such as suggesting a specific explanation or additional context. The action is implicit and vague, as the authors are left to infer that they need to clarify the relevance of \"Carefl\" in their paper. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM. It points to Equation (6) in the method description and mentions Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models\" as a reference. This provides some grounding by indicating where \"Carefl\" is mentioned, but the authors might still need to infer that it is relevant to the paper. The comment is specific in suggesting that \"Carefl\" might be a standard definition, but it does not provide detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer provides a reference to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models\" to support the claim that \"Carefl\" is a standard definition. This reference provides some justification for the claim, but it lacks detailed explanation or examples of how \"Carefl\" is used in the context of the paper. The comment is 4, as it offers a logical basis for the claim but could be strengthened with more specific examples or references to the paper\"s context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a question about the relevance of \"Carefl\" to the paper, suggesting that it might be a standard definition of a nonlinear SEM. The reviewer provides a reference to Equation (4) in \"On Causal Discovery with Cyclic Additive Noise Models\" to support the claim that \"Carefl\" is a standard definition. This feedback is 3 as it prompts the authors to clarify the relevance of \"Carefl\" in their work, which could help them better understand the context and significance of the term. However, the comment lacks depth and does not provide specific guidance on how the authors might address this issue or improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the computational intensity of the proposed approach, specifically the need for pretraining the GAA model on the same dataset as the QA model. It questions the assumption that the GAA model will be performant enough to provide meaningful prompts to annotators, which could lead to increased annotation times and undermine the speedup claim. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the approach. The action is implicit and vague, as it lacks concrete steps or recommendations for the authors to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the computational intensity of the proposed approach, specifically mentioning the need for pretraining the GAA model on the same dataset as the QA model. It raises concerns about the assumption that the GAA model will be performant enough to provide meaningful prompts to annotators, which could affect the speedup claim. However, the comment does not specify which part of the paper discusses the computational intensity or the speedup claim, making it weakly grounded. The comment is specific in detailing the concerns about the assumption and its potential impact on annotation times. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach is computationally intensive due to the need for pretraining the GAA model on the same dataset as the QA model. It questions the assumption that the GAA model will be performant enough to provide meaningful prompts to annotators, which could lead to increased annotation times and undermine the speedup claim. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the assumption might not hold true. The lack of concrete evidence or examples makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed approach, specifically its computational intensity due to the need for pretraining the GAA model on the same dataset as the QA model. It raises a concern about the assumption that the GAA model will be performant enough to provide meaningful prompts to annotators, which could lead to increased annotation times and question the speedup claim. While the comment highlights a critical weakness, it lacks specific suggestions or guidance on how the authors might address this issue or improve the approach. The feedback is 3 as it prompts the authors to reconsider their assumptions and potentially explore alternative methods to mitigate the computational burden. However, it could be more actionable with additional details or suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and generality. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on how the authors might address this limitation or suggest improvements to enhance the method\"s generality. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a limitation of the proposed method, specifically its high dependence on the server dataset, which limits its potential use cases and generality. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might infer that this relates to the methodology or results sections, the lack of explicit grounding makes it challenging to address the feedback effectively. The comment is specific in identifying the issue but lacks grounding, resulting in a score of 2.", "verifiability_rationale": "The review point claims that the proposed method has a high dependence on the server dataset, which limits its potential use cases and generality. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a significant limitation of the proposed method, specifically its high dependence on the server dataset, which restricts its potential use cases and generality. This feedback is valuable as it highlights a critical weakness in the method\"s applicability, prompting the authors to reconsider the scope and robustness of their approach. However, the comment could be more helpful if it provided suggestions on how to mitigate this dependence or explored alternative strategies to broaden the method\"s applicability. While it points out an important issue, the lack of actionable guidance limits its helpfulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include more downstream search methods, such as BO and LS, in addition to the single method (EA) currently provided. This feedback is clear and direct, giving the authors a specific action to take\u2014adding additional search methods to enhance the paper\"s comprehensiveness. The comment is explicit and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment suggests adding more downstream search methods, such as BO and LS, to the paper. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or analysis where these methods should be included. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact location in the paper that needs revision. While the suggestion is specific in terms of what should be added, the absence of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper only provides a single downstream search method (EA) and recommends adding BO and LS. However, the comment does not provide any reasoning or evidence to support why these additional methods are necessary or how they would improve the paper. Without specific justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper only provides a single downstream search method (EA) and recommends adding additional methods like BO and LS. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the comprehensiveness of the paper. By recommending the inclusion of more search methods, the comment guides the authors on how to expand the scope of their work and potentially improve its relevance and impact. However, the comment could be more helpful if it provided additional context or explanation on why these specific methods are important or how they would benefit the paper. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper does not sufficiently highlight the importance of FLOPs and FPS in sparse network research, specifically mentioning the absence of a direct comparison with other sparse models. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue. The authors are left to infer that they need to include a comparison with other sparse models, but the comment does not specify which models to include or how to present the comparison. The action is implicit and somewhat vague, as the authors know they need to make a comparison but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a direct comparison with other sparse models regarding FLOPs and FPS. The comment provides a clear direction for improvement by suggesting that the authors should include a comparison with other sparse models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not sufficiently highlight the importance of FLOPs and FPS in sparse network research, specifically mentioning the absence of a direct comparison with other sparse models. The comment is 3 as it identifies a gap in the paper but lacks specific examples or references to support the claim. The authors would need to infer the importance of FLOPs and FPS and understand the need for a comparison with other sparse models. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of a direct comparison with other sparse models regarding FLOPs and FPS. It highlights that while FLOPs for pDETR are listed in Table 7, a comparison with other sparse models is missing. This feedback is clear and actionable, as it directs the authors to include a comparison with other sparse models to strengthen their analysis. However, the comment could be more helpful if it provided specific examples of other sparse models or suggested how to present the comparison effectively. Overall, the comment is 4 as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a significant issue with the metrics described in Appendix A.1, noting that they are hard to understand and lack clarity in the result tables. The reviewer provides a specific example of how the accuracy for binary boolean questions in Table 5 could be misleading if simply reversing the prediction of DollyV27B yields an accuracy of 97%, which is incorrect. This feedback is explicit and provides a concrete action for the authors to take, which is to clarify the metrics and ensure that the numbers in the result tables are accurately interpreted. The comment is clear and actionable, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix A.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the metrics, explaining that they are hard to understand and lack clarity in the result tables. The comment provides a concrete example of how the metrics could be misleading, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the metrics described in Appendix A.1 are hard to understand and lack clarity in the result tables. The reviewer provides a specific example to illustrate this issue, mentioning that reversing the prediction of DollyV27B could yield an accuracy of 97%, which is misleading. This example provides a clear and logical reasoning for the claim, making it 4. However, the comment could be strengthened by referencing specific metrics or providing more detailed examples. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity and understandability of the metrics described in Appendix A.1. It highlights that the result tables are not clear, making it difficult for readers to interpret the numbers. The comment provides a concrete example of how the accuracy for binary boolean questions could be misleading, which is a valuable insight for the authors to consider. By addressing this issue, the authors can improve the clarity and accuracy of their results, making the paper more accessible to readers. The feedback is clear, actionable, and provides a specific example to guide the authors in making improvements, making it 5 for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the Gaussian assumption and its implications for the analysis. It asks whether the assumption is typical in practice, whether it is always possible to compute the effective variance for nonGaussian outputs, and if there is a finiteN expansion that characterizes the departure from Gaussianity in nonideal cases. While the comment poses these questions, it does not provide explicit instructions or suggestions for the authors to address them. The actions are implicit and somewhat vague, as the authors need to infer that they should explore these aspects further. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the Gaussian assumption and its implications for the analysis, specifically questioning whether it is typical in practice and whether it is always possible to compute the effective variance for nonGaussian outputs. It also inquires about a finiteN expansion that characterizes the departure from Gaussianity in nonideal cases. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or experiments where the Gaussian assumption is discussed. This makes it weakly grounded, as the authors cannot confidently determine which parts of the paper need attention. The questions are specific, as they address the validity and applicability of the Gaussian assumption. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the Gaussian assumption and its implications for the analysis. It asks whether the assumption is typical in practice, whether it is always possible to compute the effective variance for nonGaussian outputs, and if there is a finiteN expansion that characterizes the departure from Gaussianity in nonideal cases. These questions are based on logical reasoning and common knowledge, as they explore the validity and applicability of the Gaussian assumption in different scenarios. However, the comment lacks specific references or detailed reasoning to fully substantiate the claims, making it 3. The authors would need to further develop their understanding of these issues to address the questions effectively.", "helpfulness_rationale": "The review comment raises several important questions about the Gaussian assumption and its implications for the analysis. It asks whether the assumption is typical in practice, whether it is always possible to compute the effective variance for nonGaussian outputs, and if there is a finiteN expansion that characterizes the departure from Gaussianity in nonideal cases. These questions prompt the authors to consider the limitations and applicability of their assumptions, which is crucial for improving the robustness and generalizability of their work. However, the comment does not provide specific suggestions or guidance on how to address these questions or incorporate them into the draft. While it identifies areas for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the approach to the math and science categories, suggesting that the open vocabulary problem is not clearly addressed. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the draft. The comment implies that the authors should clarify or resolve the open vocabulary problem, but it lacks concrete details or suggestions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the approach to the math and science categories, suggesting that the open vocabulary problem is not clearly tackled. However, it does not specify which part of the paper discusses this approach, making it weakly grounded. The comment is specific in identifying the issue with the open vocabulary problem and suggests that other categories are addressed using Wikipedia and a popularity metric. This provides some guidance on what needs to be addressed, but without explicit references to sections or figures, the authors may still struggle to pinpoint the exact areas needing improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the approach to the math and science categories suggests an open vocabulary problem that is not clearly tackled, while other categories are addressed using Wikipedia and a popularity metric. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach to the math and science categories, specifically the open vocabulary problem that is not clearly addressed. It contrasts this with the approach used for other categories, which involves Wikipedia and a popularity metric. While the comment highlights a specific area of concern, it lacks detailed guidance or suggestions on how the authors might address this issue or improve their approach. The feedback is 3 as it points out a potential weakness, but it does not provide actionable steps for the authors to take, making it 3 but incomplete."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should provide a more thorough discussion of the similarity between their work and stochastic routing. However, it does not specify what aspects of this comparison should be elaborated upon or how the authors should approach this discussion. The action is implicit and vague, as the authors are left to infer that they need to expand on this point without clear guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a more thorough discussion of the similarity between their work and stochastic routing. However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the similarity should be discussed. This makes it difficult for the authors to pinpoint the exact section or elements that need attention. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the similarity between the work and stochastic routing warrants a more thorough discussion. However, it does not provide specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a more thorough discussion of the similarity between their work and stochastic routing. However, it lacks specificity and does not offer detailed guidance on how to address this point or what aspects of the comparison should be elaborated upon. Without concrete suggestions or examples, the authors may find it challenging to understand the importance of this comparison and how to improve their draft accordingly. Therefore, the comment is 2, as it identifies a potential area for improvement but does not provide actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the terminology used in the paper, specifically questioning whether \"convergence in direction\" should be considered as \"convergence\" given that CrossEntropy (CE) loss cannot be minimized due to its exponential nature. However, the comment does not provide any explicit or implicit suggestions on how the authors should address this issue or what changes could be made to improve the clarity or accuracy of their terminology. Without specific guidance or actionable steps, the authors are left without a clear understanding of how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the terminology used in the paper, specifically questioning whether \"convergence in direction\" should be considered as \"convergence\" given the nature of CrossEntropy (CE) loss. However, it does not specify which part of the paper this concern pertains to, such as a particular section, table, or figure. The authors might infer that it relates to the discussion of convergence or loss functions, but this inference is not direct. The comment is specific in its critique of the terminology but lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the terminology used in the paper, specifically whether \"convergence in direction\" should be considered as \"convergence\" given that CrossEntropy (CE) loss cannot be minimized due to its exponential nature. While the comment raises a valid concern about the terminology, it lacks specific examples or references to support the claim. The reasoning is based on a logical observation about the nature of CE loss, but without additional context or evidence, the claim remains somewhat vague. Therefore, the comment is categorized as 3, as it provides a basis for the claim but requires more detailed justification or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment raises a concern about the terminology used in the paper, specifically questioning whether \"convergence in direction\" should be considered as \"convergence\" given that CrossEntropy (CE) loss cannot be minimized due to its exponential nature. While the comment identifies a potential issue with the terminology, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the clarity of their terminology. Without actionable feedback or detailed reasoning, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors have stated the flexibility of their framework by allowing component replacement with other models but did not provide any evidence of this flexibility. It implies that the authors should attempt to make changes or try alternative models to demonstrate the robustness of their framework. However, the comment does not specify which components should be changed or how to test the robustness, leaving the action somewhat vague. The authors can infer that they need to conduct experiments with alternative models, but the lack of concrete guidance makes the action 3.", "grounding_specificity_rationale": "The comment addresses the authors\" claim about the flexibility of their framework by allowing component replacement with other models. However, it does not specify which components were mentioned or how they were used, making it difficult for the authors to pinpoint the exact part of the paper that needs revision. The comment is specific in its critique of the lack of evidence for the framework\"s robustness, but it is 1 as it does not reference a specific section or component. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not attempt any changes or alternatives to prove the robustness of their proposed framework, despite stating that components can be replaced with other models for flexibility. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide evidence or references to substantiate the assertion that the framework lacks robustness. As a result, the claim is 1 due to the absence of supporting details or examples, making it difficult for the authors to address the feedback effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of attempts to change or use alternative models to demonstrate the robustness of the proposed framework. While it highlights an area for improvement, the comment does not provide specific suggestions or guidance on how the authors might address this issue. It lacks actionable advice or detailed examples, which would be more helpful for the authors to make informed decisions on how to enhance their work. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making changes."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of the number of disentangled factors in the Atari game experiments, specifically questioning whether it is arbitrary and how it might be specified for other domains. While the comment implies that the authors should consider justifying this choice, it does not provide explicit guidance or concrete suggestions on how to address this issue. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a rationale for their choice of 30 factors. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Atari game experiments,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the choice of the number of disentangled factors, which is a clear issue that needs to be addressed. The comment suggests that this choice might be arbitrary and hard to specify for other domains, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the choice of the number of disentangled factors in the Atari game experiments, specifically asking how this number was chosen and whether it is arbitrary. While the comment raises a valid concern about the specificity of the choice, it does not provide any supporting evidence, reasoning, or references to justify why this choice might be problematic or how it could be improved. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the choice of the number of disentangled factors in the Atari game experiments, specifically questioning whether this number is arbitrary and how it might be specified for other domains. While the comment identifies a potential issue with the experimental setup, it lacks actionable guidance or suggestions on how the authors might address this concern. The feedback is 3 as it prompts the authors to consider the justification for their choice of 30 factors, but it does not provide specific steps or examples for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a specific issue with the use of colloquial expressions, such as \"By the way,\" in the paper. It explicitly points out that this is unprofessional and suggests that the authors should avoid using such expressions. However, the comment does not provide any guidance on how to replace these expressions or what specific instances should be addressed. While the action is clear, the lack of detailed instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the use of colloquial expressions, such as \"By the way,\" in the paper. However, it does not specify which part of the paper contains these expressions, making it weakly grounded. The comment is specific in its critique of the use of colloquial language, which could be addressed by providing more detailed guidance on how to improve the professionalism of the writing. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of colloquial expressions, such as \"By the way,\" is unprofessional. However, it does not provide any specific examples or references to support this claim, making it difficult for the authors to understand the context or the extent of the issue. The lack of detailed justification or evidence weakens the verifiability of the claim, leaving the authors uncertain about how to address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of colloquial expressions, such as \"By the way,\" in the paper. It highlights the unprofessional nature of these expressions, which could detract from the paper\"s professionalism and clarity. However, the comment lacks depth and does not provide actionable suggestions or examples of how to improve the language used in the paper. Without specific guidance or detailed feedback, the authors may struggle to address the issue effectively. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in making improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the abbreviations \"LLH\" and \"ECE\" have not been defined in the paper, despite \"OOD\" being explicitly defined. This provides clear and direct actions for the authors to take, which is to define the missing abbreviations. The comment also suggests that the authors should provide an explanation for these abbreviations, as they are pivotal metrics in the work. This level of detail and specificity makes the comment 5, as it guides the authors on what needs to be addressed and how to do so. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment explicitly mentions the abbreviations \"LLH\" and \"ECE,\" which allows the authors to accurately identify the parts of the paper where these abbreviations are used. It also specifies the issue by pointing out that these abbreviations have not been defined, despite \"OOD\" being explicitly defined. Additionally, the comment highlights that \"ECE\" is a pivotal metric, which adds context to the importance of defining these abbreviations. This level of detail and specificity, combined with explicit references to the paper, makes the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point claims that the abbreviations \"LLH\" and \"ECE\" have not been defined in the paper, despite \"OOD\" being explicitly defined. This claim is 3 as it highlights a specific issue with the lack of definition for certain abbreviations, which is a clear point of concern. However, the comment does not provide additional context or examples to fully substantiate the claim, such as explaining why these abbreviations are critical or how their absence impacts the paper\"s understanding. Therefore, the comment is rated as 3, as it provides a clear observation but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper by pointing out that the abbreviations \"LLH\" and \"ECE\" have not been defined, despite \"OOD\" being explicitly defined. This is a significant oversight that could hinder the understanding of the paper\"s content. The comment also highlights the importance of these abbreviations as pivotal metrics in the work, emphasizing the need for their proper definition. By pointing out these missing definitions, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their draft. However, the comment could be more helpful if it offered suggestions on how to define these abbreviations or provided context for their use. Overall, the comment is 4 as it directs the authors\" attention to a critical area that needs clarification."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, as the probability of failure in stochastic/random projection increases with each layer. The reviewer explicitly asks the authors to justify the stability of the proposed method and to provide information on how stable it is, as well as what happens when more layers are stacked. This feedback provides a clear and explicit action for the authors to take, which is to address the stability concern and provide justifications. The comment is specific in its request for additional information, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly addresses the concern about the stability of the proposed method when stacking multiple layers of WLS units. It mentions the probability of failure in stochastic/random projection increasing with each layer, which allows the authors to identify the specific part of the paper being discussed. The comment is also specific, as it clearly specifies the concern about the stability of the proposed method and asks for justification and information on the impact of stacking more layers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the stability of the proposed method when stacking multiple layers of WLS units, noting that the probability of failure in stochastic/random projection increases with each layer. The reviewer questions the feasibility of forming deeper GNNs due to this issue. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the method\"s stability is compromised. Without additional evidence or explanation, the claim remains somewhat vague, making it difficult for the authors to address the concern effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a critical concern regarding the stability of the proposed method when stacking multiple layers of WLS units. It points out that the probability of failure in stochastic/random projection increases with each layer, potentially hindering the formation of deeper GNNs. The reviewer asks for justification of the method\"s stability and what happens when more layers are stacked, providing clear and actionable feedback. This feedback is valuable as it prompts the authors to address a potential weakness in their methodology and to substantiate their claims with evidence or analysis. However, the comment could be more helpful if it included specific suggestions or examples on how to improve the stability of the method. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some sections of the paper lack clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, it does not provide explicit guidance on how the authors should improve the clarity of these sections or suggest specific changes to make the explanation clearer. The action is implicit, as the authors can infer that they need to clarify the computation of the Bottleneck Distance, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the clarity of the paper, mentioning the computation of the Bottleneck Distance in Definition 4.1. This provides full grounding as the authors can accurately identify the section being addressed. However, the comment lacks specificity regarding what aspects of the computation are unclear or how the authors might improve the clarity. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that some sections of the paper lack clarity, specifically mentioning the computation of the Bottleneck Distance in Definition 4.1. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks clarity, namely the computation of the Bottleneck Distance in Definition 4.1. This feedback is 3 as it highlights a particular issue that the authors need to address to improve the clarity of their work. However, the comment does not provide any suggestions or guidance on how the authors might clarify this section or what specific aspects of the computation are unclear. Without actionable advice or detailed feedback, the authors are left with a general idea of what needs improvement but without a clear path forward. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the visualization in Figure 5 is weaker compared to Balikas COLING16\"s work and questions the segmenting and assigning results of the document. It provides a concrete suggestion to improve the visualization by offering a longer exemplar and ensuring color assignment consistency with topics listed in Figure 4. This feedback is clear and provides specific guidance on how to enhance the paper\"s visualization, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the visualization, suggesting that it is weaker compared to Balikas COLING16\"s work and questioning the segmenting and assigning results of the document. The comment further provides a concrete suggestion to improve the visualization by offering a longer exemplar and ensuring color assignment consistency with topics listed in Figure 4. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the visualization in Figure 5 is weaker compared to Balikas COLING16\"s work and questions the segmenting and assigning results of the document. The reviewer suggests improving the visualization by providing a longer exemplar and ensuring color assignment consistency with topics listed in Figure 4. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to Balikas COLING16\"s work to substantiate the claim fully. This makes the claim 3, as the authors would need to further investigate and understand the specific aspects of Balikas COLING16\"s work to address the feedback effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the visualization in Figure 5, noting that it is weaker compared to Balikas COLING16\"s work. It questions the segmenting and assigning results of the document and suggests improvements, such as providing a longer exemplar and ensuring color assignment consistency with topics listed in Figure 4. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and consistency of their visualization. By addressing this feedback, the authors can significantly improve the presentation and understanding of their results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about the purpose of using a small model like P5small and the necessity of employing a parameterefficient training method. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the use of P5small as the backbone model and the necessity of employing a parameterefficient training method. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion where these choices are made. Without explicit references to sections, figures, or tables, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what the authors should consider or address in response to this question. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the purpose of using a small model like P5small and the necessity of employing a parameterefficient training method. However, it does not provide any supporting evidence, reasoning, or references to justify why this choice is questioned or what specific issues arise from it. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to substantiate the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the purpose of using a small model like P5small and the necessity of employing a parameterefficient training method. While it identifies a potential area of concern, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not offer guidance on how the authors might address this issue or what aspects of their work could be improved. As a result, the feedback is not particularly helpful to the authors, as it does not provide a clear path for enhancing their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors are attempting to propose a method for creating a challenging set, but it claims that what is described is too specific and not scalable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their approach. The feedback lacks concrete details on what specific aspects are too specific or how the authors might make their method more scalable. As a result, the authors are left without clear direction on how to proceed, making the comment 1.", "grounding_specificity_rationale": "The comment provides a general critique about the authors\" approach of creating a challenging set, suggesting that what is described is too specific and not scalable. However, it does not specify which part of the paper this critique pertains to, such as specific sections or experiments where the challenge set is discussed. Without explicit references to the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is vague and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the authors\" approach of creating a challenging set is too specific and not scalable. However, the comment lacks detailed reasoning or examples to support this claim. It does not provide specific instances where the approach is too specific or how it could be made more scalable. Without such evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a general critique of the authors\" approach, suggesting that their method for creating a challenging set is too specific and not scalable. However, it lacks specificity and does not offer detailed feedback or suggestions on how the authors might address these issues. Without actionable guidance or examples, the comment does not provide the authors with a clear path for improvement. As a result, it is 2, as it identifies a potential weakness but does not offer a comprehensive or actionable response."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern, such as suggesting alternative approaches or providing additional analysis. Without any actionable steps or suggestions, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not specify which part of the paper this concern is based on, nor does it provide details on what aspects of this reliance need to be addressed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the reliance are problematic or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses concern about the reliance of the proposed method on the optimal value function corresponding to the reward function. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this concern. Without additional context or guidance, the authors are left without a clear understanding of what aspects of their method need improvement or clarification. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the approach is derivative, taking two existing approaches and combining them. It acknowledges that this is acceptable if the combination works. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve their approach or address the derivative nature of their work. Without specific suggestions or actions, the authors are left without direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the approach being derivative, taking two existing approaches and combining them. However, it does not specify which part of the paper this critique is based on, nor does it provide specific details on what makes the approach derivative or why it might be acceptable. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the approach could be improved or how the derivative nature might be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the approach is derivative, taking two existing approaches and combining them. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. The comment lacks specific details or references that would help the authors understand why the approach is considered derivative or how it could be improved. Without this additional information, the claim remains 1, making it difficult for the authors to address the critique effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment critiques the approach as being derivative, taking two existing approaches and combining them. While it acknowledges that derivatives can be acceptable if they work, it does not provide specific feedback or suggestions on how the authors might improve their approach or address the derivative nature of their work. The comment lacks actionable guidance or detailed insights, leaving the authors without clear direction on how to enhance their draft. As a result, the comment is not particularly helpful in guiding the authors toward improving their work, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of comparisons against other potential baseline approaches in the evaluation section. It suggests that a simple photographic style transfer method might achieve similar or better results. While the comment implies that the authors should include such comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add comparisons to other baseline approaches and consider suggesting a simple method as a baseline. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation section, specifically mentioning the lack of comparisons against other potential baseline approaches. It provides a specific example of a simple photographic style transfer method that could achieve similar or better results. However, the comment does not explicitly mention which part of the paper this evaluation is discussed in, making it weakly grounded. The authors can infer that it relates to the evaluation section, but this inference is not as direct as it could be. The comment is specific in detailing what is missing in the evaluation, namely comparisons against other baseline approaches. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no comparisons against other potential baseline approaches in the evaluation, suggesting that a simple photographic style transfer method might achieve similar or better results. However, the comment lacks specific examples or references to other baseline approaches that could be compared against, making it difficult for the authors to fully understand and address the issue. The reasoning is somewhat vague and lacks detailed evidence or references to support the claim, resulting in a score of 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of comparisons against other potential baseline approaches in the evaluation section. It suggests that a simple photographic style transfer method might achieve similar or better results, which is a valuable insight for the authors to consider. However, the comment could be more helpful if it provided specific examples of baseline approaches that could be compared against or suggested ways to conduct such comparisons. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific issue with the mapping of symbols in Figure 2 to the equations, noting that the authors did not explain the meaning of certain symbols like C_i, Q_i, R_i, and A_i. It also points out a potential confusion between S_i in Figure 2 and the calligraphic S_j in line 431, which was not addressed in the paper. The comment implies that the authors should provide clearer explanations for these symbols and clarify the distinction between S_i and S_j. While the action is explicit, it lacks concrete guidance on how to address the issue, such as suggesting specific ways to explain the symbols or the distinction. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with mapping symbols, such as C_i, Q_i, R_i, and A_i, and points out a potential confusion between S_i in Figure 2 and the calligraphic S_j in line 431. The comment provides clear guidance on what needs to be addressed, including the lack of explanation for these symbols and the need to clarify the distinction between S_i and S_j. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the difficulty in mapping symbols in Figure 2 to the equations makes it challenging to understand the proposed method. It provides specific examples, such as the lack of explanation for symbols like C_i, Q_i, R_i, and A_i, and the confusion between S_i in Figure 2 and the calligraphic S_j in line 431. These examples provide a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific sections or providing more detailed examples of the confusion. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the paper, particularly regarding the mapping of symbols in Figure 2 to the equations. It highlights the lack of explanation for symbols like C_i, Q_i, R_i, and A_i, which are crucial for understanding the proposed method. Additionally, it points out a potential confusion between S_i in Figure 2 and the calligraphic S_j in line 431, noting that this distinction was not adequately addressed in the paper. The comment provides clear and actionable feedback, suggesting that the authors should provide clearer explanations for these symbols and clarify the distinction between S_i and S_j. This feedback is 4 as it directs the authors to specific areas that need improvement, but it could be more comprehensive with additional suggestions on how to address these issues. Therefore, the comment is rated as 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should also study the number of backtracking steps and the acceptance rate, in addition to the hyperparameter $I$. It implies that the authors should investigate how much tuning is required for these parameters to achieve good results. While the action is not explicitly stated, it is clear and concrete, as it provides a specific area for further investigation and suggests a direct action for the authors to take. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should also study the number of backtracking steps and the acceptance rate, in addition to the hyperparameter $I$. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where these parameters are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting additional parameters to study, but without grounding, it lacks clarity on which parts need attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should also study the number of backtracking steps and the acceptance rate, in addition to the hyperparameter $I$. However, it does not provide any supporting evidence, reasoning, or references to justify why these parameters are important or how they might affect the results. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should also study the number of backtracking steps and the acceptance rate, in addition to the hyperparameter $I$, to understand how much tuning is required to achieve good results. This feedback is 3 as it identifies an area for further investigation that could enhance the comprehensiveness of the study. However, the comment could be more helpful if it provided specific guidance on how to approach this study or why these parameters are important. Overall, the comment offers a clear direction for improvement but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the objective function used in GSdyn and FABOLAS, specifically asking which accuracy is being considered\u2014on the validation dataset or the test dataset. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to clarify the objective function used in GSdyn and FABOLAS, particularly regarding the accuracy metric\u2014whether it is the validation or test dataset accuracy. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the objective function used in GSdyn and FABOLAS, specifically regarding the accuracy metric. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the objective function used in GSdyn and FABOLAS, particularly regarding the accuracy metric\u2014whether it is based on the validation or test dataset. This is a clear and actionable piece of feedback that can help the authors clarify their methodology and ensure consistency in their reporting. By addressing this question, the authors can improve the clarity and accuracy of their paper. However, the comment could be more helpful if it provided additional context or suggestions on how to address this issue. Overall, the feedback is 4 as it points out a specific area for clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that section 3.1 should be moved to the Related Work section, and section 3.2 should become section 3 with the proposal. This implies that the authors should reorganize their paper to better align section 3.1 with the Related Work section and split section 3.2 into a new section 3. However, the comment does not provide specific guidance on how to implement this change or what exactly should be included in the new sections. The action is implicit and somewhat vague, as the authors need to infer the exact changes required. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that section 3.1 should be moved to the Related Work section and that section 3.2 should become section 3 with the proposal. This provides some grounding as it mentions specific sections, but it does not explicitly state which part of the paper these sections correspond to, making it weakly grounded. The comment is specific in suggesting a reorganization of the sections to improve clarity and structure. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that section 3.1 should be moved to the Related Work section and that section 3.2 should become section 3 with the proposal. However, the comment does not provide any justification or reasoning for why this reorganization is necessary or beneficial. It lacks specific examples or explanations that would help the authors understand the potential impact of this change. As a result, the claim is 1 due to the absence of supporting evidence or detailed reasoning.", "helpfulness_rationale": "The review comment suggests a reorganization of the sections in the paper, specifically moving section 3.1 to the Related Work section and reclassifying section 3.2 as section 3 with the proposal. This feedback is 3 as it provides a clear direction for improving the structure and flow of the paper. However, it lacks specific details on why this reorganization is necessary or how it would benefit the paper. The authors are given a general idea of what needs to be done but are not provided with detailed guidance on how to implement the changes. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors perform additional evaluations on the VOT dataset to compare their methods using different metrics such as accuracy, robustness, and EAO. While the suggestion is explicit, it lacks concrete details on how to implement this additional evaluation or which specific metrics to focus on. The authors know that they need to conduct evaluations on the VOT dataset, but the comment does not provide specific guidance on how to do so. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the datasets (OTB50, OTB100, OTB2015, LASOT, and VOT) and the metrics (AUC and precision) used for evaluation. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it suggests performing additional evaluations on the VOT dataset using different metrics like accuracy, robustness, and EAO. This provides clear guidance on what needs to be done to enhance the evaluation of the proposed framework. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors perform additional evaluations on the VOT dataset to compare their methods using different metrics like accuracy, robustness, and EAO. The comment provides a logical reasoning by suggesting that the current evaluation on OTB50, OTB100, OTB2015, and LASOT datasets, which use AUC and precision, is insufficient. It implies that the authors should consider a broader evaluation on the VOT dataset to provide a more comprehensive assessment of their framework. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the rationale to fully understand and address the suggestion.", "helpfulness_rationale": "The review comment suggests that the authors perform additional evaluations on the VOT dataset to compare their methods using different metrics like accuracy, robustness, and EAO. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation of the proposed framework. By suggesting an additional dataset and different metrics, the comment offers a concrete way to improve the comprehensiveness and robustness of the evaluation. However, it could be more helpful if it included specific examples or reasons why these additional metrics are important. Overall, the comment is 4 as it guides the authors toward a more thorough evaluation, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern that the proposed method is not compared to any stateoftheart unsupervised semantic segmentation technique. It points out that while the paper mentions the performance being comparable to supervised semantic segmentation, it does not report any performance metrics against stateoftheart methods. This feedback implies that the authors should include comparisons with existing techniques to strengthen their evaluation. However, the comment does not provide specific guidance on which techniques to compare or how to conduct these comparisons, leaving the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a concern about the lack of comparison to stateoftheart unsupervised semantic segmentation techniques, which is a specific issue. However, it does not explicitly mention which part of the paper this concern pertains to, making it weakly grounded. The comment is specific in detailing what is missing in the paper, namely the comparison to stateoftheart methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the lack of comparison to stateoftheart unsupervised semantic segmentation techniques. However, the comment does not provide specific examples or references to these techniques, nor does it explain why such a comparison is necessary or how it would strengthen the paper. Without detailed justification or evidence, the claim remains 1, as it lacks the necessary support to substantiate the concern. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of comparison to stateoftheart unsupervised semantic segmentation techniques. It points out that while the paper mentions the performance being comparable to supervised semantic segmentation, it does not provide any performance metrics against existing techniques. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to include comparisons with stateoftheart methods to strengthen their evaluation. However, the comment could be more helpful if it suggested specific techniques to compare against or provided guidance on how to conduct these comparisons. Overall, the comment is 4 as it directs the authors to a specific area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses uncertainty about the explanation of the first curvefinding part in relation to the FGE work. It highlights a potential issue with the cyclical learning rate scheduling and its impact on the weight changes. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the explanation. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the first curvefinding part of the paper, providing a specific reference to the cyclical learning rate scheduling and its impact on weight changes. However, it does not explicitly mention which section of the paper this part is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the explanation of the FGE work and the potential impact of the cyclical learning rate scheduling. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses uncertainty about the explanation of the first curvefinding part in relation to the FGE work. It highlights a potential issue with the cyclical learning rate scheduling and its impact on weight changes. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the explanation is unclear or incorrect. Without these elements, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment expresses uncertainty about the explanation of the first curvefinding part in relation to the FGE work. It highlights a potential issue with the cyclical learning rate scheduling, suggesting that it may not guarantee weight changes along the curve described in the first part. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the explanation. While it identifies a potential weakness, it does not provide actionable feedback, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should present a case study, ideally with synthetic datasets, to demonstrate why or when a distillation strategy is better. It specifically mentions that in Table 3, LFADSHard performs better than LFADSSoft, and for NDT NDTCorrelation, it also performs better. The reviewer questions whether the authors checked the reason behind this performance and requests more reasoning or hypotheses. While the comment implies that the authors should provide additional analysis or explanations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a case study and provide reasoning for the observed performance differences. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests presenting a case study with synthetic datasets to demonstrate why or when a distillation strategy is better. The comment further questions the reason behind the performance differences observed in the table, prompting the authors to provide more reasoning or hypotheses. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the authors should present a case study with synthetic datasets to demonstrate why or when a distillation strategy is better. It questions the performance differences observed in Table 3, specifically between LFADSHard and LFADSSoft, and between NDT NDTCorrelation. The comment implies that the authors should provide more reasoning or hypotheses to explain these differences. However, the comment lacks specific examples or detailed reasoning to support the claim, making it 3. The authors would need to infer the need for additional analysis, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a constructive suggestion for improving the paper by recommending the inclusion of a case study with synthetic datasets to demonstrate the effectiveness of a distillation strategy. It specifically points out discrepancies in the performance of different strategies, as seen in Table 3, and questions the reason behind these differences. By prompting the authors to provide more reasoning or hypotheses, the comment encourages a deeper analysis of the results. However, the comment could be more helpful if it offered specific guidance on how to design the case study or what aspects to focus on. Overall, the feedback is 3 as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider using clozestyle or question answering evaluation sets to focus on the generation of factual knowledge, as opposed to evaluating LM loss. While the comment implies that the authors should create these types of evaluation sets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should create specific evaluation sets. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should consider using clozestyle or question answering evaluation sets to focus on factual knowledge, as opposed to evaluating LM loss. However, it does not specify which part of the paper discusses the evaluation of LM loss, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its suggestion for improvement but lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that evaluating LM loss is not clean enough because only a few tokens in a sentence are related to facts. The reviewer suggests that creating clozestyle or question answering evaluation sets could be a better approach. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the suggestion of using different evaluation sets. This makes the claim 3, as the authors would need to further explore and justify the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation approach used in the paper, specifically the reliance on evaluating LM loss. It suggests that this approach may not be sufficient for assessing factual knowledge, as only a few tokens in a sentence are related to facts. The comment offers a constructive suggestion by recommending the use of clozestyle or question answering evaluation sets to focus on the generation of factual knowledge. This feedback is clear and actionable, providing the authors with a specific direction for improving their evaluation methodology. However, it could be more helpful if it included examples of how to implement these evaluation sets or discussed the potential benefits of such an approach in more detail. Overall, the comment is 4 as it guides the authors toward a more effective evaluation strategy, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions and suggests areas for clarification. It points out that the authors have claimed that the RTD score is sensitive to cluster and suggests that theoretical or topological explanations should be provided for this sensitivity. Additionally, it questions why the RTD score is specifically applicable to network representation and whether it can be used for vectors of the same size. While the comment highlights areas that need further explanation, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer what specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the key contribution of the paper, specifically the sensitivity of the RTD score to cluster, and suggests that theoretical or topological explanations should be provided. It also questions why the RTD score is specifically applicable to network representation and whether it can be used for vectors of the same size. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion of the RTD score and its applications. The comment is specific in detailing what needs to be addressed, such as theoretical explanations and the applicability of the RTD score. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the applicability of the RTD score, specifically questioning why it is specifically used for network representation and whether it can be applied to vectors of the same size. While the comment highlights a potential limitation or area for further exploration, it does not provide a subjective claim or opinion that requires verification. It is more of a request for clarification or additional explanation, which fits the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a critical question about the applicability and specificity of the RTD score, particularly in the context of network representation. It challenges the authors to provide theoretical or topological explanations for the sensitivity of the RTD score to cluster and to clarify why it is specifically applicable to network representation. This feedback is valuable as it prompts the authors to address potential gaps in their methodology and theoretical foundation, which could significantly enhance the clarity and robustness of their work. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these questions. Overall, the comment is 4 as it identifies important areas for improvement and encourages the authors to provide additional context and justification for their claims."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit guidance on how to improve the experiments section by suggesting an ablation study to demonstrate the contribution of each auxiliary task on object detection performance in ROCK and standard MTL. It specifies the action by mentioning the comparison between the full model (DNS) and models where one task is dropped out (DS, NS, DN). This level of detail gives the authors clear instructions on how to implement the suggested changes, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines (L8889) where the reviewer is trying to make a case about ROCK\"s complexity compared to the original model. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it suggests a weakness in the experiments section, namely the lack of ablation studies showing the contribution of each auxiliary task on object detection performance. It provides a clear suggestion for improvement by recommending comparing the full model (DNS) with models where one task is dropped out (DS, NS, DN). Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ROCK adds 8 conv layers, 3 pooling layers, and 1 fusion layer, which might make the claim about similar complexity to the original model seem surprising. However, the comment does not provide specific evidence or reasoning to support the claim that ROCK\"s complexity is similar to the original model. It lacks detailed justification or examples to substantiate the claim, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides specific feedback on the experimental section, particularly regarding the claim that ROCK has similar complexity to the original model. It points out the addition of multiple layers (8 conv layers, 3 pooling layers, and 1 fusion layer) and suggests that inference timings should be provided to support the claim. This feedback is actionable as it directs the authors to include additional information that could strengthen their argument. Additionally, the comment offers a constructive suggestion for improvement by proposing an ablation study to demonstrate the contribution of each auxiliary task on object detection performance. This detailed guidance empowers the authors to enhance their draft by addressing both the complexity claim and the experimental design. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the need for more discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also points out the potential behavior of the model on noisy or imbalanced realworld medical datasets. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the need for more discussion on the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also highlights the potential behavior of the model on noisy or imbalanced realworld medical datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the dataset and model evaluation sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, such as discussing rare conditions and imaging variations, and the potential behavior on noisy or imbalanced datasets. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the diversity and quality of the dataset, particularly regarding rare conditions and imaging variations. It also questions the model\"s behavior on noisy or imbalanced realworld medical datasets. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the discussion on the diversity and quality of the dataset, particularly concerning rare conditions and imaging variations. It also raises concerns about the model\"s behavior on noisy or imbalanced realworld medical datasets, where labels may be incomplete, inaccurate, or skewed. This feedback is valuable as it highlights areas where the paper could be strengthened by providing more comprehensive analysis and discussion. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of how to improve the dataset or model evaluation. Overall, the comment is 3 as it points out important areas for improvement but lacks detailed guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the reproducibility of the results due to the lack of provided training details about data and hyperparameters. However, it does not explicitly instruct the authors to include these details or suggest how to address the reproducibility issue. The action is implicit, as the authors can infer that they need to provide more detailed information about data and hyperparameters to ensure reproducibility. However, the comment lacks concrete guidance on what specific information should be included or how to present it effectively. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the overall model, which is comprised of multiple components and requires multiple training stages. It highlights the issue of reproducibility due to the lack of provided training details about data and hyperparameters. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the problem with reproducibility and the lack of detailed information about data and hyperparameters. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of provided training details about data and hyperparameters makes the results reproducible. However, the comment does not provide specific examples or references to support this claim, leaving the authors without clear guidance on how to address the issue. The lack of detailed reasoning or evidence makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a critical issue with the reproducibility of the results due to the lack of detailed training information about data and hyperparameters. This feedback is valuable as it highlights a potential weakness in the paper that could hinder the reproducibility of the results, which is essential for the credibility and impact of the research. However, the comment could be more helpful if it provided suggestions on how to address this issue, such as recommending specific details that should be included or how to ensure reproducibility. Overall, the comment is 3 as it points out a significant concern but lacks actionable guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment questions the claim of being the first deep generative model for unsupervised scenegraph discovery, suggesting that it is not fair to give a narrow definition of \"scene graph\" and to claim \"the first.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific aspects of the definition need to be reconsidered. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the claim of being the first deep generative model for unsupervised scenegraph discovery, suggesting that it is not fair to give a narrow definition of \"scene graph\" and to claim \"the first.\" However, it does not specify which part of the paper this claim is made in, nor does it provide details on what aspects of the definition are problematic. Without explicit references to sections or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the claim of being the first deep generative model for unsupervised scenegraph discovery, suggesting that it is not fair to give a narrow definition of \"scene graph\" and to claim \"the first.\" However, the comment does not provide specific examples, references, or detailed reasoning to support this critique. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment critiques the claim of being the first deep generative model for unsupervised scenegraph discovery, questioning the narrow definition of \"scene graph\" and the fairness of such a claim. While it identifies a potential issue with the paper\"s assertion, it lacks specific suggestions or guidance on how the authors might address this concern or improve their work. The comment raises a valid point but does not provide actionable feedback or detailed reasoning, making it 3. The authors are left with a general understanding of the critique but without clear direction on how to improve their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a limitation in the ablation study, specifically that it does not explore the effect of different numbers of projectors on distillation when feature dimensions vary. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the study. The action is implicit, as the authors need to infer that they should conduct additional experiments or analyses to address the identified limitation. Additionally, the comment lacks concrete details on how to implement this change, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of exploration of the effect of different numbers of projectors on distillation when feature dimensions are different. This provides clear guidance on what needs to be addressed in the study. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study does not provide the effect of different numbers of projectors on distillation when feature dimensions are different. However, the comment does not offer any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the ablation study, noting that it does not explore the effect of different numbers of projectors on distillation when feature dimensions vary. This feedback is clear and actionable, as it highlights a gap in the study that the authors should address to improve the comprehensiveness of their analysis. However, the comment could be more helpful if it provided suggestions on how to address this limitation or what specific experiments or analyses could be conducted to fill this gap. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that more experiments on diverse datasets should be conducted to demonstrate the generalization capabilities of the model beyond the three categories mentioned. It also recommends evaluating more complex shapes with various topologies to further validate the proposed method. While the comment provides a clear direction for expanding the experiments, it lacks specific guidance on which datasets or topologies to choose, making the action somewhat vague. However, the authors can infer that they need to conduct additional experiments, which makes the comment 4.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on diverse datasets to demonstrate the generalization capabilities of the model, specifically mentioning three categories (chair, airplane, car). It also recommends evaluating more complex shapes with various topologies to further validate the proposed method. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The comment is specific in suggesting additional experiments and topologies to consider, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that more experiments on diverse datasets and complex shapes with various topologies should be conducted to demonstrate the generalization capabilities of the model. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim. The authors would need to infer the necessity of these additional experiments, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending additional experiments on diverse datasets and complex shapes with various topologies. This feedback is valuable as it highlights the need to demonstrate the generalization capabilities of the model beyond the initial scope, which is crucial for establishing the robustness and applicability of the proposed method. By suggesting these additional experiments, the comment empowers the authors to enhance the comprehensiveness and depth of their work. However, the comment could be more helpful if it provided specific examples of datasets or topologies to consider, or if it offered guidance on how to design these experiments. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that a comparison against methods requiring more training time is necessary, particularly those proposed by Park & Van Hentenryck (2023) and others, which do not require extensive training. It highlights the importance of understanding the implications of low computational requirements, noting that while low compute restrictions are typically essential for inference, training fewer models may render such restrictions unnecessary. The comment provides a clear and explicit action for the authors to take, which is to include a comparison with these methods. Additionally, it offers concrete guidance on what to consider regarding the implications of low computational requirements. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests a comparison against methods that require more training time, specifically mentioning the neural networks proposed by Park & Van Hentenryck (2023) and others. This provides a clear reference to specific methods, allowing the authors to identify the part of the paper being addressed. However, the comment does not specify what aspects of the comparison should be focused on, such as the implications of low computational requirements or the necessity of training fewer models. While the authors can infer that this relates to the methodology or results sections, the lack of specific guidance on what needs to be addressed makes the comment weakly specific. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that a comparison against methods requiring more training time is necessary, particularly those proposed by Park & Van Hentenryck (2023) and others. The reviewer argues that understanding the implications of low computational requirements is crucial, noting that while low compute restrictions are typically essential for inference, training fewer models may render such restrictions unnecessary. The comment provides a logical reasoning based on the need for a fair comparison and the importance of understanding computational implications. However, it lacks specific examples or references to support the claim further, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests a necessary comparison against methods that require more training time, particularly those proposed by Park & Van Hentenryck (2023) and others. It highlights the importance of understanding the implications of low computational requirements, noting that while low compute restrictions are typically essential for inference, training fewer models may render such restrictions unnecessary. This feedback is clear and actionable, as it provides a specific area for the authors to expand their analysis and comparison. By addressing this suggestion, the authors can enhance the comprehensiveness and relevance of their work. However, the comment could be more helpful if it included specific examples or detailed guidance on how to conduct this comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The reviewer explicitly recommends that the authors provide more comparisons between DetNAS and other networks constructed using efficient blocks, such as the 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and provides a concrete action for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison between DetNAS and ResNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests providing more comparisons with other networks constructed using efficient blocks, such as the 3.8G FLOPs ShuffleNetv2 in Table 2. This provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the comparison between DetNAS and ResNet is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The reviewer suggests providing more comparisons with other networks constructed using efficient blocks, such as the 3.8G FLOPs ShuffleNetv2 in Table 2. This claim is 3 as it provides a logical reasoning for the unfairness of the comparison and suggests a specific example for further comparison. However, the comment could be strengthened by providing more detailed reasoning or references to support the claim, making it more 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison between DetNAS and ResNet, suggesting that the comparison is unfair due to the efficiency of the ShuffleNetv2 block compared to the Residual block in ResNet. The reviewer provides a specific suggestion to enhance the comparison by including results for a 3.8G FLOPs ShuffleNetv2 in Table 2. This feedback is clear and actionable, offering a concrete way for the authors to improve the fairness and comprehensiveness of their comparison. By addressing this suggestion, the authors can provide a more robust evaluation of their work, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation in the generality of the input and output spaces/representations used in the paper, suggesting that it is restricted to specific cases. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might expand the generality of their approach or what specific changes could be made to achieve this. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the input and output spaces/representations, noting that they are restricted to specific cases. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the limitation and suggesting that it is less general compared to other works mentioned. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the input and output spaces/representations are restricted to specific cases, such as the group itself under the regular or trivial representation, or a homogeneous space. The reviewer supports this claim by comparing it to two papers mentioned in point (3), which can work with any finitedimensional representation. This comparison provides a logical basis for the claim, as it contrasts the current approach with more general methods. However, the comment could be strengthened by providing more detailed reasoning or examples of the general methods mentioned. Overall, the claim is 4, as it is supported by a logical comparison but lacks additional depth or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific limitation in the generality of the input and output spaces/representations used in the paper. It points out that the current approach is restricted to specific cases, such as the group itself under the regular or trivial representation, or a homogeneous space of the group. The reviewer suggests that this is less general compared to the two papers mentioned in point (3), which can work with any finitedimensional representation. This feedback is 3 as it highlights a potential weakness in the paper\"s approach and provides a direction for improvement by suggesting a more general framework. However, the comment could be more helpful if it offered specific suggestions on how to expand the generality of the input and output spaces or provided examples of how to achieve this. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a complexity in practical applications, specifically mentioning the need to specify a source prompt, blend word, and various conditions for image editing tasks. However, it does not provide explicit guidance or suggestions on how the authors might address this complexity or simplify the process for typical users. The comment lacks actionable details, such as recommending specific methods or tools to streamline the process, making it difficult for the authors to know how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the complexity in practical applications, specifically mentioning the need for specifying a source prompt, blend word, and various conditions for image editing tasks. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the complexity and the need for simplification, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that realworld image editing tasks often involve multiple objects and require flexible prompts, complicating the process and restricting practical usability. The comment provides a logical reasoning by explaining the complexity and the need for specifying various conditions, which supports the claim. However, it lacks specific examples or references to similar systems or studies that have encountered similar challenges, which would strengthen the claim. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be more robust with additional evidence or examples.", "helpfulness_rationale": "The review comment identifies a significant issue with the practical usability of the system, specifically highlighting the complexity involved in realworld image editing tasks. It points out that the need to specify a source prompt, blend word, and various conditions can complicate the process, potentially restricting the system\"s usability for typical users seeking simpler image adjustments. This feedback is valuable as it directs the authors to address a critical limitation in their work, potentially improving the system\"s accessibility and practicality. However, the comment could be more helpful if it provided specific suggestions or examples on how to simplify the process or enhance the system\"s usability. Overall, the comment is 4, as it highlights an important area for improvement but lacks detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the novelty of the technique but expresses concern about the significance of the paper\"s contributions. It also notes a lack of attempt to contrast the technique with traditional classification or manifold learning literature. While the comment highlights areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback is somewhat vague, as it identifies potential areas for enhancement but does not offer concrete steps or examples for the authors to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the novelty and significance of the paper\"s contributions, noting that they are not very significant. It also mentions the lack of attempt to contrast the technique with traditional classification or manifold learning literature. However, the comment does not specify which part of the paper discusses these contributions or where the contrast with traditional methods is lacking. This makes it weakly grounded, as the authors cannot confidently determine which sections need revision. The comment is specific in identifying the issue of lack of contrast with traditional literature but lacks grounding in terms of where this issue is present in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s contributions are not very significant, despite the technique being novel. It also suggests that there is not much attempt to contrast the technique with traditional classification or manifold learning literature. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed evidence or reasoning makes the claim 3, as the authors would need to infer the basis of the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the novelty of the technique but expresses concern about the significance of the paper\"s contributions. It also points out a lack of attempt to contrast the technique with traditional classification or manifold learning literature. While the comment identifies areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it highlights potential weaknesses in the paper\"s contribution and encourages the authors to consider broader comparisons, but it does not provide detailed direction for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary. It provides references to support the claim, indicating that larger datasets could offer more accurate estimates but would require more computational time. However, the comment does not explicitly instruct the authors to include this discussion or provide specific guidance on how to integrate it into their paper. The action is implicit and somewhat vague, as the authors need to infer that they should include this discussion and understand the references provided. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary, providing references to support the claim. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting the need for a discussion and providing references to support the claim, but without explicit guidance on where to place this discussion, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary, providing references to support the claim. The references are to two papers that discuss the effectiveness of language model finetuning and the impact of sparsity on learning, which adds credibility to the suggestion. However, the comment could be strengthened by explaining how these references directly relate to the impact of the fewshot dataset for the sparsity ratio. Overall, the claim is 4 due to the references provided, but it could be more robust with additional explanation or context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that a discussion on the impact of the fewshot dataset for the sparsity ratio is necessary. It acknowledges that larger datasets could provide more accurate estimates but also notes the increased computational time required. The comment is supported by references to relevant literature, which adds credibility to the suggestion. However, the comment could be more helpful if it provided specific guidance on how to integrate this discussion into the paper or suggested ways to address the computational time issue. Overall, the feedback is 3 as it highlights an important aspect of the paper that could enhance its comprehensiveness, but it lacks detailed actionable advice for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the lack of illustration on why keeping representations in the same hidden space is beneficial and the absence of experimental verification to confirm that they are indeed in the same hidden space. While the comment identifies specific areas that need clarification and evidence, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and experimental evidence to support their claims. The action is implicit and somewhat vague, as it lacks concrete guidance on how to implement the suggested changes. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of illustration and experimental verification regarding the benefit of keeping representations in the same hidden space. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the need for illustration and verification but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors have not illustrated why it is better to keep representations in the same hidden space and has not experimentally verified this aspect. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2, as it provides some indication of a problem but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be improved. It points out the lack of illustration on why it is beneficial to keep representations in the same hidden space and the absence of experimental verification to confirm that they are indeed in the same hidden space. While the comment highlights important aspects that need clarification and evidence, it does not provide specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to provide more detailed explanations and experimental evidence, which limits the helpfulness of the comment. Therefore, the comment is 3, as it provides insight but lacks actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of sufficient novelty in the methodologies introduced in the paper, specifically noting that the approach of using Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster RCNN (Ren et al., 2015) does not seem to offer a significant advancement beyond existing methods. However, the comment does not provide any explicit or implicit suggestions on how the authors might address this issue or improve the novelty of their work. Without actionable guidance or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s introduction of Longitudinal Representation Learning as an extension of Karwande et al. (2022) using Faster RCNN (Ren et al., 2015). This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue of lack of sufficient novelty in the methodologies, indicating that the approach does not offer a significant advancement beyond existing methods. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks sufficient novelty in its methodologies, specifically noting that the approach of using Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster RCNN (Ren et al., 2015) does not offer a significant advancement beyond existing methods. The comment provides a specific reference to Karwande et al. (2022) and Ren et al. (2015), which can be used to support the claim. However, the comment could be strengthened by providing additional context or examples of how the current approach differs from previous work or by explaining why the contribution is limited. Overall, the claim is 4, as it is supported by references but could benefit from more detailed reasoning or examples.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the methodologies introduced in the paper, specifically noting that the approach of using Longitudinal Representation Learning as an extension of Karwande et al. (2022) with Faster RCNN (Ren et al., 2015) does not offer a significant advancement beyond existing methods. This feedback is 3 as it highlights a potential weakness in the paper\"s contribution, prompting the authors to reconsider the novelty and impact of their work. However, the comment could be more helpful if it provided suggestions on how the authors might enhance the novelty or differentiate their approach from existing methods. Overall, the comment offers some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper overlooks various SSMbased approaches that address the issue of keeping \u0394t fixed, such as S5, which avoids the issue by computing the inputoutput via a parallel scan. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this oversight or incorporate these approaches into their work. Without specific suggestions or instructions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific oversight in the paper regarding the consideration of various SSMbased approaches that address the issue of keeping \u0394t fixed, such as S5. However, it does not specify which part of the paper this oversight is discussed in, making it weakly grounded. The comment is specific in identifying the issue of overlooking these approaches, but without clear guidance on how to address it, the authors may struggle to understand the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper overlooks various SSMbased approaches that address the issue of keeping \u0394t fixed, such as S5. However, the comment does not provide specific examples or detailed reasoning to support this claim. It mentions S5 as an example but does not elaborate on how it avoids the issue or why it is relevant. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand the basis of the critique without further explanation.", "helpfulness_rationale": "The review comment identifies a specific oversight in the paper regarding the consideration of various SSMbased approaches that address the issue of keeping \u0394t fixed. It mentions S5 as an example, which avoids the issue by computing the inputoutput via a parallel scan. This feedback is 3 as it highlights a potential area for improvement, suggesting that the authors should consider these approaches to enhance their work. However, the comment could be more helpful if it provided additional context or explanation on why these approaches are relevant or how they could be integrated into the paper. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the paper\"s presentation and content. It questions the use of \"3\" as the underlying data generating mechanism, suggesting that it is not accurate. It also recommends using causal graphs instead of label inference for the underlying system, referencing Figure 2. Additionally, it points out that Definition 4 is hard to read due to unclear explanation of which graph should be considered for determining independencies. While the comment identifies specific issues, it does not provide explicit guidance on how to address them or suggest specific changes to improve the clarity or accuracy of the paper. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the presentation and content of the paper, such as the use of \"3\" as the underlying data generating mechanism and the recommendation to use causal graphs instead of label inference. It also points out that Definition 4 is hard to read due to unclear explanation of which graph should be considered for determining independencies. However, the comment does not explicitly mention which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the inaccuracy of the data generating mechanism and the need for clearer explanations in Definition 4. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several claims about the paper\"s presentation and content. It questions the use of \"3\" as the underlying data generating mechanism, suggesting that it is not accurate. The comment also recommends using causal graphs instead of label inference for the underlying system, referencing Figure 2. Additionally, it points out that Definition 4 is hard to read due to unclear explanation of which graph should be considered for determining independencies. While the comment provides some reasoning and references, it lacks detailed evidence or specific examples to fully substantiate these claims. The authors would need to make significant effort to understand and address the issues raised, making the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the paper\"s presentation and content. It questions the use of \"3\" as the underlying data generating mechanism, suggesting that it is not accurate. The comment also recommends using causal graphs instead of label inference for the underlying system, referencing Figure 2, which provides a more standard approach. Additionally, it points out that Definition 4 is hard to read due to unclear explanation of which graph should be considered for determining independencies. While the comment highlights these areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The feedback is 3 as it directs the authors to areas needing clarification and improvement, but it could be more actionable with detailed advice or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate the dualfree approach. While the comment implies that the authors should provide examples to illustrate the point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include examples and determine how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate the dualfree approach. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in suggesting the inclusion of more examples to motivate the dualfree approach, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate the dualfree approach. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a concern or how it impacts the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the cost of evaluating the gradient of a conjugate function and suggests including more examples in machine learning to motivate the dualfree approach. While it identifies a potential area for improvement, it lacks specificity and actionable guidance on how to address the issue or what examples would be most effective. The comment provides some insight but does not offer detailed suggestions or a clear path for the authors to follow in enhancing their draft. Therefore, it is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to explain the reason for selecting a probability from 0, Pcj(0) in the data approximation technique. This is a direct and clear request for clarification, providing the authors with a specific action to take. The comment is explicit and concrete, as it clearly identifies what needs to be addressed and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the data approximation technique (step 3 of the Algorithm 1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of explanation regarding the selection of a probability from 0, Pcj(0) and requests clarification on this aspect. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the lack of explanation regarding the selection of a probability from 0, Pcj(0) in the data approximation technique. However, it does not provide any supporting evidence, reasoning, or references to justify why this lack of explanation is problematic or how it affects the paper. Without additional context or examples, the claim remains 1, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires clarification, namely the selection of a probability from 0, Pcj(0) in the data approximation technique. It points out the lack of explanation, which is a clear and actionable piece of feedback. By requesting an explanation for this choice, the comment provides the authors with a concrete direction to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered additional guidance on how to provide this explanation or what aspects of the explanation might be beneficial. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a precise definition or an informal description of the \"spectrum of distributions and their characteristic functions\" mentioned in the paper. This feedback is explicit, as it clearly states what the authors need to do to improve their draft. However, it lacks concrete details on how to present this information or what specific aspects should be clarified. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (line 128 and line 168) where the authors refer to the spectrum of distributions and their characteristic functions. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the need for a precise definition or an informal description of the concept. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper would benefit from a precise definition or an informal description of the \"spectrum of distributions and their characteristic functions.\" However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or how it would enhance the paper. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, noting that the authors refer to the \"spectrum of distributions and their characteristic functions\" without providing a precise definition or informal description. This feedback is clear and actionable, as it directs the authors to enhance the clarity and comprehensibility of their text by including a definition or description of this concept. However, the comment could be more helpful if it provided additional context or examples of how this concept is used in the paper. Despite this, the feedback is 4 as it guides the authors toward a significant improvement in their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two main issues with the AIGgeneration task. First, it points out that the task is not convincing and suggests that more background should be provided for readers unfamiliar with the area of logic synthesis. Second, it recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to strengthen the argument. While the comment does not explicitly instruct the authors to add background information or conduct benchmarking, it provides clear and concrete suggestions for improvement. The authors can infer the actions to take, making the comment 4.", "grounding_specificity_rationale": "The comment addresses the AIGgeneration task, specifically noting that it is not convincing and suggesting that more background should be provided for readers unfamiliar with the area of logic synthesis. It also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a). While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where the AIGgeneration task is discussed. The comment is specific in suggesting additional background and benchmarking, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the AIGgeneration task is not convincing and suggests that more background should be provided for readers unfamiliar with the area of logic synthesis. The reviewer also recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to strengthen the argument. While the comment provides a logical reasoning for the claim, it lacks specific examples or detailed references to support the suggestion of benchmarking on LayerDAG datasets. This makes the claim 3, as the authors would need to further explore and substantiate the recommendation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the AIGgeneration task, noting that it is not convincing and lacks clarity for readers unfamiliar with the area of logic synthesis. It provides a clear suggestion to enhance the paper by offering more background information, which would help readers understand the context and significance of the task. Additionally, the comment recommends benchmarking the proposed method on existing datasets, such as those used by LayerDAG (Li et al., 2024a), to strengthen the argument. This feedback is actionable and provides specific guidance on how to improve the paper\"s clarity and persuasiveness. However, the comment could be more helpful if it included examples of how to provide the additional background or how to conduct the benchmarking effectively. Overall, the comment is 4 as it directs the authors toward meaningful improvements in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that some statements in the paper lack detail and analysis, but it does not specify which statements are problematic or how the authors should address this issue. Without explicit guidance or suggestions on what specific aspects need more detail or analysis, the authors are left without a clear understanding of what actions to take to improve their draft. As a result, the comment is 1 because it lacks both explicit and concrete instructions for the authors to follow.", "grounding_specificity_rationale": "The comment indicates that some statements in the paper lack detail and analysis, but it does not specify which statements are problematic or how they need to be improved. Without explicit references to specific sections or examples, the authors cannot confidently determine which parts of the paper need attention. Additionally, the comment lacks specificity regarding what kind of detail or analysis is missing. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some statements in the paper lack detail and analysis. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some statements in the paper lack detail and analysis, which is a valid concern. However, it does not provide specific examples or suggestions on how the authors might address this issue. Without actionable feedback or detailed guidance, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that comparing the current model with other generative models, such as VAE, could provide more informative insights. It also mentions that diffusion models have unique features, like diffusion timesteps, and suggests analyzing how these differences affect feature learning. While the comment provides a clear direction for comparison and analysis, it does not specify which aspects of the comparison should be focused on or how to conduct the analysis. The action is explicit but somewhat vague, as it lacks detailed guidance on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current model with other generative models, such as VAE, and highlights the unique features of diffusion models, like diffusion timesteps, to provide additional value. However, it does not specify which part of the paper this comparison should be made or where the analysis of feature learning differences should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact sections or parts of the paper being addressed. The comment is specific in suggesting the need for comparison and analysis, but without grounding, it lacks clarity on how to implement these suggestions. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that comparing the current model with other generative models, such as VAE, could provide more informative insights. It also mentions that diffusion models have unique features, like diffusion timesteps, and suggests analyzing how these differences affect feature learning. While the comment highlights the potential value of such comparisons, it lacks specific examples or references to support the claim that these comparisons would add significant value. The reasoning is somewhat vague, as it does not provide detailed guidance or evidence to substantiate the suggestion. Therefore, the comment is categorized as 2, as it provides some reasoning but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment suggests comparing the current model with other generative models, such as VAE, to provide more informative insights. It also highlights the unique features of diffusion models, like diffusion timesteps, and suggests analyzing how these differences affect feature learning. This feedback is 3 as it identifies a potential area for improvement by suggesting a comparative analysis that could enhance the paper\"s value. However, the comment could be more helpful if it provided specific guidance on how to conduct this comparison or what aspects of feature learning should be analyzed. Overall, the comment offers a direction for improvement but lacks detailed actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment provides specific observations about the results in Table 4, noting that the combination of selfsupervised tasks ICT and DaPI does not seem complementary, and the effectiveness of DaPI is not significant. It also points out that the ICoL method is proposed to address insufficient memory on a single GPU and allow more negative instances for better performance, but there are no experiments to demonstrate the influence of the number of negatives. The comment suggests that the quality of negatives is more important than the quantity, as shown in TASB. While the comment highlights specific areas for improvement, it does not provide explicit instructions or detailed guidance on how to address these issues. The authors can infer that they need to conduct additional experiments to validate the claims and explore the impact of the number of negatives, but the comment lacks concrete steps for execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with the combination of selfsupervised tasks ICT and DaPI, noting that the effectiveness of DaPI is not significant despite doubling GPU memory usage. Additionally, it points out the lack of experiments to demonstrate the influence of the number of negatives and suggests that the quality of negatives is more important than the quantity. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two claims. The first claim is that the combination of selfsupervised tasks ICT and DaPI does not seem complementary, and the effectiveness of DaPI is not significant, as evidenced by the minimal change in performance (0.434 > 0.438). This claim is supported by specific numerical data, making it 4. The second claim is that ICoL is proposed to mitigate insufficient memory on a single GPU and allow more negative instances for better performance, but there are no corresponding experiments to demonstrate the influence of the number of negatives. The reviewer references the importance of the quality of negatives over their quantity, as shown in TASB. This provides a logical reasoning and reference to support the claim, making it 4. However, the comment could be strengthened by providing more detailed experiments or comparisons. Therefore, the overall assessment is 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on two key aspects of the paper. First, it points out that the combination of selfsupervised tasks ICT and DaPI does not seem complementary, and the effectiveness of DaPI is not significant, as evidenced by the minimal change in performance (0.434 > 0.438). This observation highlights a potential issue with the experimental setup and suggests that the authors need to reconsider the combination of these tasks. Second, the comment notes that while ICoL is proposed to address memory constraints and improve performance, there are no experiments to demonstrate the influence of the number of negatives. It also references the importance of the quality of negatives over their quantity, as shown in TASB. This feedback is clear and actionable, providing the authors with specific areas to investigate and improve their work. However, the comment could be more helpful if it offered suggestions on how to conduct these experiments or what specific aspects to focus on. Overall, the comment is 4, as it effectively guides the authors toward meaningful improvements in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly suggests that the caption for Figure 3 should be added to clarify the differences between the three plots on the same row. This is a direct and concrete action for the authors to take, as it provides a clear instruction on how to improve the figure. The comment is specific in its request, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need for a caption to clarify the differences between the three plots on the same row. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the caption for Figure 3 should be added to clarify the differences between the three plots on the same row. However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition is necessary or how it would improve the clarity of the figure. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion effectively.", "helpfulness_rationale": "The review comment is 3 as it identifies a specific issue with Figure 3, noting that the plots on the same row are not clearly distinguishable. The suggestion to add a caption to clarify the differences is actionable and provides a clear direction for improvement. However, the comment could be more helpful if it offered additional guidance on how to design the caption or suggested alternative ways to differentiate the plots. Overall, the feedback is useful but could be more comprehensive, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the results on the VQA dataset in Table 1 are reported on the testdev split, but it suggests that numbers should be reported on the teststandard split instead. This is a clear and direct action for the authors to take, as it provides a specific and actionable step to improve the accuracy and reliability of their results. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results on the VQA dataset, noting that the testdev split should be replaced with the teststandard split to avoid overfitting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results on the VQA dataset in Table 1 are reported on the testdev split, which may lead to overfitting. It references the guidelines from the VQA dataset authors, which specify that numbers should be reported on the teststandard split to avoid overfitting. This reference provides a clear and logical justification for the claim, making it 5. The comment is wellsupported by external references, allowing the authors to understand and address the issue effectively.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that the results are reported on the testdev split, which may lead to overfitting. It provides a clear reference to the guidelines from the VQA dataset authors, which specify that numbers should be reported on the teststandard split to avoid overfitting. This feedback is actionable and constructive, as it guides the authors to make a necessary adjustment to improve the accuracy and reliability of their results. By addressing this issue, the authors can enhance the validity of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the limited applicability of the methods presented in the paper, specifically mentioning that while they can be applied to convolutional networks with minimal modification, their performance is significantly lower compared to fully connected architectures. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the applicability of their methods. The action is implicit and vague, as it does not specify what changes or improvements are needed to enhance the methods\" applicability. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the limited applicability of the methods presented in the paper, specifically mentioning that while they can be applied to convolutional networks with minimal modification, their performance is significantly lower compared to fully connected architectures. However, the comment does not specify which part of the paper discusses the methods or where the applicability issue is addressed, making it weakly grounded. The comment is specific in identifying the issue of limited applicability and the performance trail of the methods compared to fully connected architectures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the limited applicability of the methods presented in the paper, specifically mentioning that while they can be applied to convolutional networks with minimal modification, their performance is significantly lower compared to fully connected architectures. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the methods are not ready for extension to nonfully connected architectures. This lack of supporting evidence makes the claim 3, as the authors would need to infer the basis of the concern without explicit justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the limited applicability of the methods presented in the paper, specifically noting that while they can be applied to convolutional networks with minimal modification, their performance is significantly lower compared to fully connected architectures. This feedback highlights a potential weakness in the paper\"s scope and suggests that the methods may not be ready for extension to nonfully connected architectures. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the applicability of their methods. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential limitation but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses uncertainty about how to evaluate the refactoring process but notes that using a pass rate for unit tests is insufficient. It suggests that the authors consider using alternative metrics for their next benchmark. While the comment implies that the authors should explore additional evaluation metrics, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should consider alternative metrics. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of a refactoring process, indicating that using a pass rate for unit tests is insufficient. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure. The suggestion to consider alternative metrics for evaluation is specific, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point expresses uncertainty about how to evaluate the refactoring process and suggests that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be used for evaluation. However, the comment lacks specific examples or detailed reasoning to support why a pass rate is insufficient or how the suggested metrics would improve the evaluation. This makes the claim 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment acknowledges the need for a clear evaluation of the refactoring process but points out that using a pass rate for unit tests is insufficient. It provides a list of potential metrics that could be used for evaluation, offering a direction for improvement. However, the comment lacks specific guidance on which metrics to prioritize or how to implement them effectively. While it identifies an area for improvement, it does not offer detailed suggestions or examples, making it 3. The authors would gain some insight into potential evaluation metrics but may need further guidance to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the Wiener deconvolution has already been proposed, suggesting that the main contribution of the paper is not significantly novel. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their contribution. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the Wiener deconvolution method, suggesting that it has already been proposed. However, it does not specify which part of the paper discusses this method or where the authors might address the issue of novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. Additionally, the comment lacks specificity regarding how the authors might address the issue of novelty. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the Wiener deconvolution has already been proposed, thus questioning the novelty of the main contribution. However, the comment lacks specific references or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1 due to the absence of supporting details or references.", "helpfulness_rationale": "The review comment points out that the Wiener deconvolution has already been proposed, suggesting that the main contribution of the paper is not significantly novel. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without detailed guidance or examples, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies several weaknesses in the connection to spin glasses, specifically regarding the role of regularization, the effect on Parisi\u2019s order parameter, and the role of temperature or learning rate. While it highlights these areas, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the explanation. The feedback is 3 as it points out areas needing clarification but lacks concrete steps or suggestions for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"equation 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issues with the connection to spin glasses, including the need to explain how regularization helps escape local minima, the effect on Parisi\u2019s order parameter, and the role of temperature or learning rate. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the connection to spin glasses is weak due to the lack of explanation on how regularization helps escape local minima, the effect on Parisi\u2019s order parameter, and the role of temperature or learning rate. The comment provides a logical reasoning by pointing out the specific aspects that need clarification, but it does not offer external references or detailed examples to support these claims. This makes the claim 3, as the authors would need to further develop the explanation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s connection to spin glasses, specifically highlighting the lack of explanation on how the regularization term helps escape local minima, the effect on Parisi\u2019s order parameter, and the role of temperature or learning rate. This feedback is clear and actionable, as it points out specific areas where the paper needs further elaboration and clarification. By addressing these points, the authors can significantly enhance the depth and relevance of their work. However, the comment could be more helpful if it provided suggestions on how to improve these explanations or examples of how to integrate spin glass theory into the discussion. Overall, the comment is 4, as it provides valuable insights for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the selftraining scheme is a direct application and that the contribution of the paper is relatively limited. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the contribution or improve the application of the selftraining scheme. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the selftraining scheme as a direct application and suggests that the contribution of the paper is relatively limited. However, it does not specify which part of the paper discusses the selftraining scheme or where the authors might have expanded on it to increase its contribution. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks specificity and grounding, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the selftraining scheme is a direct application and that the contribution of the paper is relatively limited. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the selftraining scheme as a direct application and suggests that the contribution of the paper is relatively limited. While it identifies a potential area for improvement, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might enhance the contribution or address the concern. The comment is vague and does not offer a clear path for the authors to improve their draft, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the results shown in the paper are lowresolution and recommends having zoomedin regions of the rendered focal stack or allinfocus images to inspect the quality. This feedback provides a clear and explicit action for the authors to take, which is to include higherresolution images or detailed views of the rendered focal stack. The suggestion is concrete, as it specifies exactly what needs to be done to improve the quality of the results. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results shown in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lowresolution nature of the results and the suggestion to include zoomedin regions of the rendered focal stack or allinfocus images to inspect the quality. This provides clear guidance on how to improve the paper. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point suggests that the results shown in the paper are lowresolution and recommends including zoomedin regions of the rendered focal stack or allinfocus images to inspect the quality. While the comment identifies a potential issue with the visual quality of the results, it lacks specific examples or references to support the claim that the results are lowresolution. The suggestion to include higherresolution images or detailed views is logical, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in the paper, noting that they are lowresolution. It provides a clear and actionable suggestion to include zoomedin regions of the rendered focal stack or allinfocus images to better inspect the quality of the results. This feedback is valuable as it offers a concrete way for the authors to enhance the visual presentation and understanding of their findings. However, the comment could be more helpful if it included additional suggestions or considerations for improving the overall presentation of the results. Despite this, the feedback is 4 as it directs the authors toward a specific improvement that could significantly enhance the quality of their work. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two concerns regarding the comparative inference method: the significant increase in inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration, which may not be readily available for openended generation tasks. While the comment identifies potential issues, it does not provide explicit guidance on how the authors might address these concerns or suggest specific actions to mitigate them. The feedback is 3 as it points out areas of concern, but it lacks concrete steps or suggestions for improvement, leaving the authors to infer the necessary actions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparative inference method, specifically mentioning the increase in inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration. This provides some grounding as it refers to specific aspects of the method. However, it does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concerns about computational cost and the availability of validation data, which helps the authors understand what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparative inference method increases inference cost significantly due to multiple forward passes and that posthoc calibration requires validation data, which may not be readily available for openended generation tasks. The comment provides logical reasoning by explaining the implications of these issues for realworld applications with limited computational resources. However, it lacks specific examples or references to support the claim about the increase in inference cost or the unavailability of validation data. This makes the claim 3, as the authors would need to further explore these points to fully understand and address them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies two significant concerns with the comparative inference method: the substantial increase in inference cost due to multiple forward passes and the requirement for validation data for posthoc calibration, which may not be readily available for openended generation tasks. These points are relevant and provide valuable insights into potential limitations of the method, particularly in realworld applications where computational resources and data availability are constrained. However, the comment could be more helpful if it offered suggestions on how the authors might address these issues or alternative approaches to mitigate the concerns. Overall, the feedback is 3 as it highlights important areas for improvement but lacks detailed guidance for the authors to fully benefit from the critique."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests performing gradient clipping with a high value for the gradient norm to avoid NaNs, as an alternative to simply reinitializing the model. This provides a clear and concrete action for the authors to take, offering a specific method to address the issue of exploding gradients. The suggestion is direct and leaves no ambiguity about how to implement it, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L265,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a solution to the problem of exploding gradients, recommending gradient clipping with a high value for the gradient norm to avoid NaNs. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a potential solution to the issue of exploding gradients by recommending gradient clipping with a high value for the gradient norm. However, it does not provide any supporting evidence, reasoning, or references to justify why this approach is necessary or effective. The comment lacks detailed explanation or examples, making it difficult for the authors to understand the basis of the suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment provides a specific suggestion for addressing a potential issue with exploding gradients, recommending gradient clipping with a high value for the gradient norm to avoid NaNs. It also critiques the approach of simply reinitializing the model, suggesting it is a hacky solution. This feedback is actionable and offers a clear path for the authors to improve their draft by addressing the problem of exploding gradients. However, the comment could be more helpful if it provided additional context or explanation on why gradient clipping is a suitable solution or how it might be implemented. Overall, the comment is 4 as it directs the authors toward a specific improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for a more detailed explanation of the term \"common pattern,\" which provides a clear and direct action for the authors to take. It suggests that the authors should clarify the exact meaning of this term, which is crucial for understanding the context of their work. Since the action is explicit and the authors know exactly what needs to be done, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"W1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is a more detailed explanation of the term \"common pattern.\" This provides clear guidance on what the authors need to do to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the term \"common pattern.\" It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the term \"common pattern\" and requests a more detailed explanation. This feedback is clear and actionable, as it directs the authors to clarify a key concept in their paper, which is essential for ensuring the accuracy and comprehensibility of their work. By addressing this issue, the authors can improve the clarity and effectiveness of their draft. However, the comment could be more helpful if it provided additional context or examples to guide the authors in understanding the term. Overall, the comment is 4, as it effectively highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the generalizability of the pretrained model across different datasets, specifically questioning whether it can generalize to datasets from other sources like Twitter or Facebook. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern, such as suggesting additional experiments, datasets, or analyses to test generalizability. Without actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"all five downstream datasets are related to Reddit,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the generalizability of the pretrained model to datasets from other sources like Twitter or Facebook. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the generalizability of the pretrained model across different datasets, specifically questioning its applicability to datasets from other sources like Twitter or Facebook. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generalizability of the pretrained model across different datasets, specifically questioning its applicability to datasets from other sources like Twitter or Facebook. This feedback is 3 as it identifies a potential limitation in the study and prompts the authors to consider the broader applicability of their model. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional experiments or datasets to test generalizability. While it highlights an important area for improvement, the feedback could be more actionable with further elaboration or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point raises a concern about the quality of the generated dataset, specifically questioning how the authors ensure that the dataset is free from hallucinations, a common issue with large language models (LLMs). However, it does not provide any explicit or implicit suggestions on how to address this issue or what specific actions the authors should take to improve the dataset quality. Without guidance on potential methods or steps to mitigate hallucinations, the authors are left without a clear path forward. The comment lacks actionable details, making it 1.", "grounding_specificity_rationale": "The comment raises a concern about the quality of the generated dataset, specifically questioning how the authors ensure that the dataset is free from hallucinations, a common issue with large language models (LLMs). However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its question about quality checking, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the quality of the generated dataset, specifically questioning how the authors ensure that the dataset is free from hallucinations, a common issue with large language models (LLMs). However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the dataset quality is an issue. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the quality of the generated dataset, specifically questioning how the authors ensure that the dataset is free from hallucinations, a common issue with large language models (LLMs). While the comment identifies a potential weakness in the paper, it lacks specificity and actionable guidance. It does not provide any suggestions or methods for addressing this issue, leaving the authors without a clear path to improve their draft. Therefore, the comment is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the comparison across the four models, suggesting that the finetuned wav2vec model might perform better than the others, making the comparison less meaningful. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the comparison. The comment implies that the authors should consider a different approach to ensure a fair comparison, but it lacks concrete suggestions or actions for implementation. As a result, the comment is vague and lacks actionable details, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the comparison across the four models, suggesting that the finetuned wav2vec model might perform better than the others, making the comparison less meaningful. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where the comparison is discussed. This lack of grounding makes it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its critique, it is 1 because it does not provide clear references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison across the four models might not be meaningful because the finetuned wav2vec model is likely to perform better. However, the comment lacks specific evidence or examples to support this claim, such as comparisons of performance metrics or references to similar studies. Without detailed justification or references, the claim remains 3, as it provides a logical basis but lacks the necessary details to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the comparison across the four models, suggesting that the finetuned wav2vec model might perform better than the others, making the comparison less meaningful. While the comment identifies a potential issue with the experimental setup, it lacks specific suggestions or guidance on how the authors might address this concern or improve the comparison. The feedback is 3 as it highlights a potential weakness in the paper, but it does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges that the paper is wellwritten but feels dense, especially compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would help. While the comment implies that adding examples would improve the paper, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors know they need to include more examples but are not given specific guidance on which examples to add or how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment acknowledges that the paper is wellwritten but feels dense, especially compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would help. However, the comment does not specify which part of the paper is dense or where the examples should be added, making it weakly grounded. The suggestion to include more examples is specific, but without clear grounding, the authors may struggle to identify the exact sections that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is wellwritten but feels dense, especially compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would help. However, the comment lacks specific examples or detailed reasoning to support the claim that the paper is dense or how the suggested examples would alleviate this issue. The suggestion to include more examples is somewhat vague, as it does not provide concrete examples or guidance on which examples would be most beneficial. Therefore, the comment is 3, as it provides a general suggestion but lacks detailed justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges that the paper is wellwritten but feels dense, especially compared to other puremath ML papers. It suggests that including more examples, such as Figure 2, would help clarify the content. While the comment identifies a specific area for improvement, it lacks detailed guidance on which examples to include or how they would enhance the paper\"s clarity. The feedback is 3 as it provides a direction for improvement, but it could be more actionable with specific suggestions or examples. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a discrepancy in the presentation of the paper, noting that section 4.2 provides highlevel intuition while section 4.1 does not. However, it does not specify what the authors should do to address this issue or how they might improve the presentation. The comment lacks explicit guidance or concrete suggestions on how to enhance the clarity or provide intuition in section 4.1. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"4.2\" and \"4.1,\" allowing the authors to accurately identify the sections being addressed. It specifies the issue by pointing out the discrepancy in the presentation of highlevel intuition in section 4.2 compared to the lack thereof in section 4.1. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the structure of the paper, noting that section 4.2 provides highlevel intuition while section 4.1 does not. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment points out a discrepancy in the presentation of the paper, noting that section 4.2 provides highlevel intuition while section 4.1 does not. This observation highlights a potential issue with the paper\"s structure and could be an area for improvement. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or enhance the presentation of section 4.1. Without actionable feedback or detailed advice, the authors are left with a general observation that does not directly assist them in improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that Figure 3 includes permutation matrices and recommends introducing more discussions on this topic. While the action is explicit in suggesting that more discussions should be added, it lacks specific guidance on what aspects of the permutation matrices should be discussed or how to integrate these discussions into the paper. The comment provides a clear direction but does not offer detailed instructions on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that more discussions on the obtained permutation matrices should be introduced. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Figure 3 includes permutation matrices and recommends introducing more discussions on this topic. However, it does not provide any supporting evidence, reasoning, or examples to justify why these permutation matrices are important or how they should be discussed. The lack of detailed explanation or references makes it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that Figure 3 includes permutation matrices and recommends introducing more discussions on this topic. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on what aspects of the permutation matrices should be discussed or how they should be integrated into the paper. The comment offers a general direction for enhancement but does not fully support the authors in making a concrete and actionable plan for improvement. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the crowd workers, specifically asking about their recruitment and training processes. While the question is explicit, it does not provide any guidance on how the authors should address this issue or what specific actions they should take to improve their draft. The comment lacks concrete suggestions or actionable steps, leaving the authors without a clear path forward. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the crowd workers, specifically asking about their recruitment and training processes. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the recruitment and training of crowd workers, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking information about the recruitment and training of crowd workers, which is a factual inquiry. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the recruitment and training processes of the crowd workers, which is a relevant and important aspect of the paper. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable advice, leaving the authors with only a general inquiry without a clear path for improvement. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. It raises questions about the validity and robustness of the conclusions and emphasizes the importance of human evaluations. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as the authors are left to infer that they need to consider the limitations of their metrics and possibly incorporate human evaluations. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of weak correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. However, it does not specify which part of the paper discusses this issue, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the concern regarding the correlation, it lacks grounding as it does not mention a particular section or figure. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the correlation between automatic metrics and human evaluations is weak, which could question the validity and robustness of the conclusions. The comment suggests that human evaluations are more important and raises questions about the conclusions. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the automatic metrics do not fully capture the quality of the simplifications. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the correlation between automatic metrics and human evaluations, suggesting that the automatic metrics may not fully capture the quality of the simplifications. This raises concerns about the validity and robustness of the conclusions. While the comment highlights a critical point, it lacks specific suggestions or guidance on how the authors might address this issue or improve their draft. The feedback is 3 as it prompts the authors to consider the limitations of their metrics and the importance of human evaluations, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to be more specific about the \"Chain of Reasoning\" section, particularly line 276. This provides a clear and direct action for the authors to take, as they know exactly what part of the paper needs further elaboration. The comment is specific in its request, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 276,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is being more specific about the \"Chain of Reasoning\" section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for more specificity in the \"Chain of Reasoning\" section, particularly line 276. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 3 as it identifies a specific area for improvement, namely the \"Chain of Reasoning\" section, particularly line 276. However, it lacks depth and does not provide guidance on how the authors might enhance the specificity of this section or what aspects should be clarified. While it points out a potential area for improvement, the comment does not offer actionable suggestions or detailed feedback, limiting its usefulness to the authors. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a sample quality metric on the CARLA data, specifically mentioning the common metrics like minADE or minMSD. It implies that the authors should compute these metrics to evaluate the performance of their approach. However, the comment does not provide explicit instructions on how to implement this or which specific metrics to use, leaving the action somewhat vague. The authors can infer that they need to add these metrics, but the lack of concrete guidance makes the action 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ability to perform \"hypothetical inference\" or planning, and it refers to the CARLA data, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it suggests the inclusion of a sample quality metric, such as minADE or minMSD, which are common metrics used in the field. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should include a sample quality metric on the CARLA data, specifically mentioning the common metrics like minADE or minMSD. The comment provides a logical reasoning by explaining the importance of these metrics in evaluating the performance of the approach. However, it lacks specific examples or references to support the claim fully, making it 3. The authors would need to further explore these metrics to fully understand the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of a sample quality metric on the CARLA data, such as minADE or minMSD. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the evaluation of the authors\" approach. By incorporating these metrics, the authors can better assess the performance of their method, which is crucial for demonstrating the effectiveness of their work. However, the comment could be more helpful if it provided additional context or explanation on why these metrics are important or how they should be implemented. Overall, the comment is 4 as it directs the authors to a specific enhancement that could significantly improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the authors assume that every constraint can be naturally accompanied by a corresponding discriminator. While it implies that the authors should consider this assumption, it does not explicitly instruct them to do so or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors can infer that they need to reconsider their assumptions but may not be entirely sure of the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the assumption made regarding constraints and discriminators, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this issue is discussed. Additionally, the comment lacks specificity regarding what needs to be addressed or clarified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the assumptions made in the paper, specifically regarding the relationship between constraints and discriminators. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumption made in the paper regarding the relationship between constraints and discriminators. While it identifies a potential area of concern, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks depth and actionable advice, making it 2. Authors are left with a general inquiry but no clear path forward for improvement. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the use of Optimal Transport (OT) or the Wasserstein Distance in GANs, specifically in the context of WGAN, could be beneficial to discuss or include as a baseline method. While the comment implies that the authors should consider adding a discussion or baseline for WGAN, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion or baseline for WGAN. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests using Optimal Transport (OT) or the Wasserstein Distance in GANs, specifically referencing the WGAN paper by Arjovsky et al. (2017). It implies that the authors should discuss WGAN or include it as a baseline method. However, the comment does not specify which part of the paper this suggestion pertains to, such as a methodology section or a discussion of related work. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of WGAN as a baseline, but it lacks grounding as it does not explicitly mention the relevant sections. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that using Optimal Transport (OT) or the Wasserstein Distance in GANs, specifically in the context of WGAN, could be beneficial. It references the WGAN paper by Arjovsky et al. (2017) to support this claim. The comment provides a logical reasoning by citing a specific paper that introduced the concept, making the claim 4. However, it could be strengthened by providing more context or examples of how this approach could benefit the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment suggests that the use of Optimal Transport (OT) or the Wasserstein Distance in GANs, specifically in the context of WGAN, could be beneficial. It recommends discussing WGAN or adding it as a baseline method. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the paper\"s discussion on GANs and their applications. By recommending the inclusion of WGAN as a baseline, the comment offers a concrete way for the authors to improve their draft. However, it could be more helpful if it provided additional context or examples of how WGAN could be integrated into the study. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies a gap in the paper by noting the absence of important related work on MCMC in discrete spaces. It suggests discussing methods that have applied Langevin MCMC to sample discrete sequences, as referenced in the provided sources. The comment also provides specific references, which gives the authors clear guidance on what additional content to include. Additionally, the comment offers a critique of the paper\"s presentation, suggesting it may be more suitable for a workshop than a conference publication. This feedback is explicit and provides concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the absence of important related work on MCMC in discrete spaces and suggests discussing methods that have applied Langevin MCMC to sample discrete sequences, referencing specific works. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be addressed, namely the discussion of related work and the critique of the paper\"s presentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that important related work on MCMC in discrete spaces is absent and suggests discussing methods that have applied Langevin MCMC to sample discrete sequences, referencing specific works. The comment provides specific references to papers that have applied these methods, which supports the claim. However, it does not elaborate on why these works are relevant or how they relate to the current paper\"s context. While the references are provided, the explanation lacks depth, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by noting the absence of important related work on MCMC in discrete spaces. It suggests discussing methods that have applied Langevin MCMC to sample discrete sequences, referencing specific works that should be included. This feedback is clear and actionable, providing the authors with a concrete direction for expanding their literature review and enhancing the paper\"s context. Additionally, the comment critiques the paper\"s presentation, suggesting it may be more suitable for a workshop than a conference publication, which offers valuable insight into the paper\"s potential audience. Overall, the comment is 5 as it provides specific suggestions for improvement and offers a clear critique of the paper\"s presentation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about why DSFedDRO and FedDRO use different methods to estimate $g$. However, it does not provide any explicit or implicit suggestions for the authors to address this issue. The comment lacks guidance on how the authors might investigate or resolve this discrepancy, leaving them without a clear path forward. As a result, the comment is 1 because it does not offer any actionable steps or insights for the authors to improve their draft.", "grounding_specificity_rationale": "The comment raises a question about the methods used by DSFedDRO and FedDRO to estimate $g$. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what the reviewer is seeking clarification on or what issues arise from the differing methods. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the methods used by DSFedDRO and FedDRO to estimate $g$. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the methods used by DSFedDRO and FedDRO to estimate $g$. While it identifies a potential area of confusion or inconsistency in the paper, it does not provide any guidance or suggestions for the authors to address this issue. The comment lacks depth and actionable advice, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it points out a potential issue but does not offer constructive feedback for resolution."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point mentions a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l,\" but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on what specific aspects need clarification or how the authors should address the issue. Without actionable steps or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment mentions a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l,\" but it does not specify which part of the paper this discussion is located in, making it weakly grounded. The comment is specific in identifying the need for a discussion about the difference between these two terms, but it lacks detail on how this discussion should be expanded or what specific aspects need clarification. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point mentions a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l,\" but it does not provide any context, explanation, or reasoning to support why this difference is important or how it affects the paper. Without additional information or justification, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment points out a discussion about the difference between \"(6)\" in Nicekl Kiela and \"l,\" but it does not provide any context, explanation, or guidance on how this difference impacts the paper or why it is important. The comment lacks specificity and actionable advice, leaving the authors without a clear understanding of what needs to be addressed or improved. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. While it identifies a potential issue, it does not explicitly instruct the authors to conduct multiple experiments or perform variance analysis. The action is implicit, as the authors can infer that they need to address these issues, but the comment lacks concrete guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments. The authors might infer that it relates to the experimental section, but this inference is not direct. The comment is specific in identifying the need for multiple experiments and variance analysis but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. However, it does not provide any supporting evidence, reasoning, or references to justify why multiple experiments or variance analysis are necessary. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental design, specifically noting that the experiments were not conducted multiple times and that there is a lack of variance analysis for the results. This feedback is 3 as it highlights a critical area that could enhance the robustness and reliability of the study. However, the comment does not provide specific suggestions on how to address these issues, such as recommending additional experiments or methods for variance analysis. While it points out a problem, it lacks actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a gap between the AL experiments conducted by the authors and the goal of achieving label efficiency with a human in the loop. It points out that factors such as differing dataset qualities and temporal drifts in data distributions, which are characteristic of realworld data, are not accounted for in the experiments. However, the comment does not provide explicit guidance or suggestions on how the authors should address these gaps or incorporate these considerations into their work. The action is implicit and vague, as the authors are left to infer that they need to address these gaps but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of gaps with realworld datasets, specifically mentioning the differences in dataset qualities and temporal drifts in data distributions. However, it does not explicitly mention which part of the paper discusses these gaps, making it weakly grounded. The comment is specific in identifying the need to account for these factors in the experiments, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point highlights a gap between the AL experiments conducted by the authors and the goal of achieving label efficiency with a human in the loop. It mentions specific factors such as differing dataset qualities and temporal drifts in data distributions, which are characteristic of realworld data, that are not accounted for in the experiments. This provides a logical basis for the claim, as it identifies specific aspects of realworld data that are not addressed in the current experiments. However, the comment could be strengthened by providing more detailed examples or references to support these claims. Overall, the comment is 4, as it provides a clear rationale but lacks specific examples or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap between the AL experiments conducted by the authors and the goal of achieving label efficiency with a human in the loop. It highlights specific factors, such as differing dataset qualities and temporal drifts in data distributions, that are characteristic of realworld data and are not accounted for in the experiments. This feedback is valuable as it points out an area where the authors need to address to make their work more applicable to realworld scenarios. However, the comment could be more helpful if it provided suggestions on how to incorporate these considerations into the experiments or discussed potential solutions. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point questions the communication cost of the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or improve their communication cost. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the communication cost in the paper, specifically mentioning the complexity as O(SAH^2) or O(MSAH^2). It compares this to other federated Qlearning algorithms, which is a relevant point. However, the comment does not specify which part of the paper discusses the communication cost, making it weakly grounded. The comment is specific in its critique of the communication cost and its comparison to other algorithms, providing clear guidance on what might need to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the communication cost in the paper is not particularly low or noteworthy, given that other federated Qlearning algorithms have demonstrated that O(H) communication rounds are sufficient. The comment provides a reference to other algorithms, which supports the claim by highlighting a benchmark for comparison. However, the comment lacks specific details or examples from those other algorithms, which would strengthen the argument. Therefore, the claim is 3, as it provides a basis for comparison but requires more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the communication cost in the paper, suggesting that it is not particularly low or noteworthy compared to other federated Qlearning algorithms. It references other algorithms that have demonstrated lower communication rounds, which provides a basis for comparison. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their communication cost. While it highlights a potential weakness, it does not offer actionable feedback or detailed advice, making it 3. The authors would gain some insight into the problem but may need to explore additional information or strategies on their own to fully address the feedback."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature, and it notes that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, it does not offer any explicit or implicit suggestions for how the authors might address this issue or improve their draft. The comment lacks actionable guidance, leaving the authors without a clear path to enhance their work. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the main idea of using an ensemble of neural networks, noting that it is trivial and common in machine learning literature. It also mentions that the paper does not provide any specific adaptation to the homomorphic encryption domain. However, the comment does not specify which part of the paper discusses the ensemble of neural networks or where the homomorphic encryption domain is addressed, making it difficult for the authors to pinpoint the exact areas needing improvement. The lack of specific references or detailed guidance on what aspects should be adapted to the homomorphic encryption domain makes the comment weakly grounded. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point claims that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature, and that the paper does not provide any specific adaptation to the homomorphic encryption domain. While the comment highlights a potential issue with the novelty of the approach, it lacks specific examples or references to support the claim that the idea is trivial or common. The absence of detailed reasoning or evidence makes it difficult for the authors to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the main idea of using an ensemble of neural networks is trivial and common in machine learning literature. It also points out that the paper does not provide any specific adaptation to the homomorphic encryption domain. While this feedback highlights an area for improvement, it lacks actionable guidance or suggestions on how the authors might address this issue or enhance their work. The comment does not offer concrete steps or examples for the authors to consider, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a gap in the paper regarding the explanation of why and how the new model works better than the previous stateoftheart, MH. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should provide a clearer explanation, but it lacks concrete steps or examples on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment provides a general overview of the paper, mentioning the new model for detecting overlapping entities and its improvement over the stateoftheart, MH, in experiments on benchmark datasets. However, it does not specify which part of the paper this discussion is related to, making it weakly grounded. The comment does not provide specific details on what is unclear or needs further explanation regarding the new model\"s performance or mechanism. Therefore, the comment is 2, aligning with label 2.", "verifiability_rationale": "The review point claims that the paper presents a new model for detecting overlapping entities in text that improves upon the stateoftheart, MH, in experiments on benchmark datasets. However, it does not provide any specific details or evidence to support this claim, such as results, comparisons, or explanations of the model\"s improvements. Without additional information or references, the claim remains 1, as it lacks the necessary justification or evidence to substantiate the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper regarding the explanation of why and how the new model for detecting overlapping entities in text works better than the previous stateoftheart, MH. While it points out a critical area for improvement, it lacks specific suggestions or guidance on how the authors might address this issue. The comment highlights an important aspect of the paper that needs further elaboration but does not provide actionable steps or detailed feedback to help the authors improve their draft. Therefore, the comment is 3, as it points out a significant area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the formula used in the Adjective Projection part, suggesting that it may not be reasonable. The reviewer provides a specific critique, indicating that the approach of estimating whether an object is large or small should involve calculating the similarity between the object and \"large\" and \"small\" separately, and then comparing these similarities, rather than using the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. While the comment identifies a potential issue, it does not explicitly instruct the authors to make this change or provide detailed guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Adjective Projection part,\" allowing the authors to accurately identify the section being addressed. It is also specific because it provides a detailed critique of the formula used, suggesting a more logical approach to estimating whether an object is large or small. The comment specifies what needs to be addressed, namely the potential issue with the formula and the suggestion for a better method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the formula used in the Adjective Projection part, suggesting that the current approach may not be reasonable. The reviewer provides a logical reasoning by explaining that the correct method should involve calculating the similarity between the object and \"large\" and \"small\" separately, and then comparing these similarities, rather than using the similarity between the object embedding and the difference between \"large\" and \"small\" embeddings. This reasoning is clear and provides a solid basis for the claim, making it 5. The comment is wellsupported by logical reasoning, providing the authors with a clear understanding of the issue and how to address it. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the formula used in the Adjective Projection part, suggesting that the current approach may not be reasonable. It provides a clear and logical explanation of why the suggested method is more appropriate, by emphasizing the need to calculate similarity between the object and \"large\" and \"small\" separately, and then comparing these similarities. This feedback is actionable and constructive, as it offers a specific alternative approach that the authors can consider to improve their methodology. However, the comment could be more helpful if it included suggestions on how to implement this alternative approach or provided examples of similar methods. Overall, the comment is 4, as it guides the authors toward a more effective method for their analysis."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss and compare their approach to more recent works on anyresolution image generation, specifically mentioning two examples. While the comment provides a clear direction for the authors to include additional comparisons, it does not specify which aspects of the comparison should be focused on or how to structure the discussion. The action is explicit but somewhat vague, as it lacks detailed guidance on how to implement the suggested comparisons. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should discuss and compare their approach to more recent works on anyresolution image generation, specifically mentioning two examples. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to compare with recent works, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the claim about the advantage of anyresolution generation should be discussed and compared to more recent works. The comment provides specific references to two recent works, 1 and 2, which are cited as examples. This level of detail supports the claim by providing concrete evidence of recent advancements in the field, making the comment 4. However, the comment could be strengthened by explaining how these works relate to the current study or why they are relevant. Overall, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors discuss and compare their approach to more recent works on anyresolution image generation. It explicitly mentions two relevant works, 1 and 2, which are cited as examples. This guidance is clear and actionable, as it directs the authors to include a comparative analysis with these recent studies, potentially enhancing the paper\"s relevance and impact. However, the comment could be more helpful if it provided additional context or guidance on how to effectively incorporate these comparisons into the paper. Overall, the feedback is 4, as it offers a concrete direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several points that suggest areas for improvement. It notes that the CT experiment has only one subject in the test set, which may lead to overfitting, and questions whether Section 6 adequately describes the limitations of the work. The reviewer suggests that the authors discuss the limitations of the approach, including theoretical assumptions and implementation considerations. Additionally, the comment questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and how training time might compare if these alternatives are implemented with online learning. While the comment identifies specific areas for improvement, it does not provide explicit instructions on how to address these issues or what specific changes should be made. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the range of pages (84: 1763\u20131780) and provides a specific reference to a paper, making it easy for the authors to locate the relevant section. It also specifies the issue with the CT experiment having only one subject in the test set, which is prone to overfitting. The comment further suggests that Section 6 should be expanded to discuss the limitations of the approach, including theoretical assumptions and implementation considerations. Additionally, it raises a question about the relative improvement of ODER over RED (Unfold) or RED (Denoising) and how training time might compare if these alternatives are implemented with online learning. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a concern about the CT experiment having only one subject in the test set, which may lead to overfitting. The reviewer questions whether Section 6 adequately describes the limitations of the work and suggests that the authors discuss the limitations of the approach, including theoretical assumptions and implementation considerations. Additionally, the comment questions the relative improvement of ODER over RED (Unfold) or RED (Denoising) and how training time might compare if these alternatives are implemented with online learning. While the comment raises valid concerns, it lacks specific examples or references to substantiate the claims about overfitting or the limitations of the approach. The suggestions for improvement are 3, as they provide a direction for the authors to address the issues, but they could be more robust with additional evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the CT experiment, noting that having only one subject in the test set may lead to overfitting. It questions whether Section 6 adequately describes the limitations of the work and suggests that the authors discuss the limitations of the approach, including theoretical assumptions and implementation considerations. Additionally, the comment raises a question about the relative improvement of ODER over RED (Unfold) or RED (Denoising) and how training time might compare if these alternatives are implemented with online learning. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The feedback is 3 as it points out areas for enhancement but does not provide detailed instructions or examples for the authors to follow. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between the proposed multiscale hierarchical predictor and other methods like IEConv, CDConv, and ProNet. It provides a list of references for further exploration. However, it does not explicitly instruct the authors to address this question or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should compare their method with these existing approaches and identify the differences. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the differences between the proposed multiscale hierarchical predictor and other methods like IEConv, CDConv, and ProNet. It provides a list of references for further exploration, which helps the authors understand the context of the comparison. However, the comment does not specify which part of the paper this comparison should be made, making it weakly grounded. The question is specific in asking about the differences, but without explicit grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the differences between the proposed multiscale hierarchical predictor and other methods like IEConv, CDConv, and ProNet. It provides a list of references for further exploration, which adds some context and support to the claim. However, the comment lacks detailed reasoning or specific examples to fully substantiate the claim, making it 3. The authors would need to refer to the provided references to understand the differences better, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the differences between the proposed multiscale hierarchical predictor and other methods like IEConv, CDConv, and ProNet. It provides a list of references for further exploration, which could help the authors understand the context and potential gaps in their work. However, the comment lacks actionable guidance or specific suggestions on how to address these differences or improve the comparison. While it identifies an area for improvement, it does not provide detailed feedback that would help the authors make significant progress. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper does not read well and suggests that more careful proofreading is needed. However, it does not provide specific details on what aspects of the paper could be improved or how the authors should address the issue. The comment lacks explicit guidance or concrete suggestions for improvement, leaving the authors without a clear understanding of what needs to be done to enhance the readability of their draft. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment indicates that the paper does not read well and suggests that more careful proofreading is needed. However, it does not specify which parts of the paper are difficult to read or where specific issues might exist. Without explicit references to sections, figures, or particular elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the writing could be improved. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper does not read well and suggests that more careful proofreading is needed. However, it does not provide any specific examples or details to support this claim, such as which sections are difficult to read or what specific issues might be present. Without additional context or evidence, the authors may find it challenging to address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the paper does not read well and suggests that more careful proofreading is needed. However, it lacks specificity and does not provide any details on what aspects of the paper could be improved or how the authors might enhance readability. Without actionable feedback or specific suggestions, the authors are left without a clear understanding of how to address the issue. Therefore, the comment is 2, as it identifies a problem but does not offer guidance on how to resolve it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests several actions for the authors to take. It recommends analyzing the distribution of the addressing coefficients (Betas) with and without the bias towards sequential addressing, as this difference is important for the synthetic task. Additionally, it questions the value and selection of the tradeoff parameter (Theta) and asks about the performance of a baseline using the attention from the previous question instead of a soft attention. These suggestions are explicit and provide concrete guidance on what analyses or questions the authors should address. The comment is 5 as it clearly outlines the specific actions the authors should take to improve their draft.", "grounding_specificity_rationale": "The comment suggests analyzing the distribution of the addressing coefficients (Betas) with and without bias towards sequential addressing, which is relevant to the synthetic task. It also questions the value and selection of the tradeoff parameter (Theta) and explores the performance of a baseline using attention from the previous question instead of soft attention. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these analyses and questions are likely discussed. The comment is specific in detailing what needs to be addressed, such as the distribution of Betas and the role of Theta. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of several suggestions and questions, which are factual in nature. It does not contain subjective claims, opinions, or suggestions that require verification. The comment is purely descriptive, asking for additional analysis and clarification regarding the addressing coefficients and the tradeoff parameter. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides several specific and actionable suggestions for improving the draft. It recommends analyzing the distribution of the addressing coefficients (Betas) with and without bias towards sequential addressing, as this difference is crucial for the synthetic task. Additionally, it questions the value and selection of the tradeoff parameter (Theta) and explores the performance of a baseline using attention from the previous question instead of soft attention. These suggestions are clear and provide the authors with concrete directions for enhancing their work, making the comment 5. The feedback is detailed and offers a comprehensive approach to improving the draft, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses uncertainty about the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of standard concentration inequalities is expected. The reviewer also questions the relevance of this proposition, stating that it is decorative math and does not contribute to the paper\"s complexity measure in a statistical learning sense. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the draft. The authors are left to infer that they might need to reconsider the inclusion or relevance of Proposition 1, but without concrete steps, the action remains vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses Proposition 1, which allows the authors to identify the specific part of the paper being discussed. However, it does not explicitly mention which section or part of the paper Proposition 1 is located in, making it weakly grounded. The comment is specific in its critique, pointing out that Proposition 1 is a standard regression problem and questioning the necessity of the mathematical approach presented. It also suggests that the paper is already interesting and that the proposition does not contribute to the complexity measure in a statistical learning sense. This provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of Proposition 1, suggesting that it is a standard regression problem and that the application of standard concentration inequalities is expected. The reviewer also questions the relevance of this proposition, stating that it is decorative math and does not contribute to the paper\"s complexity measure in a statistical learning sense. While the comment provides some reasoning, it lacks specific examples or references to support the claim that the proposition is unnecessary or decorative. This makes the claim 3, as the authors would need to further explore and justify the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of Proposition 1, questioning its relevance as a standard regression problem and suggesting that the application of standard concentration inequalities is expected. The reviewer also critiques the proposition for being decorative math and not contributing to the paper\"s complexity measure in a statistical learning sense. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve the draft. The feedback is 3 as it prompts the authors to reconsider the inclusion or relevance of Proposition 1, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the evaluation of defense techniques, specifically in the context of backdooring classification. It suggests that the evaluation of the proposed method should include several defenses that rely on input perturbation, referencing specific works by Doan et al. (2021) and Doan et al. (2021). While the comment implies that the authors should conduct additional evaluations, it does not provide explicit instructions or detailed guidance on how to incorporate these defenses into the analysis. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of defense techniques, specifically in the context of backdooring classification. It mentions several defenses that rely on input perturbation and suggests evaluating the proposed method against these defenses. The comment is fully grounded as it explicitly mentions the topic of defense techniques and provides references to specific works, allowing the authors to accurately identify the parts of the paper being addressed. However, the comment lacks specificity regarding which aspects of the evaluation are lacking or how the proposed method should be evaluated against these defenses. Therefore, this comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the evaluation of defense techniques is limited, specifically in the context of backdooring classification. It suggests that the evaluation of the proposed method should include several defenses that rely on input perturbation, referencing specific works by Doan et al. (2021) and Doan et al. (2021). This provides a logical reasoning by identifying a gap in the evaluation and suggesting specific references to support the claim. However, the comment could be strengthened by providing more detailed examples or a broader context of the evaluation process. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of defense techniques, specifically in the context of backdooring classification. It highlights the importance of evaluating the proposed method against several defenses that rely on input perturbation, referencing specific works by Doan et al. (2021) and Doan et al. (2021). This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their evaluation by incorporating additional defense techniques. However, the comment could be more helpful if it offered suggestions on how to conduct these evaluations or provided examples of how to integrate these defenses into the analysis. Overall, the comment is 4, as it effectively guides the authors toward a more comprehensive evaluation of their method."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the related work section should be more focused and include descriptions of similar datasets for nonEnglish or underrepresented languages. It also points out that the context and evidencebased methods are presented in a shallow manner. While the comment provides some guidance on what could be improved, it lacks explicit instructions on how to achieve these changes. The authors are left to infer that they need to enhance the focus of the related work section and provide more detailed descriptions of datasets and methods. The action is implicit and somewhat vague, as it does not specify how to make the related work section more focused or how to present the context and evidencebased methods more thoroughly. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests improvements to the related work section, specifically mentioning the need for a more focused section and the inclusion of datasets for nonEnglish or underrepresented languages. However, it does not specify which part of the related work section should be revised or how to incorporate these suggestions. The comment also points out that the context and evidencebased methods are presented in a shallow manner, but it does not provide specific guidance on how to improve this aspect. While the authors can infer that the comment pertains to the related work section, the lack of explicit references and detailed guidance makes it weakly grounded. The comment is specific in suggesting improvements but lacks grounding, resulting in a score of 3.", "verifiability_rationale": "The review point suggests that the related work section should be more focused and include descriptions of similar datasets for nonEnglish or underrepresented languages. It also claims that the context and evidencebased methods are presented in a shallow manner. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The suggestion to include more detailed descriptions of datasets and methods is 3, as it provides a direction for improvement, but the lack of concrete evidence or examples makes it challenging to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement, particularly in the related work section. It suggests that the section should be more focused and include descriptions of similar datasets for nonEnglish or underrepresented languages. Additionally, it points out that the context and evidencebased methods are presented in a shallow manner. While the comment identifies areas for improvement, it lacks detailed guidance on how to achieve these changes or what specific aspects should be emphasized. The feedback is 3 as it directs the authors to enhance the related work section, but it could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific observation about the BN (Batch Normalization) implementation in the context of ReLU and Convolution operations. It notes that BN can be folded into the Convolution operation in a certain way, but questions whether BN after ReLU can be folded into the next Convolution operation. However, the comment does not provide explicit guidance or suggestions on how the authors should address this observation or incorporate it into their draft. The action is implicit and vague, as it lacks concrete steps or recommendations for the authors to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observation about BN (Batch Normalization) and its implementation in the context of ReLU and Convolution operations, providing a clear understanding of what the comment is addressing. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point makes a claim about the BN implementation in the context of ReLU and Convolution operations. It provides a logical reasoning by explaining that BN can be folded into the Convolution operation, but questions whether BN after ReLU can be folded into the next Convolution operation. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and clarify the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific observation about the BN (Batch Normalization) implementation in the context of ReLU and Convolution operations. It highlights a potential issue with the BN implementation and questions whether BN after ReLU can be folded into the next Convolution operation. However, the comment lacks actionable guidance or suggestions on how the authors might address this observation or incorporate it into their draft. While it identifies a potential area for improvement, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of largescale experiments in the paper, noting that the models used in the experiments are small. It suggests that including experiments that vary the size of the network and show a trend could be beneficial. While the comment implies that the authors should conduct such experiments, it does not provide specific guidance on how to implement this suggestion or what specific network sizes to consider. The action is implicit and somewhat vague, as the authors know they need to expand their experiments but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experiments section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the issue of smallscale experiments and suggests conducting experiments that vary the size of the network to observe trends. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the models used in the experiments are small, specifically mentioning 80 hidden neurons for MNIST and a single convolutional layer with 40 channels for SVHN. The reviewer suggests that including experiments with varying network sizes could provide insights into the scalability of the results. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that smallscale experiments may not extend to larger scales. This makes the claim 3, as the authors would need to conduct additional experiments to substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the models used in the experiments are small, with 80 hidden neurons for MNIST and a single convolutional layer with 40 channels for SVHN. It suggests that including experiments with varying network sizes could provide insights into the scalability of the results. This feedback is clear and actionable, as it guides the authors to consider expanding their experiments to larger scales, which could enhance the robustness and generalizability of their findings. However, the comment could be more helpful if it provided specific examples or suggestions for how to conduct these experiments or what trends to look for. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the implications of using an identity matrix for W and how the results would compare to prior work. While it raises an interesting point, it does not provide explicit guidance or suggestions on how the authors should address this question or what specific actions they should take to explore it. The comment lacks concrete instructions or actionable steps, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implications of using an identity matrix for W and how the results would compare to prior work. However, it does not specify which part of the paper this question pertains to, such as a particular section or result. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its inquiry about the comparison with prior work, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking about the implications of using an identity matrix for W and how the results would compare to prior work. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting question about the implications of using an identity matrix for W and how the results would compare to prior work. This question prompts the authors to explore a specific scenario that could provide valuable insights into the robustness or limitations of their approach. However, the comment does not provide any guidance or suggestions on how the authors might address this question or what specific aspects they should consider. While it highlights an area for further exploration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it identifies a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work primarily focuses on CO problems on graphs, which limits its application scope compared to general MILP or QUBO problems. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might broaden their application scope or what specific changes could be made to achieve this. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a limitation in the scope of the work, specifically that it focuses on CO problems on graphs rather than general MILP or QUBO problems. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of application scope, it lacks grounding as it does not provide clear guidance on where this issue is discussed in the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work focuses on CO problems on graphs, which limits its application scope compared to general MILP or QUBO problems. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the work, noting that it primarily focuses on CO problems on graphs rather than general MILP or QUBO problems. This observation highlights a potential area for expansion in the application scope of the research. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might broaden their application scope or integrate general MILP or QUBO problems into their work. While it points out an important consideration, the feedback could be more helpful if it offered actionable advice or examples. Therefore, the comment is 3, as it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors have not analyzed or compared their work to existing methods that promote the learning of both low and highfrequency information in balance. It explicitly mentions several related works, such as 1 Stochastic Frequency Masking to Improve SuperResolution and Denoising Networks, and provides references to these works. The comment suggests that the authors should include an analysis or comparison with these related works to strengthen their contribution. While the action is explicit, it lacks concrete guidance on how to conduct this analysis or comparison, such as suggesting specific aspects to focus on or providing a framework for the analysis. Therefore, the comment is 3, as it identifies a clear area for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific works that the authors should analyze or compare their work to, providing clear references to related literature. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what needs to be addressed, namely the lack of analysis or comparison with existing works that promote the learning of both low and highfrequency information in balance. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors have not analyzed or compared their work to existing methods that promote the learning of both low and highfrequency information in balance. The comment provides specific references to four related works that have explored similar approaches, such as \"Stochastic Frequency Masking to Improve SuperResolution and Denoising Networks\" and others. This extensive list of references supports the claim by providing a clear and detailed basis for the assertion, making the comment 5. The authors can use this information to understand the context and improve their draft by incorporating these references into their analysis.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the authors have not analyzed or compared their work to existing methods that promote the learning of both low and highfrequency information in balance. It provides specific references to related works, such as \"Stochastic Frequency Masking to Improve SuperResolution and Denoising Networks\" and others, which can help the authors understand the context and improve their contribution. However, the comment could be more helpful by suggesting how the authors might incorporate these references into their analysis or by providing guidance on how to conduct a meaningful comparison. Overall, the comment is 4 as it directs the authors to a specific area for improvement but lacks detailed actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the compression bandwidth of PC+IDF compared with IDF should be recommended in Section 5. However, it does not provide explicit guidance on how to implement this recommendation or what specific aspects of the comparison should be highlighted. The action is implicit, as the authors can infer that they need to include a comparison, but it lacks concrete details on how to execute this recommendation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec. 5,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by recommending a comparison between the compression bandwidth of PC+IDF and IDF. This provides clear guidance on what needs to be addressed in Section 5. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the compression bandwidth of PC+IDF compared with IDF should be recommended in Section 5. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the compression bandwidth of PC+IDF compared with IDF should be recommended in Section 5. However, it lacks specificity and does not provide any guidance on how to implement this recommendation or what aspects of the comparison should be highlighted. Without detailed feedback or actionable suggestions, the authors are left without clear direction on how to improve their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but does not offer substantial guidance for the authors to follow."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model names T5ind and T5seq are misleading and proposes alternative names such as Descind/seq, Egind, Demoind/seq. While the comment implies that the authors should consider these alternative names, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should adopt the suggested names. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the model names T5ind and T5seq are misleading and proposes alternative names. However, it does not specify which part of the paper discusses these model names, making it difficult for the authors to identify the exact section that needs revision. The comment is specific in suggesting alternative names, but it lacks grounding as it does not point to a particular section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the model names T5ind and T5seq are misleading and proposes alternative names. However, it does not provide any justification or reasoning for why these names are misleading or how the alternative names would be more appropriate. Without supporting evidence or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the naming of models, suggesting that the current names (T5ind, T5seq) are misleading. It proposes alternative names, such as Descind/seq, Egind, and Demoind/seq, which could be more descriptive and less ambiguous. This feedback is clear and actionable, as it provides specific suggestions for improving the clarity and professionalism of the model naming in the paper. However, the comment could be more helpful if it explained why the current names are misleading or how the proposed names would address that issue. Overall, the comment is 4 as it offers a clear direction for improvement, but it could be more comprehensive with additional context or explanation."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the choice of the acronym \"AR\" for \"artificial intelligence\" and notes that it is used again in line 055. While it implies that the authors should clarify the acronym, it does not provide explicit instructions or concrete guidance on how to address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the acronym and ensure consistency in its usage. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 055,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of the acronym \"AR\" for \"artificial intelligence\" and noting its inconsistent use. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a question and observation about the use of the acronym \"AR\" for \"artificial intelligence.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The comment raises a question about the choice of the acronym \"AR\" for \"artificial intelligence\" and notes its inconsistent use in line 055. While it identifies a potential issue with the acronym\"s consistency, it does not provide any suggestions or guidance on how the authors might address this issue. The feedback is 3 as it highlights a specific area for attention, but it lacks depth and actionable advice, making it 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity regarding the motivation behind the gating design for multitask learning (MTL) and suggests that the concept is not new. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the lack of motivation or clarify the novelty of their approach. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the core idea of the paper, which is to find a parameter to control the ratio of taskspecific features to taskshared features. It also mentions the motivation behind the gating design for multitask learning (MTL) and notes that the gating mechanism is not a new story in MTL. However, the comment does not specify which part of the paper discusses the gating design or the motivation for the core idea, making it weakly grounded. The comment is specific in identifying the lack of clarity and novelty regarding the gating mechanism. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation behind the gating design for multitask learning (MTL) is not clear and that the concept is not new. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The absence of detailed reasoning or evidence weakens the verifiability of the claim, leaving the authors uncertain about the validity of the critique. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the motivation behind the gating design for multitask learning (MTL) and suggests that the concept is not new. This feedback highlights a potential weakness in the paper\"s originality and provides a specific area for the authors to address. However, the comment does not offer any suggestions or guidance on how the authors might improve the motivation or clarify the novelty of their approach. While it points out an area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment states that the experimental part is less convincing, specifically mentioning that the LR and SVMbased baselines are too weak compared to deep learning approaches. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the experimental setup, what specific aspects need to be enhanced, or how to address the perceived weakness in the baselines. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the experimental part, specifically mentioning that the LR and SVMbased baselines are too weak compared to deep learning approaches. However, it does not specify which part of the experimental section this critique is based on, such as specific experiments or comparisons. This lack of detail makes it difficult for the authors to pinpoint the exact areas needing improvement. While the comment is specific in its critique, it is 1 as it does not provide clear guidance on which parts of the paper should be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experimental part is less convincing, specifically noting that the LR and SVMbased baselines are too weak compared to deep learning approaches. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific weakness in the experimental part of the paper, noting that the LR and SVMbased baselines are too weak compared to deep learning approaches. This feedback is 3 as it highlights an area that needs improvement, prompting the authors to reconsider their choice of baselines. However, the comment lacks depth and does not provide specific suggestions or guidance on how to enhance the experimental setup or compare the baselines more effectively. To be more helpful, the comment could include recommendations on alternative approaches or metrics for comparison. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of discussion on the communication cost in the motivation and contributions of the GLASU algorithm. It highlights that neither the theorem nor the experiment address this aspect, which is crucial for understanding the paper\"s contribution. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors need to infer that they should include a discussion on communication cost in their paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"GLASU algorithm\" and the \"theorem\" and \"experiment,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of discussion on the communication cost in the motivation and contributions of the GLASU algorithm. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a discussion on the communication cost, which is a critical aspect of the motivation and contribution of the GLASU algorithm. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issue or how to address it. The lack of detailed justification or evidence weakens the verifiability of the claim, making it challenging for the authors to improve their draft based on this feedback. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper regarding the communication cost, which is a critical aspect of the motivation and contribution of the GLASU algorithm. It points out that neither the theorem nor the experiment discuss the communication cost, which undermines the paper\"s contribution. This feedback is clear and actionable, as it directs the authors to address a key omission in their work. However, the comment could be more helpful if it provided specific suggestions on how to incorporate a discussion on communication cost or examples of how to present this information effectively. Overall, the comment is 4 as it highlights an important area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the contributions of the paper should be explicitly stated. This provides a clear and direct action for the authors to take, which is to clearly outline the contributions of their work. The comment is specific in its request, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the contributions of the paper should be explicitly stated, but it does not specify which part of the paper this refers to. Without explicit references to sections, figures, or specific elements, the authors cannot confidently determine where the contributions are discussed or need clarification. Additionally, the comment lacks specificity regarding what aspects of the contributions need to be explicitly stated. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the contributions of the paper should be explicitly stated. However, it does not provide any reasoning, examples, or references to support why this is necessary or how it would benefit the paper. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the contributions of the paper should be explicitly stated. While it identifies a potential area for improvement, it lacks specificity and does not provide guidance on how the authors might address this issue. The comment does not offer any suggestions or examples of how to clearly articulate the contributions, making it 3. The authors are left with a general direction but without detailed guidance on how to implement the suggestion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the motivation and explanation of the work, suggesting that the authors should justify the statement about semantic conflicts caused by different densities either experimentally or theoretically. While the comment implies that the authors should provide additional justification, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include experimental or theoretical justification for the statement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the motivation and explanation of the work, specifically mentioning the statement about \"different densities directly will cause semantic conflicts.\" This provides some grounding as the authors can infer that the comment relates to the motivation section. However, it lacks specificity because it does not detail which part of the explanation is unclear or how the authors should justify the statement. The comment suggests that the authors should provide experimental or theoretical justification, but it does not specify where in the paper this justification should be included. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the motivation and explanation of the work are not clear and that the statement about \"different densities directly will cause semantic conflicts\" should be justified experimentally or theoretically. While the comment identifies a potential issue with the explanation, it lacks specific examples or detailed reasoning to support the claim. The suggestion to justify the statement is logical, but without further elaboration or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the motivation and explanation of the work, specifically regarding the statement about \"different densities directly will cause semantic conflicts.\" It suggests that this point should be justified experimentally or theoretically, providing a clear direction for improvement. However, the comment could be more helpful if it offered specific suggestions on how to conduct these justifications or examples of how to approach the justification. Overall, the feedback is 3 as it highlights an area for improvement and provides a basis for further elaboration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the training method of the three transformer modules in the proposed approach, specifically whether they are trained iteratively or endtoend. It also critiques the visualization in Figure 5, noting that it is similar to Figure 1 and suggesting that repeating the visualization may not be necessary. While the comment raises a question and critiques a figure, it does not provide explicit guidance on how the authors should address these issues. The authors are left to infer that they need to clarify the training method and possibly reconsider the inclusion of Figure 5. The action is implicit and somewhat vague, as the authors need to determine the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the training method of the three transformer modules and critiques the visualization in Figure 5, suggesting that it may not be necessary to repeat the visualization if no new point is demonstrated. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the training method of the three transformer modules and critiques the visualization in Figure 5, suggesting that it may not be necessary to repeat the visualization. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the training method or visualization is important. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a question about the training method of the three transformer modules in the proposed approach, specifically whether they are trained iteratively or endtoend. It also critiques the visualization in Figure 5, noting that it is similar to Figure 1 and suggesting that repeating the visualization may not be necessary. While the comment identifies a potential issue with the visualization, it does not provide specific guidance or suggestions on how the authors might address these concerns. The feedback is 3 as it highlights areas for improvement, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the writing could be more precise and clear, with specific points for improvement, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also notes that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The comment implies that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations not due to BFNs. While the comment provides some guidance, it lacks explicit instructions on how to implement these suggestions, making it 3.", "grounding_specificity_rationale": "The comment suggests that the writing could be more precise and clear, with specific points for improvement, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also notes that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The comment implies that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations not due to BFNs. However, the comment does not specify which sections or parts of the paper need these improvements, making it weakly grounded. The specificity of the comment is moderate as it provides clear suggestions for improvement but lacks detailed guidance on how to implement them. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the writing could be more precise and clear, with specific examples provided for improvement, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also notes that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The comment implies that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations not due to BFNs. While the comment provides some direction for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. Therefore, the comment is 3, as it provides a general suggestion but requires more detailed justification or examples to be fully actionable.", "helpfulness_rationale": "The review comment identifies a need for greater precision and clarity in the writing, providing specific examples of areas for improvement, such as distinguishing between \"parameters of BFNs\" and \"parameters of BFNproduced distributions.\" It also notes that the proposed method is closely related to infoDiffusion, with the main adaptation being its application to BFNs. The comment suggests that the authors should explicitly outline the unique contributions of ParamReL, distinguishing it from infoDiffusion by clarifying any innovations not due to BFNs. While the comment provides some valuable feedback on improving the clarity and precision of the writing, it could be more helpful by offering specific suggestions or examples of how to address these issues. Overall, the comment is 3 as it highlights areas for improvement but lacks detailed guidance for the authors to fully benefit from it."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential issue with the paper\"s focus on a specific aspect of the gradient of the sum of losses not being the sum of individual gradients. It suggests that this point is not clearly communicated in the text and that the paragraph in question could be discussed in less space. The comment implies that the authors should clarify this point and possibly reduce the space allocated to it. However, it does not provide specific guidance on how to address the issue or what specific changes should be made to improve the communication. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the point and possibly reduce the space allocated to it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the discussion in lines 6074, which corresponds to the beginning of Section 2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue: the authors want to focus on a situation where the gradient of the sum is not the sum of the individual gradients, but this is not communicated in the text. It also suggests that the paragraph in question could be discussed in less space and provides a rationale for the situation being rare and requiring some space. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors want to focus on a situation where the gradient of the sum is not the sum of the individual gradients, but this is not communicated in the text. The reviewer suggests that this paragraph could be discussed in less space and provides a rationale for why this situation is rare and requires some space. However, the comment lacks specific examples or references to support the claim that this situation is rare or why it is important. The reasoning is somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper\"s focus on a specific aspect of the gradient of the sum of losses not being the sum of individual gradients. It highlights that this point is not clearly communicated in the text and suggests that the paragraph in question could be discussed in less space. The comment provides a clear and actionable feedback by pointing out the need for better communication and suggesting a reduction in the space allocated to this specific aspect. However, it could be more helpful if it offered specific suggestions on how to improve the communication or examples of how to present this information more effectively. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their draft that needs clarification and could be expanded upon."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses concern about the proposed questionrewrite strategy, noting that it does not cover a sufficiently large number of questions. The reviewer provides specific data, such as the percentage of invalid questions and the impact on different models, which suggests that the method is not effective. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the strategy. The action is implicit and vague, as the authors are left to infer that they need to reconsider the questionrewrite strategy or find ways to increase its effectiveness. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed questionrewrite strategy and provides specific data, such as the percentage of invalid questions and the impact on different models. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it details the concern regarding the coverage of questions and provides numerical data to support the claim, such as the percentage of invalid questions and the impact on different models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the proposed questionrewrite strategy, specifically questioning its effectiveness in covering a sufficient number of questions. The reviewer provides specific data, such as the percentage of invalid questions and the impact on different models, which supports the claim. This detailed information helps the authors understand the issue and provides a basis for evaluating the claim. However, the comment could be strengthened by referencing specific studies or comparisons that have shown similar strategies to be effective. Overall, the claim is 4 due to the detailed data provided, but it could be further strengthened with additional references or comparisons.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the proposed questionrewrite strategy, noting that it does not cover a sufficiently large number of questions. The reviewer provides detailed data, such as the percentage of invalid questions and the impact on different models, which highlights the limitations of the method. This feedback is clear and actionable, as it guides the authors to reconsider the effectiveness of their strategy and potentially explore ways to improve it. However, the comment could be more helpful if it offered suggestions on how to address these limitations or alternative strategies to consider. Overall, the comment is 4, as it provides valuable insight into a critical area of the paper that needs attention."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the description of the related work is scattered throughout the paper and suggests that a broader discussion comparing the algorithm to other offline RL algorithms would be beneficial. While the comment implies that the authors should include a more comprehensive discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand their related work section. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper, noting that the description of the related work is scattered throughout the paper. It mentions that most relevant papers, such as 14,15, are included but suggests a broader discussion on how the algorithm compares to other offline RL algorithms. However, the comment does not specify which sections of the paper contain these scattered descriptions, making it weakly grounded. The suggestion to include a broader discussion is specific, as it clearly indicates what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the description of the related work is scattered throughout the paper and suggests that a broader discussion comparing the algorithm to other offline RL algorithms would be beneficial. However, the comment does not provide specific examples or references to support this claim, nor does it explain why such a discussion would be necessary or how it would enhance the paper. Without detailed justification or evidence, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the description of the related work is scattered throughout the paper. It highlights the inclusion of relevant papers, such as 14,15, but suggests that a broader discussion comparing the algorithm to other offline RL algorithms would be beneficial. This feedback is 3 as it points out a gap in the paper\"s organization and suggests a way to improve the comparative analysis. However, the comment could be more actionable by providing specific examples or guidance on how to conduct such a comparison. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the impact of having all increments available at the same time on the final solution. While it implies that the authors should consider this scenario, it does not explicitly instruct them to do so or provide guidance on how to address it. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect and may not be entirely sure of the best way to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the impact of having all increments available at the same time on the final solution. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references, the authors may find it challenging to determine where to address this question. Additionally, the comment lacks specificity regarding what aspects of the solution should be considered or how the authors might explore this question. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for clarification about the impact of having all increments available at the same time on the final solution. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the impact of having all increments available at the same time on the final solution. While it identifies a potential area for exploration, it does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the solution should be considered. The comment lacks depth and actionable advice, making it 2. It gives the authors a starting point for further investigation but does not fully support their need for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the convoluted and potentially circular nature of the technique described in the paper. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on how the authors might simplify the technique or clarify its circularity, leaving them without a clear path forward. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the technique of using multiple different feature spaces, specifically mentioning the 25 feature space of Mitchell et. al and the full/pruned glove model. This provides some grounding as the authors can infer that the comment relates to these specific sections of the paper. However, the comment lacks specificity as it does not detail what is convoluted or circular about the technique, nor does it suggest how the authors might address this issue. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the technique of using multiple different feature spaces is convoluted and potentially circular. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the technique described in the paper, specifically the use of multiple different feature spaces. It points out that the approach may be convoluted and potentially circular, which could hinder the clarity and effectiveness of the method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the technique. While it highlights a concern, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it provides some insight but lacks depth and specificity in its guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and to provide their FLOPs and parameter sizes. It also questions why the results of OFA with progressive shrink are not included in the table. This feedback is clear and provides specific actions for the authors to take, making it 5. The authors know exactly what comparisons to add and what information to include, ensuring they can effectively address the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests including comparisons with other works, such as AtomNAS, and provides a rationale for why the results of OFA with progressive shrink should be included. This guidance is clear and provides a concrete direction for improvement, making the comment 5.", "verifiability_rationale": "The review point consists of two parts: a request for additional comparisons with other works using the MobileNetV3 search space and a question about the inclusion of OFA with progressive shrink results in the table. The first part is a request for clarification and does not contain a subjective claim. The second part is a question seeking more information, which also does not constitute a claim. Therefore, the comment is purely factual and descriptive, fitting the \"No\" label.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors include comparisons with other works that use the MobileNetV3 search space, such as AtomNAS, and provide their FLOPs and parameter sizes. It also questions the inclusion of OFA with progressive shrink results in the table, prompting the authors to consider why these results are not included. This feedback is clear and constructive, offering a concrete way to enhance the paper\"s comparative analysis and provide a more comprehensive understanding of the results. By addressing these points, the authors can significantly improve the quality and depth of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors include a brief discussion on why hallucinations are undesirable and to point to existing work. While the comment implies that the authors should address this aspect, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides some guidance on how to implement it by suggesting a discussion on the undesirability of hallucinations. However, it lacks specific details on what aspects of the discussion should be included or how to integrate it into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a brief discussion on why hallucinations are undesirable and to point to existing work. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to include a discussion on the undesirability of hallucinations and to reference existing work, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors include a brief discussion on why hallucinations are undesirable and to point to existing work. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it would benefit the paper. Without additional context or examples, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors include a brief discussion on why hallucinations are undesirable and to point to existing work. This feedback is 3 as it identifies a potential area for improvement in the paper, specifically the need for a discussion on the undesirability of hallucinations. However, the comment lacks depth and does not provide specific guidance on how to incorporate this discussion or what aspects of existing work should be referenced. While it prompts the authors to consider an important aspect of their work, the feedback could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the terms Type1 error, Type2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This feedback highlights a potential issue with the order of information presentation. However, it does not provide explicit guidance on how the authors should reorganize the content or suggest specific changes to improve the clarity of the draft. The action is implicit, as the authors can infer that they need to reorder the information to present the null hypothesis after introducing these terms. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 5054,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the mention of terms like Type1 error, Type2 error, and false positive rate before the null hypothesis is clearly stated. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the order of information presentation in the paper. It mentions specific lines and terms, but it does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the order of information presentation in the paper, noting that certain terms like Type1 error, Type2 error, and false positive rate are mentioned before the null hypothesis is clearly stated. This feedback is clear and actionable, as it highlights a potential issue with the clarity and flow of the paper. However, the comment could be more helpful if it provided suggestions on how to reorganize the content or improve the presentation of these concepts. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the LISA embedding, noting that while the SFAM scorers correlate well with human evaluations on semanticsrelevant styles, they do not correlate well with linguisticrelevant styles. The reviewer suggests that this might make the LISA more contentfocused rather than stylefocused. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the LISA embedding. The action is implicit and vague, as the authors are left to infer that they need to explore or adjust the LISA embedding to better align with linguisticrelevant styles. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the correlation between SFAM scorers and human evaluations on different linguistic styles. It mentions \"semanticsrelevant styles\" and \"linguisticsrelevant styles,\" such as \"simplification\" and \"linguistic acceptability,\" which provides some specificity. However, the comment does not explicitly mention which part of the paper discusses these evaluations, making it weakly grounded. The authors can infer that it relates to sections discussing the evaluation of the LISA embedding, but this inference is not direct. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the SFAM scorers, which are fundamental components of the LISA embedding, do not correlate well with human evaluations on linguisticrelevant styles. The reviewer supports this claim by providing examples of linguisticrelevant styles, such as \"simplification\" and \"linguistic acceptability,\" and suggests that this might make the LISA more contentfocused rather than stylefocused. However, the comment lacks specific data or references to substantiate the claim, such as correlation coefficients or comparisons with other models. This makes the claim 3, as it provides a logical reasoning but requires more detailed evidence to fully support the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the LISA embedding, noting that while the SFAM scorers correlate well with human evaluations on semanticsrelevant styles, they do not correlate well with linguisticrelevant styles. This observation suggests that the LISA embedding might be more contentfocused rather than stylefocused. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the LISA embedding. While it highlights a potential weakness, the feedback lacks actionable advice, making it 3. The authors are left to infer that they need to explore or adjust the LISA embedding to better align with linguisticrelevant styles, but without explicit guidance, the comment is limited in its usefulness. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments should include evaluations on other realworld datasets, specifically DexYCB, using more recent handobject pose estimation pipelines to predict initial handobject poses. This feedback provides a clear and explicit action for the authors to take, as it specifies which datasets and methods should be considered. The suggestion is concrete, as it outlines the exact changes needed to enhance the evaluation. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the experiments on additional realworld datasets, specifically DexYCB, using more recent handobject pose estimation pipelines to predict initial handobject poses. However, it does not specify which part of the paper this suggestion pertains to, such as the methodology or results sections. The authors might infer that it relates to the experimental evaluation, but this inference is not direct. The comment is specific in suggesting additional datasets and methods to consider, but it lacks grounding as it does not explicitly mention the section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the experiments on additional realworld datasets, specifically DexYCB, using more recent handobject pose estimation pipelines to predict initial handobject poses. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this suggestion is beneficial or necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests evaluating the experiments on additional realworld datasets, specifically DexYCB, using more recent handobject pose estimation pipelines to predict initial handobject poses. This feedback is clear and actionable, as it provides a specific direction for enhancing the experimental evaluation. By suggesting the inclusion of DexYCB and more recent methods, the comment offers a concrete way for the authors to expand their evaluation and potentially improve the robustness and applicability of their findings. However, the comment could be more helpful if it included additional context or rationale for why these datasets and methods are particularly relevant. Overall, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper lacks explicit explanations on important components, such as the design of sequential models and how the attention model is updated. This feedback highlights a specific area where the authors need to provide more detailed explanations to enhance the understanding of the proposed work. While the comment identifies a clear area for improvement, it does not provide specific guidance on how to address these issues or what kind of additional information would be beneficial. The action is implicit and somewhat vague, as the authors know they need to provide more detailed explanations but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a lack of explicit explanation on important components, such as the design of sequential models and the update of the attention model. However, it does not specify which part of the paper these components are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the lack of explicit explanations on these components. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks explicit explanations on important components, such as the design of sequential models and the update of the attention model. However, it does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of explicit explanations on critical components, such as the design of sequential models and the update of the attention model. This feedback is valuable as it highlights areas where the authors need to provide more detailed explanations to enhance the understanding of the proposed work. However, the comment could be more helpful if it offered suggestions on how to address these gaps or provided examples of what kind of explanations would be beneficial. Overall, the comment is 3 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors make the entire code accessible if the paper is accepted. This is a direct and explicit action, as it clearly indicates what the authors should do to improve their draft. The comment provides a concrete action, leaving no ambiguity about how the authors should proceed. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the entire code should be made accessible if the paper is accepted. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its suggestion to make the code accessible, but it lacks grounding as it does not specify where in the paper this change should be made. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the entire code should be made accessible if the paper is accepted. However, it does not provide any reasoning, examples, or references to support why this suggestion is necessary or beneficial. Without additional context or justification, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the entire code should be made accessible if the paper is accepted. This is a clear and actionable suggestion that could enhance the reproducibility and transparency of the research. However, the comment does not provide specific guidance on how to implement this suggestion, such as where in the paper the code should be made accessible or how to structure the code for accessibility. While the suggestion is valuable, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the proposed method is an incremental improvement over AutoAugment but notes that the performance improvements are not significant compared to recent methods. It also mentions that the standard deviation (std) is very large, which raises doubts about the generalizability of the results. While the comment identifies specific areas of concern, it does not provide explicit guidance on how the authors should address these issues or suggest specific actions to improve the draft. The feedback is somewhat vague and lacks concrete instructions, making it barely actionable.", "grounding_specificity_rationale": "The comment provides a general critique of the proposed method, noting that it is an incremental improvement over AutoAugment and that the performance improvements are not significant compared to recent methods. It also mentions the large standard deviation (std) and its implications for generalizability. However, the comment does not specify which part of the paper this critique is based on, such as specific sections or results, making it weakly grounded. The comment is specific in detailing the performance comparisons and the issue with generalizability due to the large std. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is an incremental improvement over AutoAugment but notes that the performance improvements are not significant compared to recent methods. It provides a specific example, mentioning that on ImageNet, ResNet50 is only 0.3 better than 18. This specific reference to a particular study supports the claim, making it 4. However, the comment could be strengthened by providing more context or additional comparisons to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a balanced critique of the proposed method, noting that it is an incremental improvement over AutoAugment but highlighting the lack of significant performance improvements compared to recent methods. It also points out the large standard deviation, which raises doubts about the generalizability of the results. While the comment identifies specific areas of concern, it lacks actionable suggestions or detailed guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it directs the authors\" attention to important aspects of their work, but it could be more comprehensive with specific recommendations or suggestions for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a weakness in the comparison section, noting that it lacks references to existing prior arts and that a simple search with respect to the 5 experiment datasets shows significant performance gaps between the proposed method and the latest methods. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific references or comparisons should be included. The action is implicit and somewhat vague, as the authors are left to infer that they need to incorporate references to prior arts and conduct additional comparisons. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison section of the paper, specifically mentioning the lack of references to existing prior arts and the performance gaps between the proposed method and the latest methods. However, it does not specify which part of the paper this comparison is made in, making it weakly grounded. The comment is specific in detailing the issue of weak comparison and the performance gaps, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison is weak without references to existing prior arts, such as 1. It also mentions that a simple search with respect to the 5 experiment datasets shows significant performance gaps between the proposed method and the latest methods. While the comment provides some evidence of the issue, it lacks specific references or detailed examples to fully substantiate the claim. The mention of \"a simple search\" adds some context, but more detailed information or references would be needed for the claim to be 5. Therefore, the comment is 3, as it provides a basis for the claim but requires additional evidence to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a significant issue with the comparison section of the paper, noting that it lacks references to existing prior arts and that a simple search with respect to the 5 experiment datasets shows significant performance gaps between the proposed method and the latest methods. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to provide a more comprehensive comparison with relevant prior work. However, the comment could be more helpful if it offered specific suggestions on how to address these gaps or provided examples of relevant prior arts. Overall, the comment is 3 as it points out a clear weakness but lacks detailed guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide a quantification of the data diversity, suggesting that even a shallow types vs. token statistic would be useful. This feedback is clear and provides a direct action for the authors to take, making it 5. The comment is specific in its request for a quantification, which gives the authors a concrete direction to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide a quantification of the data diversity, implying that this aspect is not adequately addressed in the paper. However, it does not specify which part of the paper discusses the data diversity or where the quantification should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in suggesting the need for quantification, but without clear grounding, it is challenging for the authors to know where to make the necessary changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a quantification of the data diversity, implying that this aspect is not adequately addressed. The comment is 3 as it suggests a specific type of quantification (types vs. token statistic) that could be useful. However, it lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to infer the need for quantification and understand the suggestion, which limits the verifiability of the comment.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of quantification regarding the diversity of the data gathered. It suggests that even a simple types vs. token statistic would be useful, providing a clear and actionable suggestion for the authors to enhance their draft. This feedback is 4 as it directs the authors to a concrete step they can take to address a perceived weakness in their work. However, it could be more helpful if it offered additional guidance on how to implement this suggestion or provided examples of what a types vs. token statistic might look like. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of support for the claim that the paper created a more diverse set of positive instance pairs. It highlights the absence of a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or what specific measures or comparisons should be included. The action is implicit and somewhat vague, as the authors need to infer that they should include a measure of diversity and compare it with earlier works. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim that the paper created a more diverse set of positive instance pairs, but it does not specify which part of the paper this claim is made in, making it weakly grounded. It does specify the issue, which is the lack of a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. This provides some level of specificity, as the authors know what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper created a more diverse set of positive instance pairs but lacks sufficient support. It mentions the absence of a suggested measure of diversity and a comparison with earlier works regarding the diversity of examples. This provides some level of justification, as it highlights the need for a measure of diversity and a comparison with previous studies. However, the comment could be strengthened by providing specific examples or references to existing measures of diversity and comparisons with earlier works. Therefore, the claim is 4, as it is supported by logical reasoning but lacks detailed evidence or references.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of a suggested measure of diversity for the positive instance pairs and the absence of a comparison with earlier works regarding the diversity of examples. This feedback is clear and actionable, as it directs the authors to include specific measures of diversity and comparisons with prior studies to substantiate their claim. By addressing this issue, the authors can significantly enhance the credibility and robustness of their findings. However, the comment could be more helpful if it provided examples of measures of diversity or suggested specific comparisons with earlier works. Overall, the comment is 4, as it effectively highlights a critical area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about how the authors\" approach compares to or aligns with other inputs, specifically mentioning the AUCROC metric. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on what the authors should do to address this question or how they might improve their approach in light of the comparison. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the comparison of the approach with other inputs, specifically mentioning the AUCROC metric. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its request for a comparison with other inputs, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the comparison of the approach with other inputs, specifically mentioning the AUCROC metric. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the AUCROC is \"pretty high\" in other models. Without additional context or justification, the claim remains 1. The authors would need to make significant effort to understand and address the question raised in the comment, making it difficult to provide a clear and actionable response. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a relevant question about the comparison of the authors\" approach with other inputs, specifically mentioning the AUCROC metric. It points out that the AUCROC is \"pretty high\" in other models in the literature, which could imply that the authors\" approach might not be as novel or competitive as it appears. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential area for improvement, the feedback is vague and lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests several actions for improvement. First, it recommends stating the objective function in experiments, using Monte Carlo estimates of the expectations. This is an explicit action that the authors can take to enhance their paper. Second, it questions the use of a reverse inequality sign in Equation 7, suggesting that it might be incorrect given the definition of v as the expected loss. This is another explicit action that the authors can address. Third, the reviewer points out that sections 3.2 and 4 are technical but do not effectively explain the main method, suggesting that more space be allocated to explaining the training procedure in section 4. This is a concrete suggestion for improvement. Overall, the comment provides multiple explicit and concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.2\" and \"section 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, such as stating the objective function in experiments with Monte Carlo estimates, questioning the use of a reverse inequality sign in Equation 7, and suggesting that more space be allocated to explain the training procedure in section 4. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: questioning the use of a reverse inequality sign in Equation 7 and suggesting that more space be allocated to explain the training procedure in section 4. The first part is based on a logical reasoning about the definition of v as the expected loss, which is a common concept in machine learning. However, the comment does not provide specific examples or references to support the claim about the reverse inequality sign. The second part is a suggestion for improvement, not a claim, and thus does not require verification. Overall, the comment is 3 due to the lack of detailed justification for the first part, making it a 3.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improving the paper. It suggests that the authors should state the objective function in experiments using Monte Carlo estimates of the expectations, which could enhance the clarity and reproducibility of the work. Additionally, it questions the use of a reverse inequality sign in Equation 7, suggesting that it might be incorrect given the definition of v as the expected loss. This feedback is clear and could help the authors correct any potential errors in their mathematical formulation. Furthermore, the comment points out that sections 3.2 and 4 are technical but do not effectively explain the main method, suggesting that more space be allocated to explain the training procedure in section 4. This is a constructive suggestion that could improve the accessibility of the paper to a broader audience. Overall, the comment is 4 as it provides specific and actionable feedback that can guide the authors in enhancing their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the Disc. reward for SPACE and fPCPO in Grid, specifically in the top right plot of Figure 3. The reviewer explicitly asks for an explanation of this observation, which provides a clear and direct action for the authors to take. However, the comment does not provide specific guidance on how to address this issue or what kind of explanation is expected. While the action is explicit, the lack of detailed instructions on how to improve the explanation makes the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Grid (Fig.3, top right plot),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is explaining why the Disc. reward for SPACE and fPCPO is going down in Grid. This provides clear guidance on what the authors need to address in their paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for an explanation of a specific observation in the paper, without making any subjective claims, opinions, or suggestions. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the Disc. reward for SPACE and fPCPO in Grid, as depicted in Figure 3, top right plot. It prompts the authors to explain why this particular metric is decreasing. This feedback is clear and actionable, as it directs the authors to address a specific aspect of their results that requires further explanation. However, the comment could be more helpful if it provided additional context or suggested potential reasons for the observed trend. Despite this, the feedback is 4 as it identifies a critical area for clarification and improvement in the paper."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that key implementation details are missing, specifically mentioning the resolutions at which images successfully achieve adversarial effects. This provides a clear and direct action for the authors to take, which is to include these details in their draft. The comment is specific and concrete, as it identifies exactly what information is missing and how it should be presented. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"key implementation details,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the resolutions at which images successfully achieve adversarial effects. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that key implementation details are missing, specifically mentioning the resolutions at which images successfully achieve adversarial effects. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these details are important or how they impact the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of the missing details and how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of key implementation details, particularly regarding the resolutions at which images successfully achieve adversarial effects. This feedback is clear and actionable, as it directs the authors to include these details in their draft, which is crucial for understanding the experimental setup and results. By addressing this feedback, the authors can enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to present these details effectively. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the current approach of using DDIM Inversion for all videos to obtain motion guidance for training is effective but does not significantly simplify the overall complexity. It recommends exploring improvements to the motion guidance strategy to enhance training efficiency. While the comment implies that the authors should consider optimizing the motion guidance strategy, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to improve the motion guidance strategy. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section on data preprocessing, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the current approach, which involves using DDIM Inversion on all videos to obtain motion guidance for training, and suggests that exploring improvements to the motion guidance strategy itself could enhance training efficiency. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current approach of using DDIM Inversion on all videos to obtain motion guidance for training is effective but does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy to enhance training efficiency. However, the comment lacks specific examples or detailed reasoning to support why the current approach is insufficient or how improvements could be made. Without concrete evidence or references, the claim remains 3, as it provides a general suggestion without detailed justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the data preprocessing section, noting that while the approach of using DDIM Inversion to obtain motion guidance for training is effective in reducing training time, it does not significantly simplify the overall complexity. The reviewer suggests exploring improvements to the motion guidance strategy itself to enhance training efficiency. This feedback is clear and actionable, as it provides a direction for the authors to consider optimizing their preprocessing approach. However, the comment could be more helpful if it offered specific suggestions or examples of how to improve the motion guidance strategy. Overall, the comment is 4, as it guides the authors toward a potential improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the statistics of relation phrases and the impact of chunking them into phrases on the prediction of rare relation phrases. It also mentions the disadvantage of seeing individual words instead of phrases and the problem of a heavy tail in relations compared to words. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these concerns or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the statistics of relation phrases and the impact of chunking them into phrases on the prediction of rare relation phrases. It also mentions the disadvantage of seeing individual words instead of phrases and the problem of a heavy tail in relations compared to words. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or experiments. This makes it difficult for the authors to pinpoint the exact areas needing attention. While the comment is specific in its questions, it lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the statistics of relation phrases and the impact of chunking them into phrases on the prediction of rare relation phrases. It also mentions the disadvantage of seeing individual words instead of phrases and the problem of a heavy tail in relations compared to words. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate these claims. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises questions about the statistics of relation phrases and the impact of chunking them into phrases on the prediction of rare relation phrases. It highlights a potential disadvantage of seeing individual words instead of phrases, which could lead to a heavy tail problem in relations compared to words. While the comment identifies an area of concern, it lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it prompts the authors to consider the implications of their approach, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a potential issue with the robustness of the method in dynamic regions, particularly in the Bonn dataset where moving objects occupy a significant portion of the image. It suggests that the authors consider more robust approaches, such as using segmentation masks to mask out dynamic regions or rerunning relative pose estimation after identifying dynamic regions. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Bonn dataset\" and the issue of moving objects occupying over 50% of the image, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear example of a potential issue and suggests specific solutions, such as using segmentation masks or rerunning relative pose estimation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements\" is generally true but acknowledges the need for more robust approaches in edge cases, such as the Bonn dataset where moving objects occupy over 50% of the image. The reviewer provides a specific example of the Bonn dataset and suggests potential solutions, such as using segmentation masks or rerunning relative pose estimation. This level of detail and specificity supports the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or references to similar approaches in the literature. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the robustness of the method in dynamic regions, particularly in the Bonn dataset where moving objects occupy a significant portion of the image. It acknowledges that the statement \"For most scenes, where most pixels are static, random samples of points will place more emphasis on the static elements\" is generally true but highlights the need for more robust approaches in edge cases. The comment provides specific examples and suggests potential solutions, such as using segmentation masks to mask out dynamic regions or rerunning relative pose estimation after identifying dynamic regions. This feedback is clear and actionable, offering the authors a concrete way to enhance the robustness of their method. However, it could be more helpful if it included additional context or explanation on why these solutions are necessary or how they might impact the overall performance of the method. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments primarily focus on comparing the models proposed by the authors and do not include comparisons with other methods. While it identifies a gap in the experimental design, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include comparisons with other methods, but it lacks concrete instructions on which methods to include or how to structure these comparisons. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the experiments, noting that they only compare the models proposed by the authors and lack comparison with other methods. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for comparisons with other methods, but without clear grounding, the authors may struggle to pinpoint the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments lack comparison with other methods, which is a subjective observation. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the experimental section, noting that the experiments primarily focus on comparing the models proposed by the authors and do not include comparisons with other methods. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to broaden their comparative analysis. However, the comment lacks specific suggestions or guidance on how to incorporate these comparisons, such as recommending additional methods to include or how to structure the comparisons effectively. While it points out an important issue, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a minor issue regarding the presentation of models in Table 3 and 4, noting that the MAVIS models are considered math specialists but lack a specific indicator (*). The reviewer suggests that these models should also be marked with a * to align with the presentation of other models. While the comment implies that the authors should add a * to the MAVIS models, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3 and 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the lack of a * on the MAVIS models, which are considered math specialists, while other models in the tables are marked with a *. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the presentation of models in Table 3 and 4, specifically noting the lack of a * on the MAVIS models. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of models in Table 3 and 4, noting that the MAVIS models are considered math specialists but lack a specific indicator (*). This feedback is clear and actionable, as it provides a direct suggestion for improvement by recommending that the MAVIS models also be marked with a * to align with the presentation of other models. By addressing this issue, the authors can enhance the clarity and consistency of their presentation, making the comment 4. However, it could be more helpful if it included additional context or suggestions on how to improve the overall presentation of the models. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the technical novelty of the work is limited, specifically mentioning that KNNbased methods are widely studied in fields like language modeling and machine translation. It suggests that the work provides few insights into a nonparametric method for text classification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the perceived limitation in novelty or how they could enhance the insights provided by their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical novelty of the work, specifically mentioning that KNNbased methods are widely studied in fields like language modeling and machine translation. It suggests that the work provides few insights into a nonparametric method for text classification. However, the comment does not specify which part of the paper discusses these methods or where the novelty is claimed, making it weakly grounded. The comment is specific in its critique of the novelty and the lack of insights, but without clear grounding, the authors may struggle to identify the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical novelty of the work is limited, specifically mentioning that KNNbased methods are widely studied in fields like language modeling and machine translation. The reviewer suggests that the work provides few insights into a nonparametric method for text classification. This claim is 3 as it references the widespread use of KNNbased methods in related fields, which provides a basis for the critique. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a limitation in the technical novelty of the work, specifically noting that KNNbased methods are widely studied in fields like language modeling and machine translation. It suggests that the work provides few insights into a nonparametric method for text classification. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. The feedback is 3 as it points out a direction for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper emphasizes the enhancement of the IM for most existing RL algorithms but lacks a comparison with the latest work, particularly nonpixelbased approaches. It suggests that the description of the mainstream RL algorithms in related work is somewhat outdated, as it only mentions SAC in 2018. The comment implies that the authors should include a comparison with more recent works to provide a more comprehensive overview. However, it does not explicitly instruct the authors to make this comparison or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison with more recent works, but they are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s emphasis on enhancing the IM for most existing RL algorithms but points out that the most recent description of mainstream RL algorithms in related work is limited to SAC in 2018. It suggests that the paper lacks a comparison with the latest work, especially nonpixelbased approaches to solving data efficiency. However, the comment does not specify which part of the paper discusses the related work or where the authors should include this comparison. This makes it weakly grounded, as the authors cannot confidently determine which sections need revision. The comment is specific in its critique of the lack of comparison with recent work, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s emphasis on enhancing the IM for most existing RL algorithms is overstated, as it only mentions SAC in 2018 as the most recent description of mainstream RL algorithms. The reviewer suggests that the paper lacks a comparison with the latest work, especially nonpixelbased approaches to data efficiency. However, the comment does not provide specific examples or references to more recent works, making it difficult for the authors to fully understand and address the critique. The lack of detailed evidence or references makes the claim 3, as the authors would need to conduct further research to substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential overstatement in the paper regarding the emphasis on enhancing the IM for most existing RL algorithms, noting that the most recent description of mainstream RL algorithms in related work is limited to SAC in 2018. It suggests that the paper lacks a comparison with the latest work, especially nonpixelbased approaches to data efficiency. This feedback is 3 as it highlights a gap in the paper\"s literature review and suggests that the authors should include a more comprehensive comparison with recent work. However, the comment could be more helpful if it provided specific examples of recent works or guidance on how to incorporate them into the paper. Overall, the comment offers a direction for improvement but lacks detailed instructions, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to expand the background discussion in Section 2 and related work by incorporating further background knowledge on adversarial examples and the distinctions between whitebox, greybox, and blackbox threat models in the context of poisoning. It also suggests referencing relevant surveys to clarify the threat model and position, which would help nonexpert readers understand these distinctions. The comment provides clear and concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2\" and \"related work,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be expanded, namely the background discussion on adversarial examples and the distinctions between whitebox, greybox, and blackbox threat models in the context of poisoning. Additionally, it suggests referencing relevant surveys to clarify the threat model and position, which would help nonexpert readers understand these distinctions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests expanding the background discussion in Section 2 and related work to include further background knowledge on adversarial examples and the distinctions between whitebox, greybox, and blackbox threat models in the context of poisoning. It also recommends referencing relevant surveys to clarify the threat model and position. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that the current background discussion is insufficient. This makes the claim 3, as the authors would need to identify and address the specific areas needing expansion on their own.", "helpfulness_rationale": "The review comment provides clear and actionable feedback by suggesting that the authors expand the background discussion in Section 2 and related work to include further background knowledge on adversarial examples and the distinctions between whitebox, greybox, and blackbox threat models in the context of poisoning. It also recommends referencing relevant surveys to clarify the threat model and position, which would help nonexpert readers understand these distinctions. This feedback is 4 as it offers specific directions for improvement, but it could be more comprehensive by providing examples of relevant surveys or more detailed guidance on how to incorporate this additional information. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses confusion about the importance of the proposed multiplespan answer setting in realworld applications. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might clarify this point or address the reviewer\"s concern. Without any actionable steps or suggestions, the authors are left without direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses confusion about the importance of the proposed multiplespan answer setting in realworld applications. However, it does not specify which part of the paper this concern pertains to, making it difficult for the authors to identify the exact section that needs clarification. Additionally, the comment lacks specificity regarding what aspects of the multiplespan answer setting are unclear or how they might be clarified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses confusion about the importance of the proposed multiplespan answer setting in realworld applications. However, it does not provide any supporting evidence, reasoning, or examples to clarify this point. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses confusion about the importance of the proposed multiplespan answer setting in realworld applications. However, it does not provide any specific guidance or suggestions on how the authors might clarify this point or address the reviewer\"s concern. Without actionable feedback or detailed insights, the authors are left without a clear path to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the inclusion of train set examples with hypernyms and nonhypernyms in the \"Testsets\" section. However, it does not provide explicit guidance or suggestions on how the authors should address this question or what changes might be beneficial. The action is implicit, as the authors can infer that they might need to consider including these examples, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide clear instructions on how to execute it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Testsets\" and \"574ff,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the inclusion of train set examples with hypernyms and nonhypernyms, providing clear guidance on what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification on the inclusion of train set examples with hypernyms and nonhypernyms in the \"Testsets\" section. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inclusion of train set examples with hypernyms and nonhypernyms in the \"Testsets\" section. While it identifies a potential area for consideration, it does not provide specific guidance or suggestions on how the authors might address this issue or what benefits could be gained from including these examples. The comment lacks depth and actionable advice, making it 3 as it prompts the authors to think about a potential improvement but does not fully support their need for guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for the results of the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in the table. This direct request for additional results provides clear and concrete guidance on what the authors need to do to improve their draft. The action is explicit and specific, leaving no ambiguity about how the authors should respond to the comment. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing the results for the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in the table. This provides clear guidance on what additional information is needed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional results, specifically asking for the results of the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in the table. This is a factual request for information and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment requests additional results for the AdpCLR_full approach for the ResNet50 (1x, 2x, 4x) architecture, similar to the results provided for AdpCLR_pre in the table. This feedback is specific and actionable, as it clearly identifies a missing piece of information that could enhance the comprehensiveness and clarity of the paper. By providing this additional data, the authors can better understand the performance of their approach across different configurations. However, the comment could be more helpful if it suggested how to present or analyze these results. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the similarity of N trajectories to the concept of replay in the Dyna model. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should explore this similarity, how it might impact their work, or what specific changes they should make to address this question. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the similarity of N trajectories to the concept of replay in the Dyna model. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what the reviewer is seeking clarification on or how it might impact the paper. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the similarity of N trajectories to the concept of replay in the Dyna model. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the similarity of N trajectories to the concept of replay in the Dyna model. While it identifies a potential area of confusion or misunderstanding, it does not provide any guidance or suggestions on how the authors might address this issue or clarify the concept. The comment lacks actionable feedback, making it unhelpful in its current form. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point identifies a potential issue with the experiment results, specifically noting that Tables 16 and 17 share the same result despite changing the 2hop EG to 3hop EG. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is an error, if it needs to be addressed, or how to correct it. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 16 and 17,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue of suspicious results, noting that the same result is observed despite changing the 2hop EG to 3hop EG. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that some experiment results are suspicious, specifically noting that Tables 16 and 17 share the same result despite changing the 2hop EG to 3hop EG. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this observation is suspicious or how it impacts the validity of the results. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experiment results, specifically noting that Tables 16 and 17 share the same result despite changing the 2hop EG to 3hop EG. This observation raises a concern about the consistency and reliability of the results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the robustness of their experiment. Without actionable feedback or specific advice, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it highlights a potential problem but lacks depth and direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the experimental results show some advantages of the proposed algorithms, but these advantages are not very significant. It also mentions that the results are still competitive with stateoftheart algorithms. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of the results not being very significant or how they might enhance the competitiveness of their algorithms. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the experimental results, noting that they show some advantages of the proposed algorithms but are not very significant and still competitive with stateoftheart algorithms. However, it does not specify which part of the paper this observation pertains to, such as specific sections, tables, or figures. Without explicit references to the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks specificity regarding what aspects of the results need further elaboration or discussion. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental results show some advantages of the proposed algorithms, but these advantages are not very significant. It also states that the results are still competitive with stateoftheart algorithms. However, the comment lacks specific details or examples to support these claims, such as numerical results or comparisons with specific stateoftheart algorithms. Without this additional information, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment acknowledges the advantages of the proposed algorithms but notes that these advantages are not very significant. It also mentions that the results are still competitive with stateoftheart algorithms. While this feedback highlights a potential limitation in the experimental results, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the significance of their results. The comment lacks actionable advice or detailed feedback, making it 3 as it points out a concern but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the persentence assessment protocol, noting that it may be prone to LLMs\" overconfidence, preferring its predictions even if they are incorrect. However, it does not provide explicit guidance or suggestions on how the authors might address this issue or improve the protocol. The comment lacks actionable details, such as recommending specific methods or steps to mitigate the overconfidence issue. As a result, the authors are left without a clear understanding of what changes are needed to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the use of a persentence assessment protocol to identify and fix inconsistencies, noting a potential issue with LLMs\" overconfidence. However, it does not specify which part of the paper discusses this protocol, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue of overconfidence, it lacks grounding as it does not provide clear references or sections within the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the persentence assessment protocol may be prone to LLMs\" overconfidence, preferring its predictions even if they are incorrect. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the concern raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the persentence assessment protocol, noting that it may be prone to LLMs\" overconfidence, preferring its predictions even if they are incorrect. This feedback highlights a critical weakness in the methodology used to assess and fix inconsistencies. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their protocol. While it points out a problem, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the experimental results, asking whether they are due to the method\"s superiority or an accidental result from a specific kernel function and feature map. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what steps they should consider to clarify the results. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the experimental results, specifically asking whether the promising results are due to the method\"s superiority or an accidental result from a specific kernel function and feature map. However, it does not specify which part of the paper this question pertains to, such as a particular section or result. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its inquiry but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the experimental results, asking whether they are due to the method\"s superiority or an accidental result from a specific kernel function and feature map. This is a subjective opinion or critique, as it expresses a concern about the interpretation of the results. However, it does not provide any supporting evidence, reasoning, or references to justify the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a critical question about the experimental results, asking whether the promising results are due to the method\"s superiority or an accidental result from a specific kernel function and feature map. This question prompts the authors to consider the validity and reliability of their findings, which is an important aspect of evaluating experimental results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their analysis. While it highlights a potential weakness in the paper, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that a discussion of the computational costs associated with training the proposed method would be beneficial. While the comment implies that the authors should include this discussion, it does not explicitly instruct them to do so. The action is clear but inferred, and the authors are given a concrete idea of what to include in their discussion. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method, which allows the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the complexity of the method, involving modified GromovHausdorff distances and hypergraph structures, and suggests that a discussion of the computational costs associated with training would be beneficial. The comment provides clear guidance on what needs to be addressed, making it 5.", "verifiability_rationale": "The review point claims that the proposed method is complex, involving modified GromovHausdorff distances and hypergraph structures, which likely increases time complexity. The reviewer supports this claim by mentioning that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B. However, the comment does not provide specific examples or detailed reasoning to fully substantiate the claim about the increased time complexity. While the authors can infer that the analysis in Appendix B supports the claim, the lack of explicit examples or detailed explanations makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the proposed method, noting its complexity involving modified GromovHausdorff distances and hypergraph structures, which may increase time complexity. It acknowledges that the time complexity of each component is theoretically analyzed and inference efficiency is addressed in Appendix B, but suggests that a discussion of the computational costs associated with training would be beneficial. This feedback is clear and actionable, as it provides a specific area for improvement by suggesting that the authors include a discussion on computational costs. However, the comment could be more helpful if it offered additional guidance on how to present this discussion or what specific aspects of computational costs should be addressed. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the proposed method does not represent a groundbreaking innovation but effectively builds upon existing strategies. It also points out that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of the unique contributions and advantages of the new approach. While the comment identifies a gap in the paper, it does not provide explicit guidance on how to address this issue or suggest specific ways to differentiate the proposed method from existing techniques. The action is implicit and somewhat vague, as the authors need to infer that they should provide a clearer comparison or explanation of their method relative to existing approaches. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim of proposing a groundbreaking innovation in LLMs, suggesting that the method does not represent a significant advancement. It highlights the lack of differentiation from existing contrastive decoding techniques, which is a specific issue that needs clarification. However, the comment does not explicitly mention which part of the paper discusses these claims or techniques, making it weakly grounded. The authors can infer that it relates to the introduction or methodology sections, but this inference is not direct. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method does not represent a groundbreaking innovation within the field of LLMs, despite effectively building upon existing strategies. The reviewer suggests that the paper does not adequately distinguish its proposed method from existing contrastive decoding techniques, leaving readers without a clear understanding of its unique contributions. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to existing techniques that the proposed method might be compared against. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the proposed method does not represent a groundbreaking innovation within the field of large language models (LLMs). It highlights that the method effectively builds upon existing strategies but lacks a clear distinction from existing contrastive decoding techniques. This feedback is 3 as it prompts the authors to clarify the unique contributions and advantages of their proposed method, which is crucial for understanding the paper\"s value. However, the comment could be more helpful if it provided specific suggestions or examples of how to differentiate the proposed method from existing techniques. Overall, the comment offers a direction for improvement but lacks depth and specificity, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Figure 4\"s tabular representation of node agent interactions is not intuitive. However, it does not provide any explicit guidance or suggestions on how the authors might improve the clarity or intuitiveness of the representation. The comment lacks specific details or actionable steps, leaving the authors uncertain about what changes to make to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the tabular representation of node agent interactions, indicating that it is not intuitive. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4\"s tabular representation of node agent interactions is not intuitive. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Figure 4, noting that its tabular representation of node agent interactions is not intuitive. While it highlights a potential weakness in the paper, it lacks actionable guidance or suggestions on how the authors might improve the clarity or intuitiveness of the representation. Without specific advice or examples, the authors are left with a general understanding of the problem but without clear steps to address it. Therefore, the comment is 3, as it points out an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the appropriateness of using other frameworks as baselines for the PU loss and discusses the impact of PU loss on calibration and uncertainty estimation. While it suggests considering alternative frameworks and questions the impact on calibration, it does not provide explicit instructions or concrete steps for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should explore alternative baselines and consider the impact on calibration and uncertainty estimation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the appropriateness of using other frameworks as baselines for the PU loss and discusses the impact of PU loss on calibration and uncertainty estimation. However, it does not specify which part of the paper these questions pertain to, making it weakly grounded. The comment is specific in its inquiry about alternative frameworks and the impact on calibration and uncertainty estimation, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions and suggestions rather than claims. It asks for clarification on the appropriateness of using other frameworks as baselines and explores the impact of PU loss on calibration and uncertainty estimation. Since it does not contain subjective opinions, judgments, or suggestions that require verification, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the appropriateness of using other frameworks as baselines for the PU loss and explores the impact of PU loss on calibration and uncertainty estimation. While it identifies potential areas for improvement, it lacks specific guidance or suggestions on how the authors might address these questions or incorporate additional frameworks. The comment is 3 as it prompts the authors to consider alternative approaches and provides a direction for further exploration, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses disagreement with the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL). The reviewer suggests that TL is a broader term and that Finetuning is a sequential approach, while Standard MTL is a parallel method. However, the comment does not provide explicit guidance or suggestions on how the authors should revise their introduction to address this characterization. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL). It explicitly mentions these terms, allowing the authors to identify the specific part of the paper being discussed. However, the comment does not provide specific guidance on what aspects of the characterization are incorrect or how they should be revised. While the authors can infer that it relates to the introduction, the lack of detailed feedback on what needs to be changed makes the comment 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point challenges the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL). The reviewer argues that TL is a broader term and that Finetuning is a sequential approach, while Standard MTL is a parallel method. This claim is 3 as it provides a logical reasoning based on the definitions of TL, FT, and MTL. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment challenges the characterization of Transfer Learning (TL) and Finetuning (FT) as sequential Multitask Learning (MTL). It suggests that TL is a broader term and that Finetuning is a sequential approach, while Standard MTL is a parallel method. This feedback provides a clear and actionable critique, prompting the authors to reconsider their terminology and potentially revise their introduction to align with a more accurate characterization of these concepts. However, the comment could be more helpful if it offered specific suggestions on how to rephrase the introduction or provided examples of alternative terminology. Despite this, the feedback is 4 as it directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks a Limitation section, which is an important aspect for any research paper. This feedback provides a clear and direct action for the authors to take, which is to include a Limitation section in their draft. The comment is specific in its request, as it identifies the exact missing element and provides a concrete action for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the absence of a Limitation section. However, it does not specify which part of the paper should include this section, making it weakly grounded. The comment is specific in detailing what is missing, which is the Limitation section. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a Limitation section, which is important. However, it does not provide any supporting evidence, reasoning, or examples to justify why a Limitation section is necessary or how its absence impacts the paper\"s comprehensiveness. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically the absence of a Limitation section. This is a critical aspect for any research paper, as it provides insight into the boundaries of the study and the potential implications of the findings. By pointing out this omission, the comment offers a clear and actionable suggestion for the authors to enhance the completeness and rigor of their work. However, the comment could be more helpful if it provided additional guidance on what specific limitations should be included or how to effectively present them. Overall, the feedback is 4 as it directs the authors to a crucial area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It suggests that the theory behind diffusion models in Section 2.1 needs more detailed explanations, and that the works of Choi et al. (2021) and Meng et al. (2021) should be better explained. Additionally, it points out that the captions of figures are often not explanatory, specifically mentioning Figures 3, 4, 7, and 8. These suggestions are clear and provide concrete steps for the authors to improve their draft. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as Section 2.1, Section 2.2, and Section 3.2, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the need for more detailed explanations of the theory behind diffusion models, the lack of explanation for the works of Choi et al. (2021) and Meng et al. (2021), and the unexplanatory nature of figure captions. This provides clear guidance on what needs to be addressed in each section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: one about the theory behind diffusion models needing more detailed explanations and another about the captions of figures being unexplanatory. The first part is a request for more detailed explanations, which is a suggestion and does not contain a claim. The second part points out that figure captions are often not explanatory, which is a factual observation. Since the comment does not contain any subjective claims or opinions, it is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on several aspects of the paper. It identifies that the theory behind diffusion models in Section 2.1 needs more detailed explanations, which is a clear suggestion for improvement. Additionally, it points out that the works of Choi et al. (2021) and Meng et al. (2021) are not adequately explained, offering a specific area for further elaboration. The comment also highlights issues with the captions of figures, noting that they are often unexplanatory. This feedback is clear and provides the authors with concrete directions for enhancing the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered suggestions on how to improve the explanations or captions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the title should include the term \"tensor completion\" to better reflect the application of the new model presented in the paper. This is a direct and explicit action for the authors to take, as it clearly indicates what change is needed to improve the title. The comment is specific in its request, providing a clear and actionable step for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the title should include the term \"tensor completion\" to better reflect the application of the new model presented in the paper. However, it does not specify which part of the paper this suggestion pertains to, such as the title itself or a specific section. The authors can infer that it relates to the title, but this inference is not as direct as it could be. The comment is specific in its suggestion, but the lack of explicit grounding makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the title should include the term \"tensor completion\" to better reflect the application of the new model presented in the paper. However, the comment does not provide any reasoning or evidence to support why this change is necessary or how it would improve the title. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a minor improvement to the title by recommending the inclusion of the term \"tensor completion\" to better reflect the application of the new model presented in the paper. This feedback is specific and actionable, as it provides a clear direction for enhancing the title to better represent the content of the paper. However, the comment could be more helpful if it offered additional suggestions or context on why this term is important or how it fits into the overall narrative of the paper. Despite this, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include a comparison of their proposed method with a simple baseline, such as character frequencies, to strengthen the empirical evaluation. While the comment implies that this comparison is necessary, it does not explicitly instruct the authors to make this change. The action is clear but inferred, and the comment provides a concrete suggestion for improvement. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their proposed method with a simple baseline, such as character frequencies, to strengthen the empirical evaluation. However, it does not specify which part of the paper this comparison should be made in, leaving the authors to infer that it relates to the empirical evaluation section. The comment is specific in suggesting a particular type of baseline to include, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include a comparison with a simple baseline, such as character frequencies, to strengthen the empirical evaluation. This claim is 3 as it provides a logical reasoning for why such a comparison would be beneficial, but it lacks specific examples or references to support the suggestion. The authors would need to determine which baseline to use and how to implement the comparison, which adds some level of difficulty to following the advice. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s empirical evaluation by pointing out the lack of comparison with other prior methods. It suggests that the authors should include a simple baseline, such as character frequencies, to strengthen the empirical evaluation. This feedback is clear and actionable, providing the authors with a specific direction to enhance the robustness and persuasiveness of their work. However, the comment could be more helpful if it included examples of such baselines or more detailed guidance on how to implement the comparison. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their empirical evaluation."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the proposed method regarding its practicality in reducing computational load, particularly in real applications. It points out that different tokens activate different channels, making it difficult to apply a uniform activation pattern across all tokens. The reviewer also notes that the method relies on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially negating the intended efficiency gains. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the method\"s practicality. The action is implicit and vague, as the authors are left to infer that they need to explore ways to overcome the challenges mentioned. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of limited practicality in reducing computational load, specifically mentioning the challenges faced by the proposed method in real applications. It highlights the difficulty in applying a uniform activation pattern across different tokens due to their varying activation patterns. The comment also points out the reliance on precomputed PPL and activation patterns, which may not generalize well to other tokens. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the challenges and limitations, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method may face challenges in reducing computational load in real applications due to the difficulty in applying a uniform activation pattern across different tokens. The reviewer provides a logical reasoning by explaining that different tokens activate different channels, making it difficult to generalize activation patterns. However, the comment lacks specific examples or references to support the claim about the challenges in generalizing activation patterns. This makes the claim 3, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation in the proposed method regarding its practicality in reducing computational load, particularly in realworld applications. It highlights the challenge of applying a uniform activation pattern across different tokens due to their varying activation patterns. The comment also points out the reliance on precomputed PPL and activation patterns, which may not generalize well to other tokens, potentially negating the intended efficiency gains. While the comment provides a clear and actionable insight into a critical limitation, it lacks specific suggestions or guidance on how the authors might address this issue or improve the method\"s practicality. Therefore, the feedback is 3, as it highlights an important area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the core motivation of the paper, noting that the abstract and proposed methods are presented as stacked statements without effectively capturing the main problem to be solved. However, it does not provide explicit guidance on how the authors should clarify this motivation or what specific changes are needed to improve the clarity. The action is implicit and somewhat vague, as the authors are left to infer that they need to reorganize or better articulate the motivation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the core motivation of the paper, noting that it is not clearly explained. It mentions specific elements of the abstract, such as the difficulty in demarcating task boundaries and the proposed benchmark, metrics, and gating technique. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of unclear motivation and the need for better articulation of the main problem. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the core motivation of the paper is not clear enough, as the abstract and proposed methods are presented as stacked statements without effectively capturing the main problem to be solved. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed analysis to substantiate the assertion that the motivation is unclear. As a result, the claim is 3, as it provides a general observation but lacks the depth and specificity needed for full verification.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the core motivation of the paper, noting that the abstract and proposed methods are presented as stacked statements without effectively capturing the main problem to be solved. This feedback is 3 as it highlights an area for improvement, prompting the authors to reconsider their approach and ensure that the motivation is clearly articulated. However, the comment could be more helpful if it provided specific suggestions on how to clarify the motivation or reorganize the content to better convey the main problem. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the sequence inference classifier used to filter data, questioning what kind of data passes this filter. It suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data. While the comment implies that the authors should provide examples to clarify the filter, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide examples to address the concern. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the sequence inference classifier used for filtering data, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises concerns about the nature of the data filtered by this classifier and suggests that examples of the filtered data would be helpful. The comment provides clear guidance on what needs to be clarified or addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises concerns about the sequence inference classifier used to filter data, questioning the nature of the data that passes this filter. The reviewer suggests that the task of filtering data using the task description is different from the original MNLI distribution and requests examples of the filtered data. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The request for examples provides some guidance, but the overall claim remains 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a concern regarding the sequence inference classifier used to filter data, questioning the nature of the data that passes this filter. It highlights a discrepancy between the task of filtering data using the task description and the original MNLI distribution. The comment suggests that providing examples of the filtered data would be helpful to clarify the issue. This feedback is clear and actionable, as it directs the authors to provide additional information that could enhance the transparency and understanding of their methodology. However, it could be more helpful if it offered specific suggestions on how to present these examples or what aspects of the filter should be clarified. Overall, the comment is 4, as it effectively guides the authors in improving their draft by addressing a critical issue and suggesting a way to enhance clarity."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment provides several explicit actions for the authors to take. It suggests that the application experiments may have biases due to the limited scope of the dataset and recommends conducting comprehensive experiments to verify the effectiveness of the proposed methods. Additionally, it advises the authors to examine the structure, argumentation, and language clarity of the paper to ensure it meets highquality standards. Specific examples are given, such as the chaotic equation numbering and the lack of indentation in Algorithm 1. These suggestions are clear and provide concrete steps for the authors to follow, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the application experiments and the specific issue of relying on a single model (DALLE) and a small dataset, which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the difficulty in convincing the results due to limited experiments and the need for comprehensive experiments. Additionally, the comment provides specific suggestions for improvement, such as examining the structure, argumentation, and language clarity, and mentions specific formatting issues like chaotic equation numbering and Algorithm 1 lacking indentation. This level of detail and specificity makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the application experiments may have biases due to the limited scope of the dataset, which only includes 30 famous paintings and 30 generated paintings. The reviewer suggests that this limitation makes the experiment results difficult to be convincing and recommends comprehensive experiments to verify the effectiveness of the proposed methods. The comment provides a logical reasoning by highlighting the potential biases and the need for a broader dataset. However, it lacks specific examples or references to support the claim further, which could enhance the verifiability. Therefore, the comment is 4, as it provides a reasonable basis for the claim but could be strengthened with additional evidence or examples.", "helpfulness_rationale": "The review comment provides several valuable insights and suggestions for improving the paper. It points out potential biases in the application experiments due to the limited scope of the dataset, which only includes 30 famous paintings and 30 generated paintings. This critique highlights the need for comprehensive experiments to validate the effectiveness of the proposed methods. Additionally, the comment offers actionable advice by suggesting that the authors examine the structure, argumentation, and language clarity of the paper to ensure it meets highquality standards. Specific examples are given, such as the chaotic equation numbering and the lack of indentation in Algorithm 1, which can be addressed to improve the paper\"s professionalism and readability. Overall, the feedback is clear, actionable, and provides a comprehensive guide for the authors to enhance their draft, making it 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide comments on the practical applications of their work, particularly in the context of catastrophic forgetting. It highlights that the experiments are based on datasets created from standard benchmarks, which may not reflect realworld scenarios. The reviewer implies that the authors should consider discussing the relevance of their work to realworld applications. While the comment suggests a potential area for improvement, it does not provide specific guidance on how to address this issue or what aspects of the work should be highlighted. The action is implicit and somewhat vague, as the authors need to infer that they should provide comments on practical applications and consider the limitations of their current dataset setup. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s focus on catastrophic forgetting and provides a specific suggestion for improvement by asking for practical applications. It also mentions the datasets used in the experiments, which are based on standard benchmarks, and suggests that the authors should consider the relevance of their work to realworld applications. This provides clear guidance on what the authors need to address. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the practical applications of the experiments conducted in the paper, specifically mentioning that the datasets used are based on standard benchmarks and manipulated samples. The reviewer suggests that there might be realworld tasks with available data that could benefit from the model. However, the comment lacks specific examples or references to support the claim that the current datasets are not representative of realworld applications. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a relevant point by questioning the practical applications of the experiments conducted in the paper, particularly in the context of catastrophic forgetting. It suggests that the datasets used are based on standard benchmarks and manipulated samples, which may not reflect realworld scenarios. The reviewer implies that the authors should consider discussing the relevance of their work to realworld applications. This feedback is 3 as it prompts the authors to think about the practical implications of their work and consider expanding the scope of their discussion. However, the comment could be more actionable by providing specific suggestions or examples of realworld tasks that could benefit from the model. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should consider other backdoor detection methods that are input datafree, such as those based on weight matrix statistics or matrix factorization, in their analysis of algorithm performance. While the comment implies that these methods should be included, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should incorporate these additional methods into their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Robustness\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests considering other backdoor detection methods that are input datafree, such as those based on weight matrix statistics or matrix factorization, and emphasizes the need to include these in the analysis of algorithm performance. This provides clear guidance on what additional elements should be considered in the analysis. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the \"Robustness\" section should consider other backdoor detection methods that are input datafree, such as those based on weight matrix statistics or matrix factorization. While the comment identifies a potential area for improvement, it lacks specific examples or references to these methods, making it 3. The authors would need to further research to understand and implement these additional methods, which limits the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the \"Robustness\" section by suggesting that other input datafree backdoor detection methods, such as those based on weight matrix statistics or matrix factorization, should be considered in the analysis of algorithm performance. This feedback is actionable as it provides a specific direction for the authors to enhance their analysis by incorporating additional methods. However, the comment could be more helpful if it offered a brief explanation of why these methods are relevant or how they might impact the analysis. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the \"relation works section\" is incomplete and that the authors need to describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. This feedback provides clear and direct actions for the authors to take, specifying what needs to be addressed in the paper. The comment is specific and actionable, giving the authors a clear understanding of what needs to be improved and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"relation works section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the need to describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. This provides clear guidance on what aspects of the paper require further elaboration. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"relation works section\" is incomplete and that the authors need to describe which view of the knowledge graph is part of the assumption. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is a critical issue or how it impacts the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that is incomplete, namely the \"relation works section,\" and highlights the need for further elaboration on the problem definition and methodology. It suggests that the authors should describe which view of the knowledge graph is part of the assumption, such as instanceview, ontologyview, or twoview KG. This feedback is clear and actionable, providing the authors with a concrete direction for improving the completeness and clarity of their paper. However, the comment could be more helpful if it offered additional guidance on how to address these issues or provided examples of how to describe the assumptions. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of theoretical support for the technical design, particularly regarding the update derivation for the intrinsic reward parameters. It suggests that the authors should provide more justification for the update derivation, referencing a previous work (Sorg et al. 2010) for comparison. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more justification for the update derivation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"technical design\" and the \"update derivation for the intrinsic reward parameters,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the lack of theoretical support for the design and suggests that the update derivation for the intrinsic reward parameters is not convincing. The comment provides a clear indication of what needs to be addressed, including the need for more justification for the update derivation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical design lacks theoretical support, particularly regarding the update derivation for the intrinsic reward parameters. The reviewer references a previous work (Sorg et al. 2010) to provide context, which partially supports the claim. However, the comment does not provide detailed reasoning or specific examples from the referenced work to fully substantiate the claim. The lack of explicit evidence or detailed explanation makes the claim 3, as the authors would need to infer the extent of the issue and how it relates to the previous work. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the technical design, specifically the lack of theoretical support for the update derivation of the intrinsic reward parameters. It highlights that while the design may be acceptable, the update derivation for the intrinsic reward parameters is not convincing and lacks justification. The comment references a previous work (Sorg et al. 2010) to provide context, which is a helpful starting point for the authors to understand the issue. However, the comment could be more helpful by offering specific suggestions or examples of how to strengthen the theoretical justification for the update derivation. Overall, the feedback is 4 as it points out a critical area for improvement and provides a reference for further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the adaptive variance reduction property, suggesting that the claim of adaptivity is weakened by the requirement of choosing a \"small enough\" \u03b2 parameter. However, it does not provide explicit guidance on how the authors should address this issue or suggest alternative approaches to maintain the adaptivity claim. The feedback is implicit, as it implies that the authors need to reconsider their claim, but it lacks concrete steps or suggestions for improvement. Therefore, the comment is 3, as it identifies a potential problem but does not offer detailed guidance on how to resolve it.", "grounding_specificity_rationale": "The comment addresses the adaptive variance reduction property claimed by the authors, suggesting that it boils down to picking a \"small enough\" \u03b2 parameter. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the issue with the adaptivity claim and provides an example of a similar adaptive method, AdaGrad, which does not rely on a fixed \u03b2 parameter. This provides some level of specificity, but the lack of grounding makes it 3. Therefore, the comment aligns with category 3.", "verifiability_rationale": "The review point claims that the adaptive variance reduction property is based on choosing a \"small enough\" \u03b2 parameter, which the reviewer argues takes away the adaptivity. The comment provides a logical reasoning by comparing this approach to adaptive methods like AdaGrad, which do not rely on a fixed \u03b2 parameter. This comparison supports the claim by referencing a known adaptive method, making the comment 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the \u03b2 parameter affects adaptivity. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the adaptive variance reduction property claimed by the authors, suggesting that it is based on choosing a \"small enough\" \u03b2 parameter. The reviewer points out that this approach may not provide the adaptivity that the authors are claiming, as seen in adaptive methods like AdaGrad. This feedback is 3 as it highlights a critical aspect of the claim that may need clarification or reconsideration. However, the comment could be more helpful if it provided suggestions on how the authors might address this issue or alternative approaches to maintain the adaptivity claim. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the value of different augmentation techniques is unclear and recommends further investigation into why DINOv2 performs the best. It implies that the authors should explore the reasons behind the effectiveness of DINOv2 and consider ways to improve it. While the comment provides a clear direction for further investigation, it lacks specific guidance on how to conduct this investigation or what aspects to focus on. The action is explicit but somewhat vague, as it does not provide detailed steps for improvement. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the value of different augmentation techniques and suggests further investigation into why DINOv2 performs the best. However, it does not specify which part of the paper discusses these techniques or where the authors should focus their investigation. The authors might infer that it relates to the section discussing augmentation techniques, but this inference is not direct. The comment is specific in suggesting further investigation into the performance of DINOv2, but it lacks grounding as it does not pinpoint the exact section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the value of different augmentation techniques is unclear, suggesting that while different techniques have varying effects on different models, DINOv2 is the most effective. The comment implies that further investigation is needed to understand why DINOv2 performs the best and how to improve it. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the value of augmentation techniques is unclear. This makes the claim 3, as it provides a general direction for further exploration but lacks the depth and specificity needed for full verification.", "helpfulness_rationale": "The review comment identifies a gap in the understanding of the value of different augmentation techniques, noting that while they have varying effects on different models, DINOv2 consistently performs the best. It suggests further investigation into why DINOv2 is the most effective and how to improve it. This feedback is clear and actionable, as it provides a direction for the authors to explore and enhance their work. However, it could be more helpful if it offered specific suggestions or methods for conducting this investigation. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the acronym for \"Follow the Top Perturbed Leader\" is unfortunate, as it conflicts with the commonly used acronym \"FTL\" for \"Follow the Leader.\" The reviewer implies that a change in the acronym might be beneficial. However, the comment does not provide specific guidance on which acronym to use or how to implement this change. The action is implicit and vague, as the authors are left to infer that they should consider changing the acronym, but without concrete instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the acronym for \"Follow the Top Perturbed Leader\" is unfortunate, as it conflicts with the commonly used acronym \"FTL\" for \"Follow the Leader.\" However, it does not specify which part of the paper this acronym is used, making it weakly grounded. The comment is specific in suggesting a change in the acronym, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the acronym for \"Follow the Top Perturbed Leader\" is unfortunate because it conflicts with the commonly used acronym \"FTL\" for \"Follow the Leader.\" However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the acronym used for \"Follow the Top Perturbed Leader\" is unfortunate, as it conflicts with the commonly used acronym \"FTL\" for \"Follow the Leader.\" This feedback is 3 as it identifies a potential inconsistency in terminology that could be clarified. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing alternative acronyms or explaining the rationale behind the current choice. Without actionable advice, the authors are left with a general observation that could be improved but without a clear path forward. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out that the selection of attacks in Table 1 is arbitrary and not stateoftheart, suggesting that there are better attacks like MIDIFGSM. It also provides a specific request to mention the number of iterations for the attacks and their hyperparameters. This feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the selection of attacks, noting that they are not stateoftheart and suggesting better alternatives like MIDIFGSM. Additionally, it provides a request to mention the number of iterations and hyperparameters for the attacks. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the selection of attacks in Table 1 is arbitrary and not stateoftheart, suggesting that there are better attacks like MIDIFGSM. The comment provides a reference to a survey that analyzes various attacks, which supports the claim. However, the comment could be strengthened by explicitly mentioning the specific attacks that are considered better and how they differ from the current selection. Additionally, it could provide more detailed reasoning or examples to fully substantiate the claim. Therefore, the comment is 4, as it provides some justification but lacks complete evidence and examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the selection of attacks in Table 1, noting that they are not stateoftheart and suggesting better alternatives like MIDIFGSM. It provides a reference to a survey that analyzes various attacks, which adds credibility to the claim. Additionally, the comment offers actionable feedback by requesting the authors to mention the number of iterations and hyperparameters for the attacks. This level of detail and constructive suggestion provides the authors with clear guidance on how to improve their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the method, specifically that it is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this limitation or improve the method\"s applicability to other pretraining methods. As a result, the comment lacks actionability, leaving the authors without any clear steps to follow to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the limitations and conclusion sections of the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, noting that the method is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). This provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the limitation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically that the method is primarily effective for encoders pretrained with contrastive learning and may not perform well with other selfsupervised learning pretraining methods like Masked Image Modeling (MIM). This feedback is valuable as it highlights a potential area for improvement, prompting the authors to consider the applicability of their method across different pretraining methods. However, the comment could be more helpful if it provided suggestions on how to address this limitation or explored alternative approaches that might enhance the method\"s applicability. Overall, the comment is 3 as it points out a significant weakness but lacks depth and actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides several specific questions and suggestions for improvement regarding the qualitative analysis section. It asks for clarification on how the two input sentences for qualitative analysis were determined, whether they occurred during the finetuning process, and whether the attribution values in Figure 1 are normalized. Additionally, it questions the effectiveness of the attribution map for input examples that failed to be classified. These questions are explicit and provide clear guidance on what needs to be clarified or addressed in the paper. The authors can directly use this feedback to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 4.5.5\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed questions about the qualitative analysis, including how the input sentences were determined, whether they occurred during finetuning, and the normalization of attribution values. Additionally, it questions the effectiveness of the attribution map for unclassified input examples. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of several questions and requests for clarification regarding the qualitative analysis section. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information to better understand the methodology and results. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the qualitative analysis section of the paper. It questions the determination of two input sentences for qualitative analysis, asking whether they occurred during the finetuning process. Additionally, it inquires about the normalization of attribution values in Figure 1 and the effectiveness of the attribution map for unclassified input examples. These questions and suggestions are clear and provide the authors with concrete guidance on how to improve the clarity and comprehensiveness of their qualitative analysis. By addressing these points, the authors can enhance the rigor and detail of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point provides a specific suggestion for the authors to include examples of practical applications where specific types of tensors need to be equivariant and to clarify how these scenarios validate the advantages of using equivariant tensor functions. This feedback is explicit and concrete, as it clearly outlines what the authors should do to improve their draft. The suggestion is actionable because it provides a clear direction for enhancing the paper\"s content, making it 5.", "grounding_specificity_rationale": "The comment suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or paragraph where these examples should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. Nonetheless, the comment is specific in its suggestion for improvement, providing clear guidance on what needs to be added to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including examples of practical applications where specific types of tensors need to be equivariant and clarifying how these scenarios validate the advantages of using equivariant tensor functions. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why these examples are necessary or how they would validate the advantages. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to enhance their draft by including examples of practical applications where specific types of tensors need to be equivariant. It also suggests clarifying how these scenarios validate the advantages of using equivariant tensor functions. This feedback is clear and constructive, offering a concrete way for the authors to improve the relevance and applicability of their work. However, the comment could be more helpful if it provided additional guidance on how to select or design these examples or how to effectively communicate the validation of advantages. Despite this, the suggestion is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific issues with the tables, noting that certain methods like ERM, cRT, and LWS are not properly referenced. It also points out a misalignment between Section 3.2.3 and the table. While the comment highlights these issues, it does not provide explicit guidance on how to address them or suggest specific actions for the authors to take. The authors are left to infer that they need to clarify the references and ensure consistency between the section and the table. However, the lack of concrete instructions makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Section 3.2.3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the tables, such as the lack of proper references for methods like ERM, cRT, and LWS, and the misalignment between the section and the table. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are issues with the tables, specifically noting that certain methods like ERM, cRT, and LWS are not properly referenced. The comment also points out a misalignment between Section 3.2.3 and the table. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims. While it identifies areas for improvement, it does not provide enough evidence or explanation to fully verify the claims, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies specific issues with the tables, noting that certain methods like ERM, cRT, and LWS are not properly referenced. It also points out a misalignment between Section 3.2.3 and the table. While the comment highlights these problems, it does not provide detailed guidance or suggestions on how to address them. The authors are left to infer that they need to clarify the references and ensure consistency between the section and the table, but the comment lacks actionable advice or specific steps for improvement. Therefore, the comment is 3, as it provides some insight but not enough detail to be fully beneficial."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides two specific questions for the authors to address. The first question asks whether the model is suitable for sarcastic/nonsarcastic utterances and suggests that the authors provide more details for further analysis. The second question questions the utility of eyemovement data beyond textual features for sarcastic/nonsarcastic sentiment classification and requests additional explanations. Both questions are explicit and provide concrete guidance on what the authors should do to improve their draft. The authors know exactly what additional information or explanations are needed to address these points, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"General Discussion\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear questions and suggestions for improvement, such as asking whether the model is suitable for sarcastic/nonsarcastic utterances and requesting more details for further analysis. Additionally, it questions the utility of eyemovement data beyond textual features for sarcastic/nonsarcastic sentiment classification and requests more explanations. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of a general observation that the paper is wellwritten and organized, followed by specific questions and suggestions for improvement. The claims made in the comments are based on the authors\" own work and the analysis conducted, which provides a logical basis for the suggestions. However, the comment lacks specific examples or references to support the claims about the model\"s suitability for sarcastic/nonsarcastic utterances or the utility of eyemovement data. While the suggestions are clear, the lack of detailed justification or evidence makes the claims 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a balanced assessment of the paper, noting that it is wellwritten and organized. It offers specific and actionable feedback by questioning the suitability of the model for sarcastic/nonsarcastic utterances and requesting more details for further analysis. Additionally, it suggests that the authors provide more explanations on the utility of eyemovement data beyond textual features for sarcastic/nonsarcastic sentiment classification. This feedback is clear and constructive, guiding the authors to enhance the depth and clarity of their analysis. However, the comment could be more helpful if it included examples or specific suggestions on how to address these questions. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the limited number of experimental results and the improper labeling of the DDIM as a sampler method in the tables. While it points out these issues, it does not provide explicit guidance on how the authors should address them. The authors are left to infer that they need to conduct more experiments on larger datasets and correct the labeling in the tables. The action is implicit and somewhat vague, as it lacks specific instructions on how to improve the experimental setup or correct the labeling. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the experimental results, specifically noting that they are limited to two smallscale/resolution datasets. It also points out that the tables are improperly labeled, with DDIM being referred to as a sampler method instead of a model. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the experimental results and tables. The comment is specific in detailing the issues with the experimental setup and the incorrect labeling in the tables. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experimental results are limited to two smallscale datasets and that the tables incorrectly label DDIM as a sampler method. While the comment identifies specific issues, it lacks detailed reasoning or references to support why these limitations are problematic or how they impact the paper\"s conclusions. The absence of specific examples or comparisons to other studies makes it difficult for the authors to fully understand and address the concerns. Therefore, the comment is 3, as it provides some insight but requires more detailed justification to be fully actionable.", "helpfulness_rationale": "The review comment identifies two specific issues with the experimental results: the limited number of datasets used and the incorrect labeling of DDIM as a sampler method in the tables. While it points out these problems, it does not provide detailed guidance on how the authors might address them or suggest improvements. The feedback is 3 as it highlights areas for improvement, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors provide more clarification about the importance of the proposed method, specifically questioning whether it merely adjusts the variance level of DPSGD and what impact this might have on utility or privacy. The reviewer implies that the authors should explain the significance of their method and how it affects privacy and utility. However, the comment does not explicitly instruct the authors to do this, nor does it provide specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the importance of their method and its implications. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors provide more clarification about the importance of their proposed method, specifically questioning whether it merely adjusts the variance level of DPSGD and what impact this might have on utility or privacy. However, it does not specify which part of the paper this clarification should be included in, making it weakly grounded. The comment is specific in its request for clarification regarding the importance and implications of the proposed method. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the importance of the proposed method, suggesting that it may only adjust the variance level of DPSGD and implies that the impact on utility or privacy should be clarified. However, the comment does not provide specific examples, reasoning, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the critique, rendering the claim 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper by questioning the importance of the proposed method, suggesting that it may only adjust the variance level of DPSGD. The reviewer implies that the authors should clarify the significance of their method and its impact on privacy and utility. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to address the issue or what aspects should be emphasized to clarify the method\"s importance. This limits the comment\"s helpfulness, as it provides a general direction for improvement but does not offer detailed feedback or actionable steps for the authors. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the empirical results are more illustrative than demonstrative and recommends a largerscale experiment, particularly a longerhorizon example. It also mentions that a tabular example would be appreciated. While the comment provides a clear direction for improvement, it does not specify how to conduct the largerscale experiment or what specific aspects of the longerhorizon example should be emphasized. The authors are given an explicit action to take, but the lack of detailed guidance on execution makes the comment 3.", "grounding_specificity_rationale": "The comment suggests that the empirical results are more illustrative than demonstrative and recommends a largerscale experiment, specifically a longerhorizon example. It also mentions that a tabular example would be appreciated. However, the comment does not specify which part of the paper discusses the empirical results, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not direct. The comment is specific in suggesting a largerscale experiment and a longerhorizon example, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the empirical results are more illustrative than demonstrative and recommends a largerscale experiment, particularly a longerhorizon example. However, the comment does not provide specific examples or evidence to support the claim that a largerscale experiment would be more beneficial. The suggestion lacks detailed reasoning or references to substantiate the claim, making it difficult for the authors to understand the basis of the recommendation. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient evidence or justification.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending a largerscale experiment, particularly a longerhorizon example, to better illustrate the empirical results. It also suggests that a tabular example would be beneficial. This feedback is actionable and offers a clear direction for the authors to enhance the comprehensiveness and impact of their results. However, the comment could be more helpful if it included additional guidance on how to design or execute the largerscale experiment or provided examples of what a longerhorizon example might look like. Despite this, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Equation (13) does not have a closedform solution in general and suggests that some details about its solution in experiments and computational complexity would be helpful. While the comment implies that the authors should provide more information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional details about the solution and computational complexity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (13),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of a closedform solution and the need for details about how it is solved in experiments and on computational complexity. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Equation (13) does not have a closedform solution in general and suggests that additional details about its solution in experiments and computational complexity would be helpful. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this claim is important or how it impacts the paper. Without specific examples or explanations, the authors may find it challenging to understand the significance of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Equation (13), noting that it does not have a closedform solution in general. It suggests that providing details about how the equation is solved in experiments and its computational complexity would be beneficial. This feedback is clear and actionable, as it highlights a gap in the paper that could enhance the understanding and reproducibility of the results. However, the comment could be more helpful if it offered specific suggestions on how to address the issue or presented examples of how similar equations are handled in the literature. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the paper should include a discussion on the choice of \"proximity\" and the nature of the task. It highlights a specific issue with the current analysis, noting that while proximity on the fingertip Cartesian positions is strongly correlated with proximity in the solution space, this relationship does not hold for certain tasks, such as those in complicated mazes or with various obstacles and collisions. The comment provides a clear action for the authors to take, which is to analyze what tasks have reasonable proximity metrics and demonstrate failure on those that don\"t. This feedback is specific and actionable, giving the authors a clear direction for improvement. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of discussion on the choice of \"proximity\" and the nature of the task, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, namely analyzing what tasks have reasonable proximity metrics and demonstrating failure on those that don\"t. This guidance is detailed and actionable, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a discussion on the choice of \"proximity\" and the nature of the task. It provides a specific example of how proximity on fingertip Cartesian positions correlates with proximity in the solution space but fails for certain tasks, such as those in complicated mazes or with obstacles. The comment suggests that the paper should analyze what tasks have reasonable proximity metrics and demonstrate failure on those that don\"t. This claim is 4 as it provides a logical reasoning and a specific example to support the assertion. However, it could be strengthened by referencing similar studies or providing more detailed analysis of the tasks mentioned. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area of improvement by pointing out the lack of discussion on the choice of \"proximity\" and the nature of the task. It provides a clear example of how proximity on fingertip Cartesian positions correlates with proximity in the solution space but fails for certain tasks, such as those in complicated mazes or with obstacles. The comment suggests that the paper should analyze what tasks have reasonable proximity metrics and demonstrate failure on those that don\"t. This feedback is actionable and provides a concrete direction for the authors to enhance their draft by addressing the limitations of their current analysis. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of implementation details in the experiments, which is crucial for readers to understand or reproduce the results. However, it does not provide specific guidance on what details are missing or how the authors should address this issue. The comment implies that the authors should include more details, but it does not specify what those details should be or how to implement them. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of implementation details in the experiments, which is a specific issue that needs to be addressed. However, it does not specify which part of the paper this issue pertains to, such as particular sections or experiments. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in identifying the need for more details but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the experiments lack implementation details necessary for readers to understand or reproduce the results. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to address the issue effectively. Without detailed guidance or examples, the authors may struggle to identify what specific details are missing. Therefore, the comment is considered 2, as it lacks sufficient evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the lack of implementation details in the experiments, which is crucial for readers to understand or reproduce the results. However, the comment does not provide specific guidance or suggestions on what details are missing or how the authors might address this issue. While it highlights an important area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors would gain some insight into the need for more detailed explanations, but they would still need to determine the exact nature of the missing information themselves. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the fairness of the comparison between SSUL and Mask2Former, suggesting that SSUL uses an offtheshelf saliencymap detector while Mask2Former is used for region proposals. The reviewer questions whether SSUL could adopt Mask2Former for detecting unseen classes or generate object proposals in an unsupervised manner without additional data or heavy model usage. While the comment implies that the authors should consider these alternatives, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of different methods for detecting unseen classes and generating region proposals in the paper. It specifically mentions the use of the offtheshelf saliencymap detector by SSUL and the pretrained Mask2Former used by the paper. The comment raises a concern about the fairness of the comparison due to differences in data and model size, suggesting that SSUL could adopt Mask2Former or generate object proposals in an unsupervised way. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue of fairness and suggesting potential solutions, but without explicit references to sections, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the comparison between SSUL and Mask2Former, suggesting that the use of different methods for detecting unseen classes and generating region proposals may introduce unfairness due to differences in data and model size. The reviewer provides a logical reasoning by pointing out that Mask2Former is trained on COCO and has larger parameters than the offtheshelf detector used by SSUL. The comment suggests potential alternatives, such as adopting Mask2Former or generating object proposals in an unsupervised manner. However, the comment lacks specific examples or references to substantiate the claim fully, making it 3. The authors would need to further explore these suggestions to address the concern, but the comment provides a reasonable basis for the claim.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of the comparison between SSUL and Mask2Former, particularly regarding the use of different methods for detecting unseen classes and generating region proposals. It points out that Mask2Former, which is used for region proposals, is trained on COCO and has significantly larger parameters than the offtheshelf detector used by SSUL. This discrepancy may introduce an unfair comparison in terms of data and model size. The comment suggests potential alternatives, such as adopting Mask2Former for detection or generating object proposals in an unsupervised manner without additional data or heavy model usage. While the comment identifies a critical issue and provides a direction for improvement, it lacks specific guidance on how to implement these suggestions or evaluate their impact. Therefore, the comment is 4, as it offers valuable insights but could be more comprehensive with detailed actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights potential issues with the validation of the proposed approach, specifically mentioning the reliance on a style classifier for style accuracy and the difficulty in verifying transfer results for styled motion inputs. However, it does not provide explicit guidance or suggestions on how to address these concerns or improve the validation process. The feedback is vague and lacks concrete steps for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the experiments section, specifically mentioning the metrics used for validation and the potential issues with style accuracy and transfer results. It provides specific examples, such as the reliance on a style classifier and the difficulty in verifying transfer results for styled motion inputs. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the potential problems with the validation metrics, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments may not effectively validate the performance of the proposed approach, specifically mentioning the reliance on a style classifier for style accuracy and the difficulty in verifying transfer results for styled motion inputs. The comment provides some reasoning by suggesting that the style classifier may be too accurate, but it lacks specific examples or references to support these claims. This makes the claim 3, as the authors would need to further investigate and possibly provide additional evidence to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the validation of the proposed approach, specifically mentioning the reliance on a style classifier for style accuracy and the difficulty in verifying transfer results for styled motion inputs. This feedback is 3 as it highlights areas where the experimental validation may be lacking, prompting the authors to consider alternative metrics or methods for validation. However, the comment could be more helpful if it provided specific suggestions or examples of how to address these issues. Overall, the feedback provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity regarding how individual preferences are generated in the proposed method. It suggests that the authors need to clarify this aspect, as it is unclear whether the preferences are rules/policies learned from experiences or something else. While the comment identifies a specific area that needs clarification, it does not provide explicit guidance on how to address this issue or what specific details should be included in the clarification. The action is implicit and somewhat vague, as the authors know they need to clarify the issue but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the argument about the proposed method taking individual preferences into account, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear generation of individual preferences, such as how certain agents are more risk averse than others, and suggests that the term \"preference\" might be interpreted as rules/policies learned from experiences. This provides clear guidance on what needs to be clarified. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of how individual preferences are generated in the proposed method. It questions the interpretation of \"preference\" as rules/policies learned from experiences and suggests that the authors need to clarify this aspect. While the comment identifies a potential issue, it lacks specific examples or references to support the claim that the current explanation is unclear. The authors would need to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the generation of individual preferences in the proposed method. It highlights the lack of clarity regarding how these preferences are generated, such as whether certain agents are more risk averse than others. The comment suggests that the term \"preference\" might be interpreted as rules/policies learned from experiences, which could be a point of confusion. This feedback is clear and actionable, as it directs the authors to clarify the methodology for generating individual preferences. However, it could be more helpful if it provided specific suggestions on how to address this issue or examples of how to clarify the explanation. Overall, the comment is 4, as it effectively points out a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several questions about Figure 4, including the meaning of \"1200 frames,\" how the values are computed, and why precision and recall change with trajectory length. It also asks about \"action repeat.\" While the comment identifies areas of confusion, it does not provide explicit instructions or suggestions for the authors to clarify these points. The actions are implicit, as the authors can infer that they need to provide clearer explanations or context for these elements. However, the comment lacks concrete guidance on how to address these issues, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the figure, such as the unclear meaning of \"1200 frames,\" the computation of values, the relationship between precision and recall with trajectory length, and the definition of \"action repeat.\" This provides clear guidance on what needs to be clarified or addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and requests for clarification about the content of Figure 4, rather than making subjective claims or opinions. It does not contain any claims that require verification, as it is purely factual and seeks to understand the details of the figure. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas of confusion in Figure 4, such as the meaning of \"1200 frames,\" how the values are computed, and the relationship between precision and recall with trajectory length. It also questions the definition of \"action repeat.\" While the comment highlights these issues, it does not provide suggestions or guidance on how the authors might address these concerns or improve the clarity of the figure. The feedback is 3 as it points out areas needing clarification, but it lacks actionable advice for improvement, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the arbitrariness of design decisions, such as the number of initial ground truth examples and labeled examples. It suggests that the authors should provide justification for these choices, particularly in the context of costeffectiveness. The comment implies that the authors should consider providing a rationale for their design decisions to improve the paper. However, it does not explicitly instruct the authors to do so, leaving the action somewhat vague. The authors can infer that they need to justify their design decisions, but the comment does not provide specific guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific design decisions, such as the number of initial ground truth examples and labeled examples, suggesting that these choices are arbitrary. It implies that the authors should provide justification for these decisions, particularly in the context of costeffectiveness. However, the comment does not explicitly mention which part of the paper these design decisions are discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should provide justification for these decisions, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the arbitrariness of design decisions, such as the number of initial ground truth examples and labeled examples. The reviewer suggests that the authors should provide justification for these choices, particularly in the context of costeffectiveness. However, the comment lacks specific examples or references to support the claim that these design decisions are arbitrary or that a different approach would be more satisfactory. Without detailed reasoning or evidence, the claim remains 3, as the authors may find it challenging to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the arbitrariness of design decisions, specifically the number of initial ground truth examples and labeled examples. It suggests that the authors should provide justification for these choices, particularly in the context of costeffectiveness. The comment implies that the authors should consider providing a rationale for their design decisions to improve the paper\"s soundness. However, the comment could be more helpful if it offered specific examples or suggestions for how to justify these decisions. Overall, the feedback is 3 as it highlights an area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the motivation for investigating a graphstructured model, suggesting that the approach might be unnecessarily complex. However, it does not provide explicit guidance or suggestions on how the authors could address this concern or simplify their approach. The comment implies that the authors should consider simplifying their model or providing a clearer rationale for their choice, but it lacks concrete steps or examples. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the motivation for investigating a graphstructured model, specifically questioning the need for it given that the encoder and decoder are based on Transformer, which can already capture global dependencies. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion on the model\"s motivation. The authors might infer that it relates to the introduction or motivation section, but this inference is not direct. The comment is specific in its critique of the motivation, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the motivation for investigating a graphstructured model, suggesting that the approach might be unnecessarily complex given that the Transformer encoder and decoder can already capture global dependencies. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or detailed analysis to substantiate the assertion that the current approach is overly complex. As a result, the claim is 3, as it provides a general critique but lacks the depth and specificity needed for full verification.", "helpfulness_rationale": "The review comment raises a concern about the motivation for investigating a graphstructured model, suggesting that the approach might be unnecessarily complex given the capabilities of the Transformer encoder and decoder in capturing global dependencies. While the comment identifies a potential issue with the motivation, it lacks specific suggestions or guidance on how the authors might address this concern or simplify their approach. The feedback is 3 as it prompts the authors to reconsider their motivation and possibly streamline their methodology, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests two actions. First, it recommends providing videos demonstrating different policies controlling cars on various tracks to aid in understanding how different methods work. This is an explicit and concrete action that the authors can take to enhance the reproducibility of their work. Second, it points out the lack of implementation details in the main paper, which makes it difficult to reproduce the results. It also questions the policy gradient approach used, indicating that this is an area needing clarification. While the first action is explicit and concrete, the second part is more of an implicit suggestion, as it implies that the authors should provide more details. Therefore, the comment is 4, as it provides clear guidance on one aspect and hints at another area for improvement.", "grounding_specificity_rationale": "The comment suggests providing videos to demonstrate different policies controlling cars on different tracks, which is a specific request for enhancement. It also points out the lack of implementation details in the main paper, making it difficult to reproduce the results, and questions the policy gradient approach used. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the experimental setup or results sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two parts: a suggestion for providing videos to demonstrate different policies controlling cars on different tracks, and a critique of the lack of implementation details in the main paper, which makes it difficult to reproduce the results. The first part is a suggestion for improvement and does not contain a claim. The second part is a critique of the paper\"s lack of implementation details, which is a factual observation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two distinct pieces of feedback. First, it suggests that the authors provide videos demonstrating different policies controlling cars on various tracks, which would enhance the understanding of how different methods work. This is a clear and actionable suggestion that could significantly improve the reproducibility and clarity of the paper. Second, the comment points out the lack of implementation details in the main paper, making it difficult to reproduce the results, and questions the policy gradient approach used. This feedback is valuable as it highlights specific areas where the paper could be improved, particularly in terms of reproducibility and clarity. However, the comment could be more helpful if it provided specific examples or guidance on how to address these issues. Overall, the feedback is 4, as it identifies important areas for improvement and provides some direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It questions the approximation used in Equation 11 and suggests that the authors should provide more detailed explanations or experiments to support their claims. Additionally, it points out that Figure 1 does not clearly indicate which specific layer each color represents, suggesting that the authors should conduct more experiments and theoretical analyses to address this issue. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these additional experiments or analyses. The authors can infer that they need to provide more detailed explanations and evidence, but the comment does not offer concrete steps on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 11\" and \"Figure 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the approximation used in Equation 11 and suggests that the authors should provide more detailed explanations or experiments to support their claims. Additionally, it points out a limitation in Figure 1 regarding the representation of layer parameters. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point raises a question about the approximation used in Equation 11 and suggests that the authors should provide more detailed explanations or experiments to support their claims. It also points out a limitation in Figure 1, where the representation of layer parameters is unclear. While the comment identifies specific areas for improvement, it lacks detailed reasoning or references to support the claims. The authors would need to conduct further analysis to fully understand and address the issues raised, making the comment 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the approximation used in Equation 11, questioning its validity and suggesting that the authors should provide more detailed explanations or experiments to support their claims. It also points out a limitation in Figure 1, where the representation of layer parameters is unclear, and suggests that the authors should conduct more experiments and theoretical analyses to address this issue. This feedback is clear and actionable, as it identifies specific areas where the authors can improve their work by providing additional evidence and analysis. However, the comment could be more helpful if it offered specific suggestions on how to conduct these additional experiments or analyses. Overall, the comment is 4, as it provides valuable insights for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that the approach of offlinetoonline learning adaptation is incremental, given that most previous offline RL benchmarks are based on simulation environments and rulebased reward functions. It implies that implementing online finetuning on top of existing benchmarks is feasible. However, the comment does not provide explicit guidance or concrete steps for the authors to take to address this issue. The action is implicit and vague, as it does not specify how to implement the online finetuning or what specific aspects need to be considered. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of offlinetoonline learning adaptation, suggesting that it is incremental due to the reliance on simulation environments and rulebased reward functions in previous offline RL benchmarks. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to implement online finetuning on existing benchmarks, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"addressing offlinetoonline learning adaptation appears to be incremental\" because most previous offline RL benchmarks are based on simulation environments and rulebased reward functions. The comment suggests that implementing online finetuning on top of existing benchmarks is feasible. However, the claim lacks specific examples or references to support the assertion that the approach is incremental. Without detailed evidence or examples, the claim remains 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment makes an observation about the incremental nature of offlinetoonline learning adaptation, suggesting that it is feasible to implement online finetuning on existing benchmarks. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their approach. It lacks actionable advice or detailed feedback that would help the authors enhance their draft. As a result, the comment is not particularly helpful in guiding the authors toward improving their work, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights specific instances where the results contradict the claim that emotionawareness could be useful for synthetic text detection. It provides examples of models, such as AT and GAS, that perform worse than BERTsynth and other models, respectively. However, the comment does not offer any explicit or implicit suggestions for how the authors might address these contradictions or improve their draft. There is no guidance on potential changes, analyses, or additional experiments that could be conducted to clarify or support the claim. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed examples of contradicting evidence, such as the comparison between AT and BERTsynth, and the low F1 score of GAS. The comment clearly specifies what needs to be addressed in terms of clarifying the results and supporting the claim about the usefulness of emotionawareness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results in Table 6 contradict the claim that emotionawareness could be useful for synthetic text detection. The reviewer provides specific examples, such as the comparison between AT and BERTsynth, and the low F1 score of GAS, to support this claim. However, the comment lacks detailed reasoning or references to substantiate why these results are contradictory or how they impact the overall argument. The examples provided are clear, but the lack of additional context or explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies specific contradictions in the results presented in Table 6, providing concrete examples of models that perform worse than expected. It highlights issues with AT and GAS, noting that they achieve lower F1 scores despite being finetuned with emotion classification datasets. This feedback is valuable as it points out areas where the claims about the usefulness of emotionawareness might not hold, prompting the authors to reconsider their conclusions. However, the comment could be more helpful if it offered suggestions on how to address these contradictions or how to strengthen the argument. Overall, the comment is 4 as it directs the authors\" attention to critical issues in their results, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review point suggests conducting more experiments to address the research question and demonstrate the method\"s generalizability. It specifically recommends testing with Vision Transformers (ViT) and including results under more complex input noise models, such as those involving multiplicative distortions. The comment provides explicit actions for the authors to take, such as testing with specific models and evaluating under different noise models. This level of detail gives the authors clear guidance on how to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment suggests conducting more experiments to address the research question and demonstrate the method\"s generalizability. It specifically recommends testing with Vision Transformers (ViT) and including results under more complex input noise models, such as those involving multiplicative distortions. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the experimental section or results. The suggestion is specific, as it provides clear guidance on what additional experiments should be conducted. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point suggests conducting more experiments to address the research question and demonstrate the method\"s generalizability. It recommends testing with Vision Transformers (ViT) and evaluating under more complex input noise models, such as those involving multiplicative distortions. The comment provides specific examples of models to test and suggests additional experiments to enhance the evaluation. This level of detail and specificity supports the claim, making it 4. However, the comment could be further strengthened by referencing specific studies or providing more detailed reasoning for why these experiments are necessary. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific and actionable suggestions for improving the paper by recommending additional experiments to address the research question and demonstrate the method\"s generalizability. It suggests testing with Vision Transformers (ViT) and evaluating under more complex input noise models, such as those involving multiplicative distortions. These suggestions are clear and provide a roadmap for the authors to enhance their experimental design and results. By offering concrete directions for improvement, the comment is 5 in guiding the authors to strengthen their work. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly states that the number of human annotators mentioned in the D.2 appendix should be four, based on the author responses. This provides a clear and direct action for the authors to take, which is to adjust the number of annotators mentioned in the appendix. The comment is specific and gives precise guidance on how to implement the change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"D.2 appendix,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the incorrect number of human annotators mentioned in the appendix, suggesting it should be four. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the number of human annotators mentioned in the D.2 appendix. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive and factual, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it points out an inconsistency in the number of human annotators mentioned in the D.2 appendix. It suggests that the number should be four, based on the author\"s responses. This feedback is clear and provides a direct path for the authors to correct the information in their manuscript, improving the accuracy and clarity of their documentation. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not provide specific guidance on how to develop this motivation or what aspects should be emphasized. The action is implicit, as the authors can infer that they need to provide more detailed explanations or justifications for the encoder and decoder structure, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not specify which part of the paper this motivation should be included in, making it weakly grounded. The comment is specific in its suggestion to provide a better motivation, but without clear guidance on how to achieve this, it lacks specificity. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point suggests that a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that providing a better motivation for the encoder and decoder structure would enhance the understanding of the proposed approach. While it identifies a potential area for improvement, it lacks specific guidance or suggestions on how to develop this motivation or what aspects should be emphasized. The comment is 3 as it points out a potential weakness in the paper, but it does not offer detailed feedback or actionable steps for the authors to address this issue. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises several concerns about the novelty of the paper, suggesting that the loss functions explored are not new. It provides some guidance by mentioning the use of JS divergence, masked CE loss, and masked spherical loss, which have not been commonly used in segmentation attacks. However, the comment does not explicitly instruct the authors to address these issues or suggest specific actions to enhance the novelty of their work. The mention of whitebox attacks and the absence of blackbox evaluation is noted, but the comment does not provide concrete guidance on how to improve these aspects. The suggestion to extend the analysis to targeted attacks is a specific action, but the lack of detailed guidance on how to do so makes the comment 3. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several concerns about the novelty of the paper, specifically regarding the use of loss functions like JS divergence, masked CE loss, and masked spherical loss. It also points out the absence of blackbox evaluation and the focus on untargeted attacks, suggesting that the analysis should be extended to targeted attacks. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the methodology and results sections. The comment is specific in detailing what needs to be addressed, such as the novelty of the loss functions and the need for blackbox evaluation and targeted attacks. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the novelty of the paper, specifically regarding the use of loss functions like JS divergence, masked CE loss, and masked spherical loss. The reviewer claims that these loss functions are not new, which is a subjective opinion. The comment provides some reasoning by noting that these loss functions have not been commonly used in segmentation attacks, but it lacks specific references or detailed examples to substantiate the claim. The mention of whitebox attacks and the absence of blackbox evaluation is also a point of concern, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3, as it provides some reasoning but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises several concerns about the novelty of the paper, specifically regarding the use of loss functions like JS divergence, masked CE loss, and masked spherical loss. It points out that these loss functions are not new, which is a significant concern. The comment also highlights the absence of blackbox evaluation and the focus on untargeted attacks, suggesting that the analysis should be extended to targeted attacks to showcase the strength of the proposed attack method. While the comment identifies important areas for improvement, it lacks specific suggestions or guidance on how to address these issues or enhance the novelty of the paper. The feedback is 3 as it provides direction for the authors to consider, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. It also recommends including results for CIFAR100. While the comment implies that the authors should conduct a direct comparison and include results for an additional dataset, it does not provide specific guidance on how to perform the comparison or what aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the feedback. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"CIFAR10\" and \"CIFAR100,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by stating that the results for CIFAR10 are not impressive and suggests a direct comparison with other approaches, as well as recommending results for CIFAR100. This provides clear guidance on what needs to be addressed and improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results for CIFAR10 are not impressive and suggests that a direct comparison with other approaches is necessary. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the results are not impressive or what aspects of the comparison are missing. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand and address the feedback effectively.", "helpfulness_rationale": "The review comment identifies a specific issue with the results for CIFAR10, noting that they are not impressive compared to other approaches mentioned in the paper. It suggests that a direct comparison is necessary and recommends including results for CIFAR100. This feedback is clear and actionable, as it highlights a potential weakness in the paper and provides a concrete suggestion for improvement. However, the comment could be more helpful if it offered additional guidance on how to conduct the comparison or what aspects of the results should be emphasized. Overall, the comment is 4, as it effectively directs the authors to a specific area for improvement but could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that hyperbolic space is known to be suitable for hierarchical datasets, but it does not provide any specific guidance on how the authors should demonstrate this suitability in their experiments. The comment lacks explicit instructions or suggestions on what aspects of the experiments could be enhanced to showcase the benefits of hyperbolic space. Without concrete guidance, the authors are left without a clear understanding of how to address this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a known suitability of hyperbolic space for hierarchical datasets but notes that none of the experiments clearly demonstrate this. However, it does not specify which part of the paper discusses the experiments or where the demonstration of hyperbolic space\"s suitability is lacking. The authors might infer that it relates to the experimental section, but this inference is not direct. The comment is specific in identifying the issue but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that hyperbolic space is known to be suitable for hierarchical datasets, but it does not provide any supporting evidence or references to substantiate this claim. The comment lacks specific examples or references to external studies or literature that demonstrate the effectiveness of hyperbolic space in handling hierarchical datasets. Without this additional information, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a known characteristic of hyperbolic space, which is its suitability for hierarchical datasets, but it points out that the experiments in the paper do not clearly demonstrate this. This feedback highlights a gap in the paper\"s demonstration of the theoretical advantages of hyperbolic space, which is a valuable insight for the authors to address. However, the comment lacks specific suggestions or guidance on how the authors might demonstrate this suitability in their experiments. While it points out an area for improvement, it does not provide actionable steps for the authors to take, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the main strength of MixBoost, specifically asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. While the comment identifies areas of confusion, it does not provide explicit guidance on how the authors should address these questions or what specific actions they should take to clarify the strengths of their method. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the main strength of MixBoost, specifically asking whether it is related to computational savings, generalization performances, or the use of Random Fourier Features. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs clarification. While the questions are specific, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the main strength of MixBoost, specifically regarding computational savings, generalization performance, and the use of Random Fourier Features. These are factual inquiries that do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the main strength of MixBoost, specifically asking whether it is related to computational savings, generalization performance, or the use of Random Fourier Features. This inquiry seeks clarification on the key aspects of the method, which could help the authors better understand and communicate the significance of their work. However, the comment does not provide specific suggestions or guidance on how the authors might address these questions or improve their paper. While it identifies an area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a point of surprise regarding the use of the test set for hyperparameter tuning, suggesting that it is a surprising choice. The reviewer agrees that proper hyperparameter tuning is essential in machine learning but finds the wording challenging. Additionally, the comment suggests that the \"smaller training set\" could be avoided by training the network with optimal parameters on the complete training and validation sets. While the comment provides some guidance on how to address the issue, it lacks explicit instructions on how to implement the suggested changes. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions line 243 and line 245, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the wording regarding the use of the test set for hyperparameter tuning and suggests an alternative approach to avoid the \"smaller training set\" by training on the complete training and validation sets. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two parts: a comment on the use of the test set for hyperparameter tuning and a suggestion to avoid the \"smaller training set.\" The first part expresses agreement with the necessity of proper hyperparameter tuning in machine learning but critiques the wording. The second part suggests an alternative approach to training the network with optimal parameters on the complete training and validation sets. While the comment provides some reasoning about the importance of hyperparameter tuning, it lacks specific examples or references to support the claim about the wording being challenging. The suggestion to avoid the \"smaller training set\" is logical but could be more robust with additional justification or evidence. Overall, the comment is 3, as it provides some reasoning but requires more detailed support to be fully actionable.", "helpfulness_rationale": "The review comment identifies a point of surprise regarding the use of the test set for hyperparameter tuning, which is a critical aspect in machine learning. It acknowledges the importance of proper hyperparameter tuning but critiques the wording, suggesting it could be more precise. Additionally, the comment offers a constructive suggestion to avoid the \"smaller training set\" by training the network with optimal parameters on the complete training and validation sets. This feedback is clear and actionable, providing the authors with specific areas to consider and improve their draft. However, the comment could be more helpful if it included examples or further elaboration on the suggested changes. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the introduction is too vague and lacks detailed explanations about how parameters are tokenized and how DDPM is used to predict them. The reviewer provides a specific action by suggesting that the authors hint at these details to gain clearer insights. While the action is explicit, it lacks concrete guidance on what specific details should be included or how to effectively convey them. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment suggests that the introduction is too vague and lacks detailed explanations about the implementation of parameters and the use of DDPM. It provides a specific suggestion to hint at these details to improve clarity. However, the comment does not explicitly mention which part of the introduction is unclear or vague, making it weakly grounded. The authors can infer that it relates to the introduction, but this inference is not as direct as it could be. The comment is specific in suggesting what needs to be clarified, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduction is \"quite obscure and highlevel,\" lacking detailed explanations about the implementation of parameters and the use of DDPM. The reviewer suggests that the authors should provide more specific hints on these aspects to gain clearer insights. While the comment identifies a potential issue with the introduction, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to hint at specific details is 3, as it provides a direction for improvement but does not fully support the initial claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the introduction, noting that it is too vague and lacks detailed explanations about the implementation of parameters and the use of DDPM. The reviewer provides a specific suggestion to include hints about these aspects, which could help the authors gain clearer insights. This feedback is actionable and offers a clear direction for improvement, making it 4. However, it could be more helpful if it included examples or further guidance on what specific details should be included. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the presentation is not good and suggests that the authors \"name a few.\" However, it does not specify which aspects of the presentation are lacking or provide any guidance on what the authors should do to improve it. The comment lacks explicitness and concreteness, leaving the authors uncertain about what specific areas need attention or how to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment indicates that the presentation is not good, but it does not specify which part of the presentation is lacking or how it could be improved. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the presentation are considered poor or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the presentation is not good, but it lacks any supporting evidence, reasoning, or specific examples to substantiate this claim. Without additional context or details, the authors may find it challenging to understand what aspects of the presentation are considered unsatisfactory. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment indicates that the presentation is not good, but it lacks specificity and does not provide any guidance or suggestions on how to improve it. It simply suggests that the authors \"name a few,\" which is vague and does not offer actionable advice. Without detailed feedback or constructive suggestions, the authors are left without a clear path to enhance their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing reference in the related work section, specifically mentioning the work by Rieck et al. 2. This provides a clear and direct action for the authors to take, which is to include this reference in their draft. The comment is specific and gives precise guidance on how to improve the draft by adding the missing citation. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the work by Rieck et al. 2, which should be included in the related work section. This provides clear guidance on what needs to be addressed to improve the draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper misses the work by Rieck et al. 2, specifically mentioning the correlation of topological complexity with generalization ability. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the related work section, pointing out that the paper does not reference the work by Rieck et al. 2, which is relevant to the discussion of the correlation between topological complexity and generalization ability. This feedback is clear and actionable, as it directs the authors to include this missing reference to strengthen their literature review and provide a more comprehensive context for their work. By addressing this omission, the authors can enhance the depth and relevance of their paper. Therefore, the comment is rated as 4, as it provides a clear and constructive suggestion for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the usefulness of the exploration parameter gamma, given that only upperbounds on the pseudoregret are provided. It suggests that the choice of gamma=0 might be optimal and questions the analysis\"s reliance on expectations, asking if it can be extended to highprobability bounds on the regret. The comment implies that the authors should consider providing a remark on highprobability upperbounds and the role of gamma. While the action is implicit, it is concrete in terms of suggesting specific areas for improvement, such as providing a remark on highprobability bounds and the role of gamma. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Alg 1 and Thm 3.1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the usefulness of the exploration parameter gamma, given the limited information on upperbounds on the pseudoregret. The comment suggests that the choice of gamma=0 might be optimal and questions the analysis\"s reliance on expectations, asking if it can be extended to highprobability bounds on the regret. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the usefulness of the exploration parameter gamma, given that only upperbounds on the pseudoregret are provided. It suggests that the choice of gamma=0 might be optimal and questions the analysis\"s reliance on expectations, asking if it can be extended to highprobability bounds on the regret. The comment provides a logical reasoning by pointing out the limitations of the current analysis and suggesting a potential improvement. However, it lacks specific examples or references to support the claim that the analysis is heavily based on expectations. This makes the claim 3, as the authors would need to further explore and substantiate the reasoning themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the exploration parameter gamma, noting that only upperbounds on the pseudoregret are provided, which may render gamma less useful. It suggests that the choice of gamma=0 might be optimal and questions the analysis\"s reliance on expectations, asking if it can be extended to highprobability bounds on the regret. This feedback is clear and actionable, as it prompts the authors to consider providing a remark on highprobability bounds and the role of gamma. However, the comment could be more helpful if it offered specific suggestions or examples on how to extend the analysis to highprobability bounds. Overall, the comment is 4, as it provides valuable insights and directions for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to address a specific issue by adding a restatement of the definition of the LCA relaxation from Wang et. al. or to include a description in the appendix. This feedback provides clear and direct guidance on what needs to be done to improve the paper, making it 5. The authors know exactly what action to take to resolve the issue, which aligns with the criteria for a 5 comment.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 150,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a direct definition of the LCA relaxation, and provides a clear suggestion for resolution by either restating the definition from Wang et. al. or adding a description to the appendix. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification and suggests a specific action to be taken, which does not involve making a subjective claim or judgment. It is a factual request for additional information or a suggestion for improvement, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue in the paper, namely the lack of a direct definition of the LCA relaxation on line 150. It provides a clear and actionable suggestion to address this issue by either restating the definition from Wang et. al. or adding a description to the appendix. This feedback is precise and offers a concrete way for the authors to improve the clarity and comprehensiveness of their paper. By addressing this feedback, the authors can enhance the readability and understanding of their work, making the comment highly valuable for their revision efforts."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the dataset description is thorough but implies that more information on how validation and test splits influence model training could strengthen reproducibility. While the action is implicit, it is concrete because it specifies what additional information is needed to enhance reproducibility. The authors know that they need to provide more details on the validation and test splits to improve the reproducibility of their results. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the dataset description is thorough but implies that more information on how validation and test splits influence model training could strengthen reproducibility. However, it does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in suggesting that more details on validation and test splits are needed to enhance reproducibility, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the dataset description is thorough but implies that more information on how validation and test splits influence model training could strengthen reproducibility. However, the comment does not provide specific examples or detailed reasoning to support why this information is crucial or how it would enhance reproducibility. The lack of explicit evidence or examples makes it difficult for the authors to understand the basis of the claim, rendering it 2. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment acknowledges that the dataset is thoroughly described but suggests that providing more information on how validation and test splits influence model training could strengthen reproducibility. This feedback is 3 as it identifies a potential area for improvement in the paper. However, it lacks depth and does not offer specific suggestions or examples on how to enhance the reproducibility of the results. The authors are left with a general direction for improvement but without detailed guidance on how to achieve it. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises several questions and suggests areas for exploration, such as considering other regularization techniques like L2 regularization, data augmentation, and adding noise. It also questions the practicality of using ZeroLiers together with these techniques. While the comment implies that the authors should explore these additional regularization methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should consider these techniques and their combinations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the authors\" approach to addressing overfitting, specifically questioning the use of dropout and suggesting the consideration of other regularization techniques like L2 regularization, data augmentation, and adding noise. It also inquires about the practicality of using ZeroLiers together with these techniques. However, the comment does not specify which part of the paper discusses the regularization techniques or where these questions should be addressed. The authors can infer that it relates to the sections discussing regularization methods, but this inference is not direct. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions and suggestions about the authors\" approach to addressing overfitting, specifically questioning the use of dropout and suggesting the consideration of other regularization techniques like L2 regularization, data augmentation, and adding noise. While the comment raises valid points about the practicality of using multiple regularization techniques, it does not provide specific evidence or references to support the claim that the authors should consider these techniques. The questions are more of a request for clarification rather than a claim that requires verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions and suggestions regarding the authors\" approach to addressing overfitting. It questions the use of dropout and suggests considering other regularization techniques like L2 regularization, data augmentation, and adding noise. Additionally, it inquires about the practicality of using ZeroLiers together with these techniques. This feedback is valuable as it prompts the authors to explore a broader range of regularization methods and their combinations, which could lead to more robust and generalizable models. However, the comment could be more helpful if it provided specific guidance or examples on how to implement these suggestions. Overall, the comment is 4 as it identifies areas for improvement and encourages the authors to consider additional regularization techniques, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should discuss the generalization of Assumption A to the function approximation setting, given that it is mentioned in the section about consistency. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so or what specific aspects to focus on. The action is implicit and somewhat vague, as the authors need to infer that they should expand on this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption A (overlap)\" and the section about consistency, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the generalization of the assumption to the function approximation setting. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the generalization of Assumption A to the function approximation setting, suggesting that it is fine in a tabular setting but not necessarily in a function approximation context. The comment implies that the authors should discuss this generalization, but it does not provide specific reasoning or examples to support why this generalization might be problematic or how it could be addressed. The lack of detailed justification or references makes the claim 3, as the authors would need to infer the basis of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the generalization of Assumption A to the function approximation setting, noting that it is fine in a tabular setting but not necessarily in this context. It suggests that the authors should discuss this generalization, implying that it could be beneficial to address this point. While the comment highlights a specific area for improvement, it lacks detailed guidance or suggestions on how to approach this generalization or what aspects to consider. The feedback is 3 as it points out a potential weakness and encourages the authors to expand on their discussion, but it could be more actionable with additional details. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment provides explicit actions for the authors to take. It suggests that Table 1 should be one column wide and that figures, particularly Figures 3, 5, and 6, would benefit from a twocolumn width. Additionally, it notes that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. These suggestions are concrete and provide clear guidance on how to enhance the paper\"s readability and layout. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Figures 3, 5, and 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by recommending that Table 1 should be one column wide and that the figures would benefit from a twocolumn width. Additionally, it notes that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that Table 1 should be one column wide and that Figures 3, 5, and 6 would benefit from a twocolumn width. It also notes that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. While the comment provides some guidance on formatting, it lacks specific examples or detailed reasoning to fully substantiate the claim that the paper is difficult to understand. The suggestion to improve the layout and readability is 3, as it highlights areas for potential enhancement, but it could be strengthened with more detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the formatting and readability of the paper. It suggests that Table 1 should be one column wide and that Figures 3, 5, and 6 would benefit from a twocolumn width. Additionally, it notes that the paper was not easy to understand during the first read and suggests that major improvements could be achieved by straightening up the content. This feedback is clear and provides the authors with concrete steps to enhance the clarity and layout of their paper, making it 5. The comment offers a comprehensive guide for improving the draft, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests a modification to the TextDPO baseline by using perturbed images for additional imagequestionanswer triplets. It implies that the perturbation of images is the source of the performance benefit, rather than the specific DPO objective. However, the comment does not provide explicit instructions on how to implement this change or what specific aspects should be addressed. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a modification to the TextDPO baseline by using perturbed images for additional imagequestionanswer triplets. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment does specify what the authors should consider, namely the use of perturbed images and the potential source of performance benefits. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests a modification to the TextDPO baseline by using perturbed images for additional imagequestionanswer triplets. However, it lacks specific examples or detailed reasoning to support the claim that the perturbation of images is the source of the performance benefit. The comment does not provide enough evidence or justification to fully substantiate the claim, making it difficult for the authors to understand and address the suggestion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests a modification to the TextDPO baseline by using perturbed images for additional imagequestionanswer triplets. It implies that the perturbation of images might be the source of the performance benefit, rather than the specific DPO objective. However, the comment does not provide specific guidance or suggestions on how to implement this change or what aspects of the performance benefit should be explored. While it offers an interesting angle for further investigation, the feedback lacks actionable details, making it 3 but incomplete. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the assumption that there is no difference in expertise between Alice and Bob. It suggests that in many realworld humanAI collaboration tasks, this assumption may not hold, and there could be nonlinear interactions between success rate and speedup due to differing levels of expertise. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this concern or incorporate it into their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific assumption regarding the expertise levels of Alice and Bob, suggesting that this assumption may not hold in realworld humanAI collaboration tasks. However, it does not explicitly mention which part of the paper this assumption is discussed in, making it weakly grounded. The comment is specific in detailing the issue with the assumption and suggesting that there could be nonlinear interactions between success rate and speedup due to differing levels of expertise. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that there is no difference in expertise between Alice and Bob. It suggests that in many realworld humanAI collaboration tasks, this assumption may not hold, and there could be nonlinear interactions between success rate and speedup due to differing levels of expertise. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The reasoning is logical but lacks detailed evidence or examples, which limits the verifiability of the claim. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a critical assumption in the paper, namely that there is no difference in expertise between Alice and Bob. It highlights a potential weakness in the paper by pointing out that in many realworld humanAI collaboration tasks, this assumption may not hold, and there could be nonlinear interactions between success rate and speedup due to differing levels of expertise. This feedback is valuable as it prompts the authors to reconsider their assumptions and explore the implications of varying expertise levels in their work. However, the comment could be more helpful if it provided specific suggestions on how to address this issue or examples of realworld tasks where this assumption might not hold. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the generalizability of the framework due to the specificity of the mitigation strategies, such as sanitizing the data. It suggests that the framework may not be applicable to other LLMs or datasets. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes could be made to improve generalizability. The action is implicit and vague, as it does not specify how to make the framework more generalizable or what steps should be taken to achieve this. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of generalizability of the framework, specifically mentioning the specificity of mitigation strategies like sanitizing the data. However, it does not explicitly mention which part of the paper discusses these strategies, making it weakly grounded. The comment is specific in detailing the concern about the framework\"s applicability to other LLMs and datasets, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the mitigation strategies, such as sanitizing the data, are datasetspecific and may limit the framework\"s generalizability. The comment provides a logical reasoning by suggesting that the framework may not be applicable to other LLMs or datasets due to this specificity. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the framework regarding its generalizability. It points out that the mitigation strategies, such as sanitizing the data, are datasetspecific and may not be applicable to other LLMs or datasets. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors should consider the broader applicability of their framework. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this limitation or how to enhance the framework\"s generalizability. Overall, the comment is 3 as it directs the authors\" attention to an important aspect of their work that needs further exploration and refinement."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the paper is not sufficiently clear in certain aspects, but it does not specify which aspects or provide detailed guidance on how to improve clarity. The comment mentions a list of questions but does not elaborate on them, leaving the authors without specific direction on what needs to be clarified or improved. Without explicit actions or concrete suggestions, the authors are left to infer what changes are needed, making the comment 3. Therefore, this comment is rated as 3.", "grounding_specificity_rationale": "The comment indicates that the paper is not sufficiently clear in some aspects but does not specify which aspects or provide detailed guidance on how to improve clarity. It mentions a list of questions but does not elaborate on them, making it difficult for the authors to identify the specific areas needing clarification. Since the comment lacks grounding and specificity, it does not provide the authors with clear guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is not sufficiently clear in some aspects, but it does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what is unclear, the authors may find it challenging to address the feedback effectively. The lack of specific guidance or references makes the claim 2, as it provides a general critique without detailed justification. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment indicates that the paper is not sufficiently clear in certain aspects, but it does not specify which aspects or provide detailed guidance on how to improve clarity. The comment suggests that the weaknesses could be fixed until the final submission, but it lacks actionable feedback or specific suggestions for improvement. Without concrete examples or detailed advice, the authors are left with a general impression of the need for clarification but without a clear path forward. Therefore, the comment is 3, as it highlights an area for improvement but does not fully support the authors in making those improvements. This aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses two questions: \"Are the natural and synthetic audio signals related to the task conditions referenced in Figure 2?\" and \"What task are participants performing?\" These questions are explicit and direct, as they clearly instruct the authors to clarify the relationship between the audio signals and the task conditions, as well as to specify the task being performed. The authors can directly address these questions by providing additional context or clarification in their draft. However, the comment does not provide specific guidance on how to address these questions, such as suggesting what kind of clarification is needed or how to present the information. Therefore, the action is explicit but somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task being performed by the participants. This provides clear guidance on what aspects of the paper require further clarification or explanation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task being performed by participants. These are factual inquiries that do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the relationship between natural and synthetic audio signals and the task conditions referenced in Figure 2, as well as the task being performed by participants. These questions are clear and direct, prompting the authors to clarify and provide additional context in their draft. By addressing these questions, the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to present or clarify these points. Overall, the feedback is 3 as it identifies areas for improvement but lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not address other problems in open domain dialogue, such as memory to register and personalize to user characteristics, and reasoning over common sense and facts. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address these issues or what specific aspects they should focus on. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the authors\" paper, mentioning that they did not address other problems in open domain dialogue, such as memory to register and personalize to user characteristics, and reasoning over common sense and facts. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the content it addresses, it lacks grounding as it does not provide clear guidance on where in the paper these issues are discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors did not address other problems in open domain dialogue, such as memory to register and personalize to user characteristics, and reasoning over common sense and facts. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the exact issues that need to be addressed. Without detailed justification or evidence, the claim is not 5, leaving the authors uncertain about how to improve their draft. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a specific area where the authors\" work could be improved by addressing other problems in open domain dialogue, such as memory to register and personalize to user characteristics, and reasoning over common sense and facts. This feedback is 3 as it highlights a potential gap in the paper\"s scope and suggests areas for further exploration. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address these issues. Without actionable advice, the authors are left with a general idea of what needs to be improved but without a clear path forward. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the lack of statistical distribution on paper venues, specifically questioning the number of papers from ACL and EMNLP versus Arxiv. It also expresses reservations about including Arxiv papers in the study, suggesting that they are not considered formal publications and may not be reliable sources. While the comment highlights a potential issue with the study\"s methodology, it does not provide explicit guidance on how the authors should address these concerns or what specific actions they should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, making it difficult for the authors to know how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the statistical distribution of papers on different venues, particularly focusing on the number of papers from ACL and EMNL versus Arxiv. It also raises reservations about including Arxiv papers in the study, suggesting that they are not considered formal publications and may not be reliable sources. This provides clear guidance on what the authors need to address, making the comment specific. However, it does not explicitly mention which part of the paper this issue pertains to, such as a section discussing venue distributions or results. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a claim about the lack of statistical distribution on paper venues, specifically questioning the number of papers from ACL and EMNLP versus Arxiv. The reviewer expresses reservations about including Arxiv papers in the study, citing their potential bias and lack of quality. While the comment provides a logical reasoning for the concern, it lacks specific data or references to support the claim about the number of papers from these venues. The mention of Arxiv papers being considered junk and not formal publications adds some context but does not fully substantiate the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed evidence or references to fully substantiate it.", "helpfulness_rationale": "The review comment raises a valid concern about the lack of statistical distribution on paper venues, specifically questioning the number of papers from ACL and EMNLP versus Arxiv. It also expresses reservations about including Arxiv papers in the study, citing their potential bias and lack of quality. This feedback is 3 as it identifies a potential issue with the study\"s methodology and encourages the authors to consider the representativeness of their data. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns, such as suggesting alternative venues or methods for ensuring a balanced representation of papers. Overall, the comment offers some insight but lacks actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending excessive space on applications. While the comment implies that the authors should prioritize the problem and framework, it does not explicitly instruct them to do so or provide specific guidance on how to balance the content. The action is implicit and somewhat vague, as the authors need to infer that they should allocate more attention to the problem and framework. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should focus more on the proposed problem and framework rather than spending excessive space on applications. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or examples where the focus should be shifted. Without explicit references to sections or elements, the authors may find it challenging to determine where to make the necessary adjustments. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should focus more on the proposed problem and framework rather than applications. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should focus more on the proposed problem and framework rather than spending excessive space on applications. This feedback is 3 as it provides a direction for the authors to prioritize their content, potentially improving the clarity and relevance of their work. However, the comment lacks specific guidance on how to balance the content or what aspects of the problem and framework should be emphasized. Without detailed suggestions or examples, the authors may find it challenging to fully address the feedback. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper is marginally above the acceptance threshold and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not provide any specific guidance or suggestions for improvement. The comment lacks actionable details, such as recommending specific changes or clarifications, which would help the authors enhance their draft. As a result, the authors are left without a clear understanding of what steps to take to improve their work. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general assessment of the paper\"s marginally above acceptance threshold and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it does not specify which part of the paper this assessment pertains to, nor does it provide specific details on what aspects of the work are considered limitations or potential negative societal impacts. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is marginally above the acceptance threshold and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, the comment does not provide any specific evidence, reasoning, or examples to support the claim that the paper meets the acceptance threshold or that the authors have adequately addressed these issues. Without detailed justification or references, the claim remains 1, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a general assessment of the paper\"s marginally above acceptance threshold and acknowledges that the authors have adequately addressed the limitations and potential negative societal impact of their work. However, it lacks specificity and does not offer detailed feedback or suggestions on how the authors might improve their draft. Without actionable guidance or specific areas for enhancement, the comment does not provide the authors with a clear path forward for improving their work. Therefore, it is rated as 2, as it offers limited value to the authors in terms of actionable feedback."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the current dataset\"s simplicity could be addressed by an agent translating natural language into <source, path, destination> triples, potentially using code or search libraries. It also notes that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters. However, the comment does not provide explicit guidance on how the authors should address these issues or improve their draft. The feedback lacks concrete suggestions or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the simplicity of the current dataset and suggests that it could be addressed by an agent translating natural language into <source, path, destination> triples, using code or search libraries. It also notes that the natural language is generated by patterns, making natural language understanding easy. The comment further suggests that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters. However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the suggested improvements and the potential limitations of the research, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the current dataset is simple and could be solved by an agent translating natural language into <source, path, destination> triples, using code or search libraries. It also suggests that the natural language is generated by patterns, making natural language understanding easy. The comment further implies that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to fully understand and address the critique. The reasoning is 3 due to the lack of detailed evidence or references, but it provides a general direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the simplicity of the current dataset and suggests that it could be addressed by an agent translating natural language into <source, path, destination> triples, using code or search libraries. It also notes that the natural language is generated by patterns, making natural language understanding easy. The comment further implies that the paper may have limited research impact, as future studies might follow the path of the GSM8K dataset, using methods like PAL or LLMs with code interpreters. While the comment identifies a potential weakness in the dataset\"s complexity and suggests areas for improvement, it lacks specific guidance or actionable steps for the authors to address these issues. The feedback provides some insight into the limitations of the current approach but does not offer detailed suggestions on how to enhance the research impact or address the critique. Therefore, the comment is 3, as it highlights areas for improvement but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests revising a statement that claims the limitations of the proposed measure are not fairly discussed. It also points out that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not demonstrate experimental outperformance. While the comment implies that the authors should address these issues, it does not provide specific guidance on how to revise the statement or what aspects of the discussion need to be improved. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without explicit instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"25: masures\" and \"242: Possibly revise this statement,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out that the limitations of the proposed measure are not fairly discussed and that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures, nor does it demonstrate experimental outperformance. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not demonstrate experimental outperformance. The comment provides a logical reasoning by explaining that the limitations of the proposed measure are not adequately discussed, which supports the claim. However, it lacks specific examples or references to substantiate the claim further, making it 3. The authors would need to conduct additional research or provide more detailed evidence to fully validate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, pointing out that the limitations of the proposed measure are not adequately discussed. It suggests that the proposed measure does not provide a stronger theoretical connection to generalization than competing measures and does not demonstrate experimental outperformance. This feedback is clear and actionable, as it directs the authors to address a critical gap in their discussion. However, the comment could be more helpful if it provided specific suggestions on how to improve the theoretical or experimental aspects of the measure. Overall, the comment is 4, as it effectively highlights an area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out the absence of results from finetuned opensource large language models (LLMs) in the context of a domainspecific benchmark. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific results are missing or how they should be incorporated into the paper. Without explicit instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights the lack of results from finetuned opensource large language models (LLMs) in the context of a domainspecific benchmark. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where these results are typically discussed, the comment lacks full grounding. It is specific in identifying the missing results but does not provide detailed guidance on how to address this issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the lack of results from finetuned opensource large language models (LLMs) is important for a domainspecific benchmark. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the significance of this claim or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of results from finetuned opensource large language models (LLMs) in the context of a domainspecific benchmark. This is an important aspect that could enhance the paper\"s relevance and impact. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or incorporate these results into their work. Without actionable feedback or detailed suggestions, the authors are left without a clear path forward to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the training process of the regression model, including the input and output, the impact of different feature sizes on the parameter space of ridge regression models, and whether the number of parameters affects model performance. While the questions are explicit and direct, they do not provide concrete guidance on how the authors should address these issues or what specific changes to make. The authors are left to infer that they need to clarify these aspects in their draft, but without detailed instructions on how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several questions about the training process of the regression model, including the input and output, the impact of different feature sizes on the parameter space of ridge regression models, and the effect of the number of parameters on model performance. However, it does not specify which part of the paper these questions pertain to, such as specific sections or figures where the model is discussed. This makes it weakly grounded, as the authors cannot confidently determine which parts of the paper need attention. The comment is specific in detailing what needs to be clarified or addressed, but without grounding, it is not fully actionable. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the training process of the regression model, including the input and output, the impact of different feature sizes on the parameter space, and the effect of the number of parameters on model performance. These are factual inquiries that do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the training process of the regression model, including the input and output, the impact of different feature sizes on the parameter space, and the effect of the number of parameters on model performance. These questions are relevant and could guide the authors in clarifying and improving their methodology section. However, the comment lacks specific suggestions or guidance on how to address these issues or what changes could be made to enhance the clarity and robustness of the paper. While it provides valuable insights, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to add more ablation experiments to demonstrate the effectiveness of their proposed model. It specifies the particular aspects to focus on, such as the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This provides clear and concrete guidance on what additional experiments should be conducted, making the comment 5.", "grounding_specificity_rationale": "The comment suggests adding more ablation experiments to demonstrate the effectiveness of the proposed model, specifically focusing on the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. However, it does not specify which part of the paper these experiments should be added to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, providing clear guidance on the type of experiments required. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding ablation experiments to demonstrate the effectiveness of the proposed model, specifically focusing on the role of different updating methods and reweighting after selection. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these experiments are necessary or how they would demonstrate the effectiveness of the model. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors add more ablation experiments to demonstrate the effectiveness of their proposed model. It highlights two key areas to focus on: the role of different updating methods in decoupling the selecting and weighting outputs, and the role of reweighting after selection. This guidance is clear and constructive, offering a concrete way for the authors to enhance the comprehensiveness and robustness of their experimental results. By addressing these suggestions, the authors can significantly improve the clarity and impact of their work. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the experimental results can be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from specific works as baseline approaches for comparison. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement these suggestions, such as which datasets to use or how to integrate the adaptive mechanisms. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests improving the experimental results by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from specific works as baseline approaches for comparison. However, the comment does not specify which part of the paper discusses the experimental results or the datasets used, making it weakly grounded. The suggestion for improvement is specific, as it provides a clear direction for enhancing the experimental setup. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the experimental results can be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from specific works as baseline approaches for comparison. The suggestion is based on the idea that using more complex datasets could lead to better results, and the mention of adaptive mechanisms provides a logical basis for the suggestion. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore and justify the suggestion to fully understand its implications. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the experimental results can be improved by using more complex datasets and learning tasks, such as image datasets with thousands of dimensions and deep learning tasks. It also recommends considering adaptive mechanisms from specific works as baseline approaches for comparison. This feedback is clear and actionable, as it provides a direction for enhancing the experimental setup and offers a concrete suggestion for comparison. However, the comment could be more helpful if it included specific examples or detailed guidance on how to implement these suggestions. Overall, the comment is 4 as it identifies a potential area for improvement and provides a logical basis for the suggestion."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the experiment results and suggests that the relationship between temperature $\tau$ and downstream performance in Figure 5 does not adequately justify the use of a twostage pretraining approach. It questions the importance of reweighting using a positive or negative $\tau$ and notes that the results from Table 4 do not demonstrate the advantage of using PRESENCE. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback is somewhat vague and lacks concrete steps for the authors to take, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses specific experimental results and figures, such as Figure 5 and Table 4, which allows the authors to identify the parts of the paper being discussed. It also specifies the issues with the results, particularly the lack of justification for the twostage pretraining approach and the absence of advantages in using PRESENCE. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the experimental results, specifically questioning the justification for using a twostage pretraining approach and the importance of reweighting with a positive or negative $\tau$. The reviewer points out that the relationship between temperature $\tau$ and downstream performance in Figure 5 does not seem to justify the twostage pretraining. Additionally, the comment questions the results from Table 4, suggesting that they do not demonstrate the advantage of using PRESENCE. However, the comment lacks specific examples or detailed reasoning to fully substantiate these claims, making it 3. The authors would need to further develop their understanding of the experimental results to address these concerns effectively.", "helpfulness_rationale": "The review comment raises several concerns about the experimental results, particularly questioning the justification for using a twostage pretraining approach and the importance of reweighting with a positive or negative $\tau$. It points out that the relationship between temperature $\tau$ and downstream performance in Figure 5 does not seem to support the use of twostage pretraining. Additionally, the comment questions the results from Table 4, suggesting that they do not demonstrate the advantage of using PRESENCE. While the comment identifies specific areas of concern, it lacks detailed suggestions or guidance on how the authors might address these issues or improve their draft. The feedback is 3 as it prompts the authors to reconsider their experimental design and results, but it could be more actionable with additional guidance. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy in the results, noting that the performance gain for k=1 is better than the baselines, suggesting that the improvement might not be solely due to the application of Eq.10. However, it does not provide explicit guidance or suggestions on how the authors should address this observation or what specific changes to make. The comment implies that the authors should explore the reasons behind the performance gain, but it lacks concrete steps or actionable advice. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a discrepancy in the results, noting that the performance gain for k=1 is better than the baselines and suggesting that the improvement might not be solely due to the application of Eq.10. This provides clear guidance on what aspect of the results needs further exploration. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the results for k=1 in Table 2 are better than the baselines, suggesting that the performance gain might not be solely due to the application of Eq.10. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this observation and how it impacts the interpretation of the results. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a discrepancy in the results, noting that the performance gain for k=1 is better than the baselines, which might not be solely due to the application of Eq.10. This observation is valuable as it challenges the authors to reconsider the reasons behind the performance improvement. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or what additional analyses could be conducted to explore the reasons behind the performance gain. While it prompts the authors to think critically about their results, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method lacks solid grounding, specifically regarding the choice of mixedinteger programming and its advantages over alternative approaches. However, it does not provide explicit guidance on how the authors should address these issues or what specific aspects need clarification. The feedback is somewhat vague, as it identifies a problem but does not offer concrete steps for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of solid grounding for the proposed method, specifically mentioning the choice of mixedinteger programming and its advantages over alternative approaches. However, it does not specify which part of the paper discusses these aspects, making it weakly grounded. The comment is specific in identifying the issue with the choice of mixedinteger programming and its lack of justification, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method lacks solid grounding, specifically regarding the choice of mixedinteger programming and its advantages over alternative approaches. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the choice of mixedinteger programming is not justified or why its advantages are unclear. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed method, specifically the lack of solid grounding for the choice of mixedinteger programming and its advantages over alternative approaches. This feedback is valuable as it highlights a critical area that needs clarification and justification in the paper. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these concerns, such as suggesting alternative approaches or providing more detailed reasoning. While it points out a clear weakness, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point consists of two separate comments. The first comment points out that the notation in Equation 1 is confusing, using \"c\" instead of \"o,\" which is a specific issue that the authors can address by clarifying the notation. The second comment notes that \"Pedersen et al 2007\" is missing in the reference section, which is a clear and explicit action for the authors to take. Both comments provide concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation 1\" and \"Line 361,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issues: the confusing notation in Equation 1 and the missing reference to \"Pedersen et al 2007\" in the reference section. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate claims. The first claim is about the confusion in notation in Equation 1, which is a factual observation and does not require verification. The second claim is about the missing reference to \"Pedersen et al 2007\" in the reference section, which is also a factual observation. Both claims are based on direct observations and do not require additional evidence or reasoning to be understood. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues that need attention. First, it points out that the notation in Equation 1 is confusing, using \"c\" instead of \"o,\" which could lead to misunderstandings. Second, it notes that \"Pedersen et al 2007\" is missing in the reference section. Both of these points are clear and actionable, providing the authors with specific areas to improve their draft. The feedback is detailed and offers clear guidance on what needs to be corrected, making it 5 for the authors to enhance their work. Therefore, the comment aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies the second contribution of the paper as the proposal to combine SSMs with Attention, noting that this is not new and has been proposed before in MEGA and Blockstate Transformer. It suggests that the architecture in Figure 5 is very similar to the proposed architecture in Mega and recommends discussing the similarities and differences between S++ and this work in detail, including ablation studies. The comment provides clear and concrete actions for the authors to take, such as comparing the proposed architecture with existing ones and conducting ablation studies. This level of detail and specificity makes the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second contribution of the paper, the proposal to combine SSMs with Attention, and references specific works like MEGA and Blockstate Transformer. It also points out similarities between the architecture in Figure 5 and the proposed architecture in Mega, suggesting a thorough discussion and ablation studies. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the second contribution of the paper, the proposal to combine SSMs with Attention, is not new and has been previously proposed in MEGA and Blockstate Transformer. The comment provides specific references to these works, such as the cited paper in the results and the arXiv link for Blockstate Transformer, which supports the claim. Additionally, the comment suggests that the architecture in Figure 5 is very similar to the proposed architecture in Mega, implying that a detailed discussion and ablation studies are needed. This level of detail and reference makes the claim 4, as it provides sufficient evidence for the authors to understand and address the issue. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s second contribution, which is the proposal to combine SSMs with Attention. It points out that this concept is not new and has been previously proposed in MEGA and Blockstate Transformer, as evidenced by the references provided. The comment also highlights that the architecture in Figure 5 appears very similar to the proposed architecture in Mega, suggesting that a detailed discussion and ablation studies are necessary to differentiate the current work from existing literature. This feedback is clear and actionable, providing the authors with specific areas to address and improve their draft. However, it could be more helpful if it offered suggestions on how to conduct the comparison or what specific aspects to focus on in the discussion. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the reason for reporting results on knowledge transfer only on a few select environments. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should report results on more environments or if they need to justify their choice of environments. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reason for reporting results on knowledge transfer only on a few select environments, prompting the authors to consider the rationale behind this choice. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the rationale behind reporting results on knowledge transfer only on a few select environments. It does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rationale behind reporting results on knowledge transfer only on a few select environments. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue or improve their reporting. The comment lacks depth and actionable advice, making it 2. Authors would need to infer that they should consider expanding their reporting to more environments or provide a rationale for their current choice, but this inference is not explicitly stated. Therefore, the comment aligns with a score of 2, indicating it is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out the lack of specific ablation experiments, suggesting that the performance improvement might be due to pretrained weights rather than the method proposed. It implies that the authors should include detailed ablation comparisons to clarify the results. While the action is implicit, it is concrete in terms of what needs to be addressed\u2014specifically, the inclusion of ablation experiments. However, the comment does not provide explicit guidance on how to conduct these experiments or what specific comparisons should be made. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the lack of specific ablation experiments, suggesting that the performance improvement might be attributed to pretrained weights rather than the method proposed. However, it does not explicitly mention which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed\u2014specific ablation experiments and comparisons. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance improvement could be attributed to pretrained weights rather than the method proposed in the manuscript. This claim is 3 as it suggests that the authors should include specific ablation experiments to clarify the results. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to conduct additional experiments to address this concern, which is a reasonable request but not fully supported by the comment itself.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, namely the lack of specific ablation experiments. It points out that the performance improvement might be attributed to pretrained weights rather than the method proposed. This feedback is valuable as it highlights a potential weakness in the manuscript and suggests that the authors should include detailed ablation comparisons to clarify the results. However, the comment could be more helpful if it provided guidance on how to conduct these ablation experiments or what specific comparisons should be made. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a limitation in the lemmatizer that could affect realworld texts with evolving vocabularies. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might improve the lemmatizer or suggest alternative approaches to mitigate the issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific limitation in the lemmatizer, which is a part of the methodology section. However, it does not explicitly mention which part of the paper this limitation is discussed in, making it weakly grounded. The comment is specific in detailing the concern about the lemmatizer\"s impact on realworld texts with evolving vocabularies. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the described limitation in the lemmatizer is a major concern for realworld texts with evolving vocabularies. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the significance of this concern or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the lemmatizer, noting that it strips suffixes from words that are already lemmas but end with a suffix substring. This is a significant concern, especially for realworld texts with evolving vocabularies. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the lemmatizer. Without actionable feedback or constructive advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it highlights a concern but lacks depth and direction for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the comparison in Table 2, where pretrained DGCNN is used for semantic segmentation for each completion method. The reviewer suggests that the comparison of the segmentation metric is not meaningful because it implies that the segmentation of the methods combined with DGCNN is worse than the proposed method. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the comparison. The action is implicit and somewhat vague, as the authors are left to infer that they need to reconsider the comparison approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the comparison of segmentation metrics when using pretrained DGCNN for each completion method, suggesting that the comparison is not meaningful. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the comparison in Table 2 is not meaningful because the segmentation metrics of the methods combined with pretrained DGCNN are worse than the proposed method. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide references or additional context to help the authors understand why the comparison is not meaningful or how it could be improved. As a result, the claim is considered 2, as it provides some insight but lacks sufficient evidence or detail to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison in Table 2, where pretrained DGCNN is used for semantic segmentation for each completion method. It points out that the comparison of the segmentation metric is not meaningful, as it implies that the segmentation of the methods combined with DGCNN is worse than the proposed method. This feedback is 3 as it highlights a specific area of concern in the paper. However, it lacks depth and does not provide actionable suggestions or guidance on how the authors might address this issue or improve the comparison. To be more helpful, the comment could suggest alternative approaches or metrics for comparison. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point makes a statement about the difficulty of applying rules in realworld applications and suggests that statistical rules learned from data might be feasible. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their draft in response to this observation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general observation about the difficulty of applying rules in realworld applications and suggests that statistical rules learned from data might be feasible. However, it does not specify which part of the paper this observation pertains to, nor does it provide specific guidance on how to address this issue. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the application or rules should be considered. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point makes a general observation about the difficulty of applying rules in realworld applications and suggests that statistical rules learned from data might be feasible. However, it does not provide specific examples, reasoning, or evidence to support this claim. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how it might impact their work. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment makes a general observation about the difficulty of applying rules in realworld applications and suggests that statistical rules learned from data might be feasible. However, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their draft. Without detailed guidance or examples, the authors are left without a clear understanding of what changes could be made to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods. While the comment implies that this comparison is missing, it does not explicitly instruct the authors to make this addition. The action is inferred and somewhat vague, as the authors need to determine exactly which methods to compare and how to present this comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods, but it does not specify which part of the paper this comparison should be included in. This makes it difficult for the authors to pinpoint the exact section where this addition should be made. Additionally, the comment lacks specificity regarding what aspects of the comparison would be beneficial or how it would enhance the paper. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or beneficial. The lack of detailed explanation or examples makes it difficult for the authors to understand the importance of this suggestion or how it could improve their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include a comparison with dynamic sparse trainingbased and other sparsitybased methods. While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to conduct this comparison or what aspects of the comparison would be beneficial. The comment highlights a relevant area for enhancement but does not offer actionable steps or detailed suggestions, making it 3. The authors would gain some insight into a potential improvement, but the feedback could be more comprehensive and actionable to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point questions the reasoning behind the intractability of $p_\u03b8(y|x)$ in a latent variable model, suggesting that it might not necessarily be due to the intractability of $p_\u03b8(z|x)$. The reviewer provides an example where both the posterior and likelihood can be tractable, yet $p_\u03b8(y|x)$ may still be intractable. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their explanation. The action is implicit and vague, as the authors are left to infer that they need to reconsider their reasoning or provide additional context. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly refers to a specific part of the paper, namely the statement about the intractability of $p_\u03b8(y|x)$ in a latent variable model. This allows the authors to accurately identify the section being addressed. The comment is also specific because it questions the reasoning behind the intractability of $p_\u03b8(y|x)$, suggesting that it might not necessarily be due to the intractability of $p_\u03b8(z|x)$. The reviewer provides a clear example of a scenario where both the posterior and likelihood can be tractable, yet $p_\u03b8(y|x)$ may still be intractable. This provides a specific basis for the comment, making it 5.", "verifiability_rationale": "The review point questions the reasoning behind the intractability of $p_\u03b8(y|x)$ in a latent variable model, suggesting that it might not necessarily be due to the intractability of $p_\u03b8(z|x)$. The reviewer provides a logical reasoning by presenting an example where both the posterior and likelihood can be tractable, yet $p_\u03b8(y|x)$ may still be intractable (e.g., a Bernoulli likelihood with a Gaussian posterior). This example supports the claim, making the comment 4. However, the comment could be strengthened by providing more detailed examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment challenges the reasoning behind the intractability of $p_\u03b8(y|x)$ in a latent variable model, suggesting that it might not necessarily be due to the intractability of $p_\u03b8(z|x)$. The reviewer provides a logical example where both the posterior and likelihood can be tractable, yet $p_\u03b8(y|x)$ may still be intractable. This feedback is 3 as it prompts the authors to reconsider their assumptions and potentially improve the clarity of their explanation. However, it lacks specific suggestions or guidance on how the authors might address this issue, making it less actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a concern about the irreproducibility of the collected datasets outside of the associated groups. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the reproducibility of their datasets or suggest specific steps to make the datasets more accessible. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a concern about the irreproducibility of the collected datasets outside of the associated groups. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the datasets\" irreproducibility need to be addressed or improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the collected datasets are irreproducible outside of the associated groups. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the reproducibility of the collected datasets outside of the associated groups. However, it lacks specificity and does not provide any actionable suggestions or guidance on how the authors might address this concern. Without detailed feedback or constructive advice, the authors are left without a clear understanding of what steps to take to improve the reproducibility of their datasets. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the presence of a missing equation before \"where p is the firing rate\" in section 3.4.1. While it identifies a potential issue, it does not explicitly instruct the authors to add the equation or provide guidance on where it should be included. The action is implicit, as the authors can infer that they need to check for the missing equation, but it lacks concrete details on how to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"sec 3.4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely an equation before \"where p is the firing rate.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the presence of an equation in section 3.4.1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting the absence of an equation before \"where p is the firing rate\" in section 3.4.1. This is a clear and actionable piece of feedback that directs the authors to check for the missing equation and ensure its inclusion. By pinpointing the exact location of the issue, the comment provides the authors with a clear path to improve their draft. However, the comment could be more helpful if it offered additional context or suggested where the equation might logically fit. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct experiments to evaluate the sentiment word detection and correction, specifically focusing on the detection of sentiment word positions and the prediction of sentiment word candidates. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks evaluation of sentiment word detection and correction, specifically mentioning the detection of sentiment word positions and the prediction of sentiment word candidates. However, it does not specify which part of the paper this evaluation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to conduct experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks evaluation of sentiment word detection and correction, specifically mentioning the detection of sentiment word positions and the prediction of sentiment word candidates. The reviewer suggests that experiments should be conducted to validate these aspects. However, the comment does not provide specific examples or references to support the claim, making it difficult for the authors to understand the exact nature of the issue or how to address it. This lack of detailed justification results in the comment being considered 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of evaluation of sentiment word detection and correction in the paper. It suggests conducting experiments to validate the effects of the sentiment word position detection module and the predicted sentiment word candidates. This feedback is clear and actionable, providing the authors with a concrete direction for enhancing their work. However, the comment could be more helpful if it offered additional guidance on how to design these experiments or what specific metrics to consider. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that many incontext learning baselines, such as static fewshot and chainofthought, underperform the backbone in many items, and suggests that this might be due to large variance or uncareful design of the baselines. It implies that the authors should provide more explanations to support the reliability of their claims. While the comment identifies an area for improvement, it does not explicitly instruct the authors to provide these explanations or offer specific guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on these observations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"many incontext learning baselines,\" allowing the authors to identify the specific part of the paper being addressed. It is also specific because it highlights the issue of mysterious results and suggests that these might be due to large variance or uncareful design of the baselines. The comment further specifies what needs to be addressed, which is providing more explanations to support the reliability of the claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that many incontext learning baselines, such as static fewshot and chainofthought, underperform the backbone in many items, and attributes this to large variance or uncareful design of the baselines. The comment suggests that more explanations are needed to support the reliability of the claims. However, the comment lacks specific examples or references to substantiate the claim about the performance of these baselines. Without detailed evidence or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the experimental results, noting that many incontext learning baselines, such as static fewshot and chainofthought, underperform the backbone in many items. It suggests that this might be due to large variance or uncareful design of the baselines. The comment provides a clear observation and implies that the authors should provide more explanations to support the reliability of their claims. However, it lacks specific suggestions on how to address these issues or what kind of additional explanations would be beneficial. While it highlights an important area for improvement, the feedback could be more actionable with additional guidance. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the key innovation that drives the improvements claimed by GFNSeqEditor. It suggests that the paper should better articulate the novel techniques or insights that lead to these improvements. While the comment identifies an area for improvement, it does not provide specific guidance on how to address the ambiguity or what specific techniques or insights should be highlighted. The action is implicit and somewhat vague, as the authors know they need to clarify the innovation but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim that GFNSeqEditor can produce novel sequences with improved properties, suggesting that the paper should better articulate the key innovation driving these contributions. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in identifying the need for clearer articulation of the key innovation, but without explicit references to sections or specific elements, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks clarity regarding the key innovation driving the improvements claimed by GFNSeqEditor. The reviewer suggests that the paper should better articulate the novel techniques or insights that lead to these improvements. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the innovation is unclear. This lack of detailed justification makes the claim 3, as the authors may find it challenging to address the feedback without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the key innovation that drives the improvements claimed by GFNSeqEditor. It suggests that the paper should better articulate the novel techniques or insights that lead to these improvements, which would enhance the reader\"s understanding of the method\"s unique value. While the comment highlights an important area for improvement, it does not provide specific guidance or suggestions on how to address the ambiguity or what specific techniques or insights should be highlighted. This makes the feedback 3, as it points out a critical area for clarification but lacks detailed actionable advice. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. While the comment implies that an experiment is needed, it does not specify what kind of experiment or how it should be designed. The action is implicit and somewhat vague, as the authors know they need to include an experiment but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should demonstrate the faithfulness of their proposed approach by conducting at least a simple experiment. However, it does not specify which part of the paper this demonstration should be included in, making it weakly grounded. The comment is specific in its request for an experiment to validate the approach, but without clear grounding, the authors may struggle to identify the exact section to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should demonstrate the faithfulness of their proposed approach with at least a simple experiment. However, the comment does not provide any specific reasoning or examples to support why this demonstration is necessary or how it would validate the approach. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should demonstrate the faithfulness of their proposed approach with at least a simple experiment. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the paper\"s evidence and validation. However, the comment could be more helpful if it offered guidance on how to design or execute the experiment or provided examples of similar experiments used in the field. Despite this, the comment is 4 as it directs the authors toward a concrete step to improve their draft."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a limitation of the proposed method, stating that it can only operate with stateaction spaces, which is a common challenge in realworld applications. However, it does not provide any explicit or implicit suggestions on how the authors might address this limitation or improve the motivation of their method. The comment lacks actionable guidance, leaving the authors without a clear path forward for enhancing their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the motivation of the proposed method, specifically mentioning that it can only operate with stateaction spaces, which is a limitation in realworld applications. However, it does not specify which part of the paper this critique is based on, such as a particular section or paragraph. The authors might infer that it relates to the introduction or motivation section, but this inference is not direct. The comment is specific in identifying the issue with the motivation, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is limited to stateaction spaces, which is a common challenge in realworld applications. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed reasoning or evidence weakens the verifiability of the claim, leaving the authors uncertain about the validity of the critique. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a limitation of the proposed method, noting that it can only operate with stateaction spaces, which is a common challenge in realworld applications. This critique highlights a potential weakness in the motivation of the proposed method, suggesting that the authors need to address this limitation to better align with realworld applications. However, the comment does not provide specific suggestions or guidance on how the authors might overcome this limitation or improve the motivation of their method. While it points out an important area for improvement, the feedback lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the lack of competitiveness of the experiment results compared to the stateoftheart (SOTA) methods and the unclear presentation of the main results in Table 1. It suggests moving the baseline to an ablation study and only showing the proposed method. However, the comment does not provide specific guidance on how to address these issues, such as suggesting ways to improve the competitiveness of the results or how to clarify the presentation of Table 1. The actions are implicit and vague, leaving the authors without clear direction on how to implement the suggested changes. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the experiment results and the presentation of the main results in Table 1, providing specific feedback on the lack of competitiveness compared to SOTA methods and the clarity of the presentation. It also suggests moving the baseline to an ablation study. However, the comment does not explicitly mention which sections or parts of the paper these issues pertain to, making it weakly grounded. The authors can infer that it relates to the results and discussion sections, but this inference is not as direct as it could be. The comment is specific in detailing the issues with the results and presentation, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the experiment results are not competitive with the stateoftheart (SOTA) methods and that the presentation of the main results in Table 1 is unclear. The comment suggests moving the baseline to an ablation study and only showing the proposed method. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are not competitive or that the presentation is unclear. Without concrete evidence or references, the authors may find it challenging to understand and address the issues raised. Therefore, the claim is considered 2.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: the lack of competitiveness of the experiment results compared to stateoftheart (SOTA) methods and the unclear presentation of the main results in Table 1. It also suggests moving the baseline to an ablation study and only showing the proposed method. While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how to address these issues. The authors are left with a general idea of what needs to be improved but without detailed direction on how to implement the changes. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers. While the comment implies that the authors should clarify this aspect, it does not provide explicit instructions or concrete steps on how to achieve this. The action is implicit and somewhat vague, as the authors need to infer that they should add a section or explanation to address this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the copyright scenario, but without explicit grounding, the authors may find it challenging to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the manuscript could benefit from a clearer delineation of the copyright scenario, specifically asking whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this clarification is necessary or how it would improve the manuscript. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the manuscript by suggesting that a clearer delineation of the copyright scenario would be beneficial. It specifically asks whether the copyright protection mechanisms are designed to safeguard the interests of the model owner or the endusers who utilize the model. This feedback is 3 as it highlights a specific aspect that could enhance the clarity and comprehensiveness of the manuscript. However, the comment could be more actionable by providing guidance on how to address this issue or by suggesting additional context that would clarify the copyright scenario. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, whereas the highrank adapter collects domainspecific knowledge, beyond experimental observation. However, it does not provide any explicit or implicit actions for the authors to take. The comment highlights a gap in the paper but does not instruct the authors on how to address it or what specific changes to make. As a result, the authors are left without guidance on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, whereas the highrank adapter collects domainspecific knowledge, beyond experimental observation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for theoretical justification or intuitive explanation regarding the adapters\" information acquisition. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is a lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, whereas the highrank adapter collects domainspecific knowledge, beyond experimental observation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or reasoning, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of theoretical justification or intuitive explanation for why the lowrank adapter acquires domainagnostic information, whereas the highrank adapter collects domainspecific knowledge, beyond experimental observation. This feedback highlights a critical area where the paper could be strengthened by providing deeper theoretical or intuitive insights. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as recommending additional theoretical analysis or intuitive explanations. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the rationale behind the statement regarding local models and their applicability near decision boundaries. It suggests that the authors should explain why they cannot measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" This implies that the authors should provide a clearer explanation or justification for their approach. While the comment implies an action, it lacks explicit guidance on how to address the question or what specific details should be included. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the rationale behind the statement regarding local models and their applicability near decision boundaries, and it suggests a specific alternative approach to measuring differences in probabilities. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the rationale behind the statement regarding local models and their applicability near decision boundaries. It suggests that the authors should explain why they cannot measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" This question implies that the authors need to provide a clearer explanation or justification for their approach. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to further develop their explanation to address the reviewer\"s concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the rationale behind the statement regarding local models and their applicability near decision boundaries. It suggests that the authors should explain why they cannot measure differences in probabilities, such as \"if feature 1 were higher, the model would be less confident in class y.\" This feedback is 3 as it prompts the authors to clarify their approach and provide a more detailed explanation of their methodology. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this issue. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that they only report results on ImageNet and lack results on classic datasets like CIFAR10 and CIFAR100. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address this issue or suggest which datasets to include or how to present the results. The action is implicit, as the authors can infer that they need to include results on these classic datasets, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments and the specific issue of not reporting results on classic datasets like CIFAR10 and CIFAR100. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the experiments, namely the inclusion of results on these classic datasets. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments only report results on ImageNet and lack results on classic datasets like CIFAR10 and CIFAR100. This is a factual observation about the scope of the experiments, and it does not express an opinion or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific limitation in the experiments, noting that they only report results on ImageNet and lack results on classic datasets like CIFAR10 and CIFAR100. This feedback is valuable as it highlights a gap in the experimental validation that the authors should address to provide a more comprehensive evaluation of their work. However, the comment could be more helpful if it suggested ways to include these additional datasets or provided guidance on how to present the results effectively. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed suggestions for enhancement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the DinoSR part in Figure 1, noting that the softmax layer is not clearly shown, despite the text description indicating that the encoder does not include that layer. The reviewer contrasts this with the clarity of the figure in the original DinoSR paper. While the comment highlights a problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to improve the clarity of the figure. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the figure. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the DinoSR part, noting that the softmax layer is not clearly shown in the figure, despite the text description indicating that the encoder does not include that layer. The comment also contrasts this with the clarity of the figure in the original DinoSR paper, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the DinoSR part in Figure 1 is confusing due to the lack of a clearly shown softmax layer, despite the text description indicating that the encoder does not include that layer. The reviewer contrasts this with the clarity of the figure in the original DinoSR paper. This claim is 3 as it provides a logical reasoning based on the discrepancy between the text description and the figure. However, it lacks specific examples or references to the original DinoSR paper to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the DinoSR part in Figure 1, noting that the softmax layer is not clearly shown despite the text description indicating its absence. It contrasts this with the clarity of the figure in the original DinoSR paper, providing a clear point of reference. This feedback is actionable as it highlights a particular area that needs improvement, prompting the authors to clarify the figure. However, the comment could be more helpful if it offered suggestions on how to improve the clarity of the figure or provided examples of how to present the information more effectively. Overall, the comment is 4 as it directs the authors to a specific area for enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should review some related work on causal inference and discuss more works related to the paper, citing specific references. While the comment implies that the authors should include these works, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these works and determine how to incorporate them into their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should review related work on causal inference and discuss more works related to the paper, citing specific references. However, it does not specify which part of the paper should include this review or discussion, making it weakly grounded. The comment is specific in suggesting the need to include related work, but without clear guidance on where to place this information, the authors may find it challenging to address the feedback effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should review related work on causal inference and discuss more works related to the paper, citing specific references. However, the comment does not provide any detailed reasoning or explanation for why this is necessary or how it would benefit the paper. The references provided are not included in the comment, making it difficult for the authors to understand the context or relevance of the suggested work. As a result, the claim is 1 due to the lack of supporting evidence or detailed justification.", "helpfulness_rationale": "The review comment suggests that the authors should review related work on causal inference and discuss more works related to the paper, citing specific references. This feedback is 3 as it points out an area for improvement by suggesting that the paper should include more relevant literature. However, the comment lacks depth and does not provide specific guidance on how to incorporate these references or what aspects of causal inference should be discussed. The authors are given a direction but not a comprehensive roadmap for enhancing their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors could have avoided Sections 3.1 and 3.2 by using the LLM2Vec encoder, which is already cited in the paper. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects should be validated with ablation studies. The action is implicit and somewhat vague, as the authors need to infer that they should consider using the LLM2Vec encoder and conduct ablation studies to validate their decision. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.1 and 3.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests that the authors could have avoided these sections by using the LLM2Vec encoder, which is already cited in the paper. The comment further specifies the issue by questioning the reasoning for not adopting this approach and recommending validation with ablation studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. However, the comment lacks specific reasoning or examples to support why this approach would be more effective or beneficial. Without detailed justification or references, the claim remains 3, as it provides a general suggestion without concrete evidence or explanation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential improvement in the paper by suggesting that Sections 3.1 and 3.2 could have been avoided by using the LLM2Vec encoder, which is already cited in the paper. This feedback is 3 as it points out a specific area for consideration and suggests a potential enhancement to the paper. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or what aspects should be validated with ablation studies. To be more helpful, the comment could include more detailed reasoning or examples to support the claim. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the experiments, noting that only synthetic objective functions are used when comparing the proposed Batch BORE method with existing baselines, and there are no realworld problems. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue, such as suggesting the inclusion of realworld problems or providing examples of such problems. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experiments comparing the proposed Batch BORE method with existing baselines, specifically noting the use of synthetic objective functions and the absence of realworld problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the use of synthetic objective functions and the lack of realworld problems, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments comparing the proposed Batch BORE method with existing baselines only use synthetic objective functions and lack realworld problems. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the proposed Batch BORE method is compared with existing baselines using only synthetic objective functions and lacks realworld problems. This feedback highlights a potential gap in the evaluation of the method, as realworld problems are more relevant for assessing the practical applicability of the proposed approach. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as proposing additional experiments or discussing the relevance of realworld problems. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the challenge in distinguishing roles using explanationfocused cues might be due to LLMs relying more on language style than informational depth. It proposes conducting a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts to clarify these findings. While the comment provides a clear direction for further analysis, it does not specify which parts of the paper should be analyzed or how to conduct this analysis. The action is explicit but lacks concrete details, making it 3.", "grounding_specificity_rationale": "The comment suggests that the challenge in distinguishing roles using explanationfocused cues might be due to LLMs relying more on language style than informational depth. It proposes conducting a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts to clarify these findings. However, the comment does not specify which part of the paper this analysis should be conducted on, nor does it provide specific details on how to conduct the analysis. This makes the comment weakly grounded, as the authors cannot confidently determine which part of the paper it addresses, and it is not specific enough to guide the authors on how to improve their draft. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that distinguishing roles using explanationfocused cues is challenging, possibly due to LLMs relying more on language style than informational depth. The comment suggests conducting a detailed analysis of benchmark sentence differences between explanation and listenerfocused parts to clarify these findings. However, the comment lacks specific examples or references to support the claim about the challenges in distinguishing roles. While it provides a logical reasoning, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential challenge in distinguishing roles using explanationfocused cues, suggesting that this might be due to LLMs relying more on language style than informational depth. It provides a suggestion for further analysis by proposing a detailed examination of benchmark sentence differences between explanation and listenerfocused parts. This feedback is clear and actionable, offering a specific direction for the authors to explore and potentially improve their work. However, it could be more helpful if it included examples or suggested methods for conducting the analysis. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a specific issue with the use of acronyms in the paper, noting that the acronym \"DU\" is mentioned without a clear definition. This feedback is explicit, as it directly points out the problem, and it is concrete because it specifies which acronym needs a definition and how it should be addressed. The authors know exactly what needs to be done to improve the readability of their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights a specific issue with the use of acronyms in the paper, noting that the acronym \"DU\" is mentioned without a clear definition. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper discusses these acronyms, leaving the authors to infer that it relates to the introduction or methodology sections. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper makes heavy use of acronyms, which affects readability, and specifically mentions the acronym \"DU\" without a clear definition. This claim is 3 as it highlights a specific issue with the use of acronyms, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to determine if this is a significant issue and how it impacts the readability of the paper. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of acronyms in the paper, noting that the acronym \"DU\" is mentioned without a clear definition. This feedback is clear and actionable, as it highlights a potential barrier to readability and provides a direct suggestion for improvement by defining the acronym. By addressing this issue, the authors can enhance the clarity and accessibility of their work. However, the comment could be more helpful if it provided additional examples or guidance on how to effectively define acronyms in the context of the paper. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the assumption made in section 2.3 regarding the variance of the distribution p(q|s) being sentence independent. It asks for clarification on how this variance is estimated, whether it is determined using the sample variance of quality values in the training data, and whether a diagonal covariance matrix is assumed. While the comment identifies a specific area of confusion and requests clarification, it does not provide explicit instructions or suggestions on how to address the issue. The authors are left to infer that they need to clarify these points in their paper. Therefore, the comment is 3, as it identifies an area for improvement but lacks concrete guidance on how to implement the changes.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the assumption of sentenceindependent variance, the method of estimating variance, and the assumption about the covariance matrix. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the assumptions and methods used in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the assumptions made in section 2.3 regarding the variance of the distribution p(q|s) being sentence independent. It seeks clarification on how this variance is estimated, whether it is determined using the sample variance of quality values in the training data, and whether a diagonal covariance matrix is assumed. This feedback is 3 as it identifies a specific area of confusion and prompts the authors to clarify their assumptions and methods. However, it lacks detailed guidance or suggestions on how to address these questions or improve the clarity of the paper. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the initial accuracy of the MILbased baseline model compared to the converged models, particularly for the NSCLC dataset. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this observation or what changes could be made to improve the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the initial accuracy of the MILbased baseline model compared to the converged models, particularly for the NSCLC dataset. This provides clear guidance on what aspect of the figure needs further explanation or analysis. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the initial accuracy of the MILbased baseline model compared to converged models, particularly for the NSCLC dataset. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the initial accuracy of the MILbased baseline model compared to the converged models, particularly for the NSCLC dataset. While it identifies a potential area of interest, it does not provide any suggestions or guidance on how the authors might address this observation or improve their analysis. The comment lacks actionable feedback, making it unhelpful in its current form. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. While the comment implies that the authors should include additional datasets, it does not specify which datasets to consider or how to implement this suggestion. The action is implicit and somewhat vague, as the authors need to infer the specific datasets to include and the extent to which they should be considered. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests considering other datasets to explore the generalization of the proposed method across diverse data sources. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to consider other datasets, but without clear grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. However, the comment lacks specific examples or references to other datasets that could be used, making it difficult for the authors to understand the rationale behind the suggestion. Without detailed guidance or evidence, the claim is 3, as it provides a general direction but lacks the necessary details to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment suggests that the paper should consider other datasets to explore the generalization of the proposed method across diverse data sources. This feedback is 3 as it identifies a potential area for improvement, encouraging the authors to broaden the scope of their analysis. However, the comment lacks specificity and does not provide detailed guidance on which datasets to consider or how to implement this suggestion. To be more helpful, the comment could include examples of datasets that could be used or explain the potential benefits of doing so. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should establish alternative hypotheses and conduct experiments to test them, rather than focusing solely on confirmatory analysis. It implies that the authors should provide a more comprehensive analysis by laying out these alternatives and the experiments that would discriminate between them. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement this suggestion, such as which alternative hypotheses to consider or what kind of experiments to design. Therefore, the action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the need for establishing alternative hypotheses and conducting experiments to test them, suggesting that the current analysis is confirmatory rather than exploratory. However, it does not specify which part of the paper this issue pertains to, such as specific sections or experiments. The authors might infer that it relates to the introduction or methodology sections, but this inference is not direct. The comment is specific in its suggestion to establish alternative hypotheses and conduct experiments, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the expectation that the systems under investigation are Bayesoptimal on straightforward problems, suggesting that more work is needed to establish alternative hypotheses and conduct experiments to test this assumption. The comment implies that the current analysis is confirmatory rather than exploratory, which is a logical reasoning based on the nature of the research question. However, the comment lacks specific examples or references to support the claim that the systems are Bayesoptimal, making it 3. The authors would need to further develop the argument to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the paper\"s focus on confirmatory analysis rather than exploratory analysis. It questions the expectation that the systems under investigation are Bayesoptimal on straightforward problems and suggests that more work is needed to establish alternative hypotheses and conduct experiments to test this assumption. The comment provides a clear direction for improvement by emphasizing the need for a more comprehensive analysis, including laying out alternatives and designing experiments to discriminate between them. However, it could be more helpful by offering specific examples or guidance on how to implement this suggestion. Overall, the feedback is 4 as it identifies a critical area for improvement and provides a clear rationale for doing so, but it could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors add confidence intervals to the results presented in Table 1. This is a clear and direct action, as it provides a specific and concrete step for the authors to take in order to improve their draft. The comment also implies that the current results are too close to draw meaningful conclusions, which justifies the need for confidence intervals. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the reported values being too close, making it difficult to draw conclusions. The comment suggests adding confidence intervals as a solution, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reliability of the results presented in Table 1, noting that the reported values are very close, making it difficult to draw meaningful conclusions. The reviewer suggests adding confidence intervals to address this issue. While the comment identifies a potential problem with the results, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to add confidence intervals is logical, but the comment itself does not provide enough evidence or explanation to fully verify the claim. Therefore, the comment is 3, as it highlights a potential issue but requires more detailed justification or examples to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in Table 1, noting that the reported values are very close, making it difficult to draw meaningful conclusions. It suggests adding confidence intervals to address this issue, which is a clear and actionable recommendation for improving the clarity and reliability of the results. By providing a specific suggestion for improvement, the comment empowers the authors to enhance the quality and interpretability of their findings. However, the comment could be more helpful if it included additional guidance on how to calculate or interpret confidence intervals. Overall, the feedback is 4 as it directs the authors toward a concrete step to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that some choices in the paper are not justified or clear, but it does not specify which choices these are or provide any guidance on how the authors might justify or clarify them. The comment lacks explicit instructions or concrete suggestions for improvement, leaving the authors without a clear understanding of what needs to be addressed. Since the action is implicit and vague, the comment is barely actionable.", "grounding_specificity_rationale": "The comment indicates that some choices are not justified or clear but does not specify which choices these are or provide any guidance on how to address them. Without specific references to sections, tables, or figures, the authors cannot confidently determine which parts of the paper need revision. Additionally, the comment lacks specificity regarding what aspects of the choices are unclear or unjustified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that some choices are not justified or clear, but it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that some choices in the paper are not justified or clear, but it does not specify which choices these are or provide any guidance on how the authors might address this issue. The comment lacks specificity and actionable feedback, leaving the authors without a clear understanding of what needs to be improved. Without additional context or suggestions, the authors are left without a clear path forward for enhancing their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about hyperparameter tuning, noting that the paper uses two hyperparameters which complicate the pruning process. It suggests that since both hyperparameters affect FLOPs and accuracy, there are multiple solutions that could achieve the same FLOPs, making the tuning process difficult. The reviewer explicitly asks for detailed discussions regarding the grid search process and its impact on reproducibility. This feedback provides a clear and explicit action for the authors to take, which is to include detailed discussions on hyperparameter tuning and its implications. The comment is concrete, as it specifies what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment addresses a concern regarding hyperparameter tuning, specifically mentioning the use of two hyperparameters and their impact on pruning and reproducibility. It provides a detailed critique of the current presentation, suggesting that the grid search process is not clearly explained. The comment is fully grounded as it explicitly mentions the issue of hyperparameter tuning and its impact on the paper\"s presentation and reproducibility. It is also specific, as it details the problem with the grid search process and the need for detailed discussions. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about hyperparameter tuning, noting that the paper uses two hyperparameters which complicate the pruning process. It suggests that since both hyperparameters affect FLOPs and accuracy, there are multiple solutions that could achieve the same FLOPs, making the tuning process difficult. The reviewer questions the current presentation and requests detailed discussions on the grid search process and its impact on reproducibility. While the comment provides a logical reasoning for the concern, it lacks specific examples or references to support the claim about the impact of hyperparameters on FLOPs and accuracy. This makes the claim 3, as the authors would need to further develop the reasoning to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant concern regarding hyperparameter tuning in the paper. It points out that the use of two hyperparameters complicates the pruning process and affects both FLOPs and accuracy, leading to multiple solutions that could achieve the same FLOPs. The reviewer questions the current presentation and requests detailed discussions on the grid search process and its impact on reproducibility. This feedback is clear and actionable, as it provides a specific area for improvement and suggests a way to enhance the reproducibility of the results. However, the comment could be more helpful if it offered additional guidance on how to address the issue of multiple solutions and how to ensure reproducibility. Overall, the comment is 4, as it effectively highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue with the presentation of results, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1. This implies that the authors should include these accuracies in the figure to clarify the difference between known and unknown attacks. While the action is implicit, it is concrete because it specifies exactly what needs to be added to the figure. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of shown accuracies for the target model using different defenses against the FGSM attack, and it highlights the confusion regarding the difference between known and unknown attacks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1, making it unclear the difference between known and unknown attacks. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in the paper, noting that the accuracies of the target model using different defenses against the FGSM attack are not shown in Figure 1. This lack of information makes it unclear the difference between known and unknown attacks. The comment is clear and actionable, as it directs the authors to include these accuracies in the figure to improve the clarity and understanding of their results. However, it could be more helpful if it provided suggestions on how to present this information effectively or discussed the implications of this omission. Overall, the feedback is 4 as it points out a critical area for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests using a logscale for the yaxis in some figures to improve readability. This is a clear and direct action that the authors can take to enhance the presentation of their data. The comment provides a specific recommendation, making it 5. The authors know exactly what change to make to improve the readability of their figures.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"some figures,\" allowing the authors to identify the specific parts of the paper being addressed. It is also specific because it suggests using a logscale for the yaxis to improve readability, providing a clear and actionable recommendation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests using a logscale for the yaxis in some figures to improve readability. However, it does not provide any supporting evidence, reasoning, or examples to justify why a logscale would be more appropriate than the current scale. Without additional context or explanation, the claim lacks sufficient support, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the readability of some figures in the paper, suggesting the use of a logscale for the yaxis. This is a clear and actionable piece of feedback that can help the authors improve the presentation and clarity of their data. By addressing this suggestion, the authors can enhance the visual representation of their results, making it easier for readers to understand and interpret the data. However, the comment could be more helpful if it provided additional context or examples of how the logscale would improve the figures. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a gap in the experimental validation of the proposed method, specifically mentioning that the authors did not validate their claims about the usefulness of augmentation information. It suggests using finegrained datasets like the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. While the comment implies that the authors should include these datasets in their experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should incorporate these datasets into their experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"case where \"augmentation information is useful\"\" and references specific example categories like \"flowers and birds\" mentioned in the Introduction. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of validation of the claims regarding the usefulness of augmentation information. It suggests using finegrained datasets like the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method was motivated by the case where \"augmentation information is useful,\" as suggested by the authors, and provides examples like flowers and birds. However, it notes that this claim was not validated in the experiment. The reviewer suggests using finegrained datasets such as the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset to validate the claims. While the comment identifies a gap in validation, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to use specific datasets provides some direction, but more detailed explanation or evidence would be needed for the claim to be 5. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical gap in the experimental validation of the proposed method, specifically noting that the claims about the usefulness of augmentation information were not validated in the experiments. It provides specific examples of datasets, such as the Oxford 102 flowers dataset and the CaltechUCSD Birds200 dataset, that should be used to validate the claims. This feedback is clear and actionable, as it guides the authors to enhance the robustness of their experimental validation by incorporating these datasets. By addressing this feedback, the authors can strengthen their paper\"s empirical support and ensure that their claims are wellfounded. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of theoretical analyses and empirical evidence supporting the claim that GEMS converges to the Nash equilibrium. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment suggests that the authors should include theoretical analyses or empirical evaluations to support their claim, but it does not specify which aspects of the analysis should be conducted or how to conduct them. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific claim made in the paper regarding the convergence of GEMS to the Nash equilibrium. It points out the lack of theoretical analyses and empirical evidence supporting this claim, which makes the comment specific. However, it does not explicitly mention which part of the paper discusses this claim, leaving the authors to infer that it relates to the section discussing the convergence of GEMS. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks theoretical analyses and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient support or examples to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of theoretical analyses and empirical evidence to support the claim that GEMS converges to the Nash equilibrium. This feedback is valuable as it highlights a critical area where the paper could be strengthened by providing more rigorous justification for its claims. However, the comment could be more helpful if it offered suggestions on how to conduct these analyses or provided examples of similar studies that could be referenced. Overall, the comment is 4 as it directs the authors to a specific area needing improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment provides several explicit questions and suggestions for clarification regarding Equation (1). It asks whether the purpose is to define a loss function or an optimization problem, notes that the equation seems to mix both, and suggests that the optimization variable x should be in R^k instead of R^n. Additionally, it points out that the constraints notation (s.t. C(A, x)) is unusual. These questions and suggestions are clear and direct, providing the authors with specific actions to take to improve the clarity of their paper. The comment is 5 as it offers concrete guidance on how to address the issues identified in Equation (1).", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (1),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed questions and suggestions for clarification, such as whether the equation is meant to define a loss function or an optimization problem, the correct definition of the optimization variable, and the unusual constraints notation. This level of detail provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point consists of several questions and suggestions for clarification regarding Equation (1). It does not make any subjective claims or judgments that require verification. The questions are factual and seek clarification, which fits the classification of \"No.\"", "helpfulness_rationale": "The review comment provides a detailed analysis of Equation (1), identifying several areas of confusion and potential misinterpretation. It asks specific questions about the purpose of the equation, the definition of the optimization variable, and the unusual constraints notation. These questions and suggestions are clear and actionable, offering the authors a clear path to improve the clarity and precision of their paper. By addressing these issues, the authors can enhance the readability and understanding of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point questions the inclusion of collected LIVEN parallel data for finetuning and its impact on the NMT system\"s performance. It explicitly asks for more discussions or explanations on this aspect. While the action is clear and direct, it lacks concrete guidance on how the authors should address this issue or what specific aspects to discuss. The authors know they need to provide more context or analysis, but the comment does not specify what exactly should be included in the discussion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 257,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the inclusion of collected LIVEN parallel data for finetuning and its impact on the NMT system\"s performance, prompting the authors to provide more discussions or explanations on this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the inclusion of collected LIVEN parallel data for finetuning and its impact on the NMT system\"s performance. It requests more discussions or explanations on this aspect. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this inclusion is problematic or to explain the observed results. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely the inclusion of collected LIVEN parallel data for finetuning and its impact on the NMT system\"s performance. It questions the observed result and requests more discussions or explanations on this aspect. This feedback is clear and actionable, as it prompts the authors to provide additional context or analysis to address the concern. However, the comment could be more helpful if it suggested specific ways to explore or explain the issue, such as recommending alternative approaches or providing more detailed analysis. Overall, the comment is 4 as it directs the authors\" attention to a critical area that needs further exploration, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper includes unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs,\" which lack adequate reasoning or references. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should provide more reasoning or references to substantiate these conjectures, but it does not specify how to do so. Therefore, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the paper regarding unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs.\" However, it does not specify which part of the paper discusses these conjectures, making it weakly grounded. The comment is specific in identifying the need for more reasoning or references to substantiate these conjectures. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper includes unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs,\" which lack adequate reasoning or references. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. Without these elements, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the inclusion of unsubstantiated conjectures about \"finetuning as exposure of existing capabilities in LMs.\" It highlights the lack of adequate reasoning or references to support these conjectures, making it difficult for the authors to understand what the reviewer is referring to. While the comment points out a critical area for improvement, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it directs the authors\" attention to a significant gap in their work, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks could be beneficial when considering the use of FACodec. However, it does not provide explicit guidance on how to implement this suggestion or what specific aspects should be addressed. The action is implicit, as the authors can infer that they need to include NaturalSpeech 3 as a baseline, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including NaturalSpeech 3 as a baseline for voice cloning tasks when considering the use of FACodec. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or experiment where this baseline should be included. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the suggestion is specific in terms of recommending a baseline, the absence of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks could be beneficial when considering the use of FACodec. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this suggestion is beneficial or necessary. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that including NaturalSpeech 3 as a baseline for voice cloning tasks could be beneficial when considering the use of FACodec. This feedback is 3 as it identifies a potential area for improvement by suggesting an additional baseline to consider. However, the comment lacks depth and does not provide specific guidance on how to implement this suggestion or why it might be beneficial. The authors are given a direction but without detailed instructions, making the feedback 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference, while other methods should use them for training. The reviewer expresses uncertainty about the experimental setting and requests clarification. While the comment implies that the authors should address this issue, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should adjust their experimental setup to ensure fairness. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference, while other methods should use them for training. However, it does not specify which part of the paper this issue pertains to, such as the experimental setup or results section. The authors might infer that it relates to the methodology or results, but this inference is not direct. The comment is specific in identifying the issue of fairness in the experimental setting but lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference, while other methods should use them for training. The reviewer expresses uncertainty about the experimental setting and requests clarification. However, the comment does not provide specific examples, reasoning, or references to support the claim that the experiments are unfair. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the fairness of the experiments due to the use of the first four weeks of data for inference, while other methods should use them for training. The reviewer expresses uncertainty about the experimental setting and requests clarification. While the comment identifies a potential issue with the experimental design, it lacks specific guidance or suggestions on how the authors might address this concern. The feedback is 3 as it highlights a potential weakness, but it does not provide actionable steps for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category (50%, 2:4, 4:8). This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what additional results should be included, making it 5.", "grounding_specificity_rationale": "The comment suggests reporting results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these results should be included. While the authors might infer that it relates to the results or discussion sections, the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in suggesting what needs to be reported, but it is 1 because it does not provide clear guidance on where to include this information. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the paper should report results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would benefit the paper. The lack of detailed explanation or references makes it difficult for the authors to understand the rationale behind the suggestion, rendering the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to include additional results on the speedup obtained compared to the dense and SparseGPT models with varying model size and sparsity category. This feedback is clear and directly instructs the authors on what additional data they should present to enhance the comprehensiveness of their results. By addressing this suggestion, the authors can improve the depth and clarity of their analysis, making the comment 5. However, the comment could be more helpful if it provided examples of how to present these results or discussed the significance of the speedup in the context of the models. Overall, the feedback is 4 as it offers a clear direction for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the degree to which sequential bias affects the VisDial results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what specific aspects they should consider. Without any actionable steps or suggestions, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the degree to which sequential bias affects the VisDial results, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific analyses, the authors cannot confidently determine where this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of sequential bias or VisDial results need further exploration. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the impact of sequential bias on the VisDial results. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the degree to which sequential bias affects the VisDial results. While it identifies a potential area for further exploration, it does not provide specific guidance or suggestions on how the authors might address this issue or what aspects of the results should be examined. The comment lacks actionable advice or detailed feedback, leaving the authors with only a vague direction for improvement. Therefore, it is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the experimental results and the stated goal of LTAP, suggesting that the performance improvement is not as expected for tail classes. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what changes could be made to align the results with the stated goal. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ImageNetLT dataset\" and the comparison with \"ATO and RReg,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the observed discrepancy between the performance improvement for head classes and the stated goal of strengthening parameter protection for tail classes. This provides clear guidance on what aspect of the results needs further examination or clarification. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results on the ImageNetLT dataset contradict the stated goal of LTAP, which is to strengthen parameter protection for tail classes. The comment provides a specific observation about the performance improvement for head classes compared to tail classes, which seems inconsistent with the goal. However, the comment lacks detailed reasoning or evidence to fully substantiate the claim, such as specific data points or comparisons that would clarify the discrepancy. This makes the claim 3, as it provides a basis for the critique but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the experimental results and the stated goal of the paper, specifically noting that LTAP achieves a larger performance improvement for head classes than for tail classes. This observation suggests that the results do not align with the intended objective of strengthening parameter protection for tail classes. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the alignment of their results with the stated goal. While it highlights a potential area for improvement, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern regarding the reliability of the reward computation, which relies on LLMbased evaluation. It raises questions about the potential biases or inconsistencies introduced by this dependency on LLMs for assessing the quality of generated documentations. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns or improve the reliability of their evaluation process. The action is implicit and vague, as it does not specify how to mitigate the potential biases or inconsistencies. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the reward computation and its reliance on LLMbased evaluation, which raises concerns about the reliability of the search process. However, it does not specify which part of the paper discusses the reward computation or the LLMbased evaluation, making it weakly grounded. The comment is specific in detailing the concern about the reliance on LLMs for evaluation and the potential biases or inconsistencies this might introduce. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the reliability of the reward computation, which relies on LLMbased evaluation. The reviewer points out that this dependency may introduce biases or inconsistencies in the quality assessment of generated documentations. However, the comment lacks specific examples or references to support the claim about potential biases or inconsistencies. While the reasoning is logical, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reward computation, specifically the reliance on LLMbased evaluation. It raises concerns about the reliability of this process and the potential biases or inconsistencies it might introduce in the quality assessment of generated documentations. This feedback is valuable as it highlights a critical aspect of the methodology that could impact the validity of the results. However, the comment could be more helpful if it provided suggestions on how to address these concerns or alternative methods for ensuring the reliability of the evaluation process. Overall, the comment is 3 as it points out a significant area for improvement but lacks detailed guidance on how to implement the suggested changes."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more empirical examples to argue the effectiveness of the described process and compare it to SOTA performance from referenced papers. It also mentions that Eq 12 might do some of this, but it is unclear. The comment implies that the authors should clarify Eq 12 and provide more detailed comparisons. However, it does not explicitly instruct the authors to do so or provide specific guidance on how to improve the clarity of Eq 12 or the comparisons. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should provide more empirical examples to argue the effectiveness of the described process and compare it to SOTA performance from referenced papers. It specifically mentions Eq 12, which implies that the authors should clarify or improve the explanation of Eq 12. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in suggesting the need for more empirical examples and comparisons, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the described process is surprisingly effective and proposes that more empirical examples should be provided to support this claim. It mentions Eq 12 as a potential source of some of this comparison but notes that it is unclear. The comment implies that the authors should clarify Eq 12 and provide more detailed comparisons to SOTA performance. However, the comment lacks specific examples or detailed reasoning to support the claim, making it 3. The authors would need to infer the necessary details to address the feedback effectively.", "helpfulness_rationale": "The review comment suggests that the authors should provide more empirical examples to argue the effectiveness of the described process and compare it to SOTA performance from referenced papers. It also mentions that Eq 12 might do some of this, but it is unclear. This feedback is 3 as it identifies a gap in the paper\"s empirical validation and suggests a way to address it by providing more detailed comparisons. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct these comparisons. Overall, the comment provides some direction for improvement but lacks detailed instructions, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the difficulty of the problem and provides a specific explanation regarding the assumptions made in the paper. However, it does not offer any explicit or implicit actions for the authors to take in response to this concern. There is no guidance on how the authors might address this issue or improve their approach. As a result, the comment lacks actionability, leaving the authors without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the difficulty of the problem and provides a specific explanation regarding the assumptions made in the paper. It mentions \"Assumption 1\" and discusses the implications of the assumption on the problem\"s difficulty. However, it does not explicitly mention which part of the paper this concern is related to, making it weakly grounded. The comment is specific in detailing the issue with the assumption and its implications, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the difficulty of the problem and provides a specific explanation regarding the assumptions made in the paper. It mentions that \"Assumption 1\" enforces that the adversary cannot pick arbitrary S, but only those where a constant alphafraction of the observations are hidden/removed. The reviewer then explains that after removal, the problem reduces to alpha * m pairs, which still suffices for accurate recovery provided that m = O(k log n). This explanation provides a logical reasoning and specific details about the assumptions and their implications, making the claim 4. However, the comment could be strengthened by providing more context or examples to fully substantiate the concern. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a concern about the difficulty of the problem and provides a specific explanation regarding the assumptions made in the paper. It highlights that Assumption 1 restricts the adversary\"s ability to pick arbitrary subsets of observations, which may impact the problem\"s difficulty. The comment offers a detailed explanation of how this assumption affects the recovery process, noting that after removal, the problem still suffices for accurate recovery provided that the number of samples is proportional to k log n. This feedback is clear and actionable, as it identifies a potential limitation in the assumptions and provides insight into how it might affect the problem\"s difficulty. However, it could be more helpful if it suggested ways to address or mitigate this limitation. Overall, the comment is 4, as it provides valuable insight but could be further enhanced with specific guidance on how to improve the draft."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Figure 1 and Table 1, specifically noting that Figure 1 shows an increase in NNGS with k, which contradicts the comparison in the last two columns of Table 1. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to resolve the contradiction. The action is implicit and vague, as the authors are left to infer that they need to reconcile the figures and tables, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of the contradiction between the illustration in Figure 1 and the comparison in the last two columns of Table 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 1 contradicts the comparison in Table 1, specifically regarding the relationship between NNGS and the number of selected knearest neighbors. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the contradiction or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific inconsistency between Figure 1 and Table 1, noting that Figure 1 shows an increase in NNGS with k, which contradicts the comparison in the last two columns of Table 1. This feedback is clear and actionable, as it highlights a discrepancy that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to reconcile this contradiction or offered guidance on how to present the data more effectively. Overall, the comment is 4 as it points out a critical issue that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact of a large number of tasks on the set of shared parameters. It suggests that the experiments should be expanded to include more tasks, up to 20, as mentioned. The comment explicitly asks the authors to address the question regarding the effect of the number of tasks on the proposed approach. This provides a clear and direct action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact of a large number of tasks on the set of shared parameters. It suggests that the experiments should be expanded to include more tasks, up to 20, as mentioned. However, the comment does not specify which part of the paper discusses the proposed method or the experiments, making it weakly grounded. The comment is specific in its request for the authors to address the effect of the number of tasks on the proposed approach. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the extensibility of the proposed method to a large number of tasks and questions the impact of a large number of tasks on the set of shared parameters. The reviewer suggests that the experiments should be expanded to include more tasks, up to 20, as mentioned. However, the comment lacks specific examples, references, or detailed reasoning to support the claim about the challenges posed by a large number of tasks. This makes the claim 3, as the authors would need to infer the potential issues and provide their own reasoning to address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the extensibility of the proposed method to a large number of tasks, which is a relevant consideration in the context of multitask learning. It questions the impact of a large number of tasks on the set of shared parameters and suggests that the experiments should be expanded to include more tasks, up to 20, as mentioned. The comment provides a clear and actionable question for the authors to address, which is valuable for improving the draft. However, it could be more helpful if it offered specific suggestions or guidance on how to address the issue of extensibility. Overall, the comment is 4 as it identifies a potential weakness and prompts the authors to consider it, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the eyetracking data selection and filtering process, noting that everything is analyzed with some exclusions. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific changes or improvements are needed, leaving the authors uncertain about how to proceed. Since the action is implicit and vague, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the eyetracking data selection and filtering process, which is a specific aspect of the paper. However, it does not explicitly mention which section or part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue with the data selection and filtering, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"eyetracking data selection/filtering is a bit perplexing,\" suggesting that the process involves analyzing everything with some exclusions. However, the comment lacks specific examples or detailed reasoning to support this claim. Without further explanation or evidence, the authors may find it challenging to understand the exact nature of the issue or how to address it. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the eyetracking data selection and filtering process, noting that it appears to analyze everything with some exclusions. While this observation highlights a possible area for improvement, the comment lacks specific guidance or suggestions on how the authors might address this issue or improve their data analysis process. Without actionable feedback or detailed examples, the authors are left with a general understanding of the problem but without clear direction on how to resolve it. Therefore, the comment is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two main issues: uneven writing and unwieldy equations with exact notation. It suggests that the authors consider additional editing, particularly from a languageusage and type perspective, and notes that some sub/superscripts could be dropped for convenience. While the comment provides some guidance on potential areas for improvement, it lacks specific instructions on which parts of the writing or equations need editing. The authors are left with a general idea of what to address but without concrete steps to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses two main issues: uneven writing and unwieldy equations with exact notation. However, it does not specify which sections of the paper are affected by these issues, making it difficult for the authors to pinpoint the exact parts needing revision. The mention of \"sub/superscripts\" provides some guidance, but it is not explicit. Therefore, the comment is weakly grounded because it does not clearly identify the parts of the paper being addressed, and it is not specific enough to guide the authors on what needs to be improved. This aligns with a score of 2.", "verifiability_rationale": "The review point claims that the writing is uneven and could use additional editing, particularly from a languageusage and type perspective. It also notes that the equations are unwieldy due to exact notation. The comment suggests considering dropping some sub/superscripts for convenience. While the comment identifies issues, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to drop sub/superscripts is 3, as it provides a potential solution, but the overall claim is not fully supported by detailed evidence or examples. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies two main issues with the paper: uneven writing and unwieldy equations with exact notation. It provides actionable feedback by suggesting that the authors consider additional editing, particularly from a languageusage and type perspective, and notes that some sub/superscripts could be dropped for convenience. This feedback is clear and offers specific suggestions for improvement, which can help the authors enhance the clarity and readability of their draft. However, the comment could be more helpful if it included examples of where the writing is uneven or specific instances of unwieldy equations. Overall, the comment is 4 as it provides valuable insights and actionable advice for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the dataset size relative to the development cost and suggests that the authors explain the reasons behind the high cost of image acquisition and the type of manual collection used. This feedback is explicit and provides a clear action for the authors to take, which is to provide further explanation regarding the dataset\"s limitations and the methods used. However, the comment also includes minor suggestions, such as clarifying the content of \"regulatory requirements\" and explaining what is considered \"politically sensitive,\" which are not as actionable. The explicit part of the comment is actionable, while the minor comments lack concrete guidance. Therefore, the comment is 3, as it provides clear guidance on one aspect but is vague on others.", "grounding_specificity_rationale": "The comment addresses two distinct issues. First, it discusses the dataset size relative to the development cost, suggesting that the authors explain the reasons behind the high cost of image acquisition and the type of manual collection used. This part is fully grounded as it explicitly mentions the dataset size and the specific issue of image acquisition cost, allowing the authors to identify the relevant sections. It is also specific because it provides a clear direction for the authors to address the issue by explaining the reasons behind the cost and the type of manual collection used. Second, the comment includes minor comments about the phrasing of a sentence and the content of \"regulatory requirements\" and \"politically sensitive\" terms. These are not fully grounded as they do not specify which parts of the paper these issues pertain to, and they are not as specific as the first part. Overall, the comment is 5 for the first part but not for the minor comments. Therefore, the comment is 5 for the first part, but the minor comments are 1 or specific. This aligns with a score of 4.", "verifiability_rationale": "The review point raises a concern about the dataset size relative to the development cost, suggesting that the authors explain the reasons behind the high cost of image acquisition and the type of manual collection used. This is a valid observation that requires clarification, making the claim 3. However, the comment does not provide specific examples or references to support the claim, leaving the authors to infer the need for explanation. The minor comments about the phrasing of a sentence and the content of \"regulatory requirements\" and \"politically sensitive\" terms are not claims but rather suggestions for improvement. Therefore, the comment is 3, as it provides a basis for the authors to address the issue but lacks detailed justification or references.", "helpfulness_rationale": "The review comment identifies a critical issue with the dataset size relative to the development cost, suggesting that the authors explain the reasons behind the high cost of image acquisition and the type of manual collection used. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the limitations of their dataset. However, the comment also includes minor suggestions, such as clarifying the content of \"regulatory requirements\" and explaining what is considered \"politically sensitive,\" which are less actionable and more of a supplementary nature. Overall, the comment is 4 as it provides significant guidance on addressing a key issue, but it could be more comprehensive if it addressed all aspects of the feedback."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the generation of the third column in Figure 7, noting that the visualizations do not appear to be normalized. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should investigate the normalization process, how to address the issue, or what specific changes should be made to the figure. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the generation of the third column in Figure 7, noting that the visualizations do not seem to be normalized. This provides clear guidance on what aspect of the figure is unclear or problematic. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the generation of the third column in Figure 7, noting that the visualizations do not appear to be normalized. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the generation of the third column in Figure 7, noting that the visualizations do not seem to be normalized. While it identifies a potential issue with the figure, it does not provide any suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, such as recommending specific steps to normalize the visualizations or suggesting alternative approaches to improve the clarity of the figure. Without this level of detail, the authors are left without a clear path forward for improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should investigate the heuristic nature of assignment entropy maximization and evaluate its advantages in the ablation experiment. It also points out that the authors did not discuss any potential negative societal impacts of their work. While the comment provides a clear action for the authors to take\u2014specifically, to conduct an investigation and include a discussion on societal impacts\u2014the feedback lacks concrete guidance on how to conduct the investigation or what specific aspects to focus on. The authors are given an explicit action but without detailed instructions on execution, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"assignment entropy maximization\" and \"ablation experiment,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by suggesting that the investigation should be more rigorous and that the authors should discuss the limitations and potential negative societal impacts of their work. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that \"assignment entropy maximization is regarded as the objective to optimize the matching the association graph and multitask, but the investigation is rather heuristic.\" The reviewer suggests that the authors should conduct an ablation experiment to evaluate the advantages of using assignment entropy maximization. However, the comment lacks specific examples or references to support the claim that the investigation is heuristic or to provide a clear rationale for why the ablation experiment is necessary. Additionally, the comment does not address the potential negative societal impacts of the work, which is another aspect that could be explored. As a result, the claim is 3, as it provides a general suggestion but lacks detailed justification or evidence.", "helpfulness_rationale": "The review comment identifies a potential issue with the approach of using assignment entropy maximization, suggesting that the investigation is heuristic. It provides a specific suggestion to conduct an ablation experiment to evaluate the advantages of using assignment entropy maximization, which could help the authors substantiate their claims. Additionally, the comment points out that the authors did not discuss any potential negative societal impacts of their work, which is an important aspect that could be addressed. While the comment provides actionable feedback and highlights areas for improvement, it could be more helpful if it offered more detailed guidance on how to conduct the ablation experiment or how to address the societal impacts. Overall, the comment is 4 as it directs the authors to specific areas for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that there is only one baseline model in the experimental section, which may indicate a lack of comparison or robustness in the study. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider adding more baseline models or providing a rationale for the limited number of baselines, but it does not specify how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment points out that there is only one baseline model in the experimental section, which is a specific issue that needs attention. However, it does not specify which part of the experimental section this issue is related to, such as a particular table, figure, or section. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the lack of multiple baseline models, but without grounding, it is challenging for the authors to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is only one baseline model in the experimental section. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it difficult to understand the significance of this observation or how it impacts the study. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that there is only one baseline model in the experimental section, which may indicate a lack of comparison or robustness in the study. However, it does not provide any specific suggestions or guidance on how the authors could address this issue, such as suggesting additional baseline models or explaining the rationale behind having only one baseline. Without actionable feedback or detailed advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the absence of certain baselines and literature comparisons in the results section, specifically mentioning traditional QAT methods like LSQ, LSQ+, and other LLMbased QAT works such as LLMQAT 1 and SpinQuant 2. It also suggests that while these comparisons are more memory expensive, it would be important to understand the benefits of using extra memory instead of relying solely on finetuning low rank adapters. The comment implies that the authors should include these comparisons to provide a more comprehensive analysis. However, it does not explicitly instruct the authors to add these comparisons or provide detailed guidance on how to incorporate them into the draft. The action is implicit and somewhat vague, as the authors need to infer the specific comparisons to include and how to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific baselines and literature comparisons that are missing in the results section, such as traditional QAT methods like LSQ, LSQ+, and other LLMbased QAT works like LLMQAT 1 and SpinQuant 2. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it clearly specifies what is missing in the results section and suggests that the authors should include these comparisons to provide a more comprehensive analysis. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that certain baselines and literature comparisons are missing in the results section, specifically mentioning traditional QAT methods like LSQ, LSQ+, and other LLMbased QAT works such as LLMQAT 1 and SpinQuant 2. The reviewer suggests that while these comparisons are more memory expensive, it would be important to understand the benefits of using extra memory instead of relying on finetuning low rank adapters. The comment provides specific examples of missing comparisons and suggests a potential area for further analysis, which supports the claim. However, it lacks detailed reasoning or references to fully substantiate the claim, making it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the results section by pointing out the absence of certain baselines and literature comparisons, such as traditional QAT methods like LSQ, LSQ+, and other LLMbased QAT works like LLMQAT 1 and SpinQuant 2. It also suggests that while these comparisons are more memory expensive, it would be important to understand the benefits of using extra memory instead of relying solely on finetuning low rank adapters. This feedback is clear and actionable, as it directs the authors to include these missing comparisons to enhance the comprehensiveness of their analysis. However, the comment could be more helpful if it provided specific guidance on how to incorporate these comparisons or discussed the potential benefits in more detail. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment raises a question about how to define an attribute and what the difference is between attributes. It suggests that more detailed instructions should be provided. While the comment implies that the authors should clarify these aspects, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about how to define an attribute and what the difference is between attributes, suggesting that more detailed instructions should be provided. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where these definitions are discussed. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts of the paper need revision. While the comment is specific in its request for more detailed instructions, it lacks grounding because it does not point to a specific section of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for clarification on how to define an attribute and what the difference is between attributes. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the definition of an attribute and the difference between attributes, suggesting that more detailed instructions should be provided. While it identifies a potential area for improvement, it lacks specificity and does not offer actionable advice on how to address the issue. The comment is vague and does not provide the authors with clear guidance on what needs to be clarified or improved. As a result, it is 2, as it points out a potential issue but does not offer a comprehensive or actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the theory in the paper is not helpful in predicting whether a model can be trained to be robust against adversarial perturbations. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their theory to make it more applicable. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the theory in the paper is not helpful in predicting whether a model can be trained to be robust against adversarial perturbations. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the theory could be improved or how the authors might address the issue of robustness against adversarial perturbations. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the theory in the paper is not helpful in predicting whether a model can be trained to be robust against adversarial perturbations. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of this critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential limitation in the paper\"s theory regarding its ability to predict whether a model can be trained to be robust against adversarial perturbations. This is a valuable observation that could help the authors identify areas where their theory might be lacking. However, the comment lacks specificity and does not provide actionable suggestions or guidance on how the authors might address this issue or improve their theory. Without detailed feedback or constructive advice, the authors are left with a general understanding of the problem but without a clear path to improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the definition of \"scenario\" in the paper and whether it refers to class or instances. It also inquires about the \"agnostic\" part. While the comment highlights areas of confusion, it does not provide explicit guidance or suggestions on how the authors should clarify these points. The actions are implicit and vague, as the authors need to infer that they should clarify the definitions and provide more context. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the definition of \"scenario\" in the paper and whether it refers to class or instances. It also questions the \"agnostic\" part. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact sections that need clarification. The lack of specific references or detailed guidance on what needs to be clarified makes the comment weakly grounded. Since the questions are specific about the definitions, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the definitions of \"scenario\" and the \"agnostic\" part in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises questions about the definition of \"scenario\" in the paper, specifically whether it refers to class or instances, and whether the \"agnostic\" part is clearly explained. While the comment identifies areas of confusion, it does not provide specific suggestions or guidance on how the authors might clarify these points. The feedback is 3 as it highlights potential areas for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the naming of the method, specifically questioning why it is named after \"Maestro\" and whether it is ever introduced in the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or improve the clarity of the method\"s naming. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the naming of the method, specifically questioning why it is named after \"Maestro\" and whether it is ever introduced in the paper. However, it does not specify which part of the paper this question pertains to, such as the introduction, methodology, or discussion sections. Without explicit references to sections or elements of the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed regarding the naming of the method. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about the naming of a method, specifically questioning why it is named after \"Maestro\" and whether it is introduced in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the naming of the method, specifically questioning why it is named after \"Maestro\" and whether it is ever introduced in the paper. While it identifies a potential issue with the naming, it does not provide any suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it points out a potential issue but does not offer constructive advice for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the definition of \"best\" when referring to a candidate in the paper. It specifies that the authors should determine whether \"best\" refers to candidates most relevant for prediction, those with the highest confidence scores, or another criterion. This direct and concrete instruction provides clear guidance on how the authors should address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the clarification of the term \"best\" in the context of the paper. The comment requests a definition of \"best\" and specifies the criteria it might refer to, such as relevance for prediction or confidence scores. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point requests clarification on the definition of \"best\" when referring to a candidate in the paper. This is a request for clarification rather than a claim, as it does not express an opinion or judgment that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides clear and actionable feedback by requesting clarification on the definition of \"best\" when referring to a candidate in the paper. This guidance helps the authors ensure that their terminology is consistent and precise, which is crucial for the clarity and correctness of their work. By specifying the criteria that \"best\" might refer to, the comment empowers the authors to make necessary adjustments to improve the clarity and precision of their paper. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some points are overclaimed, specifically mentioning that the proposed method does not consider feedforward layers but is described as if it does. This feedback highlights a discrepancy in the description of the method. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific changes to clarify the description. The action is implicit and somewhat vague, as the authors need to infer that they should revise the text to accurately reflect the method\"s components. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the overclaimed nature of certain points in the paper, particularly regarding the consideration of feedforward layers in the proposed method. However, it does not specify which parts of the paper are overclaimed or provide detailed guidance on how to address this issue. The authors can infer that it relates to the description of the method, but the lack of explicit references or detailed suggestions makes it weakly grounded. The comment is specific in identifying the overclaimed aspect but lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some points are overclaimed, specifically mentioning that the proposed method does not consider feedforward layers but is described as if it does. This claim is 3 as it highlights a discrepancy in the description of the method. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it difficult for the authors to understand and address the issue effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the overclaimed nature of certain points in the paper, particularly regarding the consideration of feedforward layers in the proposed method. It highlights a discrepancy in the description of the method, noting that while the method does not consider feedforward layers, some text implies that it does. This feedback is 3 as it points out a potential inconsistency in the paper\"s description, which the authors can address by revising the text to accurately reflect the method\"s components. However, the comment could be more helpful if it provided specific suggestions on how to clarify the description or examples of overclaimed points. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the experiments design is not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not provide explicit guidance on how the authors should address this issue or what specific aspects of the design need clarification. The feedback lacks concrete suggestions or actionable steps, leaving the authors uncertain about how to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the experiments design, mentioning \"no variations\" and \"Up to 18 games\" finetuning methods. However, it does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in identifying the lack of motivation for these experiments, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments design is not clearly motivated, specifically mentioning the \"no variations\" and \"Up to 18 games\" finetuning methods. However, the comment lacks specific reasoning or examples to support why these aspects are not clearly motivated. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific issue with the experiments design, noting that it is not clearly motivated. It highlights two particular methods, \"no variations\" and \"Up to 18 games\" finetuning, which lack motivation. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the clarity of their experiments. While it points out a problem, it lacks actionable advice, making it 2. The authors are left with a general understanding of the issue but without specific steps to take to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the authors should provide a more comprehensive evaluation of their method performance under different missing modality cases, specifically mentioning the testing set with different missing ratios. It also suggests evaluating the method under unimodal feature learning in supervised multimodal learning and audiovisual SlowFast Networks for video recognition. This feedback is clear and provides specific actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1/2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the evaluation of the method performance under different missing modality cases, such as testing sets with varying missing ratios. Additionally, it suggests evaluating the method under unimodal feature learning in supervised multimodal learning and audiovisual SlowFast Networks for video recognition. This provides clear guidance on what additional evaluations are needed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide a more comprehensive evaluation of their method performance under different missing modality cases, specifically mentioning testing sets with varying missing ratios. However, the comment does not provide specific examples or detailed reasoning to support why this evaluation is necessary or how it would enhance the paper\"s contribution. The lack of explicit justification or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that only MissV and MissA results are shown in the tables, and it suggests that the authors should provide a more comprehensive evaluation of their method performance under different missing modality cases, such as testing sets with varying missing ratios. This feedback is clear and actionable, as it directs the authors to expand their evaluation to include additional scenarios, which could enhance the robustness and comprehensiveness of their results. However, the comment could be more helpful if it provided specific examples or guidance on how to conduct these evaluations. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include an ablation study to examine the effect of using image features. However, it does not specify which conditions should be changed or how the ablation study should be conducted. The action is implicit, as the authors can infer that they need to add an ablation study, but the lack of concrete details on how to implement this action makes it vague. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including an ablation study to examine the effect of using image features, but it does not specify which part of the paper this should be included in. The authors might infer that it relates to the experimental section or the discussion of results, but this inference is not direct. The comment is specific in suggesting the inclusion of an ablation study, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that an ablation study should be included to examine the effect of using image features. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would improve the paper. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the suggestion, rendering it 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that an ablation study should be included to examine the effect of using image features. This feedback is 3 as it points out a potential area for improvement, specifically the need to assess the impact of image features on the results. However, the comment lacks depth and does not provide specific guidance on how to conduct the ablation study or what aspects should be considered. While it offers a direction for improvement, it does not fully support the authors in making a comprehensive revision. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" While it implies that the authors should consider testing the approach in these settings, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional experiments or analyze the approach\"s performance in these challenging settings. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments performed on \"3 language pairs with the base setting,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the concern regarding the approach\"s performance in challenging settings, particularly mentioning \"Transformer Big and deep Transformers.\" This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the performance of the approach in challenging settings, specifically mentioning \"Transformer Big and deep Transformers.\" While it identifies a potential area for improvement, it does not provide specific suggestions or guidance on how the authors might address this concern. The comment lacks actionable feedback, such as recommending additional experiments or analyses to evaluate the approach in these settings. As a result, the comment is 3, as it highlights a potential weakness but does not fully support the authors in improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a misunderstanding regarding the concept of identifiability, stating that it is a property of a model assuming infinite data can be observed. It suggests that the authors cannot claim a model is not identifiable due to insufficient data. However, the comment does not provide explicit guidance on how the authors should address this misunderstanding or improve their draft. It lacks concrete suggestions or actions for the authors to take, leaving them uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses a misunderstanding regarding the concept of identifiability, which is a property of a model assuming infinite data can be observed. However, it does not specify which part of the paper discusses this concept, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific in identifying the issue with the authors\" understanding, it lacks grounding as it does not provide clear guidance on where in the paper this issue is discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" understanding of identifiability is incorrect, stating that identifiability is a property of a model assuming infinite data can be observed. The comment provides a logical reasoning by explaining that identifiability cannot be determined due to insufficient data. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the concept to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical misunderstanding regarding the concept of identifiability, which is a property of a model assuming infinite data can be observed. It clarifies that the authors cannot claim a model is not identifiable due to insufficient data. This feedback is valuable as it corrects a fundamental misunderstanding that could affect the interpretation of the results. However, the comment could be more helpful if it provided suggestions on how the authors might address this misunderstanding or improve their discussion of identifiability. Overall, the comment is 3 as it highlights an important issue but lacks depth and actionable guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the results show no particular benefit compared to a simple baseline. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve their results. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results and the comparison with a simple baseline, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that the results show no particular benefit compared to the simple baseline. This provides clear guidance on what aspect of the results needs attention or improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results show no particular benefit compared to a simple baseline. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the results, specifically that they do not demonstrate a particular benefit compared to a simple baseline. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their results. Without actionable feedback or detailed critique, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights two specific issues related to efficiency: the requirement for a pretrained vocoder on 60khour LibriLight and the lack of description on the time cost, such as GPU hours, for the pretraining process. It also mentions the slower inference speed due to the use of a diffusionbased vocoder for waveform refinement. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues, such as suggesting ways to reduce the time cost or improving the inference speed. The authors are left to infer that they need to provide more details on the pretraining process and possibly optimize the diffusionbased vocoder. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"training process\" and \"inference process,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the specific issues with the training process, such as the requirement for a pretrained vocoder on 60khour LibriLight and the lack of description on the time cost, as well as the slower inference speed due to the use of a diffusionbased vocoder. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method requires a pretrained vocoder on 60khour LibriLight and does not describe the time cost, such as GPU hours, for the pretraining process. It also mentions that the inference process using a diffusionbased vocoder results in slower inference speed compared to DSP and WarpNet. While the comment provides some logical reasoning about the time cost and the impact on inference speed, it lacks specific references or detailed examples to fully substantiate the claims. This makes the comment 3, as the authors would need to further explore and verify the claims themselves.", "helpfulness_rationale": "The review comment identifies specific inefficiencies in the methodology, particularly regarding the training and inference processes. It highlights the requirement for a pretrained vocoder on 60khour LibriLight and the lack of description on the time cost, such as GPU hours, for the pretraining process. Additionally, it points out that the use of a diffusionbased vocoder for waveform refinement results in slower inference speed compared to other methods like DSP and WarpNet. While the comment effectively identifies areas for improvement, it lacks detailed suggestions or actionable steps for the authors to address these issues. Providing more specific guidance on how to optimize the training process or improve the inference speed would make the feedback more helpful. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the generalization of the framework, specifically noting that while the scoring function s(\u00b7; G) can be generalized for multiple goal documents or without any gold document, this generalization is not explored in the paper. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific actions they should take to explore the generalization. The action is implicit and vague, as it leaves the authors to infer that they need to explore the generalization of the framework, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, indicating that this aspect is not explored in the paper. However, it does not specify which part of the paper discusses the scoring function or where the generalization issue is mentioned. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue of generalization but lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document is not explored, which raises a question about the generalizability of the framework. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the generalization of the scoring function s(\u00b7; G) for multiple goal documents or without any gold document, noting that this aspect is not explored in the paper. This feedback highlights a gap in the paper\"s exploration of the framework\"s generalizability, which is crucial for understanding the scope and applicability of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or explore the generalization further. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is dense and difficult to follow in parts, particularly due to the use of numbered lists in paragraphs that could be more effectively presented as actual lists. While the comment identifies a potential issue with the readability of the paper, it does not explicitly instruct the authors to make this change or provide specific guidance on how to restructure the paragraphs. The action is implicit, as the authors can infer that they should consider reorganizing the content for better readability, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment provides a general observation about the paper being dense and difficult to follow, suggesting that numbered lists in paragraphs could be more effectively presented as actual lists. However, it does not specify which parts of the paper are dense or where the numbered lists are located, making it difficult for the authors to pinpoint the exact areas needing improvement. Additionally, the comment lacks specificity regarding what aspects of the numbered lists could be improved or how they should be restructured. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is dense and difficult to follow, particularly due to the use of numbered lists in paragraphs. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of dense sections, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a common issue with the paper, which is its dense and difficulttofollow nature, particularly due to the use of numbered lists in paragraphs. It suggests that these lists could be more effectively presented as actual lists, which would likely improve readability. While the comment highlights a potential area for improvement, it lacks specific guidance or examples on how to restructure the content to enhance clarity. The feedback is 3 as it points out a specific area for improvement, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might be using similar spectral cues. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what changes could be made to their work. Without actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might be using similar spectral cues. However, it does not specify which part of the paper this question pertains to, such as a particular section, figure, or discussion. Without explicit references to the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what needs to be addressed or how the authors might address the question. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might be using similar spectral cues. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an interesting question about the effectiveness of a simple classifier and suggests that other \"fake image detectors\" might be using similar spectral cues. While it prompts the authors to consider this possibility, it does not provide specific guidance or suggestions on how to address this question or explore it further. The comment lacks depth and actionable advice, leaving the authors with a general idea of what to consider but without clear direction on how to improve their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the visualization results are not satisfactory compared to the ground truth and recommends analyzing both satisfied and terrible cases. However, it does not provide specific guidance on how to conduct this analysis or what aspects should be focused on. The action is implicit and somewhat vague, as the authors know they need to analyze both types of cases but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should analyze both satisfied and terrible cases to provide a more comprehensive understanding of the results. Additionally, it references a specific aspect of the paper, \"Classincremental learning for semantic segmentation reusing neither old data nor old labels,\" which further clarifies the context. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the visualization results are \"terrible\" compared to the ground truth and suggests analyzing both satisfied and terrible cases. However, the comment lacks specific examples or detailed reasoning to support why the results are considered terrible or how the suggested analysis would improve the understanding of the results. Without concrete evidence or references, the claim is difficult for the authors to address effectively, making it 2. The authors would need to make significant effort to understand and address the feedback, which limits the utility of the comment.", "helpfulness_rationale": "The review comment identifies a specific issue with the visualization results, noting that they are \"terrible\" compared to the ground truth. It suggests that the authors should analyze both satisfied and terrible cases to provide a more comprehensive understanding of the results. This feedback is 3 as it highlights a potential area for improvement and encourages the authors to consider a broader analysis. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or what aspects of the results should be focused on. Overall, the comment offers some insight but lacks depth and actionable advice, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the paper builds upon a large body of previous work, noting that this could affect the validity and effectiveness of the current work. However, it does not provide specific guidance or suggestions on how the authors should address these limitations or issues. The comment also mentions that the implementation process is similar to previous work on GAN, but it does not offer any actionable advice on how to improve upon this. As a result, the authors are left without clear direction on how to enhance their draft, making the comment 1.", "grounding_specificity_rationale": "The comment critiques the paper for building upon a large body of previous work, suggesting that this could affect the validity and effectiveness of the current work. However, it does not specify which parts of the paper are affected by this critique or how the authors might address these concerns. Additionally, the comment mentions that the implementation process is similar to previous work on GAN, but it does not provide specific details on how this similarity impacts the current work. Without explicit references to sections or specific issues, the authors cannot confidently determine which parts of the paper need attention or improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper builds upon a large body of previous work, which could affect the validity and effectiveness of the current work. However, the comment does not provide specific examples or references to the previous work that could be problematic or how they might impact the current work. Additionally, it mentions that the implementation process is similar to previous work on GAN, but without further elaboration or justification, the claim remains vague and difficult for the authors to address. Therefore, the comment is considered 2, as it provides some context but lacks detailed evidence or references to support the claim fully.", "helpfulness_rationale": "The review comment highlights a potential issue with the paper by noting that it builds upon a large body of previous work, which could affect the validity and effectiveness of the current work. It also points out that the implementation process is similar to previous work on GAN. While this feedback identifies areas of concern, it lacks specific suggestions or guidance on how the authors might address these issues or improve their work. The comment provides some insight into potential weaknesses but does not offer actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the partitioning step and the use of information unavailable to the policy. It suggests that if some information, like patient characteristics, is used for clustering but not in training the policy, it might be beneficial to incorporate it into the policy training. However, the comment does not provide explicit guidance or suggestions on how to address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors are left to infer that they should consider incorporating additional information into the policy training. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the initial idea of selecting a policy for each subgroup and questions whether information unavailable to the policy is being used during the partitioning step. It also raises a concern about why certain information, like patient characteristics, is used for clustering but not in training the policy. However, the comment does not specify which part of the paper discusses this idea or where the partitioning step is described, making it weakly grounded. The comment is specific in its questioning and suggests a potential improvement, but without explicit references to sections, the authors may struggle to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the partitioning step and the use of information unavailable to the policy. It suggests that if certain information, like patient characteristics, is used for clustering but not in training the policy, it might be beneficial to incorporate it into the policy training. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of explicit evidence or detailed explanation makes it difficult for the authors to fully understand and address the concern. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a critical question about the partitioning step and the use of information unavailable to the policy. It suggests that if certain information, like patient characteristics, is used for clustering but not in training the policy, it might be beneficial to incorporate it into the policy training. This feedback is 3 as it prompts the authors to reconsider their approach and potentially improve the methodology. However, the comment could be more helpful if it provided specific suggestions or examples on how to incorporate this information into the policy training. Overall, the comment offers a valuable insight but lacks actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the rendering quality. Without any suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix C,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, prompting the authors to consider and address this issue. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point is a question asking for an explanation of why NeRF\"s rendering quality is worse than NeuS and Geo NeuS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the rendering quality of NeRF compared to NeuS and Geo NeuS, which could be a point of interest for the authors. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve the rendering quality. The comment lacks actionable feedback, leaving the authors without a clear path for improvement. Therefore, it is rated as 2, as it identifies a potential area for discussion but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a bold assumption made in Section 3.7, questioning the suitability of purely unsupervised largescale pretraining for NLP applications. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or provide a more nuanced analysis. Without specific suggestions or steps for improvement, the authors are left without a clear understanding of what changes are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a bold assumption made in the manuscript regarding the suitability of purely unsupervised largescale pretraining for NLP applications and questions how this conclusion can be drawn from the proposed evaluation approach. This provides clear guidance on what needs to be addressed or clarified in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the manuscript makes a bold assumption in Section 3.7, stating that \"purely unsupervised largescale pretraining might not be suitable for NLP applications.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this assumption or how it relates to the proposed evaluation approach. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a bold assumption made in Section 3.7, specifically questioning the suitability of purely unsupervised largescale pretraining for NLP applications. While the comment highlights a potential issue, it lacks depth and does not provide specific guidance or suggestions on how the authors might address this concern or improve their evaluation approach. The feedback is 3 as it points out a critical area for reconsideration, but it does not offer actionable steps or detailed reasoning to support the claim. Therefore, the comment aligns with a score of 3, indicating that it provides some insight but lacks comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific gaps in the paper related to the discussion of recent related work, including the omission of qualitative and quantitative comparisons with A and DCN 18. It also mentions that B is relevant with respect to transductive label propagation. While the comment highlights these areas for improvement, it does not provide explicit instructions on how to address these gaps or suggest specific actions for the authors to take. The authors are left to infer that they need to include these discussions and comparisons in their paper. The lack of concrete guidance makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Related work 2.1\" and \"2.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It specifies the issues with the discussion of recent related work, including the omission of qualitative and quantitative comparisons with A and DCN 18, and mentions that B is relevant with respect to transductive label propagation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper misses discussions of recent related work, specifically mentioning A and DCN 18, and notes that B is relevant with respect to transductive label propagation. The comment provides specific examples of missing comparisons, such as the omission of qualitative and quantitative comparisons with A and DCN 18, and mentions that B is relevant. This level of detail and specificity provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more context or references to support the claim about the performance of A and DCN 18. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific gaps in the paper related to the discussion of recent related work. It points out the omission of qualitative and quantitative comparisons with A and DCN 18, which are relevant to the paper\"s performance claims. Additionally, it mentions that B is relevant with respect to transductive label propagation. While the comment highlights important areas for improvement, it lacks specific guidance on how the authors should address these gaps or what specific comparisons or discussions should be included. This limits the comment\"s helpfulness, as the authors are left to infer the necessary changes without clear direction. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a change in the operator used in Figure 2, recommending the use of the Hadamard product instead of addition. This is a clear and direct action for the authors to take, providing them with a specific instruction on how to modify their draft. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, recommending the use of the Hadamard product instead of addition in the operator. This provides clear guidance on what needs to be changed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a specific change in the operator used in Figure 2, recommending the use of the Hadamard product instead of addition. This is a clear and direct suggestion, as it specifies exactly what needs to be changed. However, it does not provide any reasoning or justification for why this change is necessary or how it would impact the results. While the suggestion is specific, the lack of supporting evidence or explanation makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper. It recommends changing the operator used in Figure 2 from addition to the Hadamard product. This is a clear and direct feedback that can help the authors enhance the accuracy and clarity of their results. By addressing this suggestion, the authors can improve the consistency and correctness of their methodology. However, the comment could be more helpful if it provided additional context or explanation on why this change is necessary or how it impacts the overall findings. Despite this, the comment is 4 as it offers a concrete step for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point highlights the lack of a clear explanation for the intention behind BWTP/GLBW, noting that many details are in the appendix, making it difficult for readers to understand them initially. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the clarity of the explanation. The comment implies that the authors should provide a more detailed explanation of the intention behind BWTP/GLBW, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the lack of a clear explanation for the intention behind BWTP/GLBW, noting that many details are in the appendix, making it difficult for readers to understand them at first glance. However, it does not specify which part of the paper this issue is addressed in, nor does it provide specific guidance on how to improve the explanation. The authors can infer that it relates to the explanation of BWTP/GLBW, but the comment lacks full grounding and specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the explanation for the intention of BWTP/GLBW is unclear, as many details are provided in the appendix. However, the comment does not provide specific examples or detailed reasoning to support this claim, making it difficult for the authors to understand and address the issue. The lack of specific examples or references to the appendix content leaves the claim 3, as it highlights a potential problem but lacks the necessary details to fully substantiate it. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the clarity of the explanation for the intention behind BWTP/GLBW, noting that many details are provided in the appendix, which may make it difficult for readers to understand them at first glance. While the comment highlights a specific area for improvement, it lacks actionable guidance or suggestions on how the authors might enhance the clarity of their explanation. Without specific advice on what aspects of the explanation could be improved or how to present the information more effectively, the comment provides limited value to the authors in terms of actionable feedback. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to include a proof at the end of Section 3, suggesting that it be included in the revision, possibly as supplementary material or integrated into the main paper. This feedback provides a clear and direct action for the authors to take, specifying where the proof should be placed and offering a potential solution. The comment is specific and actionable, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of a proof at the end of Section 3. The suggestion to include the proof either as supplementary material or potentially in the main paper provides clear guidance on how to improve the draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that a proof is omitted at the end of Section 3 due to space constraints. The comment implies that including the proof would be beneficial, either as supplementary material or potentially integrated into the main paper. However, the comment does not provide specific reasoning or examples to support why omitting the proof is a significant issue or how it affects the paper\"s comprehensiveness. Without detailed justification or references, the claim remains 3, as it lacks the necessary evidence or explanation to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific omission in the paper, namely the proof at the end of Section 3, which is omitted due to space constraints. The comment provides a clear and actionable suggestion to include the proof either as supplementary material or potentially integrated into the main paper. This feedback is valuable as it guides the authors on how to enhance the comprehensiveness and completeness of their paper. However, the comment could be more helpful if it offered additional context or explanation on why the proof is important or how it would benefit the paper. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide specific experimental results or references to support their claim that \"NPPs lack any direct dependence on magnitudes\" as the reason for their performance being worse than ETAS. This feedback is explicit, as it clearly states what the authors need to do to improve their draft. However, it lacks concrete details on which specific results or references should be provided, leaving the authors with a general direction but without specific guidance on how to implement the suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests providing specific experimental results or references to support the claim that \"NPPs lack any direct dependence on magnitudes\" as the reason for their performance being worse than ETAS. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in suggesting the need for more detailed evidence or references to support the claim. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide specific experimental results or references to support their claim that \"NPPs lack any direct dependence on magnitudes\" as the reason for their performance being worse than ETAS. This claim is 3 as it provides a logical reasoning for the need for more detailed evidence. However, the comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide specific experimental results or references to support their claim that \"NPPs lack any direct dependence on magnitudes\" as the reason for their performance being worse than ETAS. This feedback is clear and actionable, as it directs the authors to enhance the rigor and evidence supporting their argument. By providing specific results or references, the authors can strengthen their claims and make their reasoning more robust. However, the comment could be more helpful if it offered examples of what kind of results or references would be beneficial, or if it provided guidance on how to conduct such analyses. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the implementation details, specifically mentioning that the methodology section outlines connectivity patterns between layers but does not provide specific guidance on applying these connections to complex architectures like UNet, ResNet, and MobileNet. The reviewer also notes that these details are not included in the Appendix. This feedback implies that the authors should provide more detailed guidance on how to apply the outlined connectivity patterns to these architectures, which would help clarify the implementation process. While the action is implicit, the comment provides a clear direction for improvement, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the methodology section and Equations 3 and 4, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the implementation details, particularly the lack of guidance on applying the connectivity patterns to complex architectures like UNet, ResNet, and MobileNet. The comment also points out that these details are not included in the Appendix, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the implementation details are unclear, specifically mentioning the lack of guidance on applying the connectivity patterns outlined in Equations 3 and 4 to complex architectures like UNet, ResNet, and MobileNet. The reviewer highlights that these details are not included in the Appendix, which raises concerns about the comprehensiveness of the paper. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to infer the lack of guidance and the absence of detailed explanations in the Appendix to address the issue, which limits the verifiability of the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of implementation details in the paper. It points out that while the methodology section outlines connectivity patterns between layers, there is no specific guidance on how to apply these connections to complex architectures like UNet, ResNet, and MobileNet. This lack of detail is particularly problematic when attempting to understand and replicate the methodology. Additionally, the comment notes that these details are not included in the Appendix, further highlighting the need for comprehensive guidance. The feedback is clear and actionable, providing the authors with a specific direction to improve the clarity and comprehensiveness of their implementation details. However, it could be more helpful if it offered suggestions on how to address these issues or provided examples of how to apply the connectivity patterns to the mentioned architectures. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the calculation of HTER label, which relies on automatic scripts, may not be scalable to other annotations like MQM or DA. It implies that the authors should experiment with other languages and annotations to verify the scalability. While the comment provides a clear action\u2014testing scalability with different annotations\u2014the suggestion to experiment with other languages and annotations is not explicitly stated. The action is concrete, as it specifies what needs to be done, but it is phrased as a request rather than a direct command. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment addresses the calculation of HTER labels, which is a specific aspect of the paper. It suggests that the reliance on automatic scripts for this calculation may not be scalable to other annotations like MQM or DA. The comment implies that the authors should experiment with other languages and annotations to verify scalability. However, it does not explicitly mention which section of the paper discusses the HTER label calculation, making it weakly grounded. The comment is specific in its suggestion to test scalability with other annotations and languages, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the calculation of HTER labels, which relies on automatic scripts, may not be scalable to other annotations like MQM or DA. The reviewer suggests that the authors should experiment with other languages and annotations to verify scalability. However, the comment lacks specific examples or references to support the claim about scalability issues. Without detailed evidence or examples, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the concern. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the methodology related to the scalability of the HTER label calculation, which relies on automatic scripts. It suggests that the authors should experiment with other languages and annotations to verify the scalability of their approach. This feedback is clear and actionable, providing the authors with a specific direction to explore and potentially strengthen their work. However, the comment could be more helpful if it included examples of other languages or annotations that could be tested, or if it offered additional guidance on how to conduct these experiments. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should comment on the theorypractice gap, specifically mentioning that sparse neural networks are generally difficult to fit, as argued in Farrell, Liang, and Misra ECTA 2021. The comment implies that the authors should provide a comment on this issue to help readers understand the key elements that allow CausalStonet to learn sparse neural networks. While the action is explicit, it lacks concrete guidance on how to implement this comment or what specific elements should be highlighted. The authors know they need to address the theorypractice gap but are not given detailed instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the theorypractice gap and provides a specific reference to Farrell, Liang, and Misra ECTA 2021, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should comment on this gap, particularly focusing on the difficulty in fitting sparse neural networks and the key elements that allow CausalStonet to learn them. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a theorypractice gap in deep learning, specifically mentioning that sparse neural networks are generally difficult to fit. The comment references a specific paper (Farrell, Liang, and Misra ECTA 2021) to support this claim, providing a concrete example of the issue. This reference makes the claim more robust and verifiable, as it grounds the critique in existing literature. However, the comment could be strengthened by providing more detailed reasoning or examples from the referenced work. Overall, the claim is 4, as it is supported by a specific reference but lacks additional detailed justification.", "helpfulness_rationale": "The review comment identifies a significant issue in the paper, namely the theorypractice gap in deep learning, particularly regarding the difficulty in fitting sparse neural networks. It references a specific paper (Farrell, Liang, and Misra ECTA 2021) to support the claim, providing a concrete example of the problem. The comment suggests that the authors should comment on this issue, which would help readers better understand the key elements that allow CausalStonet to learn sparse neural networks. This feedback is clear and actionable, offering a specific direction for improvement that could enhance the paper\"s relevance and understanding. However, it could be more helpful if it provided additional guidance on how to address the theorypractice gap or what specific aspects of the methodology should be highlighted. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the manuscript is densely packed in terms of space, with figures and tables closely positioned to the text, which can make the paper seem cluttered and condensed. The reviewer provides specific suggestions for addressing this issue, such as making some tables smaller or relocating them to the Appendix, and reducing the size of certain figures. These suggestions are explicit and concrete, giving the authors clear guidance on how to improve the layout and presentation of their paper. The comment is 5 as it provides detailed steps for the authors to follow to enhance the readability and visual appeal of their work.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of the manuscript being densely packed in terms of space, with figures and tables closely positioned to the text. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it provides clear suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and reducing the size of certain figures. These suggestions are actionable and provide a clear path for the authors to follow to improve the layout and presentation of their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the manuscript is densely packed in terms of space, with figures and tables closely positioned to the text, making the paper seem cluttered and condensed. The reviewer suggests specific actions to address this issue, such as making some tables smaller or relocating them to the Appendix, and reducing the size of certain figures. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim of being \"densely packed.\" The authors would need to infer the need for such adjustments, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript\"s layout, noting that it is densely packed with figures and tables closely positioned to the text, which can make the paper seem cluttered and condensed. The reviewer provides actionable suggestions for improvement, such as making some tables smaller or relocating them to the Appendix, and reducing the size of certain figures. These suggestions are clear and constructive, offering the authors a concrete way to enhance the readability and visual appeal of their paper. By addressing these issues, the authors can significantly improve the presentation of their work, making the comment 5. Therefore, the comment deserves a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the ReCPE method being too strategic and lacking theoretical guarantees. It suggests that the authors may be able to strengthen the article from this perspective. However, the comment does not provide specific guidance on how to address this issue or what theoretical aspects could be strengthened. The action is implicit and vague, as the authors are left to infer that they need to provide more theoretical justification for their method. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the ReCPE method and suggests that it lacks theoretical guarantees, providing a clear reference to the paper. It also points out a minor issue with the spelling of \"real word\" in Note 2 on page 7. The comment is specific in its critique of the ReCPE method\"s strategic nature and the lack of theoretical support, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ReCPE method is too strategic and lacks theoretical guarantees. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The mention of a minor spelling error in Note 2 on page 7 is factual and does not constitute a claim. Therefore, the comment is categorized as 1, as it lacks sufficient evidence or reasoning to support the claim about the ReCPE method.", "helpfulness_rationale": "The review comment identifies a significant issue with the ReCPE method, noting that it is too strategic and lacks theoretical guarantees. This feedback is valuable as it highlights a critical area for improvement, suggesting that the authors may need to provide more rigorous theoretical justification for their method. However, the comment could be more helpful if it offered specific suggestions on how to strengthen the theoretical foundation or provided examples of how to address the strategic nature of the method. Additionally, the minor comment about the spelling error in Note 2 on page 7 is a separate issue and does not contribute to the main critique. Overall, the comment is 3 as it points out a critical area for improvement but lacks detailed guidance on how to address it."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the applicability of the work beyond NLU tasks, specifically asking if it can be applied to generation tasks. While it implies that the authors should consider expanding the scope of their work, it does not provide explicit instructions or concrete guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore the application to generation tasks but are not given specific steps or examples to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the applicability of the work beyond NLU tasks, specifically asking if it can be applied to generation tasks. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the applicability of the work, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question asking for clarification on the applicability of the work beyond NLU tasks, specifically to generation tasks. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the applicability of the work beyond NLU tasks, specifically asking if it can be applied to generation tasks. This inquiry prompts the authors to consider expanding the scope of their work or exploring new applications, which could be a valuable direction for future research. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this question or what aspects of the work could be relevant to generation tasks. While it identifies an area for potential improvement, the feedback is 3 as it encourages the authors to think about broader applications of their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing definition of $N_d$ and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This feedback provides a clear and direct action for the authors to take, specifying what needs to be addressed in the paper. The comment is specific and actionable, leaving no ambiguity about how the authors should proceed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"l.145ff,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of definition for $N_d$ and suggests that it would be beneficial to state explicitly that there could be a different number of observations per task. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a specific issue with the paper, namely the undefined nature of $N_d$ and the suggestion to clarify its definition. However, it does not provide any supporting evidence, reasoning, or references to justify why this is a critical issue or how it affects the paper\"s validity or conclusions. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the significance of the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that $N_d$ is not defined and suggesting that it would be beneficial to explicitly state that there could be a different number of observations per task. This feedback is clear and actionable, providing the authors with a direct point of improvement. By addressing this issue, the authors can enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered additional context or suggestions on how to effectively communicate this point. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly states that the Appendix is not cut from the main paper and mentions that the PDF provided for the main paper is a 14page document. This feedback is clear and direct, providing the authors with a specific action to take: to ensure that the Appendix is properly integrated into the main paper. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Appendix\" and the \"main paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly states the issue, which is that the Appendix is not cut from the main paper and provides a reference to the PDF provided for the main paper. This level of detail helps the authors understand exactly what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual statement about the structure of the document, indicating that the Appendix is not cut from the main paper and providing a reference to the PDF. It does not contain any subjective opinions, judgments, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 3 as it points out a structural issue with the document, specifically that the Appendix is not cut from the main paper. This feedback is clear and provides the authors with a specific area to address, which is the integration of the Appendix into the main paper. However, the comment could be more helpful if it offered suggestions on how to effectively integrate the Appendix or provided examples of how to structure it. Overall, the comment identifies a minor issue but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should provide more insight into the role of the ternary potential in their proposed model, as it appears to be a key factor in the model\"s performance. The comment implies that the authors should explain how the ternary potential contributes to the model\"s improvement over existing models, particularly in the 2 modality setup. However, the comment does not explicitly instruct the authors to include this explanation in their draft or specify how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should add an explanation but are not given detailed guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the proposed model\"s performance, particularly highlighting the role of the ternary potential and the lack of improvement in certain modalities setups. The comment suggests that the authors should provide more insight into this aspect, making it clear what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the main improvement in the proposed model is due to the ternary potential, as evidenced by the results in table 1. The reviewer suggests that without the ternary potential, the model does not outperform existing models for two modalities, except for HieCoAtt. This claim is supported by the data presented in table 1, making it 4. However, the comment could be strengthened by providing more detailed analysis or examples of how the ternary potential contributes to the model\"s performance. Overall, the comment is 4, as it provides a logical basis for the claim but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a specific issue with the results presented in table 1, noting that the main improvement in the proposed model is attributed to the ternary potential. It suggests that the authors should provide more insight into this aspect, particularly in the context of the 2 modality setup where the model does not outperform existing models except for HieCoAtt. This feedback is clear and actionable, as it directs the authors to enhance the explanation and understanding of the model\"s performance. However, the comment could be more helpful if it provided specific suggestions on how to improve the explanation or examples of how the ternary potential contributes to the model\"s performance. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should note which methods use data augmentations, their architectures, and objectives in the tables to better assess the degree of applestoapplesness of the comparisons. This feedback provides a clear and explicit action for the authors to take, specifying what additional information should be included in the tables. The comment is concrete, as it outlines exactly what needs to be added to improve the clarity and utility of the comparisons. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"tables,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be noted in the tables, namely which methods use data augmentations, their architectures, and objectives. This level of detail helps the authors understand exactly what information is needed to improve the assessment of applestoapplesness. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide additional information about the methods used in the tables, specifically regarding data augmentations, architectures, and objectives. This claim is 3 as it logically suggests that including such details would enhance the assessment of applestoapplesness. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity and utility of the paper. It recommends noting which methods use data augmentations, their architectures, and objectives in the tables to better assess the degree of applestoapplesness of the comparisons. This feedback is clear and constructive, as it guides the authors on what additional information should be included to enhance the comprehensiveness of their analysis. By addressing this suggestion, the authors can significantly improve the clarity and utility of their draft. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that more experimental details, such as the neural networks and hyperparameters used, should be included in the appendix. This provides a clear and direct action for the authors to take, specifying exactly what information is needed and where it should be placed. The comment is specific and concrete, giving the authors a precise understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests including more experimental details, such as neural networks and hyperparameters, in the appendix. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what needs to be included, but without clear grounding, the authors may struggle to identify the exact sections that require revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more experimental details, such as neural networks and hyperparameters, should be included in the appendix. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the draft by recommending the inclusion of more experimental details, such as neural networks and hyperparameters, in the appendix. This feedback is clear and directly points out an area where the authors can enhance the comprehensiveness and transparency of their work. By addressing this suggestion, the authors can provide readers with a clearer understanding of the experimental setup, which is crucial for reproducibility and validation of their findings. However, the comment could be more helpful if it included examples of what specific details should be included or how they might impact the interpretation of the results. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that Section 5.1 does not provide useful information regarding why the new model is superior. However, it does not offer any explicit guidance or suggestions on how the authors should address this issue. The comment lacks specific instructions or concrete steps for the authors to take to improve the section, leaving them uncertain about what changes are needed. As a result, the action is implicit and vague, making it difficult for the authors to know how to apply the feedback effectively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of information regarding why the new model is superior. This provides the authors with a clear understanding of what needs to be addressed in the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"Section 5.1 does not seem to provide useful information regarding why the new model is superior.\" However, the comment does not offer any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with Section 5.1, noting that it does not provide useful information regarding why the new model is superior. This feedback highlights a gap in the paper that the authors need to address to improve the clarity and comprehensiveness of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending additional analysis or comparisons that could explain the superiority of the new model. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that a comparison is necessary to address the transferability of the singleIMP. However, it does not specify which comparison should be made or what aspects should be compared. The action is implicit, as the authors can infer that they need to conduct a comparison, but it is vague because it lacks concrete details on what specific comparison should be made. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that a comparison is necessary to address the transferability of the singleIMP, but it does not specify which part of the paper this comparison should be made in. This makes it difficult for the authors to pinpoint the exact section or aspect of the paper that needs improvement. Additionally, the comment lacks specificity regarding what kind of comparison is needed or how it would address the transferability issue. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that a comparison is necessary to address the transferability of the singleIMP, but it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment suggests that a comparison is necessary to address the transferability of the singleIMP, indicating that the authors should consider this aspect in their work. However, the comment lacks specificity and does not provide detailed guidance on what kind of comparison should be made or how it would enhance the paper. Without concrete suggestions or examples, the authors may find it challenging to understand the importance of the comparison and how to incorporate it into their draft. Therefore, the comment is 2, as it points out a potential area for improvement but does not offer actionable advice."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should consider checking humanfactors literature to address the practical challenges of interacting with humans, which were identified as limitations in the proposed method. While the comment implies that the authors should explore this area, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further research or incorporate humanfactors considerations into their work. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"No.03. 2020,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by mentioning the lack of specific ethical concerns and the limitations related to practical challenges of interacting with humans. The suggestion to consider humanfactors literature is clear and provides a specific direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there are no specific ethical concerns with the proposed methods. However, it acknowledges the limitations of the proposed method, particularly regarding practical challenges of interacting with humans, and suggests that the authors should consider humanfactors literature. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim about the absence of ethical concerns. The suggestion to explore humanfactors literature is logical but could be more robust with additional evidence or references. Therefore, the comment is 3, as it provides a basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment acknowledges the absence of specific ethical concerns with the proposed methods but highlights the limitations of the method, particularly regarding practical challenges of interacting with humans. It suggests that the authors should consider humanfactors literature to address these challenges. This feedback is 3 as it identifies an area for improvement and provides a direction for the authors to enhance their work. However, the comment could be more actionable by offering specific suggestions or resources for exploring humanfactors literature. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the scalability of the proposed model selection approach beyond MNISTlike datasets and suggests comparing it with other neural network pruning methods. While the comment implies that the authors should conduct experiments on larger or more diverse datasets, it does not explicitly instruct them to do so. Additionally, it does not provide specific guidance on how to compare the proposed approach with other methods. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments conducted in the MNISTfashion dataset, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the scalability of the proposed model selection approach beyond MNISTlike datasets and suggests comparing it with other neural network pruning methods. This provides clear guidance on what needs to be addressed or improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the scalability of the proposed model selection approach beyond MNISTlike datasets and suggests comparing it with other neural network pruning methods. While the comment raises a relevant question, it does not provide specific evidence or examples to support the claim that the approach lacks scalability or that it should be compared with other methods. The lack of detailed reasoning or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a relevant question about the scalability of the proposed model selection approach beyond MNISTlike datasets and suggests comparing it with other neural network pruning methods. This feedback is valuable as it prompts the authors to consider the broader applicability and robustness of their approach, which could enhance the paper\"s impact and comprehensiveness. However, the comment could be more helpful if it provided specific guidance on how to conduct these experiments or what aspects of the comparison should be emphasized. Overall, the comment is 4 as it identifies an important area for improvement and encourages the authors to explore additional aspects of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment identifies several specific issues with the mathematical formulations in the paper, such as inconsistencies in index notation, the use of $max$ instead of $max$ in a particular line, and the presence of an unexplained variable $x\"$ in the hypervolume formula. The reviewer provides explicit suggestions for corrections, such as changing $max$ to $max$ in line 345, clarifying the index notation in line 347, and suggesting the use of a uniform distribution in line 819. These suggestions are concrete and provide clear guidance on how the authors should address the issues. The comment is 5 as it offers specific and actionable steps for the authors to take to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (e.g., Line 345, Line 347, Line 344, Line 374, Line 225, and Line 819) where issues are identified, allowing the authors to accurately pinpoint the parts of the paper being addressed. It is also specific because it details the inconsistencies and suggests corrections, such as changing $max$ to $max$ in line 345, clarifying the index notation in line 347, and suggesting the use of a uniform distribution in line 819. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a series of observations and suggestions regarding inconsistencies and potential errors in the mathematical formulations of the paper. Each line mentioned provides a specific example of an issue, such as the use of $max$ instead of $max$ in line 345, the inconsistency in index notation in line 344, and the presence of an unexplained variable $x\"$ in the hypervolume formula. These observations are supported by explicit references to specific lines in the paper, making the claims clear and verifiable. However, the comment could be strengthened by providing more detailed reasoning or examples for each suggestion. Overall, the comment is 4, as it provides a solid foundation for the claims but could benefit from additional elaboration.", "helpfulness_rationale": "The review comment provides a detailed and actionable critique of several mathematical formulations in the paper, identifying specific inconsistencies and errors. It offers clear suggestions for corrections, such as changing $max$ to $max$ in line 345, clarifying the index notation in line 347, and suggesting the use of a uniform distribution in line 819. These specific and concrete suggestions will help the authors improve the accuracy and clarity of their mathematical formulations, making the comment 5. By addressing these issues, the authors can enhance the quality and professionalism of their draft. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors would benefit from including experiments that demonstrate the effect of using different numbers of particles. It explicitly states that the current lack of clarity on the importance of this choice is a concern. While the comment implies that the authors should conduct such experiments, it does not provide specific guidance on how to design or execute these experiments. The action is explicit but somewhat vague, as it lacks detailed instructions on what experiments to include or how to interpret the results. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including experiments that demonstrate the effect of using different numbers of particles, indicating a specific area where the authors might need to improve their work. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional experiments to clarify the importance of the choice of particle numbers. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors would benefit from including experiments that demonstrate the effect of using different numbers of particles. However, it does not provide any specific reasoning or evidence to support why this would be important or how it would impact the results. The comment lacks detailed justification or examples, making it difficult for the authors to understand the significance of the suggestion. As a result, the claim is considered 2, as it provides some direction but lacks the necessary details to fully substantiate the suggestion.", "helpfulness_rationale": "The review comment suggests that the authors would benefit from including experiments that demonstrate the effect of using different numbers of particles. This feedback is 3 as it identifies a potential area for improvement, specifically the lack of clarity regarding the importance of the choice of particle numbers. However, the comment does not provide specific guidance on how to design or execute these experiments, nor does it offer suggestions on what results to expect or how to interpret them. While it points out a relevant area for enhancement, the lack of detailed instructions limits its usefulness. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric 1. While it identifies a specific area that needs attention, it does not provide explicit guidance on how to conduct this comparison or what aspects of the covariance metric should be considered. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the lack of comparison of methods on plasticity evaluation metrics, such as the covariance metric 1. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what is missing, which is the comparison of methods on plasticity evaluation metrics. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison of methods on plasticity evaluation metrics, specifically mentioning the covariance metric 1. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area where the paper lacks comparison, namely the evaluation of methods on plasticity metrics, such as the covariance metric 1. This feedback is clear and actionable, as it directs the authors to include a comparison of methods on these metrics, which could enhance the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what aspects of the covariance metric should be considered. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide a better explanation for Table 5, specifically asking for an explanation of what A, B, C, and D represent. Additionally, it suggests that there should be an explanation of why positive paths lead to a monotonic solution and under what scenarios this occurs. These instructions are clear and provide concrete actions for the authors to take, ensuring they know exactly what needs to be addressed and how to do it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the explanation of what A, B, C, and D represent in Table 5, as well as the need for an explanation of why positive paths lead to a monotonic solution and under what scenarios. This provides clear guidance on what aspects of the table require further elaboration. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the content of Table 5, specifically asking for an explanation of what A, B, C, and D represent. It also questions the need for an explanation regarding why positive paths lead to a monotonic solution and under what scenarios. This is a request for clarification and does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Table 5, asking for a better explanation of what A, B, C, and D represent. It also questions the need for an explanation regarding why positive paths lead to a monotonic solution and under what scenarios this occurs. This feedback is clear and actionable, as it directs the authors to provide additional context and clarification for their table, which is crucial for understanding the results and conclusions. However, the comment could be more helpful if it offered suggestions on how to improve the explanation or provided examples of what kind of additional information would be beneficial. Overall, the comment is 4 as it highlights areas for improvement and provides a clear direction for the authors to enhance their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the practicality of using power law prediction for model selection, particularly in the context of estimating US accuracy. It suggests that the curve in Figure 1 is saturated only towards the end, implying that early predictions may not be reliable. The comment implies that the authors should consider alternative methods or ways to make cheaper estimations, but it does not provide specific guidance on how to implement these suggestions. The action is implicit and somewhat vague, as the authors need to infer the need for alternative methods or ways to improve the estimation process. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the practicality of using power law prediction for model selection, particularly in the context of estimating US accuracy. The comment further elaborates on the observation that the curve in Figure 1 is saturated only towards the end, suggesting that early predictions may not be reliable. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the practicality of using power law prediction for model selection, particularly in the context of estimating US accuracy. It references Figure 1, which shows a saturated curve, suggesting that early predictions may not be reliable. The comment implies that the authors should consider alternative methods or ways to make cheaper estimations. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a relevant question about the practicality of using power law prediction for model selection, particularly in the context of estimating US accuracy. It points out that the curve in Figure 1 is saturated only towards the end, suggesting that early predictions may not be reliable. This observation is valuable as it highlights a potential limitation in the methodology. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies an area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. This is a clear and direct action, as it specifies what the authors need to do to improve their draft. The comment is specific in its request, detailing the type of studies needed to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where these ablation studies should be included. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in its request, the absence of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. However, it does not provide any supporting evidence, reasoning, or examples to justify why these ablation studies are necessary or how they would improve the paper. Without such details, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide ablation studies to isolate the impact of specific factors underlying epsilon sampling\"s strong performance. This feedback is clear and actionable, as it directs the authors to a specific area for improvement that could enhance the robustness and interpretability of their results. By addressing this suggestion, the authors can better understand the factors contributing to the performance of epsilon sampling and provide a more comprehensive analysis. However, the comment could be more helpful if it included examples of how to conduct these ablation studies or suggested specific factors to consider. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate how well their proposed attack is against the mode connectivity based defense proposed in the ICLR paper. However, it does not provide explicit instructions or concrete steps on how to conduct this evaluation. The comment implies that the authors should compare their attack with the defense mechanism, but it lacks specific guidance on what aspects to focus on or how to perform the comparison. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment references a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" and suggests that the authors should evaluate their proposed attack against the mode connectivity based defense. However, it does not explicitly mention which part of the paper this evaluation should be conducted in, making it weakly grounded. The comment is specific in its suggestion to compare the attack with the defense mechanism, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed attack should be evaluated against the mode connectivity based defense proposed in the ICLR paper. The comment provides a reference to a specific publication, \"Bridging Mode Connectivity in Loss Landscapes and Adversarial Robustness,\" which supports the claim by indicating that the authors should consider this comparison. However, the comment does not provide detailed reasoning or examples of how this evaluation would be conducted or why it is necessary. While the reference to the ICLR paper is helpful, the lack of further elaboration on the specific aspects of the defense mechanism being evaluated makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by referencing a relevant publication and suggesting that the authors evaluate their proposed attack against the mode connectivity based defense. This feedback is clear and actionable, as it guides the authors to consider a specific comparison that could enhance the robustness of their work. However, the comment could be more helpful if it provided additional context or explanation on why this comparison is important or how it might impact the paper\"s conclusions. Despite this, the suggestion is valuable and offers a concrete direction for the authors to improve their draft, making it 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors did not include the codes during the review process, which makes the claims less transparent. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. The comment lacks guidance on whether the authors should include the codes or how they should present their claims to make them more transparent. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the authors\" choice of not including the codes during the review process, which affects the transparency of their claims. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the codes are mentioned. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of transparency, it lacks grounding as it does not provide clear guidance on where the codes are mentioned or how they should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors\" choice of not including the codes during the review process makes the claims less transparent. However, the comment does not provide any specific reasoning or examples to support this claim. Without detailed justification or references, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the transparency of the authors\" claims, specifically noting that the codes were not included during the review process. This feedback is 3 as it identifies a gap in the transparency of the claims, which is an important aspect of scientific communication. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending the inclusion of codes or explaining the reasoning behind their exclusion. Without actionable advice, the authors are left with a general observation that could be addressed in multiple ways. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should validate their proposed approach in Waymax in the future, as it provides more traffic scenarios compared to the current version which uses only 4 scenarios. While the comment implies that the authors should conduct additional validation, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on how to conduct the validation or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests validating the proposed approach in Waymax in the future, implying that the authors should consider additional traffic scenarios beyond the current 4 scenarios. However, it does not specify which part of the paper this validation should be included in, making it weakly grounded. The comment is specific in suggesting the need for validation and providing a rationale for it, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should validate their proposed approach in Waymax in the future, as it provides more traffic scenarios compared to the current version which uses only 4 scenarios. However, the comment does not provide any specific reasoning, examples, or references to support why this validation is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes the claim 2, as it provides a general suggestion without sufficient support or explanation. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment suggests that the authors should validate their proposed approach in Waymax in the future, as it provides more traffic scenarios compared to the current version which uses only 4 scenarios. This feedback is 3 as it identifies a potential area for improvement, encouraging the authors to consider expanding the scope of their validation. However, the comment lacks specific guidance on how to conduct this validation or what aspects of the approach should be focused on. While it provides a direction for improvement, it does not offer detailed instructions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment critiques the technical contribution of the paper, suggesting that the proposed method does not offer significant novelty compared to existing works like RTDNet. It highlights the use of additional features, such as 3D pose and action features obtained by Laban Movement Analysis (LMA), and notes that this might not provide substantial insights. However, the comment does not provide explicit guidance or suggestions on how the authors could enhance their contribution or address the perceived lack of novelty. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the technical contribution of the paper, suggesting that it is not very significant. It references previous works, such as RTDNet, and highlights the main difference between the proposed method and RTDNet, which lies in the visual features. The comment also mentions the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the comment does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the perceived lack of novelty and the use of additional features, but without explicit references to sections or figures, the authors may struggle to identify the exact parts needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the technical contribution of the paper is not very significant, suggesting that the proposed method does not offer substantial novelty compared to existing works like RTDNet. The reviewer supports this claim by referencing the use of a transformerbased TAPG method and the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA). However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as how the proposed method differs from RTDNet or why the additional features are not surprising. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the technical contribution of the paper, suggesting that it is not very significant compared to existing works like RTDNet. It highlights the use of a transformerbased TAPG method and the consideration of 3D pose and action features obtained by Laban Movement Analysis (LMA). The reviewer points out that while these features might seem relevant, their effectiveness is not surprising, as LMA has been proven effective in dance action recognition. This feedback provides a clear critique of the paper\"s novelty and suggests that the proposed method may not offer substantial insights or improvements over existing approaches. However, the comment could be more helpful if it offered specific suggestions on how the authors might enhance the technical contribution or differentiate their work from existing literature. Overall, the comment is 3 as it identifies a key area for improvement but lacks detailed guidance on how to address the critique."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. While the comment implies that the authors should perform these comparisons, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for the authors to follow. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"implementation of tree construction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that more experimental comparisons are needed to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. However, the comment does not provide any specific reasoning or examples to support why these comparisons are necessary or how they would impact the results. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the need for more experimental comparisons to evaluate the different design choices of merging nodes among adjacent layers in the tree construction. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the experimental evaluation of the design choices. However, the comment could be more helpful if it offered additional guidance on how to conduct these comparisons or what specific aspects should be considered. Despite this, the comment is 4 as it directs the authors to a critical area for improvement, making it a 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Table 2 in the paper is incomplete and mentions that several baselines from the ReBART paper outperform it. It suggests that the authors should report these baselines for completeness, even though their results are slightly weak. This feedback provides a clear and direct action for the authors to take, specifying which baselines are missing and why they should be included. The comment is specific and actionable, giving the authors a clear understanding of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the table, namely the baselines from the ReBART paper that outperform the current table. The comment provides a clear direction for improvement by suggesting that these baselines should be reported for completeness. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 2 in the paper is incomplete because it does not report several baselines that outperform it, as mentioned in the ReBART paper. The comment suggests that these baselines should be included for completeness. However, the comment lacks specific references or detailed reasoning to support the claim that these baselines are indeed outperforming the current table. Without explicit examples or detailed explanations, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 3, as it provides a general suggestion but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 2 in the paper, noting that it is incomplete and does not report several baselines that outperform it. The comment suggests that these baselines are reported in the ReBART paper and implies that the authors should include them for completeness, despite their results being slightly weak. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by addressing the missing baselines. However, the comment could be more helpful if it offered additional guidance on how to present or integrate these baselines effectively. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear suggestion for enhancement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the evaluations on real datasets could be more thorough, specifically questioning why only three scenes were chosen from the HSERGB dataset and asking about the performance on other sequences. While the comment implies that the authors should consider expanding their evaluation to include more scenes or sequences, it does not provide explicit guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct additional evaluations but are not given specific instructions on how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluations on real datasets and the specific dataset used, HSERGB, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the choice of three scenes and asks about the performance on other sequences, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the thoroughness of evaluations on real datasets, specifically asking why only three scenes were chosen from the HSERGB dataset and how the performance would be on other sequences. This is a request for clarification and does not contain an opinion, judgment, or suggestion that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a potential area for improvement in the evaluations conducted on real datasets. It questions the choice of three scenes from the HSERGB dataset and asks about the performance on other sequences. This feedback is 3 as it prompts the authors to consider a more comprehensive evaluation, which could enhance the robustness and generalizability of their results. However, the comment lacks specific suggestions or guidance on how to expand the evaluation or what additional sequences or scenes should be considered. While it points out a potential weakness, it does not provide detailed direction for improvement, making it 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises two concerns: the size of 44 being too small and the counterintuitive aspect of predicting binary codes that represent the rank of words. While the comment suggests that more bits could be used, it does not provide specific guidance on how to implement this change or what specific improvements it would bring. Similarly, the comment questions the interpretation of bitembeddings and the model\"s ability to predict ranks, but it does not offer actionable steps for the authors to address these issues. The feedback lacks explicit instructions and concrete details, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses two specific issues: the size of 44 being too small and the counterintuitive aspect of predicting binary codes that represent the rank of words. It provides a detailed explanation of the first issue, suggesting that more bits could be used, and questions the interpretation of bitembeddings. The second part of the comment raises a question about the model\"s ability to predict ranks and the lack of semantic relations for words with odd ranks. However, the comment does not specify which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues and questions, but without explicit references to sections, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises two concerns: the size of 44 being too small and the counterintuitive aspect of predicting binary codes that represent the rank of words. The first claim about the size being too small is 3, as it suggests that more bits could be used without significantly increasing computation time. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to fully understand the reasoning behind it. The second part of the comment questions the interpretation of bitembeddings and the model\"s ability to predict ranks, which is also 3 but lacks detailed justification or examples. Overall, the comment is 3 due to the lack of comprehensive evidence and examples supporting the claims.", "helpfulness_rationale": "The review comment raises two distinct issues: first, it questions the size of 44, suggesting that more bits could be used without significantly increasing computation time. This is a relevant point that could guide the authors to consider optimizing their model for better efficiency. Second, the comment points out a counterintuitive aspect of the model predicting binary codes that represent the rank of words, questioning how these bitembeddings should be interpreted and whether the model merely memorizes the data. This feedback is valuable as it prompts the authors to reconsider the model\"s predictions and the interpretation of the results. However, the comment could be more helpful if it provided specific suggestions or examples on how to address these issues. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the practical use of the method, specifically the reliance on human annotation for providing semantically meaningful information, which can be subjective. It notes that the authors mention this limitation in the appendix but do not offer any solution for mitigation. While the comment identifies a gap in the discussion, it does not provide explicit guidance on how the authors might address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should discuss or propose solutions to mitigate the reliance on human annotation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the practical use of the method, mentioning the reliance on human annotation for providing semantically meaningful information. It notes that the authors mention this limitation in the appendix but do not provide any solution for mitigation. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of limitations or the appendix. The comment is specific in identifying the issue of subjectivity in human annotation and the lack of mitigation strategies. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the proposed solution for providing semantically meaningful information requires human annotation, which can be subjective. The reviewer notes that the authors mention this limitation in the appendix but do not offer any solution for mitigation. While the comment identifies a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The absence of concrete suggestions or references makes it 3, as the authors would need to infer the need for mitigation strategies themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the practical use of the method, specifically the reliance on human annotation for providing semantically meaningful information, which can be subjective. It notes that the authors mention this limitation in the appendix but do not offer any solution for mitigation. This feedback is 3 as it highlights a critical weakness in the method\"s practical application and prompts the authors to consider potential solutions. However, the comment could be more helpful if it provided suggestions or examples of how to mitigate the reliance on human annotation. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point provides explicit instructions for the authors to pretrain a CausalLM using a specific dataset and to compare its performance against ObscuraCoder. This guidance is clear and concrete, as it specifies exactly what needs to be done and how to implement it. The authors know precisely what actions to take to address the feedback, making this comment 5.", "grounding_specificity_rationale": "The comment provides specific instructions for the authors to pretrain a CausalLM using a specific dataset and to compare its performance against ObscuraCoder. However, it does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in detailing what needs to be done, but without explicit grounding, the authors may struggle to identify the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two separate suggestions: pretraining a CausalLM and comparing its performance against ObscuraCoder. Neither of these suggestions is a claim or opinion but rather a request for specific actions or comparisons. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors pretrain a CausalLM using a dataset that includes other datasets used by ObscuraCoder, except for the obfuscated ObscuraX. It further recommends comparing the performance of this model against ObscuraCoder to attribute any improvements to the deobfuscation objective. This feedback is clear and provides a concrete direction for the authors to enhance their work, making it 5. The comment offers a clear path for improvement and is detailed enough to guide the authors in making progress."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to add the geometric loss to the reconstruction loss, rather than having it as a separate entity. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to improve their draft. The comment is specific and concrete, leaving no ambiguity about the required changes. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"loss equation shown in L264L266,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the geometric loss should be added to the reconstruction loss rather than being separate. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the structure of the loss equation in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is a straightforward statement about the composition of the loss equation, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a minor issue with the structure of the loss equation in the paper. It specifies that the geometric loss should be added to the reconstruction loss rather than being separate. This feedback is clear and actionable, providing the authors with a specific correction to make. By addressing this issue, the authors can improve the clarity and accuracy of their work. However, the comment could be more helpful if it included additional context or explanation on why this correction is important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that while Multimodal Learning (MLM) is important and used in many applications, the method should also be employed in autoregressive language models, which are more prevalent in realworld applications. However, the comment does not provide explicit guidance or suggestions on how the authors should incorporate this recommendation into their work. It lacks concrete details on how to integrate the method into autoregressive language models or what specific aspects should be addressed. As a result, the authors are left without a clear understanding of what actions to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that while Multimodal Learning (MLM) is important and used in many applications, the method should also be employed in autoregressive language models, which are more prevalent in realworld applications. However, the comment does not specify which part of the paper this suggestion pertains to, such as a specific section, table, or figure. This lack of grounding makes it difficult for the authors to pinpoint where the suggestion should be addressed. Additionally, the comment is specific in its suggestion to employ the method in autoregressive language models, but without clear guidance on how to implement this suggestion, it remains somewhat vague. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that while Multimodal Learning (MLM) is important and used in many applications, it should also be employed in autoregressive language models, which are more prevalent in realworld applications. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion or how to address it. The absence of detailed reasoning or evidence makes the claim 2, as it provides a general observation without sufficient justification or context.", "helpfulness_rationale": "The review comment suggests that while Multimodal Learning (MLM) is important and used in many applications, it should also be employed in autoregressive language models, which are more prevalent in realworld applications. This feedback highlights a potential area for improvement by suggesting that the authors consider expanding the scope of their work to include autoregressive language models. However, the comment lacks specific guidance or suggestions on how the authors might integrate this recommendation into their draft or what aspects of the work should be addressed. While it points out a relevant area for consideration, the feedback could be more helpful with additional details or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the difficulty in optimizing the GAN and using adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the issue of vanishing gradient and model collapsing is not adequately addressed in the method section. While the comment identifies a gap in the explanation, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations or address these challenges in their method section. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the difficulty in optimizing the GAN and using adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out the lack of discussion on avoiding the issue of vanishing gradient and model collapsing in the method section. However, the comment does not specify which part of the paper discusses these issues, making it weakly grounded. The authors can infer that it relates to the method section, but this inference is not direct. The comment is specific in identifying the issues with the proposed method, such as the difficulty in optimization and the lack of discussion on vanishing gradient and model collapsing. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the proposed method is better than GAN due to the difficulty in optimization and the use of adversarial gradient updating. It also points out the lack of discussion on avoiding the issue of vanishing gradient and model collapsing in the method section. While the comment raises valid concerns, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to further explore and address these issues to fully understand the critique. Therefore, the comment is 3, as it provides a basis for the claim but requires additional evidence or explanation to be fully substantiated.", "helpfulness_rationale": "The review comment raises a valid concern about the difficulty in optimizing the GAN and using adversarial gradient updating, questioning why the proposed idea is better than GAN. It also points out that the issue of vanishing gradient and model collapsing is not adequately addressed in the method section. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address these issues or improve their method. The feedback is 3 as it highlights areas for improvement, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the design of the ablation study, specifically asking why the ablations are based on BART and BART+Longformer instead of the original model, GraphSum. While the comment implies that the authors should consider using the original model for the ablation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should use the original model for the ablation. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the design of the ablation study, asking why the ablations are based on BART and BART+Longformer instead of the original model, GraphSum. This provides clear guidance on what aspect of the ablation study needs further clarification or justification. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the design of the ablation study, specifically asking why the ablations are based on BART and BART+Longformer instead of the original model, GraphSum. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the design of the ablation study, asking why the ablations are based on BART and BART+Longformer instead of the original model, GraphSum. This question prompts the authors to clarify their methodology, which could lead to a more comprehensive understanding of the ablation process. However, the comment does not provide any suggestions or guidance on how to address this question or improve the clarity of the ablation study. While it identifies an area for improvement, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the removal of the previous report of SciBERT has made the current paper less comprehensive, as it does not mention the issue of the analyses of the models being too cursory and unsupported. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the paper. The comment implies that the authors should include a discussion of the analyses of the models, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of the removal of the previous report of SciBERT and its impact on the comprehensiveness of the current paper. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment does specify the problem, which is the lack of detailed analysis of the models\" outcomes, but it does not provide specific guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the removal of the previous report of SciBERT has made the current paper less comprehensive, as it does not mention the issue of the analyses of the models being too cursory and unsupported. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence weakens the verifiability of the claim, leading to a score of 2.", "helpfulness_rationale": "The review comment points out a potential issue with the removal of the previous report of SciBERT, which has made the current paper less comprehensive. It highlights that the analyses of the models\" outcomes were too cursory and unsupported, but notes that this is not fair to write as a weakness because the current paper does not mention this. While the comment identifies a potential weakness, it lacks specificity and does not provide actionable feedback on how the authors might address this issue. The authors are left with a general understanding of the problem but without clear guidance on how to improve their draft. Therefore, the comment is 3, as it provides some insight but lacks depth and actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a lack of confidence in the claim that Figure 4(b) demonstrates the proposed method\"s faster training. It questions the validity of this claim, especially considering that all networks are trained for the same number of epochs. The reviewer suggests that the paper would benefit from a longer discussion of related work. While the comment implies that the authors should expand their discussion on related work, it does not provide specific guidance on which aspects of related work to include or how to integrate them into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should expand their discussion on related work but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4(b),\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim that the proposed method results in faster training, suggesting that the claim is not supported by the data presented in Figure 4(b). Additionally, the comment implies that the paper would benefit from a longer discussion of related work, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that Figure 4(b) indicates the proposed method results in faster training, suggesting that the claim is not supported by the data presented. The reviewer points out that all networks are trained for the same number of epochs, which makes the claim less credible. The comment also suggests that the paper would benefit from a longer discussion of related work. While the comment raises a valid concern about the claim, it lacks specific examples or detailed reasoning to fully substantiate the critique. The suggestion to discuss related work is a reasonable addition but does not provide enough detail to fully verify the claim. Therefore, the comment is 3, as it provides some justification but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment raises a valid concern about the claim made in Figure 4(b), questioning whether the proposed method indeed results in faster training. It points out that all networks are trained for the same number of epochs, which makes the claim less credible. The reviewer suggests that the paper would benefit from a longer discussion of related work, which is a constructive suggestion for expanding the context and depth of the paper. However, the comment could be more helpful if it provided specific examples or references to related work that could be integrated into the discussion. Overall, the feedback is 3 as it identifies a potential weakness and offers a direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper is not as clear as the introduction, specifically noting the lack of background information about cognitive models. It suggests that the authors may need to refine the writing. While the comment identifies an area for improvement, it does not provide specific guidance on how to enhance the clarity or what aspects of the writing need to be improved. The action is implicit and somewhat vague, as the authors are left to infer that they need to improve the writing but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper is not as clear as the introduction, specifically noting the lack of background information about cognitive models. However, it does not specify which part of the paper lacks this information, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is specific in identifying the issue of clarity and the need for background information, but it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper is not as clear as the introduction, specifically noting the lack of background information about cognitive models. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the paper, specifically noting that the introduction does not provide sufficient background information about cognitive models. This feedback is 3 as it highlights an area that needs improvement, prompting the authors to consider enhancing the clarity and comprehensiveness of their writing. However, the comment does not offer specific suggestions or guidance on how to address this issue, such as recommending additional background information or examples. While it points out a problem, it lacks depth and actionable advice, making it 3 but not fully comprehensive."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a discrepancy in the performance of DFA compared to backprop on a standard NLP task and suggests that this should be more prominently emphasized in the paper. However, it does not provide specific guidance on how to address this issue or what aspects of the paper should be highlighted to clarify this point. The action is implicit and somewhat vague, as the authors know they need to address the issue but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"NLP task\" and the \"DFA performance,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a particular issue with the performance of DFA compared to backprop on a standard NLP task and suggests that this should be more prominently emphasized in the paper. The comment provides a clear indication of what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that DFA performance lags behind backprop performance on a standard NLP task, which is not sufficiently emphasized in the paper. The reviewer suggests that this should be more prominently highlighted, as it affects the reader\"s understanding of DFA\"s performance relative to backprop. However, the comment lacks specific examples or references to support the claim about DFA performance. Without detailed evidence or comparisons, the claim remains 3, as it provides a general observation without concrete support. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s presentation regarding the performance of DFA on a standard NLP task. It points out that the abstract gives readers the impression that DFA performs at nearbackprop levels, which is not accurate. This feedback is valuable as it highlights a potential misrepresentation of the paper\"s findings, prompting the authors to clarify and correct this aspect. However, the comment could be more helpful if it provided suggestions on how to address this issue or examples of how to present the information more accurately. Overall, the comment is 3 as it directs the authors\" attention to a critical area that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the baseline should include dimensional reduction methods in optimal transport estimation, specifically mentioning SRW and FROT. This provides a clear and direct action for the authors to take, as they know exactly which baselines to include. The comment is specific and concrete, giving the authors a clear understanding of what needs to be added to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It specifically mentions SRW and FROT as examples that should be included as baselines. However, the comment does not explicitly mention which part of the paper discusses these methods, making it weakly grounded. The authors can infer that it relates to the section discussing baseline methods or dimensional reduction techniques, but this inference is not as direct as it could be. The comment is specific in suggesting the inclusion of certain baselines, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It suggests that SRW and FROT should be included as baselines. However, the comment does not provide specific reasoning or evidence to support why these methods should be included or how they would improve the baseline. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, noting that the baseline is lacking, particularly for dimensional reduction methods in optimal transport estimation. It suggests that SRW and FROT should be included as baselines. This feedback is clear and actionable, providing the authors with a concrete direction to enhance their work by expanding the baseline section. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate these baselines or why they are particularly relevant. Overall, the comment is 4 as it directs the authors toward a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not provide any explicit guidance or suggestions on how the authors should address this omission. The comment lacks specificity and actionable details, leaving the authors uncertain about what steps to take to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific aspect of the paper, namely the discussion of the advantages and disadvantages of transductive learning. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in identifying the need for a discussion on this topic, but without explicit references to sections or figures, the authors may struggle to determine where to make the necessary changes. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the advantages and disadvantages of transductive learning have not been discussed in the paper. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting that the advantages and disadvantages of transductive learning have not been discussed. This is a clear and actionable piece of feedback that can help the authors improve their draft by encouraging them to include a discussion on this topic. However, the comment could be more helpful if it provided suggestions on how to present this discussion or what aspects of the advantages and disadvantages should be highlighted. Despite this, the comment is 4 as it directs the authors to a critical area that needs attention, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the invariance of the contractivity should be stated formally. While the comment implies that the authors should provide a formal statement, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 3. The authors know they need to formalize the statement, but the comment does not provide specific guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the invariance of the contractivity should be stated formally. However, it does not specify which part of the paper this issue pertains to, such as a particular section, table, or figure. Without explicit references, the authors may find it challenging to identify the exact part of the paper that needs attention. While the suggestion is specific in terms of what needs to be addressed, the lack of grounding makes it difficult for the authors to pinpoint the exact location in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the invariance of the contractivity should be stated formally. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is important or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the invariance of the contractivity should be stated formally. While this is a reasonable suggestion, it lacks specificity and does not provide detailed guidance on how to achieve this or why it is important. The comment identifies a potential area for improvement but does not offer actionable advice or examples to help the authors address the issue. As a result, the feedback is 3, as it points out a potential enhancement but does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses disagreement with the paper\"s claim regarding the significance of uncertainty saliency maps and their application/evaluation. It suggests that the authors should provide a more detailed explanation of the significance of these maps. However, the comment does not offer specific guidance on how to address this issue or what additional information should be included. The action is implicit and vague, as the authors are left to infer that they need to provide more details on the significance of uncertainty saliency maps. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the potential contribution of uncertainty saliency maps but questions their significance without application or evaluation. It also disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment does not specify which part of the paper discusses uncertainty saliency maps or where the application or evaluation is mentioned, making it weakly grounded. The comment is specific in its critique of the claim regarding the trustworthiness of uncertainty/confidence over explanations. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the potential contribution of uncertainty saliency maps, questioning their significance without application or evaluation. The reviewer disagrees with the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the explanation is more trustworthy. This makes the claim 3, as it provides a basis for the critique but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the potential contribution of uncertainty saliency maps, questioning their significance without application or evaluation. It also challenges the claim that uncertainty/confidence generated from the same mechanism is more trustworthy than the explanation itself. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve the significance of their contribution. The feedback is 3 as it prompts the authors to consider the importance of application and evaluation for their work, but it could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the importance of using a diffusion model in the context of style transfer and what it can provide that other methods cannot. However, it does not explicitly instruct the authors to address this issue or provide guidance on how to incorporate the diffusion model into their work. The action is implicit, as the authors can infer that they need to discuss the importance of the diffusion model, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the importance of using a diffusion model in the context of style transfer and what it can provide that other methods cannot. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment is specific in its inquiry about the potential benefits of using a diffusion model, but it lacks grounding as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the importance of using a diffusion model in the context of style transfer and what it can provide that other methods cannot. However, it does not present a claim or opinion that requires verification. It is a request for clarification or discussion, not an assertion that needs evidence or justification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a relevant question about the importance of using a diffusion model in the context of style transfer and what it can provide that other methods cannot. This question prompts the authors to consider the potential benefits of incorporating a diffusion model into their work, which could be a valuable area for exploration. However, the comment lacks specific guidance or suggestions on how the authors might address this question or integrate the diffusion model into their methodology. While it identifies an area for improvement, it does not provide detailed feedback that would help the authors make actionable changes. Therefore, the comment is 3, as it highlights a potential area for enhancement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a specific issue: the lack of study on the impact of Age and FaceID features in the ablation. While it identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include an ablation study focusing on these features, but it does not specify how to conduct this study or what aspects to consider. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue regarding the lack of study on the impact of Age and FaceID features in the ablation. However, it does not specify which part of the paper this issue pertains to, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the absence of an ablation study for these features. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the impact of Age and FaceID features is not studied in the ablation. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern: the lack of study on the impact of Age and FaceID features in the ablation. This is a clear and actionable piece of feedback that highlights a potential weakness in the paper\"s analysis. By pointing out this omission, the comment provides the authors with a concrete direction for improvement, encouraging them to conduct a thorough analysis of these features. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what aspects to focus on. Overall, the feedback is 4 as it directs the authors\" attention to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests moving the detailed discussion from the Appendix to the main manuscript, indicating that the authors should include the discussion in the main text. This provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done. However, the comment does not provide specific guidance on how to integrate the discussion into the main text or what specific aspects should be included. While the action is explicit, the lack of detailed instructions on execution makes it 3. Therefore, the comment is rated as 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Fig. 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the values in Table 2 and Fig. 5 and suggesting moving the detailed discussion to the main manuscript. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the inclusion of Table 2 and Fig. 5 in the manuscript, suggesting that the detailed discussion should be moved to the main text. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the discussion should be moved or why the table and figure are not mentioned. This lack of justification makes the claim 1, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the inclusion of Table 2 and Fig. 5 in the manuscript, questioning their relevance and suggesting that the detailed discussion should be moved to the main text. This feedback is clear and actionable, as it provides a direct suggestion for improving the organization and clarity of the manuscript. By addressing this issue, the authors can enhance the readability and coherence of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively present the data in Table 2 and Fig. 5 or why the discussion is necessary. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include more LLMrelated results in their experiments, specifically mentioning the need for results from models like Llama370B and Mistral7B. This feedback provides a clear and concrete action for the authors to take, as it specifies which additional experiments should be conducted to enhance the paper\"s results. The comment is 5 because it offers a direct and specific direction for improvement, ensuring the authors know exactly what needs to be done to address the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction where the author stated the main purpose of the Lorta method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the authors should include in their experiments, namely more LLMrelated results such as Llama370B and Mistral7B. This provides clear guidance on what additional experiments are needed to enhance the paper\"s results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper should include more LLMrelated results beyond the current experiments on llama27B and mtbench. The reviewer supports this claim by stating that the introduction mentions the main purpose of the Lorta method, which is to solve the problem of efficient finetuning of LLM. However, the comment lacks specific examples or references to other LLM models that should be included, such as Llama370B and Mistral7B. This makes the claim 3, as it provides a logical basis but requires more detailed justification or examples to fully substantiate the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific area for improvement in the paper, namely the inclusion of more LLMrelated results in the experiments. It suggests that the authors should include results from models like Llama370B and Mistral7B, which would provide a more comprehensive evaluation of the Lorta method\"s effectiveness. This feedback is clear and actionable, offering a concrete direction for the authors to enhance their experimental results and demonstrate the method\"s applicability to a broader range of models. However, the comment could be more helpful if it provided additional context or rationale for why these specific models are important or how they would impact the paper\"s conclusions. Overall, the comment is rated as 4, consistent with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) and suggests that it may not generalize well to other types of large language models (LLMs) beyond LLaMA, GPT, and Claude. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or explore the generalizability of DFSDT. The comment implies that the authors should consider testing DFSDT on a broader range of LLMs, but it lacks concrete steps or specific actions to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) and its performance compared to ReAct prompting. It also mentions the relationship of DFSDT to selfconsistency + CoT and Treeofthoughts, and raises concerns about its generalizability to other types of LLMs beyond LLaMA, GPT, and Claude. However, the comment does not specify which part of the paper discusses DFSDT or where these concerns are raised, making it weakly grounded. The comment is specific in detailing the concerns about the generalizability of DFSDT, but without clear grounding, it is challenging for the authors to pinpoint the exact sections needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) outperforms ReAct prompting but is closely related to selfconsistency + CoT and Treeofthoughts. The reviewer expresses uncertainty about the generalizability of DFSDT to other types of LLMs beyond LLaMA, GPT, and Claude. However, the comment lacks specific examples, references, or detailed reasoning to substantiate the claim about the relationship between DFSDT and the mentioned techniques. This makes the claim 3, as it provides a general observation but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed \"Depth First Searchbased Decision Tree\" (DFSDT) by noting that it appears to outperform ReAct prompting but is closely related to selfconsistency + CoT and Treeofthoughts. This observation raises concerns about the generalizability of DFSDT to other types of large language models (LLMs) beyond LLaMA, GPT, and Claude. However, the comment does not provide specific suggestions or guidance on how the authors might address this concern or explore the generalizability of DFSDT. While it highlights an important area for consideration, the feedback lacks actionable advice, making it 3. The authors would benefit from knowing how to further investigate or address the generalizability issue, but the comment does not fully support them in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights the importance of proper acknowledgment of contributions and suggests that it is inappropriate to propose an identical method while claiming to be the first. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should ensure their work is original and properly acknowledged, but it lacks concrete steps or examples on how to implement this. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of proper acknowledgment of contributions and the inappropriate claim of being the first to propose an identical method. However, it does not specify which part of the paper this issue pertains to, such as specific sections or examples where this problem might occur. The authors can infer that it relates to the introduction or discussion sections, but this inference is not direct. The comment is specific in its critique but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the appropriateness of claiming originality when proposing an identical method. It suggests that acknowledging contributions is important and that such claims can be inappropriate. However, the comment does not provide specific examples or references to support the claim that proposing an identical method while claiming originality is inappropriate. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment raises a valid concern about the appropriateness of claiming originality when proposing an identical method, emphasizing the importance of proper acknowledgment of contributions. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or ensure the originality of their work. It highlights a potential flaw in the paper but does not provide actionable steps or examples for improvement. As a result, while it identifies a critical issue, it does not offer comprehensive feedback that would be 5 to the authors. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance comparison between XDC and MMV, specifically asking for an explanation of why MMV outperforms XDC. It suggests that MMV might be better due to its use of a better backbone architecture. While the comment implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain the performance difference and consider the backbone architecture as a potential factor. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"XDC\" and \"MMV,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning the performance comparison between XDC and MMV, particularly focusing on why MMV outperforms XDC. The comment further asks if MMV is better than XDC due to its use of a better backbone architecture. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the performance comparison between XDC and MMV, specifically asking for an explanation of why MMV outperforms XDC. It suggests that MMV might be better due to its use of a better backbone architecture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance comparison between XDC and MMV, specifically asking for an explanation of why MMV outperforms XDC. It suggests that MMV might be better due to its use of a better backbone architecture. While the comment identifies a potential area for clarification, it lacks specific guidance or suggestions on how the authors might address this issue or improve their analysis. The feedback is 3 as it prompts the authors to consider an important aspect of their results, but it could be more actionable with additional details or suggestions. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the writing is too verbose and hard to follow, suggesting that the paper should focus on a main idea or two and show analyses of why those ideas work, rather than presenting a complex, wellengineered system with many functions and considerations. While the comment provides a clear direction for improvement, it does not specify which main ideas should be emphasized or how to effectively present the analyses. The action is explicit but somewhat vague in terms of execution, making it 3.", "grounding_specificity_rationale": "The comment critiques the writing as being too verbose and hard to follow, suggesting that the paper should focus on a main idea or two and show analyses of why those ideas work. However, it does not specify which parts of the paper are verbose or where the main ideas are located, making it difficult for the authors to pinpoint the exact areas needing revision. The comment is 1 as it lacks specific references to sections or elements of the paper, and it is also not specific in detailing what aspects of the writing are problematic. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the writing is too verbose and hard to follow, suggesting that the paper should focus on a main idea or two and show analyses of why those ideas work, rather than presenting a complex, wellengineered system. While the comment identifies a potential issue with the writing style, it lacks specific examples or detailed reasoning to support the claim. The suggestion to focus on main ideas or analyses is 3 but could be more robust with additional justification or examples. Therefore, the comment is categorized as 3, as it provides some direction but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the writing style, noting that it is too verbose and hard to follow. It suggests that the paper should focus on a main idea or two and provide analyses of why those ideas work, rather than presenting a complex, wellengineered system with many functions and considerations. This feedback is clear and actionable, offering a specific direction for improvement by emphasizing the need for a more focused and concise presentation. However, the comment could be more helpful if it provided examples of how to achieve this focus or suggested specific areas for simplification. Overall, the comment is 4 as it guides the authors toward a more effective way of presenting their work, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks the provision of code and supplementary documentation, which could enhance clarity and reproducibility. It suggests that providing these resources would be beneficial for the reader to understand and replicate the methodology. The action is clear and direct, as it specifies what the authors need to do to improve their draft. The comment also provides concrete guidance on how to implement the suggested action, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper lacks the provision of code and supplementary documentation, which could enhance clarity and reproducibility. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where these resources are missing. While the authors might infer that this relates to the methodology or results sections, the comment lacks full grounding. It is specific in suggesting the need for code and supplementary documentation but does not provide detailed guidance on where these resources should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks the provision of code and supplementary documentation, which could enhance clarity and reproducibility. The comment suggests that providing these resources would be beneficial for the reader to understand and replicate the methodology. However, the comment does not provide specific examples or references to support the claim that the absence of these resources is a significant issue. While the suggestion is logical, the lack of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of code and supplementary documentation. This is a critical issue that could enhance the clarity and reproducibility of the research, allowing readers to better understand and replicate the methodology. The comment provides clear and actionable feedback by suggesting that the authors provide these resources, which would be beneficial for the reader. However, the comment could be more helpful if it offered specific guidance on where to include these resources or how to format them effectively. Overall, the feedback is 4 as it directs the authors toward a crucial improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should discuss ensembles and uncertainty estimation in the context of offline RL, specifically mentioning the use of random ensembles (REM) and their performance compared to DQN/naive ensembling. It also implies that the authors should empirically compare these methods to incorporate value uncertainty in offline RL. While the comment provides a clear direction for the authors to include additional discussion and comparisons, it lacks specific guidance on how to structure this discussion or what specific comparisons should be made. The action is explicit but somewhat vague, as it does not provide detailed instructions on how to implement the suggested changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ensembles and uncertainty estimation\" and \"offline RL,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need to discuss these topics and empirically compare them, particularly in the context of random ensembles (REM) and their performance compared to DQN/naive ensembling. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that ensembles have been studied in the context of offline RL on discrete Atari games and that random ensembles (REM) outperform DQN/naive ensembling. The comment suggests that this should be discussed and empirically compared in the paper. However, the claim lacks specific references or detailed reasoning to fully substantiate the assertion about the performance of REM compared to DQN. While the comment provides a logical basis for the claim, it does not offer sufficient evidence or examples to fully verify the claim. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper should discuss ensembles and uncertainty estimation in the context of offline RL. It references prior work on this topic, specifically mentioning the use of random ensembles (REM) and their superior performance compared to DQN/naive ensembling. The comment also provides a clear suggestion to empirically compare these methods to incorporate value uncertainty in offline RL. This feedback is actionable and provides the authors with a concrete direction for enhancing their draft by expanding on related work and including empirical comparisons. However, the comment could be more helpful if it offered specific guidance on how to structure this discussion or what particular comparisons should be made. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their paper."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the two methods have been cleverly combined, implying a lack of novelty. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to enhance the novelty of their work. The feedback lacks concrete suggestions or actionable steps, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the second paragraph of the introduction and the proposed methodology, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the impression that the two methods have been cleverly combined together, lacking novelty. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the two methods have been cleverly combined together, suggesting a lack of novelty. However, the comment does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the novelty of the work, suggesting that the combination of two methods may not be as innovative as implied by the author\"s statements. However, the comment lacks specificity and does not provide detailed feedback or suggestions on how the authors might enhance the novelty of their work. Without actionable guidance or examples, the authors are left without a clear path to address the concern. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the scalability of the proposed approach, specifically questioning whether each target language requires a different model to be finetuned. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern, such as suggesting alternative approaches or providing examples of how to improve scalability. Without actionable advice or specific suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the scalability of the proposed approach, specifically questioning whether each target language requires a different model to be finetuned. However, it does not specify which part of the paper this concern pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue of scalability, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the scalability of the proposed approach, specifically questioning whether each target language requires a different model to be finetuned. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the scalability of the proposed approach, specifically questioning whether each target language requires a different model to be finetuned. While it identifies a potential issue with the approach, it lacks specific suggestions or guidance on how the authors might address this concern or improve the scalability of their method. The comment highlights an important aspect of the methodology but does not provide actionable feedback or detailed insights to help the authors enhance their draft. Therefore, the comment is 3, as it points out a potential weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that more details about \"valid words\" in Eq.20 would be helpful for readers unfamiliar with bAbI or question answering. It also clarifies that \"valid words\" refer to possible answer words for the given story and question. While the comment implies that additional explanation or context is needed, it does not specify how to provide this information or where in the paper this clarification should be made. The action is implicit and somewhat vague, as the authors know they need to add more details but are not given explicit guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq.20,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that more details about \"valid words\" would be helpful for readers unfamiliar with bAbI or question answering. The comment further clarifies that \"valid words\" refer to possible answer words for the given story and question. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that more details about \"valid words\" in Eq.20 would be beneficial for readers unfamiliar with bAbI or question answering. The comment clarifies that \"valid words\" refer to possible answer words for the given story and question. However, it does not provide specific examples or references to support the claim that more details are needed. The lack of detailed justification or examples makes the claim 3, as the authors would need to infer the necessity of additional explanation themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area in the paper, Eq.20, where additional details would be beneficial for readers unfamiliar with bAbI or question answering. It clarifies that \"valid words\" refer to possible answer words for the given story and question, which is a helpful clarification. However, the comment could be more helpful if it provided suggestions on how to explain these concepts or examples of how they are used in the context of the paper. While it points out a potential area for improvement, it lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point identifies that the concept of \"interestedregionbased adversarial attacking\" is not novel and has been proposed earlier by Yao et al. in their 2019 paper. However, it does not provide any explicit or implicit actions for the authors to take in response to this feedback. There is no guidance on whether the authors should address this issue, how it might impact their work, or what steps they could take to differentiate their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely that the concept of \"interestedregionbased adversarial attacking\" is not novel and has been proposed earlier by Yao et al. in their 2019 paper. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the claim that the idea is not novel, but it lacks grounding as it does not direct the authors to a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the concept of \"interestedregionbased adversarial attacking\" is not novel, as it has been proposed earlier by Yao et al. in their 2019 paper. This claim is supported by providing a specific reference to Yao et al., which adds credibility to the assertion. However, the comment could be strengthened by explaining how the current work differs from Yao et al.\"s approach or by providing more context on the significance of the concept. Overall, the claim is 4 due to the reference provided, but it could be more robust with additional explanation or context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the concept of \"interestedregionbased adversarial attacking\" is not novel and has been proposed earlier by Yao et al. in their 2019 paper. This feedback is valuable as it highlights a potential redundancy in the paper\"s contribution. However, the comment lacks actionable guidance or suggestions on how the authors might address this issue or differentiate their work from the existing literature. Without specific advice on how to enhance the novelty or originality of their contribution, the authors are left without a clear path forward. Therefore, the comment is 3, as it points out a potential weakness but does not provide sufficient guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the proposed methods are composed of wellknown components, implying that the contribution of the paper may not be significant. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the significance of their contribution or suggest improvements to their methods. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the proposed methods are composed of wellknown components, implying that the contribution of the paper may not be significant. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what specific components are being referred to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed methods are composed of wellknown components, suggesting that the contribution of the paper may not be significant. However, the comment lacks specific examples or references to these components, making it difficult for the authors to understand the basis of the claim or how to address it. Without detailed justification or evidence, the claim is considered 2, as it provides some reasoning but lacks the necessary details to fully substantiate the argument.", "helpfulness_rationale": "The review comment suggests that the proposed methods are composed of wellknown components, implying that the contribution of the paper may not be significant. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might enhance the significance of their contribution. Without detailed guidance or examples, the authors are left without a clear understanding of how to address the concern or improve their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the dataset, specifically the use of multiturn data and publicly available history conversations that may still provide assistance in answering the final question, which could lead to data leakage. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might mitigate this risk or suggest improvements to the dataset. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the test set, mentioning that it includes multiturn data and publicly available history conversations that may still provide assistance in answering the final question, potentially leading to data leakage. However, it does not specify which part of the paper discusses the test set or the dataset\"s composition, making it weakly grounded. The comment is specific in detailing the potential risk of data leakage, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the test set includes multiturn data and publicly available history conversations, which may still provide assistance in answering the final question, potentially leading to data leakage. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the extent of the risk or how to address it. The lack of detailed justification or evidence makes the claim 2, as it requires more information to be fully substantiated. Therefore, the comment is rated as 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the dataset, specifically the inclusion of multiturn data and publicly available history conversations that may still provide assistance in answering the final question. This could lead to a risk of data leakage, which is a significant concern in machine learning and data privacy contexts. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or mitigate the risk of data leakage. While it highlights a critical weakness, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it points out an important concern but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should compare their results with VSD + TTUR, as TTUR improves the performance of VSD according to the DMD2 paper. This implies that the authors should include a comparison in their analysis to strengthen their results. However, the comment does not explicitly instruct the authors to make this comparison or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison and may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a comparison with VSD + TTUR, as TTUR improves the performance of VSD according to the DMD2 paper. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare their results with VSD + TTUR, as TTUR improves the performance of VSD according to the DMD2 paper. This claim is 3 as it references the DMD2 paper and the improvement of VSD with TTUR. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further explore the DMD2 paper and understand the specifics of TTUR to fully address the suggestion.", "helpfulness_rationale": "The review comment identifies a specific aspect of the paper that could be improved by suggesting a comparison with VSD + TTUR, as TTUR improves the performance of VSD according to the DMD2 paper. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s results and analysis. By including this comparison, the authors can strengthen their findings and make the paper more convincing. However, the comment could be more helpful if it provided additional guidance on how to conduct this comparison or what specific aspects of the comparison should be emphasized. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the paper\"s analysis is shallow and lacks clear takeaways or conclusions, recommending that it be moved to the appendix if it doesn\"t enhance the paper\"s value or clarity. It also advises integrating essential details, such as dataset splitting justifications, into the main text. This feedback provides clear and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"shallow analysis\" and the \"appendix,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be addressed, such as the lack of clear takeaways or conclusions and the suggestion to integrate essential details from the appendix into the main text. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper provides a shallow linguistic dataset analysis without clear takeaways or conclusions. It suggests that if the analysis isn\"t enhancing the paper\"s value or clarity, it might be better suited for the appendix. The comment also advises integrating essential details, such as dataset splitting justifications, into the main text. While the comment identifies a potential issue with the analysis, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to move the analysis to the appendix or integrate details into the main text provides some guidance, but more detailed evidence or examples would strengthen the claim. Therefore, the comment is 3, as it provides a basis for the claim but lacks comprehensive support.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s analysis, noting that it is shallow and lacks clear takeaways or conclusions. It suggests that if the analysis does not enhance the paper\"s value or clarity, it might be better suited for the appendix. Additionally, the comment advises integrating essential details, such as dataset splitting justifications, into the main text. This feedback is clear and actionable, providing the authors with specific guidance on how to improve the clarity and impact of their analysis. By addressing these points, the authors can enhance the quality and comprehensiveness of their paper. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the metric of Table 1 is not clearly stated and that the experimental details, such as the backbone choice, learning rate, and optimization schedules, are not provided. This feedback is clear and direct, giving the authors a specific action to take: clarify the metrics in Table 1 and provide the necessary experimental details. The comment is explicit and concrete, providing clear guidance on how to improve the draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the lack of clear statement of the metric in Table 1 and the absence of experimental details such as backbone choice, learning rate, and optimization schedules. This provides clear guidance on what information is missing and needs to be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are not clearly stated and that certain details are missing. However, it does not provide any supporting evidence or reasoning to justify why these details are important or how they impact the results. The lack of specific examples or references makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that the metric of Table 1 is not clearly stated and that important details such as the backbone choice, learning rate, and optimization schedules are missing. This feedback is clear and actionable, as it directs the authors to provide additional information that would enhance the clarity and comprehensiveness of their experimental results. By addressing these points, the authors can improve the transparency and reproducibility of their work, making the comment 5. However, the comment could be more helpful if it suggested specific ways to present the missing information or how to improve the clarity of the results. Overall, the feedback is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a potential oversight in the paper regarding the assumption of POMDPs, specifically the lack of discussion on how previous decisions affect the observable data. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific changes to make. The action is implicit and somewhat vague, as the authors need to infer that they should discuss the impact of previous decisions on observable data. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the assumption of POMDPs and the lack of discussion on how previous decisions affect the observable data. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue, which is the lack of discussion on how previous decisions influence the observable data. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not leverage the advantage of POMDPs, specifically the assumption that the decisionmaker does not directly observe the target variable Y. The reviewer provides an example of how this assumption could be leveraged by discussing the impact of previous decisions on observable data. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3. The authors would need to further develop the argument to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential oversight in the paper regarding the assumption of POMDPs, specifically the lack of discussion on how previous decisions affect the observable data. It highlights a critical point that the paper does not leverage the advantage of POMDPs, which is the assumption that the decisionmaker does not directly observe the target variable Y. By pointing out this gap, the comment provides the authors with a clear and actionable suggestion to enhance the depth and relevance of their work. However, the comment could be more helpful if it offered specific guidance on how to address this issue or provided examples of how to incorporate this discussion into the paper. Overall, the feedback is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the pretraining tokens_per_sample is extremely small (256) and suggests that this might be insufficient for a regularsize program. It also questions whether using a batch_size=64 for pretraining is enough. While the comment identifies a potential issue with the pretraining setup, it does not provide explicit guidance on how to address this concern or suggest specific changes to improve the pretraining process. The authors are left to infer that they might need to increase the tokens_per_sample or adjust the batch_size, but without concrete steps, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the pretraining tokens_per_sample and batch_size, which are specific aspects of the methodology section. However, it does not explicitly mention which part of the paper these details are discussed in, making it weakly grounded. The comment is specific in identifying the issue with the pretraining setup, suggesting that the tokens_per_sample is too small and the batch_size is insufficient. This provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the pretraining tokens_per_sample is extremely small (256) and suggests that this might be insufficient for a regularsize program. It also questions whether using a batch_size=64 for pretraining is enough. While the comment identifies specific parameters that may be problematic, it lacks detailed reasoning or evidence to support why these values are considered insufficient. The authors would need to make an educated guess about the impact of these parameters on the model\"s performance, making the claim 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the pretraining setup, noting that the tokens_per_sample is extremely small (256) and questioning whether this is sufficient for a regularsize program. It also critiques the batch_size=64 for pretraining, suggesting that it might be insufficient. While the comment highlights potential weaknesses in the methodology, it lacks specific guidance or suggestions on how to address these issues. The authors are left to infer that they might need to increase the tokens_per_sample or adjust the batch_size, but without concrete steps, the feedback remains 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of ablation experiments in the work, suggesting that readers might not fully understand the proposed method. It provides specific examples of potential experiments, such as replacing the clustering algorithm with KMeans or testing the model\"s performance on differentsized descendant models. The comment is explicit in its request for additional experiments and provides concrete suggestions on what those experiments could be. This guidance gives the authors clear direction on how to enhance their draft by including these experiments, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for ablation experiments, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting specific experiments, such as replacing the clustering algorithm with KMeans and testing the model\"s performance on differentsized descendant models. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the work lacks sufficient ablation experiments to help readers understand the proposed method. It provides specific examples of potential experiments, such as replacing the clustering algorithm with KMeans and testing the model\"s performance on differentsized descendant models. This level of detail and specificity supports the claim, making it 4. However, the comment could be strengthened by providing more context or references to similar studies that have successfully used ablation experiments, which would further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of ablation experiments, which are crucial for understanding the proposed method. It provides specific examples of potential experiments, such as replacing the clustering algorithm with KMeans and testing the model\"s performance on differentsized descendant models. This feedback is clear and actionable, offering the authors a concrete way to enhance their draft by including these experiments. By addressing this feedback, the authors can provide readers with a deeper understanding of their method. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the comparison to the Talking Heads Transformer should be expanded beyond the initial comparison in Table 1, to include all tasks presented in the paper. It also questions the difficulty in assessing the benefit of the proposed interaction modules and manytomany formulation compared to a simple linear transform. While the comment implies that the authors should include these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should expand the comparison and consider the question about the benefit of their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Talking Heads Transformer\" and \"Table 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests expanding the comparison to include all tasks presented in the paper, rather than just comparing against the vanilla transformer. Additionally, it raises a question about the difficulty in assessing the benefit of the proposed interaction modules and manytomany formulation compared to a simple linear transform. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"Talking Heads Transformer\" should be the defacto baseline for all tasks, suggesting that the current comparison in Table 1 is insufficient. The reviewer provides a logical reasoning by questioning the difficulty in assessing the benefit of the proposed interaction modules and manytomany formulation compared to a simple linear transform. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore and justify the claim themselves, which limits the verifiability score.", "helpfulness_rationale": "The review comment identifies a relevant baseline, the Talking Heads Transformer, and suggests that it should be the defacto baseline for all tasks in the paper. It points out that the current comparison in Table 1 is limited and questions the difficulty in assessing the benefit of the proposed interaction modules and manytomany formulation compared to a simple linear transform. This feedback is clear and actionable, as it directs the authors to expand their comparisons and consider the limitations of their approach. However, the comment could be more helpful if it provided specific suggestions on how to conduct these comparisons or what aspects to focus on. Overall, the comment is 4 as it provides valuable insights and directions for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides a clear and explicit suggestion for the authors to reframe their paper\"s focus from breast cancer to the loss function and its applications. It specifies that the paper should highlight the loss function\"s versatility and its ability to be applied to various problems in semantic segmentation, including handling distribution shifts. This feedback is concrete and actionable, as it gives the authors a specific direction to improve the framing of their work. The authors know exactly what aspect of their paper needs to be revised and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus on breast cancer in the Introduction, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the paper\"s focus should be on the loss function and its applications rather than breast cancer. The comment provides clear guidance on what needs to be addressed, including the evaluation of the loss function over multiple datasets and its extension to other problems in semantic segmentation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper\"s focus on breast cancer is not central to its contributions, which are more about the loss function and its applications. The reviewer provides a logical reasoning by stating that the loss function can be applied to any semantic segmentation network and extended to handle distribution shifts. However, the comment lacks specific examples or references to support the claim that the paper\"s focus is misplaced. While the reasoning is sound, the absence of detailed evidence or examples makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper\"s focus. It points out that while the Introduction mentions breast cancer, the paper\"s contributions are not specifically tied to this domain. The reviewer suggests reorganizing the focus to the loss function and its applications, which is a more general and impactful aspect of the work. This feedback is valuable as it guides the authors to enhance the clarity and relevance of their paper. However, the comment could be more helpful if it included specific examples or suggestions on how to reframe the content. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks the authors to include agreement statistics for the corpus in either section 3.1 or 3.2. This is a direct and clear request for the authors to add specific data or information, providing them with a concrete action to take. The comment is explicit and provides clear guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1 or 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the inclusion of agreement statistics for the corpus. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information, specifically asking for agreement statistics for the corpus in a particular section. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it requests the inclusion of agreement statistics for the corpus in either section 3.1 or 3.2. This feedback provides clear guidance on what additional information the authors should include to enhance the comprehensiveness and clarity of their paper. By addressing this request, the authors can improve the quality and depth of their work. However, the comment could be more helpful if it provided examples of what agreement statistics might include or how they could be presented. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment discusses the novelty of the instruction aggregation and the use of LLMs, as well as the use of consecutive subtrajectories. It mentions that crosstrajectory chaining has novelty but notes that many of its techniques are inspired by goalconditioned RL approaches, referencing a specific paper. However, the comment does not provide explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address these points or improve their draft. As a result, the comment is 1, as it does not offer any actionable steps for the authors to follow.", "grounding_specificity_rationale": "The comment discusses the novelty of the instruction aggregation and the use of LLMs, as well as the use of consecutive subtrajectories. It mentions that crosstrajectory chaining has novelty but notes that many of its techniques are inspired by goalconditioned RL approaches, referencing a specific paper. However, the comment does not specify which part of the paper this discussion pertains to, such as specific sections or figures. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what is novel and what is not, but it lacks grounding as it does not explicitly mention the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of consecutive subtrajectories is straightforward, which is 3. The comment references \"goalconditioned RL approaches\" and provides a specific example, \"offline goal chaining Chebotar et al., 2021,\" which helps to substantiate the claim. However, the comment does not provide detailed reasoning or additional examples to fully support the assertion that the use of consecutive subtrajectories is straightforward. This makes the claim 3, as it provides some evidence but lacks comprehensive justification. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a balanced perspective on the novelty of the paper. It acknowledges the potential novelty of the instruction aggregation and the use of LLMs but points out that existing LLMs are already being used, which may limit the originality of the work. The comment also highlights the straightforwardness of the use of consecutive subtrajectories and notes that crosstrajectory chaining has novelty, but its techniques are inspired by goalconditioned RL approaches. This feedback is 3 as it identifies areas where the paper may lack originality and provides a reference to a related work, which could help the authors understand the context of their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or how to differentiate the work from existing approaches. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the role of the identity map in improving the expressive power of the attention module and suggests that more discussion should be conducted on this topic. While the comment implies that the authors should provide a more detailed explanation or justification for the use of the identity map, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to expand on this point. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the role of the identity map in improving the expressive power of the attention module and suggests that more discussion should be conducted on this topic. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the identity map is discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in questioning the choice of identity mapping and suggesting that more discussion is needed, but without grounding, it lacks specificity. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point raises a question about the role of the identity map in improving the expressive power of the attention module and suggests that more discussion should be conducted on this topic. However, it does not provide any supporting evidence, reasoning, or references to justify why the identity map is considered the best choice or why more discussion is needed. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the role of the identity map in improving the expressive power of the attention module and suggests that more discussion should be conducted on this topic. While it identifies an area for further exploration, it lacks specificity and does not provide actionable guidance on how the authors might address this issue. The comment is 3 as it prompts the authors to consider an important aspect of their work, but it does not offer detailed suggestions or examples to guide them in making improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to explain why they are considering decoderonly transformers, providing a clear and direct action for the authors to take. This feedback is specific and gives the authors a concrete task to address, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 235,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is explaining why the authors are considering decoderonly transformers. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The comment is a request for clarification, not a claim or opinion. It does not contain any subjective statements or assertions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for the authors to improve their draft. By asking the authors to explain why they are considering decoderonly transformers, the comment directs them to address a potential gap or assumption in their work. This feedback is clear and prompts the authors to provide additional context or justification for their choice, which can significantly enhance the clarity and comprehensiveness of their paper. Therefore, the comment is rated as 5."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the qualitative analysis is lacking in detail, specifically mentioning the proportion of each error category. It also implies that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying cause of the observed issues and potential ways to mitigate them. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to address these issues or what specific details should be included. The suggestion to include more thoughts or speculations is clear, but the lack of detailed instructions on how to implement this makes the action somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"qualitative analysis\" and the \"paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the lack of details regarding the proportion of each error category and suggests that the paper could be strengthened by including more thoughts or speculations about the underlying cause of the observed issues and potential ways to mitigate them. Additionally, it references a specific work, \"Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting,\" which provides a basis for the critique. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the qualitative analysis is lacking in detail, specifically mentioning the proportion of each error category. It also suggests that the paper could be strengthened by including more thoughts or speculations about the underlying cause of the observed issues and potential ways to mitigate them. The comment references a specific work, \"Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting,\" which provides a basis for the critique. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, making it 3. The authors would need to further explore the reference to understand the full context of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the qualitative analysis by pointing out the lack of details, such as the proportion of each error category. It also suggests that the paper could be strengthened by including more fruitful thoughts or speculations about the underlying cause of the observed issues and potential ways to mitigate them. The comment references a specific work, \"Language Models Don\"t Always Say What They Think: Unfaithful Explanations in ChainofThought Prompting,\" which provides a basis for the critique. This feedback is clear and actionable, offering the authors a direction for enhancing the depth and relevance of their analysis. However, it could be more helpful if it provided specific examples or suggestions on how to incorporate these thoughts or speculations into the paper. Overall, the comment is 4 as it guides the authors toward a more comprehensive analysis."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors could apply Reinforcement Learning, RNNs, and Wasserstein GANs with simple data filling methods to empirically validate that these techniques are not suitable for their proposed approach, given the context of incomplete and small data. This feedback provides a clear and explicit action for the authors to take, which is to test the applicability of these methods using simple data filling. The comment also concretely specifies what needs to be done, making it 5. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the specific part of the paper where the authors discuss the baselines, including the mention of \"Reinforcement Learning, RNNs, Wasserstein GANs\" and the comparison with a Markov chain approach. This allows the authors to accurately identify the section being addressed. The comment is also specific because it provides a clear suggestion for improvement by recommending that the authors apply these techniques with simple data filling methods to empirically validate their suitability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should consider applying Reinforcement Learning, RNNs, and Wasserstein GANs with simple data filling methods to validate their approach. The comment provides a logical reasoning by suggesting that these techniques are not suitable for small or incomplete datasets, which is a common knowledge in machine learning. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and justify this suggestion themselves, which limits the verifiability score. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending that the authors test the applicability of Reinforcement Learning, RNNs, and Wasserstein GANs with simple data filling methods. This feedback is actionable and offers a clear direction for the authors to validate the suitability of these techniques for their proposed approach, particularly in the context of small or incomplete datasets. By suggesting empirical validation, the comment empowers the authors to strengthen their analysis and demonstrate the limitations of these methods. This level of guidance is valuable for improving the draft, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of baseline comparison, specifically mentioning that the GEVAL method is based solely on GPT3.5 and GPT4 without demonstrating their performance using the simplest prompt and then comparing it with the GEVAL method. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how to conduct this comparison or what specific aspects should be considered. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take to address the issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the lack of baseline comparison in the paper, particularly concerning the GEVAL method. It highlights that the method is based solely on GPT3.5 and GPT4 without demonstrating their performance using the simplest prompt and then comparing it with the GEVAL method. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the lack of a baseline comparison. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the GEVAL method lacks a baseline comparison, specifically mentioning the absence of performance demonstration using the simplest prompt for GPT3.5 and GPT4 before comparing it with the GEVAL method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, namely the lack of a baseline comparison. It points out that the GEVAL method is based solely on GPT3.5 and GPT4 without demonstrating their performance using the simplest prompt and then comparing it with the GEVAL method. This feedback is clear and actionable, as it directs the authors to include a baseline comparison to strengthen their evaluation. However, the comment could be more helpful if it provided suggestions on how to conduct this comparison or what specific aspects should be considered. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to enhance their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a specific issue related to updating weights in multiagent environments, noting that it requires full knowledge of game payoffs and the policies of other agents. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve their methodology. The comment implies that the authors should consider these requirements when updating weights, but it lacks concrete steps or actions for the authors to take. As a result, the comment is vague and does not offer actionable advice, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific issue related to updating weights in multiagent environments, mentioning the need to compute expected rewards or NE gaps for different perturbations. It highlights a potential issue with the base policies, which only update based on observed rewards, unlike the required knowledge of game payoffs. Additionally, it notes the necessity of knowing the policies of other agents when computing NE gaps. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the issue with updating weights and the requirements for doing so, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the method of updating weights in multiagent environments, specifically questioning the necessity of full knowledge of game payoffs and the policies of other agents. The comment provides a logical reasoning by explaining that this requirement is different from the base policies, which only update based on observed rewards. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and clarify these points to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the method of updating weights in multiagent environments, specifically questioning the necessity of full knowledge of game payoffs and the policies of other agents. It highlights a potential issue with the base policies, which only update based on observed rewards, unlike the required knowledge of game payoffs. This feedback is 3 as it identifies a potential weakness in the methodology and prompts the authors to reconsider their approach. However, the comment could be more helpful if it provided suggestions or examples on how to address this issue or alternative methods for updating weights. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the comparison, such as suggesting additional comparisons, discussing limitations, or providing more detailed analysis. Without any actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the paper primarily compares the proposed methods with DiffUCO, but it does not specify which part of the paper this comparison is made in. Without explicit references to sections, figures, or tables, the authors cannot confidently determine where this comparison is discussed. Additionally, the comment lacks specificity regarding what aspects of the comparison could be improved or what additional comparisons might be beneficial. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper primarily compares the proposed methods with DiffUCO. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this statement or how it impacts the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment states that the paper primarily compares the proposed methods with DiffUCO, but it does not provide any specific feedback or suggestions on how this comparison could be improved or expanded. Without actionable advice or detailed guidance, the authors are left without a clear understanding of what aspects of their work could be enhanced or what additional comparisons might be beneficial. This lack of specificity and actionable feedback makes the comment unhelpful for guiding the authors in improving their draft. Therefore, it aligns with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights that the paper is too repetitive and superficial in its exposition of the decomposition method, specifically mentioning the lack of explicit definitions of local subtasks and their corresponding policies, as well as the relationship between them. It also points out the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. While the comment identifies several areas that need clarification and improvement, it does not provide specific guidance on how to address these issues or suggest particular actions for the authors to take. The authors are left to infer that they need to provide more detailed explanations and proofs, but without concrete steps, the action remains vague. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"contribution\" and the \"paper,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issues with the paper\"s exposition, including the lack of explicit definitions of local subtasks and their corresponding policies, the relationship between them, and the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is too repetitive and superficial in its exposition of the decomposition method, specifically mentioning the lack of explicit definitions of local subtasks and their corresponding policies, as well as the relationship between them, and the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. The comment provides logical reasoning by pointing out the specific areas where the paper lacks clarity and detail, which supports the claim. However, it could be more verifiable with additional examples or references to similar works that have successfully addressed these aspects. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s exposition, specifically the lack of explicit definitions and explanations regarding the decomposition method, particularly the local subtasks and their corresponding policies. It also points out the absence of a complete proof of the equivalence between the local policy product and the globally optimal policy. This feedback is clear and actionable, as it directs the authors to provide more detailed and rigorous explanations in their draft. However, the comment could be more helpful if it offered suggestions on how to structure these explanations or examples of how to present the information effectively. Overall, the comment is 4, as it provides valuable insights for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point indicates that the performance curves of each algorithm during training are missing. While it highlights a specific issue, it does not provide explicit guidance on how the authors should address this omission. The comment implies that the authors should include these curves, but it does not specify whether they should be added, what aspects of the curves are important, or how they should be presented. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to address the issue. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment points out that the performance curves of each algorithm during training are missing, which is a specific issue. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in identifying the missing information, but without clear guidance on where to add it, the authors may struggle to address the issue effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the performance curves of each algorithm during training are missing. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of the missing information and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the performance curves of each algorithm during training are missing. This is a clear and actionable piece of feedback that highlights a critical omission in the paper. By pointing out the missing information, the reviewer provides the authors with a direct and constructive suggestion for improvement, which can help them enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered additional guidance on how to present or analyze these curves. Overall, the feedback is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a computational issue with the proposed Gaussian kernelbased graph construction method, specifically noting that it requires computing the full adjacency matrix, which is computationally expensive for largescale graphs due to its O(N^2) time complexity. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what steps they could consider to mitigate the computational burden. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the proposed Gaussian kernelbased graph construction method, namely the computational expense of computing the full adjacency matrix for largescale graphs. This provides clear guidance on what aspect of the method is problematic. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed Gaussian kernelbased graph construction method requires computing the full adjacency matrix, which is computationally expensive for largescale graphs with O(N^2) time complexity. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed Gaussian kernelbased graph construction method, specifically noting that it requires computing the full adjacency matrix, which is computationally expensive for largescale graphs due to its O(N^2) time complexity. This feedback is clear and actionable, as it highlights a critical limitation of the method that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to mitigate this computational burden or alternative approaches that could be considered. Despite this, the comment still offers valuable insight into an area that needs improvement, making it 4. Therefore, it aligns with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the choice of loss reweighting cases in the paper, specifically questioning the rationale behind using case (1) by default in Eq. (5) when case (3) performs better for most widths. The reviewer suggests that the authors should explain why case (1) is chosen despite its apparent suboptimal performance. This feedback implies that the authors should provide a clearer justification for their choice, making the action implicit but concrete. The authors know that they need to address this issue by explaining their decision, but the comment does not explicitly instruct them to do so. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 8\" and \"Table 2e,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the choice of loss reweighting cases, particularly the use of case (1) by default in Eq. (5) despite case (3) performing better for most widths. The comment further critiques the rationale provided by the authors, suggesting that all subnetworks with different widths should be equally important for the concept of slimmable networks. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the authors\" choice of using case (1) by default in Eq. (5), despite case (3) performing better for most widths. The reviewer argues that all subnetworks with different widths should be equally important for the concept of slimmable networks. This claim is 3 as it raises a logical concern about the choice of reweighting cases, but it lacks specific examples or references to support the argument. The authors would need to provide more detailed reasoning or evidence to address this critique effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of loss reweighting cases in the paper, particularly questioning the rationale behind using case (1) by default in Eq. (5) despite case (3) performing better for most widths. The reviewer challenges the authors\" explanation, suggesting that all subnetworks with different widths should be equally important for the concept of slimmable networks. This feedback is clear and actionable, as it prompts the authors to reconsider their choice of reweighting cases and provide a more robust justification for their selection. However, the comment could be more helpful if it offered specific suggestions or examples of how to address the issue. Overall, the comment is 4 as it highlights a critical area for improvement and encourages the authors to provide a more comprehensive explanation."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It questions the use of a double summation and asks for clarification on the function f(.) in the line above equation 3. It also mentions existing works like TailorNet and Patel et al. 2021 that use PBS for garment simulation and suggests that the authors provide details on the challenges of simulating multiple layers compared to singlelayered clothing. While the comment raises several points, it does not provide explicit instructions or concrete steps for the authors to take. The actions are implicit and somewhat vague, as the authors need to infer what changes to make. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line just above eq. 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises questions about the use of a double summation, the function f(.) in the equation, and the challenges of simulating multiple layers compared to singlelayered clothing. Additionally, it references existing works like TailorNet and Patel et al. 2021, providing context and suggesting areas for further discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the use of a double summation and the function f(.) in the context of garment simulation. It also references existing works like TailorNet and Patel et al. 2021, which use similar techniques, suggesting that the authors should provide details on the challenges of simulating multiple layers. While the comment provides some context and references, it lacks detailed explanations or specific examples to fully substantiate the claim. The authors would need to infer the reasoning behind the suggestion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could enhance the paper\"s clarity and comprehensiveness. It questions the use of a double summation and asks for clarification on the function f(.) in the line above equation 3, which is crucial for understanding the methodology. Additionally, it references existing works like TailorNet and Patel et al. 2021 that use similar techniques, prompting the authors to provide details on the challenges of simulating multiple layers compared to singlelayered clothing. This feedback is 4 as it identifies specific areas for clarification and suggests a comparative analysis with existing literature, which can significantly improve the paper\"s depth and relevance. However, the comment could be more helpful if it provided more detailed guidance on how to address these issues or examples of how to improve the explanation. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the theoretical analysis, specifically about the definition of the supremum and its relation to the GRADE method. While it identifies a potential area of confusion, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to clarify or resolve the confusion. The comment lacks concrete suggestions or steps for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is vague and 1, aligning with a score of 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Definition 1\" and \"supremum,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the theoretical analysis, asking for clarification on why the supremum is defined as it is and how the proposed GRADE method reduces this supremum. This provides clear guidance on what needs to be addressed in the theoretical analysis. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a question about the theoretical analysis, specifically regarding the definition of the supremum and its relation to the GRADE method. It does not make a subjective claim or suggestion but rather seeks clarification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the theoretical analysis, particularly regarding the definition of the supremum and its relation to the GRADE method. It raises a question about how the proposed GRADE reduces this supremum, which could be a valuable point for the authors to address. However, the comment lacks actionable guidance or suggestions on how the authors might clarify or resolve this confusion. While it points out a potential weakness, it does not provide detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically questioning whether performance might drop on these lengthy dialogues. While the comment implies that the authors should provide such results and analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to include this information but are not given specific guidance on how to incorporate it into their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including results and analysis on lengthy dialogue samples, specifically questioning whether performance might drop on these lengthy dialogues. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis. The authors might infer that it relates to the results or discussion sections, but this inference is not direct. The comment is specific in its request for additional results and analysis but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include results and analysis on lengthy dialogue samples, specifically questioning whether performance might drop on these lengthy dialogues. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this analysis is necessary or how it would impact the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include results and analysis on lengthy dialogue samples, specifically questioning whether performance might drop on these lengthy dialogues. This feedback is 3 as it identifies a potential area for improvement in the paper, prompting the authors to consider the impact of lengthy dialogues on performance. However, the comment lacks depth and does not provide specific guidance on how to incorporate this analysis or what aspects of the performance to focus on. While it highlights an important consideration, the feedback could be more actionable with additional details or suggestions. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the datasets used in the paper only contain visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. It also provides references to support the suggestion, indicating that the authors should consider these works for further insight. The comment is explicit in its request for additional modalities and provides concrete references to guide the authors on potential directions for improvement. However, it does not specify which modalities should be included or how they should be integrated into the current work. Despite this, the action is clear and actionable, as it gives the authors a specific direction to enhance their dataset evaluation. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that the datasets used in the paper only contain visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. It provides references to support the suggestion, indicating that the authors should consider these works for further insight. However, the comment does not specify which part of the paper discusses the datasets or where the authors should incorporate these additional modalities. This makes it weakly grounded, as the authors cannot confidently determine which sections or aspects of the paper need revision. The comment is specific in suggesting the inclusion of additional modalities and providing references, but without explicit grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the datasets used in the paper only contain visual modality and recommends including more natural modalities, such as audio and visual, for better evaluation. The comment provides references to support the suggestion, specifically mentioning works by Weiyao Wang et al., Thomas Winterbottom et al., and Ya Sun et al., which discuss the limitations of multimodal classification networks and the potential bias in datasets. This provides a solid foundation for the claim, as it references existing literature that supports the need for diverse modalities. However, the comment could be strengthened by explicitly explaining how these references relate to the current work and why they are relevant. Overall, the comment is 4, as it is wellsupported by references but lacks detailed explanation within the comment itself.", "helpfulness_rationale": "The review comment identifies a limitation in the current study, noting that the datasets used only contain visual modality. It suggests that including more natural modalities, such as audio and visual, could enhance the evaluation. The comment is supported by references to relevant works that discuss the limitations of multimodal classification networks and the potential bias in datasets. This feedback is clear and actionable, as it provides the authors with a specific direction for improving their dataset selection and evaluation. However, it could be more helpful if it offered additional guidance on how to incorporate these modalities or suggested specific datasets to consider. Overall, the comment is 4, as it effectively directs the authors toward enhancing their work, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a similarity between the oraclecontext model and some prompt tuning works, such as Visual Prompt Tuning and Prompt Learning for VisionLanguage Models. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should discuss these works, how they might relate to their own work, or if they should consider incorporating these references. Without specific instructions or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a similarity between the oraclecontext model and some prompt tuning works, such as Visual Prompt Tuning and Prompt Learning for VisionLanguage Models. However, it does not specify which part of the paper discusses the oraclecontext model or where these works are mentioned. This makes it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the content being similar to other works, it lacks grounding as it does not provide clear guidance on which parts of the paper should be revised or expanded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the oraclecontext model is very similar to some prompt tuning works, such as Visual Prompt Tuning and Prompt Learning for VisionLanguage Models, but notes that these works are not discussed in the paper. This claim is 3 as it provides a specific example of a similar work, but it lacks detailed reasoning or evidence to fully substantiate the claim. The authors would need to further explore the similarities and provide a more comprehensive explanation to fully understand the basis of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential similarity between the oraclecontext model and some existing prompt tuning works, such as Visual Prompt Tuning and Prompt Learning for VisionLanguage Models. However, it does not provide any specific guidance or suggestions on how the authors might address this similarity or incorporate these works into their paper. The comment lacks actionable feedback, such as recommending a discussion or comparison with these works, which would be beneficial for the authors to improve their draft. As a result, the comment is not particularly helpful and does not align with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper should provide more insights into how the observed phenomenon can be used to design better resilient systems. It raises a specific example of choosing a linear architecture and proposes a potential defense method that could be integrated into a hierarchical system to demonstrate the usefulness and significance of the observed results. While the comment implies that the authors should explore this idea, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should provide more insights into how the observed phenomenon can be used to design better resilient systems. It raises a specific example of choosing a linear architecture and proposes a potential defense method that could be integrated into a hierarchical system. However, the comment does not explicitly mention which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion for improvement, but without explicit grounding, the authors may struggle to identify the exact part of the paper that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper only discusses the observed phenomenon without providing deeper insights into how these observations can be used to design better resilient systems. The reviewer suggests that the paper should explore the potential of using these observations to design hierarchical systems, which could demonstrate the usefulness and significance of the results. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to infer the basis of the claim and may require additional information to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s contribution by noting that it only discusses the observed phenomenon without providing deeper insights into how these observations can be used to design better resilient systems. It raises a specific example of choosing a linear architecture and suggests exploring the potential of integrating a proposed defense method into a hierarchical system to demonstrate the usefulness and significance of the observed results. This feedback is clear and actionable, as it provides a concrete direction for the authors to enhance the depth and relevance of their work. However, the comment could be more helpful if it included specific suggestions or examples on how to implement this exploration. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide rigorous definitions for the concept of \"reliability or trust\" as it pertains to what LLMs \"knows.\" However, it does not explicitly instruct the authors to do so or provide specific guidance on how to develop these definitions. The action is implicit and somewhat vague, as the authors can infer that they need to address this issue but may not be entirely sure of the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors should provide rigorous definitions for the concept of \"reliability or trust\" as it pertains to what LLMs \"knows.\" However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to provide rigorous definitions, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide rigorous definitions for the concept of \"reliability or trust\" as it pertains to what LLMs \"knows.\" However, the comment does not offer any supporting evidence, examples, or references to justify why this is necessary or how it would improve the paper. Without additional context or reasoning, the claim remains 1, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, specifically the lack of rigorous definitions for the concept of \"reliability or trust\" as it pertains to what LLMs \"knows.\" This feedback is clear and actionable, as it highlights a specific area where the authors need to provide more detailed and precise definitions to strengthen their work. However, the comment could be more helpful if it offered suggestions on how to develop these definitions or provided examples of how to approach this rigorously. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the necessity of masked selfattention in the YFuture encoder and the preference for ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments. While the comment poses questions that could guide the authors to consider these aspects, it does not provide explicit instructions or concrete actions for the authors to take. The questions are openended and leave the authors to determine how to address them, making the comment 3.", "grounding_specificity_rationale": "The comment raises questions about the necessity of masked selfattention in the YFuture encoder and the preference for ProbSparse over other methods. It also inquires about the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or experiments. This makes it weakly grounded, as the authors cannot confidently determine which parts of the paper are being addressed. The comment is specific in its questions about the necessity of masked selfattention and the impact on computational efficiency, but without clear grounding, it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the necessity of masked selfattention in the YFuture encoder and the preference for ProbSparse over other methods. It also questions the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. The comment does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and seeks clarification, making it a normal statement.", "helpfulness_rationale": "The review comment raises several questions about the necessity of masked selfattention in the YFuture encoder and the preference for ProbSparse over other methods. It also questions the impact on computational efficiency, given the larger forecasting horizons compared to history lengths in experiments from Appendix E.2. While the comment identifies areas of interest and potential concerns, it lacks specific suggestions or guidance on how the authors might address these issues or improve their draft. The questions are openended and could be expanded with more detailed feedback to be more helpful. Therefore, the comment is 3, as it provides some insight but lacks actionable advice for the authors."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of theoretical analysis regarding why deep layer parameters are more suitable for distillation. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue or what specific aspects of the theoretical analysis need to be explored. Without guidance on what the authors should do to improve their draft, the comment lacks actionability. The authors are left without a clear understanding of how to enhance their work based on this feedback. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights a lack of theoretical analysis regarding the suitability of deep layer parameters for distillation. However, it does not specify which part of the paper this issue pertains to, such as a particular section or paragraph discussing the theoretical analysis. Without explicit references to the paper, the authors cannot confidently determine which part of the paper needs attention. While the comment is specific about the issue of theoretical analysis, it lacks grounding as it does not provide enough context or detail to guide the authors. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the theoretical analysis of why deep layer parameters are more suitable for distillation is lacking. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the theoretical analysis of why deep layer parameters are more suitable for distillation. It highlights a gap in the paper that needs to be addressed to strengthen the theoretical foundation of the work. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or what specific aspects of the theoretical analysis should be explored. While it points out an important area for improvement, the lack of actionable feedback limits its usefulness to the authors. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks depth and guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that a significant portion of the paper\"s details are in the appendix, indicating that the paper is not sufficiently selfcontained. While it highlights a lack of selfcontainment, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include more details in the main text or ensure that the appendix is not necessary, but it does not specify how to achieve this. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve the paper\"s selfcontainment. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a concern about the paper\"s selfcontainment, noting that a lot of important details are in the appendix. However, it does not specify which sections or details are missing or how they should be addressed. The authors cannot confidently determine which parts of the paper are affected by this issue, as it is not fully grounded. The comment lacks specificity regarding what details are missing or how they should be integrated into the main text. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that \"a lot of the important paper details are in the appendix,\" suggesting that the paper is not sufficiently selfcontained. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of the missing details, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment points out a significant issue with the paper\"s selfcontainment, noting that a substantial portion of the important details are in the appendix. This feedback is valuable as it highlights a critical area that needs attention to ensure the paper is accessible and understandable to readers who may not be familiar with the appendix. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as moving certain sections to the main text or providing a summary of key points in the appendix. While it identifies a problem, it does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment acknowledges the argument that gradient descentbased methods for clustering can scale to large datasets but questions the scalability of the largest dataset used, which is about 50,000 points. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern, such as suggesting alternative methods, additional experiments, or further analysis. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the argument regarding the scalability of gradient descentbased methods for clustering, mentioning the largest dataset used, which is about 50,000 points. However, it does not specify which part of the paper this critique pertains to, such as a particular section or result. The authors might infer that it relates to the discussion of scalability or the experimental results, but this inference is not direct. The comment lacks specificity regarding what aspect of the argument is being questioned or improved. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point questions the scalability of the argument presented, specifically mentioning that the largest dataset used is about 50,000 points. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that this dataset size is insufficient. Without additional context or justification, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment acknowledges the argument that gradient descentbased methods for clustering can scale to large datasets but questions the scalability of the largest dataset used, which is about 50,000 points. While it identifies a potential limitation in the study, it does not provide specific suggestions or guidance on how the authors might address this issue or improve the scalability of their methods. The comment lacks actionable feedback, leaving the authors without clear direction on how to enhance their work. Therefore, it is rated as 2, as it highlights a concern but does not offer constructive advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the practicality of the assumptions made in the paper, specifically regarding the difficulty in verifying the assumptions. It mentions that the method relies on \"overloading the library with ASD subroutines\" (assumption 3.2) and questions how practical this assumption is. However, the comment does not provide explicit guidance or suggestions on how the authors might address this concern or improve the practicality of the assumptions. The action is implicit and vague, as it does not specify what the authors should do to make the assumptions more practical or how they might verify their practicality. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the assumptions made in the paper, specifically regarding the practicality of assumption 3.2, which involves \"overloading the library with ASD subroutines.\" However, it does not specify which part of the paper discusses these assumptions, making it weakly grounded. The comment is specific in identifying the issue with the assumptions and questioning their practicality, providing a clear direction for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the practicality of the assumptions made in the paper, specifically regarding the difficulty in verifying assumption 3.2, which involves \"overloading the library with ASD subroutines.\" However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the assumptions are not practical. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practicality of the assumptions made in the paper, specifically regarding the difficulty in verifying assumption 3.2, which involves \"overloading the library with ASD subroutines.\" While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this issue or improve the practicality of their assumptions. The feedback is 3 as it prompts the authors to consider the practicality of their assumptions, but it does not provide actionable steps or detailed insights to enhance the draft. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment suggests that the authors should be less enthusiastic about using a methodology commonly employed in data augmentation. However, it does not provide any explicit guidance or suggestions on how to achieve this or what specific aspects should be adjusted. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to address the feedback. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the authors should be less enthusiastic about utilizing a methodology commonly used in data augmentation. However, it does not specify which part of the paper this suggestion pertains to, nor does it provide details on what aspects of the methodology should be reconsidered. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention. Additionally, the comment lacks specificity regarding what aspects of the methodology should be adjusted or improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should be less enthusiastic about utilizing a methodology commonly used in data augmentation. However, it does not provide any supporting evidence, reasoning, or examples to justify why this approach is less exciting or why it should be reconsidered. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should be less enthusiastic about utilizing a methodology commonly used in data augmentation. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this concern or improve their work. Without actionable feedback or detailed reasoning, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a specific issue with the paper, noting that a statement in section 4 is incorrect. It highlights a discrepancy between the claim made in the text and the results shown in Figure 4. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to correct the statement. The action is implicit and vague, as it does not specify how to revise the statement or what aspects of the results should be clarified. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4\" and \"Fig. 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the statement in section 4, pointing out the discrepancy between the claim and the results shown in Figure 4. The comment specifies what needs to be addressed, namely the correction of the statement regarding the performance of multiimage IMP. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that some statements in the paper are incorrect, specifically regarding the results presented in Figure 4. The reviewer provides a detailed critique by stating that the multiimage IMP shows essentially the same performance as others, contradicting the claim made in the text. This claim is supported by the reference to Figure 4, which allows the authors to verify the discrepancy themselves. However, the comment could be strengthened by providing more detailed analysis or examples of the incorrectness, which would make it 5. As it stands, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that a statement in section 4 is incorrect. It highlights a discrepancy between the claim made in the text and the results shown in Figure 4, where the multiimage IMP does not significantly improve the quality of the LIPs in the crossdomain setting. This feedback is clear and actionable, as it points out a potential error in the paper\"s claims and suggests that the authors should reexamine and correct this statement. However, the comment could be more helpful if it provided guidance on how to revise the statement or what specific aspects of the results should be clarified. Overall, the comment is 4 as it directs the authors\" attention to a critical issue that needs addressing."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point provides a specific claim that the rank of the proposed method in the VLN Leaderboard is 22nd, which is not better than existing methods. It references specific works, such as 1,2,3, to support this claim. However, the comment does not offer any explicit or implicit suggestions for improvement or action. It lacks guidance on how the authors might address this issue or enhance their method to surpass the existing methods. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the rank in the VLN Leaderboard and provides specific references to existing methods, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of improvement over existing methods, and provides references to support this claim. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the rank of the proposed method in the VLN Leaderboard is 22nd, which is not better than existing methods. The comment supports this claim by referencing specific works, such as 1,2,3, which are cited as examples of existing methods. This provides a logical basis for the claim, as it references specific works that the authors can compare their method to. However, the comment could be strengthened by providing more detailed comparisons or explaining why the proposed method is not better than these existing methods. Overall, the claim is 4, as it is supported by references but could benefit from additional explanation or evidence.", "helpfulness_rationale": "The review comment provides a specific claim about the rank of the proposed method in the VLN Leaderboard, noting that it is 22nd and not better than existing methods. It supports this claim by referencing specific works, such as 1,2,3, which are cited as examples of existing methods. However, the comment lacks actionable feedback or suggestions on how the authors might address this issue or improve their method to surpass the existing methods. While it identifies a potential weakness, it does not offer guidance on how to enhance the manuscript, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the discussion in section 2.2 is not convincing in explaining how semantic similarity is modeled with the proposed approach. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to improve the discussion or what specific aspects need clarification. Without actionable advice or suggestions, the authors are left without a clear path to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of convincing explanation of how semantic similarity is modeled with the proposed approach. This provides clear guidance on what needs to be addressed in the discussion. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion in section 2.2 is not convincing in explaining how semantic similarity is modeled with the proposed approach. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that lacks clarity, namely the explanation of how semantic similarity is modeled with the proposed approach in section 2.2. This feedback is clear and actionable, as it highlights a critical gap in the paper\"s discussion that needs to be addressed. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or examples of how semantic similarity could be modeled. Despite this, the comment still provides valuable guidance for the authors to enhance the comprehensibility of their work. Therefore, it is rated as 4, consistent with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This feedback is clear and provides concrete guidance on what the authors should do to address the issue of parameter estimation challenges. The comment is specific in its request for additional analysis, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed SEPAI3R3O model, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of parameter estimation challenges and suggests that the authors discuss the uncertainty in fitted parameter values and provide sensitivity analysis. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the SEPAI3R3O model introduces over 10 parameters, which may be difficult to estimate given limited realworld observations. It further suggests that modeling these parameters as timevarying complicates the estimation process. The comment provides logical reasoning by explaining the challenges of parameter estimation with limited data and the impact of timevarying parameters. However, it lacks specific examples or references to support the claim about the difficulty of estimation. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the proposed SEPAI3R3O model, specifically the introduction of over 10 parameters that may be difficult to estimate given limited realworld observations. It further highlights the added complexity of modeling these parameters as timevarying, which exacerbates the estimation challenge. The comment provides actionable feedback by suggesting that the authors discuss the uncertainty in fitted parameter values and offer sensitivity analysis. This guidance is clear and constructive, helping the authors address a critical limitation in their model and improve the robustness of their findings. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the assumption that causal parameters across domains are random samples and suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how these parameters change or remain unchanged across domains. However, it does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The comment lacks actionable details, leaving the authors uncertain about what specific changes or improvements are needed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises concerns about the assumption that causal parameters across domains are random samples and questions the dependence of the proposed method\"s performance on how these parameters change or remain unchanged across domains. However, it does not specify which part of the paper this assumption is discussed in, nor does it provide specific guidance on how to address these concerns. The authors may infer that it relates to the methodology or results sections, but this inference is not direct. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a concern about the assumption that causal parameters across domains are random samples and questions the dependence of the proposed method\"s performance on how these parameters change or remain unchanged across domains. The reviewer suggests that the performance of the method and the relative performances of MC, IB, and HSIC tests are significantly influenced by this assumption. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that the assumption is incorrect or how it affects the method\"s performance. This makes the claim 3, as it provides a logical basis but requires more detailed evidence to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical point about the assumption that causal parameters across domains are random samples and questions its validity. It suggests that the performance of the proposed method and the relative performances of MC, IB, and HSIC tests depend on how these parameters change or remain unchanged across domains. This feedback highlights a potential weakness in the methodology and prompts the authors to consider the robustness of their assumptions. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their analysis. While it identifies an important area for consideration, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the novelty of the paper, questioning whether the structural optimization method is new or not. It suggests that the title of the paper makes the narrative weaker. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the concern about novelty or improve the narrative. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the novelty of the paper, specifically questioning whether the structural optimization method is new or not. However, it does not specify which part of the paper this concern pertains to, such as the introduction, methodology, or results sections. Additionally, the comment does not provide specific details on what aspects of the method might be novel or how the title might weaken the narrative. As a result, the authors cannot confidently determine which parts of the paper need attention or clarification. The comment lacks both grounding and specificity, making it 1 at all.", "verifiability_rationale": "The review point raises a concern about the novelty of the paper, specifically questioning whether the structural optimization method is new or not. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the novelty of the paper, specifically questioning whether the structural optimization method is new or not. It points out that the title of the paper makes the narrative weaker, which suggests that the authors need to clarify the originality of their work. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the narrative. While it identifies an area for improvement, the feedback is vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights an important issue but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption in the proof regarding the lambda value in the mixup method. It suggests that the assumption may not be correct because, in standard mixup, the mixed sample can be generated when lambda is 0.5. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete instructions or actionable steps, leaving the authors uncertain about how to proceed. The action is implicit and vague, making it difficult for the authors to know what specific changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proof\" and the \"lambda not to be 0.5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption in the proof, particularly regarding the lambda value in the mixup method. The comment provides a clear explanation of the concern, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the assumption in the proof may not be correct because, in standard mixup, the mixed sample can be generated when lambda is 0.5. This claim is 3 as it provides a logical reasoning based on the standard mixup method. However, it lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore the implications of this observation to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a potential issue with the assumption in the proof regarding the lambda value in the mixup method. It points out that in standard mixup, the mixed sample can be generated when lambda is 0.5, suggesting that the assumption in the proof may not be correct. This feedback is 3 as it highlights a specific area that requires clarification or reconsideration. However, it lacks detailed guidance or suggestions on how the authors might address this issue or what specific changes could be made to the proof. To be more helpful, the comment could provide examples or further explanation of the implications of this observation. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to highlight which set of equations have the same form as the Riccati equation in the paragraph above Theorem 3.1. It also suggests extracting some of the currently inlined math into environments to facilitate looking up symbols, specifically on page 6. These requests are clear and provide specific actions for the authors to take, making the comment 5. The authors know exactly what needs to be done to improve their draft, which aligns with the criteria for a score of 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the paragraph above Theorem 3.1\" and \"page 6,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be done: highlighting the set of equations with the same form as the Riccati equation and extracting inlined math into environments to facilitate symbol lookup. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate suggestions: one asking for clarification on which equations have the same form as the Riccati equation in a specific paragraph, and another suggesting the extraction of inlined math into environments for easier symbol lookup. Neither of these suggestions is a claim or opinion but rather requests for clarification and improvement in presentation. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides specific and actionable feedback by asking the authors to clarify which set of equations have the same form as the Riccati equation in a specific paragraph. This request for clarification can help the authors improve the clarity and precision of their paper. Additionally, the comment suggests extracting inlined math into environments to facilitate symbol lookup, which is a practical suggestion for enhancing readability and accessibility. While the comment is clear and provides valuable guidance, it could be more helpful if it included examples or further elaboration on how to implement the suggested changes. Overall, the feedback is 4, as it offers clear directions for improvement but could be more comprehensive with additional details."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the need for clearer structure and transitions in certain sections of the paper, as well as the use of subjective terms like \"significant\" without statistical evidence. While it identifies specific areas for improvement, it does not provide explicit instructions on how to achieve this clarity or what specific transitions or statistical evidence should be included. The authors are left to infer that they need to restructure their sections and provide more statistical support for their claims, but without concrete guidance, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses clarity in writing, specifically mentioning the need for clearer structure and transitions in certain sections. It also points out the use of subjective terms like \"significant\" and suggests the inclusion of statistical evidence, such as pvalues, to clarify these terms. However, the comment does not specify which sections or lines are problematic, making it weakly grounded. The authors can infer that it pertains to sections with unclear transitions and subjective terms, but this inference is not direct. The comment is specific in its suggestions for improvement, such as providing statistical evidence, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that certain sections of the paper could benefit from clearer structure and transitions, as well as the use of statistical evidence to clarify subjective terms like \"significant.\" While the comment identifies areas for improvement, it lacks specific examples or references to support the claim that clearer structure and transitions would enhance the paper\"s clarity. The suggestion to include statistical evidence is logical, but the comment does not provide detailed guidance on how to implement these changes. Therefore, the claim is 3, as it provides a general direction for improvement but lacks specific evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies areas for improvement in the clarity of the paper, specifically mentioning the need for clearer structure and transitions in certain sections. It also points out the use of subjective terms like \"significant\" and suggests the inclusion of statistical evidence, such as pvalues, to clarify these terms. While the comment highlights specific areas for improvement, it lacks detailed guidance on how to achieve these changes or provides examples of how to enhance the clarity of the writing. This makes the feedback 3, as it offers a direction for improvement but does not fully support the authors in making those changes. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly points out the absence of detailed information regarding the construction of graphs, specifically mentioning the need for information on how edges are defined and how a graph is constructed for nonEuclidean datasets. This feedback provides a clear and direct action for the authors to take, which is to include this information in their draft. The comment is specific and gives concrete guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"detailed information for graph construction,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the details on how edges are defined and how a graph is constructed for nonEuclidean datasets. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that detailed information for graph construction is missing, specifically mentioning the need for information on how edges are defined and how a graph is constructed for nonEuclidean datasets. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this information is missing or why it is important. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper regarding the detailed information for graph construction, particularly the need for information on how edges are defined and how a graph is constructed for nonEuclidean datasets. This feedback is clear and actionable, as it directs the authors to include this information in their draft, which is crucial for the completeness and clarity of the paper. By addressing this feedback, the authors can significantly enhance the comprehensiveness of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about the visual and textual representations used in each method, which is crucial for understanding the source of the endtoend performance gain attributed to the proposed attention model. While the comment implies that the authors should clarify this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more details on the representations used. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a clear question about the visual and textual representations used in each method, which is crucial for understanding the source of the endtoend performance gain attributed to the proposed attention model. This provides the authors with a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the visual and textual representations used in each method, which is crucial for understanding the source of the endtoend performance gain attributed to the proposed attention model. However, it does not provide any claim, judgment, or suggestion that requires verification. It is a factual observation seeking clarification, so it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the visual and textual representations used in each method, which is crucial for understanding the source of the endtoend performance gain attributed to the proposed attention model. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about the representations used, which could enhance the clarity and comprehensibility of their work. However, the comment could be more helpful if it offered suggestions on how to present this information or emphasized its importance. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights several issues with the studied problems, such as insufficient description of uncertainty calibration and the lack of organization and summarization of the issues. It suggests that the authors should further organize and summarize these issues. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to organize or summarize these issues. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues with the studied problems, such as the lack of illustration and description of uncertainty calibration. It also mentions the need for further organization and summarization of the issues, including small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients. However, the comment does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The authors can infer that it relates to the sections discussing the studied problems or results, but this inference is not as direct as it could be. The comment is specific in detailing what needs to be improved, such as the description of uncertainty calibration and the organization of the issues. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the studied problems are not welldriven and illustrated, specifically mentioning the insufficiency of the description of uncertainty calibration. The reviewer suggests that the issues, such as small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to organize and summarize the issues is logical, but without additional context or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several issues with the studied problems, such as the lack of illustration and description of uncertainty calibration, which can be unfriendly to new readers. It also suggests that the issues, including small datasets, highly heterogeneous data distribution, uncertainty calibration, and new clients, should be further organized and summarized. This feedback is clear and actionable, providing the authors with specific areas to improve the clarity and organization of their work. However, the comment could be more helpful if it included examples or suggestions on how to organize these issues. Overall, the comment is 4 as it guides the authors toward enhancing the presentation and comprehensiveness of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a gap in the paper regarding the incorporation of PACtuning with other finetuning techniques like pruning and data augmentation. However, it does not provide explicit guidance on how the authors should address this gap or what specific techniques should be explored. The action is implicit, as the authors need to infer that they should include results on these additional techniques, but it lacks concrete details on how to implement this. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to achieve it.", "grounding_specificity_rationale": "The comment highlights a specific area of the paper that lacks exploration, namely the incorporation of PACtuning with other finetuning techniques like pruning and data augmentation. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the gap in the exploration of PACtuning with other techniques, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no results exploring the incorporation of PACtuning with other finetuning techniques such as pruning and data augmentation. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper, noting that there are no results exploring the incorporation of PACtuning with other finetuning techniques such as pruning and data augmentation. This feedback is clear and actionable, as it highlights an area where the authors could enhance their work by expanding the scope of their experiments. However, the comment could be more helpful if it provided suggestions on how to approach this exploration or examples of relevant techniques. Overall, the comment is 4 as it directs the authors to a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "4", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the experimental analysis is insufficient and suggests that it should be validated on more models. It also mentions a specific question, \"Please see the fourth question below,\" which implies that the authors should address this issue. The comment provides a clear and direct action for the authors to take, which is to expand their experimental analysis to include more models. However, it does not provide specific guidance on which models to include or how to validate the analysis, leaving some room for interpretation. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment suggests that the experimental analysis is insufficient and should be validated on more models. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs improvement. Additionally, the comment does not provide specific guidance on which models should be included or how to validate the analysis, further limiting its specificity. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the experimental analysis is insufficient and suggests that it should be validated on more models. However, the comment does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental analysis, stating that it is insufficient and should be validated on more models. This feedback is clear and actionable, as it provides a direct suggestion for improvement. However, the comment lacks depth and does not offer specific guidance on which models should be included or how to enhance the analysis. While it points out a critical area for improvement, it does not fully empower the authors to make a comprehensive revision. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a specific issue with the proposed method, noting that while it improves over the original initialization, the motivation for this improvement is not fully explained. The comment suggests that the authors should provide a clearer rationale for the proposed method\"s effectiveness. However, it does not offer concrete guidance on how to address this issue or what specific aspects need clarification. The feedback is implicit and lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the comparison with the original initialization, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by highlighting the lack of motivation for the proposed method\"s improvement and the limited improvement observed in the ImageNet experiments. The mention of specific references (1 and 2) provides additional context, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method improves over the original initialization but lacks a clear motivation or detailed explanation. The comment references specific works (1 and 2) to support the claim, providing some context and evidence. However, the explanation is somewhat vague and lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to further explore the references to understand the basis of the claim fully. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that while it improves over the original initialization, the motivation for this improvement is not clearly explained. The comment highlights the lack of a clear rationale for the proposed method\"s effectiveness, which is a significant concern for the authors. Additionally, the comment points out that the ImageNet experiments do not demonstrate a substantial improvement over the baselines, which further questions the validity of the proposed method. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. While it highlights important areas for improvement, the feedback could be more helpful with actionable advice or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include a discussion on the robustness and immunizability of their proposed method compared to the method proposed in Yu et al. 2021. While the action is explicit, it lacks concrete details on how to conduct this comparison or what specific aspects should be discussed. The authors know that they need to add a discussion on robustness and immunizability, but they are not provided with specific guidance on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding a discussion on the robustness and immunizability of the proposed method compared to the method proposed in Yu et al. 2021. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in its suggestion to compare robustness and immunizability, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests adding a discussion on the robustness and immunizability of the proposed method compared to the method proposed in Yu et al. 2021. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this comparison is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests adding a discussion on the robustness and immunizability of the proposed method compared to the method proposed in Yu et al. 2021. This feedback is 3 as it identifies a specific area for improvement that could enhance the paper\"s contribution and understanding. However, the comment lacks depth and does not provide specific guidance on how to conduct this comparison or what aspects of robustness and immunizability should be discussed. While it points out a relevant area for improvement, the authors may need to infer the exact steps to take, making the feedback 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the postprocessing effort is not clear in footnote 2. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what specific information is missing or how the authors might clarify the postprocessing effort. As a result, the authors are left without a clear understanding of what steps to take to improve the draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"footnote 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity regarding the postprocessing effort. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point is a request for clarification regarding the postprocessing effort mentioned in footnote 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment points out a lack of clarity regarding the postprocessing effort mentioned in footnote 2. While it identifies a specific area of confusion, it does not provide any suggestions or guidance on how the authors might address this issue or clarify the postprocessing effort. The comment is 3 as it highlights a potential area for improvement, but it lacks depth and actionable advice, making it only 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to run their codes for multiple seeds and report the mean. This is a clear and direct action that the authors can take to improve their draft. The comment provides specific guidance on what needs to be done, making it 5. The authors know exactly what steps to follow to address the feedback provided.", "grounding_specificity_rationale": "The comment suggests running the codes for multiple seeds and reporting the mean, which is a specific request for improvement. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the results are discussed. The authors can infer that it relates to the experimental results or analysis section, but this inference is not as direct as it could be. Therefore, the comment is weakly grounded because it does not explicitly mention the section, but it is specific in its request for multiple runs and mean reporting. This aligns with a score of 3.", "verifiability_rationale": "The review point is a request for clarification, specifically asking the authors to run their codes for multiple seeds and report the mean. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information or analysis, making it a normal statement.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for the authors to improve their draft. It requests that the authors run their codes for multiple seeds and report the mean, which is a clear and direct request for additional information or analysis. This feedback is valuable as it helps the authors enhance the robustness and reliability of their results by ensuring consistency across different runs. However, the comment could be more helpful if it provided guidance on how to implement this request or why it is important. Despite this, the feedback is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup, as well as the absence of certain results in the tables. While it identifies specific areas of confusion, it does not provide explicit instructions or suggestions for the authors to address these issues. The authors can infer that they need to clarify these differences and include the missing results, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup, as well as the absence of certain results in the tables. It specifically mentions the absence of results for models like InceptionV3 and ResNet in Table 3, while Table 2 includes them. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which part of the paper these questions pertain to, such as the datasets or tables, which limits the authors\" ability to pinpoint the exact sections needing revision. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the differences between the BCI and IHC4BC datasets and the experimental setup, as well as the absence of certain results in the tables. These are factual inquiries that do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the differences between the BCI and IHC4BC datasets and the experimental setup, as well as the absence of certain results in the tables. It points out that Table 3 lacks results for models like InceptionV3 and ResNet, while Table 2 includes them. This feedback highlights specific areas where the paper may be unclear or incomplete, prompting the authors to clarify these points. However, the comment does not provide suggestions or guidance on how to address these issues, such as recommending additional experiments or clarifications. While it identifies areas for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly instructs the authors to provide a more thorough description of the results shown in Figure 4. This is a direct and clear action, leaving no ambiguity about what the authors need to do to improve their draft. The comment is specific, as it clearly identifies the part of the paper that needs attention and specifies the nature of the improvement required. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is providing a more thorough description of the results shown in Figure 4. This provides clear guidance on what the authors should do to improve their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors provide a more thorough description of the results shown in Figure 4. However, it does not offer any specific guidance or examples on how to achieve this, nor does it provide any rationale or evidence to support why this is necessary. The comment lacks detailed reasoning or examples, making it difficult for the authors to understand and address the feedback effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors provide a more thorough description of the results shown in Figure 4. This is a clear and actionable piece of feedback that directs the authors to enhance the clarity and detail of their results presentation. However, the comment does not specify what aspects of the results need to be expanded upon or how the authors might improve the description. While it points out a specific area for improvement, it lacks depth and specificity, making it 3. The authors would benefit from this feedback but would need to make further efforts to address it fully. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should compare their work with the most relevant literature, specifically mentioning \"work more in the method part\" or \"work in more details.\" While the comment provides a general direction for comparison, it does not specify which aspects of the method or work should be compared or how to implement this comparison. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the work with the most relevant literature, specifically mentioning \"work more in the method part\" or \"work in more details.\" However, it does not specify which part of the paper this comparison should be made in, nor does it provide detailed guidance on how to conduct the comparison. The authors can infer that it relates to the method section, but the lack of specific guidance makes it weakly grounded. The comment is specific in suggesting a comparison with relevant literature, but without clear instructions on how to implement it, it is not fully grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the most relevant literature is 11 and recommends comparing the work with this literature in the method part or in more detail. However, the comment does not provide specific reasoning or examples to support why this comparison is necessary or how it would benefit the paper. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the suggestion, rendering the claim 2. Therefore, the comment is classified as 2.", "helpfulness_rationale": "The review comment suggests that the authors should compare their work with the most relevant literature, specifically mentioning \"work more in the method part\" or \"work in more details.\" This feedback is 3 as it points out a potential area for improvement by suggesting a comparison with relevant literature, which could enhance the paper\"s context and relevance. However, the comment lacks specificity and does not provide detailed guidance on how to conduct this comparison or which aspects of the method should be emphasized. To be more helpful, the comment could include examples or specific sections where such comparisons should be made. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific survey that discusses the potential for legitimate shared words between English and languagespecific vocabulary. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their justification. The action is implicit, as the authors can infer that they need to provide a more robust justification for their process, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the process of removing words with identical English counterparts in the class label translation and cleaning, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by pointing out the potential lack of justification for this process and references a specific survey, \"Ten Years of BabelNet: A Survey,\" which provides context for the potential shared words between English and languagespecific vocabulary. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the justification for removing words with identical English counterparts in the class label translation and cleaning process. It references a specific survey, \"Ten Years of BabelNet: A Survey,\" which discusses the potential for legitimate shared words between English and languagespecific vocabulary. This reference provides a basis for the claim, as it highlights a potential issue with the authors\" approach. However, the comment could be strengthened by providing more detailed reasoning or examples from the survey to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the justification for the process of removing words with identical English counterparts in the class label translation and cleaning. It references a specific survey that discusses the potential for legitimate shared words between English and languagespecific vocabulary, which provides a basis for the claim. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve their justification. While it highlights an important area for consideration, the feedback lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the study should consider more models beyond LLaVA and InstructBLIP to verify the findings. While the comment implies that the authors should explore additional models, it does not provide specific guidance on which models to include or how to analyze them. The action is implicit and somewhat vague, as the authors need to infer the specific models to study and the methods to apply. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the study should consider more models beyond LLaVA and InstructBLIP to verify the findings. However, it does not specify which additional models should be studied or how this would impact the conclusions. The authors might infer that they need to explore more models, but the comment lacks specificity regarding which models to consider or how to analyze them. As a result, the comment is weakly grounded because it does not clearly identify the part of the paper being addressed, and it is not specific in detailing what needs to be addressed. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the study should consider more models beyond LLaVA and InstructBLIP to verify the findings. However, the comment lacks specific examples or references to other models that could be studied, making it difficult for the authors to understand the basis of the suggestion or how to implement it. Without detailed justification or evidence, the claim is considered 2, as it provides a general suggestion without sufficient support or explanation.", "helpfulness_rationale": "The review comment suggests that the study should consider more models beyond LLaVA and InstructBLIP to verify the findings. This feedback is 3 as it identifies a potential limitation in the study\"s scope and encourages the authors to explore additional models. However, the comment lacks specificity and does not provide guidance on which models to consider or how to analyze them. To be more helpful, the comment could include examples of other models that could be studied or suggest a methodology for expanding the analysis. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide a further explanation or exploration of the reason behind the significant reduction in the norm for OpenCLIP in Figure 7, despite the lack of significant improvement in object localization in Table 3. This feedback implies that the authors should clarify the discrepancy between the results shown in the figure and the table. While the action is not explicitly stated, it is clear and concrete, as it provides a specific direction for the authors to address the issue. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights a discrepancy between the results shown in the figure and the table, suggesting that further explanation or exploration is needed to understand the reason behind this discrepancy. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is a discrepancy between the results shown in Figure 7 and Table 3, specifically regarding the significant reduction in the norm for OpenCLIP and the lack of significant improvement in object localization. However, the comment does not provide any supporting evidence, reasoning, or references to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the discrepancy or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a discrepancy between the results shown in Figure 7 and Table 3, specifically regarding the significant reduction in the norm for OpenCLIP and the lack of significant improvement in object localization. It suggests that further explanation or exploration of this discrepancy is necessary for the paper to be more widely adopted. This feedback is clear and actionable, as it provides a specific area for the authors to address and improve their draft. However, the comment could be more helpful if it offered suggestions on how to explore or explain the discrepancy, such as recommending specific analyses or comparisons. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review comment highlights a lack of clarity regarding the use of 3D rendering in conjunction with G. It points out that while Section 3.3 explains how the latent code z is used to modulate the weights of the rendering network, it does not provide details on how the Point cloud is used in this stage. Additionally, the comment requests more information on how the 3D rendering and the GAN objective are combined. This feedback provides a clear and explicit action for the authors to take, which is to provide more detailed explanations and information in the relevant sections. The comment is specific about what needs to be clarified, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the use of 3D rendering and the GAN objective, requesting more details on how the Point cloud is used and how the 3D rendering and GAN objective are combined. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of how 3D rendering is used in conjunction with G, specifically regarding the use of the Point cloud and the combination of 3D rendering with the GAN objective. While the comment identifies a potential area of confusion, it does not provide specific examples or detailed reasoning to support the claim that the explanation is unclear. The lack of detailed justification or examples makes it difficult for the authors to fully understand and address the issue. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding the use of 3D rendering in conjunction with G. It points out that while Section 3.3 explains how the latent code z is used to modulate the weights of the rendering network, it does not provide details on how the Point cloud is used in this stage. Additionally, the comment requests more information on how the 3D rendering and the GAN objective are combined. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and information in the relevant sections. By addressing these points, the authors can improve the clarity and comprehensiveness of their draft, making the comment 5. Therefore, it is rated as a 5."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a concern about the increased hyperparameter complexity of the QIF model compared to the traditional LIF model. It notes that while parameter insensitivity is claimed, the supporting evidence is based on simple architectures and datasets, which is not convincing. However, the comment does not provide explicit guidance or suggestions on how the authors might address this issue or improve the evidence. The action is implicit, as the authors can infer that they need to provide more robust evidence or consider alternative approaches to validate the parameter insensitivity claim. The lack of concrete details makes the action somewhat vague, aligning with a score of 2.", "grounding_specificity_rationale": "The comment addresses the issue of increased hyperparameter complexity in the QIF model compared to the traditional LIF model. It highlights a concern about the claim of parameter insensitivity, noting that the supporting evidence is based on simple architectures and datasets. However, the comment does not specify which part of the paper discusses the QIF model or the specific hyperparameters introduced, making it weakly grounded. The comment is specific in detailing the issue of parameter insensitivity and the reliance on simple architectures and datasets. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the QIF model introduces additional hyperparameters, which is not supported by evidence based on complex architectures and datasets. The comment suggests that the supporting evidence is insufficient, as it relies on simple architectures and datasets. However, the claim lacks specific examples or detailed reasoning to substantiate the argument, making it 3. The authors would need to provide more evidence or examples to fully address the concern, which aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the QIF model, specifically the increased hyperparameter complexity compared to the traditional LIF model. It points out that while the claim of parameter insensitivity is made, the supporting evidence is based on simple architectures and datasets, which is not convincing. This feedback is 3 as it highlights a critical area that needs attention and provides a direction for improvement by suggesting that the authors should provide more robust evidence or consider alternative approaches to validate their claims. However, the comment could be more helpful if it offered specific suggestions on how to strengthen the evidence or alternative methods to address the issue. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method, despite achieving the largest improvements among competitors, could benefit from exploring further improvements using other large language models (e.g., RoBERTa, T5, Vicuna, or Llama2) instead of BERT. It also recommends discussing the meaningful aspects of the proposed method and experiments in the context of large language models, such as computational costs or realworld scenarios. While the comment provides a clear direction for further exploration and discussion, it does not explicitly instruct the authors to conduct these analyses or provide specific steps on how to implement them. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"proposed method\" and the \"competitors,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it suggests exploring further improvements using other large language models (e.g., RoBERTa, T5, Vicuna, or Llama2) and discusses the meaningful aspects of the proposed method and experiments in the context of large language models, such as computational costs or realworld scenarios. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of the proposed method\"s performance over baselines, suggesting that further improvements could be achieved with other large language models (e.g., RoBERTa, T5, Vicuna, or Llama2) instead of BERT. The reviewer provides a logical reasoning by suggesting that exploring these models could lead to better performance, which is a valid point. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore and justify these suggestions to fully understand the reasoning behind them. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the proposed method\"s performance over baselines, questioning whether further improvements could be achieved with other large language models (e.g., RoBERTa, T5, Vicuna, or Llama2) instead of BERT. It suggests exploring these models to potentially enhance performance, which is a meaningful and actionable suggestion for the authors to consider. Additionally, the comment prompts the authors to discuss the meaningful aspects of their method and experiments in the context of large language models, such as computational costs or realworld scenarios. This feedback is clear and constructive, providing the authors with a direction for further exploration and enhancing the depth of their analysis. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the explanation of using soft assignment instead of hard assignment is discussed in the methodology section, but it is unclear whether the authors have reported an experiment to prove their conjecture. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to infer that they should include an experiment to validate their conjecture, but it is vague because it does not specify how to conduct this experiment or what results to expect. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"description of the methodology,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of reporting an experiment to prove the conjecture about using soft assignment instead of hard assignment. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the explanation regarding the use of soft assignment instead of hard assignment, suggesting that the authors have not reported an experiment to prove their conjecture. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a gap in the paper by pointing out that the explanation of using soft assignment instead of hard assignment is discussed in the methodology section, but it is unclear whether the authors have reported an experiment to prove their conjecture. This feedback highlights a specific area where the paper lacks clarity and provides a clear suggestion for improvement by suggesting that the authors include an experiment to validate their conjecture. However, the comment could be more helpful if it offered guidance on how to design or conduct such an experiment. Overall, the comment is 3 as it directs the authors to a specific area needing clarification and provides a clear suggestion for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the applicability of the methods presented in the paper, specifically mentioning that they are mostly relevant in a crosssilo setting. However, it does not provide any explicit or implicit actions for the authors to take to address this limitation. There is no guidance on how the authors might expand the applicability of their methods to general federated learning problems or suggest ways to improve the methods to make them more broadly applicable. As a result, the comment lacks actionability, leaving the authors without any clear direction on how to improve their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the applicability of the methods presented in the paper, specifically mentioning that they are mostly relevant in a crosssilo setting. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the methods\" applicability could be improved or how the authors might address the limitation mentioned. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point critiques the applicability of the methods presented in the paper, specifically mentioning that they are mostly relevant in a crosssilo setting. However, the comment lacks specific examples or detailed reasoning to support the claim that the methods are limited to this setting. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the claim is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment critiques the applicability of the methods presented in the paper, specifically mentioning that they are mostly relevant in a crosssilo setting. This observation highlights a limitation in the paper\"s scope, which could be a valuable point for the authors to consider when expanding the applicability of their methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this limitation or improve the methods\" applicability to broader federated learning scenarios. While it identifies an area for improvement, the feedback lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about what constitutes distributional generalization in the context of regression. It suggests that in regression, the phenomenon might be less surprising because a smooth regression model interpolating the training data would naturally exhibit distributional generalization. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this question or incorporate it into their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about what constitutes distributional generalization in the context of regression. It provides a brief explanation, suggesting that in regression, the phenomenon might be less surprising due to the nature of smooth regression models interpolating the training data. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors might infer that it relates to the discussion or methodology sections, but this inference is not direct. The comment is specific in its question and reasoning but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about what constitutes distributional generalization in the context of regression. It provides a brief explanation, suggesting that in regression, the phenomenon might be less surprising due to the nature of smooth regression models interpolating the training data. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that distributional generalization is less surprising in regression. This makes the claim 3, as it provides a general observation but lacks the depth and specificity needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about what constitutes distributional generalization in the context of regression. It provides a brief explanation, suggesting that in regression, the phenomenon might be less surprising due to the nature of smooth regression models interpolating the training data. However, the comment lacks depth and does not offer specific guidance or suggestions on how the authors might address this question or incorporate it into their work. Without actionable feedback or detailed insights, the authors are left without a clear path forward for improvement. Therefore, the comment is not particularly helpful, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the references and baselines being out of date and the potential for obtaining many results by searching for items like \"Item Frequencies of Data Streams.\" While it points out these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to update their references and baselines to include more recent research and possibly explore alternative methods to avoid the issue of obtaining many results. However, the comment lacks concrete steps or suggestions on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment suggests that the references and baselines are out of date and recommends covering more recent research. It also mentions the ease of obtaining many results by searching for items like \"Item Frequencies of Data Streams.\" However, the comment does not specify which sections or parts of the paper are affected by these issues, making it difficult for the authors to pinpoint the exact areas needing revision. While the authors might infer that these issues pertain to the references and baselines sections, the lack of explicit grounding makes it challenging to address the feedback effectively. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the references and baselines are out of date and suggests that more recent research should be included. It also mentions the ease of obtaining many results by searching for items like \"Item Frequencies of Data Streams.\" However, the comment lacks specific examples or references to support the claim about the outofdate nature of the references and baselines. Additionally, it does not provide detailed reasoning or evidence to substantiate the ease of obtaining many results. This makes the claim 3, as the authors would need to infer the lack of support and may struggle to address the feedback effectively. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the current references and baselines, suggesting that they are out of date and do not include more recent research. It also points out a potential problem with the ease of obtaining many results by searching for items like \"Item Frequencies of Data Streams.\" While the comment highlights important areas for improvement, it lacks specific guidance or suggestions on how the authors might address these issues, such as recommending specific recent studies or providing alternative search strategies. This limits the comment\"s usefulness, as it provides insight into potential weaknesses but does not offer actionable steps for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a gap in the experimental analysis, noting that while the introduction discusses the computational challenges of scaling quadratic programs to highdimensional action spaces, the experimental analysis in Section 5 focuses on lowerdimensional spaces. The reviewer suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. This feedback provides a clear and explicit action for the authors to take, which is to conduct a more comprehensive analysis of ARAM\"s performance in highdimensional action spaces. The comment is specific and provides concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5\" and \"highdimensional action spaces,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of indepth analysis of ARAM\"s performance in highdimensional action spaces, particularly for complex robotic manipulators. The comment provides a clear direction for improvement by suggesting that the authors should conduct a more comprehensive analysis in this area. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a gap in the experimental analysis, noting that while the introduction discusses the computational challenges of scaling quadratic programs to highdimensional action spaces, the experimental analysis in Section 5 focuses on lowerdimensional spaces. The reviewer suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. This claim is 3 as it identifies a specific area where the experimental analysis could be improved, but it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to further explore and justify why this analysis is crucial, making the comment 3.", "helpfulness_rationale": "The review comment identifies a gap in the experimental analysis, noting that while the introduction discusses the computational challenges of scaling quadratic programs to highdimensional action spaces, the experimental analysis in Section 5 primarily focuses on lowerdimensional spaces. The reviewer suggests that the performance of ARAM in highdimensional action spaces, such as complex robotic manipulators, would benefit from more indepth analysis. This feedback is clear and actionable, as it highlights a specific area where the authors could enhance their experimental analysis. By addressing this gap, the authors can provide a more comprehensive understanding of ARAM\"s performance in complex scenarios, which is crucial for the paper\"s contribution. Therefore, the comment is 4, as it provides a clear direction for improvement but could be further enhanced with additional suggestions on how to conduct the analysis."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the experimental results, noting that there is no information on the computational cost required to achieve the observed performance. The reviewer suggests that the extra performance might be due to the increased number of parameters or computation. The comment implies that the authors should provide information on the computational resources used, such as the number of parameters or computation time, to better understand the results. However, it does not explicitly instruct the authors to include this information or provide specific guidance on how to present it. The action is implicit and somewhat vague, as the authors need to infer that they should include computational cost details but may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it highlights the lack of information regarding the computational cost required to achieve the observed results and suggests that the extra performance might be due to increased parameters or computation. The comment provides a clear direction for improvement by recommending that the authors consider the computational resources used. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are good but lacks information on the computational cost required to achieve them. The reviewer suggests that the extra performance might be due to increased parameters or computation. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or evidence makes the claim 3, as it requires further elaboration or evidence to be fully substantiated. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a gap in the experimental results by pointing out the lack of information on the computational cost required to achieve the observed performance. It suggests that the extra performance might be due to increased parameters or computation, and proposes that if the model had the same floats, the performance might be similar to the original transformers. This feedback is clear and actionable, as it directs the authors to consider and address the computational aspects of their experiments. However, it could be more helpful if it provided specific suggestions on how to measure or present the computational cost. Overall, the comment is 4, as it provides valuable insight into a potential area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment indicates that the evaluation and results are not convincing, with inconsistent trends and some improvements that are not statistically significant. However, it does not provide specific guidance on how the authors should address these issues or what changes could be made to improve the evaluation or results. The feedback lacks explicit instructions or concrete suggestions, leaving the authors uncertain about how to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the evaluation and results, noting that they are not convincing and that the results do not show consistent trends or statistically significant improvements. However, it does not specify which part of the paper this critique pertains to, such as specific sections or figures where the evaluation is discussed. Without explicit references to the paper, the authors cannot confidently determine which parts need revision. The comment is specific in its critique of the evaluation and results but lacks grounding, as it does not provide detailed guidance on what aspects need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the evaluation and results are not convincing, with inconsistent trends and some improvements that are not statistically significant. However, the comment lacks specific examples or detailed reasoning to support these claims. Without concrete evidence or references to specific data points, the authors may find it challenging to understand and address the issues raised. This makes the claim 3, as it provides a general critique but lacks the necessary details to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation and results of the paper, noting that they are not convincing and that the results do not consistently show trends or statistically significant improvements. This feedback is valuable as it highlights areas where the authors need to strengthen their analysis and results. However, the comment lacks specific suggestions or guidance on how to address these issues, such as recommending additional statistical tests or providing more detailed analysis. While it points out a critical weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point acknowledges that several questions require subjective answers and suggests that it would be useful to highlight the percentage of the error rate attributed to these subjective questions. It proposes looking at agreement among humans to determine the extent of this issue. While the comment provides a clear direction for the authors to consider, it lacks specific guidance on how to implement this suggestion, such as which questions are subjective or how to measure agreement among humans. The action is implicit and somewhat vague, making it 3.", "grounding_specificity_rationale": "The comment addresses the issue of subjective questions in the paper, suggesting that it would be useful to highlight the percentage of the error rate made up by these subjective questions. It implies that the authors should consider looking at agreement among humans to determine the extent of this issue. However, the comment does not explicitly mention which part of the paper discusses these subjective questions, making it weakly grounded. The comment is specific in suggesting a way to address the issue by examining agreement among humans, providing clear guidance on what needs to be done. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that several questions require subjective answers and suggests that it would be useful to highlight the percentage of the error rate attributed to these subjective questions. The reviewer provides a logical reasoning by suggesting that examining agreement among humans could help determine the extent of this issue. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to conduct further analysis to fully understand and address the issue, which justifies a score of 3.", "helpfulness_rationale": "The review comment acknowledges that several questions require subjective answers and suggests that it would be useful to highlight the percentage of the error rate attributed to these subjective questions. It proposes examining agreement among humans to determine the extent of this issue. While the comment provides a logical suggestion for improvement, it lacks specific guidance on how to implement this suggestion or which questions are subjective. This makes the feedback 3, as it offers a direction for the authors to consider but does not fully support their implementation. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the evaluation is weak, limited to a single dataset and a few NLP tasks, specifically intent recognition. It suggests that the paper would improve if additional NLP tasks, such as sentiment classification and namedentity recognition, were considered. This feedback provides a clear and direct action for the authors to take, specifying which tasks should be included to enhance the evaluation. The comment is explicit and concrete, giving the authors a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, noting that it is weak due to being limited to a single dataset and a few NLP tasks, specifically intent recognition. The comment further suggests improvements by recommending additional NLP tasks such as sentiment classification and namedentity recognition. This provides clear guidance on what needs to be addressed to enhance the evaluation. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is weak, limited to a single dataset and a few NLP tasks, specifically intent recognition. The reviewer suggests that the paper would improve if additional NLP tasks, such as sentiment classification and namedentity recognition, were considered. While the comment identifies a limitation in the evaluation, it lacks specific examples or references to support the claim that these additional tasks would significantly improve the evaluation. The suggestion for improvement is logical but could be more robust with additional evidence or references. Therefore, the comment is 3, as it provides a reasonable basis for the claim but lacks detailed justification.", "helpfulness_rationale": "The review comment identifies a significant weakness in the evaluation section of the paper, noting that it is limited to a single dataset and only a few NLP tasks, specifically intent recognition. It suggests that the paper would benefit from considering additional NLP tasks, such as sentiment classification and namedentity recognition, to enhance the evaluation. This feedback is clear and actionable, providing the authors with a specific direction for improving their work. However, the comment could be more helpful if it offered examples of how these additional tasks would improve the evaluation or suggested specific tasks to consider. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear path for enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests a correction to the labeling of a figure, specifically changing the label from \"c\" to \"s\". This is a direct and clear instruction for the authors to make a specific change to their draft. The action is explicit and concrete, providing the authors with a precise action to take. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be corrected, namely the labeling of the class semantic feature as \"s\" instead of \"c.\" This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point is a request for a correction in the labeling of a figure, specifically changing the label from \"c\" to \"s.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for clarification or correction, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it clearly identifies a potential error in the labeling of a figure. By suggesting that the class semantic feature should be labeled as \"s\" instead of \"c,\" the reviewer provides a direct and precise correction that the authors can easily implement. This feedback is valuable as it helps the authors improve the accuracy and clarity of their work. However, the comment could be more helpful if it included additional context or explanation about why this correction is necessary or how it impacts the overall understanding of the paper. Despite this, the comment is 4 as it provides a clear and actionable suggestion for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their method with stateoftheart face swapping algorithms to clarify the distinction between deidentification and face swapping. This feedback provides a clear and explicit action for the authors to take, which is to conduct a comparative analysis. The suggestion is concrete, as it specifies the type of comparison to be made, making it 5. Therefore, the comment is rated as 5.", "grounding_specificity_rationale": "The comment addresses the distinction between deidentification and face swapping, specifically mentioning the use of 3DMM in the target face. It suggests comparing the method with stateoftheart face swapping algorithms. However, the comment does not explicitly mention a specific section of the paper where this distinction is discussed, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting a comparison with existing face swapping algorithms, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method proposed in the paper is essentially a form of face swapping, similar to deepfake technology, but with a key difference in the target face being derived from a 3DMM. The reviewer suggests that the authors should compare their method with stateoftheart face swapping algorithms to clarify the distinction. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the method is similar to deepfake technology. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential confusion in the paper regarding the distinction between deidentification and face swapping. It points out that the method described in the paper appears to be similar to deepfake technology, with the key difference being the use of a 3DMM for the target face. The reviewer suggests that the authors should compare their method with stateoftheart face swapping algorithms to clarify this distinction. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their draft by conducting a comparative analysis. However, the comment could be more helpful if it included examples of stateoftheart face swapping algorithms or provided more detailed guidance on how to conduct the comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental results on word embeddings in Tables 1 and 2 are not as compelling as compared to Gaussian embeddings, which are considered the chief baseline from the literature. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the presentation of their results. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Tables 1 and 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the experimental results on word embeddings, noting that they are not as compelling as compared to Gaussian embeddings, which are considered the chief baseline from the literature. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results on word embeddings in Tables 1 and 2 are not compelling compared to Gaussian embeddings, which are considered the chief baseline from the literature. However, the comment does not provide specific examples, detailed analysis, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it lacks sufficient justification or evidence to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results on word embeddings, noting that they are not as compelling as compared to Gaussian embeddings, which are considered the chief baseline from the literature. This feedback is 3 as it highlights a potential weakness in the paper\"s results, prompting the authors to reconsider the significance of their findings. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or improve the presentation of their results. To be more helpful, the comment could include recommendations on how to enhance the comparison or clarify the results. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method is similar to previous studies, except for the task change to text summarization and the adjustment of the reward function. While it acknowledges the effectiveness of IRL in text summarization, it suggests that the contribution is small due to the limited differences from previous work. However, the comment does not provide explicit guidance or suggestions on how the authors could differentiate their method or enhance its contribution. The lack of actionable advice leaves the authors uncertain about how to address the feedback effectively. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous studies (Shi et al., 2018; Ghosh et al., 2021) and the specific task change to text summarization, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the contribution is small due to the limited differences from previous work. However, the comment could be more specific by suggesting ways to enhance the contribution or differentiate the proposed method from the previous studies. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is similar to previous studies, except for the task change to text summarization and the adjustment of the reward function. The reviewer supports this claim by referencing Shi et al., 2018 and Ghosh et al., 2021, which are relevant to the task of text summarization. However, the comment lacks specific examples or detailed reasoning to fully substantiate the claim, such as how the reward function was adjusted or how this change impacts the contribution. While the references provide some context, the overall argument is 3 due to the need for more detailed explanation or examples to fully support the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the originality of the proposed method, noting that it is similar to previous studies except for the task change to text summarization and the adjustment of the reward function. While the comment acknowledges the effectiveness of IRL in text summarization, it suggests that the contribution might be small due to the limited differences from previous work. However, the comment does not provide specific suggestions or guidance on how the authors could differentiate their method or enhance its contribution. This limits the usefulness of the feedback, as it offers insight into a potential weakness but lacks actionable advice for improvement. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a perceived limitation in the novelty of the paper, suggesting that the authors have combined multiple pieces to create the paper. It implies that the main contribution is a new ITrelated dataset. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the novelty of their work. The feedback lacks concrete steps or actionable advice, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the paper, suggesting that it seems to combine multiple pieces rather than presenting a new contribution. It implies that the main contribution is a new ITrelated dataset. However, the comment does not specify which parts of the paper are being discussed or how the authors might address the issue of novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is limited, suggesting that the authors have combined multiple pieces to create the paper. The reviewer implies that the main contribution is a new ITrelated dataset. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to the specific aspects of the paper that are being criticized, the authors may find it challenging to understand and address the feedback. Therefore, the comment is considered 2, as it provides a general critique but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a perceived limitation in the novelty of the paper, suggesting that the authors have combined multiple pieces to create the paper. It implies that the main contribution is a new ITrelated dataset. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or enhance the novelty of their work. Without detailed guidance or examples, the authors may struggle to understand the nature of the problem and how to improve their draft. Therefore, the comment is 2, as it points out a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper lacks an ablation study related to query embedding, which could provide insights into the significance and impact of this component. While the comment implies that the authors should include such a study, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment lacks specific guidance on how to conduct the ablation study or what aspects to focus on. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks an ablation study related to query embedding, which could provide insights into the significance and impact of this component. However, it does not specify which part of the paper should include this ablation study, making it weakly grounded. The comment is specific in suggesting the inclusion of an ablation study, but without clear guidance on where to place it or what aspects to focus on, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks an ablation study related to query embedding, which could provide insights into the significance and impact of this component. However, the comment does not provide any specific reasoning or examples to support why an ablation study is necessary or how it would benefit the paper. Without detailed justification or references, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting the inclusion of an ablation study related to query embedding. This is a clear and actionable piece of feedback that could enhance the paper\"s contribution and provide deeper insights into the significance of the query embedding component. However, the comment could be more helpful if it offered suggestions on how to conduct the ablation study or what aspects to focus on. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point expresses a concern that the contribution of the paper is marginal compared to previous works in 1, 2, 3. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve their contribution or what specific aspects need to be enhanced to make it more significant. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the marginal contribution of the paper compared to previous works in 1, 2, 3. However, it does not specify which part of the paper this concern pertains to, nor does it provide details on what aspects of the contribution might be marginal. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. Additionally, the comment lacks specificity regarding what aspects of the contribution are marginal or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the paper is marginal compared to previous works in 1, 2, 3. However, the comment does not provide any specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of this claim or how it impacts their work. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment expresses a concern that the contribution of the paper is marginal compared to previous works in 1, 2, 3. However, it lacks specificity and does not provide any actionable feedback or suggestions on how the authors might address this issue or enhance their contribution. Without detailed guidance or examples, the authors are left without a clear understanding of what needs to be improved or how to make their contribution more significant. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point consists of a question asking the authors to explain the loss of performance of w2gm against w2g in the analysis of SWCS. It does not provide any explicit or implicit actions for the authors to take, such as suggesting improvements or clarifications. The comment lacks guidance on how the authors should address this question or what specific aspects they should consider. As a result, the authors are left without any actionable steps to follow, making the comment 1.", "grounding_specificity_rationale": "The comment consists of a question asking the authors to explain the loss of performance of w2gm against w2g in the analysis of SWCS. It does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section being addressed. Additionally, the comment lacks specificity as it does not provide details on what aspects of the performance loss need to be clarified or addressed. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question seeking clarification about the performance loss of w2gm against w2g in the analysis of SWCS. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment consists of a question seeking clarification about the performance loss of w2gm against w2g in the analysis of SWCS. While it identifies a potential area of confusion, it does not provide any actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address the issue or what specific aspects to consider. As a result, it offers limited value to the authors in terms of improving their draft, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a gap in the paper regarding the evaluation of overoptimization. It suggests that the paper should instead focus on calibration and human evaluation, which is a different approach from the current focus. The reviewer also points out that current works, such as AlignProp, address the overoptimization issue with early stopping, but this is not discussed in the paper. The comment implies that the authors should consider evaluating the tradeoffs of not using early stopping and discuss the benefits of this approach. While the comment provides a clear direction for improvement, it lacks specific guidance on how to implement this change or what specific aspects to focus on. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on overoptimization and suggests that the evaluation should instead focus on calibration and human evaluation. It also mentions the need to discuss the benefits of not using early stopping, referencing current works like AlignProp. However, the comment does not specify which part of the paper discusses overoptimization or where the evaluation is performed, making it weakly grounded. The comment is specific in suggesting improvements and providing references, but without explicit grounding, it is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper does not directly evaluate for overoptimization, which is a concern. It suggests that the paper instead evaluates for calibration and human evaluation, and points out that current works like AlignProp address the overoptimization issue with early stopping. The comment provides a logical reasoning by referencing a specific work (AlignProp) to support the claim, making it 4. However, it could be strengthened by providing more detailed examples or further elaboration on the evaluation methods. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical gap in the paper\"s evaluation of overoptimization. It suggests that the paper should focus on calibration and human evaluation instead of overoptimization, which is a more nuanced and comprehensive approach. The comment also references a relevant work, AlignProp, to illustrate the issue of overoptimization with early stopping, providing a concrete example for the authors to consider. Additionally, it suggests discussing the benefits of not using early stopping, which could enhance the paper\"s contribution. While the comment highlights important areas for improvement, it could be more helpful by offering specific suggestions on how to address these issues or by providing guidance on how to incorporate the referenced work into the paper. Overall, the comment is 4 as it directs the authors toward a more comprehensive evaluation approach, but it could be more detailed to be fully actionable."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should analyze and discuss the equivalence between the proposed TW model and the TR model, specifically by showing that the core tensor C can be represented by a TR and then fused with the cores G_n to reach an equivalent TR representation. The reviewer explicitly states that this analysis should be included in the paper and provides a clear suggestion for how to implement it. The comment is explicit and concrete, giving the authors a specific action to take and a clear understanding of how to apply it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the proposed TW model is equivalent to TR by noting that the core tensor C can be represented by a TR and then fused with the cores G_n to reach an equivalent TR representation. It implies that the authors should include this analysis in the paper and discuss why TW is considered better than TR. However, the comment does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting the need for this analysis and discussion, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed TW model is equivalent to TR by suggesting that the core tensor C can be represented by a TR and then fused with the cores G_n to reach an equivalent TR representation. The reviewer suggests that this analysis should be included in the paper and discusses why TW might be considered better than TR. However, the comment lacks specific examples, detailed reasoning, or references to support the claim that the TW model is equivalent to TR. This makes the claim 3, as the authors would need to provide more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential equivalence between the proposed TW model and the TR model, suggesting that the authors should include an analysis of this equivalence in the paper. It also implies that the authors should discuss why the TW model might be considered better than the TR model. This feedback is clear and actionable, as it provides a specific area for the authors to expand upon in their draft. However, the comment could be more helpful if it offered suggestions on how to conduct this analysis or what aspects of the equivalence should be emphasized. Overall, the comment is 4, as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should discuss the transferability of the toolset by noting that the toolset for the VQA task and the reasoning task are not the same. It implies that the authors could experiment to create a general tool set for all tasks and observe the outcomes. While the comment provides a clear direction for the authors to take, it does not specify how to conduct this experiment or what specific aspects to focus on. The action is explicit but somewhat vague in terms of execution, making the comment 4.", "grounding_specificity_rationale": "The comment suggests discussing the transferability of the toolset, noting that the toolset for the VQA task and the reasoning task are not the same. It implies that the authors could experiment to create a general tool set for all tasks. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of the toolset or the methodology section. The comment is specific in suggesting an experiment to create a general tool set, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the transferability of the toolset should be discussed, noting that the toolset for the VQA task and the reasoning task are not the same. The reviewer proposes an experiment to create a general tool set for all tasks. While the comment identifies a potential area for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to experiment is logical, but without further elaboration or evidence, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the transferability of the toolset should be discussed. It points out that the toolset for the VQA task and the reasoning task are not the same, implying that the authors could experiment to create a general tool set for all tasks. This feedback is clear and actionable, as it provides a specific suggestion for enhancing the paper\"s discussion on toolset transferability. However, the comment could be more helpful if it included examples of how to conduct such an experiment or what specific aspects of the toolset should be considered. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests evaluating the model\"s performance using multiple random feature orders as a way to assess the impact of feature order variability without the need for a complex controller. It implies that this approach could help determine whether the benefits of feature reordering are due to the specific order found by the metacontroller or can be achieved by exposing the model to diverse orders. However, the comment does not provide explicit instructions or concrete steps on how to implement this suggestion, leaving the authors to infer the exact actions needed. The action is implicit and somewhat vague, as it lacks detailed guidance on how to execute the proposed evaluation. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests evaluating the model\"s performance using multiple random feature orders to assess the impact of feature order variability. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where this evaluation could be implemented. While the authors might infer that it relates to the methodology or results sections, the lack of explicit grounding makes it difficult to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion but weakly grounded due to the absence of explicit references. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests evaluating the model\"s performance using multiple random feature orders to assess the impact of feature order variability. The comment provides a logical reasoning for this suggestion, explaining that it could help determine if the benefits of feature reordering are due to the specific order found by the metacontroller or can be achieved by exposing the model to diverse orders. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the rationale to fully understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests evaluating the model\"s performance using multiple random feature orders to assess the impact of feature order variability. This approach could help determine whether the benefits of feature reordering are due to the specific order found by the metacontroller or if they can be achieved by exposing the model to diverse orders. While the comment provides a logical suggestion for improving the evaluation process, it lacks specific guidance or examples on how to implement this suggestion. The authors would need to infer the exact steps to take, which limits the comment\"s helpfulness. Therefore, it is 3, as it offers a direction for improvement but lacks detailed instructions."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out that the related work section is severely lacking, particularly in terms of missing references and the omission of lexically constrained decoding methods. This feedback provides a clear and direct action for the authors to take, which is to address the issue of missing references and include lexically constrained decoding methods in both the related work section and as baselines for comparison. The comment is specific and provides concrete guidance on what needs to be done to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"related work section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of references and the omission of lexically constrained decoding methods in both the related work and as baselines for comparison. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the related work section is severely lacking, particularly in terms of missing references and the omission of lexically constrained decoding methods. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the extent of the issue or how to address it. The lack of detailed justification or evidence makes the claim 2, as it provides some indication of the problem but lacks the necessary details to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant issue with the related work section, specifically noting its lack of references and the omission of lexically constrained decoding methods. This feedback is clear and actionable, as it highlights a critical area that needs attention to strengthen the paper\"s context and relevance. By pointing out the absence of these elements, the comment provides the authors with a specific direction to improve their draft, potentially enhancing the paper\"s comprehensiveness and impact. However, the comment could be more helpful if it offered suggestions on how to incorporate these references or methods into the related work section. Overall, the feedback is 4 as it directs the authors\" attention to an important aspect of their work that needs enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out that the comparison is not comprehensive due to the absence of important baseline models and datasets. It explicitly mentions specific models, SimVLM and OFA, which the authors should include to enhance the comprehensiveness of the comparison. This feedback provides a clear and explicit action for the authors to take, namely to add these models to their comparison. The comment is specific and concrete, giving the authors a direct path to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights a specific issue with the comprehensiveness of the comparison due to the absence of important baseline models and datasets. It explicitly mentions \"SimVLM\" and \"OFA,\" providing clear guidance on which models should be included. However, it does not specify which part of the paper discusses these comparisons, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but the lack of grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the comparison is not comprehensive due to the absence of important baseline models and datasets. It provides specific references to \"SimVLM\" and \"OFA,\" which are models that should be included in the comparison. This level of detail supports the claim by offering concrete examples of missing models, making the comment 4. However, the comment could be strengthened by explaining why these specific models are important and how their inclusion would enhance the comprehensiveness of the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the comprehensiveness of the comparison due to the absence of important baseline models and datasets. By explicitly mentioning specific models like \"SimVLM\" and \"OFA,\" the comment provides clear guidance on what the authors should include to enhance the comprehensiveness of their comparison. This feedback is actionable and offers a concrete suggestion for improvement, making it 5 for the authors to address the weaknesses in their draft. Therefore, the comment deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the manuscript is framed as a dataset paper but lacks new data collection or release. It highlights that the paper presents derivative data, specifically 3D pose estimates from existing datasets, which is disappointing for readers seeking a new data source. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the manuscript. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the manuscript\"s framing as a dataset paper but points out that it lacks new data collection or release, instead presenting derivative data. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the manuscript\"s content, but it lacks grounding as it does not reference a particular section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the manuscript is framed as a dataset paper but lacks new data collection or release, instead presenting derivative data. The reviewer provides a logical reasoning by stating that the paper presents 3D pose estimates from existing datasets, which is disappointing for readers seeking new data. However, the comment does not provide specific examples or references to support the claim that the data is derivative or lacks new data collection. This lack of detailed evidence or references makes the claim 3, as the authors may find it challenging to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the manuscript\"s framing as a dataset paper, noting that it lacks new data collection or release. Instead, it presents derivative data, specifically 3D pose estimates from existing datasets. This critique is clear and highlights a critical aspect of the manuscript\"s content, which is important for readers seeking new data sources. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the manuscript. While it points out a problem, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point criticizes Lsoftmax and Asoftmax for requiring an annealinglike training procedure, but it notes that this method has a very specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this critique or improve their draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques Lsoftmax and Asoftmax for requiring an annealinglike training procedure, but it does not specify which part of the paper this critique is based on. The authors might infer that it relates to the methodology or experimental setup, but this inference is not direct. The comment also mentions \"experiments on CIFAR and Face Verification,\" which provides some grounding, but it does not specify which part of the paper these experiments are discussed in. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that Lsoftmax and Asoftmax require an annealinglike training procedure, but this method has a very specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. The lack of detailed explanation or justification makes it difficult for the authors to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the use of Lsoftmax and Asoftmax for requiring an annealinglike training procedure, noting that this method has a very specific learning rate schedule for experiments on CIFAR and Face Verification. However, the comment does not provide any suggestions or guidance on how the authors might address this critique or improve their draft. It lacks actionable feedback or constructive advice, leaving the authors without a clear path for improvement. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the focus of the analysis, suggesting that the authors should delve deeper into the analysis of the results themselves rather than just comparing AE to diffusion. It specifically asks for insights into which elements are crucial for detecting a chair, such as the handle transformation and its consistency across different chairs. The comment implies that the authors should provide more detailed analysis of the visualizations to address these questions. However, it does not explicitly instruct the authors to conduct this analysis or provide specific guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct a deeper analysis of the visualizations. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the focus of the quantitative and qualitative analysis, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by questioning the analysis of the results, particularly regarding the detection of a chair and the crucial elements involved. The comment provides specific questions about the handle transformation and its consistency across different chairs, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the focus of the analysis, suggesting that the authors should explore the analysis of the results themselves rather than just comparing AE to diffusion. The comment provides specific questions about the handle transformation and its consistency across different chairs, which could be addressed with further analysis. However, the comment lacks detailed reasoning or references to support the claim that the current analysis is insufficient. While it identifies a potential area for improvement, the lack of specific examples or references makes it 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s analysis, specifically focusing on the comparison between AE to diffusion and the more profound idea of analyzing the results themselves. It raises questions about the visualizations, asking what can be learned from them regarding crucial elements for detecting a chair, such as the handle transformation and its consistency across different chairs. This feedback is 3 as it prompts the authors to consider a deeper analysis of their results, potentially leading to more insightful conclusions. However, the comment could be more helpful if it provided specific suggestions or guidance on how to conduct this analysis or what aspects to focus on. Overall, the comment offers a direction for improvement but lacks detailed actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly questions the wording used in the beginning of Section 2.2, suggesting that the competitive ratio should be \"at most $b$\" instead of \"at least $b$\". This is a clear and direct action for the authors to take, as it specifies exactly what needs to be corrected. The comment provides concrete guidance on how to implement the change, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the beginning of Section 2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the wording regarding the competitive ratio, questioning whether it should be \"at most $b$\" instead of \"at least $b$.\" The comment provides a detailed explanation of the potential issue and its implications, making it easy for the authors to understand and address the concern. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the wording used in the beginning of Section 2.2, specifically regarding the competitive ratio. It suggests that the ratio should be \"at most $b$\" instead of \"at least $b$.\" The comment provides a logical reasoning by explaining the implications of this change, particularly in the worstcase scenario where x=1, leading to a ratio of b. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the issue.", "helpfulness_rationale": "The review comment identifies a specific issue in the wording used in the beginning of Section 2.2, questioning the use of \"at least\" instead of \"at most\" in the context of a competitive ratio. It provides a clear and actionable suggestion to correct the wording, which is crucial for accurately representing the concept of a competitive ratio. By addressing this issue, the authors can improve the clarity and correctness of their paper. However, the comment could be more helpful if it included additional context or explanation on why this correction is important. Overall, the feedback is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that there is a missing proper expression for the third face image in Figure 2. This provides a clear and direct action for the authors to take, which is to provide the correct expression for the image. The comment is specific and gives precise guidance on what needs to be addressed, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, which is the proper expression for the third face image in Figure 2. This provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that there is a missing proper expression for the third face image in Figure 2. However, it does not provide any reasoning, examples, or references to support this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the absence of a proper expression for the third face image in Figure 2. This is a clear and actionable piece of feedback that directly points out a missing element in the paper. By addressing this issue, the authors can improve the completeness and accuracy of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to express the image properly. Overall, the comment is 3 as it highlights a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This feedback provides a clear and explicit action for the authors to take, as it specifies what additional information should be included in the paper. The suggestion is concrete, as it outlines a specific comparison that could enhance the paper\"s content. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where such an example would be relevant. This lack of grounding makes it difficult for the authors to pinpoint where to make the suggested change. While the suggestion is specific in terms of what could be improved, the absence of grounding makes it challenging to address effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests including an example created by BERT and comparing it with one created by the proposed model. However, it does not provide any supporting evidence, reasoning, or references to justify why this comparison would be beneficial or necessary. The lack of detailed explanation or examples makes it difficult for the authors to understand the rationale behind the suggestion. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests including an example created by BERT and comparing it with one created by the proposed model. This feedback is 3 as it provides a specific suggestion for enhancing the paper by adding a comparative analysis. However, the comment lacks depth and does not explain why this comparison would be beneficial or how it would improve the paper. It also does not offer guidance on how to implement this suggestion or what aspects of the comparison would be most valuable. While it points out a potential area for improvement, the comment could be more actionable and detailed to be fully helpful. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point suggests that the dataset sizes for the code summarization and code search tasks should be the same to demonstrate that Vault is better in terms of data quality than CSN. This feedback provides a clear and explicit action for the authors to take, which is to ensure that the dataset sizes are balanced for these tasks. The comment is specific in its request, as it clearly states what needs to be done to address the issue. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"code summarization task\" and the \"code search task,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need for the dataset sizes of Vault and CSN to be the same to demonstrate that Vault is better in terms of data quality than CSN. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the dataset sizes for the code summarization and code search tasks should be the same to demonstrate that Vault is better in terms of data quality than CSN. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would demonstrate the superiority of Vault. Without additional context or explanation, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental setup, noting that the dataset sizes for the code summarization and code search tasks should be the same to effectively demonstrate that Vault is better in terms of data quality compared to CSN. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to ensure consistency in their dataset sizes, which is crucial for a fair and accurate comparison. By addressing this issue, the authors can improve the validity and reliability of their experimental results. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies specific areas where the paper lacks clarity, namely the explanation of important concepts like \"actionrepeat\" and the \"dithering phenomenon.\" It explicitly suggests that these terms should be explained more carefully. While the comment does not provide explicit instructions on how to improve the explanations, it does offer a clear direction for the authors to enhance the clarity of their paper. The action is implicit but concrete, as the authors know they need to provide more detailed explanations for these concepts. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment identifies specific concepts that are not wellexplained in the paper, such as \"actionrepeat\" and the \"dithering phenomenon.\" However, it does not specify which part of the paper these concepts are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the need for clearer explanations of these concepts. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that certain concepts, such as \"actionrepeat\" and the \"dithering phenomenon,\" are not wellexplained in the paper. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the exact issues or how to address them. The lack of detailed justification or examples renders the claim 1, as it does not provide sufficient evidence or reasoning to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity, particularly in the explanation of important concepts like \"actionrepeat\" and the \"dithering phenomenon.\" By pointing out these gaps, the comment provides the authors with a clear direction for improving the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to explain these concepts or provided examples of how to do so effectively. Overall, the feedback is 3 as it highlights areas needing attention but lacks depth and actionable guidance for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests an alternative approach for generating and encoding instructions, proposing a method that avoids discretization by using instruction embeddings and an auxiliary objective. The comment provides a specific action for the authors to consider, which is to create an instruction embedding from the state encoding and pass it directly to the executor. It also suggests adding an auxiliary objective to bring the instruction encoding closer to the gold standard. This feedback is explicit and provides concrete steps for the authors to follow, making it 5.", "grounding_specificity_rationale": "The comment provides a specific suggestion for an alternative approach to generating and encoding instructions, which could potentially improve the methodology. However, it does not explicitly mention which part of the paper this suggestion relates to, such as a specific section or figure. The authors can infer that it pertains to the methodology or experimental setup, but this inference is not as direct as it could be. The comment is specific in detailing the proposed changes and the rationale behind them, but it lacks grounding as it does not specify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with the label 3.", "verifiability_rationale": "The review point suggests an alternative approach for generating and encoding instructions, proposing a method that avoids discretization by using instruction embeddings and an auxiliary objective. The comment provides a logical reasoning for why this approach might be better, as it avoids potential issues with discretization and decoding errors. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and validate this suggestion on their own, which limits the verifiability score. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the methodology of the paper. It proposes an alternative approach to generating and encoding instructions, avoiding discretization by using instruction embeddings and an auxiliary objective. This feedback is clear and offers a concrete way for the authors to enhance their work, potentially leading to better results by reducing the risk of errors due to discretization. The suggestion is welljustified and provides a constructive path for improvement, making it 5 for the authors. Therefore, the comment deserves a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment states that the novelty of the proposed model is not significant, but it does not provide any guidance or suggestions on how the authors might address this issue or enhance the novelty of their model. There is no explicit or implicit action for the authors to take, and no concrete details on how to improve the novelty. As a result, the comment lacks actionability, leaving the authors without any direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment states that the novelty of the proposed model is not significant, but it does not specify which part of the paper this claim pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this feedback is relevant. Additionally, the comment lacks specificity regarding what aspects of the model\"s novelty are lacking or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the proposed model is not significant. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the novelty of the proposed model is not significant, which is a critical observation for evaluating the originality and impact of the work. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or enhance the novelty of their model. Without actionable feedback or detailed examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, as it identifies a potential weakness but does not offer constructive advice for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the dataset\"s class distribution might make it easier for the model to classify certain numbers, potentially leading to misleading accuracy metrics. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or improve the dataset. The comment implies that the authors should consider alternative metrics or methods to evaluate the model\"s performance, but it lacks concrete steps or examples. As a result, the action is implicit and vague, making it difficult for the authors to know how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the dataset\"s class distribution, specifically mentioning the proportions of certain numbers like 9, 6, and 7. This provides some grounding as it refers to specific elements of the dataset. However, the comment does not explicitly mention which part of the paper discusses the dataset or the classification task, making it weakly grounded. The comment is specific in detailing the issue with the class distribution and the potential impact on accuracy, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset\"s class distribution makes it easier for the model to classify certain numbers, potentially leading to misleading accuracy metrics. The reviewer provides specific examples, such as the low number of observations for certain classes (e.g., 9, 6, and 7), which could indeed affect the accuracy. However, the comment lacks detailed reasoning or references to support the claim fully. While the examples are relevant, the lack of a comprehensive explanation or additional context makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the dataset\"s class distribution, suggesting that the proportions of certain classes might make the dataset easier to classify, potentially leading to misleading accuracy metrics. The reviewer provides specific examples, such as the low number of observations for certain classes, which could indeed affect the model\"s performance. This feedback is 3 as it highlights a potential issue with the dataset\"s composition and suggests that the authors should consider alternative metrics or methods to evaluate the model\"s performance. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of alternative metrics. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the importance of showing that prediction may have strategic aspects but does not provide explicit guidance on how to address this. It raises questions about the \"true\" payoff in Table 1, suggesting that the test set payoff or population empirical payoff might be more relevant. Additionally, it mentions a similarity to Vapnik\"s work on teaching a learner with side information, implying that the authors should consider this aspect. While the comment highlights areas for improvement, it lacks specific instructions or concrete steps for the authors to take. The authors can infer that they need to clarify the payoff in Table 1 and explore the connection to Vapnik\"s work, but the comment does not provide detailed guidance on how to implement these changes. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the \"true\" payoff in Table 1 and suggesting that the test set payoff or population empirical payoff might be more relevant. Additionally, it raises a question about the similarity to Vapnik\"s work on teaching a learner with side information, providing a clear direction for the authors to consider. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that \"prediction is not done in isolation\" and suggests that the paper does not adequately demonstrate the \"main\" contribution of showing that the task of prediction may have strategic aspects. The reviewer provides specific questions about the \"true\" payoff in Table 1, suggesting that the test set payoff or population empirical payoff might be more relevant. Additionally, the reviewer draws a connection to Vapnik\"s work on teaching a learner with side information, implying a similarity to the current work. This provides some level of support for the claim, as it highlights specific areas where the paper could be improved. However, the comment could be strengthened by providing more detailed reasoning or references to substantiate the claim fully. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment acknowledges the importance of showing that prediction may have strategic aspects but questions the paper\"s demonstration of this contribution. It raises specific questions about the \"true\" payoff in Table 1, suggesting that the test set payoff or population empirical payoff might be more relevant. Additionally, it draws a connection to Vapnik\"s work on teaching a learner with side information, implying a similarity to the current work. This feedback provides the authors with specific areas to clarify and improve, such as the payoff analysis in Table 1 and the relevance of the strategic aspects of prediction. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to incorporate the feedback into the draft. Overall, the comment is 3 as it identifies areas for improvement but lacks detailed guidance, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the proposed method, which focuses on domainalignment methods, should explore another UDA method based on selftraining. This feedback provides a clear and explicit action for the authors to take, which is to consider incorporating selftraining into their method. The suggestion is concrete, as it specifies the type of UDA method to explore, making it 5.", "grounding_specificity_rationale": "The comment suggests exploring another UDA method based on selftraining, implying that the authors should consider incorporating selftraining into their proposed method. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or method discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting an alternative approach but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that selftraining is a prominent and effective approach within unsupervised domain adaptation (UDA) but suggests that the proposed method, which focuses on domainalignment methods, should explore another UDA method based on selftraining. This claim is 3 as it highlights a potential area for improvement by suggesting the exploration of selftraining in UDA. However, the comment lacks specific examples or references to support the claim that selftraining is prominent or effective, which would strengthen the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by suggesting that the proposed method, which focuses on domainalignment methods, should explore another UDA method based on selftraining. This feedback is clear and actionable, as it provides a specific direction for the authors to consider in their work. By recommending the exploration of selftraining in UDA, the comment offers a concrete suggestion that could enhance the comprehensiveness and effectiveness of the proposed method. However, the comment could be more helpful if it provided additional context or examples of how selftraining could be integrated into the method. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the reliability diagrams, suggesting that the proposed methods do not appear to perform better than a perfect system. It also points out potential pathologies in the diagrams, such as highaccuracy spikes in low confidence regimes, and asks whether these are due to dataset pathologies or variance/unpredictability in the methods. While the comment identifies an issue with the reliability diagrams, it does not provide explicit guidance on how the authors should address this concern or improve their analysis. The action is implicit and somewhat vague, as the authors are left to infer that they need to further investigate or clarify the pathologies in the diagrams. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 1, top,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the reliability of the proposed methods based on the accuracy vs confidence plots and highlights potential pathologies in the diagrams, such as highaccuracy spikes in low confidence regimes. The comment seeks clarification on whether these pathologies are due to dataset or methodrelated issues. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reliability of the proposed methods based on the accuracy vs confidence plots, suggesting that the observed pathologies might be due to dataset or methodrelated issues. The comment provides a logical reasoning by pointing out the potential pathologies in the diagrams, such as highaccuracy spikes in low confidence regimes. However, it lacks specific examples or references to support the claim that these pathologies are due to dataset or methodrelated issues. This makes the claim 3, as the authors would need to further investigate and provide evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the reliability of the proposed methods, specifically regarding the accuracy vs confidence plots. It points out potential pathologies in the diagrams, such as highaccuracy spikes in low confidence regimes, and asks whether these are due to dataset or methodrelated issues. This feedback is valuable as it prompts the authors to thoroughly examine and clarify the reliability of their methods, which is crucial for the validity of their results. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these pathologies or improve the analysis. Overall, the comment is 4 as it identifies a significant area for improvement and encourages the authors to conduct a more detailed investigation."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a potential weakness in the paper regarding the evaluation of advanced attacks, specifically mentioning that the current evaluation does not account for attackers who could finetune on a partial subset of the dataset D. It suggests that the paper only considers the detection of backdoor attacks and does not discuss the removal of such attacks, which is a significant area for improvement. While the comment identifies a gap in the evaluation, it does not provide specific guidance on how to address this issue or suggest alternative methods for evaluation. The action is implicit and somewhat vague, as the authors need to infer that they should consider evaluating more advanced attack scenarios and discuss backdoor removal methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation of advanced attacks and the detection of backdoor attacks, allowing the authors to identify the specific parts of the paper being addressed. It is also specific because it details the issue with the current evaluation, suggesting that the paper does not account for attackers who could finetune on a partial subset of the dataset D and that it does not discuss backdoor removal methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper does not evaluate advanced attacks beyond those mentioned, specifically highlighting the potential issue of an attacker finetuning on a partial subset of the dataset D. The reviewer provides a logical reasoning by suggesting that this could still leave the backdoor intact, making it difficult for customers to verify misbehaviors. Additionally, the comment points out that the paper only considers the detection of backdoor attacks and does not discuss removal methods, which are part of the SOTA (stateoftheart) methods. This provides a clear rationale for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim about the evaluation of advanced attacks. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that it does not evaluate advanced attacks beyond those mentioned, such as attackers who could finetune on a partial subset of the dataset D. This is a critical issue because it could leave the backdoor mechanism vulnerable, making it difficult for customers to verify misbehaviors. The comment also highlights that the paper only considers the detection of backdoor attacks and does not discuss removal methods, which are part of the stateoftheart (SOTA) methods. This feedback is clear and actionable, as it directs the authors to address these limitations in their evaluation and discussion. However, the comment could be more helpful if it provided specific suggestions on how to evaluate advanced attacks or discuss removal methods. Overall, the comment is 4, as it effectively identifies areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of the original adjacency matrix in the paper, suggesting that it deviates from the conventional graph convolutional operation used in the original GCN (Kipf and Welling). However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider using the conventional graph convolutional operation, but it lacks concrete steps or details on how to implement this change. As a result, the action is implicit and vague, making it difficult for the authors to know what specific changes to make. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the use of the original adjacency matrix in the proposed method, contrasting it with the conventional graph convolutional operation used in the original GCN (Kipf and Welling). However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the issue of not using the conventional graph convolutional operation and questioning the reason behind this choice. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of the original adjacency matrix in the paper, contrasting it with the conventional graph convolutional operation used in the original GCN (Kipf and Welling). The comment suggests that the authors should consider using the conventional graph convolutional operation, but it does not provide specific reasoning or evidence to support this claim. Without detailed justification or examples, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the critique. Therefore, the comment is categorized as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the use of the original adjacency matrix in the paper, questioning the reason behind not using the conventional graph convolutional operation. This feedback is 3 as it prompts the authors to consider the implications of their choice and potentially explore alternative approaches. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending an ablation study or providing a rationale for their choice. While it identifies a potential weakness, it does not offer actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the inconsistency in the provision of links for WMT\"15 training corpora but not for WMT\"14. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether this is a problem that needs addressing or if it is intentional. Without any suggestions or recommendations, the authors are left without a clear understanding of what to do in response to this observation. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the inconsistency in the provision of links for WMT\"15 training corpora but not for WMT\"14. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to identify the exact section that needs attention. The lack of specific details about the content or context of the links makes it challenging to provide a clear and actionable response. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the inconsistency in the provision of links for WMT\"15 training corpora but not for WMT\"14. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the inconsistency in the provision of links for WMT\"15 training corpora but not for WMT\"14. While it identifies a potential issue, it does not provide any guidance or suggestions on how the authors might address this inconsistency or why it is important. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it points out a potential issue but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights the importance of knowing the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. However, it does not provide any explicit guidance or suggestions on how the authors should determine these bounds or how they can be used to select other hyperparameters. The comment lacks concrete details or actionable steps, leaving the authors uncertain about how to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the need to know the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where these matrices are discussed. Without explicit references, the authors may find it challenging to identify the exact part of the paper that needs attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on where to address the concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the necessity of knowing the upper and lower bounds for adaptive matrices A_t and B_t to select other hyperparameters. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the necessity of knowing the upper and lower bounds for adaptive matrices A_t and B_t in order to select other hyperparameters. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their methodology. The comment lacks depth and actionable advice, leaving the authors without clear direction on how to enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the paper is not particularly high, as most techniques used were proposed and demonstrated before. It suggests that the authors consider adding experimental results on the PDBbind dataset. While the comment implies that the authors should include these results, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include experimental results on the PDBbind dataset. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the novelty of the paper is not particularly high and questions the use of techniques that were previously proposed and demonstrated. It also requests experimental results on the PDBbind dataset. However, the comment does not specify which part of the paper discusses the techniques or the results, making it weakly grounded. The suggestion to include experimental results on the PDBbind dataset is specific, but since the authors cannot confidently determine which part of the paper this relates to, the comment is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the novelty of the paper is not particularly high, as most techniques used were previously proposed and demonstrated. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The suggestion to include experimental results on the PDBbind dataset is a request for additional information but does not provide a claim that needs verification. Therefore, the comment is considered 2, as it lacks sufficient evidence or references to support the claim about the novelty of the paper.", "helpfulness_rationale": "The review comment points out that the novelty of the paper is not particularly high, as most techniques used were previously proposed and demonstrated. It suggests that the authors consider adding experimental results on the PDBbind dataset to strengthen their claims. While the comment identifies a potential weakness in the paper, it does not provide specific guidance or suggestions on how to address this issue or what aspects of the PDBbind dataset could be particularly relevant. The feedback is 3 as it prompts the authors to consider additional evidence or results, but it lacks depth and specificity, making it less actionable. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that adding error bars to the results on comparing pairs of models would be beneficial. This feedback provides a clear and explicit action for the authors to take, which is to include error bars to demonstrate that the observed differences exceed what would be expected from noise when comparing equally performant models. The comment is specific and gives concrete guidance on how to implement this action, making it 5.", "grounding_specificity_rationale": "The comment suggests adding error bars to the results on comparing pairs of models to demonstrate that the differences exceed noise. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or figures where these results are presented. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact location in the paper that needs revision. While the suggestion is specific in terms of what needs to be added, the absence of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that adding error bars to the results on comparing pairs of models would be beneficial. However, it does not provide any specific reasoning or examples to support why this addition would be necessary or how it would demonstrate that the differences exceed noise. The comment lacks detailed justification or references, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the paper by recommending the addition of error bars to the results on comparing pairs of models. This feedback is clear and directly addresses a potential limitation in the presentation of results, which is the lack of visual representation of variability or confidence intervals. By suggesting the inclusion of error bars, the comment empowers the authors to enhance the clarity and robustness of their findings, making it a valuable piece of feedback. However, the comment could be more helpful if it provided additional guidance on how to effectively incorporate these error bars or discussed the potential impact of doing so. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a specific issue with the paper, namely that the full state is not defined properly on page 2, line 81. It asks the authors to clarify what is included in a full state. This feedback provides a clear and direct action for the authors to take, which is to ensure that the definition of a full state is properly explained in the paper. The comment is explicit and concrete, giving the authors a precise task to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Page 2, line 81,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of a proper definition of a \"full state.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the definition of a \"full state\" on page 2, line 81. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely that the full state is not defined properly on page 2, line 81. It asks the authors to clarify what is included in a full state. This feedback is clear and actionable, as it directs the authors to a specific area of the paper that needs clarification. By addressing this issue, the authors can improve the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided additional context or suggestions on how to define a full state. Overall, the comment is 4 as it points out a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper is a good empirical study but lacks new proposals for neural architecture encoding. It implies that the authors should provide new initial proposals based on their analysis. However, the comment does not specify which aspects of the study need new proposals or how to formulate these proposals. The action is implicit and vague, as it lacks concrete guidance on what specific new proposals should be made or how to integrate them into the paper. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment critiques the paper for lacking new proposals for neural architecture encoding, suggesting that a good empirical analysis should include such proposals. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what specific aspects of the study are lacking new proposals. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need improvement. The comment is 1 and lacks specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper is a good empirical study but lacks new proposals for neural architecture encoding. It suggests that a good empirical analysis should include new initial proposals based on the analysis. However, the comment does not provide specific examples or detailed reasoning to support the claim that the paper is lacking in this aspect. Without concrete evidence or references, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment acknowledges the strength of the paper as an empirical study but points out a potential weakness: the lack of new proposals for neural architecture encoding. It suggests that a good empirical analysis should not only provide insightful observations but also include new initial proposals based on the analysis. This feedback is 3 as it highlights an area for improvement, encouraging the authors to consider expanding their work with new proposals. However, the comment could be more actionable by offering specific suggestions on what kind of new proposals might be relevant or how to integrate them into the study. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the proposed approach performs well in simulations but struggles with real data, questioning its practical advantage. It implies that including more real data analyses or comparisons could help support the method\"s practicality. While the comment suggests an action\u2014conducting more real data analyses or comparisons\u2014the feedback is vague and lacks specific guidance on how to implement this suggestion. The authors are left with a general idea of what to do but without concrete steps on how to execute it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the proposed approach performs well in simulations but struggles with real data, questioning its practical advantage. It implies that including more real data analyses or comparisons could help support the method\"s practicality. However, the comment does not specify which part of the paper discusses the simulations or the real data, making it weakly grounded. The suggestion to include more real data analyses or comparisons is specific, as it provides a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed approach performs well in simulations but struggles with real data, questioning its practical advantage. The reviewer suggests that including more real data analyses or comparisons could help support the method\"s practicality. However, the comment lacks specific examples or detailed reasoning to substantiate the claim that the approach lacks practical advantage. Without concrete evidence or references, the claim remains 3, as it provides a general observation but lacks detailed justification or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the proposed approach, noting that while it performs well in simulations, it struggles with real data, which questions its practical advantage. The comment suggests that including more real data analyses or comparisons could help support the method\"s practicality. This feedback is 3 as it highlights a gap in the evaluation of the proposed approach and provides a direction for further investigation. However, it could be more helpful if it offered specific suggestions on how to conduct these analyses or comparisons, or if it provided examples of similar studies that have successfully addressed this issue. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors could exploit ReferIt more before moving on to other datasets. This implies that the authors should consider using more of ReferIt\"s data to potentially improve their results or analysis. However, the comment does not provide specific guidance on how to implement this suggestion, such as which aspects of ReferIt should be utilized or how it could be integrated into the current work. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors could exploit ReferIt more before moving on to other datasets. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or dataset. Without explicit references to the paper\"s content, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of ReferIt should be exploited or how it could be integrated into the current work. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors could exploit ReferIt more before moving on to other datasets. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the suggestion or how it could be implemented. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors could exploit ReferIt more before moving on to other datasets. This feedback is 3 as it points out a potential area for improvement, specifically the utilization of additional data from ReferIt. However, the comment lacks depth and does not provide specific guidance on how to integrate ReferIt into the current work or what aspects of ReferIt should be considered. Without detailed suggestions or examples, the authors may struggle to understand how to implement this recommendation effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies several areas where the explanation is unclear and requests elaboration on specific points. It asks for clarification on why a particular calculation (5*3 instead of 5*2) is used and the rationale behind choosing knn over another classifier. While the comment explicitly requests detailed explanations, it does not provide specific guidance on how to address these issues or what information should be included. The authors can infer that they need to provide more detailed explanations for these points, but the comment lacks concrete instructions on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, namely lines 243245 and 247, allowing the authors to accurately identify the parts being addressed. It is also specific because it clearly specifies what needs to be clarified, such as the rationale behind the calculation of 5*3 instead of 5*2, the choice of knn over another classifier, and the details of the k and distance metric used. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about specific aspects of the paper, such as the rationale behind a particular calculation and the choice of a classifier. These are questions that require the authors to provide more detailed explanations or justifications, rather than making subjective claims or judgments. Since the comment is primarily seeking clarification and does not contain claims or opinions, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas of the paper where the explanation is unclear and requests detailed elaboration. It asks for clarification on why a particular calculation (5*3 instead of 5*2) is used and the rationale behind choosing knn over another classifier. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and justifications for these aspects of their work. However, the comment could be more helpful if it offered suggestions on how to improve the clarity or provided examples of what kind of elaboration would be beneficial. Overall, the comment is 4 as it effectively guides the authors in enhancing the clarity and comprehensibility of their work."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to describe the background of SharpnessAware Minimization (SAM) in detail. This is a clear and direct action, providing the authors with a specific task to address. The comment is concrete because it specifies exactly what needs to be done\u2014providing a detailed description of SAM\"s background. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. However, it does not specify which part of the paper this background is discussed in, making it weakly grounded. The comment is specific in its request for a detailed description of SAM\"s background, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. However, it does not provide any supporting evidence, reasoning, or references to justify why this is necessary or how it would benefit the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of this suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the background of SharpnessAware Minimization (SAM) should be described in detail. This is a clear and actionable piece of feedback that provides the authors with a specific area to improve their draft. By addressing this suggestion, the authors can enhance the comprehensiveness and clarity of their work, making it more accessible to readers who may not be familiar with SAM. However, the comment could be more helpful if it provided additional context or guidance on how to effectively describe SAM\"s background. Despite this, the feedback is 4 as it directs the authors toward a specific improvement that could significantly enhance the quality of their paper."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a missing related work section, specifically mentioning a closely related line of work involving collective entity linking. It suggests that the proposed model is a special case of this work but notes that the paper does not mention this line of work. The comment provides a clear and direct action for the authors to take, which is to include this related work in their paper. However, it does not provide specific guidance on how to integrate this information or where to place it within the paper. While the action is explicit, the lack of detailed instructions on execution makes it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for related work, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the mention of a closely related line of work involving collective entity linking. The comment provides a clear direction for improvement by suggesting that the proposed model is a special case of this work, but it does not specify how to integrate this information into the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed model is a special case of collective entity linking, a line of work that the paper does not mention. The comment provides a logical reasoning by suggesting that the proposed model fits within this existing framework. However, it lacks specific references or detailed examples to substantiate the claim, making it 3. The authors would need to further explore and verify this claim themselves, which limits the verifiability of the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the absence of related work on collective entity linking, which considers multiple mentions in the same document. It suggests that the proposed model is a special case of this work but notes that the paper does not mention this line of work. This feedback is clear and actionable, as it directs the authors to include this related work in their paper, potentially enhancing the context and relevance of their contribution. However, the comment could be more helpful if it provided specific references or examples of this related work to guide the authors in integrating it into their draft. Overall, the comment is 4 as it highlights an important area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of truncating the log likelihood function on sensitivity and suggests that it would be interesting to see a comparison. This implies that the authors should conduct an experiment or analysis to explore this aspect, providing a clear and implicit action for the authors to take. However, the comment does not provide specific guidance on how to conduct this comparison or what aspects to focus on. While the action is clear, the lack of detailed instructions makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses two distinct points. First, it discusses the impact of truncating the log likelihood function on sensitivity and suggests a comparison, which is a specific issue that needs attention. Second, it provides minor comments about Algorithm 1, questioning whether the query functions for all data sources are the same, despite the general framework stating they can be different. This part of the comment is specific, as it clearly identifies the issue with the query functions and suggests a potential improvement by removing the subscript. However, the first part of the comment is more general and does not specify which part of the paper it addresses, making it weakly grounded. Overall, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the impact of truncating the log likelihood function on sensitivity and suggests that it would be interesting to see a comparison. This is a request for further analysis rather than a claim that requires verification. The minor comments about Algorithm 1 are factual observations about the query functions and suggest a potential improvement by removing the subscript. These are factual statements that do not require verification. Therefore, the review point is classified as \"No.\"", "helpfulness_rationale": "The review comment raises an interesting point about the impact of truncating the log likelihood function on sensitivity, suggesting that it would be beneficial to see a comparison. This feedback is 3 as it prompts the authors to consider a potential improvement or area for further exploration. However, the comment could be more helpful if it provided specific guidance on how to conduct the comparison or what aspects to focus on. Additionally, the minor comments about Algorithm 1 are more of a factual observation, questioning the consistency of query functions across data sources. Overall, the comment provides some insight but lacks depth and actionable suggestions, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the evaluation should be expanded to include a larger and more diverse dataset, such as a larger set of molecules from the MD17 dataset, including more complex molecules and materials. While the comment implies that the authors should conduct additional evaluations, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform these evaluations but are not given specific guidance on how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests expanding the evaluation to include a larger and more diverse dataset, specifically mentioning the MD17 dataset. However, it does not specify which part of the paper discusses the evaluation or where the dataset is mentioned, making it weakly grounded. The comment is specific in suggesting the need for a more comprehensive evaluation, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the evaluation is limited to a small set of molecules from the MD17 dataset and recommends expanding it to a larger and more diverse dataset. However, the comment does not provide any specific examples, references, or reasoning to support why a larger dataset would be beneficial or how it would improve the evaluation. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand the basis of the suggestion without further explanation.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation section, noting that it is based on a small set of molecules from the MD17 dataset. It suggests that expanding the evaluation to a larger and more diverse dataset, including more complex molecules and materials, would provide a more comprehensive assessment of the method\"s performance. This feedback is clear and actionable, as it provides a specific direction for improving the evaluation process. However, it could be more helpful if it offered additional guidance on how to select or design the larger dataset or what specific aspects of the method should be evaluated. Overall, the comment is 4 as it highlights a critical area for improvement and offers a clear suggestion for enhancement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the qualitative results do not show significant improvement compared to ConceptWeaver, which can handle more than two concepts. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue or improve their results. There is no guidance on what specific changes or improvements are needed to make the qualitative results more competitive with ConceptWeaver. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"qualitative results,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by comparing the results to ConceptWeaver, which can handle more than two concepts, and references a specific paper. This provides clear guidance on what aspect of the results needs improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the qualitative results do not show significant improvement compared to ConceptWeaver, which can handle more than two concepts. The comment references a specific paper by Gihyun Kwon et al. (2024) that discusses ConceptWeaver. This reference provides a basis for the claim, as it allows the authors to understand the context and the specific comparison being made. However, the comment could be strengthened by providing more detailed analysis or examples of how the results differ or could be improved. Overall, the claim is 4 due to the reference, but it could be more robust with additional explanation or evidence. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the qualitative results, noting that they do not show significant improvement compared to ConceptWeaver, which can handle more than two concepts. It references a specific paper by Gihyun Kwon et al. (2024) to support this claim. While the comment highlights a potential weakness in the paper, it lacks actionable feedback or suggestions on how the authors might address this issue or improve their results. Without specific guidance or recommendations, the authors are left with a general understanding of the problem but without clear steps to resolve it. Therefore, the comment is 3, as it points out a potential area for improvement but does not provide detailed guidance on how to achieve it."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the problem reduces to subspace clustering with missing data, which could be addressed by alternating between matrix completion and subspace clustering. However, it does not provide explicit instructions or concrete steps for the authors to take to implement this suggestion. The action is implicit, as the authors need to infer that they should explore this approach, but it lacks detailed guidance on how to do so. Therefore, the comment is 3, as it identifies a potential area for improvement but does not provide clear instructions on execution.", "grounding_specificity_rationale": "The comment suggests that the problem reduces to subspace clustering with missing data, which could be addressed by alternating between matrix completion and subspace clustering. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the problem or approach need to be addressed or improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the problem reduces to subspace clustering with missing data, which could be addressed by alternating between matrix completion and subspace clustering. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the suggestion or how to implement it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the problem could be addressed by treating it as subspace clustering with missing data, which could be solved by alternating between matrix completion and subspace clustering. While this provides a potential approach for the authors to consider, the comment lacks specific guidance or detailed suggestions on how to implement this idea. It does not offer actionable steps or examples that would help the authors refine their work. As a result, the feedback is 3, as it points out a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the reliance of CCKTDet++ on the quality and alignment of teacher models. It suggests that if the teacher model has limitations or biases, these could affect performance and introduce unintended biases. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue, such as recommending alternative approaches or methods to mitigate the reliance on teacher models. The action is implicit and vague, as the authors are left to infer that they need to consider the limitations of their teacher models. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the reliance of CCKTDet++ on teacher models, specifically mentioning the potential impact of their limitations or biases on performance and bias introduction. However, it does not specify which part of the paper discusses CCKTDet++ or the teacher models, making it weakly grounded. The comment is specific in detailing the potential issues with the reliance on teacher models, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that CCKTDet++ is heavily reliant on the quality and alignment of teacher models, which could propagate limitations or biases. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed evidence or examples, the claim remains 3, as it provides a general observation without thorough justification. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the reliance of CCKTDet++ on the quality and alignment of teacher models, which could lead to performance issues and unintended biases. This feedback is valuable as it highlights a critical aspect of the methodology that the authors should consider. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these limitations or improve the robustness of the model. While it points out an important concern, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a concern about the selection of comparison objects in the experiment, noting that they are very old and that the performance has not improved significantly. However, it does not provide any explicit or implicit suggestions for how the authors might address this issue. There is no guidance on what changes could be made to the selection of comparison objects or how to improve performance. Without actionable advice or specific recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific issue regarding the selection of comparison objects in the experiment, noting that they are very old and that performance has not improved significantly. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the problem with the selection of comparison objects and the lack of improvement in performance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison objects selected in the experiment are very old and that the performance has not been greatly improved. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the selection of comparison objects in the experiment, noting that they are very old and that performance has not improved significantly. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental setup. Without actionable feedback or detailed advice, the authors are left without a clear path forward for enhancing their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about how masks are handled in CNN layers within the representation block. While it implies that the authors should address this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide information on mask handling in their work. However, the comment does not offer specific guidance on how to address this issue, making it 3.", "grounding_specificity_rationale": "The comment raises a question about how masks are handled in CNN layers within the representation block, but it does not specify which part of the paper this question pertains to. The authors might infer that it relates to the methodology or experimental setup, but this inference is not direct. The comment lacks specificity regarding what aspect of mask handling is unclear or needs clarification. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point is a question seeking clarification about how masks are handled in CNN layers within the representation block. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about how masks are handled in CNN layers within the representation block. While it identifies an area that may need clarification or further explanation, it does not provide any suggestions or guidance on how the authors might address this issue. The comment lacks actionable feedback, leaving the authors without clear direction on how to improve their draft. Therefore, it is 2, as it points out a potential area for improvement but does not offer detailed guidance or suggestions for resolution."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for an explanation regarding the larger training loss observed when using \"without dropout\" in Figure 8. It also suggests considering the role of activation clipping in reducing model capacity. This feedback provides a clear and direct action for the authors to take, as they need to provide an explanation for the observed phenomenon. The comment is specific in its request for clarification and offers a potential angle for understanding the results, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it requests an explanation for the observed phenomenon of \"without dropout\" having larger training loss and suggests considering the role of activation clipping in reducing model capacity. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the observed phenomenon in Figure 8, specifically asking for an explanation of why \"without dropout\" has larger training loss. It also suggests considering the role of activation clipping in reducing model capacity. This request is factual and does not contain subjective claims or opinions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is specific and actionable, as it requests an explanation for the observed phenomenon in Figure 8, particularly the larger training loss when \"without dropout\" is used. It also suggests considering the role of activation clipping in reducing model capacity, which provides a potential angle for understanding the results. This feedback is valuable as it guides the authors to clarify and interpret their findings, potentially leading to a more comprehensive analysis. However, the comment could be more helpful if it offered additional context or suggested specific ways to explore the relationship between dropout and activation clipping. Overall, the comment is 4, as it provides clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights the importance of establishing a largescale matting dataset as a key significance of the paper. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this point or incorporate it into their work. Without specific suggestions or actions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the paper\"s significance lies in establishing a largescale matting dataset, which is rarely mentioned. However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity regarding what aspects of the dataset establishment are missing or how they could be improved. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper\"s significance lies in establishing a largescale matting dataset, which is rarely mentioned. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and how it impacts the paper\"s contribution. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential significance of the paper, suggesting that it could help establish a largescale matting dataset, which is rarely mentioned. However, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this point or incorporate it into their work. Without actionable feedback or detailed insights, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the number of adversarial examples is insufficient to demonstrate a particular distribution. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details on what specific changes or improvements are needed to increase the number of adversarial examples or to better demonstrate the distribution. As a result, the authors are left without a clear understanding of how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the number of adversarial examples being too small to demonstrate a particular distribution. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the issue, it lacks grounding as it does not provide clear guidance on where in the paper this problem is addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the number of adversarial examples is too small to demonstrate a particular distribution. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the number of adversarial examples being insufficient to demonstrate a particular distribution. However, it lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or improve the demonstration. Without actionable feedback or detailed advice, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the appropriateness of the proposed channelsparse gradients and suggests that they may not save time or memory in practice. It also points out that the analysis experiments or qualitative studies in Section 5.2 are conducted with a subset of common corruptions, questioning whether these findings may or may not generalize to the full set. The comment implies that the authors should consider conducting these experiments with the full set of corruptions for thoroughness and comparability with other results. While the action is implicit, the authors can infer that they need to expand their experiments to include the full set of corruptions. However, the comment does not provide specific guidance on how to implement this change, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5)\" and \"Section 5.2,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the concerns regarding the appropriateness of the proposed channelsparse gradients and the limitations of the analysis experiments or qualitative studies conducted with a subset of common corruptions. The comment suggests that the experiments should be conducted with the full set of corruptions for thoroughness and comparability with other results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the appropriateness of the proposed channelsparse gradients, suggesting that they may not save time or memory in practice. The reviewer provides a logical reasoning by pointing out that most frameworks only support dense gradients for inputs and parameters, implying that zeroing out a particular channel may not alter the computation performed. Additionally, the comment questions the generalizability of the analysis experiments or qualitative studies conducted with a subset of common corruptions, suggesting that they should be conducted with the full set for thoroughness and comparability. This reasoning is 4, as it provides a clear rationale and logical deductions, but it could be strengthened with specific examples or references to support the claims. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a critical point about the proposed channelsparse gradients, questioning their practicality in terms of time and memory savings. It highlights a potential issue with the analysis experiments conducted in Section 5.2, suggesting that they should be performed with the full set of common corruptions for thoroughness and comparability with other results. This feedback is valuable as it prompts the authors to reconsider the scope and robustness of their experiments, potentially leading to more comprehensive and reliable findings. However, the comment could be more helpful if it provided specific suggestions on how to address these concerns or examples of how to conduct the experiments with the full set of corruptions. Overall, the comment is 4, as it identifies important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the authors\" claim regarding the consideration of sparsity or low rank in their work. It suggests that the proof might be related to concentrationofmeasure and low rank, implying that the claim is not as strong as it seems. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns or improve their draft. The feedback lacks actionable details, leaving the authors uncertain about how to respond to the critique. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses two specific points: the consideration of sparsity or low rank and the claims made in the paper. However, it does not specify which sections or parts of the paper these points are discussed in, making it weakly grounded. The comment is specific in its critique of the authors\" claims and the connection to existing results, providing clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point raises a claim that the authors\" claims about not considering sparsity or low rank are not as strong as they seem, suggesting that the proof might be related to concentrationofmeasure and low rank. The reviewer also mentions that the results have been previously reported in 394244, implying that the findings are extensions of existing work. However, the comment lacks specific examples or detailed reasoning to support the claim that the authors have not considered sparsity or low rank. The references provided are not directly related to the claims in question, making it difficult for the authors to understand and address the critique. Therefore, the claim is 3, as it provides some reasoning but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises concerns about the authors\" claims regarding the consideration of sparsity or low rank and the novelty of their results. It suggests that the proof might be related to concentrationofmeasure and low rank, implying that the claim of not considering low rank is not as strong as it seems. Additionally, the comment points out that the results have been previously reported in 394244, suggesting that the findings are extensions of existing work. However, the comment lacks specific suggestions or actionable feedback on how the authors might address these concerns or improve their draft. While it identifies areas for improvement, it does not provide detailed guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The comment points out that the Limitations section is too concise and lacks the detailed and clear writing style found in the main body of the paper. However, it does not provide specific guidance on how the authors should expand or improve the Limitations section. The feedback is explicit in identifying the issue but lacks concrete instructions on how to address it. As a result, the authors are left with a general direction but no detailed steps to follow, making the comment 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the Limitations section, noting that it is too concise compared to the detailed writing style in the main body of the paper. However, it does not specify which part of the Limitations section is too concise or provide details on what aspects of the writing style need to be improved. This makes it weakly grounded, as the authors cannot confidently determine which parts of the Limitations section need attention. The comment is specific in identifying the issue of conciseness but lacks detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the Limitations section is too concise compared to the detailed writing style in the main body of the paper. However, it does not provide any specific examples or detailed reasoning to support this claim. Without concrete evidence or examples of what makes the main body detailed, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a specific issue with the Limitations section, noting that it is too concise compared to the detailed and clear writing style found in the main body of the paper. This feedback is 3 as it identifies a potential area for improvement, encouraging the authors to expand on the limitations section. However, the comment lacks depth and does not provide specific suggestions or guidance on how to enhance the Limitations section. Without actionable advice, the authors may struggle to effectively address the feedback. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, PatchCore, with an added denoising process to the memory bank. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the novelty of their method. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the proposed method is weak, implying it is a modified version of previous work, PatchCore, with an added denoising process to the memory bank. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs attention. The comment lacks specificity regarding what aspects of the novelty are being questioned or how the modification affects the original work. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the proposed method is weak, suggesting it is a modified version of PatchCore with an added denoising process. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the novelty of the proposed method is weak, suggesting it is a modified version of previous work, PatchCore, with an added denoising process to the memory bank. While this observation highlights a potential issue with the originality of the work, it lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their method. Without actionable feedback or detailed critique, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests providing more detailed instructions for installing and running the software, as well as listing all the prompts used in the evaluation. These suggestions are concrete and provide clear guidance on how the authors can improve their draft. The comment also recommends including these details in an extensive version of Table 1 or in the appendix, similar to binpwn. This level of detail ensures that the authors know exactly what actions to take to address the issue, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue with the repository lacking clear instructions for installation and execution, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear suggestions for improvement, such as providing detailed instructions for each challenge and listing all prompts used in the evaluation. These suggestions are further detailed by recommending the inclusion of these details in an extensive version of Table 1 or in the appendix, similar to binpwn. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors could not run the code due to the lack of clear instructions for installation and execution. The reviewer suggests providing more detailed instructions and listing all prompts used in the evaluation. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for improvement is clear, but the lack of specific guidance or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the study, as the authors could not run the code due to the lack of clear instructions for installation and execution. The reviewer provides actionable suggestions for improvement, such as providing detailed instructions for each challenge and listing all prompts used in the evaluation. These suggestions are specific and would greatly enhance the paper\"s utility and reproducibility. By addressing these points, the authors can significantly improve the clarity and accessibility of their work. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a discrepancy between the model ablation results and the major claim of the paper regarding interpretable VQA. It suggests that the global representation g_v, which allows for grounded QA, is more crucial than other components, as indicated by the results in Table 3. However, the comment does not provide explicit guidance or suggestions on how the authors should address this discrepancy or incorporate these findings into their work. The action is implicit and vague, as the authors are left to infer that they need to reconcile this difference in their analysis or discussion. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the discrepancy between the model ablation results and the major claim of interpretable VQA, particularly regarding the global representation g_v. This provides clear guidance on what aspect of the paper needs attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the model ablation results in Table 3 suggest that the global representation g_v is more crucial than other components, which contradicts the major claim of interpretable VQA. The comment provides a specific reference to Table 3, which allows the authors to verify the claim. However, the reasoning could be strengthened by explaining how the results in Table 3 support the claim and how this contradicts the major claim of the paper. Overall, the comment is 4, as it provides a clear basis for the claim but lacks detailed explanation or references to fully substantiate the argument.", "helpfulness_rationale": "The review comment identifies a discrepancy between the model ablation results and the major claim of the paper regarding interpretable VQA. It highlights that the global representation g_v, which allows for grounded QA, appears more crucial than other components, as indicated by the results in Table 3. This observation challenges the paper\"s main claim and suggests that the authors need to reconsider their interpretation or provide additional justification for their findings. However, the comment does not offer specific suggestions or guidance on how the authors might address this discrepancy or incorporate these findings into their analysis. While it points out an important issue, the feedback could be more helpful with additional constructive advice or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the \"primarysecondary\" relationship is mentioned frequently in the paper, but its difference with nuclearity is unclear and not precisely defined. While the comment identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to clarify the relationship between \"primarysecondary\" and nuclearity, but without specific suggestions on how to do so, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"primarysecondary\" relationship, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity and precise definition of the difference between the \"primarysecondary\" relationship and nuclearity. This provides the authors with a clear understanding of what needs to be addressed in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"primarysecondary\" relationship is mentioned frequently in the paper, but its difference with nuclearity is unclear and not precisely defined. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the \"primarysecondary\" relationship is mentioned frequently, but its difference with nuclearity is unclear and not precisely defined. This feedback highlights a gap in the paper\"s clarity and precision, which is crucial for readers to understand the concepts being discussed. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as recommending additional explanations or examples. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks depth and specificity in its guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation regarding the effect of mask ratio across different datasets and suggests that an intuitive guide for choosing this ratio would be beneficial. While it points out the missing insight in the discussions, it does not explicitly instruct the authors to provide this guide. The action is implicit, as the authors can infer that they need to include a discussion on choosing the mask ratio, but the comment does not specify how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the effect of mask ratio and its impact on different datasets, which is relevant to the limitations section. However, it does not specify which part of the paper discusses these limitations, making it weakly grounded. The comment is specific in identifying the missing insight about the impact of mask ratio and suggests that an intuitive guide for choosing this ratio would be helpful. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the effect of mask ratio varies across different datasets, leading to more tuning, as mentioned in the limitations. However, it also states that the insight about the impact of mask ratio is missing in the discussions and suggests that an intuitive guide for choosing this ratio would be helpful. While the comment highlights a potential issue, it lacks specific examples or references to support the claim about the missing insight. The suggestion for an intuitive guide is 3, as it implies a need for clarification, but without detailed guidance, it remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation regarding the effect of mask ratio across different datasets, noting that it leads to more tuning. It also points out that the impact of mask ratio is not discussed in the paper, suggesting that an intuitive guide for choosing this ratio would be beneficial. This feedback is clear and actionable, as it highlights a specific area where the paper could be improved by providing guidance on selecting the mask ratio. However, the comment could be more helpful if it offered suggestions on how to present this information or examples of how to choose the ratio. Overall, the comment is 4, as it effectively directs the authors to a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from another round of proofreading, indicating that several sections are difficult to follow. While the comment implies that the authors should proofread the paper, it does not specify which sections are problematic or provide detailed guidance on how to improve the clarity of those sections. The action is explicit but somewhat vague, as the authors know they need to proofread but may not be entirely sure which specific sections require attention. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from another round of proofreading and mentions that several sections are difficult to follow. However, it does not specify which sections are challenging or provide details on what might be causing the difficulty. This lack of specificity makes it difficult for the authors to pinpoint the exact areas that need improvement. Additionally, the comment does not provide guidance on how to address these issues, further reducing its specificity. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the paper could benefit from another round of proofreading due to several sections being difficult to follow. However, the comment lacks specific examples or details about which sections are challenging or why they are difficult to follow. Without this information, the authors may find it challenging to address the feedback effectively. Therefore, the claim is considered 2, as it provides a general suggestion but lacks detailed justification or examples to support it.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from another round of proofreading, indicating that several sections are difficult to follow. While this feedback highlights an area for improvement, it lacks specific details or suggestions on which sections are problematic or how the authors might enhance the clarity of those sections. The comment provides a general direction for improvement but does not offer actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript. It suggests that the reviewer is uncertain about whether it refers to stochastic gates. While the comment identifies a missing reference, it does not provide explicit guidance on how the authors should address this issue. The action is implicit, as the authors need to determine what additional information to include, and it is vague because it lacks specific instructions on how to incorporate the missing reference. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly points out the issue with the term \"STG layer,\" which has never been mentioned in the manuscript, and the reviewer is uncertain about its reference. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"STG layer\" in Figure 2 has never been mentioned in the manuscript. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The lack of detailed justification or explanation makes it difficult for the authors to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the manuscript, noting that the term \"STG layer\" in Figure 2 has never been mentioned throughout the manuscript. This is a clear and actionable piece of feedback that highlights a missing reference or explanation, which the authors can address by incorporating the necessary information. However, the comment could be more helpful if it provided additional context or suggested how the authors might integrate this information into their discussion. Overall, the comment is 3 as it points out a critical omission, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights that the proposed methodology shows limited improvements in some cases and even underperforms compared to the baseline in specific instances, such as FiQA and CONALA. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these limitations or improve their methodology. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the proposed methodology, noting that it shows limited improvements and even underperforms compared to the baseline in certain cases, such as FiQA and CONALA. However, it does not specify which part of the paper discusses these improvements or where the baseline is mentioned, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these comparisons are made, the comment lacks full grounding. It is specific in identifying the issue of limited improvements and underperformance but does not provide detailed guidance on how to address it. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed methodology shows limited improvements and even underperforms compared to the baseline in specific cases, such as FiQA and CONALA. However, the comment does not provide any supporting evidence, examples, or detailed reasoning to substantiate this claim. Without additional context or references, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment highlights a specific issue with the proposed methodology, noting that it shows limited improvements and even underperforms compared to the baseline in certain cases, such as FiQA and CONALA. This feedback is 3 as it identifies a critical area where the methodology may need improvement. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address these limitations or enhance their methodology. Without actionable advice or detailed feedback, the authors are left with a general idea of the problem but without a clear path to improvement. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of clarity in the comparisons with 1, specifically questioning the contributions or advantages beyond the work cited. While it identifies a gap in the explanation, it does not provide explicit guidance on how the authors should address this issue or what specific aspects need clarification. The action is implicit, as the authors can infer that they need to provide more detailed explanations of the contributions and advantages beyond the cited work. However, the comment lacks concrete details on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison with 1, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of unclear contributions or advantages beyond the cited work, prompting the authors to provide more detailed explanations. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of comparisons with 1, specifically asking about the contributions or advantages beyond the cited work. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of comparisons made in the paper, particularly regarding the contributions or advantages beyond the cited work 1, which focuses on differentially private model personalization. This feedback is 3 as it highlights a potential area for improvement, prompting the authors to clarify their contributions. However, the comment lacks depth and does not provide specific suggestions on how to address the issue or what aspects of the comparison could be improved. To be more helpful, the comment could include examples or guidance on how to enhance the clarity of the comparisons. Therefore, it aligns with a score of 3, indicating that the comment provides some insight but lacks comprehensive guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the rebalancing step method, used to make multimodal learning less greedy, is not well described and lacks analysis in the full text. It suggests that the authors should provide a clear explanation of why using the average feature of previous samples can stop the training of the unimodal branch. While the comment identifies a specific area that needs clarification, it does not provide explicit instructions or detailed guidance on how to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the explanation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the rebalancing step method used in multimodal learning, specifically mentioning that it is not well described and lacks analysis in the full text. It suggests that the authors should provide a clear explanation of why using the average feature of previous samples can stop the training of the unimodal branch. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, namely the lack of description and analysis of the rebalancing step method. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the rebalancing step method is not well described and lacks analysis in the full text. It suggests that the authors should provide a clear explanation of why using the average feature of previous samples can stop the training of the unimodal branch. However, the comment does not provide specific examples, detailed reasoning, or references to support this claim. The lack of detailed justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some indication of a problem but lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific issue with the description of the rebalancing step method used in multimodal learning. It points out that the method is not well described and lacks analysis in the full text, particularly concerning why using the average feature of previous samples can stop the training of the unimodal branch. This feedback is 3 as it highlights a gap in the explanation that the authors need to address. However, the comment could be more helpful if it provided suggestions on how to improve the explanation or examples of how to address the issue. Overall, the comment offers some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: first, it asks for the differences and advantages of the \"Reduce\" part compared to EATA, and second, it questions whether it is possible to identify harmful outofdistribution (OOD) instances using an entropy metric instead of an energy one. While the questions are explicit, they do not provide concrete guidance on how the authors should address these points or what specific changes should be made to the draft. The authors are left to infer that they need to provide more detailed comparisons and explore alternative metrics, but without explicit instructions, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two questions: the differences and advantages of the \"Reduce\" part compared to EATA, and whether it is possible to identify harmful OOD instances using an entropy metric instead of an energy one. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification and exploration of specific aspects of the paper, rather than making subjective claims or opinions. It does not contain any claims that require verification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions regarding Section 4.1 of the paper. The first question asks about the differences and advantages of the \"Reduce\" part compared to EATA, prompting the authors to provide more detailed comparisons. The second question questions whether it is possible to identify harmful outofdistribution (OOD) instances using an entropy metric instead of an energy one, suggesting an alternative approach for analysis. While the comment identifies areas for improvement and prompts the authors to explore additional aspects of their work, it lacks specific guidance or suggestions on how to address these questions or what analyses to conduct. The feedback is 3 as it directs the authors to consider additional comparisons and alternative metrics, but it could be more actionable with more detailed guidance. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests comparing the proposed method with deterministic control, given the popularity of deterministic policies. However, it does not provide explicit guidance on how to conduct this comparison or what specific aspects should be considered. The comment implies that this comparison could be useful, but it lacks concrete instructions or detailed suggestions on how to implement it. As a result, the authors are left with a general idea of what might be beneficial but without clear steps to follow. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method with deterministic control, given the popularity of deterministic policies. However, it does not specify which part of the paper this comparison should be made in, nor does it provide details on what aspects of the comparison should be considered. The authors cannot confidently determine which section or part of the paper this suggestion pertains to, making it weakly grounded. Additionally, the comment lacks specificity as it does not outline what exactly should be compared or how this comparison would impact the paper\"s claims. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point suggests comparing the proposed method with deterministic control, given the popularity of deterministic policies. However, it does not provide any specific reasoning, examples, or references to support why this comparison is necessary or how it would impact the paper\"s claims. The lack of detailed justification or evidence makes the claim 1, as the authors would need to infer the importance of this comparison on their own. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests comparing the proposed method with deterministic control, given the popularity of deterministic policies. This is a relevant and actionable suggestion that could enhance the paper\"s relevance and impact by demonstrating how the proposed method stacks up against a widely used alternative. However, the comment lacks specific guidance on how to conduct this comparison or what aspects of the comparison should be emphasized. While it provides a direction for improvement, it does not offer detailed instructions or examples, making it 3. The authors would need to infer the necessary steps to implement this suggestion, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the naming of a column in Table 4, suggesting that it should be named \"ATE\" instead of the current name. It also implies that the term \"Corr\" might be related to \"CauAnt.\" However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes are needed. The action is implicit and somewhat vague, as the authors are left to infer that they need to correct the column name and possibly clarify the relationship between \"Corr\" and \"CauAnt.\" Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the naming of the third column in Table 4 and the relationship between \"Corr\" and \"CauAnt.\" This provides clear guidance on what the authors should consider or clarify in their draft. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the naming of a column in Table 4, suggesting that it should be named \"ATE\" instead of the current name. It also implies that \"Corr\" might be related to \"CauAnt.\" However, the comment lacks specific reasoning or evidence to support why the column should be named \"ATE\" or how \"Corr\" relates to \"CauAnt.\" Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a specific question about the naming of a column in Table 4, suggesting that it should be named \"ATE\" instead of the current name. It also implies that \"Corr\" might be related to \"CauAnt.\" While the comment identifies a potential issue with the naming of a column, it lacks depth and does not provide actionable guidance or suggestions for improvement. The authors are left to infer that they need to address the naming issue, but without specific instructions or examples, the feedback remains 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity regarding the anchoring of the mechanism in prior work, noting that the experiments section only provides a vague sense of this. It suggests that more clarity could be provided, particularly in the methods section where the methods are made clear. Additionally, the comment points out that it is challenging to see why the differences in the curves are exciting and suggests that annotations or zooming in to ground them quantitatively would help. While the comment provides some guidance on areas for improvement, it lacks specific instructions on how to achieve this clarity. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses two distinct aspects of the paper. First, it mentions the lack of clarity regarding the anchoring of the mechanism in prior work, specifically noting that the experiments section only provides a vague sense of this. This part is weakly grounded as it does not specify which sections or figures are being referred to, but it is somewhat specific in suggesting that more clarity could be provided, particularly in the methods section. Second, the comment highlights the difficulty in understanding why the differences in the curves are exciting and suggests that annotations or zooming in to ground them quantitatively would help. This part is also weakly grounded as it does not specify which figures or sections are being referred to, but it is specific in its suggestion for improvement. Overall, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a concern about the lack of clarity regarding the anchoring of the mechanism in prior work, noting that the experiments section only provides a vague sense of this. The reviewer suggests that more clarity could be provided, particularly in the methods section where the methods are made clear. The comment also questions the difficulty in understanding the significance of the differences in the curves and suggests that annotations or zooming in to ground them quantitatively would help. While the comment identifies a potential issue, it lacks specific examples or references to prior work that could help the authors address the concern. The suggestion to provide more clarity is 3, as it points out a gap in the paper, but it could be strengthened with more detailed guidance or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the anchoring of the mechanism in prior work, noting that the experiments section only provides a vague sense of this. It suggests that more clarity could be provided, particularly in the methods section where the methods are made clear. Additionally, the comment questions the difficulty in understanding the significance of the differences in the curves and suggests that annotations or zooming in to ground them quantitatively would help. While the comment highlights specific areas for improvement, it lacks detailed guidance or examples on how to achieve this clarity. The feedback is 3 as it points out areas for improvement but could be more actionable with additional suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the limited novelty of the paper, specifically noting that the key contribution appears to be the application of a pretrained mechanism to the task of fewshot graph learning. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or enhance the novelty of their work. The comment lacks actionable guidance, leaving the authors without a clear path to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the limited novelty of the paper, specifically mentioning the application of a pretrained mechanism to the task of fewshot graph learning. However, it does not specify which part of the paper this concern pertains to, such as the introduction, methodology, or results sections. Without explicit references to specific sections or elements, the authors cannot confidently determine which parts need attention. While the comment is specific about the issue of novelty, it lacks grounding because it does not provide detailed guidance on how to address this concern. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses a concern about the limited novelty of the paper, specifically mentioning the application of a pretrained mechanism to the task of fewshot graph learning. However, the comment lacks specific examples or detailed reasoning to support the claim that the contribution is not exciting or complicated. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it provides some indication of the issue but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a concern about the limited novelty of the paper, specifically noting that the key contribution appears to be the application of a pretrained mechanism to the task of fewshot graph learning. While the comment highlights a potential weakness, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The feedback is 3 as it points out an area for improvement, but it does not provide actionable steps or detailed insights for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a gap in the paper, noting that while it empirically validates which setups or parameters are useful for test time training, it does not provide theoretical understanding on why these setups or parameters do not collapse. However, the comment does not offer any explicit or implicit suggestions on how the authors might address this gap or what theoretical framework could be used to explain the phenomenon. Without specific guidance or suggestions, the authors are left without a clear path forward to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a gap in the paper, noting that while it empirically validates which setups or parameters are useful for test time training, it does not provide theoretical understanding on why these setups or parameters do not collapse. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what theoretical understanding is missing or how it could be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper empirically validates which setups or parameters are useful for test time training but does not provide theoretical understanding on why these setups or parameters do not collapse. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that a theoretical understanding is missing. This makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides some indication of a gap but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a gap in the paper, noting that while it empirically validates which setups or parameters are useful for test time training, it does not provide theoretical understanding on why these setups or parameters do not collapse. This feedback highlights a critical area where the paper could be strengthened by offering theoretical insights, which would enhance the depth and comprehensiveness of the study. However, the comment does not offer specific suggestions or guidance on how the authors might address this gap or what theoretical framework could be used to explain the phenomenon. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the proposed method not requiring pose estimation in the inference phase, which implies that test images do not have pose maps. It also questions the clarity of the visual analysis in Section 4.4, specifically whether the results are from training images or test images. While the comment identifies an area of confusion, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to clarify the results. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the visual analysis results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the proposed method\"s lack of pose estimation in the inference phase and questions the clarity of the visual analysis in Section 4.4. It specifies the part of the paper being discussed, making it fully grounded. However, it lacks specificity as it does not provide detailed guidance on how to clarify the visual analysis or what specific aspects of the analysis need to be addressed. Therefore, this comment is fully grounded but underspecific, aligning with category 4.", "verifiability_rationale": "The review point raises a concern about the proposed method\"s lack of pose estimation in the inference phase and questions the clarity of the visual analysis in Section 4.4. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the results. The comment lacks specific details or references that would help the authors understand the issue or how to address it. As a result, the claim is 1, as it does not provide sufficient justification for the concern raised.", "helpfulness_rationale": "The review comment raises a concern about the proposed method\"s lack of pose estimation in the inference phase, implying that test images do not have pose maps. It also questions the clarity of the visual analysis presented in Section 4.4, specifically whether the results are from training images or test images. While the comment identifies a potential issue with the methodology, it does not provide specific guidance or suggestions on how the authors might address this concern or improve the clarity of their analysis. The feedback is 3 as it highlights an area for improvement, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should explore the application of the DEER method to other methods like LEM or UnICORNN. It questions whether these methods would maintain the same performance or if better performance could be achieved with the DEER method due to potential training speed improvements and hyperparameter tuning. The comment provides a clear and explicit action for the authors to take, which is to conduct this exploration. However, it does not provide specific guidance on how to implement this exploration or what aspects to focus on. While the action is clear, the lack of detailed instructions on execution makes it 3.", "grounding_specificity_rationale": "The comment suggests exploring the application of the DEER method to other methods like LEM or UnICORNN, which could potentially improve performance. However, it does not specify which part of the paper this exploration should be conducted in, making it weakly grounded. The comment is specific in suggesting a potential area for improvement and questioning the performance implications, but without clear grounding, the authors may struggle to identify the exact sections to address. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the DEER method could be applied to other methods like LEM or UnICORNN, questioning whether they would maintain the same performance or achieve better performance with the DEER method. While the comment raises an interesting question, it lacks specific examples or references to support the claim that the DEER method could potentially improve performance. The reasoning is based on a logical assumption but lacks detailed evidence or examples to substantiate the claim. Therefore, the comment is 3, as it provides a plausible suggestion but requires more detailed justification or evidence to be fully convincing.", "helpfulness_rationale": "The review comment suggests exploring the application of the DEER method to other methods like LEM or UnICORNN, questioning whether they would maintain the same performance or achieve better performance with the DEER method. This feedback is 3 as it identifies a potential area for further exploration that could enhance the paper\"s impact and provide additional insights into the comparative performance of different methods. However, the comment could be more helpful if it provided specific guidance on how to conduct this exploration or what aspects to focus on. Overall, the comment offers a valuable suggestion for improving the paper\"s scope and depth, but it lacks detailed actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the presentation is difficult to follow due to the excessive use of notations. However, it does not provide any explicit guidance or suggestions on how the authors might address this issue. The comment lacks concrete details on which notations are problematic or how they could be simplified. Without specific advice or examples, the authors are left without a clear understanding of what steps to take to improve the clarity of their presentation. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the presentation, noting that it is difficult to follow due to the excessive use of notations. However, it does not specify which part of the paper this issue is present in, making it weakly grounded. The comment is specific in identifying the problem of too many notations, but without pointing to a particular section or figure, the authors may struggle to pinpoint where to make improvements. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the presentation is difficult to follow due to the excessive use of notations. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples of how the notations are complicating the presentation, the authors may find it challenging to address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a specific issue with the presentation, noting that it is difficult to follow due to the excessive use of notations. However, it lacks actionable guidance or suggestions on how the authors might address this problem. Without specific advice on simplifying the notation or improving clarity, the comment provides limited value to the authors in terms of actionable feedback. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests including some results of GPT4V, acknowledging that its API is not yet released but suggesting that quick experiments using ChatGPT\"s UI could be sufficient. While the action is explicit in terms of including results, it is somewhat vague because it does not specify which aspects of GPT4V\"s results should be included or how they should be presented. The authors know they need to include some results, but the comment lacks detailed guidance on what exactly to include or how to integrate them into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including results of GPT4V, acknowledging that its API is not yet released but suggesting quick experiments using ChatGPT\"s UI as an alternative. However, it does not specify which part of the paper should include these results or where the authors should focus their attention. The authors might infer that it relates to the experimental section or results, but this inference is not direct. The comment is specific in suggesting the inclusion of results, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including results of GPT4V, acknowledging that its API is not yet released but suggesting quick experiments using ChatGPT\"s UI as an alternative. However, the comment does not provide specific reasoning or evidence to support why these results should be included or how they would benefit the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the significance of the suggestion. Therefore, the claim is considered 2, as it provides some reasoning but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment suggests including some results of GPT4V, acknowledging that its API is not yet released but suggesting quick experiments using ChatGPT\"s UI as an alternative. This feedback is 3 as it provides a direction for the authors to consider additional experiments or results that could enhance the paper\"s findings. However, the comment lacks specificity regarding which aspects of GPT4V\"s results should be included or how they should be integrated into the paper. Additionally, it does not offer detailed guidance on how to conduct these experiments or what specific outcomes to expect. While it points out a potential area for improvement, the comment could be more actionable with additional details. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors discuss more about the meaning of their theoretical analysis and why CoPur could perform better compared to baselines. While the comment implies that the authors should provide additional discussion, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should elaborate on the analysis and its implications. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the authors discuss more about the meaning of their theoretical analysis and why CoPur could perform better compared to baselines. However, it does not specify which part of the paper this analysis is discussed in, making it weakly grounded. The comment is specific in suggesting that the authors should provide more discussion on the implications of their analysis and the performance advantages of CoPur over baselines. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper provides an extensive theoretical analysis and implies that the authors should discuss more about the meaning of this analysis. It also questions why CoPur could perform better compared to baselines. However, the comment lacks specific examples or detailed reasoning to support the claim that the analysis is extensive or that the comparison with baselines is unclear. Without additional context or evidence, the claim remains somewhat vague and difficult for the authors to address effectively. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment suggests that the authors should provide more discussion on the meaning of their theoretical analysis and why CoPur could perform better compared to baselines. This feedback is 3 as it identifies a gap in the paper\"s discussion, prompting the authors to elaborate on the implications of their analysis. However, the comment lacks specific guidance or suggestions on how to address this gap, such as recommending particular aspects to discuss or examples to include. While it points out an area for improvement, the feedback could be more actionable with additional details. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two main issues with the evaluation metrics. First, it notes that the reported metrics are mostly for 3D NVS, with only the keypoint distance metric related to dynamics. It points out that this metric only assesses the size of motions but not their quality. Second, it questions the evaluation protocol, specifically asking whether the camera parameters are consistent across all frames when generating the videos, as this could affect the keypoint distance. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific changes to make the evaluation more comprehensive. The actions are implicit and somewhat vague, as the authors need to infer what steps to take to improve the evaluation metrics and protocol. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Result/eval,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation metrics, noting that they are mostly for 3D NVS and that the keypoint distance metric only assesses the size of motions, not their quality. Additionally, it raises a concern about the evaluation protocol, questioning whether camera parameters are consistent across all frames. This provides clear guidance on what needs to be addressed in the evaluation section. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the reported metrics are mostly for 3D NVS and that the keypoint distance metric only assesses the size of motions, not their quality. The comment also questions the evaluation protocol, specifically asking about the consistency of camera parameters across all frames. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The authors would need to infer the importance of these observations and understand the implications for the evaluation, making the claims 3. Therefore, the comment aligns with a label of 3.", "helpfulness_rationale": "The review comment identifies specific issues with the evaluation metrics and the evaluation protocol. It points out that the reported metrics are mostly for 3D NVS, and the keypoint distance metric only assesses the size of motions, not their quality. Additionally, it questions the consistency of camera parameters across all frames, which could affect the keypoint distance. This feedback is clear and actionable, as it highlights areas where the evaluation could be improved and suggests specific aspects that need clarification. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of how to improve the evaluation protocol. Overall, the comment is 4, as it provides valuable insights for enhancing the draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the two parts of pretraining and regularization appear to be incremental additions rather than naturally integrated components, which affects the coherence of the paper. However, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to integrate these components more cohesively. The feedback lacks concrete details or actionable steps, leaving the authors uncertain about how to improve the coherence of their paper. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the presentation of two parts of pretraining and regularization, suggesting that they appear to be incremental additions rather than naturally integrated components. However, it does not specify which sections or parts of the paper these components are discussed in, making it weakly grounded. The comment is specific in identifying the issue of disjointed presentation and its impact on coherence, but without explicit references to sections, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the two parts of pretraining and regularization appear to be incremental additions rather than naturally integrated components, which affects the coherence of the paper. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the presentation of the paper, specifically noting that the two parts of pretraining and regularization appear to be incremental additions rather than naturally integrated components. This observation highlights a lack of coherence in the paper, which is a critical aspect for the overall readability and logical flow. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or integrate these components more cohesively. While it points out a problem, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the importance of Renyi divergence is not well explained, making it unclear for readers unfamiliar with differential privacy. However, it does not provide specific guidance on how the authors should clarify this point or what aspects of Renyi divergence should be emphasized. The action is implicit and vague, as the authors are left to infer that they need to improve the explanation but are not given concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a specific issue with the explanation of Renyi divergence, noting that it is not well explained for readers unfamiliar with differential privacy. However, it does not specify which part of the paper discusses Renyi divergence or where the explanation is lacking, making it weakly grounded. The comment is specific in identifying the need for a clearer explanation of Renyi divergence\"s importance, but without explicit references to sections or figures, the authors cannot confidently determine which parts need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the importance of Renyi divergence is not well explained, making it unclear for readers unfamiliar with differential privacy. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of improvement by pointing out that the importance of Renyi divergence is not well explained, particularly for readers unfamiliar with differential privacy. This feedback is valuable as it highlights a gap in the paper\"s explanation, which could hinder understanding for a broader audience. However, the comment lacks specific suggestions or guidance on how the authors might clarify this point, such as recommending additional explanations or examples. While it provides a clear direction for improvement, the lack of detailed guidance limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the authors should focus more on simplicity and clarity rather than concluding with \"mathematical theories.\" While the suggestion implies that the authors should address these aspects, it does not provide specific guidance on how to achieve this. The action is explicit in terms of the focus on simplicity and clarity but lacks concrete details on how to implement this suggestion. Therefore, the comment is 3, as it provides a clear direction but lacks detailed instructions for execution.", "grounding_specificity_rationale": "The comment suggests that the authors should focus on simplicity and clarity rather than concluding with \"mathematical theories.\" However, it does not specify which part of the paper this suggestion pertains to, making it difficult for the authors to identify the exact section that needs attention. The comment lacks specificity regarding what aspects of simplicity and clarity should be emphasized or how \"mathematical theories\" might be addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests that the authors should focus on simplicity and clarity rather than concluding with \"mathematical theories.\" However, it does not provide any specific reasoning, examples, or references to support this claim. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should focus on simplicity and clarity rather than concluding with \"mathematical theories.\" While it identifies a potential area for improvement, it lacks specific guidance or examples on how to achieve this. The comment provides a general direction but does not offer detailed feedback or actionable steps for the authors to follow. This limits its helpfulness, as it gives the authors a vague idea of what to work on but does not fully support their efforts to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the ablation study in the work is limited and recommends further studies on the impact of the predefined threshold \u03f5. While the comment implies that the authors should conduct additional experiments or analyses to explore this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct further studies but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the ablation study is limited and recommends further studies on the impact of the predefined threshold \u03f5. However, it does not specify which part of the paper this comment is addressing, such as a particular section or figure where the ablation study is discussed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact part of the paper that needs improvement. While the comment is specific about what needs to be addressed, the absence of grounding information makes it weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the ablation study is limited and recommends further studies on the impact of the predefined threshold \u03f5. However, the comment does not provide specific examples or detailed reasoning to support why the current study is insufficient or how the impact of \u03f5 could be explored further. Without additional context or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a limitation in the ablation study, specifically the lack of exploration into the impact of the predefined threshold \u03f5. It suggests that further studies should be conducted to address this gap. While the comment highlights an area for improvement, it lacks specific guidance or suggestions on how to conduct these additional studies or what aspects to focus on. This limits the comment\"s usefulness, as it provides a direction for improvement but does not offer detailed instructions or examples. Therefore, the comment is 3, as it points out a potential weakness but does not fully support the authors in making improvements."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that only RougeL is used for evaluation, which may make the evaluation less reliable, especially for some classification tasks where RougeL is not sensitive enough. However, it does not provide explicit guidance on what the authors should do to improve the evaluation process. The comment implies that the authors should consider using additional metrics or methods to enhance the reliability of their evaluation, but it does not specify which metrics or methods to use. The action is implicit and somewhat vague, as the authors need to infer the need for additional evaluations and are not given concrete steps to take. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"RougeL\" for evaluation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights a particular issue with the evaluation method, noting that it may not be reliable for some classification tasks. The comment provides clear guidance on what needs to be addressed, suggesting that the authors should consider using additional metrics or methods to enhance the reliability of their evaluation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using only RougeL for evaluation makes the results less reliable, especially for some classification tasks where RougeL is not sensitive enough. While the comment identifies a potential issue with the evaluation method, it lacks specific examples or references to support the claim about the insensitivity of RougeL for certain tasks. This makes the claim 3, as the authors would need to further investigate and possibly provide additional evidence or examples to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation methodology by pointing out that only RougeL is used, which may make the evaluation less reliable, especially for some classification tasks where RougeL is not sensitive enough. This feedback is 3 as it highlights a potential weakness in the evaluation process and suggests that the authors should consider using additional metrics or methods to enhance the reliability of their evaluation. However, the comment could be more helpful if it provided specific suggestions or examples of alternative metrics or methods that could be used. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a specific issue with the definitions of variables in the paper, noting that the definitions do not properly match the formula (i.e., Equation 3) and that the variable n_k is not present in Equation 3. This feedback provides a clear and direct action for the authors to take, which is to ensure that the definitions of variables align with the formula presented. The comment is explicit and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 580588, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the definitions of variables not matching the formula (i.e., Equation 3) and notes the absence of n_k in Equation 3. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the definitions of variables do not properly match the formula (i.e., Equation 3) and notes the absence of n_k in Equation 3. However, the comment does not provide any supporting evidence, reasoning, or references to justify why the definitions are incorrect or how they should be revised. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the definitions of variables in the paper, noting that they do not properly align with the formula presented in Equation 3. It points out the absence of n_k in Equation 3, which is a critical oversight. This feedback is clear and actionable, as it directs the authors to ensure consistency between the variable definitions and the equations. By addressing this issue, the authors can improve the accuracy and clarity of their paper. However, the comment could be more helpful if it provided suggestions on how to revise the definitions or examples of correct definitions. Overall, the comment is 4 as it highlights a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space and suggests that this approach might conflict with the samplespecific assumption of the paper. It also mentions that some key experiments are missing. While the comment raises a question and points out a potential issue, it does not provide explicit guidance on how the authors should address these concerns or what specific experiments are missing. The action is implicit and somewhat vague, as the authors need to infer the need for additional experiments and the potential issue with the single vector approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space and suggests that this approach might conflict with the samplespecific assumption of the paper. It also mentions that some key experiments are missing. However, the comment does not specify which part of the paper discusses the classspecific token or the experiments in question, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in questioning the sufficiency of a single vector and the potential conflict with the samplespecific assumption, but it is 1 because it does not provide explicit references to sections or experiments. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the sufficiency of a single vector for each class with large variances in the semantic space and suggests that this approach might conflict with the samplespecific assumption of the paper. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that a single vector strategy is conflicting with the samplespecific assumption. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the sufficiency of a single vector for each class with large variances in the semantic space and suggests that this approach might conflict with the samplespecific assumption of the paper. It also points out that some key experiments are missing. While the comment identifies a potential issue with the methodology, it lacks specific guidance or suggestions on how the authors might address this concern or what experiments could be conducted to validate their approach. The mention of missing key experiments provides a minor point of improvement, but the overall feedback is 3 as it highlights areas for further exploration and consideration. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a key limitation of the work, which is the assumption of known number of intent classes during graph construction. It specifically questions whether the IntenDD experiments reported in Table 1 are under this assumption and can be directly comparable to the cited baselines. The reviewer acknowledges this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting. While the comment implies that the authors should provide more details to address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the intent discovery experiment setting. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the assumption of known number of intent classes during graph construction and questions the comparability of the IntenDD experiments to the cited baselines. The comment provides a clear request for further clarification on the intent discovery experiment setting. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point identifies a key limitation of the work, which is the assumption of known number of intent classes during graph construction. It questions whether the IntenDD experiments reported in Table 1 are under this assumption and can be directly comparable to the cited baselines. The reviewer acknowledges this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting. While the comment highlights a potential issue, it lacks specific examples or detailed reasoning to fully substantiate the claim. The authors would need to infer the need for clarification, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a key limitation of the work, which is the assumption of known number of intent classes during graph construction. It specifically questions whether the IntenDD experiments reported in Table 1 are under this assumption and can be directly comparable to the cited baselines. The reviewer acknowledges this as a limitation but suggests that further clarification is needed on the intent discovery experiment setting to ensure fair comparison with baselines. This feedback is clear and actionable, as it provides a specific area for the authors to address and improve their draft. However, it could be more helpful if it offered additional guidance on how to conduct this clarification or what specific aspects should be considered. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical issue and provides a clear path for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment acknowledges the rigorous experimentation but points out the limited significance of the results due to the application of dseparation criteria in the intervened graph with known variables and causal relationships. It suggests that the experiments on the corrupted CIFAR and ImageNet datasets could be simplified by requiring knowledge of corruption labels. However, the comment does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback is implicit and lacks concrete details, making it difficult for the authors to know what changes to make. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment acknowledges the rigorous experimentation but points out the limited significance of the results due to the application of dseparation criteria in the intervened graph with known variables and causal relationships. It suggests that the experiments on the corrupted CIFAR and ImageNet datasets could be simplified by requiring knowledge of corruption labels. However, the comment does not specify which part of the paper discusses these experiments or the dseparation criteria, making it weakly grounded. The comment is specific in identifying the issue with the significance of the results and suggesting a potential simplification, but without explicit references to sections, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point acknowledges the rigorous experimentation but critiques the significance of the results, suggesting that the application of dseparation criteria in the intervened graph with known variables and causal relationships is limited. The reviewer provides references to support the claim, such as works by Martin Arjovsky et al. and Polina Kirichenko et al., which discuss invariant risk minimization and robustness to spurious correlations. This provides a solid foundation for the critique, making the claim 4. However, the comment could be strengthened by further elaboration on how the dseparation criteria limits the significance of the results or by providing more specific examples from the paper. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment acknowledges the rigorous experimentation but points out a limitation in the significance of the results, specifically regarding the application of dseparation criteria in the intervened graph with known variables and causal relationships. It suggests that the experiments on the corrupted CIFAR and ImageNet datasets could be simplified by requiring knowledge of corruption labels, which would simplify the problem. The comment provides a clear and actionable suggestion for improving the draft by highlighting a potential area for simplification. However, it could be more helpful if it offered additional guidance on how to implement this suggestion or provided examples of how the simplification might affect the results. Overall, the comment is 4 as it identifies a specific area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the reliance on gradientbased saliency methods for evaluating feature map channel importance, suggesting that this approach may not align with the feature selection mechanisms in the human brain. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what alternative methods to consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the reliance on gradientbased saliency methods for evaluating feature map channel importance, suggesting that this approach may not align with the feature selection mechanisms in the human brain. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. The comment is specific in its critique of the method\"s alignment with human brain mechanisms but lacks grounding as it does not reference a particular section or figure. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the reliance on gradientbased saliency methods for evaluating feature map channel importance, suggesting that this approach may not align with the feature selection mechanisms in the human brain. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that gradientbased methods are not suitable for this purpose. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2, as it provides a general critique but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises a concern about the reliance on gradientbased saliency methods for evaluating feature map channel importance, suggesting that this approach may not align with the feature selection mechanisms in the human brain. While the comment identifies a potential issue with the methodology, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. Without actionable feedback or alternative methods, the comment provides limited value to the authors in terms of improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper uses Pythia, which is not stateoftheart (SOTA), but highlights the advantage of having available checkpoints. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should consider using a different model, why the current choice is problematic, or how to address the issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the model choice in the paper, specifically mentioning Pythia and noting that it is not stateoftheart (SOTA). However, it does not specify which part of the paper discusses the model choice, making it weakly grounded. The comment is specific in identifying the issue with the model choice, but it lacks detailed guidance on how to address this issue or what alternative models could be considered. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that Pythia is not stateoftheart (SOTA), but it highlights the advantage of having available checkpoints. However, the comment lacks specific evidence or references to support the claim that Pythia is not SOTA. Without detailed justification or examples, the claim remains 1, as it does not provide a clear basis for the authors to understand and address the issue. Therefore, the comment is categorized as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the model choice in the paper, noting that Pythia is not stateoftheart (SOTA) despite having available checkpoints. This feedback is 3 as it highlights a potential weakness in the paper\"s methodology. However, it lacks depth and does not provide suggestions or guidance on how the authors might address this issue or improve their model choice. Without actionable advice or specific recommendations, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggests that the authors provide more information to challenge the community to solve the image observation version of Franka Kitchen. It questions whether the failure of existing works is due to the incompleteness of offline RL algorithms or the lack of image representation learning. Additionally, it asks if the task can be intuitively completed with the provided offline data and suggests leveraging alternative data sources if not. While the comment implies that the authors should provide more information or resources, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide more information and address the questions raised. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the image observation version of Franka Kitchen and suggests providing more information to challenge the community to solve it. It also questions the failure of existing works, attributing it to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment further asks if the task can be intuitively completed with the provided offline data and suggests leveraging alternative data sources. However, the comment does not specify which part of the paper these questions pertain to, making it weakly grounded. The questions are specific in nature, providing clear directions for the authors to address. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions and suggestions aimed at prompting the authors to provide more information and address specific aspects of their work. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, seeking clarification rather than making assertions. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises several questions and suggestions that could help the authors improve their draft. It questions the failure of existing works, suggesting that it might be due to the incompleteness of offline RL algorithms or the lack of image representation learning. The comment also asks if the task can be intuitively completed with the provided offline data and suggests leveraging alternative data sources. While the comment identifies areas for improvement and prompts the authors to provide more information, it lacks specific guidance or suggestions on how to address these issues. The feedback is 3 as it highlights potential weaknesses and areas for further exploration, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point asks for insight into why the multilingual model is described as \"noticeably weaker\" on specific evaluations. While it implies that the authors should provide an explanation, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors need to determine how to address the question themselves. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 236,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking for insight into why the multilingual model is described as \"noticeably weaker\" on the ET\u2192En and LV\u2192EN evaluations. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the description of the multilingual model\"s performance. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for additional information, making it a normal statement.", "helpfulness_rationale": "The review comment seeks clarification on why the multilingual model is described as \"noticeably weaker\" on specific evaluations. While it identifies a potential area of confusion in the paper, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment lacks actionable feedback, such as recommending additional analysis or comparisons, which would be more helpful for the authors to improve their draft. Therefore, the comment is 2, as it highlights a concern but does not offer a clear path for resolution."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaning of numbers in brackets in tables 1 and 2. While it identifies a specific issue, it does not provide explicit guidance on how the authors should address this question or clarify the numbers. The action is implicit, as the authors can infer that they need to explain the meaning of these numbers, but it lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"tables#1,2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the meaning of the numbers in brackets in these tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the meaning of numbers in brackets in tables 1 and 2. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the unclear meaning of numbers in brackets in tables 1 and 2. This is a clear and actionable piece of feedback that can help the authors improve the clarity and readability of their work. By addressing this issue, the authors can enhance the understanding of their results and make their findings more accessible to readers. However, the comment could be more helpful if it provided suggestions on how to clarify these numbers or presented examples of how similar issues have been resolved in other works. Overall, the comment is 4 as it points out a specific area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the connection between the presented RDRO results and the limitations of previous fairness notions, particularly in the context of longterm fairness. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the draft. The comment lacks concrete suggestions or detailed instructions, leaving the authors uncertain about how to proceed. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the connection between the presented RDRO results and the limitations of previous fairness notions, particularly in the context of longterm fairness. However, it does not specify which part of the paper discusses these limitations or where the RDRO results are presented, making it weakly grounded. The comment is specific in identifying the need to connect the results to the limitations, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the connection between the presented RDRO results and the limitations of previous fairness notions, particularly in the context of longterm fairness. The reviewer expresses a lack of understanding about how these results relate to the limitations mentioned in the paper. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that the connection is unclear or missing. This lack of supporting evidence makes the claim 2, as the authors may find it challenging to address the critique without further clarification or evidence.", "helpfulness_rationale": "The review comment identifies a gap in the paper by questioning the connection between the presented RDRO results and the limitations of previous fairness notions, particularly in the context of longterm fairness. It highlights a potential area for improvement by suggesting that the authors should clarify how their results relate to these limitations. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what aspects of the results should be emphasized. While it points out an important area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the accuracy of the table assembly tasks, noting that 29 percent accuracy is low. It also questions the high Euclidean distance error units in Table 1, suggesting that they might be normalized per datapoint position errors. The reviewer implies that an error of 5 cm with HDRIL is unreasonably high. While the comment highlights specific issues, it does not provide explicit guidance on how to address these concerns or improve the accuracy or error analysis. The authors are left to infer that they need to investigate the accuracy and error normalization, but the comment lacks concrete steps or suggestions for improvement. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the accuracy of the table assembly tasks, noting a low accuracy of 29 percent and questioning the high Euclidean distance error units. The comment further suggests that the errors might be normalized per datapoint position errors and points out that an error of 5 cm with HDRIL seems unreasonably high. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point raises a concern about the accuracy of table assembly tasks, noting a low accuracy of 29 percent. It also questions the high Euclidean distance error units in Table 1, suggesting that they might be normalized per datapoint position errors. The reviewer points out that an error of 5 cm with HDRIL seems unreasonably high. While the comment raises a valid concern, it lacks specific references or detailed reasoning to fully substantiate the claim. The authors would need to conduct further analysis to understand the context and implications of these observations. Therefore, the comment is 3, as it provides a basis for concern but requires additional evidence or explanation to fully support the claim.", "helpfulness_rationale": "The review comment raises a concern about the accuracy of table assembly tasks, noting a low accuracy of 29 percent. It also questions the high Euclidean distance error units in Table 1, suggesting that they might be normalized per datapoint position errors. The reviewer points out that an error of 5 cm with HDRIL seems unreasonably high, which provides a specific area for the authors to investigate and potentially address. While the comment identifies a potential issue, it does not offer detailed guidance or suggestions on how to improve the accuracy or error analysis. However, it provides a clear direction for the authors to focus on, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment states that the article provides a fresh perspective but does not reach a conclusion, suggesting that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or improve the draft. As a result, the comment lacks actionability, leaving the authors without any clear direction on how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the article provides a fresh perspective but does not reach a conclusion, implying that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, it does not specify which part of the paper this observation is based on, nor does it provide details on what needs to be addressed or improved. Without specific references or detailed feedback, the authors cannot confidently determine which sections or aspects of the paper need revision. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the article provides a fresh perspective but does not reach a conclusion, suggesting that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specific evidence or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without detailed reasoning or references, the claim remains 1, as it does not provide a clear justification for the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the article provides a fresh perspective but does not reach a conclusion, implying that existing sentiment analysis models are already capable of handling both combinatorial and uncombinatorial sentences. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue or improve their draft. Without detailed guidance or examples, the authors are left without clear direction on how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm design is primarily based on the labeler\"s strategy, which is already predefined. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the contribution of their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the theoretical results, noting that they are not surprising and have limited contribution to the algorithm design. However, it does not specify which part of the paper these theoretical results are discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the theoretical results are considered \"not surprising\" or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the theoretical results are not surprising and have limited contribution to the algorithm design, as the algorithm design is mainly based on the labeler\"s strategy, which is already predefined. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion that the results are not surprising or how they contribute to the algorithm design. This makes the claim 3, as the authors would need to infer the basis of the critique without explicit evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment critiques the theoretical results, noting that they are not surprising and have limited contribution to the algorithm design. It points out that the algorithm design is primarily based on the labeler\"s strategy, which is already predefined. While this feedback highlights a potential issue with the novelty and impact of the theoretical results, it lacks specific suggestions or guidance on how the authors might address this concern or improve the contribution of their work. The comment provides some insight into the limitations of the theoretical results but does not offer actionable advice for improvement. Therefore, the comment is 3, as it identifies a potential weakness but does not fully support the authors in making improvements. This aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "1", "actionability_rationale": "The review point raises two concerns: first, it questions the detailed explanation of how reverse chain proved to be effective in multiAPI planning, and second, it critiques the article for focusing on comparing multiple tools or methods in API calling and planning, which it claims reduces the research contribution. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how to address these issues or improve the draft. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises two concerns: first, it questions the detailed explanation of how reverse chain proved to be effective in multiAPI planning, and second, it critiques the article for focusing on comparing multiple tools or methods in API calling and planning, which it claims reduces the research contribution. However, the comment does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact sections that need attention. The lack of specific references or detailed guidance on what needs to be improved makes the comment 2. Therefore, this comment aligns with a score of 2.", "verifiability_rationale": "The review point consists of two separate claims. The first claim questions the detailed explanation of how reverse chain proved to be effective in multiAPI planning, which is a subjective opinion. The second claim critiques the article for focusing on comparing multiple tools or methods in API calling and planning, which reduces the research contribution. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. Therefore, the claims are 3, as they provide some reasoning but require more detailed evidence to be fully substantiated.", "helpfulness_rationale": "The review comment raises two concerns: first, it questions the detailed explanation of how reverse chain proved to be effective in multiAPI planning, and second, it critiques the article for focusing on comparing multiple tools or methods in API calling and planning, which it claims reduces the research contribution. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. Without actionable feedback or detailed advice, the authors are left without a clear path forward for enhancing their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly recommends rejecting the paper due to its weaknesses in experimental rigor, content space, and degree. It also suggests that the significant editing required to address other issues is unrealistic in terms of time and space. This feedback provides clear and direct guidance on why the paper should be rejected and highlights specific issues that are difficult to resolve. The authors are given a clear understanding of the reasons for rejection and the challenges in addressing the issues mentioned. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment provides a recommendation for rejection based on the weaknesses identified in the review. However, it does not specify which aspects of the paper are considered weaknesses, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment lacks grounding as it does not reference specific sections, tables, or figures, and it is also not specific in detailing what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a recommendation for rejection based on the weaknesses identified in the paper. However, it does not provide any specific reasoning or evidence to support why the weaknesses are significant or how they could be addressed. The comment lacks detailed justification or examples, making it difficult for the authors to understand the basis of the recommendation. As a result, the claim is 1 due to the absence of supporting details.", "helpfulness_rationale": "The review comment provides a clear and actionable recommendation for rejection of the paper, citing the weaknesses in experimental rigor, content space, and degree. It also highlights the unrealistic nature of the significant editing required to address other issues. This feedback is valuable as it gives the authors a specific and direct path to follow in improving their draft. However, the comment could be more helpful if it offered suggestions on how to address the weaknesses or provided additional context on the challenges faced. Overall, the comment is 4 as it guides the authors toward a clear decision but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the fairness of the competition between standalone Medusa and Medusa+ParallelSpec, suggesting that the speedup gain might be due to the change in the draft model architecture rather than parallel prediction. The reviewer proposes that a baseline should be provided where only the architecture of the draft model is altered, and suggests that the current name might be misleading. While the comment identifies a potential issue and provides a specific suggestion for improvement, it does not explicitly instruct the authors to implement this suggestion or provide detailed guidance on how to create the baseline. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"original Medusa setup\" and the \"Medusa+ParallelSpec\" setup, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a concern about the fairness of the competition between the two setups, questioning the extent to which the speedup gain is due to the change in architecture versus parallel prediction. The comment suggests providing a baseline to clarify the impact of the architecture change, which adds depth to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the fairness of the competition between standalone Medusa and Medusa+ParallelSpec. It questions the extent to which the speedup gain is due to the change in architecture rather than parallel prediction. The comment suggests providing a baseline where only the architecture is altered, implying that the current name might be misleading. However, the comment lacks specific examples or references to support the claim that the competition is unfair or to clarify the impact of the architecture change. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the competition between standalone Medusa and Medusa+ParallelSpec. It points out that the speedup gain might be due to the change in architecture rather than parallel prediction. The comment suggests providing a baseline where only the architecture is altered, which would help clarify the impact of the change. This feedback is clear and actionable, as it guides the authors to improve the clarity and fairness of their comparison. However, it could be more helpful if it included specific suggestions on how to implement the baseline or further elaborated on the implications of the architecture change. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the focus on Masked Language Models and the results of experiments with autoregressive LMs. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address these questions or improve their draft. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises questions about the focus on Masked Language Models and the results of experiments with autoregressive LMs. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. Additionally, the comment lacks specificity regarding what aspects of the focus on Masked Language Models or the results of experiments with autoregressive LMs are problematic. Without explicit references or detailed guidance, the authors may struggle to address the feedback effectively. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of questions seeking clarification about the focus on Masked Language Models and the results of experiments with autoregressive LMs. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises questions about the focus on Masked Language Models and the results of experiments with autoregressive LMs. While it identifies areas of potential interest or concern, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment does not guide the authors on how to address these questions or what aspects of the paper might need clarification or revision. As a result, the feedback is 2, as it highlights potential issues but does not offer a clear path for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"How is the map encoded?\" and \"should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" The first question is explicit, as it directly asks for clarification on the encoding process. However, it does not provide guidance on how to address this question or what specific information is needed. The second question is also explicit, as it clearly instructs the authors to demonstrate the effectiveness of their method on experiments proposed in YNet. However, it lacks concrete details on how to implement this suggestion, such as which experiments to include or how to measure effectiveness. Overall, the comment provides some explicit actions but lacks detailed guidance, making it 3.", "grounding_specificity_rationale": "The comment raises two questions: \"How is the map encoded?\" and \"should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" The first question is specific about the encoding process, but it does not specify which part of the paper this question pertains to, making it weakly grounded. The second question is more specific, as it suggests that the authors should demonstrate the effectiveness of their method on experiments proposed in YNet, but it also lacks grounding as it does not specify which part of the paper this suggestion is related to. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions: \"How is the map encoded?\" and \"should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" These are questions seeking clarification and suggestions for improvement, rather than claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions: \"How is the map encoded?\" and \"should the authors have shown the effectiveness of their method on the experiments proposed in YNet?\" These questions are clear and actionable, as they direct the authors to clarify a specific aspect of their methodology and to consider demonstrating the effectiveness of their method on additional experiments. However, the comment does not provide further guidance or suggestions on how to address these questions or what specific experiments should be included. While it points out areas for improvement, it lacks depth and specificity, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the proposed model is not significantly better than the MSA Transformer in terms of R\u00b2. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, improve their model, or justify the claim. Without any actionable steps or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"2), the proposed model is not more much better than MSA Transformer in terms of r2,\" but it does not specify which part of the paper this refers to, making it weakly grounded. The comment is specific in that it points out a comparison between the proposed model and MSA Transformer in terms of R\u00b2, which provides a clear area for improvement. However, without explicit grounding, the authors cannot confidently determine which part of the paper is being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed model is not significantly better than the MSA Transformer in terms of R\u00b2. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim or address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a specific claim that the proposed model is not significantly better than the MSA Transformer in terms of R\u00b2. However, it lacks depth and does not provide any context, reasoning, or suggestions for how the authors might address this issue or improve their model. Without actionable feedback or guidance, the comment does not offer much value to the authors in terms of improving their draft. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of clarity regarding the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the scaling observed in the test error. It suggests that the authors should provide more mathematical details to clarify this point. While the comment implies that additional mathematical explanations are needed, it does not specify exactly what kind of details are missing or how to present them. The action is implicit and somewhat vague, as the authors know they need to add more details but are not given specific guidance on what to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the top of page 6,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the lack of clarity regarding the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the scaling observed in the test error. The comment requests more mathematical details to clarify this point, providing a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the concept \"ensemble of independent measures on the full feature space\" and its relevance to the observed scaling in the test error. The reviewer suggests that more mathematical details are needed to clarify this point. However, the comment does not provide specific examples, references, or detailed explanations to support the claim that the concept is unclear or poorly explained. This lack of supporting evidence makes the claim 3, as the authors would need to infer the need for more details on their own. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires clarification, namely the concept of \"ensemble of independent measures on the full feature space\" and its relevance to the observed scaling in the test error. It points out that the authors do not adequately explain this concept, which is crucial for understanding the hypothesis presented in the paper. The comment suggests that the authors should provide more mathematical details to clarify this point, which would significantly enhance the clarity and comprehensibility of the paper. However, the comment could be more helpful if it offered specific suggestions on what kind of mathematical details would be beneficial or if it provided examples of how to present the concept more clearly. Overall, the feedback is 4 as it directs the authors to a specific area needing improvement and provides a clear direction for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should consider using BlenderBot version 2.0 with incorporated knowledge and explore how dialog improvements can be achieved using domain ontologies from the SGD dataset. While the comment implies that the authors should try this approach, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should conduct this exploration. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests using BlenderBot version 2.0 with incorporated knowledge and explores the potential of improving dialogues using domain ontologies from the SGD dataset. However, it does not specify which part of the paper this suggestion relates to, such as a particular section or experiment. The authors might infer that it pertains to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting a potential improvement, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should consider using BlenderBot version 2.0 with incorporated knowledge and explore the potential of improving dialogues using domain ontologies from the SGD dataset. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be beneficial or how it could improve the dialogues. Without specific examples or explanations, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests an interesting direction for improvement by recommending the use of BlenderBot version 2.0 with incorporated knowledge and exploring the potential of improving dialogues using domain ontologies from the SGD dataset. This feedback is 3 as it identifies a potential area for innovation and provides a specific suggestion for further exploration. However, the comment lacks depth and does not offer detailed guidance or examples on how to implement this suggestion, which would make it more actionable. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the difference between \"argwise consistency\" and \"accuracy,\" which suggests that the authors should clarify these concepts in their paper. However, it does not provide explicit guidance on how to address this issue or what specific changes are needed to improve the clarity. The comment implies that the authors should explain these terms more clearly, but it lacks concrete instructions on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the difference between \"argwise consistency\" and \"accuracy,\" suggesting that the authors should clarify these concepts. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for clarification, but without explicit references to sections or figures, the authors may struggle to identify the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the difference between \"argwise consistency\" and \"accuracy,\" suggesting that the authors should clarify these concepts. However, the comment does not provide any supporting evidence, reasoning, or references to justify the claim that the difference is confusing or that the label annotation agreement should be lower. Without additional context or explanation, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the difference between \"argwise consistency\" and \"accuracy,\" which could be confusing for readers. It suggests that the authors should clarify these concepts in their paper. However, the comment does not provide specific guidance or suggestions on how to address this issue or improve the clarity of the paper. While it identifies a potential area for improvement, it lacks actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are provided, could enhance reproducibility. It also recommends sharing the code of their implementation, which is a significant request for reproducibility. The comment is explicit in its suggestions, specifying what additional information and resources the authors should provide to improve reproducibility. The actions are concrete, as they clearly outline what needs to be done to enhance the paper\"s reproducibility. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests providing more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are provided, to enhance reproducibility. It also recommends sharing the code of their implementation, which is a significant request for reproducibility. However, the comment does not specify which part of the paper discusses the neural network parametrization or the reverse process, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in suggesting what additional information is needed to enhance reproducibility, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that providing more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are provided, could enhance reproducibility. It also recommends sharing the code of their implementation, which is a significant request for reproducibility. While the comment identifies a potential area for improvement, it lacks specific examples or detailed reasoning to fully substantiate the claim. The suggestion to share the code is logical, but the lack of detailed justification or examples makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors provide more details on the neural network parametrization of the reverse process, particularly regarding how position embeddings are provided. This suggestion could enhance the reproducibility of the work. Additionally, the comment recommends sharing the code of their implementation, which is a significant request for reproducibility. By addressing these points, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it provided examples or specific guidance on how to provide these details. Overall, the feedback is 4 as it offers clear directions for improvement, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a specific issue in the paper, namely that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is clear and direct, providing the authors with a clear action to take: remove the duplicate paragraph to avoid redundancy. The comment is specific and concrete, as it not only identifies the problem but also specifies what needs to be done to address it. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the first paragraph of section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue as a \"repeated paragraph,\" providing a clear direction for the authors to take action. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the first paragraph of section 3.3 contains a repeated paragraph. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, namely that the first paragraph of section 3.3 contains a repeated paragraph. This feedback is clear and actionable, as it points out a redundancy that could be addressed by the authors to improve the clarity and originality of their work. By removing the duplicate paragraph, the authors can enhance the overall quality and coherence of their draft. However, the comment could be more helpful if it provided additional context or suggestions on how to avoid such repetitions in the future. Despite this, the feedback is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reusability and sustainability of synthetic data, which is relevant to the onthefly generation of data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider the sustainability and reusability of synthetic data, but it lacks concrete steps or actions to take. As a result, the authors are left without a clear understanding of what specific changes or improvements are needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the reusability and sustainability of synthetic data, which is relevant to the onthefly generation of data mentioned in the paper. However, it does not specify which part of the paper this question pertains to, such as a particular section or discussion on data generation. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the sustainability and reusability of synthetic data, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the reusability and sustainability of synthetic data, which is relevant to the onthefly generation of data. However, it does not provide any supporting evidence, reasoning, or references to justify why this is an important consideration or how it impacts the paper. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the concern. As a result, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a relevant question about the reusability and sustainability of synthetic data, which is an important consideration in the context of onthefly data generation. This feedback highlights a potential weakness in the paper, as it does not adequately address the practicality and longterm implications of using synthetic data. However, the comment lacks specific suggestions or guidance on how the authors might address this issue, such as recommending ways to assess or improve the sustainability of synthetic data. While it points out an important area for improvement, the feedback could be more helpful with additional details or actionable advice. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two issues with the introduction of the ProbTransfomer model: the lack of consideration for the likelihood of alternative RNA structures arising from biological circumstances and the need to consider RNA abundance when building datasets. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The authors are left to infer that they should incorporate these considerations into their work, but without concrete steps, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the introduction of the ProbTransfomer model and raises two specific issues: the lack of consideration for the likelihood of alternative RNA structures arising from biological circumstances and the need to consider RNA abundance when building datasets. However, it does not specify which part of the paper discusses the introduction of the ProbTransfomer model, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as examining the likelihood of alternative RNA structures and considering RNA abundance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors should consider RNA abundance when building datasets, as it is not currently addressed. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence weakens the verifiability of the claim, leaving it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. First, it points out that the authors do not consider the likelihood of alternative RNA structures arising from biological circumstances, which is a critical aspect of RNA folding. Second, it suggests that the authors should consider RNA abundance when building datasets. These observations are clear and actionable, providing the authors with specific directions for enhancing their work. However, the comment could be more helpful if it offered additional guidance on how to incorporate these considerations into the analysis or datasets. Overall, the feedback is 4 as it highlights important areas for improvement and provides a clear basis for action."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review point highlights a discrepancy between the information in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the dataset is stated to have no evidence in the table, but the paper claims that sources used by journalists were collected and included in the analysis. This feedback suggests that the authors should clarify or correct the information in Table 1 to align with the text. The action is explicit, as it clearly states what needs to be done, and it is concrete because it specifies the exact part of the table that needs correction. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue: the discrepancy between the information in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. The comment provides a clear request for clarification or correction, making it easy for the authors to understand what needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between the information in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the dataset is stated to have no evidence in the table, but the paper claims that sources used by journalists were collected and included in the analysis. This claim is 3 as it provides a clear observation of the inconsistency between the table and the text. However, it lacks specific examples or detailed reasoning to fully substantiate the claim, making it 3.", "helpfulness_rationale": "The review comment identifies a discrepancy between the information presented in Table 1 and the text of the paper regarding the Vlachos and Riedel 2014 dataset. It points out that the dataset is stated to have no evidence in the table, but the paper claims that sources used by journalists were collected and included in the analysis. This feedback is clear and actionable, as it directs the authors to correct the inconsistency in their presentation. By addressing this issue, the authors can ensure that their paper accurately reflects the information provided in the text, enhancing the credibility and consistency of their work. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly instructs the authors to include details about the parameters used in each simulator, such as whether they used the GPU or CPU pipeline, the substeps for physics simulation, and the number of total vertices. This provides a clear and direct action for the authors to take, ensuring they know exactly what information to add to improve their draft. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need to include details about the parameters used in each simulator, such as the GPU or CPU pipeline, substeps for physics simulation, and the number of total vertices. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific, as it clearly specifies what needs to be included in the details about the parameters for each simulator. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that different simulators have varying parameters that can significantly impact performance, and it requests the inclusion of details about these parameters. However, the comment does not provide any specific reasoning or evidence to support why this is a critical issue or how it affects the overall performance. Without additional context or examples, the claim remains vague and lacks sufficient justification, making it difficult for the authors to understand the importance of the suggestion. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper, noting that different simulators have varying parameters that can significantly affect overall performance. It provides a clear and actionable suggestion to include details about these parameters, such as whether the GPU or CPU pipeline was used, the substeps for physics simulation, and the number of total vertices. This feedback is specific and offers a concrete way for the authors to enhance the clarity and comprehensiveness of their work. By addressing this feedback, the authors can improve the robustness and reliability of their findings, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a potential issue with the empirical selection of hyperparameters $s$ and $k$ in the proposed method, suggesting that this choice reduces the generalizability of the loss function. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve the generalizability. The comment implies that the authors should consider a more systematic or theoretically grounded approach to selecting $s$ and $k$, but it lacks concrete steps or suggestions for implementation. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Supplementary Material A.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the empirical selection of hyperparameters $s$ and $k$ and how this affects the generalizability of the proposed loss function. The comment provides a clear understanding of what needs to be addressed in terms of improving the generalizability of the method. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the choice of hyperparameters $s$ and $k$ is crucial for the effectiveness of the proposed method but notes that these values are empirically selected in the supplementary material. The reviewer suggests that this empirical selection reduces the generalizability of the proposed loss function. However, the comment lacks specific examples or detailed reasoning to support the claim that the empirical selection is insufficient. While the authors might infer that the lack of theoretical justification for the choice of $s$ and $k$ is a concern, the comment does not provide enough detail to fully substantiate the claim. Therefore, the comment is 3, as it provides a logical basis but lacks comprehensive evidence or examples.", "helpfulness_rationale": "The review comment identifies a potential issue with the empirical selection of hyperparameters $s$ and $k$ in the proposed method, which could affect the generalizability of the loss function. It highlights that the choice of these hyperparameters is crucial for the effectiveness of the method but lacks a theoretical or systematic basis for their selection. This feedback is valuable as it prompts the authors to consider a more robust approach to hyperparameter selection, potentially leading to a more generalizable and reliable method. However, the comment could be more helpful if it provided suggestions on how to address this issue or recommended alternative methods for selecting hyperparameters. Overall, the comment is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their optimization times with OpenTuner, which can adaptively use different search techniques. While the comment implies that the authors should conduct this comparison, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to determine the exact steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OpenTuner,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a comparison of optimization times with OpenTuner, which can adaptively use different search techniques. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should compare their optimization times with OpenTuner, which uses adaptive search techniques. However, the comment does not provide specific reasoning or evidence to support why this comparison is necessary or how it would benefit the paper. It lacks detailed justification or examples, making it difficult for the authors to understand the significance of the suggestion. Therefore, the claim is considered 2, as it provides some direction but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment suggests a specific comparison with OpenTuner, which uses adaptive search techniques, to evaluate the optimization times of the authors\" work. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance their analysis by comparing their results with a known adaptive search framework. However, the comment could be more helpful if it offered additional guidance on how to conduct this comparison or what specific aspects of the comparison should be emphasized. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the limited novelty of the work, noting that many existing works have already introduced diffusion models into anomaly detection. It suggests that the introduction of NCSN into this area is not original. Additionally, it points out that the work only makes minor adjustments to NCSN by combining techniques like time step embedding and finding a correspondence between anomaly scores and diffusion scores. However, the comment does not provide explicit guidance or suggestions on how the authors could address these issues or improve the novelty of their work. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment critiques the novelty of the work, noting that many existing works have already introduced diffusion models into anomaly detection. It specifically mentions works 1, 2, and 3, which provides some grounding by referencing specific works. However, the comment does not specify which part of the paper discusses the introduction of NCSN into anomaly detection or how it adapts the model. This makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in identifying the issue of limited novelty and the lack of originality, but it lacks detailed guidance on how to address these concerns. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is not novel, as it builds upon existing works that have introduced diffusion models into anomaly detection. The reviewer references specific works (1, 2, 3) to support this claim, providing a basis for the critique. However, the comment does not elaborate on how these existing works differ from the current approach or what makes the current work unique. While the references provide some support, the lack of detailed explanation or comparison makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of novelty in the work, noting that many existing works have already introduced diffusion models into anomaly detection. It references specific works (1, 2, 3) to support this claim, providing a clear basis for the critique. Additionally, the comment points out that the work only makes minor adjustments to NCSN by combining techniques like time step embedding and finding a correspondence between anomaly scores and diffusion scores. This feedback is 3 as it highlights areas where the work could be more original and suggests that the authors need to address these limitations. However, the comment could be more helpful if it provided specific suggestions on how to enhance the novelty or originality of the work. Overall, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point identifies specific issues with grammar and labeling in the paper. It explicitly mentions two grammar errors and the lack of labeling in Figure 2. The comment provides clear guidance for the authors to correct the grammar and ensure that the axes in Figure 2 are properly labeled. This level of detail gives the authors a direct and concrete action to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issues with grammar and the lack of labeling in Figure 2, providing clear guidance on what needs to be corrected. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: identifying grammar errors and noting the lack of labeling in Figure 2. The first part is a factual observation, as it points out specific instances of grammar issues. The second part is also factual, as it mentions the absence of labels in Figure 2. Neither part contains subjective claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies specific issues with the paper, such as grammar errors and the lack of labeling in Figure 2. By pointing out these areas, the comment provides clear and actionable feedback that can help the authors improve the clarity and professionalism of their draft. However, the comment could be more helpful if it offered suggestions on how to correct the grammar errors or improve the labeling in Figure 2. Despite this, the feedback is 4 as it directs the authors to areas needing attention and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the error analysis in section 5.2 is insufficient and recommends that a more quantitative error analysis would be beneficial. While the comment implies that the authors should conduct a more detailed error analysis, it does not provide specific guidance on how to achieve this or what aspects of the error analysis should be improved. The action is implicit and somewhat vague, as the authors need to infer the need for a more detailed error analysis and determine the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"5.2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that a more quantitative error analysis would be beneficial, providing clear guidance on what needs to be improved. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the error analysis in section 5.2 is \"crappy\" and suggests that a more quantitative error analysis would be beneficial. However, the comment does not provide any specific examples, references, or detailed reasoning to support why the current error analysis is insufficient or how a more quantitative approach would improve it. This lack of supporting evidence makes the claim difficult for the authors to address effectively, rendering the comment 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement, noting that the error analysis in section 5.2 is insufficient and suggesting that a more quantitative error analysis would be beneficial. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the quality of the error analysis. However, the comment could be more helpful if it offered specific guidance on how to conduct a more quantitative error analysis or provided examples of what kind of additional analysis would be beneficial. Despite this, the comment is 4 as it directs the authors toward a meaningful improvement in their draft."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should not rely solely on tSNE for evaluating distribution alignment and recommends using the ProxyA distance as an additional measure. This is an explicit action, as it clearly instructs the authors to include this additional metric. However, the comment also mentions that Figure 6c and 6d appear to be the same and suggests crosschecking if the ProxyA distance is close to them. While this part of the comment is somewhat vague, the explicit suggestion to use the ProxyA distance makes the overall comment 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 6c, 6d,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by recommending the use of the ProxyA distance as an additional measure for evaluating distribution alignment, which is a clear and specific request for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should not rely solely on tSNE for evaluating distribution alignment and recommends using the ProxyA distance as an additional measure. This claim is 3 as it provides a specific suggestion for improvement, but it lacks detailed reasoning or references to support why the ProxyA distance is a better measure. The mention of \"Fig. 6c, 6d\" being the same is also a suggestion for crosschecking, but it does not provide a full explanation or evidence for why this observation is problematic. Therefore, the comment is rated as 3, as it provides some justification but lacks comprehensive support.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that the authors should not rely solely on tSNE for evaluating distribution alignment. It recommends using the ProxyA distance as an additional measure, which is a clear and constructive suggestion for improving the robustness of their analysis. Additionally, the comment points out that Figures 6c and 6d appear to be the same and suggests crosschecking if the ProxyA distance is close to them, which could help identify potential issues in the visualization. This feedback is 4 as it offers concrete steps for the authors to enhance the reliability and comprehensiveness of their evaluation. However, it could be more helpful if it provided further guidance on how to implement the suggested changes or why the ProxyA distance is particularly important. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises questions about the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. While it implies that the authors should provide a rationale and evaluate the performance, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address these questions in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines \"L216217,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the rationale behind using cross entropy for the first (P  floor(t/m)) phrases and the performance when using a reinforcement algorithm for all phrases. While it identifies areas for clarification, it does not provide actionable feedback or suggestions on how the authors might address these questions or improve their draft. The comment lacks depth and does not offer guidance on potential improvements or alternative approaches, making it 2. Therefore, it aligns with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a gap in the paper\"s related work section, specifically noting that the proposed crossmodality adaptation has been validated in BEVDepth 1 and 2DPASS 2, but the paper does not discuss these in the related work. However, it does not provide explicit guidance on how the authors should address this gap or incorporate these references into their related work section. The action is implicit, as the authors can infer that they need to include these references, but the comment lacks concrete details on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue regarding the validation of the proposed crossmodality adaptation in BEVDepth 1 and 2DPASS 2, but it does not specify which part of the paper should discuss these validations. The authors can infer that it relates to the related work section, but this inference is not direct. The comment is specific in identifying the need for discussion of these validations but lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed crossmodality adaptation has been validated in BEVDepth 1 and 2DPASS 2, but the paper does not discuss these in the related work section. However, the comment does not provide specific references or detailed reasoning to support the claim that these validations are relevant or necessary. Without explicit evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s related work section by pointing out that the proposed crossmodality adaptation has been validated in BEVDepth 1 and 2DPASS 2, but these references are not discussed in the related work. This feedback highlights an area where the paper could be improved by providing a more comprehensive discussion of related work. However, the comment does not offer specific suggestions on how the authors might address this gap or integrate these references into their discussion. While it points out a potential improvement, the lack of actionable guidance limits its helpfulness. Therefore, the comment is 3, as it provides insight into an area for improvement but lacks detailed guidance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Table 1 only presents test loss as a metric for performance degradation and lacks generation results like BLEU scores to assess the quality of output. While it identifies a specific area for improvement, it does not provide explicit guidance on how to incorporate these additional metrics or suggest which metrics to include. The action is implicit and somewhat vague, as the authors know they need to add generation results but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of generation results such as BLEU scores in Table 1, in addition to test loss, to assess the quality of output. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Table 1 only presents test loss as a metric for performance degradation and lacks generation results like BLEU scores to assess the quality of output. This claim is 3 as it highlights a specific issue with the presentation of results in the paper. However, it lacks detailed reasoning or examples to fully substantiate the claim, such as explaining why the absence of generation results is a significant concern or how it affects the evaluation of the output quality. Providing more context or references to similar studies would enhance the verifiability of the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Table 1, noting that it only presents test loss as a metric for performance degradation and lacks generation results like BLEU scores to assess the quality of output. This feedback is clear and actionable, as it highlights a gap in the evaluation of the output quality that the authors need to address. By suggesting the inclusion of generation results, the comment provides a concrete step for the authors to take in improving their draft. However, it could be more helpful if it offered additional guidance on which specific generation metrics to include or how to present them effectively. Overall, the comment is 4 as it directs the authors to a specific area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include experiments to validate their analysis, particularly for discussions on different regimes. While the comment implies that the authors should add these experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should conduct experiments and specify which aspects of the analysis require validation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should include experiments to validate their analysis, particularly for discussions on different regimes. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for additional experiments to validate the analysis, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper, despite being a theory paper, could benefit from additional experiments to validate the analysis, particularly for discussions on different regimes. However, the comment does not provide specific examples of what kind of experiments would be beneficial or how they could be conducted. This lack of detailed guidance or references makes the claim 3, as the authors would need to infer the necessary experiments and their relevance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper, despite being a theory paper, could benefit from additional experiments to validate the analysis, particularly for discussions on different regimes. This feedback is 3 as it identifies a potential area for improvement, encouraging the authors to conduct experiments that could strengthen their analysis. However, the comment lacks specificity regarding which aspects of the analysis need validation or what kind of experiments would be most beneficial. Without detailed guidance, the authors may find it challenging to implement the suggested improvements. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests including two naive baselines with only text and a single center frame as part of the benchmark. This is an explicit action, as it clearly states what the authors should do to improve their draft. The comment provides a concrete suggestion for enhancing the benchmark, making it actionable. However, it does not specify how to implement these baselines or what specific insights the authors should expect, which could be a minor gap. Despite this, the action is clear and direct, making the comment 4.", "grounding_specificity_rationale": "The comment suggests including two naive baselines with only text and a single center frame as part of the benchmark. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these baselines should be included. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the inclusion of these baselines to provide insights into the benchmark, but without clear grounding, it is challenging for the authors to apply the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests including two naive baselines with only text and a single center frame as part of the benchmark. However, it does not provide any supporting evidence, reasoning, or references to justify why these baselines would be beneficial or how they might contribute to the benchmark. The lack of detailed explanation or examples makes it difficult for the authors to understand the rationale behind the suggestion, rendering the claim 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests including two naive baselines with only text and a single center frame as part of the benchmark. This is a specific and actionable suggestion that could provide valuable insights into the benchmarking process. By proposing these baselines, the reviewer is encouraging the authors to explore additional aspects of their work that might not have been considered. However, the comment could be more helpful if it provided more context or explanation on why these baselines are relevant or how they might impact the results. Despite this, the suggestion is clear and actionable, making the comment 4. Therefore, it aligns with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that while each part of the proposed method is effective, the overall algorithm is cumbersome due to its multiple stages. It contrasts this with existing pruning methods that do not require finetuning. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the issue of the algorithm being cumbersome or how they could improve it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the overall algorithm being cumbersome due to multiple stages, contrasting it with existing pruning methods that do not require finetuning. However, it does not specify which part of the paper this observation pertains to, such as a particular section or method description. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue of the algorithm being cumbersome, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the overall algorithm is cumbersome due to multiple stages, contrasting it with existing pruning methods that do not require finetuning. However, the comment lacks specific examples or references to existing methods that are mentioned, making it difficult for the authors to understand the basis of the claim. The reasoning is somewhat vague, as it does not provide detailed comparisons or evidence to support the assertion that the proposed method is cumbersome. Therefore, the comment is categorized as 2, as it provides some reasoning but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment identifies a potential issue with the overall algorithm being cumbersome due to its multiple stages, contrasting it with existing pruning methods that do not require finetuning. This observation highlights a gap in the paper that could be addressed by simplifying the algorithm or integrating it with more efficient methods. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the algorithm. While it points out a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential weakness but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the new quantile function (3) compared to the existing function (2). It highlights that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large, but the paper does not provide supporting data on why this reduced sensitivity is desired. While the comment identifies a gap in the justification for the change, it does not explicitly instruct the authors to address this issue or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide supporting data or reasoning for the change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the comparison between the new quantile function (3) and the existing function (2), allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the change in the function and the issue of reduced sensitivity to tail parameters when they are large, and it points out the lack of supporting data on why this reduced sensitivity is desired. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the advantage of the new quantile function (3) over the existing function (2) is unjustified. It highlights that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large. However, the comment does not provide specific examples, data, or references to support why the reduced sensitivity is desired or how it impacts the overall performance of the function. This lack of detailed justification makes the claim 3, as the authors would need to infer the reasoning behind the claim and may require further explanation or evidence to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the new quantile function (3) compared to the existing function (2). It points out that the change from multiplicative factors to an additive term makes the function less sensitive to tail parameters when they are large, but the paper does not provide supporting data on why this reduced sensitivity is desired. This feedback is 3 as it highlights a gap in the justification for the change and prompts the authors to consider the implications of this modification. However, it could be more helpful if it provided suggestions on how to address this issue or why the reduced sensitivity might be beneficial. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that Figure 3 is confusing and provides specific points for improvement regarding the contribution of the work over SWEBench. It highlights two main issues: the low contribution and the potential misrepresentation of the benchmark. The reviewer points out that if a model can fix a bug, it inherently involves fault localization, which is already tested in the repair benchmarks. Additionally, it suggests that the LLM\"s role in issue generation is not necessary, as unit tests can be passed automatically. While the comment identifies areas for improvement, it does not provide explicit instructions on how to address these issues or suggest specific changes to the figure or text. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the contribution over SWEBench is low and questions the authors\" claims regarding the benchmark\"s new additions. The comment further elaborates on the potential misrepresentation of the benchmark, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 3 is confusing and that the contribution over SWEBench is low. It also questions the authors\" claims regarding the benchmark\"s new additions, specifically suggesting that the fault localization capabilities are already tested in repair benchmarks and that the LLM\"s role in issue generation is unnecessary. The comment provides logical reasoning by explaining that if a model can fix a bug, it inherently involves fault localization, which is already tested. However, it lacks specific examples or references to support the claim about the LLM\"s role, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 3, suggesting that it is confusing. It also critiques the authors\" claim about the contribution over SWEBench, questioning the validity of their benchmark\"s new additions. The comment provides logical reasoning by explaining that if a model can fix a bug, it inherently involves fault localization, which is already tested in repair benchmarks. Additionally, it suggests that the LLM\"s role in issue generation is unnecessary, as unit tests can be passed automatically. While the comment highlights important areas for improvement, it lacks specific suggestions or detailed guidance on how to address these issues. Therefore, the feedback is 3, as it provides insight into potential weaknesses but does not offer actionable steps for improvement. This aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the generality of the system identification method, questioning whether it will improve simtoreal policy deployment based on a single realworld manipulation case. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern or what steps they could take to strengthen their argument. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the generality of the system identification method, specifically questioning whether it will improve simtoreal policy deployment based on a single realworld manipulation case. However, it does not specify which part of the paper this concern is based on, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this issue is discussed, the comment lacks full grounding. It is specific in identifying the concern about the generality of the method, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generality of the system identification method, questioning whether it will improve simtoreal policy deployment based on a single realworld manipulation case. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a valid concern about the generality of the system identification method, questioning whether it will improve simtoreal policy deployment based on a single realworld manipulation case. This feedback highlights a potential weakness in the paper, prompting the authors to consider the robustness and applicability of their method beyond the specific case presented. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this concern or strengthen their argument. While it identifies an important area for improvement, the feedback could be more helpful with additional insights or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment expresses skepticism about the quality of the ShortcutQA, suggesting that while the edits are verified to not change the semantics, they might introduce ambiguity, potentially degrading performance. The reviewer asks for details on how the distracted texts are \"answerable\" and requests examples and qualitative results to support this claim. While the comment implies that the authors should provide additional evidence or examples, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide specific details and examples. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"ShortcutQA,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the quality of the shortcut QA by suggesting that while the edits are verified to not change semantics, they might introduce ambiguity, potentially degrading performance. The comment further requests details on how the distracted texts are \"answerable\" and asks for examples and qualitative results to support this claim. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point expresses skepticism about the quality of the ShortcutQA, suggesting that while the edits are verified to not change semantics, they might introduce ambiguity, potentially degrading performance. The reviewer requests details on how the distracted texts are \"answerable\" and provides examples and qualitative results to support this claim. This request for additional evidence and examples makes the comment 4, as it provides a clear direction for the authors to address the concern. However, it could be more robust if it included specific examples or references to support the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the quality of the ShortcutQA, questioning whether the edits introduced by the authors might lead to ambiguity and degradation in performance. It suggests that while the edits are verified to not change the semantics, they might introduce ambiguity, which could affect the performance. The reviewer provides a clear and actionable suggestion by asking for details on how the distracted texts are \"answerable\" and requests examples and qualitative results to support this claim. This feedback is 4 as it guides the authors to provide additional evidence and examples to strengthen their work. However, it could be more helpful if it included specific examples or suggested how to address the potential ambiguity. Therefore, the comment is rated as 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" This is an explicit action, as it clearly states what the authors should do to improve their draft. However, it lacks concrete details on how to implement this suggestion, such as whether a specific section or part of the text should include the pointer. While the action is clear, the lack of detailed guidance makes it 3.", "grounding_specificity_rationale": "The comment suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" However, it does not specify which part of the paper this issue is related to, making it weakly grounded. The comment is specific in suggesting the inclusion of a forward pointer to clarify the definition of \"deep,\" which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" However, it does not provide any supporting evidence, reasoning, or examples to justify why this addition would be beneficial or necessary. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper would be clearer if it included a forward pointer to the definition of \"deep.\" This feedback is 3 as it identifies a specific area for improvement, which is the clarity of the paper. However, the comment lacks depth and does not provide further guidance on how to implement this suggestion or why it is particularly important. The authors are left with a general idea of what to improve but without detailed instructions on how to achieve it. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a practical concern about the number of archetypes, k, and questions whether the presented framework allows for model selection to determine an appropriate k. While the comment implies that the authors should explore this aspect, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate model selection for determining k. However, the comment provides a clear direction for the authors to consider, making it 3.", "grounding_specificity_rationale": "The comment raises a practical concern about the number of archetypes, k, and questions whether the presented framework allows for model selection to determine an appropriate k. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a way to perform model selection to identify an appropriate k, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the practical aspect of the number of archetypes, k, and whether the presented framework allows for model selection to determine an appropriate k. However, it does not provide any claim, judgment, or suggestion that requires verification. It is purely a question seeking clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a practical concern about the number of archetypes, k, and questions whether the presented framework allows for model selection to determine an appropriate k. This feedback is 3 as it identifies a potential area for improvement in the paper, prompting the authors to consider model selection for determining k. However, the comment lacks depth and does not provide specific suggestions or guidance on how to implement model selection or what criteria to use for determining k. While it highlights an important aspect of the paper, it does not fully support the authors in making significant improvements. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to clarify the placement of Theorem 1, noting that it is missing at the beginning of page 6, where Theorem 2 is directly mentioned. It also suggests that the counting of Assumptions, Lemmas, and Theorems should be separated. This feedback provides clear and direct actions for the authors to take, ensuring they know exactly what needs to be addressed and how to do it. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Theorem 1\" and \"Theorem 2,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the missing placement of Theorem 1 and the need for separated counting between Assumptions, Lemmas, and Theorems. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the placement of Theorem 1 in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the organization of the paper, noting that Theorem 1 is missing at the beginning of page 6, where Theorem 2 is directly mentioned. It also suggests that the counting of Assumptions, Lemmas, and Theorems should be separated. This feedback is clear and actionable, providing the authors with a direct point of reference and a specific suggestion for improvement. By addressing this issue, the authors can enhance the clarity and structure of their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of long document summarization. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what changes could be made to the draft to address it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of long document summarization. However, it does not specify which part of the paper this assumption is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in questioning the assumption, it lacks grounding as it does not provide clear guidance on where in the paper this issue is addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task. The reviewer questions whether this assumption holds for long document summarization, similar to its application in QA. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that this assumption is too heavy or not generalizable. Without additional context or evidence, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a concern about the assumption that a subsequence shorter than the length limit of pretrained Transformers is necessary and sufficient for performing a target task, particularly in the context of long document summarization. It questions whether this assumption holds beyond QA tasks. While the comment identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this concern or improve their approach. The feedback is 3 as it prompts the authors to reconsider their assumptions, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method appears straightforward and that the novelty is marginal. It raises a question about the clarity of certain aspects, specifically mentioning line 180 and the potential issue of having multiple different graphs if different weights are learned for edges. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve the clarity of their work. The feedback lacks actionable details, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 180,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the proposed method and the potential issue of having multiple different graphs if different weights are learned for edges. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is \"very straightforward\" and that the novelty is marginal. It raises a question about the clarity of certain aspects, specifically mentioning line 180 and the potential issue of having multiple different graphs if different weights are learned for edges. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. The authors are left to infer the basis of the critique, making it difficult to fully understand and address the feedback. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient evidence or detail to be fully substantiated.", "helpfulness_rationale": "The review comment points out that the proposed method appears straightforward and that the novelty is marginal, which suggests that the authors may need to provide more detailed explanations or evidence to justify the novelty of their approach. The comment also raises a specific question about the clarity of the method, particularly regarding line 180, and questions the potential issue of having multiple different graphs if different weights are learned for edges. This feedback is 3 as it identifies areas where the authors need to clarify their work, but it lacks depth and actionable suggestions. The authors are given a starting point for improvement but are not provided with comprehensive guidance on how to address the issues. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments are limited in scope, mentioning that there are only two simulation experiments and a third example involving time of travel by taxis. It suggests that a more complicated manifold would be beneficial to explore. While the comment implies that the authors should consider expanding their experiments to include more complex manifolds, it does not provide specific guidance on how to implement this suggestion or what specific aspects of the experiments should be expanded. The action is implicit and somewhat vague, as the authors know they need to consider more complex examples but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments on a unit sphere and spiral curves, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out the limitation of the experiments being limited to specific examples and suggesting a more complicated manifold for learning geometry. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are limited in scope, suggesting that the authors should consider more complex manifolds for learning geometry. The comment provides a specific example of a unit sphere, where the geometry can be learned using only firstorder information, and suggests that a more complicated manifold would be beneficial. However, the comment lacks detailed reasoning or examples to fully substantiate the claim, such as how a more complex manifold would offer additional insights or challenges. This makes the claim 3, as it provides a direction for improvement but requires more detailed justification or examples to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the scope of the experiments, noting that only two simulation experiments and a third example involving time of travel by taxis are presented. It suggests that exploring the geometry of a more complicated manifold would be beneficial. This feedback is 3 as it highlights a potential area for improvement, encouraging the authors to consider a broader range of examples. However, the comment could be more actionable by providing specific suggestions or examples of more complex manifolds that could be explored. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights a perceived weakness in the paper, noting that the current knowledge relies on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might improve the template or integrate the LLM\"s abilities more effectively. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the reliance on a specific template for the current knowledge, which lacks naturalness and does not fully utilize the capabilities of the LLM. However, it does not specify which part of the paper this critique pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the perceived weakness but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the current knowledge relies on a specific template, which lacks naturalness and does not fully utilize the capabilities of the LLM. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a perceived weakness in the paper, specifically the reliance on a specific template that lacks naturalness and does not fully utilize the capabilities of the LLM. This is an important observation that could impact the validity and comprehensiveness of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve the template. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the number of baselines is small, which affects the universality and generality of the study. However, it does not provide any explicit or implicit suggestions on how to address this issue. The authors are left without guidance on how to increase the number of baselines or what specific steps to take to enhance the study\"s universality and generality. Without actionable advice or examples, the authors may struggle to understand how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the issue of a small number of baselines, which affects the universality and generality of the study. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the problem of having a small number of baselines, it lacks grounding as it does not provide clear guidance on where this issue is discussed in the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the number of baselines is small, which degrades the universality and generality of the study. However, the comment does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out a potential weakness in the study, specifically the small number of baselines, which may limit the universality and generality of the findings. However, it lacks specificity and does not provide actionable guidance or suggestions on how to address this issue. Without detailed feedback or examples, the authors may struggle to understand how to improve their draft. Therefore, the comment is 2, as it identifies a problem but does not offer a clear path for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights the absence of information about the tokenizer training, specifically mentioning the mixture of corpus size and the software stack, which are important factors in practice. However, it does not provide explicit guidance on what the authors should do to address this issue. The comment implies that the authors should include this information, but it lacks concrete instructions on how to incorporate it into their draft. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment highlights the absence of information about the tokenizer training, specifically mentioning the mixture of corpus size and the software stack. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in detailing what is missing, namely the details about the tokenizer training. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no information about the tokenizer training, specifically mentioning the mixture of corpus size and the software stack. However, the comment does not provide any supporting evidence, references, or detailed reasoning to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper regarding the information about the tokenizer training, including the mixture of corpus size and the software stack. This is a clear and actionable piece of feedback that highlights a critical area where the authors need to provide more detailed information. By addressing this issue, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it suggested ways to incorporate this information or provided examples of how to present it effectively. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the necessity of the cotraining, positive mining, and alternate optimization steps proposed by the authors, suggesting that the additional complexity may not be justified. However, it does not provide explicit guidance or suggestions on how the authors should address this concern. The comment implies that the authors should clarify the necessity of these steps, but it lacks concrete instructions on how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the proposed positive mining framework, which is similar to a reference A. It questions whether the additional complexity of the proposed method is warranted and asks if the cotraining, positive mining, and alternate optimization steps are necessary. However, the comment does not specify which part of the paper discusses these steps, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in questioning the necessity of these steps, providing a clear direction for improvement. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the additional complexity in the proposed positive mining framework, suggesting that it may not be justified. The comment references a specific work (A) for comparison, which provides a basis for the critique. However, the comment lacks detailed reasoning or examples to fully substantiate the claim that the additional complexity is unwarranted. While the reference to A adds some context, the lack of further explanation or evidence makes the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of the additional complexity in the proposed positive mining framework, questioning whether it is justified. It points out that the paper does not address this question, leaving the authors with a gap in their explanation. The comment suggests that the cotraining, positive mining, and alternate optimization steps, which are the main contributions of the paper over prior work, may not be necessary. This feedback is 3 as it identifies a critical area for clarification and prompts the authors to justify the complexity of their proposed method. However, it could be more helpful if it provided specific suggestions or examples to address the concern. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential limitation of the approach, specifically the computational complexity of multimarginal OT and spline calculations, which may limit scalability for large datasets. It suggests that a more comprehensive discussion is required. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or what specific aspects of the discussion need to be expanded. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide a more detailed discussion on computational complexity. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the computational complexity of multimarginal OT and spline calculations, suggesting that a more comprehensive discussion is needed. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation and suggesting a need for a more detailed discussion, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the computational complexity of multimarginal OT and spline calculations may limit the scalability of the approach for large datasets, which could be problematic for realworld applications. The comment suggests that a more comprehensive discussion is required. However, it lacks specific examples or references to support the claim about the computational complexity, making it difficult for the authors to fully understand and address the issue. The lack of detailed justification or evidence makes the claim 3, as it provides a general observation but requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential limitation of the approach, specifically the computational complexity of multimarginal OT and spline calculations, which may limit scalability for large datasets. It suggests that a more comprehensive discussion is required to address this issue. While the comment highlights a critical area that could impact the applicability of the approach, it lacks specific guidance or suggestions on how to improve the discussion or address the computational complexity. The feedback is 3 as it points out a potential weakness, but it could be more actionable with additional details or recommendations. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors evaluated their work based on only 10 samples, which may have led to biased findings due to the small scale of the experiment. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should increase the sample size, what specific changes to make, or how to mitigate the potential bias. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 6.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the evaluation, noting that it was based on only 10 samples, which may have resulted in biased findings due to the small scale of the experiment. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation in Section 6.2 was based on only 10 samples, which may have resulted in biased findings due to the small scale of the experiment. While the comment identifies a potential issue with the sample size, it lacks specific examples or references to support the claim about the bias. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is categorized as 2, as it provides some indication of the problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the evaluation methodology in Section 6.2, specifically noting that the authors based their evaluation on only 10 samples. This is a critical point because a small sample size can lead to biased findings and may not accurately represent the broader context or population being studied. The comment highlights a weakness in the experimental design and provides a clear and actionable suggestion for improvement by suggesting that the authors should consider increasing the sample size to ensure more reliable and unbiased results. This feedback is 4 as it directs the authors to a specific area for improvement and offers a clear path for enhancing the robustness of their evaluation. However, it could be more helpful if it provided additional guidance on how to increase the sample size or what specific changes might be necessary. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential limitation of the method, specifically its applicability to significantly different combinatorial optimization problems. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or what experiments could be conducted to explore the method\"s generalizability. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the generalizability of the method, specifically noting that it is tailored to similar MILP tasks and potentially limiting its applicability to significantly different combinatorial optimization problems. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the potential limitation of the method\"s generalizability, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is tailored to similar MILP tasks, potentially limiting its generalizability to significantly different combinatorial optimization problems. The comment acknowledges this limitation but does not provide specific examples or references to support the claim. Without detailed evidence or examples, the claim remains 3, as the authors may find it challenging to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation of the method, specifically its applicability to significantly different combinatorial optimization problems. It acknowledges this limitation but does not provide specific suggestions or guidance on how the authors might address it or expand the scope of their work. While it highlights an important area for consideration, the comment lacks actionable advice or detailed feedback, making it 3. The authors are given a point to consider but are not provided with a clear path forward for improvement. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a difficulty in understanding how the baselines (Rerank and Adv) work and their relation to InterFair, as well as whether they are sufficiently competitive. However, it does not provide explicit guidance or suggestions on how the authors should clarify these aspects in their draft. The feedback lacks actionable details, such as specific questions or recommendations for improvement, leaving the authors uncertain about how to address the issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Results section\" and the specific lines (L256261) where the baseline is described, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the baseline description, namely the difficulty in understanding how these baselines work, their relation to InterFair, and whether they are sufficiently competitive. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point expresses difficulty in understanding the baselines and their relation to InterFair, as well as whether they are sufficiently competitive. However, it does not provide specific examples, detailed explanations, or references to support these claims. The lack of detailed justification or evidence makes it challenging for the authors to understand and address the issue effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the brief description of the baselines in the Results section, noting that the authors struggle to understand how these baselines work and their relation to InterFair, as well as whether they are sufficiently competitive. This feedback is 3 as it highlights areas where the authors need to clarify their work, but it lacks depth and actionable suggestions. The comment provides a starting point for improvement but does not offer specific guidance on how to address these issues. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any explicit guidance or suggestions on how the authors should address this issue. The comment lacks concrete details on what aspects of the comparison are lacking or how the authors might improve it. Without specific instructions or examples, the authors are left without a clear understanding of what steps to take to enhance their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment highlights a specific issue with the comparison to other baselines on cycle counting and ZINC, indicating that this comparison is insufficient. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on what aspects of the comparison are lacking. Without explicit references to sections, figures, or tables, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the comparison are insufficient or how they could be improved. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the comparison to other baselines on cycle counting and ZINC is insufficient. However, it does not provide any specific examples, detailed reasoning, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the comparison to other baselines on cycle counting and ZINC. It highlights that this comparison is insufficient, which is a clear and actionable piece of feedback. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might improve their comparison or address the identified issue. While it points out a critical area for improvement, the feedback could be more helpful if it included recommendations on how to conduct a more comprehensive comparison or what aspects of the comparison could be enhanced. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. This feedback implies that the authors should provide a more detailed analysis or justification for the effectiveness of this specific combination. However, the comment does not explicitly instruct the authors to include this explanation or provide guidance on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should add a detailed explanation but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective, while most similar ones are not. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a clearer explanation, but without explicit grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper would benefit from a clearer explanation of why a specific combination of mask snippets is particularly effective. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this explanation is necessary or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the paper would benefit from a clearer explanation of why a particular combination of mask snippets is particularly effective, while most similar ones are not. This feedback is actionable as it provides a clear direction for the authors to enhance the clarity and depth of their explanation. However, the comment could be more helpful if it offered specific suggestions on how to present this explanation or examples of what might be included. Overall, the comment is 4 as it highlights a meaningful area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the performance of SLQ compared to previous CRD methods, as evidenced by the F1 score and conductance values. It also notes that in Figure 3, SLQ shows worse performance than CRD, and in Figure 4, the improvement over ACL appears minimal. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or improve the performance of SLQ. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3\" and \"Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by comparing the performance of SLQ with previous CRD methods and noting the limitations in SLQ\"s performance as shown in the figures. This provides clear guidance on what needs to be addressed in terms of performance evaluation and comparison. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of SLQ, as measured by F1 score and conductance values, is limited compared to previous CRD methods. It supports this claim by referencing specific figures (Figure 3 and Figure 4) where SLQ shows worse performance than CRD and minimal improvement over ACL. The use of specific figures and metrics provides a clear basis for the claim, making it 4. However, the comment could be strengthened by providing more detailed analysis or comparison of the results, which would enhance the verifiability of the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the performance of SLQ compared to previous CRD methods, as evidenced by the F1 score and conductance values. It provides specific references to Figures 3 and 4, where SLQ shows worse performance than CRD and minimal improvement over ACL. This feedback is clear and actionable, as it highlights areas where the authors need to address the performance issues of SLQ. However, the comment could be more helpful if it offered suggestions on how to improve SLQ or alternative approaches to enhance its performance. Overall, the comment is 4 as it directs the authors\" attention to a critical area that needs improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should add more baselines for robust performance comparisons, despite the existence of ample work. This feedback provides a clear and direct action for the authors to take, specifying what needs to be added to improve the draft. The comment is specific and actionable, as it clearly indicates the need for additional baselines and how to implement this change. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the selection of baselines is limited to naive/old models, despite the existence of ample work. It encourages the authors to add more baselines for robust performance comparisons. However, the comment does not specify which part of the paper discusses the baselines or where the authors should add these additional baselines. This makes it weakly grounded, as the authors cannot confidently determine the exact section being addressed. The comment is specific in suggesting the addition of more baselines, but without grounding, it lacks clarity on which part of the paper needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the selection of baselines is limited to naive/old models, despite the existence of ample work. The reviewer suggests adding more baselines for robust performance comparisons. However, the comment lacks specific examples or references to support the claim that the current baselines are insufficient or that more baselines are needed. Without detailed justification or evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a significant limitation in the selection of baselines, noting that they are limited to naive/old models despite the existence of ample work. It provides a clear and actionable suggestion by encouraging the authors to add more baselines for robust performance comparisons. This feedback is specific and constructive, offering a clear direction for improvement that can enhance the paper\"s comprehensiveness and validity. However, the comment could be more helpful if it provided examples of additional baselines or discussed the potential impact of these additions. Overall, the comment is 4 as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should justify their choice of target structures in Table 2 or provide additional experiments to demonstrate the method\"s adaptability to different target structures. This feedback is clear and provides a direct action for the authors to take, ensuring they know exactly what needs to be addressed. The comment is specific in its request for justification or additional experiments, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the choice of target structures and provides a request for justification or additional experiments to demonstrate the method\"s adaptability to different target structures. This guidance is clear and actionable, making the comment 5.", "verifiability_rationale": "The review point questions the choice of target structures in Table 2, suggesting that the authors should justify their selection or provide additional experiments to demonstrate the method\"s adaptability to different target structures. While the comment raises a valid concern about the generalizability of the proposed method, it lacks specific examples or references to support the claim. The authors would need to conduct further analysis or experiments to address this feedback, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the choice of target structures in Table 2, questioning why only a limited set of target structures (2816, 7680, 8) was used for evaluation. It suggests that the authors should either justify this choice or provide additional experiments to demonstrate the method\"s adaptability to different target structures. This feedback is clear and actionable, as it prompts the authors to consider the generalizability of their method and potentially expand their experiments. By addressing this comment, the authors can enhance the robustness and applicability of their findings, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation in the application scope of the research, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios like medical diagnosis. It suggests that exploring applications in critical areas like healthcare could significantly increase the paper\"s impact and relevance. While the comment identifies a potential area for improvement, it does not provide specific guidance on how to address this limitation or what specific applications should be considered. The action is implicit and somewhat vague, as the authors know they need to expand the application scope but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limited application scope of the research, specifically mentioning the knapsack problem and suggesting that more realistic scenarios, such as medical diagnosis, should be explored. However, it does not specify which part of the paper discusses the knapsack problem or where the application scope is addressed, making it weakly grounded. The comment is specific in suggesting that exploring applications in critical areas like healthcare would increase the paper\"s impact and relevance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the research primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. The comment suggests that exploring applications in critical areas like healthcare would increase the paper\"s impact and relevance. However, the comment lacks specific examples or references to support the claim that the knapsack problem is the only area of focus or that medical diagnosis is a more realistic scenario. Without detailed evidence or examples, the claim is 3, as it provides a general direction for improvement but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the application scope of the research, noting that it primarily focuses on the knapsack problem and neglects more realistic scenarios, such as medical diagnosis. It suggests that exploring applications in critical areas like healthcare could significantly increase the paper\"s impact and relevance. This feedback is 3 as it highlights a potential area for expansion and improvement, providing the authors with a direction for enhancing the scope and applicability of their work. However, the comment could be more helpful if it offered specific examples or guidance on how to explore these additional applications. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the method\"s claimed improvement in robustness and sensitivity, suggesting that the results in Figure 3 do not support this claim. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to improve the robustness and sensitivity. The comment implies that the authors should reconsider their claims or provide additional evidence to support the effectiveness of their method, but it lacks concrete instructions or suggestions for action. As a result, the comment is vague and 1, as the authors do not know what specific steps to take to address the issue. Therefore, it aligns with a score of 2.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"fig 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the method\"s claimed improvement in robustness and sensitivity, and it provides specific feedback about the noise levels in certain domains compared to competitors. This level of detail helps the authors understand what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the method does not improve robustness and sensitivity as suggested in the motivation, based on the results shown in Figure 3. The comment provides specific evidence of the method\"s performance, noting that it is noisier in two domains and equally noisy as competitors in the rest. This level of detail supports the claim with concrete data, making the comment 4. However, it could be further strengthened by referencing specific studies or comparisons that directly address the claimed improvements. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the method\"s claimed improvement in robustness and sensitivity, as evidenced by the results in Figure 3. It points out that the new method is noisier in two domains and equally noisy as competitors in the rest. This feedback is valuable as it highlights a potential flaw in the method\"s performance, prompting the authors to reconsider their claims and provide a more accurate assessment of their method\"s effectiveness. However, the comment could be more helpful if it offered suggestions on how to address this issue or how to improve the method\"s robustness and sensitivity. Overall, the comment is 3 as it directs the authors\" attention to a critical area that needs clarification and improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the robustness of the conclusion in the context of more sophisticated or aggressive removal methods. While it implies that the authors should consider testing their conclusion against these methods, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to conduct additional experiments or analyses to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the robustness of the conclusion in the context of more sophisticated or aggressive removal methods. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. While the question is specific in nature, the lack of grounding makes it challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the robustness of the conclusion in the context of more sophisticated or aggressive removal methods. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it impacts the paper\"s conclusions. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment raises a relevant question about the robustness of the conclusion in the context of more sophisticated or aggressive removal methods. This feedback is valuable as it prompts the authors to consider the generalizability and reliability of their findings. However, the comment lacks specific guidance or suggestions on how to address this concern, such as recommending additional experiments or analyses. While it identifies an important area for improvement, the lack of detailed feedback limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper introduces explainable AI in the introduction but is about interpretable methods. It highlights the lack of explanation regarding the definition of interpretability and the difference between the two concepts. However, it does not provide specific guidance on how the authors should address these issues or what changes are needed to improve the paper. The comment lacks explicit instructions or concrete details on how to enhance the explanation of these concepts, leaving the authors uncertain about the exact actions to take. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the introduction of the paper, where it mentions the topic of explainable AI and interpretable methods. However, it does not specify which part of the introduction or which sections of the paper need to be revised to clarify the definitions and differences between these concepts. The authors can infer that it relates to the introduction, but the comment lacks specific guidance on what needs to be addressed. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the paper introduces \"explainable AI\" in the introduction but is about \"interpretable methods.\" It argues that the authors do not explain the definition of interpretability or the difference between these two concepts. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand and address the issue. The absence of detailed evidence or reasoning makes the claim 2, as it provides a general critique without sufficient support.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s introduction, noting that it introduces \"explainable AI\" but is about \"interpretable methods.\" It points out that the authors do not explain the definition of interpretability or the difference between these two concepts, which is a significant gap in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve the clarity of their introduction. While it highlights an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical weakness but lacks detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the training data used in the compositionality and transitivity experiments. While it highlights a potential area of concern, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify this aspect, but it lacks concrete instructions on what specific changes or additional information are needed. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the training data used in the compositionality and transitivity experiments, which is specific to a particular aspect of the paper. However, it does not explicitly mention which section of the paper this question pertains to, making it weakly grounded. The comment is specific in identifying the need for clarification regarding the training data, but without explicit grounding, the authors may find it challenging to pinpoint the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the training data used in specific experiments. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the training data used in the compositionality and transitivity experiments. This is a relevant and actionable inquiry that could help the authors clarify their methodology and ensure the reproducibility of their results. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their experimental setup. While it identifies a potential area for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the text is unclear regarding the use of \"not only the complete captions but also parts thereof,\" and questions the argument about why filling in the blanks is hard. It also mentions that there are ways to perform bidirectional beam search for fillintheblanks applications. However, the comment does not provide explicit guidance or suggestions on how the authors should clarify these points or address the argument. The feedback is vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lines \"L133134,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the clarity of the text regarding the use of \"not only the complete captions but also parts thereof\" and the argument about why filling in the blanks is hard. Additionally, the comment provides a suggestion by mentioning the possibility of using bidirectional beam search for fillintheblanks applications, which adds specificity to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the clarity of the text regarding the use of \"not only the complete captions but also parts thereof\" and the argument about why filling in the blanks is hard. The reviewer provides a reference to a method involving bidirectional beam search for fillintheblanks applications, which supports the claim by offering a potential solution or alternative approach. This reference adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed reasoning or examples to fully substantiate the argument. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the unclear explanation of what is meant by \"not only the complete captions but also parts thereof.\" It also questions the argument about why filling in the blanks is hard, suggesting that there are ways to perform bidirectional beam search for such applications. This feedback is 3 as it highlights a potential issue with the clarity of the text and provides a suggestion for improvement by referencing a method that could be used. However, the comment could be more helpful if it offered a detailed explanation or examples of how the current approach could be clarified or improved. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment raises concerns about the use of reverse KL divergence in training flows, noting that it assumes differentiability of the function $g$ and is mode seeking, which may be a limitation for applications requiring coverage of all modes of a density. While the comment identifies potential issues, it does not provide explicit guidance on how the authors should address these concerns or suggest alternative approaches. The feedback is somewhat vague and lacks concrete steps for improvement, leaving the authors uncertain about how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of reverse KL divergence in training flows, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by questioning the assumption of differentiability of the function $g$ and the modeseeking nature of reverse KL divergence, suggesting that it may be a limitation for applications requiring coverage of all modes of a density. Additionally, it references recent work on normalizing flows to provide context and suggests a potential limitation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises concerns about the use of reverse KL divergence in training flows, noting its assumptions and limitations. The reviewer provides logical reasoning by explaining the caveats, such as the assumption of differentiability of the function $g$ and the modeseeking nature of reverse KL divergence. The comment also references recent work on normalizing flows to suggest potential limitations, which adds depth to the critique. However, the comment could be strengthened by providing specific examples or references to further substantiate the claims. Overall, the comment is 4, as it provides a clear rationale but lacks detailed evidence or examples to fully substantiate the claims.", "helpfulness_rationale": "The review comment raises a critical point about the use of reverse KL divergence in training flows, noting its assumptions and limitations. It questions the realism of assuming differentiability of the function $g$ and highlights the modeseeking nature of reverse KL divergence, which may be a significant limitation for applications requiring coverage of all modes of a density. The comment also references recent work on normalizing flows to suggest potential limitations, providing a clear and actionable critique. However, the comment could be more helpful if it offered suggestions on how to address these limitations or alternative approaches. Overall, the feedback is 4 as it identifies important concerns and provides a foundation for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that annotations in the visual event detection stage might contain noises due to the use of an offtheshelf semantic role labeling system. It implies that a detailed analysis of the curated dataset is necessary to address this issue. However, the comment does not provide explicit guidance on how to conduct this analysis or what specific aspects should be examined. The action is implicit and somewhat vague, as the authors need to infer the need for a detailed analysis but lack concrete steps on how to implement it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of noise in annotations within the visual event detection stage of the ViStruct Suite. It suggests that a detailed analysis of the curated dataset is necessary to address this issue. However, the comment does not specify which part of the paper discusses the visual event detection stage or the dataset in question, making it weakly grounded. The comment is specific in suggesting the need for a detailed analysis, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that annotations in the visual event detection stage might contain noises due to the use of an offtheshelf semantic role labeling system. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed reasoning or evidence, the claim remains 1, as it does not provide a clear rationale or justification for the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the annotations in the visual event detection stage, suggesting that they might contain noises due to the use of an offtheshelf semantic role labeling system. It highlights the need for a detailed analysis of the curated dataset to address this concern. While the comment points out a potential weakness, it lacks specific guidance or suggestions on how to conduct this analysis or what aspects of the dataset should be examined. This limits the comment\"s usefulness, as it provides insight into a problem but does not offer actionable steps for improvement. Therefore, the comment is 3, as it provides some direction but lacks depth and specificity."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the model implementation should be better justified, specifically pointing out the stopping rule with n consecutive identical samples as arbitrary and lacking discussion on sensitivity with regard to n. While the comment identifies areas for improvement, it does not provide explicit instructions on how to justify the stopping rule or discuss sensitivity. The authors are left to infer that they need to provide more justification and analysis, but the comment lacks concrete guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the model implementation, specifically mentioning the stopping rule with n consecutive identical samples and the lack of discussion on sensitivity with regard to n. This provides some grounding as it refers to specific elements of the model implementation. However, the comment does not explicitly mention which part of the paper discusses these issues, making it weakly grounded. The comment is specific in identifying the need for better justification of the stopping rule and the lack of sensitivity discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the stopping rule with n consecutive identical samples is arbitrary and lacks discussion on sensitivity with regard to n. While the comment identifies a potential issue with the model implementation, it does not provide specific examples or references to support the claim that the stopping rule is arbitrary or lacks sensitivity discussion. This lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to fully understand and address the issue without further clarification.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the model implementation, namely the stopping rule with n consecutive identical samples. It points out that this stopping rule appears arbitrary and lacks discussion on sensitivity with regard to n. This feedback is clear and actionable, as it directs the authors to provide more justification and analysis for their stopping rule. However, the comment could be more helpful if it offered suggestions on how to justify the stopping rule or discussed potential alternatives. Overall, the comment is 4 as it highlights a critical area for improvement and provides a direction for the authors to enhance their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies two main issues that need attention. First, it points out that the authors do not provide a time complexity analysis or running time report for their proposed algorithms, which is important given the NPhard nature of the maximum common subgraph detection problem. Second, it suggests that the proposed \"learntosearch\" algorithm could be compared with stateoftheart algorithms to assess its performance in terms of search time as the number of nodes increases. The comment provides clear and specific actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"maximum common subgraph detection problem\" and the \"proposed algorithms,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of time complexity analysis and running time report for the proposed algorithms, and the suggestion to compare the proposed \"learntosearch\" algorithm with stateoftheart algorithms in terms of search time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors should provide time complexity analysis or running time reports for their proposed algorithms, given the NPhard nature of the maximum common subgraph detection problem. The comment also suggests comparing the proposed \"learntosearch\" algorithm with stateoftheart algorithms in terms of search time. While the comment identifies a logical gap in the paper, it lacks specific examples or references to support the claim about the importance of time complexity analysis. The suggestion to compare with stateoftheart algorithms is also vague and lacks detailed guidance. Therefore, the comment is 3, as it provides a general direction for improvement but lacks specific evidence or detailed reasoning to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies two key areas for improvement in the paper. First, it points out that the authors do not provide a time complexity analysis or report the running time of their proposed algorithms, which is important given the NPhard nature of the maximum common subgraph detection problem. This feedback is actionable, as it directs the authors to include crucial information that would enhance the comprehensiveness and impact of their work. Second, the comment suggests comparing the proposed \"learntosearch\" algorithm with stateoftheart algorithms to assess its performance in terms of search time as the number of nodes increases. This suggestion is also actionable and provides a clear direction for further investigation. Overall, the comment is 4 as it offers specific and actionable feedback that can significantly improve the paper, but it could be more comprehensive with additional guidance on how to conduct the comparison."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of quality control or manual evaluation on the data collected through an automatic modelbased approach. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue, such as suggesting specific methods for quality control or manual evaluation. Without actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights the absence of quality control or manual evaluation on the data collected through an automatic modelbased approach. However, it does not specify which part of the paper this issue pertains to, such as specific sections or figures where data quality is discussed. This makes it difficult for the authors to pinpoint the exact area that needs attention. While the comment is specific about the issue of data quality control, it lacks grounding as it does not provide clear references to the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no quality control or manual evaluation on the data collected through an automatic modelbased approach. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, specifically the lack of quality control or manual evaluation on the data collected through an automatic modelbased approach. This feedback is valuable as it highlights a critical aspect of data validation that the authors should address to ensure the reliability and accuracy of their results. However, the comment does not provide specific suggestions or guidance on how the authors might implement such quality control or evaluation methods. While it points out an important area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks detailed guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors could compare a confidence interval derived from a small development set with the Frechet bound. This implies that the authors should perform this comparison to evaluate the performance of their classifier. While the action is not explicitly stated, it is clear and concrete, providing a direct path for the authors to take. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"most tasks\" and \"a small set of labeled data,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to compare a confidence interval from a small development set with the Frechet bound, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors could compare a confidence interval from a small development set with the Frechet bound. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim. The authors would need to infer the importance of this comparison, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific suggestion for improvement by recommending a comparison between a confidence interval derived from a small development set and the Frechet bound. This feedback is actionable and offers a clear direction for the authors to enhance their work by exploring this comparison. By addressing this suggestion, the authors can potentially gain deeper insights into the performance of their classifier. However, the comment could be more helpful if it included additional context or explanation on why this comparison is important or how it might impact the results. Overall, the comment is 4 as it provides a concrete and actionable suggestion for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation of the proposed method, noting that it is only applicable to problems with lowdimensional input spaces. It explains this limitation as being due to the curse of dimensionality, which arises from using a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint. However, the comment does not provide any explicit or implicit suggestions for how the authors might address this limitation or improve the applicability of their method. There is no guidance on potential modifications, alternative approaches, or additional experiments that could be conducted to overcome this limitation. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the applicability of the proposed method, specifically noting that it is only applicable to problems with lowdimensional input spaces. It explains this limitation as being due to the curse of dimensionality, which arises from using a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint. However, the comment does not specify which part of the paper discusses the method or the experiments, making it weakly grounded. The comment is specific in detailing the limitation and the reasoning behind it, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the proposed method is only applicable to problems with lowdimensional input spaces, citing the curse of dimensionality as the reason. The comment provides a logical explanation for this limitation, explaining that the use of a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint leads to this limitation. However, the comment lacks specific examples or references to support the claim about the curse of dimensionality, which would make it more verifiable. The authors could benefit from additional references or examples to fully understand and address the limitation. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of the proposed method, noting that it is only applicable to problems with lowdimensional input spaces. It explains this limitation as being due to the curse of dimensionality, which arises from using a finite set of points to cover the region of interest in the surrogate modeling of the shape constraint. This feedback is valuable as it highlights a critical weakness in the method\"s applicability and provides a clear explanation of the underlying issue. However, the comment could be more helpful if it offered suggestions on how the authors might address this limitation or explored potential solutions. Despite this, the comment is 4 as it directs the authors\" attention to an important area that needs improvement, providing a solid foundation for further development of their work. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the results of all methods, as presented in Table 1 and Table 2, are within their standard deviations, which implies that the presented method is not significantly better than others. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the draft to support the claim. The action is implicit and vague, as it does not specify how the authors should revise their results or present their findings to strengthen their claim. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1 and Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the results, stating that they are within their standard deviations and thus not supporting the claim of the presented method being significantly better than others. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results of all methods, as presented in Table 1 and Table 2, are within their standard deviations, which undermines the claim that the presented method is significantly better than others. However, the comment does not provide specific data or examples from the tables to support this claim. Without detailed evidence or references, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment identifies a potential issue with the results presented in the paper, specifically noting that the results of all methods are within their standard deviations. This observation challenges the claim that the presented method is significantly better than others. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their results. While it highlights a critical point, the feedback lacks actionable advice, making it 3. The authors would need to infer that they should reconsider their claims or provide additional evidence to support their assertions, which limits the utility of the comment. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights the nontrivial nature of generating synthetic tabular data and provides examples of challenges, such as multiple entries in a table being associated with the same entity. However, it does not offer any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address these challenges or improve their approach. As a result, the comment lacks actionability, leaving the authors without any clear steps to follow to enhance their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment addresses the challenge of generating synthetic tabular data, noting that it is nontrivial due to factors like multiple entries in a table being associated with the same entity. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment provides some specificity regarding the nature of the challenge, it lacks grounding as it does not reference a specific section or part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that generating synthetic tabular data is nontrivial due to factors like multiple entries in a table being associated with the same entity. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any references or evidence to substantiate the assertion, making it difficult for the authors to understand the basis of the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the complexity of generating synthetic tabular data and provides examples of challenges, such as multiple entries in a table being associated with the same entity. However, it does not offer any actionable feedback or suggestions on how the authors might address these challenges or improve their approach. Without specific guidance or recommendations, the comment lacks practical value for the authors in terms of improving their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not provide meaningful guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential issue with the focus on the AmbiQT benchmark, suggesting that it lacks broader context or validation on other datasets. However, it does not provide explicit guidance on how the authors should address this concern or what specific actions they should take to improve the draft. The feedback implies that the authors should consider expanding the scope of their analysis or providing validation on other datasets, but it does not offer concrete steps or examples for how to implement this suggestion. As a result, the comment is vague and lacks actionable details, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the creation of the AmbiQT benchmark, which is a specific aspect of the paper. However, it does not explicitly mention which section or part of the paper this issue pertains to, making it weakly grounded. The comment is specific in its critique, as it points out the potential overemphasis on the AmbiQT benchmark without broader context or validation on other datasets. This provides clear guidance on what needs to be addressed, but the authors still cannot confidently determine the exact part of the paper being discussed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that an overemphasis on the AmbiQT benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance to other scenarios. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides some justification but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the focus on the AmbiQT benchmark, suggesting that an overemphasis on this specific benchmark without broader context or validation on other datasets could lead to questions about its applicability and relevance to other scenarios. This feedback is 3 as it highlights a critical area for improvement, prompting the authors to consider the broader applicability of their benchmark. However, the comment could be more helpful if it provided specific suggestions or examples on how to address this concern, such as recommending additional datasets for validation or discussing the implications of focusing solely on the AmbiQT benchmark. Overall, the comment provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the lack of annotation training details and guidelines, which is important for professional translators dealing with nonstandard tasks. It also mentions the absence of information about the tool used. While the comment identifies specific areas that need attention, it does not provide explicit instructions on how to address these issues or what specific details should be included. The authors are left to infer that they need to provide more information about annotation training and the tool used, but without concrete guidance, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of annotation training details and guidelines, which is relevant to the paper\"s content. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment also mentions the absence of information about the tool used, which is a specific issue that needs attention. While the comment is specific about the issues, it lacks grounding as it does not clearly identify the sections or parts of the paper that need improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks annotation training details and guidelines, which is important for professional translators dealing with nonstandard tasks. It also mentions the absence of information about the tool used. While the comment identifies specific areas that need attention, it lacks detailed reasoning or examples to fully substantiate the claim. The absence of specific references or detailed explanations makes it 3, as the authors would need to infer the importance of these details themselves. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment identifies two significant areas where the paper could be improved: the lack of annotation training details and guidelines, and the absence of information about the tool used. These points are crucial for professional translators dealing with nonstandard tasks, as they highlight potential gaps in the paper\"s comprehensiveness and clarity. However, the comment could be more helpful if it provided specific suggestions on what details or information should be included to address these issues. While it points out important areas for improvement, the feedback lacks depth and actionable guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the presentation of results in Table 1, specifically regarding the boldfacing of \"EX/NORB\" and the statistical significance of the difference between two values. While it implies that the authors should consider these aspects, it does not provide explicit instructions or concrete guidance on how to address these issues. The action is implicit and somewhat vague, as the authors are left to infer that they need to make changes to the presentation and statistical analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the presentation of results, particularly regarding the boldfacing of \"EX/NORB\" and the statistical significance of the difference between two values. This provides clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions about the presentation of results in Table 1, specifically regarding the boldfacing of \"EX/NORB\" and the statistical significance of the difference between two values. These are factual questions seeking clarification, not opinions or claims that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the presentation of results in Table 1, specifically regarding the boldfacing of \"EX/NORB\" and the statistical significance of the difference between two values. While it identifies an area for potential improvement, it does not provide specific guidance or suggestions on how the authors might address these issues. The comment lacks actionable feedback, such as recommending alternative ways to present the results or suggesting statistical tests to determine significance. As a result, the comment is 3, as it highlights a potential area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the metric used for the video level supervision experiment, suggesting that it is not using trackletbased metrics as indicated in the paper. While the comment implies that the authors should provide details on the metrics used, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include details on the metrics used. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the metric used for the video level supervision experiment, suggesting that it is not using trackletbased metrics as indicated in the paper. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in identifying the issue with the metrics used, but without clear grounding, the authors may struggle to determine where to address this concern. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the use of trackletbased metrics for the video level supervision experiment, suggesting that the paper did not provide details on this. However, the comment does not offer any supporting evidence, reasoning, or references to justify why trackletbased metrics are not used or why they should be considered. This lack of detailed explanation or justification makes the claim 1, as the authors may not understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a specific question about the metrics used in the video level supervision experiment, suggesting that the paper did not provide details on this aspect. This feedback is 3 as it identifies a potential gap in the paper\"s explanation, prompting the authors to clarify their methodology. However, the comment lacks depth and does not offer suggestions on how to address this issue or what specific metrics should be considered. To be more helpful, the comment could provide guidance on what kind of details are necessary or suggest alternative metrics to consider. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about why \"person blocking\" affects the models, as shown in Figure 4. It suggests that models might be learning personrelated features, which is undesirable. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider discussing or explaining the impact of person blocking on their models, but it lacks concrete steps or details on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about why \"person blocking\" affects the models, suggesting that models might be learning personrelated features, which is undesirable. The comment provides a clear direction for the authors to consider and address the issue. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about why \"person blocking\" affects the models, as shown in Figure 4. It suggests that models might be learning personrelated features, which is undesirable. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of \"person blocking\" on the models, as shown in Figure 4. It suggests that models might be learning personrelated features, which could be undesirable. While the comment identifies a potential issue, it lacks specific guidance or suggestions on how the authors might address this concern or improve their analysis. The feedback is 3 as it prompts the authors to consider the implications of their findings, but it does not provide actionable steps or detailed insights for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about whether the authors have tried a specific combination of techniques, namely TFIDF and dense retrieval, for evidence sentence extraction. While it implies that the authors should consider this combination, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should explore this combination. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the authors have tried a specific combination of techniques, namely TFIDF and dense retrieval, for evidence sentence extraction. However, it does not specify which part of the paper this question pertains to, such as a particular section or method discussed in the paper. This makes it difficult for the authors to pinpoint the exact location in the paper where this combination might be relevant. While the comment is specific in its suggestion, it lacks grounding as it does not provide clear guidance on where to address this question. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point is a question asking for clarification on whether a specific combination of techniques (TFIDF and dense retrieval) has been tried for evidence sentence extraction. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, making it a normal statement.", "helpfulness_rationale": "The review comment raises a question about whether the authors have tried a specific combination of techniques, namely TFIDF and dense retrieval, for evidence sentence extraction. While it identifies a potential area for exploration, it does not provide any guidance or suggestions on how the authors might approach this combination or why it might be relevant. The comment lacks depth and actionable advice, leaving the authors with only a vague direction for potential improvement. Therefore, it is rated as 2, as it provides some insight but lacks the detailed guidance needed for a more comprehensive improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the paper should mention or provide examples where timeseries prediction did not perform well, specifically in the context of the COVID19 dataset. It provides a concrete example by mentioning the UK and Russia, which are highly correlated despite not being neighboring countries, and asks for more examples. The comment also inquires about the trajectories of other countries and their relation to the top eigenvectors of the Laplacian. This feedback is explicit and provides clear guidance on what additional information the authors should include to enhance their draft. The authors know exactly what needs to be addressed and how to implement the suggested improvements, making this comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the COVID19 dataset and specific countries, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what additional information should be included, such as mentioning cases where timeseries prediction did not perform well and exploring the relationship between country trajectories and the top eigenvectors of the Laplacian. This level of detail provides clear direction for the authors to improve their draft. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper should include examples where timeseries prediction did not perform well, specifically mentioning the COVID19 dataset and the correlation between the UK and Russia. The comment provides a specific example and questions the relevance of the dataset, which adds some level of justification. However, it lacks detailed reasoning or references to support why these examples are important or how they would enhance the paper. The suggestion is 3 as it provides a starting point for improvement but requires further elaboration to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific suggestions for improvement by highlighting areas where the paper could be enhanced. It suggests mentioning or providing examples where timeseries prediction did not perform well, using the COVID19 dataset as a context. The comment also raises questions about the correlation between nonneighboring countries and the relevance of the dataset, prompting the authors to explore these aspects further. Additionally, it inquires about the relationship between country trajectories and the top eigenvectors of the Laplacian, which could be a valuable area for further investigation. This feedback is clear, actionable, and provides a structured approach for the authors to enhance their draft, making it 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the claims of proposing a \"learning framework\" are overblown, as it is not a new framework but a modified loss and architecture. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this feedback, such as suggesting alternative ways to present their claims or providing more detailed explanations. Without actionable advice or specific instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but a modified loss and architecture. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. The comment lacks specificity regarding what aspects of the claims are overblown or how they should be revised. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the claims of proposing a \"learning framework\" are overblown, suggesting that it is not a new framework but a modified loss and architecture. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment critiques the claims of proposing a \"learning framework,\" suggesting that it is not a new framework but a modified loss and architecture. While it identifies a potential issue with the claims, it lacks specificity and does not provide actionable feedback or suggestions for improvement. The comment highlights a concern but does not guide the authors on how to address it or what aspects of their work might need revision. As a result, the comment is 2, as it points out a potential weakness but does not offer a clear path for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a limitation in the specificity of the learned prompts, which are currently tailored for specific transformerbased architectures like CLIP and DINOv2. It suggests that this specificity may hinder crossmodel generalization, as prompts would need to be retrained for each new architecture. The comment implies that the authors should explore designing prompts with more universal features or optimizing them independently of the model architecture to enhance broader applicability. While the action is implicit, the comment provides a clear direction for improvement by suggesting a potential area for further exploration. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the learned prompts and their customization for specific transformerbased architectures like CLIP and DINOv2. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies the issue with the specificity of the learned prompts and suggests a potential area for improvement by exploring more universal features or optimization independent of model architecture. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the learned prompts are specific to individual transformerbased architectures, such as CLIP and DINOv2, and that this specificity may limit crossmodel generalization. The reviewer suggests that prompts should be designed with more universal features or optimized independently of model architecture for broader applicability. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim about the impact of specificity on crossmodel generalization. The reasoning is 3, as it provides a logical basis for the claim but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the specificity of the learned prompts, which are currently tailored for specific transformerbased architectures like CLIP and DINOv2. It highlights that this specificity may hinder crossmodel generalization, as prompts would need to be retrained for each new architecture. The comment suggests exploring the design of prompts with more universal features or optimizing them independently of model architecture to enhance broader applicability. This feedback is clear and actionable, providing the authors with a specific direction for improving their work. However, it could be more helpful if it included examples or further elaboration on how to achieve this broader applicability. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point raises a concern about the absence of baselines in the paper, suggesting that the model architecture used is somewhat antiquated. It provides a specific suggestion to include comparisons with other models, particularly advanced timeseries forecasting models available in the \"TimeSeries Library\" repository. This feedback is explicit and provides concrete guidance on how the authors can address the concern by adding relevant baselines. The suggestion is clear and actionable, making the comment 5.", "grounding_specificity_rationale": "The comment addresses the absence of baselines in the paper, which raises a concern about the model architecture being somewhat antiquated. It suggests that the current methodology lacks evidence of its effectiveness or novelty compared to contemporary timeseries forecasting architectures. The comment is fully grounded as it explicitly mentions the absence of baselines and the need for comparisons with other models. It is also specific because it provides a concrete suggestion for improvement by recommending the inclusion of advanced timeseries forecasting models, such as those available in the \"TimeSeries Library\" repository. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the antiquated nature of the model architecture used in the paper, suggesting that the current methodology lacks evidence of its effectiveness or novelty compared to contemporary timeseries forecasting architectures. The reviewer provides a specific suggestion to include comparisons with advanced timeseries forecasting models, such as those available in the \"TimeSeries Library\" repository. This claim is supported by logical reasoning and a concrete suggestion for improvement, making it 4. However, the comment could be strengthened by providing more detailed examples or references to specific models that could be used as baselines. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant concern regarding the lack of baselines in the paper, suggesting that the model architecture used appears to be somewhat outdated. It provides a clear and actionable suggestion by recommending the inclusion of comparisons with other models, particularly advanced timeseries forecasting models available in the \"TimeSeries Library\" repository. This feedback is valuable as it guides the authors to enhance the robustness and novelty of their methodology by incorporating relevant baselines. However, the comment could be more helpful if it provided specific examples of these advanced models or explained how their inclusion would strengthen the paper. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper only presents standard MLPs as baselines, suggesting that at least one strong baseline should be included in one of the tasks. While the comment implies that the authors should consider adding a more robust baseline, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a strong baseline and determine which task would benefit most from it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the baselines presented in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of strong baselines in the tasks, and suggests that at least one strong baseline should be included. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only presents standard MLPs as baselines, suggesting that at least one strong baseline should be included in one of the tasks. However, the comment does not provide any supporting evidence, reasoning, or references to justify why standard MLPs are insufficient or why a strong baseline is necessary. This lack of detailed justification makes the claim 1, as the authors may not fully understand the basis of the critique. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific weakness in the paper, noting that the only baselines presented are standard MLPs. It suggests that the authors should include at least one strong baseline in one of the tasks. This feedback is clear and actionable, as it provides a concrete suggestion for improvement that could enhance the paper\"s relevance and robustness. However, the comment could be more helpful if it offered additional guidance on what constitutes a strong baseline or how to implement it. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the proposed method is similar to two prior works cited by the authors and recommends that the paper more clearly compare the proposed method to these prior works. It also advises including these prior works for comparison in the tables of experimental results. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done to improve the paper. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and two prior works cited by the authors, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, the need for a clearer comparison to the prior works and the inclusion of these prior works in the tables of experimental results. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is very similar to two prior works cited by the authors. However, it does not provide any specific examples or detailed reasoning to support this claim, nor does it offer any references or evidence to substantiate the assertion. Without additional context or comparison, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the paper, noting that the proposed method is very similar to two prior works cited by the authors. It suggests that the paper should more clearly compare the proposed method to these prior works and include them for comparison in the tables of experimental results. This feedback is actionable and provides a clear direction for the authors to enhance the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it offered specific suggestions on how to conduct the comparison or what aspects of the comparison should be emphasized. Overall, the comment is 4 as it guides the authors on how to improve their draft, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the lack of clarity regarding the broader goals identified by the authors, which affects the evaluation of the claim about the absence of visualization systems for interpretable reinforcement learning. However, it does not provide any explicit or implicit actions for the authors to take. The comment highlights a gap in the paper but does not offer guidance on how the authors might address this issue or improve the clarity of their goals. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the lack of clarity regarding the broader goals identified by the authors, which affects the evaluation of the claim about the absence of visualization systems for interpretable reinforcement learning. However, it does not specify which part of the paper discusses these broader goals or where the claim is made, making it difficult for the authors to pinpoint the exact area needing revision. While the comment is specific in its critique, it is 1 as it does not provide clear references to the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there are no visualization systems built for interpretable reinforcement learning that effectively address the broader goals identified by the authors. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of clarity regarding the broader goals that have been identified in the paper, which affects the evaluation of the claim about the absence of visualization systems for interpretable reinforcement learning. While the comment highlights a critical issue, it does not provide specific suggestions or guidance on how the authors might address this lack of clarity or improve the presentation of their goals. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the independence of the introduced AAL and SLS and suggests that applying them separately might not provide a stable improvement. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to stabilize the improvement. The comment implies that the authors should consider the interaction between AAL and SLS or explore methods to ensure stability, but it lacks concrete steps or suggestions for implementation. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses the independence of the introduced AAL and SLS and suggests that applying them separately might not provide a stable improvement. However, it does not specify which part of the paper this issue is discussed in, such as the methodology or results sections. The mention of \"Table (14)\" provides some grounding, but the authors might still need to infer which tables are being referred to. The comment is specific in its critique of the independence of AAL and SLS and the slight improvements observed, but it lacks full grounding due to the lack of explicit references to sections or tables. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the introduced AAL and SLS seem to be independent and that the improvements are slight. However, it does not provide specific evidence or examples to support this claim, such as detailed analysis or comparisons that would clarify the independence or the nature of the slight improvements. Without this additional information, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the independence of the introduced AAL and SLS and suggests that applying them separately might not provide a stable improvement. While it identifies a potential issue with the independence of the methods, it does not offer specific guidance or suggestions on how the authors might address this concern or improve the stability of the improvements. The comment lacks actionable advice or detailed feedback, making it 3 as it highlights a potential weakness but does not provide a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the experiments are limited to a single task (sentiment classification) and a single dataset (SST2). It implies that the authors should explore the effects on different tasks or utilize multiple datasets for the same task to gain deeper insights. While the comment provides a clear direction for improvement, it does not explicitly instruct the authors to conduct these explorations. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the limitation of the experiments being limited to a single task (sentiment classification) and a single dataset (SST2). It suggests exploring the effects on different tasks or utilizing multiple datasets for the same task to gain deeper insights. However, the comment does not specify which part of the paper discusses these experiments, making it weakly grounded. The suggestion for improvement is specific, as it clearly indicates what needs to be explored. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are limited to a single task and dataset, suggesting that exploring different tasks or utilizing multiple datasets would provide deeper insights. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the suggestion. The lack of detailed reasoning or evidence makes the claim 2, as it provides a general observation without sufficient justification or examples.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the study is limited to a single task (sentiment classification) and a single dataset (SST2). It suggests that exploring the effects on different tasks or utilizing multiple datasets for the same task could provide deeper insights. This feedback is clear and actionable, as it guides the authors to consider expanding their experiments to enhance the comprehensiveness and depth of their analysis. However, the comment could be more helpful if it provided specific examples of how to implement these suggestions or discussed potential benefits of such expansions. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the use of simulated data in the experiments, suggesting that it might be easier to fit than realworld data. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should consider using realworld data, but it lacks concrete steps or examples on how to implement this change. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the use of simulated data in the experiments, specifically mentioning the Heat Equation, Damped Wave, and NavierStokes simulations. However, it does not specify which part of the paper discusses these experiments or where the issue of using simulated data is addressed. This lack of explicit reference makes it difficult for the authors to pinpoint the exact section that needs revision. While the comment is specific about the issue of using simulated data, it is 1 because it does not provide clear guidance on where to address this concern. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the use of simulated data in the experiments, suggesting that it might be easier to fit than realworld data. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the concern. Without detailed justification or evidence, the claim remains 1, as it does not provide a clear rationale or examples to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a concern about the use of simulated data in the experiments, suggesting that it might be easier to fit than realworld data. However, the comment lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this issue. It does not offer guidance on whether the use of simulated data is appropriate or how it could be improved. Without detailed advice or examples, the authors are left without clear direction on how to enhance their draft. Therefore, the comment is 2, as it identifies a potential issue but does not provide sufficient guidance for improvement."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the study, specifically the absence of a dedicated image quality metric for evaluating image generation models. It suggests that including metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. While the comment implies that the authors should consider adding these metrics, it does not explicitly instruct them to do so. The action is clear but inferred, making the comment 4.", "grounding_specificity_rationale": "The comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating image generation models. It suggests that including metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. However, the comment does not specify which part of the paper discusses image generation models or where the evaluation metrics are mentioned, making it weakly grounded. The suggestion is specific, as it clearly specifies what needs to be addressed to improve the evaluation. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the absence of a dedicated image quality metric is a limitation of the study. It suggests that including metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation. The comment provides a logical reasoning by suggesting that such metrics would provide a more robust basis for evaluating image generation models. However, it lacks specific references or examples to fully substantiate the claim, making it 3. The authors would need to further explore and justify the necessity of these metrics to fully understand the argument.", "helpfulness_rationale": "The review comment identifies a specific limitation in the study, namely the absence of a dedicated image quality metric for evaluating image generation models. It suggests that including metrics like interclass or intraclass Frechet Inception Distance (FID) would enhance the comprehensiveness of the evaluation and comparison between different models. This feedback is clear and actionable, as it provides a concrete suggestion for improving the evaluation process. However, the comment could be more helpful if it offered additional context or explanation on why these metrics are particularly relevant or how they would impact the study. Overall, the comment is 4 as it guides the authors on a specific area for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the potential application of a mechanism in the context of vision transformers. While it suggests that the authors might be interested in exploring this possibility, it does not provide explicit guidance or suggestions on how to proceed with this exploration. The action is implicit, as the authors can infer that they might need to investigate or integrate this mechanism into their work, but the comment lacks concrete details on how to do so. Therefore, the comment is 3, as it identifies a potential area of interest but does not provide detailed guidance on execution.", "grounding_specificity_rationale": "The comment raises a question about the potential application of a mechanism in the context of vision transformers. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of vision transformers are being questioned or what potential applications are being considered. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question seeking clarification about the potential application of a mechanism in the context of vision transformers. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the potential application of a mechanism in the context of vision transformers. While it identifies an area of interest, it does not provide specific guidance or suggestions on how the authors might explore this application. The comment lacks actionable feedback, such as recommending potential experiments or providing references to relevant literature, which would be more helpful. Therefore, the comment is 2, as it points out a potential area for further exploration but does not offer detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: one about the precision of IMLE compared to the proposed Adaptive IMLE, and another about the applicability of the method to different domains. While the questions prompt the authors to consider these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The authors can infer that they need to explain the difference in precision and explore the method\"s applicability, but the comment lacks detailed steps or suggestions on how to do so. Therefore, the comment is 3, as it identifies areas for improvement but does not provide actionable guidance.", "grounding_specificity_rationale": "The comment raises two questions: one about the precision of IMLE compared to the proposed Adaptive IMLE and another about the applicability of the method to different domains. However, it does not specify which part of the paper these questions pertain to, such as specific sections or results. This makes it difficult for the authors to pinpoint the exact areas needing clarification or expansion. While the questions are specific in nature, the lack of grounding makes it challenging for the authors to address them effectively. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of two questions asking for clarification on the precision of IMLE compared to the proposed Adaptive IMLE and the applicability of the method to different domains. These are questions seeking additional information rather than claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: one about the precision of IMLE compared to the proposed Adaptive IMLE and another about the applicability of the method to different domains. While these questions prompt the authors to consider important aspects of their work, they do not provide specific guidance or suggestions on how to address these issues. The feedback is 3 as it identifies areas for further exploration, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experimental results are lacking and questions whether all necessary modules are included. While it identifies a potential issue, it does not provide explicit guidance on how to address it or what specific modules should be included. The action is implicit, as the authors can infer that they need to include additional modules, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the experimental results are lacking and questions whether all necessary modules are included. However, it does not specify which part of the paper this issue pertains to, such as specific sections or results that are lacking. The authors might infer that it relates to the results section, but this inference is not direct. The comment is specific in identifying the issue of lacking modules, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the experimental results are lacking and questions whether all necessary modules are included. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental results, noting that they are lacking and questioning whether all necessary modules are included. This feedback highlights a specific area where the authors might need to enhance their work by providing more comprehensive results. However, the comment lacks depth and does not offer suggestions on how to address this issue or what specific modules should be included. While it points out a potential weakness, it does not provide actionable guidance, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should explore the behavior of their network with a larger number of layers, such as 32 and 64, given that many GNNs tend to oversmooth as more layers are added. However, the comment does not provide explicit instructions or concrete steps on how the authors should conduct this exploration or what specific aspects they should focus on. The action is implicit and somewhat vague, as the authors need to infer that they should experiment with more layers and analyze the results. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the consideration of a few layers, up to 8 layers, and suggests exploring the behavior of the network with more layers, such as 32 and 64. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a known issue with GNNs, the tendency to oversmooth with more layers, and suggests a specific area for further exploration. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should explore the behavior of their network with more layers, such as 32 and 64, given the known tendency of many GNNs to oversmooth with more layers. While the comment provides a logical reasoning based on common knowledge about GNN behavior, it lacks specific examples or references to support the claim about oversmoothing. This makes the claim 3, as the authors would need to further substantiate the claim with evidence or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should explore the behavior of their network with more layers, such as 32 and 64, given the known tendency of many GNNs to oversmooth as more layers are added. This feedback is 3 as it identifies a potential area for further investigation that could enhance the understanding of the network\"s behavior. However, the comment lacks specific guidance on how the authors might conduct this exploration or what specific aspects they should focus on. While it provides a direction for improvement, it does not offer detailed instructions or examples, making it 3 but not fully comprehensive. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should perform significance tests to ensure the reliability of their experimental results. This is an explicit action, as it clearly instructs the authors to conduct additional statistical tests. However, the comment does not provide specific guidance on which tests to perform or how to interpret the results, leaving some level of detail missing. Therefore, the action is explicit but somewhat vague, making the comment 4.", "grounding_specificity_rationale": "The comment suggests that the authors should perform significance tests to ensure the reliability of their experimental results, specifically mentioning the improvement of MT over ST. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where the results are discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for significance tests, but without grounding, it lacks clarity on where these tests should be applied. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the improvement of MT over ST is very limited and suggests that the authors should perform significance tests to ensure the reliability of their experimental results. However, the comment does not provide any supporting evidence, such as specific examples, references, or detailed reasoning to substantiate the claim that the improvement is limited. Without this additional information, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically the limited improvement of MT over ST, and suggests that the authors should perform significance tests to ensure the reliability of their experimental results. This feedback is clear and actionable, as it provides a specific recommendation for the authors to enhance the robustness of their findings. However, the comment could be more helpful if it offered guidance on which significance tests to use or how to interpret the results. Despite this, the suggestion is valuable and provides a clear direction for improvement, making the comment 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point questions the claim that the proposed framework is modelagnostic, as it only evaluates the framework under different GCN architectures. The reviewer suggests that the authors should test the framework on various GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional experiments to validate the modelagnostic claim. The suggestion is concrete, as it specifies which GNN blocks should be tested and what the authors should expect to observe. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"figure 5,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the claim that the proposed framework is modelagnostic, suggesting that it should be evaluated under different GNN blocks such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that the proposed framework is modelagnostic, suggesting that it should be evaluated under different GNN blocks such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. This critique is based on logical reasoning, as it challenges the generality of the framework\"s claim by pointing out the need for broader testing. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to conduct additional experiments to fully address the critique, which aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the claim that the proposed framework is modelagnostic. It points out that the framework is only evaluated under different GCN architectures and suggests that the authors should test it on various GNN blocks, such as GAT, GraphSAGE, GIN, Geniepath, and LSTMlike aggregation methods. This feedback is actionable and provides a clear direction for the authors to enhance their evaluation and substantiate their claim of modelagnosticism. By suggesting specific GNN blocks to test, the comment offers a concrete way for the authors to improve the robustness and generalizability of their framework. Therefore, the comment is 4, as it provides valuable guidance for the authors to strengthen their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the method has many moving parts and requests an error analysis to understand how the approach works if one of the components makes a mistake. Specifically, it asks what happens if GPT4 misses some details. While the comment implies that the authors should conduct an error analysis, it does not provide explicit instructions or detailed guidance on how to perform this analysis. The action is implicit and somewhat vague, as the authors need to infer that they should conduct an error analysis but are not given specific steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the method has many moving parts and requests an error analysis regarding how the approach works if one of the components makes a mistake. However, it does not specify which part of the paper this analysis should be conducted on, making it weakly grounded. The comment is specific in its request for an error analysis, particularly regarding the potential impact of GPT4 missing some details. This provides clear guidance on what needs to be addressed, but the lack of grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that the method has many moving parts and requests an error analysis regarding the impact of component failures. However, it does not provide any specific examples, reasoning, or references to support why this analysis is necessary or how it would benefit the paper. The lack of detailed justification or evidence makes the claim 2, as the authors may find it challenging to understand the basis of the suggestion without further explanation.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, noting that the method has many moving parts. It suggests that the authors should provide an error analysis to understand how the approach works if one of the components makes a mistake, specifically asking what happens if GPT4 misses some details. This feedback is 3 as it highlights an area for improvement and prompts the authors to consider the robustness of their method. However, the comment could be more helpful if it provided specific guidance on how to conduct this analysis or suggested potential components to focus on. Overall, the comment offers a clear direction for improvement but lacks depth, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the absence of an error analysis in the paper, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, it does not provide explicit guidance on how the authors should incorporate this analysis or suggest specific methods for conducting it. The action is implicit, as the authors can infer that they need to include an error analysis, but the comment lacks concrete details on how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights the absence of an error analysis in the paper, which is relevant to understanding the limitations of SetCSE. However, it does not specify which part of the paper lacks this analysis, making it weakly grounded. The comment is specific in identifying the need for an error analysis, but without clear guidance on where to include it or how to conduct it, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that there is no mention of an error analysis, which would be beneficial for understanding the limitations of SetCSE in certain scenarios. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why an error analysis is necessary or how it would benefit the paper. Without this additional information, the claim remains 1, as it lacks the necessary details to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the absence of an error analysis in the paper. This is a valuable piece of feedback as it highlights a potential gap in the understanding of the limitations of SetCSE, which could be crucial for readers to grasp the scope and applicability of the method. However, the comment does not provide specific suggestions on how the authors might incorporate an error analysis or what aspects of the error analysis would be most beneficial. While it directs the authors to a potential enhancement, the feedback could be more helpful with additional guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that it might not be sufficient in certain scenarios. It questions whether a bit of unintentional finetuning could recover the toolknowledge and mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes to make. The action is implicit and vague, as it leaves the authors to infer that they need to consider additional methods or prompts to measure toolknowledge more comprehensively. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that it might not be sufficient in certain scenarios. It questions whether unintentional finetuning could recover the toolknowledge and mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. However, the comment does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where prompts are discussed, the comment lacks full grounding. It is specific in its critique of the sufficiency of prompting methods but does not provide detailed guidance on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that it might not be sufficient in certain scenarios. The comment questions whether unintentional finetuning could recover the toolknowledge and mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. However, the comment lacks specific examples, references, or detailed reasoning to support the claim that prompting might not suffice. This makes it difficult for the authors to fully understand and address the issue, as the justification is insufficient. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a concern about the sufficiency of measuring toolknowledge by prompting, suggesting that it might not be sufficient in certain scenarios. It questions whether unintentional finetuning could recover the toolknowledge and mentions the possibility of other prompts that could elicit the model\"s ability to use a tool. While the comment identifies a potential weakness in the methodology, it lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. The feedback is 3 as it prompts the authors to consider additional methods or prompts, but it could be more actionable with more detailed guidance. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks does not indicate inefficiency, but rather highlights the potential effectiveness of HA3C in different environments. The reviewer recommends exploring other tasks, including artificial ones, to demonstrate the effectiveness of HA3C. While the comment implies that the authors should consider additional tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore other tasks. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experimental results and the specific task of MuJoCo control, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear critique of the marginal improvement of HA3C over baseline algorithms and suggests that the effectiveness of HA3C might be more apparent in different environments. The comment further recommends exploring other tasks, including artificial ones, to demonstrate the effectiveness of HA3C. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks does not indicate inefficiency, suggesting that the effectiveness of HA3C might be more apparent in different environments. The reviewer provides a logical reasoning by explaining that the causal relationships in MuJoCo tasks may not be suitable for HA3C, implying that other tasks could be more appropriate. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a thoughtful critique of the experimental results, noting that the marginal improvement of HA3C over baseline algorithms on MuJoCo control tasks does not necessarily indicate inefficiency. The reviewer suggests that the effectiveness of HA3C might be more apparent in different environments, particularly those where the causal relationships based on history are simpler. The comment offers a constructive suggestion by recommending the authors explore other tasks, including artificial ones, to demonstrate the effectiveness of HA3C. This feedback is clear and actionable, providing the authors with a direction for further investigation and potentially improving the robustness of their findings. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the paper should focus on providing key insights or takeaways derived from the experiments that are generalizable and significant for the broader community. It implies that the authors should go beyond reporting aggregate numbers and instead highlight specific insights that could deepen the understanding of LLM capabilities. While the action is clear, it lacks concrete guidance on what specific insights should be highlighted or how to present them effectively. Therefore, the comment is 3, as it provides a direction but requires further elaboration to be fully actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the issue of novelty not lying in the dataset itself and suggests focusing on key insights derived from the data. It also specifies the problem by pointing out that the paper does not fully address this aspect, as it primarily reports aggregate numbers without providing specific takeaways. The comment further suggests that the authors should highlight key insights or takeaways that are generalizable and significant for the community. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the paper does not fully address the novelty of the dataset and suggests that the key contributions should focus on insights derived from the data. The reviewer provides a logical reasoning by stating that the paper primarily reports aggregate numbers without offering specific takeaways. However, the comment lacks specific examples or references to support the claim that the current approach is insufficient. This makes the claim 3, as it provides a general critique but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s novelty, suggesting that the key contributions should focus on insights derived from the data rather than aggregate numbers. It provides a clear and actionable suggestion for improvement by recommending that the authors present specific takeaways or insights that are generalizable and significant for the broader community. This feedback is 4 as it guides the authors toward enhancing the depth and relevance of their work. However, it could be more helpful if it included examples of what kind of insights or takeaways would be beneficial. Overall, the comment is rated as 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a false claim regarding the choice of GAN as the de facto choice for vocoders, suggesting that other popular alternatives like WaveNet, WaveRnn, and diffusionbased approaches are also viable. This feedback provides a clear and direct action for the authors to take, which is to acknowledge the existence of these alternative approaches and possibly revise the claim in the paper. The comment is explicit and concrete, giving the authors a clear direction on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sec 3.1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the false claim regarding the choice of GAN as the de facto choice for vocoders and provides specific alternatives like WaveNet, WaveRnn, and diffusionbased approaches. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"GAN has been the de facto choice for vocoders,\" but it argues that this is a false claim by highlighting the existence of other popular alternatives such as WaveNet, WaveRnn, and diffusionbased approaches. The comment provides specific examples of these alternatives, which supports the claim and makes it more verifiable. However, the comment could be strengthened by further elaborating on why GAN is considered the de facto choice and how the alternatives address the limitations of GAN. Overall, the claim is 4 due to the inclusion of specific examples, but it could be more robust with additional reasoning or references. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a false claim in the paper regarding the choice of GAN as the de facto choice for vocoders. It acknowledges that there are other popular alternatives, such as WaveNet, WaveRnn, and diffusionbased approaches, which are viable options. This feedback is valuable as it prompts the authors to reconsider their assumptions and potentially revise their claims to reflect the broader range of available options. By highlighting these alternatives, the comment provides actionable guidance for improving the accuracy and comprehensiveness of the paper. However, the comment could be more helpful if it offered suggestions on how to integrate these alternatives into the discussion or if it provided specific examples of how they could be used. Overall, the comment is 4 as it directs the authors\" attention to a critical oversight in their paper."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the approach, while straightforward and sensible, contains design choices that are not fully explained or empirically justified. It specifically mentions the choice of token similarity metric as an example. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific aspects need clarification or justification. The action is implicit, as the authors can infer that they need to explain or justify the design choices, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"approach\" and provides a specific example of a design choice, the choice of token similarity metric, which allows the authors to identify the part of the paper being addressed. It is also specific because it highlights the need for explanation or empirical justification of design choices, providing clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the approach, while straightforward and sensible, contains design choices that are not fully explained or empirically justified. The comment provides a specific example of a design choice, the choice of token similarity metric, which supports the claim. However, the comment lacks detailed reasoning or references to justify why this choice is problematic or how it could be improved. The absence of specific examples or detailed explanations makes the claim 3, as the authors would need to infer the full extent of the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the approach, noting that while it is straightforward and sensible, it contains design choices that are not fully explained or empirically justified. Specifically, it mentions the choice of token similarity metric as an example. This feedback is 3 as it highlights areas where the authors could improve the clarity and rigor of their work. However, the comment could be more actionable by providing specific suggestions on how to address these design choices or by offering guidance on how to justify them empirically. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment points out specific inconsistencies in the notation used in the paper, particularly in Equation (4) and Equation (6). It explicitly identifies the discrepancies between the lefthand side (LHS) and righthand side (RHS) of these equations, such as the presence of T and W on the LHS but not on the RHS in Equation (4), and the inclusion of j on the LHS but not on the RHS in Equation (6). This feedback is explicit and provides clear guidance on what needs to be corrected, making it 5. The authors know exactly which parts of the paper require attention and what specific changes are needed to address the inconsistencies in notation.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific equations, Equation (4) and Equation (6), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the inconsistencies in the notation, such as the presence of T and W on the LHS but not on the RHS in Equation (4), and the inclusion of j on the LHS but not on the RHS in Equation (6). This provides clear guidance on what needs to be corrected, making the comment 5.", "verifiability_rationale": "The review point identifies specific inconsistencies in the notation used in the paper, particularly in Equation (4) and Equation (6). The comment provides clear examples of these inconsistencies, such as the presence of T and W on the lefthand side (LHS) but not on the righthand side (RHS) in Equation (4), and the inclusion of j on the LHS but not on the RHS in Equation (6). This level of detail provides a solid foundation for the claim, making it 4. However, the comment could be further strengthened by referencing specific sections or providing more context on why these inconsistencies are problematic. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies specific inconsistencies in the notation used in the paper, particularly in Equation (4) and Equation (6). It points out that the lefthand side (LHS) and righthand side (RHS) of these equations do not align in terms of the variables used, which could lead to confusion for readers. By highlighting these inconsistencies, the comment provides clear and actionable feedback that the authors can use to improve the clarity and accuracy of their paper. The specificity of the feedback, combined with the explicit mention of equations, makes it 5 for the authors to address these issues and enhance the quality of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights two main issues with the evaluation section: the insufficient number of models constructed (less than 20) and the lack of evaluation regarding image distortion after warping. It also points out the absence of a discussion on potential countermeasures against the proposed approach. While the comment identifies specific areas that need improvement, it does not provide explicit instructions on how to address these issues. The authors are left to infer that they need to expand their evaluation to include more models, evaluate image distortion, and discuss countermeasures. However, the lack of concrete guidance on how to implement these changes makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"evaluations\" section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issues with the evaluation, such as the insufficient number of models constructed (less than 20) and the lack of evaluation regarding image distortion after warping. Additionally, it points out the absence of a discussion on potential countermeasures against the proposed approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation is insufficient because only less than 20 models are constructed, which is far from enough to demonstrate the effectiveness of the approach. It also mentions the lack of evaluation regarding image distortion after warping and the absence of a discussion on potential countermeasures. While the comment identifies specific areas of concern, it lacks detailed reasoning or examples to fully substantiate the claim. The authors would need to infer the insufficiency of the evaluation and the importance of the missing elements, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the evaluation section of the paper, noting that only less than 20 models are constructed, which is insufficient to demonstrate the effectiveness of the approach. It also points out the lack of evaluation regarding image distortion after warping and the absence of a discussion on potential countermeasures against the proposed approach. This feedback is clear and actionable, as it highlights specific areas where the paper needs improvement to strengthen its evaluation and provide a more comprehensive analysis. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to conduct the additional evaluations and discussions. Overall, the comment is 4, as it effectively guides the authors toward enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should clarify whether all entries in Table A3 are discourse particles or a combination of discourse and imported vocabulary. It also provides a concrete action by recommending that if they are a mix, they should be separated into separate tables. Additionally, the comment suggests that glosses would be helpful, offering a clear and direct action for the authors to take. This level of detail and specificity makes the comment 5, as it provides clear guidance on how to improve the clarity and organization of the table.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table A3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: clarifying whether all entries in Table A3 are discourse particles or a combination of discourse and imported vocabulary, and suggesting that if they are a mix, they should be separated into separate tables with glosses. This provides clear guidance on how to improve the clarity and organization of the table. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the content of Table A3, specifically questioning whether all entries are discourse particles or a combination of discourse and imported vocabulary. It suggests that if they are a mix, they should be separated into separate tables and that glosses would be helpful. This comment does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification and does not fit the criteria for a claim. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity and organization of Table A3. It questions whether all entries in the table are solely discourse particles or a combination of discourse and imported vocabulary. The comment suggests that if they are a mix, they should be separated into separate tables and that glosses would be helpful. This feedback is clear and provides the authors with a concrete direction for enhancing the presentation of their data, making it 5. The comment offers a clear path for improvement, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses confusion about the idea behind formula (4), specifically questioning why the maximum is taken over all possible pieces for unoccupied squares. However, it does not provide any explicit or implicit suggestions for clarification or improvement. The authors are left without guidance on how to address their misunderstanding or how to enhance the explanation of the formula. Without actionable advice or specific questions, the authors cannot determine what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"formula (4),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of understanding of the idea behind the formula, particularly the use of the maximum over all possible pieces for unoccupied squares. This provides clear guidance on what the authors need to clarify or explain. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about the idea behind formula (4), specifically questioning the rationale for taking the maximum over all possible pieces for unoccupied squares. However, it does not provide any supporting evidence, reasoning, or references to clarify the issue. Without additional context or explanation, the authors may find it challenging to understand and address the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area of confusion regarding formula (4), questioning the rationale behind taking the maximum over all possible pieces for unoccupied squares. This feedback highlights a potential gap in the explanation or understanding of the formula, which could hinder the clarity of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this confusion or improve the explanation. While it points out a specific issue, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments lack a comparison to stateoftheart subset selection methods. While it identifies a gap in the paper, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include such a comparison, but it does not specify which methods to include or how to present the comparison. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment highlights a specific issue with the experiments, namely the lack of comparison to stateoftheart subset selection methods. However, it does not specify which part of the paper this issue pertains to, such as the methodology or results sections. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in identifying the need for a comparison to stateoftheart methods, but without grounding, it lacks clarity on how to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments lack a comparison to stateoftheart subset selection methods. However, it does not provide any specific examples or references to support this claim, nor does it explain why such a comparison is necessary or how it would enhance the paper. Without detailed justification or evidence, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the experiments lack a comparison to stateoftheart subset selection methods. This is a critical area for improvement, as comparing against stateoftheart methods can provide valuable insights into the performance and effectiveness of the proposed approach. However, the comment does not offer specific suggestions or guidance on how the authors might conduct this comparison or what methods to consider. While it highlights an important aspect of the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight but lacks detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the novelty of the paper is somewhat vague and suggests that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, it does not provide explicit guidance on how the authors should clarify the novelty or differentiate their work from existing literature. The comment lacks specific suggestions or actions for the authors to take, leaving them uncertain about how to address the issue of novelty. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the novelty of the paper is somewhat vague and needs to be more concise, implying that the primary components integrate effective elements from previous works. However, it does not specify which parts of the paper are being discussed or how the integration of these elements affects the novelty. The authors cannot confidently determine which sections or components are being addressed, making the comment weakly grounded. Additionally, while it points out the need for more specificity, it does not provide detailed guidance on how to achieve this. Therefore, the comment is 2, aligning with label 2.", "verifiability_rationale": "The review point claims that the novelty of the paper is somewhat vague and suggests that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without concrete evidence or references to these elements, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 2, as it lacks sufficient justification or examples to fully substantiate the assertion.", "helpfulness_rationale": "The review comment points out that the novelty of the paper is somewhat vague and suggests that the primary components integrate effective elements from previous works, such as SCL, Aligned, and CLNN. While this feedback highlights a potential issue with the paper\"s originality, it does not provide specific suggestions or guidance on how the authors might address this concern or differentiate their work from existing literature. The comment lacks actionable advice or detailed feedback, making it 3 as it identifies a potential weakness but does not offer a clear path for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should use evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback provides a clear and explicit action for the authors to take, which is to incorporate these benchmarks into their work. The comment is specific in its suggestion, detailing what needs to be done to enhance the usability and availability of the benchmark for the community. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where these benchmarks could be integrated. While the authors might infer that it relates to the evaluation section, the lack of explicit grounding makes it challenging to pinpoint the exact part of the paper being addressed. The comment is specific in its suggestion, but without clear grounding, it is rated as 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests using evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. However, it does not provide any specific examples, references, or detailed reasoning to support why this approach is necessary or beneficial. The lack of supporting evidence or justification makes it difficult for the authors to understand the basis of the claim and how it could be implemented. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by recommending the use of evaluation benchmarks of the user simulator to demonstrate how smaller models perform as user simulators. This feedback is clear and offers a concrete way for the authors to enhance the usability and availability of their benchmarks for the community. By addressing this suggestion, the authors can make their work more relevant and accessible to a broader audience. However, the comment could be more helpful if it included examples of existing benchmarks or further elaborated on the potential benefits of this approach. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the impact of openset detectors on the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what specific aspects they should consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the impact of openset detectors on the performance of the proposed method. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the impact should be considered or how the authors might address this question. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking about the impact of openset detectors on the performance of the proposed method. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual inquiry, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the impact of openset detectors on the performance of the proposed method. While it identifies an area of interest, it does not provide any guidance or suggestions on how the authors might address this question or what specific aspects to consider. The comment lacks depth and actionable advice, making it 2. It gives the authors a starting point for further exploration but does not fully support their needs for improvement. Therefore, it aligns with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises two specific issues. First, it points out that the symbol \"*\" in Table 1 for \"oracle goals\" lacks an explanation, which is a clear and explicit action for the authors to clarify or fix. Second, it questions the meaning of \"fromscratch\" in Table 5, suggesting that it might imply random initialization despite the text indicating pretraining. This is also an explicit request for clarification. Both issues are concrete and provide clear guidance on what needs to be addressed, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1\" and \"Table 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issues: the lack of explanation for the \"*\" symbol in Table 1 and the ambiguity regarding the meaning of \"fromscratch\" in Table 5. The comment provides clear guidance on what needs to be clarified or fixed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point consists of two separate observations: one about the lack of explanation for the \"*\" symbol in Table 1 and another about the ambiguity of \"fromscratch\" in Table 5. Neither of these observations is a subjective claim or suggestion that requires verification. They are factual observations that require clarification from the authors. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies two specific issues in the paper. First, it points out that the symbol \"*\" in Table 1 for \"oracle goals\" lacks an explanation, which is a clear and actionable request for the authors to clarify or fix this. Second, it questions the meaning of \"fromscratch\" in Table 5, suggesting that it might imply random initialization despite the text indicating pretraining. This feedback is 4 as it provides clear and actionable suggestions for improving the clarity and accuracy of the paper. However, the comment could be more helpful if it offered additional guidance on how to address these issues or provided examples of how to clarify the explanations. Overall, the comment is rated as 4, consistent with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the expected behavior of transferability in the context of increasing noise intensity. It suggests that the observed results might not be as exciting as expected, given the potential for different neurons to activate to reduce confidence in source samples. However, the comment does not provide explicit guidance or suggestions on how the authors should address this observation or improve their results. The action is implicit and vague, as it leaves the authors to infer that they might need to reconsider their analysis or results. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the observed increase in transferability with higher noise intensity and suggests that the results might not be as exciting as expected. The comment provides a clear rationale for the observation, indicating that the results do not align with the expected behavior. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point questions the observed increase in transferability with higher noise intensity, suggesting that it might not be as exciting as expected. The comment provides a logical reasoning by implying that different neurons might be activated to reduce confidence in source samples, leading to increased misclassification. However, the comment lacks specific examples or references to support this claim, making it 3. The authors would need to further explore and substantiate this observation to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the observed increase in transferability with higher noise intensity, suggesting that the results might not be as exciting as expected. It provides a logical reasoning by implying that different neurons might be activated to reduce confidence in source samples, leading to increased misclassification. However, the comment lacks specific suggestions or guidance on how the authors might address this observation or improve their results. While it identifies a potential area for further exploration, it does not offer actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point provides several explicit actions for the authors to take. It suggests adding ablation studies with only importance weighting or the rejection to better understand their effects, which is a clear and direct request. Additionally, it points out that the fonts in the figures are too small to read, providing a specific issue to address. The comment also questions the ChopperCommand results in Figure 6 (a), asking why the reward becomes large quickly but decreases along the training. This question implies that the authors should provide more explanation in the paragraph. Overall, the comment is 5 as it provides specific and actionable steps for the authors to improve their draft.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig. 6 (a)\" and \"the fonts in the figures,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides detailed feedback on the need for ablation studies, the issue with figure fonts, and questions about the ChopperCommand results. The comment requests more explanation regarding the observed behavior in the results, which adds depth to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of multiple claims and suggestions. The first part suggests that adding ablation studies with only importance weighting or the rejection would help understand the effects better, which is a logical suggestion. The second part points out that no such ablation study is conducted in the current paper, which is a factual observation. The third part mentions that the fonts in the figures are too small to read, which is a factual statement. The fourth part questions the ChopperCommand results in Figure 6 (a), asking why the reward becomes large quickly but decreases along the training. This is a question seeking clarification, not a claim. Overall, the comment is a mix of factual statements and suggestions, but the primary focus is on factual observations, making it 4.", "helpfulness_rationale": "The review comment provides several actionable suggestions for improvement. It recommends adding ablation studies with only importance weighting or the rejection to better understand the effects, which is a clear and specific request. Additionally, it points out that the fonts in the figures are too small to read, offering a straightforward issue to address. The comment also questions the ChopperCommand results in Figure 6 (a), asking why the reward becomes large quickly but decreases along the training. This question prompts the authors to provide more explanation in the paragraph, which can enhance the clarity and understanding of the results. Overall, the feedback is 4 as it provides specific and actionable guidance for the authors to improve their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of technical clarity regarding the main learning framework, Equation (18), and questions the implementation of the balancing term and the penalty term. While it identifies a specific area of concern, it does not provide explicit guidance on how to address these issues or what specific details should be included to improve the technical clarity. The action is implicit, as the authors can infer that they need to provide more detailed explanations of Equation (18) and the implementation of the balancing and penalty terms. However, the comment lacks concrete instructions on how to implement these changes, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equation (18),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of technical clarity regarding the main learning framework and questions the implementation of the balancing term and the penalty term. This provides clear guidance on what needs to be addressed in terms of technical explanation. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical clarity is weak, specifically regarding the explanation of the main learning framework, Equation (18), and the implementation of the balancing and penalty terms. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the technical clarity of the paper, specifically pointing out the lack of explanation for the main learning framework, Equation (18), and the implementation of the balancing and penalty terms. This feedback is clear and actionable, as it directs the authors to provide more detailed explanations and examples to enhance the technical clarity of their work. However, the comment could be more helpful if it offered specific suggestions on how to improve the explanation or included examples of similar frameworks for reference. Overall, the comment is 4 as it highlights a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the decision boundary generation and suggests that the projection results and Voronoi tessellations should be updated as feature vectors change during training. It emphasizes the need to clarify how well these fixed tessellations capture the model\"s behavior and questions the use of 2D projections for highdimensional decision boundaries. While the comment identifies specific areas of concern, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback is somewhat vague and lacks concrete details, making it challenging for the authors to know exactly what steps to take to improve their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about decision boundary generation, specifically mentioning the projection results and Voronoi tessellations. It highlights the issue that these results appear fixed across multiple rounds, despite feature vectors updating during training. The comment also raises concerns about the use of 2D projections for highdimensional decision boundaries. While the comment does not explicitly mention specific sections of the paper, the authors can infer that it relates to the discussion of decision boundaries or results sections. The comment is specific in detailing what needs to be clarified or addressed, such as the updating of projection results and the impact of projection methods. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises concerns about the decision boundary generation, specifically questioning the consistency of projection results and Voronoi tessellations across multiple rounds. It suggests that these results should be updated as feature vectors change during training and raises concerns about the use of 2D projections for highdimensional decision boundaries. The comment provides logical reasoning by explaining the potential issues with fixed tessellations and the impact of projection methods. However, it lacks specific examples or references to support the claims, making it 3. The authors would need to further explore these issues to fully address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises concerns about the decision boundary generation, specifically questioning the consistency of projection results and Voronoi tessellations across multiple rounds. It highlights the importance of updating these results as feature vectors change during training and suggests that the fixed tessellations may not accurately capture the model\"s behavior. Additionally, it raises concerns about the use of 2D projections for highdimensional decision boundaries, noting that results can vary significantly based on the selected projection method and parameters. While the comment identifies specific areas of concern, it lacks detailed guidance or suggestions on how to address these issues. The feedback is 3 as it points out important areas for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper lacks an ablation study and a comparison to methods from the past decade. This provides clear and direct guidance for the authors, indicating that they need to include these elements in their draft. The action is explicit, and the authors know exactly what needs to be added to improve their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment highlights the absence of an ablation study and a comparison to methods from the past decade, which are both important aspects of the paper. However, it does not specify which part of the paper should include these elements, making it weakly grounded. The comment is specific in detailing what is missing, but without explicit references to sections or figures, the authors may struggle to identify the exact parts of the paper that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study and a comparison to methods from the past decade. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or examples, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant omission in the paper, specifically the lack of an ablation study and a comparison to methods from the past decade. This feedback is clear and actionable, as it directs the authors to include these elements in their draft, which would enhance the paper\"s comprehensiveness and provide a more robust evaluation of their work. However, the comment could be more helpful if it offered suggestions on how to conduct the ablation study or what specific comparisons should be made. Despite this, the feedback is 4 as it highlights critical areas for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning \"SVC\" (likely a typo for \"SVM\" or \"Support Vector Classification\"). While the comment implies that the authors should expand their theoretical analysis, it does not provide explicit guidance on which models to consider or how to integrate these results into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include more theoretical results on more complex models but lack detailed instructions on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests including more theoretical results on more complicated models, specifically mentioning \"SVC.\" However, it does not specify which part of the paper should include these additional results or how they should be integrated. The authors cannot confidently determine which sections or elements of the paper are being addressed, making the comment weakly grounded. Additionally, while the comment suggests an area for improvement, it lacks specificity regarding what theoretical results should be included or how they should be presented. Therefore, this comment is 2, aligning with label 2.", "verifiability_rationale": "The review point suggests that the paper should include more theoretical results on more complicated models, specifically mentioning \"SVC.\" However, the comment does not provide any supporting evidence, reasoning, or references to justify why additional theoretical results on more complex models are necessary or beneficial. Without this context, the authors may find it challenging to understand the basis of the suggestion or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the paper should include more theoretical results on more complicated models, specifically mentioning \"SVC.\" While this feedback identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on which models or types of theoretical results should be included. The comment highlights a direction for expansion but does not offer actionable steps or examples to guide the authors in making these improvements. As a result, the comment is 3, as it points out a potential enhancement but does not fully support the authors in executing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It specifically mentions the existing results in Fig. 11 as insufficient for this purpose. The comment provides a clear and direct action for the authors to take, which is to conduct additional ablation studies. However, it does not specify how many studies should be conducted or what specific aspects should be examined. While the action is explicit, the lack of detailed guidance on execution makes it 3.", "grounding_specificity_rationale": "The comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It specifically mentions the existing results in Fig. 11 as insufficient for this purpose. However, the comment does not explicitly mention which part of the paper this figure is located in, making it weakly grounded. The authors can infer that it relates to the results section, but this inference is not as direct as it could be. The comment is specific in suggesting the need for additional ablation studies, but it lacks detailed guidance on what aspects should be studied or how to conduct them. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. However, it does not provide specific examples or detailed reasoning to support why these studies are necessary or how they would demonstrate the necessity of the DA Inversion. The comment lacks sufficient evidence or justification, making it difficult for the authors to understand the basis of the claim. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that more ablation studies should be provided to demonstrate the necessity of the proposed DA Inversion. It specifically points out that the existing results in Fig. 11 are insufficient for this purpose. This feedback is clear and actionable, as it directs the authors to conduct additional studies to strengthen their argument. However, the comment could be more helpful if it provided specific guidance on what aspects of the DA Inversion should be tested or how the ablation studies should be structured. Despite this, the comment is 4 as it identifies a critical area for improvement and offers a direction for the authors to enhance their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the necessity of clustering in the second phase of training, given that a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this concern. While the comment implies that the authors should conduct an ablation study, it does not provide specific guidance on how to implement it or what aspects should be examined. The action is implicit and somewhat vague, as the authors need to infer the need for an ablation study and determine the specifics of how to conduct it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the necessity of clustering in the second phase of training and suggests that a clear ablation study should be presented. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of clustering in the second phase of training, given that a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this concern. However, the comment does not provide specific reasoning or examples to support why clustering is necessary or how it impacts the evaluation. Without detailed justification or evidence, the claim remains 3, as it lacks the depth needed to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of clustering in the second phase of training, given that a linear regressor is used for evaluation. It suggests that a clear ablation study should be presented to address this issue. This feedback is 3 as it identifies a potential weakness in the methodology and provides a direction for improvement by suggesting a specific type of analysis. However, the comment could be more helpful if it offered more detailed guidance on how to conduct the ablation study or what specific aspects should be examined. Overall, the comment provides some insight but lacks comprehensive detail, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the figures, specifically Fig2a, may be affected by a certain aspect, noting that the forgetting is not as drastic as in class incremental and that there is a slight increase near epoch 150. However, the comment does not provide explicit guidance on what specific changes should be made to the figures or how to address the issue. The action is implicit and vague, as the authors are left to infer that they need to adjust the figures based on the observation. Without concrete instructions or suggestions, the authors may struggle to understand what steps to take to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig2a,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details what is observed in the figure, noting that the forgetting is not as drastic as in class incremental and that there is a slight increase near epoch 150. This provides clear guidance on what aspect of the figure needs attention. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point makes a claim about the figures, specifically mentioning that the forgetting is not as drastic as in class incremental and that there is a slight increase near epoch 150. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific observation about the figures, noting that the forgetting effect is not as drastic as in class incremental and that there is a slight increase near epoch 150. This feedback is 3 as it highlights a potential issue with the figures that the authors should be aware of. However, the comment lacks depth and does not offer suggestions on how to address this issue or what specific changes should be made to the figures. To be more helpful, the comment could include recommendations on how to improve the clarity or presentation of the figures. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to highlight the datadependent nature of their approximation results, suggesting that this should be mentioned in the abstract. While the comment does not specify which part of the abstract should include this information, it provides a clear direction for the authors to follow. The action is explicit, but the lack of detailed guidance on where to place the information makes it 3. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the abstract as a place to include this information. However, it does not specify which part of the abstract should be modified or how to effectively convey this point. The authors can infer that the abstract is the relevant section, but the comment lacks specificity regarding the exact content or structure needed to address the suggestion. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should highlight the datadependent nature of their approximation results, specifically mentioning the abstract as a place to include this information. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is important or how it would benefit the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement, recommending that the authors highlight the datadependent nature of their approximation results, particularly in the abstract. This feedback is clear and directs the authors to a specific area where they can enhance the clarity and impact of their work. However, the comment could be more helpful if it offered additional guidance on how to effectively convey this point or provided examples of how to integrate this information into the abstract. Despite this, the comment is 4 as it directs the authors toward a concrete step to improve their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly asks the authors to clarify the meaning of RMSD in Figure 3, specifically whether it represents the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This direct question provides a clear and specific action for the authors to take, ensuring they know exactly what needs to be addressed. The comment is explicit and concrete, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be clarified regarding the RMSD, asking whether it represents the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus. This provides clear guidance on what needs to be addressed in the figure. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the meaning of RMSD in Figure 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is 5 as it provides a specific and actionable suggestion for the authors to clarify the meaning of RMSD in Figure 3. By asking whether RMSD represents the RMSD between a docking pose and the ground truth from PDB or between docking poses obtained with different methods to quantify consensus, the comment directs the authors to a critical area of the paper that needs further explanation. This feedback is clear and constructive, helping the authors improve the clarity and accuracy of their presentation. Therefore, it aligns with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It poses a specific question about whether a smooth regret scaling could exist without phase transitions while still maintaining the proven bounds. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explore this aspect further. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a specific area for improvement by questioning the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for a more thorough treatment and a detailed explanation of the necessity of phase transitions. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. However, the comment does not provide any specific reasoning or evidence to support why this is necessary or how it could be addressed. Without additional context or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should provide a more thorough treatment of the necessity of phase transitions in the \"actual regret scaling\" compared to the asymptotic bounds shown. It raises a specific question about whether a smooth regret scaling could exist without phase transitions while still maintaining the proven bounds. This feedback is 3 as it identifies a potential area for improvement and prompts the authors to consider a more comprehensive analysis. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to explore this aspect. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include comparisons to previous robust RL methods, specifically mentioning RARL as an example. It implies that the authors should be explicit about whether GAD or EG already include these prior works. While the comment implies that the authors should add these comparisons, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons and specify which prior works to include. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that comparisons to previous robust RL methods, such as RARL, are missing, even though they are cited. It implies that the authors should be explicit about whether GAD or EG already include these prior works. However, the comment does not specify which part of the paper should include these comparisons, making it weakly grounded. The suggestion to be explicit about prior works is specific, but without clear guidance on where to include these comparisons, the comment is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point suggests that comparisons to previous robust RL methods, such as RARL, are missing, even though they are cited. The comment implies that the authors should be explicit about whether GAD or EG already include these prior works. However, the comment lacks specific examples or detailed reasoning to support the claim that these comparisons are missing. It does not provide references or detailed explanations of why these comparisons are important or how they would enhance the paper. As a result, the claim is 3, as it provides a general suggestion but lacks the necessary details to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by suggesting that comparisons to previous robust RL methods, such as RARL, are missing despite being cited. It implies that the authors should be explicit about whether GAD or EG already include these prior works. This feedback is 3 as it highlights an area for improvement, prompting the authors to consider the inclusion of relevant comparisons. However, the comment could be more actionable by providing specific examples or suggesting how to integrate these comparisons into the paper. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This is a clear and direct action that the authors can take to improve their draft. The comment specifies what needs to be addressed, making it 5. The authors know exactly what information is missing and how to incorporate it into their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more details should be provided about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not specify which part of the paper these details should be included in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, but without clear grounding, the authors may struggle to identify the exact sections that require additional information. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details should be provided about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. However, it does not offer any supporting evidence, reasoning, or examples to justify why these details are important or how they impact the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors provide more details about the choice of $k_1, k_2, k_3$, the networks, and the learning objectives. This feedback is clear and actionable, as it directs the authors to enhance the transparency and comprehensibility of their methodology. However, the comment could be more helpful if it offered suggestions on how to present this information or emphasized the importance of these details in the context of the paper. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the relationship between HIS and the negative inverse of mean response time. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this question or what changes could be made to improve the draft. Without any actionable suggestions or instructions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the relationship between HIS and the negative inverse of mean response time, but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or equations, the authors cannot confidently determine where this question is addressed. Additionally, the comment lacks specificity regarding what needs to be clarified or addressed. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about the relationship between HIS and the negative inverse of mean response time. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the relationship between HIS and the negative inverse of mean response time, which could be a point of confusion for readers. However, it does not provide any context, explanation, or suggestions for how the authors might address this question or improve their understanding of the relationship. Without actionable feedback or guidance, the comment lacks clarity and does not assist the authors in improving their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions and suggestions for improvement. It asks for an explanation of why a particular sparse representation learning method was chosen, which implies that the authors should provide justification for their methodological choice. Additionally, it suggests that the experiments should include a comparison with FTA as a baseline, noting that this comparison is missing in a RL setting. The reviewer also questions the validity of the performance on a supervised learning setting without a corresponding comparison in a reinforcement learning setting, suggesting that a rigorous comparison is necessary. While the comment provides several implicit actions, it lacks concrete guidance on how to address each of these points. The authors can infer that they need to justify their method choice, include a baseline comparison, and ensure consistency in their experimental settings, but the comment does not provide detailed steps or examples for each action. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises several specific issues regarding the choice of the sparse representation learning method and the experimental comparisons. It questions the rationale behind the selection of this method and suggests that a comparison with FTA should be included as a baseline. Additionally, it points out a discrepancy in the comparison between supervised learning (SL) and reinforcement learning (RL) settings, questioning the validity of the performance on an SL setting without a corresponding comparison in an RL setting. The comment is fully grounded as it explicitly mentions the \"choice of the sparse representation learning method\" and the \"experiments part,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what needs to be addressed, such as justifying the method choice, including a baseline comparison, and ensuring consistency in experimental settings. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises several claims about the choice of the sparse representation learning method and the lack of comparison with FTA in the experiments. The reviewer questions the rationale behind the method selection and suggests that a comparison with FTA should be included as a baseline. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The mention of the discrepancy in comparison between supervised learning (SL) and reinforcement learning (RL) settings is also not fully justified, as it does not provide detailed reasoning or evidence. Therefore, the claims are 3, as they require more detailed explanation or references to be fully substantiated. This aligns with a score of 3.", "helpfulness_rationale": "The review comment raises several important points that could significantly improve the paper. It questions the rationale behind the choice of the sparse representation learning method, suggesting that the authors should provide justification for their methodological choice. Additionally, it points out a discrepancy in the experimental comparisons, noting that FTA should be included as a baseline in the experiments. The comment also questions the validity of the performance on a supervised learning setting without a corresponding comparison in a reinforcement learning setting, suggesting that a rigorous comparison is necessary. While the comment identifies key areas for improvement, it lacks specific suggestions or detailed guidance on how to address these issues. The authors are left with a general sense of what needs to be improved but without clear direction on how to implement the changes. Therefore, the comment is 3, as it provides insight into potential weaknesses and areas for improvement but could be more actionable with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the authors describe a particular choice of shift and scaling on page 4, line 154, and mentions that this choice is more appropriate. However, it does not provide an explicit action for the authors to take. The comment implies that the authors should explain why this choice is more appropriate, but it does not specify how to do so. The action is implicit and somewhat vague, as the authors know they need to provide an explanation but are not given detailed guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"p.4, l.154,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the omission of an explanation for the choice of shift and scaling, which is a clear issue that needs to be addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the authors neglect to explain why a particular choice of shift and scaling is more appropriate. However, it does not provide any reasoning or evidence to support this claim, such as comparisons with other choices or references to why this choice is preferable. Without additional context or justification, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue in the paper, noting that the authors describe a particular choice of shift and scaling on page 4, line 154, but fail to explain why this choice is more appropriate. This feedback is clear and actionable, as it highlights a gap in the explanation that the authors need to address. By pointing out this omission, the comment provides the authors with a concrete direction for improving the clarity and comprehensiveness of their work. However, the comment could be more helpful if it offered suggestions on how to explain the choice of shift and scaling or provided examples of why this choice might be preferable. Overall, the comment is 4, as it effectively guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests revising the title and other parts of the paper to use \"GFlowNets\" instead of \"partial inference of GFlowNets\" and \"partial inference\" elsewhere. This feedback provides a clear and direct action for the authors to take, specifying exactly what needs to be changed. The suggestion is concrete, as it outlines the specific terms that should be revised, leaving no ambiguity about how the authors should apply this feedback. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of \"partial inference of GFlowNets\" in the title and elsewhere, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the terminology, suggesting that \"GFlowNets\" should be used instead of \"partial inference of GFlowNets\" and \"partial inference\" elsewhere. This provides clear guidance on what needs to be revised. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests a change in terminology, specifically recommending the use of \"GFlowNets\" instead of \"partial inference of GFlowNets\" and \"partial inference\" elsewhere. However, the comment does not provide any reasoning, examples, or references to support why this change is necessary or beneficial. Without additional context or justification, the claim is considered 1. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the terminology used in the title and elsewhere in the paper, suggesting that \"GFlowNets\" should be used instead of \"partial inference of GFlowNets\" and \"partial inference.\" This feedback is clear and actionable, providing the authors with a direct suggestion for improvement. By addressing this issue, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it offered additional context or explanation on why this change is necessary or how it would benefit the paper. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper only measures BERTScore to illustrate the similarity of the newly generated text, but it does not discuss other matrices that could measure the stealthiness of the generated content. While the comment identifies a gap in the paper, it does not provide explicit guidance on which other matrices should be considered or how to implement this suggestion. The action is implicit and somewhat vague, as the authors know they need to explore additional metrics but are not given specific instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of BERTScore to illustrate the similarity of the newly generated text, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing in the paper, namely the discussion of other matrices that could measure the stealthiness of the generated content. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the paper only measures BERTScore to illustrate the similarity of the newly generated text, but it does not discuss other matrices that could measure the stealthiness of the generated content. While the comment identifies a potential gap in the paper, it lacks specific examples or references to other matrices that could be used to measure stealthiness. This makes the claim 3, as the authors would need to further explore and justify the choice of matrices beyond what is provided in the comment. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s methodology by pointing out that it only measures BERTScore to illustrate the similarity of the newly generated text. It suggests that there are other matrices that could measure the stealthiness of the generated content, which are not discussed in the paper. This feedback is 3 as it highlights a potential area for improvement, encouraging the authors to consider additional metrics for evaluating the stealthiness of their generated content. However, the comment could be more helpful if it provided specific examples of these matrices or guidance on how to incorporate them into the analysis. Overall, the comment offers a clear direction for enhancing the paper\"s evaluation, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues that need clarification, such as the convenience of applications, the need to highlight issues with existing estimators, and the lack of defined basic notation. It points out specific elements like the dimensionality p, unit ball S p, outer product (v)\u22972, constraint set \u0398, and the constant d 2, which are not clearly defined. The comment also mentions the heuristic nature of Algorithm 2. However, it does not provide explicit guidance on how the authors should address these issues or improve the clarity of the paper. The feedback is somewhat vague and lacks concrete steps for the authors to follow, making it 3.", "grounding_specificity_rationale": "The comment addresses several specific issues, such as the convenience of applications, issues with existing estimators, and the lack of defined basic notation. It provides detailed references to specific elements like the dimensionality p, unit ball S p, outer product (v)\u22972, constraint set \u0398, and the constant d 2, which are mentioned in the paper. However, the comment does not explicitly mention which sections or parts of the paper these elements are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be clarified or defined, but without explicit references to sections, the authors may find it challenging to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several issues, including the lack of clarity in the paper and the need to highlight issues with existing estimators. It points out specific elements that are not clearly defined, such as the dimensionality p, unit ball S p, outer product (v)\u22972, constraint set \u0398, and the constant d 2. However, the comment does not provide detailed reasoning or examples to support why these elements are unclear or how they impact the paper\"s clarity. The lack of specific references or detailed explanations makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is 3, as it provides some insight but lacks sufficient detail to be fully actionable.", "helpfulness_rationale": "The review comment identifies several areas where the paper could be improved, including the need to highlight issues with existing estimators and the lack of clarity in basic notation. It points out specific elements that are not clearly defined, such as the dimensionality p, unit ball S p, outer product (v)\u22972, constraint set \u0398, and the constant d 2. Additionally, it mentions the heuristic nature of Algorithm 2, which could be clarified. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The feedback is 3 as it provides a clear direction for improvement but could be more actionable with additional details or examples."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should elaborate on which parts of the loss functions are new, given that the neural network and loss functions used are not novel in the field of medical imaging. While the comment implies that the authors need to provide more detailed information about the novelty of the loss functions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to elaborate on the novelty of the loss functions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s claim about the use of three perceptual loss functions for PSR, two of which are new. It suggests that the authors should elaborate on which parts of the loss functions are new, given that the neural network and loss functions used are not novel in the field of medical imaging. However, the comment does not specify which part of the paper discusses these loss functions, making it weakly grounded. The comment is specific in its request for elaboration on the novelty of the loss functions, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the paper uses loss functions that are not novel in the field of medical imaging, suggesting that the novelty of the loss functions is not adequately explained. However, the comment does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence makes the claim 2, as it requires more information to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the novelty of the loss functions used in the paper, suggesting that they are not novel in the field of medical imaging. It implies that the authors should elaborate on which parts of the loss functions are new. This feedback is 3 as it highlights a potential area for clarification, but it lacks specific guidance on how the authors might address this issue or what aspects of the loss functions could be novel. The comment provides a direction for improvement but does not offer detailed suggestions or examples, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the experimental results not showing significant improvements in reallife datasets and notes that the comparison on the ZINC dataset is lacking. However, it does not provide specific guidance or suggestions on how the authors might address these issues. The feedback lacks actionable details, such as recommending specific improvements or additional experiments to conduct. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Experimental Results\" and \"Table 5 in 1,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the lack of significant improvement in reallife datasets and the inadequate comparison on the ZINC dataset. This provides clear guidance on what aspects need attention and improvement. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results do not exhibit significant improvements in reallife datasets and that the comparison on the ZINC dataset is lacking. The comment references Table 5 in 1, which provides a basis for the claim. However, the comment does not provide detailed reasoning or examples to fully substantiate the claim, such as specific metrics or comparisons that would demonstrate the lack of improvement. This makes the claim 3, as it provides a starting point but requires further elaboration for full understanding. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the experimental results, noting that they do not demonstrate significant improvements in reallife datasets and that the comparison on the ZINC dataset is lacking. By referencing Table 5 in 1, the reviewer provides a concrete example of where the authors might need to improve their analysis. This feedback is clear and actionable, as it highlights areas where the authors can enhance the robustness and relevance of their experimental results. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided additional context for the comparison on the ZINC dataset. Overall, the comment is 4, as it effectively guides the authors toward improving their draft by addressing a critical aspect of their experimental results."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point discusses the performance of different models, suggesting that the performance of smaller models might be convincing due to limited data availability. However, it also highlights that larger models generally perform better, as evidenced by the results in Figure 3 (b). While the comment provides some context and observations, it does not explicitly instruct the authors to make any changes or improvements to their draft. The action is implicit, as the authors can infer that they might need to address the limitations of smaller models or provide more context on the performance differences. However, the comment lacks concrete guidance on how to achieve this, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3 (b)\" and provides specific examples of model performance comparisons, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the performance differences between models, such as \"LucaOne performing better than BSM models\" and \"BSM270M model performing better than BSM110M model.\" This provides clear guidance on what aspects of the paper need attention. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that smaller models might be convincing due to limited data availability, but it contradicts this by referencing various experiments where larger models perform better. The comment provides specific examples, such as Figure 3 (b) and the performance of BSM models, which support the claim. This level of detail and specific examples makes the claim 4, as it provides a clear rationale for the observation. However, the comment could be strengthened by referencing specific studies or data that support the claim about larger models performing better. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides a balanced perspective by acknowledging the potential convincing nature of smaller models due to limited data availability, while also highlighting the superior performance of larger models as demonstrated in various experiments. It references specific figures and examples, such as Figure 3 (b) and the performance of BSM models, which helps the authors understand the context and implications of their results. However, the comment could be more helpful if it offered suggestions on how to address the limitations of smaller models or provided guidance on how to improve the discussion of model performance. Overall, the comment is 3 as it offers insights but lacks detailed actionable feedback."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out inconsistencies in the notation used throughout the paper, specifically mentioning that the notation in Figures 2 and 3 does not match the notation in Algorithm 1. It also notes that the notation changes again on Page 4 and Figure 4. While the comment identifies specific areas where inconsistencies exist, it does not provide explicit guidance on how to correct these inconsistencies or suggest specific changes to make the notation consistent. The authors are left to infer that they need to address these inconsistencies, but without concrete steps, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figures 2 & 3\" and \"Page 4 & Figure 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by pointing out inconsistencies in the notation, particularly with the use of \"nu\" and the changes in notation across different sections. This provides clear guidance on what needs to be addressed in terms of notation consistency. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that there is inconsistency in the notation used throughout the paper, specifically mentioning discrepancies between Figures 2 & 3 and Algorithm 1, as well as changes in notation on Page 4 and Figure 4. However, the comment does not provide specific examples or detailed explanations of where these inconsistencies occur or how they affect the understanding of the paper. Without concrete evidence or detailed reasoning, the claim is difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the notation used in the paper, noting inconsistencies in the use of \"nu\" and changes in notation across different sections, such as Figures 2 & 3 and Algorithm 1, as well as on Page 4 and Figure 4. This feedback is clear and actionable, as it highlights areas where the authors need to ensure consistency in their notation to avoid confusion and improve the clarity of their work. However, the comment could be more helpful if it provided specific examples of where the inconsistencies occur or suggested ways to standardize the notation. Overall, the comment is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that more experiments should be conducted in challenging tasks, specifically mentioning Dexterous Manipulations in Adroit as an example. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to perform more experiments, but it lacks concrete guidance on which tasks to include or how to design these experiments. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting more experiments in challenging tasks, specifically mentioning Dexterous Manipulations in Adroit as an example. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to conduct more experiments in challenging tasks, but it lacks grounding as it does not reference a specific section or figure in the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests conducting more experiments in challenging tasks, specifically mentioning Dexterous Manipulations in Adroit as an example. However, the comment lacks specific reasoning or evidence to support why these additional experiments would validate the effectiveness of the proposed method. The mention of Dexterous Manipulations in Adroit provides a reference, but it does not fully substantiate the claim. Therefore, the comment is 3, as it provides a direction for improvement but lacks detailed justification or examples.", "helpfulness_rationale": "The review comment suggests conducting more experiments in challenging tasks, specifically mentioning Dexterous Manipulations in Adroit as an example. This feedback is 3 as it identifies a potential area for improvement in the paper, suggesting that the authors should explore the effectiveness of their method in more complex scenarios. However, the comment lacks specificity regarding which additional experiments should be conducted or how they might contribute to the validation of the proposed method. While it provides a direction for improvement, it does not offer detailed guidance or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a potential issue with the summary of previous works in the introduction, specifically regarding the assumption of linear separability. It suggests that the authors should clarify whether the assumption is stronger than linear separability or if it refers to orthogonally separable data. While the comment identifies a specific area for clarification, it does not provide explicit guidance on how to address the issue or what specific changes should be made to the summary. The action is implicit and somewhat vague, as the authors need to infer the need for clarification and determine the exact nature of the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction section and the summary of previous works, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a potential issue with the assumption of linear separability and suggests that the authors should clarify whether the assumption is stronger than linear separability or if it refers to orthogonally separable data. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the fairness of the summary of previous works in the introduction, specifically regarding the assumption of linear separability. It suggests that the assumption might be stronger than linear separability and raises a potential confusion with orthogonally separable data. The comment provides a logical reasoning by pointing out the potential overreach of the assumption and suggests a specific reference to clarify the issue. However, it lacks detailed examples or references to support the claim fully, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the summary of previous works in the introduction, specifically regarding the assumption of linear separability. It points out that the assumption might be stronger than linear separability and raises a question about whether it refers to orthogonally separable data. This feedback is 3 as it highlights a potential area for clarification and prompts the authors to reconsider the assumptions made in their work. However, the comment could be more helpful if it provided specific suggestions or examples to address the issue, making it actionable for the authors. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a potential issue with the paper\"s persample weight tuning method, specifically regarding the reliance on the influence function. It explains that the theoretical approximation using Taylor\"s firstorder expansion is only valid when the upweight is close to 0. The reviewer suggests that if the weights are far from 0 during training, the influence function might not accurately reflect each sample\"s influence, potentially leading to unreliable weights. While the comment highlights a potential problem, it does not provide explicit guidance on how the authors should address this issue or suggest specific actions to improve the method. The action is implicit and somewhat vague, as the authors need to infer that they should investigate the conditions under which the influence function is valid and possibly modify their method accordingly. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the persample weight tuning method and its reliance on the influence function, providing a specific explanation of the conditions under which the theoretical approximation is valid. It highlights a potential issue with the method when the upweight is far from 0, suggesting that the influence function might not accurately reflect each sample\"s influence. This feedback is specific and provides clear guidance on what needs to be addressed in the paper. However, it does not explicitly mention a specific section or part of the paper, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper\"s persample weight tuning method relies on the influence function, but the explanation of the influence function is only valid when the upweight is close to 0. The reviewer provides a logical reasoning by explaining that the theoretical approximation using Taylor\"s firstorder expansion is not valid when the weights are far from 0. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by providing specific examples or references to support the claim further. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s persample weight tuning method, specifically regarding the reliance on the influence function. It explains that the theoretical approximation using Taylor\"s firstorder expansion is only valid when the upweight is close to 0. The comment highlights a potential problem with the method when the weights are far from 0 during training, suggesting that the influence function might not accurately reflect each sample\"s influence and could lead to unreliable weights. This feedback is clear and actionable, as it points out a specific area where the method may fail and suggests that the authors should investigate the conditions under which the influence function is valid. However, the comment could be more helpful if it provided suggestions on how to address this issue or alternative methods that could be used. Overall, the comment is 4, as it provides valuable insight into a potential weakness in the paper."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should address the issue of centering in partial shapes and scenes, noting that it may not be welldefined for such cases. This provides a clear and direct action for the authors to take, making the comment 5. Additionally, the comment includes an aside about an experiment with up to 50% missing points, which the authors should be aware of. However, the comment does not provide specific guidance on how to address the issue of centering in partial shapes or scenes, which could make it slightly less actionable. Overall, the comment is 4 due to its explicit suggestion and the additional information provided, but it could be more actionable with further guidance on how to implement the suggested changes.", "grounding_specificity_rationale": "The comment addresses the issue of centering in partial shapes and scenes, which is a specific aspect of the paper. It explicitly mentions the problem with centering for complete shapes and suggests that it may not be welldefined for partial shapes or scenes. The comment also provides an aside about an experiment with up to 50% missing points, noting that this is merely an augmentation with a provided groundtruth center. This level of detail provides clear guidance on what needs to be addressed, making the comment 5. Therefore, the comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the applicability of centering as a canonicalization method for partial shapes or scenes. It suggests that while centering works for complete shapes, it may not be welldefined for partial shapes or scenes. The reviewer provides a logical reasoning by noting that the authors present an experiment with up to 50% missing points, implying that this is an augmentation with a provided groundtruth center. However, the comment lacks specific examples or references to support the claim that centering is not welldefined for partial shapes or scenes. This makes the claim 3, as it provides a basis for the concern but requires more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the methodology of centering in the context of partial shapes and scenes, suggesting that it may not be welldefined for such cases. This is a valuable observation that could help the authors improve the robustness and applicability of their approach. The comment also provides a helpful note about an experiment with up to 50% missing points, clarifying that this is an augmentation with a provided groundtruth center. This additional insight is useful for the authors to understand the limitations of their current methodology. However, the comment could be more helpful if it offered specific suggestions on how to address the issue of centering in partial shapes or scenes. Overall, the comment is 4 as it highlights an important area for improvement and provides some context, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should consider ensembling models trained with the proposed negative augmentations and without them to potentially improve performance. This feedback provides a clear and concrete action for the authors to take, specifically suggesting an experiment to test the impact of the proposed negative augmentations. The comment is explicit and offers a direct path for improvement, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s proposed method of learning less about texture semantics by adding negative samples that share texture semantics with anchor images. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific as it suggests an action to improve the paper by proposing to ensemble models trained with the proposed negative augmentations and without them, and to test whether this could improve performance. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the paper could benefit from ensembling models trained with and without the proposed negative augmentations to potentially improve performance. This claim is 3 as it provides a logical reasoning for the suggestion, indicating that the authors should consider testing this approach. However, the comment lacks specific references or detailed examples to fully substantiate the claim, making it 3. The authors would need to further explore and justify this suggestion themselves.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by recommending an experiment to ensemble models trained with and without the proposed negative augmentations. This feedback is clear and offers a concrete way for the authors to potentially enhance the performance of their model. By suggesting this ensembling approach, the comment guides the authors toward a meaningful enhancement of their work, making it 5. The suggestion is detailed and provides a clear path for the authors to follow, aligning with a score of 5."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the partitioning method used in the paper, specifically comparing it to the buffer series in Appendix B. It also questions whether the sample efficiency of Equation 7 is sufficiently demonstrated. However, the comment does not provide explicit guidance or suggestions on how the authors should address these concerns. The authors are left to infer that they need to clarify the partitioning method and possibly provide additional evidence for the sample efficiency claim. Since the action is implicit and lacks concrete details, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses specific sections of the paper, such as page 6 and page 5, as well as Appendix B, which makes it fully grounded. It raises a question about the partitioning method used in the paper, comparing it to the buffer series in Appendix B, and questions whether the sample efficiency of Equation 7 is sufficiently demonstrated. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions and observations about the partitioning method and sample efficiency claims in the paper. It does not contain any subjective opinions, judgments, or suggestions that require verification. The questions are factual and seek clarification, making the comment purely descriptive. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the partitioning method used in the paper, specifically comparing it to the buffer series in Appendix B. It also questions whether the sample efficiency of Equation 7 is sufficiently demonstrated. While the comment identifies areas of concern, it lacks actionable feedback or suggestions on how the authors might address these issues. The questions posed do not provide clear guidance on what changes or improvements are needed, making the comment 3. Authors would gain some insight into potential areas for improvement but would need to make significant effort to address the feedback effectively. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about how the authors form clusters for tokens in Figure 1, which is unclear in Section 3. While it identifies a specific area of confusion, it does not provide explicit guidance or suggestions on how the authors should address this issue. The action is implicit, as the authors need to infer that they should clarify the method of cluster formation for tokens in Figure 1. However, the comment lacks concrete details on how to implement this clarification, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1\" and \"Section 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of clarity in how the authors form clusters for tokens in Figure 1. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding how the authors form clusters for tokens in Figure 1, which is unclear in Section 3. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, namely the method used to form clusters for tokens in Figure 1, which is unclear in Section 3. This feedback is clear and actionable, as it points out a specific issue that the authors need to address to improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided suggestions on how to clarify the method or offered examples of how to present the information more effectively. Despite this, the comment is 4 as it directs the authors\" attention to a critical area that needs clarification, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation of the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This increases the complexity and time cost of experiments, which limits its potential application for large language models in realworld settings. However, the comment does not provide any explicit or implicit actions for the authors to take. It merely points out a limitation without offering guidance on how to address it or suggest improvements. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the introduction of two additional hyperparameters in the SimNPO method, which increases the complexity and time cost of experiments. It highlights the limitation of this approach for large language models in realworld settings. However, the comment does not specify which part of the paper discusses these hyperparameters or where they are introduced, making it weakly grounded. The comment is specific in detailing the issue of additional hyperparameters and their impact on the method\"s application, but without explicit grounding, the authors may struggle to identify the exact section needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that SimNPO introduces two additional hyperparameters, which significantly increase the complexity and time cost of experiments, thereby limiting its application for large language models. The claim is 3 as it provides a logical reasoning for the limitation, but it lacks specific examples or references to support the claim fully. The authors would need to further explore the impact of these hyperparameters to fully understand the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of the SimNPO method, noting that it introduces two additional hyperparameters that must be manually adjusted to achieve optimal performance. This increases the complexity and time cost of experiments, which limits the method\"s potential application for large language models in realworld settings. While the comment highlights an important issue, it lacks specific suggestions or guidance on how the authors might address this limitation or improve the method\"s applicability. The feedback provides some insight into the problem but does not offer actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the work is overemphasizing affordance prompting, which is considered overengineered. It provides an example of the Pick&place task, suggesting that it does not sufficiently demonstrate the advantage of affordance prompting. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to the draft. The action is implicit and somewhat vague, as the authors need to infer that they should reconsider the emphasis on affordance prompting and possibly provide a clearer explanation or example of its benefits. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment critiques the emphasis on affordance prompting, suggesting that it is overengineered. It provides a specific example, the Pick&place task, to illustrate the issue. However, it does not explicitly mention which part of the paper this critique is based on, making it weakly grounded. The comment is specific in detailing the issue with the emphasis on affordance prompting and the lack of demonstration of its advantage. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the work is overemphasizing affordance prompting, which is considered overengineered. The reviewer provides an example of the Pick&place task, suggesting that it does not sufficiently demonstrate the advantage of affordance prompting. However, the comment lacks specific evidence or detailed reasoning to fully substantiate the claim. The example provided is not fully explained, and there is no additional context or comparison to support the assertion that the Pick&place task does not show enough advantage. As a result, the claim is 3, as it provides a basis for the critique but requires more detailed justification to be fully convincing. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the emphasis on affordance prompting, suggesting that it is overengineered. It provides a specific example, the Pick&place task, to illustrate the concern. However, the comment lacks detailed guidance or suggestions on how the authors might address this issue or improve the clarity of their approach. While it highlights a concern, it does not offer actionable steps for the authors to take, making it 3. The authors would need to infer that they should reconsider the emphasis on affordance prompting and provide a clearer explanation or example of its benefits. Therefore, the comment is rated as 3."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that ablation studies are needed to demonstrate the necessity of each component in the proposed algorithmic pipeline. While the comment implies that the authors should conduct these studies, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete direction for the authors to follow. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment suggests that ablation studies are needed to demonstrate the necessity of each component in the proposed algorithmic pipeline. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the methodology is detailed. This lack of explicit grounding makes it difficult for the authors to pinpoint the exact part of the paper that needs revision. While the comment is specific in suggesting the need for ablation studies, it is 1 because it does not provide clear guidance on where these studies should be conducted. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that ablation studies are needed to demonstrate the necessity of each component in the proposed algorithmic pipeline. However, it does not provide any specific reasoning or examples to support why these studies are necessary or how they would demonstrate the necessity of each component. The lack of detailed justification or references makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that ablation studies are needed to demonstrate the necessity of each component in the proposed algorithmic pipeline. This is a relevant and actionable piece of feedback that could significantly enhance the paper by providing evidence of the importance of each part of the methodology. However, the comment could be more helpful if it provided specific guidance on how to conduct these ablation studies or what aspects should be tested. While it identifies a potential area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the necessity of the instructiontuning stage in MoE models, suggesting that the performance improvement might be due to additional training and tuning costs. While it implies that the authors should address this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide evidence or reasoning to address the concern. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the necessity of the instructiontuning stage in MoE models, specifically questioning whether the performance improvement can be attributed to additional training and tuning costs. However, it does not specify which part of the paper discusses the MoE models or the instructiontuning stage, making it weakly grounded. The comment is specific in its questioning about the necessity of the stage and the potential impact of additional training costs. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the necessity of the instructiontuning stage in MoE models by suggesting that the performance improvement might be due to additional training and tuning costs. The comment provides a logical reasoning by comparing the instructiontuning stage to taskspecific finetuning, which introduces additional costs. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore and substantiate the claim to fully understand the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the necessity of the instructiontuning stage in MoE models. It questions whether the performance improvement can be attributed to additional training and tuning costs, which is a relevant point for the authors to address. By identifying this gap, the comment prompts the authors to provide evidence or reasoning to support the necessity of the instructiontuning stage. However, the comment could be more helpful if it offered specific suggestions or examples on how to address this concern. Overall, the feedback is 3 as it highlights an important area for improvement but lacks detailed guidance on how to enhance the draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the evaluation setup is outdated and recommends updating it to reflect current models like Llama3 and Llama3.1, which have advanced significantly in terms of quality. It also provides a specific suggestion to test the approach on a more challenging and representative finetuning setup, such as instruction tuning on Alpaca/OASST or any other instruction finetuning dataset. This feedback is clear and provides concrete actions for the authors to take, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the evaluation setup, allowing the authors to identify the specific part of the paper being addressed. It is also specific because it provides detailed feedback on the outdated nature of the evaluation setup and suggests testing the approach on more challenging and representative finetuning datasets, such as instruction tuning on Alpaca/OASST or other datasets. This provides clear guidance on what needs to be addressed and improved. Therefore, this comment is labeled as 5.", "verifiability_rationale": "The review point claims that the evaluation setup is outdated, noting that Llama1 and Mistralv0.1 were released more than a year ago, while current models like Llama3 and Llama3.1 have advanced significantly in terms of quality. The reviewer suggests testing the approach on a more challenging and representative finetuning setup, such as instruction tuning on Alpaca/OASST or other datasets. This claim is 4 as it provides a logical reasoning based on the release dates and advancements in model quality. However, it could be strengthened with specific references to the improvements in current models or examples of how the suggested datasets would enhance the evaluation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment is 5 as it identifies a critical issue with the evaluation setup, noting that it is outdated and based on models released more than a year ago. It provides a clear rationale by mentioning the advancements in current models like Llama3 and Llama3.1, which have significantly improved in quality. The comment also offers a constructive suggestion to test the approach on a more challenging and representative finetuning setup, such as instruction tuning on Alpaca/OASST or other datasets. This feedback is actionable and provides the authors with a clear direction for improving their evaluation setup, making the comment highly valuable for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of logical coherence in the second section, where many related works are presented but the content appears disorganized. However, it does not provide explicit guidance or suggestions on how the authors should improve the logical coherence or structure of the section. The action is implicit, as the authors can infer that they need to organize the content better, but the comment lacks concrete details on how to achieve this. Therefore, the comment is 3, as it identifies an issue but does not provide specific instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the second section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of logical coherence in the presentation of related works, indicating that the content appears disorganized. This provides clear guidance on what needs to be addressed in terms of improving the logical flow and organization of the section. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the second section lacks logical coherence, resulting in a disorganized content. However, it does not provide any specific examples or reasoning to support this claim. Without detailed evidence or examples, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of logical coherence in the second section, where many related works are presented but the content appears disorganized. While it highlights a potential issue with the organization of the section, it does not provide specific suggestions or guidance on how the authors might improve the logical flow or structure of the content. This limits the comment\"s usefulness, as it offers insight into a problem but lacks actionable advice for improvement. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in addressing it."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review comment explicitly instructs the authors to mention the language they focus on to retrieve Reddit posts. This is a direct and clear action, providing the authors with a specific task to address. The comment is explicit and concrete, as it clearly states what needs to be done without leaving any ambiguity. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors mention the language they focus on to retrieve Reddit posts. However, it does not specify which part of the paper this information should be included in, making it weakly grounded. The comment is specific in its request for information about the language focus, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a request for clarification, specifically asking the authors to mention the language they focus on to retrieve Reddit posts. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment is a request for clarification, specifically asking the authors to mention the language they focus on to retrieve Reddit posts. While it identifies a potential area for improvement, it does not provide any actionable feedback or suggestions on how the authors might address this issue. The comment lacks depth and does not offer guidance on what the authors should consider or how they might improve their draft. As a result, it is 2, as it only points out a minor issue without providing substantial assistance for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper lacks comparisons with recent works, such as 1. While it identifies a specific area for improvement, it does not provide explicit guidance on how the authors should conduct these comparisons or what aspects of the comparisons should be emphasized. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with recent works but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks comparisons with recent works, such as 1. However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in identifying the need for comparisons with recent works, but without explicit guidance on where to include them or what aspects to focus on, the authors may find it challenging to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks comparisons with recent works, such as 1. However, it does not provide specific examples or detailed reasoning to support this claim. The mention of 1 alone is insufficient to substantiate the claim, as it does not explain why the paper should include comparisons with this specific work or how it would impact the paper\"s contribution. Without further elaboration or context, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of comparisons with recent works, such as 1. This feedback is clear and actionable, as it directs the authors to include relevant comparisons in their paper to enhance its relevance and impact. However, the comment could be more helpful if it provided guidance on how to conduct these comparisons or what aspects of the comparisons should be emphasized. Despite this, the feedback is 4 as it highlights a critical area for improvement and offers a clear direction for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about whether TSG (TimeSensitive Guidance) can be applied in diffusion models that do not embed class labels into timesteps, such as UViT. While it raises an interesting point, it does not provide explicit guidance or suggestions on how the authors should address this question or incorporate it into their work. The action is implicit, as the authors can infer that they need to explore or discuss this aspect, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the applicability of TSG in diffusion models that do not embed class labels into timesteps, such as UViT. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this topic is discussed, the comment lacks full grounding. It is specific in questioning the applicability of TSG in a particular context, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point is a question seeking clarification about the applicability of TSG in a specific context, namely diffusion models that do not embed class labels into timesteps. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information or clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the applicability of TSG (TimeSensitive Guidance) in diffusion models that do not embed class labels into timesteps, such as UViT. This is a relevant and specific inquiry that could help the authors explore the limitations or applicability of their methodology in different contexts. However, the comment lacks actionable guidance or suggestions on how the authors might address this question or incorporate it into their work. While it identifies an area for potential exploration, it does not provide detailed feedback or direction, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors release their training code, dialogue dataset, and model checkpoints to allow others to reproduce the claims in the paper. This is a clear and direct action for the authors to take, providing them with a concrete step to enhance the reproducibility of their work. The comment also encourages the authors to attach these materials via anonymous repositories, which further supports the action. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment addresses the issue of limited reproducibility, specifically mentioning the need for the authors to release their training code, dialogue dataset, and model checkpoints. This provides a clear indication of what is missing in the paper, making it fully grounded as it specifies the parts of the paper that need improvement. The comment is also specific in its request for the release of these materials, which would allow reviewers to verify the claims and test the model. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks reproducibility, specifically mentioning the need for the authors to release their training code, dialogue dataset, and model checkpoints. The reviewer suggests that these materials should be made available via anonymous repositories to allow others to verify the claims and test the model. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to release the materials is logical, but the lack of specific examples or references to similar practices in the field makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the reproducibility of the paper, specifically noting that the authors have not provided their training code, dialogue dataset, or model checkpoints. This is a critical aspect for verifying the claims and replicating the results. The reviewer offers a clear and actionable suggestion by recommending that the authors release these materials via anonymous repositories. This feedback is 5 as it provides a concrete step for the authors to take, enhancing the transparency and credibility of their work. By addressing this issue, the authors can significantly improve the utility and impact of their paper. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review comment points out that the main result is considered obvious because it relates to gradient boosting, which is a known method for minimizing objectives in functional space. However, it does not provide any explicit or implicit suggestions for improvement or clarification. The comment lacks actionable guidance, leaving the authors without a clear understanding of what changes or enhancements are needed to address the perceived issue. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the main result is obvious because it relates to gradient boosting, which is a known method for minimizing objectives in functional space. However, it does not specify which part of the paper this observation pertains to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the result are considered \"obvious\" or how they could be improved. Without clear grounding and specificity, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the main result is \"a bit obvious\" because it relates to gradient boosting, which is a known method for minimizing objectives in functional space. However, the comment lacks specific examples or detailed reasoning to support this claim. It does not provide any evidence or references to substantiate the assertion that the result is \"obvious.\" Without such support, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the main result is considered obvious because it relates to gradient boosting, which is a known method for minimizing objectives in functional space. However, it does not provide any specific feedback or suggestions on how the authors might address this perceived lack of novelty or originality in their work. Without actionable guidance or constructive feedback, the comment does not offer the authors any meaningful direction for improving their draft. Therefore, it is rated as 1."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of explicit contribution and suggests that the paper appears incomplete due to insufficient explanation of the proposed model and limited related work. While it points out the need for more detailed explanations and analysis, it does not provide specific guidance on how to address these issues. The authors are left to infer that they need to expand their explanation and include more related work, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment highlights a lack of explicit contribution and suggests that the paper appears incomplete due to insufficient explanation of the proposed model and limited related work. However, it does not specify which part of the paper lacks these details, making it difficult for the authors to pinpoint the exact areas needing improvement. The comment is 1 as it does not reference specific sections or elements of the paper, and it is also not specific because it does not provide detailed guidance on what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the contribution of the work is insufficient and that the paper appears incomplete. It suggests that the details provided do not adequately explain the specifics of the proposed model and mentions the lack of related work and analysis. While the comment identifies a potential issue, it lacks specific examples or references to support the claim about the lack of contribution or completeness. This makes the claim 3, as the authors would need to further investigate and provide evidence to substantiate the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the contribution is insufficient and that the paper appears incomplete. It points out that the details provided do not adequately explain the specifics of the proposed model and mentions the lack of related work and analysis. This feedback is 3 as it highlights areas where the paper could be improved, prompting the authors to consider expanding their explanation and including more related work. However, the comment could be more helpful if it provided specific suggestions on how to address these issues or examples of what additional content would be beneficial. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly identifies a specific issue with the presentation of results in Figure 2a and Figure 2b. It points out that Figure 2a is given in walltime, while Figure 2b is labeled as training steps, but the xaxis is labeled \"item\" instead of \"training steps.\" The comment suggests that Figure 2a should also include iterations or training steps as the xaxis. This feedback provides clear and direct instructions for the authors to improve the clarity of their results presentation. The action is explicit and concrete, allowing the authors to know exactly what needs to be done to address the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2a\" and \"Figure 2b,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the presentation of results, particularly the confusion regarding what the training steps refer to (outerloop iterations or raw experience) and suggests that Figure 2a should also include iterations or training steps as the xaxis. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the results are presented in walltime (Figure 2a) and training steps (Figure 2b), but it is not clear what the training steps refer to. The comment suggests that Figure 2a should also include iterations or training steps as the xaxis. However, the comment lacks specific examples or references to clarify the confusion about the training steps, making it 3. The authors would need to infer the details themselves, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the presentation of results in Figures 2a and 2b. It points out that Figure 2a is presented in walltime, while Figure 2b is labeled as training steps but uses the xaxis label \"item\" instead of \"training steps.\" The comment suggests that Figure 2a should also include iterations or training steps as the xaxis for clarity. This feedback is clear and actionable, providing the authors with a direct way to improve the clarity and accuracy of their results presentation. However, the comment could be more helpful if it included suggestions on how to present the data more effectively or examples of how to label the axes. Overall, the comment is 4 as it directs the authors\" attention to a specific area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the use of different cost metrics for different devices, suggesting that using a consistent cost measure like flops, latency, or 1/FPS might be more appropriate. However, it does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes to make. The action is implicit, as the authors can infer that they need to consider a consistent cost metric, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the use of different cost metrics for different devices, specifically mentioning flops, latency, and 1/FPS for different hardware. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where these cost metrics are discussed. This makes it difficult for the authors to pinpoint the exact location in the paper that needs attention. While the comment is specific in its inquiry, it lacks grounding as it does not provide clear guidance on where to address the issue. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the use of different cost metrics for different devices, suggesting that a consistent cost measure like flops, latency, or 1/FPS might be more appropriate. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this approach would be better. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the use of different cost metrics for different devices, suggesting that a consistent cost measure like flops, latency, or 1/FPS might be more appropriate. However, the comment does not provide specific guidance or suggestions on how the authors could address this issue or what changes might be necessary to implement a consistent cost metric. While it identifies a potential area for improvement, the feedback lacks depth and actionable advice, making it 3. The authors may gain some insight into the problem but would need to explore it further on their own. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the maximum number of iterations set in the experiment and whether these iterations might significantly slow down the training speed. While the comment implies that the authors should consider the impact of iterations on training speed, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address this issue. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"twodimensional Wasserstein distance\" and the \"Sinkhorn algorithm,\" allowing the authors to accurately identify the parts of the paper being addressed. It also raises a specific question about the maximum number of iterations set in the experiment and whether these iterations significantly slow down the training speed. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a question about the impact of iterations on training speed when using the Sinkhorn algorithm for the twodimensional Wasserstein distance. While the comment highlights a potential concern, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the impact of iterations on training speed when using the Sinkhorn algorithm for the twodimensional Wasserstein distance. It points out that iterations are needed before each gradient descent and asks about the maximum iterations set in the experiment. This feedback is 3 as it prompts the authors to consider the potential impact of iterations on training efficiency. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered insights into how iterations might affect the training process. Overall, the comment offers a clear direction for improvement but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a major weakness in the paper regarding its soundness, specifically concerning the teacher policy and its distribution matching. It suggests that the authors should provide theoretical results to support the method, indicating that the current approach appears more like a heuristic. While the comment highlights a specific area for improvement, it does not provide explicit guidance on how to conduct these theoretical analyses or what specific results are expected. The action is implicit and somewhat vague, as the authors need to infer the need for theoretical support and determine how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue with the paper\"s soundness, particularly regarding the teacher policy and its distribution matching. It suggests that the authors should provide theoretical results to support the method, indicating that the current approach appears more like a heuristic. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections. The comment is specific in detailing what needs to be addressed, namely the lack of theoretical support for the method. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks soundness, specifically regarding the teacher policy and its distribution matching. The reviewer provides a detailed explanation of the issue, suggesting that the method appears more like a heuristic rather than a theoretically sound approach. However, the comment does not provide specific examples, references, or detailed reasoning to fully substantiate the claim. While the reasoning is logical, the lack of concrete evidence or examples makes it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies a significant weakness in the paper regarding its soundness, specifically concerning the teacher policy and its distribution matching. It highlights that the method appears more like a heuristic rather than a theoretically sound approach, which is a critical issue for the paper\"s credibility. The reviewer suggests that the authors should provide theoretical results to support their method, which would strengthen the paper\"s foundation. This feedback is clear and actionable, offering a specific direction for improvement by suggesting the inclusion of theoretical results. However, the comment could be more helpful if it provided examples of what kind of theoretical results would be beneficial or how to incorporate them into the paper. Overall, the comment is 4 as it effectively guides the authors toward enhancing the theoretical underpinning of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the proposed method does not perform well in some classes and suggests that the reasons should be analyzed and discussed. While the comment implies that the authors should investigate and address these issues, it does not provide specific guidance on how to analyze or discuss the reasons for the poor performance. The action is explicit but somewhat vague, as the authors are left to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the analysis and discussion of the reasons for the proposed method\"s poor performance in some classes. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method does not perform well in some classes and suggests that the reasons should be analyzed and discussed. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that it does not perform well in some classes. It suggests that the reasons for this poor performance should be analyzed and discussed. While the comment highlights a potential area for improvement, it lacks specific guidance or suggestions on how to conduct this analysis or what aspects to focus on. This limits the comment\"s usefulness, as it provides a general direction but not detailed steps for the authors to follow. Therefore, the comment is 3, as it points out a weakness but does not fully support the authors in addressing it."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a lack of rigor in some experimental settings, specifically mentioning that MTT should test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. While the comment provides a clear direction for improvement, it lacks specific guidance on how to conduct these additional experiments or what specific aspects of the results should be discussed. The action is explicit but somewhat vague, as the authors know they need to address the rigor of their experimental design and provide further analysis of their results, but they may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific experimental settings, such as MTT, and suggests that they should be tested on unseen tasks. It also recommends further discussion or explanation of the experimental results, particularly regarding the variation of model behavior under different datasets or settings. However, the comment does not explicitly mention which part of the paper these suggestions pertain to, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. The comment is specific in suggesting improvements to the experimental design and analysis, but it lacks full grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some experimental settings are not rigorously designed, specifically mentioning that MTT should test on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. While the comment identifies a potential issue with the experimental design, it lacks specific examples or references to support the claim about the rigor of the experimental settings. The suggestion to discuss or explain the results is somewhat vague, as it does not provide detailed guidance on how to achieve this. Therefore, the comment is 3, as it provides a general direction for improvement but lacks detailed evidence or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the experimental design, specifically noting that MTT should be tested on unseen tasks. It also suggests that the experimental results could be further discussed or explained, particularly regarding the variation of model behavior under different datasets or settings. This feedback is 3 as it points out a specific area for improvement in the experimental design and provides a direction for enhancing the discussion of results. However, the comment could be more actionable by offering specific suggestions on how to conduct these additional experiments or what aspects of the results should be emphasized. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the data collection for the 5 layouts was randomized. It suggests that the data was collected in the same order, which could introduce learning effects. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue. It lacks concrete instructions or actions for the authors to take, such as recommending a different data collection method or explaining the potential impact of the current approach. As a result, the authors are left without clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the data collection process for the 5 layouts, specifically questioning whether it was randomized. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or data collection section, but this inference is not direct. The comment is specific in identifying a potential issue with the data collection process, but it lacks grounding as it does not explicitly mention the section being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions whether the data collection for the 5 layouts was randomized, suggesting that the data was collected in the same order, which could introduce learning effects. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that learning effects might be present. Without additional context or justification, the authors may find it challenging to understand the basis of the concern. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the data collection process for the 5 layouts, specifically questioning whether it was randomized. It suggests that the data might have been collected in the same order, which could introduce learning effects. While the comment identifies a potential issue, it lacks specificity and actionable guidance on how the authors might address this concern. It does not provide suggestions for improvement or alternative methods to ensure randomization. As a result, the feedback is 3, as it highlights a potential weakness but does not offer detailed guidance for improvement. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the role of node ordering in the context of random ordering of atoms in a specific point in the composition space. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what changes could be made to the draft. Without any actionable suggestions or details, the authors are left without a clear understanding of what steps to follow to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions a specific point in the paper, allowing the authors to accurately identify the part being addressed. It also specifies the issue by questioning the role of node ordering in the context of random ordering of atoms in a specific point in the composition space. This provides clear guidance on what aspect of the paper needs further clarification or discussion. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the role of node ordering in the context of random ordering of atoms in a specific point in the composition space. It does not present an opinion, claim, or suggestion that requires verification. It is a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the role of node ordering in the context of random ordering of atoms in a specific point in the composition space. However, it does not provide any specific guidance or suggestions on how the authors might address this concern or improve their draft. The comment lacks depth and actionable feedback, leaving the authors without a clear understanding of what changes could be made to enhance their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point claims that the novelty of the current work is detracted by a previous work that also presents a dexterous manipulation benchmark with musculoskeletal hands. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this concern, such as suggesting ways to differentiate their work or providing additional context. Without actionable advice or suggestions, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"previous work 5,\" which is a specific reference to a paper. However, it does not specify which part of the paper this comment is addressing, making it weakly grounded. The comment does specify that the novelty of the current work is detracted by the previous work, providing some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the novelty of the current work is detracted by a previous work that also presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide any specific details or examples to support this claim. It lacks detailed reasoning or references to substantiate the assertion that the novelty is being detracted. As a result, the claim is 1 due to the absence of supporting evidence or justification. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment claims that the novelty of the current work is detracted by a previous work that also presents a dexterous manipulation benchmark with musculoskeletal hands. However, the comment does not provide any specific details or examples to support this claim, nor does it offer suggestions or guidance on how the authors might address this issue. Without additional context or constructive feedback, the authors are left without a clear understanding of how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to clarify the selection process of the datasets, including specifying the pool of datasets and the criteria for selection. It also mentions that the selection of the splitting procedure and split ratios is adhoc and lacks detail. This feedback provides clear and concrete actions for the authors to take, ensuring they know exactly what needs to be addressed in their draft. The comment is 5 as it offers specific guidance on how to improve the clarity and detail of the methodology section.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the selection of datasets and the splitting procedure, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it provides clear guidance on what needs to be clarified, such as specifying the pool of datasets and the criteria for selection, as well as the adhoc nature of the splitting procedure and split ratios. The comment also references specific works, such as Bischl et al. and Gijsbers et al., which adds depth to the feedback. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the selection of datasets and splitting procedures should be clarified, providing examples of relevant works like Bischl et al. and Gijsbers et al. This provides a logical basis for the claim, as it references specific examples of how other works have addressed similar issues. However, the comment could be strengthened by providing more detailed reasoning or additional references to fully substantiate the claim. Therefore, the comment is 4, aligning with a score of 4.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the clarity and detail of the methodology section, particularly regarding the selection of datasets and splitting procedures. It suggests that the authors should clarify the selection process, specifying the pool of datasets and the criteria for selection. Additionally, it points out that the selection of the splitting procedure and split ratios is adhoc and lacks detail, offering examples of relevant works that address similar issues. This feedback is clear and constructive, guiding the authors on how to improve the transparency and rigor of their methodology. However, it could be more helpful if it included suggestions on how to implement these changes or provided more detailed guidance on what specific aspects to clarify. Overall, the comment is 4, as it effectively directs the authors toward significant improvements in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the ablation study lacks a critical comparison and recommends including a baseline where an unconditional diffusion model is first refined using the suggested efficient architectural changes, followed by either consistency distillation or progressive distillation. It also suggests comparing the proposed method to a model initialized with random parameters to provide a relevant benchmark. This feedback provides clear and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides detailed suggestions for improvement, including the need for a baseline comparison with an unconditional diffusion model refined using efficient architectural changes and either consistency or progressive distillation. Additionally, it suggests comparing the proposed method to a model initialized with random parameters to provide a relevant benchmark. This level of detail provides clear guidance on what needs to be addressed, making the comment 5.", "verifiability_rationale": "The review point claims that the ablation study lacks a critical comparison, specifically suggesting the inclusion of a baseline where an unconditional diffusion model is refined using efficient architectural changes followed by either consistency or progressive distillation. The reviewer also suggests comparing the proposed method to a model initialized with random parameters to provide a relevant benchmark. While the comment provides a logical reasoning for the need for such comparisons, it lacks specific examples or references to support the claim. This makes the claim 3, as the authors would need to further explore and substantiate the suggestions themselves.", "helpfulness_rationale": "The review comment identifies a significant gap in the ablation study by suggesting the inclusion of a critical comparison. It proposes a specific baseline where an unconditional diffusion model is refined using efficient architectural changes, followed by either consistency or progressive distillation. This suggestion is actionable and provides a clear direction for the authors to enhance their study by comparing their proposed method to conventional baselines. Additionally, the comment highlights the importance of comparing the proposed method to a model initialized with random parameters, which would provide a relevant benchmark. This feedback is 4 as it offers detailed guidance on how to improve the study, but it could be further enhanced by suggesting specific metrics or methods for comparison. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the tasks in the paper are too homogeneous and suggests referring to other projects, such as 1 and 2, to design more tasks. While the comment implies that the authors should consider expanding the variety of tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to design more tasks. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that the tasks in the paper are too homogeneous and implies that the authors should consider designing more tasks, such as those referenced in 1 and 2. However, it does not specify which part of the paper these tasks are discussed in, making it weakly grounded. The comment is specific in suggesting that the tasks are too homogeneous and recommending additional tasks, but it lacks grounding as it does not point to a specific section or task. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the tasks in the paper are too homogeneous, implying that the authors should consider designing more diverse tasks. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the current tasks are considered too homogeneous. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a potential issue with the homogeneity of the tasks in the paper, suggesting that the authors should consider designing more diverse tasks. It provides a specific suggestion by referencing other projects, such as 1 and 2, which could serve as examples for the authors to consider. While the comment highlights a potential area for improvement, it lacks detailed guidance on how to implement this suggestion or what specific aspects of task diversity should be explored. This makes the feedback 3, as it points out a direction for enhancement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the comparison in Table 2 is unfair because the training data for LEPA is likely larger than the \"Without Plan/Without SelfReflection\" settings, which are aligned with lines 349360. However, the comment does not provide explicit guidance on how the authors should address this issue or what specific changes should be made to make the comparison fair. The action is implicit and somewhat vague, as the authors are left to infer that they need to adjust the comparison or provide additional context to make it fair. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the comparison is unfair due to the size of the training data for LEPA being larger than the \"Without Plan/Without SelfReflection\" settings. Additionally, it references a specific source, 1 LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPENSOURCE LLMS, which provides context for the comparison. This level of detail makes the comment 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the comparison in Table 2 is unfair due to the size of the training data for LEPA being larger than the \"Without Plan/Without SelfReflection\" settings. The comment references a specific source, 1 LUMOS: LEARNING AGENTS WITH UNIFIED DATA, MODULAR DESIGN, AND OPENSOURCE LLMS, which provides context for the comparison. This reference supports the claim by indicating that the training data size is a factor in the comparison, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how the size of the training data affects the comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential issue with the fairness of the comparison in Table 2, specifically noting that the training data for LEPA is likely larger than the \"Without Plan/Without SelfReflection\" settings. This observation is based on a reference to a specific source, which provides context for the comparison. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue or improve the fairness of their comparison. While it highlights a potential weakness, it lacks actionable advice, making it 3. The authors are left to infer that they need to consider the size of the training data in their comparison, but without detailed guidance, the feedback remains 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to add details on how to solve the optimization in the main paper. This is a direct and concrete action, as it provides a clear and specific task for the authors to follow. The comment also highlights the importance of this information, which helps the authors understand the significance of the task. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should add details on how to solve the optimization in the main paper, indicating that this is an important piece of information currently lacking. However, it does not specify which part of the paper this information should be added to, nor does it provide specific guidance on what details should be included. The authors can infer that it relates to the optimization section, but the lack of explicit grounding and specificity makes it challenging for them to pinpoint the exact areas needing improvement. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the authors should add details on how to solve the optimization in the main paper, as it is an important piece of information currently lacking. However, the comment does not provide any specific reasoning or examples to support why this information is crucial or how it would enhance the paper. Without additional context or justification, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should provide more details on how to solve the optimization in the main paper. This is a clear and actionable piece of feedback that can help the authors enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered additional guidance on what specific details should be included or how the optimization process could be better explained. Despite this, the feedback is 4 as it directs the authors toward a critical area needing attention, aligning with a score of 4."}
{"actionability_label": "4", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the exclusion of LLaVAseries and QwenVL from the evaluation and suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. While the comment implies that the authors should include these models, it does not explicitly instruct them to do so. The action is clear but inferred, and the comment provides a concrete suggestion for improvement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment raises a question about the exclusion of LLaVAseries and QwenVL from the evaluation and suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. However, it does not specify which part of the paper this question pertains to, such as the evaluation section or the discussion of model architectures. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting the inclusion of these models, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the exclusion of LLaVAseries and QwenVL from the evaluation and suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. The claim is 3 as it highlights a potential gap in the evaluation by suggesting the inclusion of commonly adopted LVLMs. However, the comment lacks specific examples or references to support the claim, making it difficult for the authors to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a question about the exclusion of LLaVAseries and QwenVL from the evaluation and suggests that including these models would provide a more comprehensive comparison across different LVLM architectures and training approaches. This feedback is 3 as it identifies a potential gap in the evaluation and offers a constructive suggestion for improvement. However, the comment could be more helpful if it provided specific guidance on how to incorporate these models or why they are particularly relevant. Overall, the comment offers some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should include captions or descriptions for the OCR heavy datasets mentioned in the previous point. While the action is explicit, it lacks concrete details on how to implement this suggestion, such as specific examples of what should be included in the captions or descriptions. The comment provides a clear direction but does not offer detailed guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is weakly grounded as it does not specify which part of the paper it refers to, making it difficult for the authors to identify the exact section that needs improvement. It mentions \"related to previous point,\" which implies a connection to a prior discussion or section, but without explicit references, the authors cannot confidently determine the exact part being addressed. The comment is specific in suggesting the inclusion of captions or descriptions for OCR heavy datasets, providing a clear direction for improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should include captions or descriptions for OCR heavy datasets mentioned in the previous point. However, it does not provide any supporting evidence, reasoning, or examples to justify why this inclusion is necessary or beneficial. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors should include captions or descriptions for OCR heavy datasets mentioned in the previous point. While it identifies a specific area for improvement, it lacks depth and does not provide detailed guidance or examples on how to implement this suggestion. The comment is 3 as it points out a potential enhancement to the draft, but it does not fully support the authors in making the necessary changes. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption about the loss of TKD being less than IYOR contradicts the information provided in the equation. However, it does not provide explicit guidance on how the authors should address this issue or what specific changes are needed to resolve the discrepancy. The action is implicit and vague, as the authors are left to infer that they need to reconcile the assumption with the equation, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Assumption 3.1\" and \"Equation 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue, which is the discrepancy between the assumption about the loss of TKD being less than IYOR and the information provided in Equation 7. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point highlights a discrepancy between Assumption 3.1 and Equation 7, suggesting that the assumption contradicts the information provided in the equation. However, the comment does not provide any detailed reasoning or explanation for why this discrepancy exists or how it affects the paper. Without additional context or justification, the authors may find it challenging to understand the significance of this observation. Therefore, the claim is considered 2, as it lacks sufficient evidence or explanation to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific discrepancy between Assumption 3.1 and Equation 7, pointing out that the assumption about the loss of TKD being less than IYOR contradicts the information provided in the equation. This feedback is clear and actionable, as it highlights a potential inconsistency in the paper that the authors need to address. By pointing out this discrepancy, the comment provides the authors with a concrete area to investigate and potentially correct, which can significantly improve the accuracy and consistency of their work. However, the comment could be more helpful if it suggested ways to resolve the discrepancy or provided additional context. Overall, the comment is 4, as it effectively directs the authors toward a specific issue that needs attention."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the clarity of the mention of question 3, which is labeled as weaknesses 2 and 4. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might clarify this point or address the question. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"question 3\" and mentions \"weakness 2 and 4,\" but it does not specify which part of the paper these questions or weaknesses are discussed in. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the questions or weaknesses are unclear or need clarification. As a result, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point is a request for clarification regarding the mention of question 3 and its relation to weaknesses 2 and 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the clarity of the mention of question 3 and its relation to weaknesses 2 and 4. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or clarify the mention. The comment lacks actionable feedback, leaving the authors without a clear path to improve their draft. Therefore, it is rated as 2, as it identifies a potential area for clarification but does not offer actionable advice."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the choice of using the lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on whether the authors should consider using middle layers instead or if they should explore the effectiveness of different layers. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the choice of using lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where this choice is discussed. Without explicit references to the paper\"s structure, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspect of the choice is being questioned or why it might be problematic. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the choice of using lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a relevant question about the choice of using lastlayer hidden states for the classifier, suggesting that middle layers might be more effective. This feedback prompts the authors to reconsider their methodology and potentially explore alternative approaches. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this issue or what alternative layers could be considered. While it identifies a potential area for improvement, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of motivation for using GUE to determine tokenization, model architecture, and training objective for the generative model. It suggests that these choices are arbitrary and potentially incongruous, and that the representations learned may not generalize well to other tasks. However, the comment does not provide explicit guidance or suggestions on how the authors could address this issue or improve the motivation for their choices. The action is implicit and vague, as it does not specify how to enhance the motivation or what specific improvements are needed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for using GUE in determining tokenization, model architecture, and training objective for the generative model. It provides a specific critique about the arbitrary and potentially incongruous nature of these choices, suggesting that the representations learned may not generalize well to other tasks. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. The comment is specific in detailing the issue with the motivation and generalizability of the model. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the use of GUE to determine tokenization, model architecture, and training objective is poorly motivated and arbitrary, potentially leading to representations that lack generalizability. The reviewer provides a logical reasoning by suggesting that the representations learned may be optimized for a narrow set of tasks presented in GUE, which could limit their applicability. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a lack of motivation for using GUE to determine tokenization, model architecture, and training objective for the generative model. It highlights that these choices appear arbitrary and potentially incongruous, suggesting that the representations learned may not generalize well to other tasks. While the comment points out a critical issue with the motivation and generalizability of the model, it does not provide specific suggestions or guidance on how the authors might address this concern. The feedback is 3 as it directs the authors to reconsider the rationale behind their choices, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment explicitly states that the paper reads clunkily due to significant grammar and spelling errors, and that it needs a major editing pass. This feedback provides a clear and direct action for the authors to take, which is to perform a thorough editing pass to correct these grammatical and spelling issues. The comment is specific about what needs to be addressed and offers a concrete action for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment indicates that the paper reads clunkily due to significant grammar and spelling errors, suggesting that it needs a major editing pass. However, it does not specify which sections of the paper are affected by these issues, making it difficult for the authors to pinpoint the exact parts that need revision. While the comment highlights a general issue, it lacks specificity regarding the particular areas that require improvement. Therefore, the comment is 1 and lacks specificity, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the paper reads clunkily due to significant grammar and spelling errors, and that it needs a major editing pass. However, the comment does not provide any specific examples of these errors or suggest how they might be addressed. Without detailed evidence or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the readability of the paper, specifically due to grammar and spelling errors. It suggests that the paper needs a major editing pass to improve its clarity and professionalism. While the comment highlights a critical area for improvement, it lacks specific examples or suggestions on how to address these issues, such as recommending specific corrections or providing guidance on editing techniques. This limits the comment\"s usefulness, as it provides a general direction but not detailed actionable feedback. Therefore, the comment is 3, as it points out a critical area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises several questions about the consistency and validity of the SITE estimator, particularly concerning the assumptions required for it to be a valid estimator of the causal effect. It also questions the definition of the loss function and its implications for the objective function used in the regression. While the comment identifies areas of concern and questions that need clarification, it does not provide explicit instructions or suggestions on how the authors should address these issues. The questions are somewhat vague and lack concrete guidance on how to improve the draft, making it 3.", "grounding_specificity_rationale": "The comment raises several questions about the consistency and validity of the SITE estimator, particularly concerning the assumptions required for it to be a valid estimator of the causal effect. It also questions the definition of the loss function and its implications for the objective function used in the regression. However, the comment does not specify which part of the paper these questions pertain to, such as specific sections or equations. This makes it weakly grounded, as the authors cannot confidently determine which parts of the paper are being addressed. The comment is specific in its questions about the assumptions and the loss function, but without clear grounding, it is rated as 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a series of questions and inquiries about the consistency and validity of the SITE estimator, particularly regarding the assumptions required for it to be a valid estimator of the causal effect. The comment does not present an opinion, judgment, or suggestion that requires verification. It is purely factual and seeks clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises several important questions about the consistency and validity of the SITE estimator, particularly concerning the assumptions required for it to be a valid estimator of the causal effect. It also questions the definition of the loss function and its implications for the objective function used in the regression. While the comment identifies areas of concern and prompts the authors to consider these aspects, it lacks specific suggestions or guidance on how to address these issues. The questions are clear and could guide the authors in refining their work, but they do not provide actionable steps for improvement. Therefore, the comment is 3, as it highlights important areas for consideration but does not offer comprehensive guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It suggests that the method\"s reliance on mask guidance from previous interactions might limit its practical utility if the target object changes between clicks. However, the comment does not provide explicit guidance or suggestions on how the authors could address this limitation or improve the method. The action is implicit and vague, as it does not specify how to enhance the method or what specific changes could be made to overcome the identified limitation. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"OIS\" and \"Objectlevel Understanding,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue by questioning whether OIS can handle interactive segmentation for multiple objects simultaneously and highlights a potential limitation related to mask guidance from previous interactions. The comment provides a clear explanation of the problem and its implications, making it specific. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It suggests that the method\"s reliance on mask guidance from previous interactions might limit its practical utility if the target object changes between clicks. The comment references a specific work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which provides context and supports the claim. However, the comment could be strengthened by providing more detailed reasoning or examples of how the method\"s limitations affect its practical utility. Overall, the claim is 4 due to the reference to a specific work, but it could benefit from additional explanation or evidence.", "helpfulness_rationale": "The review comment identifies a potential limitation in the method, specifically the ability of OIS to handle interactive segmentation for multiple objects simultaneously. It highlights a concern related to the reliance on mask guidance from previous interactions, which could hinder the method\"s practical utility if the target object changes between clicks. The comment references a specific work, \"Object Aware Contrastive Prior for Interactive Image Segmentation,\" which provides context and supports the claim. However, the comment could be more helpful if it offered suggestions on how the authors might address this limitation or explored potential solutions. Overall, the feedback is 3 as it points out a critical area for improvement but lacks depth and actionable guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the assumption that anomalies would align with concepts, questioning the realism of this assumption. However, it does not provide any explicit or implicit suggestions on how the authors might address this issue or improve their approach. There is no guidance on potential modifications, alternative methods, or additional experiments that could be conducted to validate or refine the assumption. As a result, the authors are left without any actionable steps to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the assumption that anomalies would align with concepts, questioning the realism of this assumption. However, it does not specify which part of the paper this critique pertains to, such as a particular section or methodology. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the assumption, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that anomalies would align with concepts, questioning the realism of this assumption. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. It lacks sufficient evidence or justification to make the claim 5. The authors would need to infer the basis of the critique, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a valid concern about the assumption that anomalies would align with concepts, questioning the realism of this assumption. It provides a clear example of how anomaly detection systems, like intrusion and fraud detection systems, typically work, which helps the authors understand the context of the critique. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve their approach. While it identifies a potential weakness, it does not offer actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly suggests that the authors should include a discussion on the current limitations and challenges of HLOP, as well as the experimental design. It also recommends discussing the potential downsides of HLOP and the limitations of the evaluation process. This feedback provides clear and concrete actions for the authors to take, specifying exactly what needs to be addressed in the draft. The comment is 5 as it offers specific guidance on how to improve the paper by addressing these areas of concern.", "grounding_specificity_rationale": "The comment suggests that the paper lacks discussion on the current limitations and challenges of HLOP, as well as the experimental design. It also recommends including a discussion on the potential downsides of HLOP and the limitations of the evaluation process. However, the comment does not specify which sections or parts of the paper should include this discussion, making it weakly grounded. The authors can infer that it relates to the introduction or methodology sections, but this inference is not as direct as it could be. The comment is specific in suggesting what needs to be addressed, but the lack of explicit grounding makes it 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the paper lacks discussion on the current limitations and challenges of HLOP and the experimental design, making it difficult to judge the tradeoffs between using HLOP versus other approaches. The reviewer suggests including a discussion on the potential downsides of HLOP and the limitations of the evaluation process. However, the comment does not provide specific examples or references to support these claims, making it difficult for the authors to understand and address the issues effectively. The lack of detailed reasoning or evidence makes the claim 3, as the authors would need to make an educated guess about the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of discussion on the current limitations and challenges of HLOP, as well as the experimental design. It suggests that the authors should include a discussion on the potential downsides of HLOP and the limitations of the evaluation process. This feedback is clear and actionable, providing the authors with specific areas to address in order to improve the comprehensiveness and depth of their work. By addressing these points, the authors can enhance the clarity and impact of their draft, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should evaluate the effectiveness of their proposed gating scheme on more recent language models, specifically FlanT5 and/or Llama, which have been released after GPT2. This feedback provides a clear and explicit action for the authors to take, which is to conduct additional evaluations on these models. The suggestion is concrete, as it specifies which models to consider and what aspect (the gating scheme\"s effectiveness) should be evaluated. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests evaluating the effectiveness of the proposed gating scheme on more recent language models, specifically FlanT5 and/or Llama, which have been released after GPT2. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the evaluation or results sections. The comment is specific in suggesting which models to consider and what aspect to evaluate, providing clear guidance on how to enhance the contribution of the work. Therefore, this comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the contribution of the work could be more prominent by evaluating the effectiveness of the proposed gating scheme on more recent language models, specifically FlanT5 and/or Llama, which have been released after GPT2. The comment provides a logical reasoning by suggesting that considering these models would enhance the study\"s relevance and impact. However, it lacks specific references or detailed examples of how these models could be evaluated, which would strengthen the claim. Therefore, the comment is 3, as it provides a reasonable suggestion but requires more detailed justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment suggests that the contribution of the work could be more prominent by evaluating the effectiveness of the proposed gating scheme on more recent language models, specifically FlanT5 and/or Llama, which have been released after GPT2. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their study by considering additional models. By suggesting this evaluation, the comment offers a concrete way to strengthen the paper\"s contribution and relevance. However, it could be more helpful if it included specific examples or guidance on how to conduct this evaluation. Overall, the comment is 4 as it directs the authors to a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should cite and compare their work with more recent studies that might be highly correlated, specifically mentioning a work by Wang et al. from CVPR 2020. While the comment implies that the authors should include this reference and discuss its similarities with their proposed method, it does not provide explicit guidance on how to integrate this comparison into the paper. The action is implicit and somewhat vague, as the authors need to infer that they should include this reference and discuss its similarities. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests citing and comparing the proposed method with more recent works, specifically mentioning a work by Wang et al. from CVPR 2020. However, it does not specify which part of the paper this comparison should be made in, leaving the authors to infer that it relates to the methodology or results sections. The comment is specific in suggesting a particular work to compare with, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should cite and compare their work with more recent studies, specifically mentioning a work by Wang et al. from CVPR 2020. This claim is 3 as it provides a specific example of a recent work that might be relevant. However, the comment lacks detailed reasoning or explanation of why this particular work is relevant or how it could impact the proposed method. The mention of \"Differential Treatment for Stuff and Things\" provides a starting point, but without further elaboration, the authors may find it challenging to understand the full context of the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should cite and compare their work with more recent studies that might be highly correlated, specifically mentioning a work by Wang et al. from CVPR 2020. This feedback is 3 as it identifies a potential area for improvement by highlighting the need for comparison with recent works. However, the comment lacks specificity in terms of how this comparison should be integrated into the paper or what aspects of the comparison are important. Without detailed guidance, the authors may find it challenging to effectively incorporate this suggestion into their draft. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should provide more detail about how UNKs are handled by the neural decoder or include a citation to the dictionarybased replacement strategy being used. While the comment explicitly states the need for additional detail and suggests a specific action (adding a citation), it does not provide concrete guidance on how to implement this suggestion or what specific aspects of the handling of UNKs should be elaborated upon. The action is explicit but lacks detailed instructions, making it 3.", "grounding_specificity_rationale": "The comment suggests adding more detail about how UNKs are handled by the neural decoder or including a citation to the dictionarybased replacement strategy. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where this information is discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting what needs to be added, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should provide more detail about how UNKs are handled by the neural decoder or include a citation to the dictionarybased replacement strategy. However, the comment does not provide specific examples, detailed reasoning, or references to support why this information is necessary or how it would improve the paper. Without such evidence, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improvement by recommending that the authors add more detail about how UNKs are handled by the neural decoder or include a citation to the dictionarybased replacement strategy being used. This feedback is clear and directly points out an area where the paper could be enhanced in terms of clarity and completeness. However, the comment could be more helpful if it provided additional context or examples of how to incorporate this information. Overall, the comment is 4 as it guides the authors toward a specific enhancement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should include comparisons with other stateoftheart (SOTA) code summarization methods, specifically mentioning the use of pretrained models. While the comment implies that these comparisons should be added to the experiments, it does not explicitly instruct the authors to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include these comparisons and may not be entirely sure how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests comparing the current method with other stateoftheart (SOTA) code summarization methods, specifically mentioning the use of pretrained models. However, it does not specify which part of the paper this comparison should be made in, such as in the experimental results or methodology sections. This lack of explicit reference makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in suggesting a comparison with other SOTA methods, but without grounding, it is not fully actionable. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors should compare their method with other stateoftheart (SOTA) code summarization methods, specifically mentioning the use of pretrained models. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate why this comparison is necessary or how it would benefit the paper. Without additional context or justification, the claim remains 1, as it lacks the necessary details to guide the authors in making an informed decision. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors should include comparisons with other stateoftheart (SOTA) code summarization methods, specifically mentioning the use of pretrained models. This feedback is 3 as it identifies a potential area for improvement in the experimental section, which could enhance the paper\"s comprehensiveness and robustness. However, the comment lacks depth and does not provide specific guidance on how to implement these comparisons or what aspects of the comparisons should be emphasized. To be more helpful, the comment could suggest particular metrics or methods to consider for the comparisons. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions regarding the results presented in Table 3. It asks for an explanation of why AttendOut has lower variance and for the statistical significance value when comparing Scheduled Bernoulli and AttendOut. While the questions are clear and specific, they do not provide explicit instructions on how the authors should address these issues. The authors can infer that they need to provide additional analysis or clarification, but the comment lacks concrete guidance on how to implement this. Therefore, the comment is 3, as it identifies areas for improvement but does not provide detailed instructions on execution.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two questions: \"What is the reason that AttendOut has lower variance?\" and \"What is the statistical significance value when comparing Scheduled Bernoulli and AttendOut?\" These questions provide clear guidance on what needs to be addressed in the table. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the results presented in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions regarding the results presented in Table 3. It asks for an explanation of why AttendOut has lower variance and for the statistical significance value when comparing Scheduled Bernoulli and AttendOut. These questions are clear and provide the authors with actionable feedback on areas that need further clarification or analysis. However, the comment does not offer suggestions on how to address these issues or provide guidance on what kind of analysis might be useful. While it identifies important areas for improvement, it lacks depth and specificity in its suggestions, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point highlights a potential issue with the use of confidence and accuracy for one sample in Equation (Eq.). However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment lacks specificity regarding what aspect of the confidence and accuracy is problematic or how it should be revised. Without concrete instructions or examples, the authors are left without a clear understanding of what changes are needed to improve their draft. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment refers to \"Eq.,\" which implies a specific part of the paper, making it fully grounded. It also specifies the issue by mentioning the difference between confidence and accuracy for one sample, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the difference between confidence and accuracy for one sample is not reasonable when used in Eq. However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the use of confidence and accuracy for one sample in Equation (Eq.), suggesting that the difference between these two metrics is not reasonable. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their approach. Without actionable feedback or specific recommendations, the authors are left without a clear path to enhance their work. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the method\"s ability to account for shifts between a sample and the data distribution. It suggests that the current approach may fail in such scenarios and asks if there is a way to adapt the method to address this issue. While the comment implies that the authors should consider this limitation and explore potential solutions, it does not provide explicit guidance on how to implement this adaptation. The action is implicit and somewhat vague, as the authors need to infer that they should address the issue of sample distribution shifts and potentially explore methods to mitigate this problem. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific issue related to the calculation of divergence between a sample and the data, suggesting that the current approach may fail when the sample is shifted from the data distribution. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in detailing the potential failure of the approach and questioning the possibility of adapting the method to account for such shifts. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the method\"s ability to account for shifts between a sample and the data distribution. It questions the validity of the current approach and suggests that it may fail in such scenarios. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the methodology, specifically the assumption that the divergence between a sample and the data is calculated by considering the residual. It raises a concern about the method\"s applicability when the sample is shifted from the data distribution. While the comment highlights an important consideration, it does not provide specific suggestions or guidance on how the authors might address this issue or improve their methodology. The feedback is 3 as it prompts the authors to reconsider their approach, but it lacks depth and actionable advice, making it less comprehensive. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a question about whether the replacement of words is independent of context and suggests that replacing the whole phrase might be better to avoid incoherent text. While the comment implies that the authors should consider replacing entire phrases rather than individual words, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors need to determine the exact steps to take. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (076079) in the paper, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning whether the replacement of words is independent of context and suggests that replacing the whole phrase might be better to avoid incoherent text. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the context of word replacement and suggests that replacing individual words might lead to incoherent text. The reviewer provides a logical reasoning by questioning the independence of word replacement from context and suggests a better approach of replacing entire phrases. However, the comment lacks specific examples or references to support the claim that replacing individual words could create incoherent text. This makes the claim 3, as it provides a logical basis but requires more detailed evidence or examples to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a specific question about the context of word replacement and suggests that replacing individual words might lead to incoherent text. It provides a logical reasoning by questioning the independence of word replacement from context and offers a constructive suggestion to replace entire phrases instead. This feedback is clear and actionable, as it guides the authors to consider a more coherent approach to word replacement, potentially improving the clarity and coherence of their text. However, the comment could be more helpful if it included examples or further elaboration on the potential issues with replacing individual words. Overall, the comment is 4, as it provides valuable insight and a direction for improvement, but it could be more comprehensive with additional details."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include a runtime comparison of different deep learningbased methods. This is an explicit action, as it clearly states what the authors should do to improve their draft. However, it lacks concrete details on how to conduct this comparison or what specific aspects should be included. While the action is clear, the lack of detailed guidance makes it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests including a runtime comparison of different deep learningbased methods, but it does not specify which part of the paper this should be included in. Without explicit references to sections, figures, or tables, the authors cannot confidently determine where this addition should be made. Additionally, the comment lacks specificity regarding what aspects of the runtime comparison should be included or how it would benefit the paper. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests including a runtime comparison of different deep learningbased methods, but it does not provide any supporting evidence, reasoning, or examples to justify why this comparison is desirable or how it would benefit the paper. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the rationale behind the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests including a runtime comparison of different deep learningbased methods, which is a specific and actionable suggestion for improving the paper. By providing a clear direction for enhancing the draft, the comment offers valuable guidance to the authors on how to strengthen their work. However, the comment could be more helpful if it included additional context or explanation on why this comparison is important or how it would benefit the paper. Despite this, the feedback is 4 as it directs the authors toward a meaningful enhancement of their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the ECG encoder in the MEIT framework could be improved by incorporating more advanced architectures, such as those using SSL or transformerbased methods. It implies that the authors should compare and explore these architectures, similar to how they were approached for the other parts of the framework. While the comment provides a clear direction for improvement, it lacks specific guidance on which architectures to consider or how to implement the comparison. The action is explicit but somewhat vague, as it does not provide detailed instructions on execution. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"MEIT framework\" and the specific components within it, namely the \"ECG encoder,\" \"modality alignment,\" and \"LLM backbone.\" This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it highlights the limitation of the ECG encoder, which only uses several 1D CNN layers and average pooling, and suggests that more advanced architectures, such as those using SSL or transformerbased methods, could be explored. The authors are advised to compare and explore these architectures, similar to how they were approached for the other parts of the framework. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ECG encoder in the MEIT framework could be improved by incorporating more advanced architectures, such as those using SSL or transformerbased methods. The reviewer suggests that these architectures should be compared and explored, similar to how they were approached for the other parts of the framework. This claim is 3 as it provides a logical reasoning for the suggestion, indicating that the current ECG encoder is limited and that more advanced architectures could offer significant improvements. However, the comment lacks specific references or examples of these advanced architectures, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific limitation in the ECG encoder of the MEIT framework, noting that it only uses simple 1D CNN layers and average pooling. It suggests that more advanced architectures, such as those using SSL or transformerbased methods, could significantly improve the current ECG encoder. The comment provides a clear direction for improvement by recommending the exploration and comparison of these advanced architectures, similar to how they were approached for the other parts of the framework. This feedback is actionable and offers a concrete path for the authors to enhance their work, making it 4. However, it could be more helpful if it provided specific examples of these advanced architectures or more detailed guidance on how to implement the comparison. Therefore, the comment is rated as 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to rephrase the abstract to reflect the correct focus on a modelagnostic explainability technique for deep neural networks, rather than suggesting a defense methodology. This feedback provides a clear and direct action for the authors to take, ensuring they know exactly what needs to be done to correct the abstract. The comment is specific and actionable, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the abstract, which inaccurately suggests a defense methodology is proposed, while the paper actually presents a modelagnostic explainability technique. The comment provides a clear and actionable suggestion to rephrase the abstract to reflect the correct focus on explainability. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the abstract inaccurately suggests a defense methodology is proposed, while the paper actually presents a modelagnostic explainability technique for deep neural networks. The comment provides a clear and direct correction, specifying the issue and suggesting a rephrasing of the abstract. This makes the claim 5, as it is based on a straightforward observation and a clear suggestion for improvement. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment is 5 as it identifies a specific issue with the abstract, which inaccurately suggests a defense methodology is proposed, while the paper actually presents a modelagnostic explainability technique. The comment provides a clear and actionable suggestion to rephrase the abstract to reflect the correct focus on explainability. This feedback is precise and directly addresses a potential source of confusion for readers, helping the authors improve the clarity and accuracy of their paper. Therefore, the comment is rated as 5, consistent with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a gap in the paper\"s comparisons, specifically mentioning the lack of comparisons to recent methods like FINER, Incode, and SL2AINR, which propose new or adaptive activation functions for INRs. While the comment identifies a specific area for improvement, it does not provide explicit guidance on how the authors should address this gap or what specific comparisons should be made. The action is implicit and somewhat vague, as the authors need to infer that they should include comparisons with these recent methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper lacks comparisons to recent methods like FINER, Incode, and SL2AINR, which propose new or adaptive activation functions for INRs. However, it does not specify which part of the paper should include these comparisons, making it weakly grounded. The comment is specific in identifying the need for comparisons to recent methods, but without explicit references to sections or figures, the authors may struggle to pinpoint where to make these comparisons. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks comparisons to recent methods like FINER, Incode, and SL2AINR, which propose new or adaptive activation functions for INRs. However, the comment does not provide specific references or detailed reasoning to support why these recent methods are relevant or how they could impact the paper\"s comparisons. The lack of explicit evidence or examples makes it difficult for the authors to understand the basis of the claim and address it effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a gap in the paper\"s comparisons, specifically pointing out the lack of comparisons to recent methods like FINER, Incode, and SL2AINR, which propose new or adaptive activation functions for INRs. This feedback is valuable as it highlights an area where the paper could be strengthened by expanding its comparative analysis. However, the comment could be more helpful if it provided specific suggestions on how to incorporate these recent methods into the analysis or discussed the potential impact of these methods on the paper\"s findings. While it points out a relevant area for improvement, the feedback could be more actionable and detailed to be fully helpful. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the evaluation setting can be improved, implying that the authors should consider enhancing their evaluation framework. However, it does not provide specific guidance on how to improve the evaluation setting or what aspects should be considered. The comment lacks explicit instructions or concrete details on how to implement the suggested improvement, leaving the authors uncertain about the exact actions to take. As a result, the comment is vague and 1.", "grounding_specificity_rationale": "The comment suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, implying that the evaluation setting can be improved. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or experiments. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting that the evaluation setting can be improved, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that a straightforward method works well in practice and challenges the value of research on length extrapolation. However, it does not provide specific examples or detailed reasoning to support this claim. The comment lacks evidence or references to substantiate the assertion that the evaluation setting can be improved. As a result, the claim is 1 due to the absence of supporting details or examples, making it difficult for the authors to understand and address the feedback effectively.", "helpfulness_rationale": "The review comment suggests that a straightforward method works well in practice and challenges the value of research on length extrapolation, implying that the evaluation setting can be improved. While it identifies a potential issue with the evaluation framework, it lacks specific guidance or suggestions on how to enhance it. The comment provides a general direction for improvement but does not offer detailed feedback or actionable steps for the authors to follow. This limits its helpfulness, as the authors may struggle to understand the exact areas needing attention. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly asks the authors to clarify which environment is used for training and which are used for testing in Section 2.4. It also suggests that the authors should consider performing a crossvalidation test to demonstrate the robustness of their results. This feedback provides clear and direct instructions on what needs to be clarified and how to improve the draft. The comment is specific and actionable, giving the authors a clear path to follow in addressing the issue. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 2.4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the clarification of which environment is used for training and testing, and suggests performing a crossvalidation test to demonstrate the robustness of the results. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the methodology of training and testing the autoencoder, specifically asking which environment is used for training and which are used for testing. It suggests that the authors should consider performing a crossvalidation test to demonstrate the robustness of their results. While the comment raises a valid concern about the experimental setup, it lacks specific examples or references to support the claim that a crossvalidation test would demonstrate robustness. The suggestion is logical but could be more robust with additional evidence or references. Therefore, the comment is 3, as it provides a reasonable suggestion but lacks detailed justification.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with the methodology section, particularly regarding the training and testing of the autoencoder. It questions which environment is used for training and testing and suggests that the authors should consider performing a crossvalidation test to demonstrate the robustness of their results. This feedback is clear and actionable, providing the authors with a concrete step to improve the clarity and rigor of their methodology. However, the comment could be more helpful if it included specific examples or guidance on how to conduct the crossvalidation test. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out the lack of a comparison to demonstrate how refinement during inference improves generation quality. It suggests that while the statistic of the number of refinements is noted, it only approves the change without showing an improvement. The comment implies that the authors should include a comparison to effectively demonstrate the benefits of their approach. However, it does not provide specific guidance on how to conduct this comparison or what kind of comparison would be most effective. The action is implicit and somewhat vague, as the authors need to infer that they should include a comparison, but they are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of a comparison to demonstrate the improvement in generation quality due to refinement during inference. It mentions the statistic of the number of refinements, indicating that this alone does not demonstrate an improvement. However, the comment does not specify which part of the paper this issue pertains to, such as specific sections or figures where comparisons are typically made. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in suggesting the need for a comparison to demonstrate improvement, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks a comparison to demonstrate the improvement in generation quality due to refinement during inference. It suggests that while the statistic of the number of refinements is noted, it only approves the change without showing an improvement. The comment implies that a comparison is necessary to substantiate the claim of improvement. However, the comment does not provide specific examples or detailed reasoning to support the need for such a comparison, making it 3. The authors would need to infer the necessity of a comparison but would benefit from more detailed guidance on how to conduct it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of a comparison to demonstrate how refinement during inference improves generation quality. It acknowledges the statistic of the number of refinements but notes that this only approves the change without showing an improvement. The comment suggests that including a comparison would be beneficial for the authors to effectively demonstrate the benefits of their approach. However, it does not provide specific guidance on how to conduct this comparison or what kind of comparison would be most effective. While the feedback highlights an important aspect of the paper, it lacks detailed suggestions for improvement, making it 3. The authors would need to infer the need for a comparison but would benefit from more actionable advice to fully address the comment. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises two questions: one about the \"PMI\" and the mention of a \"threshold?\" and another about whether the partitions were done randomly. While the questions imply that the authors should clarify these aspects, they do not provide explicit instructions or concrete guidance on how to address them. The actions are implicit and vague, leaving the authors with a general idea of what needs to be clarified but without specific steps to take. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (336 and 371) in the paper, allowing the authors to accurately identify the parts being addressed. It also specifies the issues, such as the mention of \"PMI\" and the question about whether the partitions were done randomly, providing clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two questions: one about the \"PMI\" and the mention of a \"threshold?\" and another about whether the partitions were done randomly. These are questions seeking clarification rather than claims or opinions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions: one about the mention of \"PMI\" and the potential absence of a threshold, and another about whether the partitions were done randomly. While these questions point out areas that need clarification, they do not provide actionable feedback or suggestions for improvement. The comment lacks depth and does not guide the authors on how to address these issues or what changes might be necessary. As a result, the feedback is 2, as it identifies potential areas for clarification but does not offer a clear path for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the time required for the MDP and suggests comparing the training time with that of ImageNet pretraining plus individual dataset finetuning. While the question implies that the authors should provide this comparison, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include a time comparison. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the time required for the MDP and suggests comparing it with the training time of ImageNet pretraining plus individual dataset finetuning. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the training time is discussed. This makes it weakly grounded, as the authors cannot confidently determine the exact part of the paper being addressed. The comment is specific in its request for a time comparison, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of a question asking for a comparison of training times between MDP and ImageNet pretraining plus individual dataset finetuning. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the time required for the MDP and suggests comparing it with the training time of ImageNet pretraining plus individual dataset finetuning. While it identifies a potential area for clarification, it does not provide specific guidance or suggestions on how the authors might address this issue. The comment is 3 as it prompts the authors to consider an important aspect of their work, but it lacks depth and actionable advice, making it less comprehensive. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a lack of significant performance improvement of the proposed method compared to Jiang et al. It provides specific metrics, such as penetration(Dep) and CR, where the proposed method only marginally outperforms Jiang et al. However, it does not offer any explicit or implicit suggestions for improvement or actions the authors should take to address this issue. The comment lacks guidance on how the authors might enhance their method or what specific aspects need to be improved. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides specific metrics and comparisons between the proposed method and Jiang et al., allowing the authors to identify the exact parts of the paper being addressed. It mentions specific performance metrics such as penetration(Dep), CR, and SimDisp(Mean), which helps in pinpointing the areas where the proposed method underperforms. However, the comment does not specify what needs to be addressed or improved in these areas, such as suggesting potential modifications or additional experiments to enhance performance. Therefore, the comment is weakly grounded because it identifies the parts of the paper being addressed, but it is not specific in detailing what needs to be addressed. This aligns with a score of 3.", "verifiability_rationale": "The review point claims that the proposed method does not significantly outperform Jiang et al. It provides specific metrics, such as penetration(Dep), CR, and SimDisp(Mean), where the proposed method either barely or does not outperform Jiang et al. This level of detail supports the claim with concrete data, making it 4. However, the comment could be strengthened by providing additional context or explanation on why these specific metrics are relevant or how they impact the overall performance comparison. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment provides specific metrics and comparisons between the proposed method and Jiang et al., highlighting areas where the proposed method does not significantly outperform Jiang et al. It mentions specific performance metrics such as penetration(Dep), CR, and SimDisp(Mean), which allows the authors to identify the exact areas where the proposed method underperforms. However, the comment lacks actionable suggestions or guidance on how the authors might address these performance gaps or improve their method. While it identifies a weakness, it does not offer constructive feedback or recommendations for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point provides explicit guidance by identifying specific references that should be included in the paper, such as \"vFSAD\" and \"CODiT,\" and suggests that these should be compared or mentioned. It also points out that the related work subtitles are not descriptive and seem unrelated to the content. This feedback is clear and actionable, as it directs the authors to specific areas for improvement and provides concrete suggestions for enhancing the paper\"s organization and content. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific references, \"vFSAD\" and \"CODiT,\" which allows the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the related work subtitles, noting that they are not descriptive and seem unrelated to the content. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the term \"vFSAD\" refers to OOD detection in timeseries data and suggests that a large quantity of work has not been compared or mentioned. The reviewer provides an example, \"CODiT: Conformal OutofDistribution Detection in TimeSeries Data,\" to support this claim. However, the comment lacks detailed reasoning or references to other works that should be compared or mentioned. Additionally, the second part of the comment points out that the related work subtitles are not descriptive, but it does not provide specific examples or suggestions for improvement. Overall, the claims are 3 due to the lack of comprehensive evidence and detailed reasoning, making it a 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by identifying a potential issue with the term \"vFSAD\" and suggesting that a large quantity of work in OOD detection for timeseries data has not been compared or mentioned. It references a specific example, \"CODiT,\" to support this claim, which adds depth to the feedback. Additionally, the comment points out that the related work subtitles for \"Policy\" and \"Evaluation tasks\" are not descriptive and seem unrelated to the content, offering a clear suggestion for improvement. This feedback is 4 as it highlights areas for enhancement and provides specific examples and suggestions for the authors to consider. However, it could be more helpful if it offered additional guidance on how to address the issue of missing comparisons or how to improve the clarity of the subtitles. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that an ablation study should be added to clarify the effect of memory size, which is currently ambiguous. This feedback provides a clear and explicit action for the authors to take, namely to include an ablation study. The comment also specifies what needs to be done\u2014conducting the study\u2014to make the action concrete. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment suggests adding an ablation study to clarify the effect of memory size, which is currently ambiguous. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its suggestion to include an ablation study, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an ablation study should be added to clarify the effect of memory size, which is currently ambiguous. However, the comment does not provide any supporting evidence, reasoning, or references to justify why an ablation study is necessary or how it would clarify the issue. Without this additional information, the claim remains 1, as it lacks the necessary details to support the suggestion effectively. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the effect of memory size is ambiguous. It suggests that an ablation study should be added to clarify the memory size selection, which is a clear and actionable recommendation. This feedback provides the authors with a concrete step to improve the clarity and robustness of their work. However, the comment could be more helpful if it offered additional guidance on how to design or execute the ablation study. Despite this, the suggestion is valuable and actionable, making the comment 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point highlights an inconsistency in the use of the abbreviation GNN, noting that it is mentioned at the end of page 1 but its full definition is only provided much later in Section 2, at the end of page 2. This feedback implies that the authors should clarify the abbreviation earlier in the paper to avoid confusion. The action is explicit, as it clearly states what needs to be done\u2014providing the full definition of GNN earlier. However, it lacks concrete guidance on where exactly to place the definition or how to integrate it into the existing text. Therefore, the comment is 3, as it identifies a specific issue but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the abbreviation \"GNN\" and its placement in the paper, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the inconsistency in the use of the abbreviation \"GNN\" and the lack of its full definition early in the paper. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a factual observation about the placement of the abbreviation \"GNN\" in the paper. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely descriptive, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the abbreviation \"GNN\" is mentioned at the end of page 1 but its full definition is only provided much later in Section 2, at the end of page 2. This feedback highlights a potential inconsistency in the paper\"s terminology, which could lead to confusion for readers who are not familiar with the abbreviation. While the comment points out a clear issue, it does not provide specific guidance on how the authors might address this problem, such as suggesting where to place the full definition or how to integrate it into the text. The feedback is 3 as it directs the authors\" attention to a potential area for improvement, but it lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a concern about the performance of baseline methods on the DAVIS dataset, noting that it is lower than stateoftheart results. It also suggests that the effectiveness of the proposed loss function on these baseline methods does not necessarily translate to topperforming ones. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their results. The feedback lacks actionable details, such as recommending specific modifications or experiments to enhance performance. As a result, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Davis dataset\" and provides a specific example of a baseline method with a low performance score, comparing it to stateoftheart results. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it highlights a particular issue with the performance of baseline methods and suggests that the effectiveness of the proposed loss function on these methods does not guarantee effectiveness on topperforming ones. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of baseline methods on the DAVIS dataset is low compared to stateoftheart results, specifically mentioning a 65.6% J mean on 2019val by 1. The reviewer supports this claim by referencing a specific baseline method and its performance, providing a clear basis for the assertion. However, the comment does not elaborate on why this performance is considered low or how it impacts the proposed loss function. While the reference to the baseline method is helpful, the lack of additional context or explanation makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the performance of baseline methods on the DAVIS dataset, noting that it is lower than stateoftheart results. It provides a concrete example of a baseline method with a performance score of 65.6% J mean on 2019val, as referenced in 1. This feedback is valuable as it highlights a potential weakness in the paper\"s evaluation and suggests that the proposed loss function may not be as effective as intended. However, the comment could be more helpful if it offered suggestions on how the authors might address this issue or improve the performance of their methods. Overall, the comment is 3 as it points out a specific area for improvement but lacks detailed guidance on how to achieve that improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the reporting of results for the proposed twostep decoding method. It specifically asks whether the results in Table 1 with decoder downsampling are obtained using or without the twostep method. If the results are without the twostep method, the reviewer also inquires about the performance difference. While the comment implies that the authors should clarify this information, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the results and possibly provide additional information. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 1 with decoder downsampling,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely, whether the results in Table 1 are obtained with or without the twostep decoding method and how much worse the twostep method performs if it is not used. This provides clear guidance on what information is missing and what needs to be clarified. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the reporting of results for the proposed twostep decoding method, specifically asking whether the results in Table 1 with decoder downsampling are obtained with or without the twostep method. This is a direct inquiry seeking clarification, not an opinion or claim that requires verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the reporting of results for the proposed twostep decoding method. It asks whether the results in Table 1 with decoder downsampling are obtained with or without the twostep method and, if without, how much worse the twostep method performs. This feedback is clear and actionable, as it prompts the authors to clarify the presentation of their results, ensuring that the methodology and results are accurately described. By addressing this question, the authors can improve the clarity and comprehensiveness of their paper. However, the comment could be more helpful if it provided additional guidance on how to present the results or what specific aspects should be clarified. Overall, the comment is 4, as it effectively directs the authors to a critical area for improvement."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to increase the font size in the figures to improve readability. This is a direct and clear action, providing the authors with a specific and actionable step to take. The comment is explicit and concrete, leaving no ambiguity about what needs to be done. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the figures,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the font size being too small, and provides a concrete action to take, which is to increase the font size. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the font size in the figures is too small and suggests increasing it to improve readability. However, it does not provide any supporting evidence, reasoning, or examples to justify why the current font size is problematic or how increasing it would specifically improve readability. Without additional context or explanation, the claim lacks verifiability, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the figures, noting that the font size is too small, which can hinder readability. It provides a clear and actionable suggestion to increase the font size to improve the figures\" clarity. This feedback is direct and offers a straightforward way for the authors to enhance the presentation of their work. However, the comment could be more helpful if it included additional suggestions, such as recommending a specific font size or explaining how increasing the font size might affect other aspects of the figures. Despite this, the comment is 4 as it directs the authors to a clear and actionable step to improve their draft. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that only synthetic problems are considered in the experiments, implying that the authors should include more diverse or realworld problems to enhance the paper\"s scope and applicability. However, the comment does not explicitly instruct the authors to do so or provide specific guidance on which problems to include or how to expand the experiments. The action is implicit and somewhat vague, as the authors need to infer that they should consider additional problem types but lack concrete steps on how to implement this change. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests that only synthetic problems are considered in the experiments, indicating a potential limitation in the scope of the study. However, it does not specify which part of the paper this observation pertains to, such as the methodology or results sections. Without explicit references to sections or figures, the authors cannot confidently determine where this feedback is relevant. While the comment is specific in identifying a potential issue, it lacks grounding as it does not point to a specific part of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that only synthetic problems are considered in the experiments, implying a potential limitation in the scope of the study. However, the comment lacks specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment points out a potential limitation in the experimental setup, noting that only synthetic problems are considered. This is a relevant observation that could impact the generalizability and applicability of the study. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this limitation, such as including realworld problems or expanding the scope of the experiments. While it identifies an area for improvement, the feedback is incomplete and could be more helpful with additional details or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should compare their explainer with other NLE interpretability tools. This is a clear and direct action for the authors to take, providing them with a specific task to address. The comment is concrete because it outlines exactly what needs to be done\u2014comparing with other NLE tools. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the authors should compare their explainer with other NLE interpretability tools, implying that they should include NLE baselines in their comparison. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or figure where these comparisons are made. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in suggesting what needs to be addressed, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point suggests that the authors should compare their explainer with other NLE interpretability tools, implying that their current comparison is insufficient. However, the comment does not provide specific examples of other NLE tools or detailed reasoning for why such a comparison is necessary. This lack of detailed justification or references makes the claim 3, as the authors would need to infer the necessity of the comparison and identify the specific tools to include. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by suggesting that the authors should include comparisons with other NLE (Natural Language Explanations) interpretability tools. This feedback is clear and actionable, as it provides a direct suggestion for enhancing the comprehensiveness of the evaluation. By recommending the inclusion of additional comparisons, the comment helps the authors expand the scope of their analysis and potentially strengthen their findings. However, the comment could be more helpful if it provided examples of relevant NLE tools or explained why these comparisons are particularly important. Overall, the comment is 4 as it directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a specific issue with Eq. (5), noting that it only uses one pertinent positive data point and lacks an exhaustive test over the diversity of all data points that satisfy Eq. (1) and Eq. (2). The reviewer suggests that the authors should include a more comprehensive test to address this concern. While the comment identifies a clear area for improvement, it does not provide specific guidance on how to conduct this exhaustive test or what aspects should be emphasized. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Eq. (5),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the use of only one data point in Eq. (5) and suggests that an exhaustive test over the diversity of all data points should be included. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Eq. (5) only uses one pertinent positive data point, while there are many data points that satisfy Eq. (1) and Eq. (2). The reviewer suggests that these data points contribute equally to Eq. (3) but have different perturbation directions, and Eq. (5) lacks an exhaustive test over the diversity of all these data points. While the comment identifies a potential issue with the comprehensiveness of the analysis, it lacks specific examples or references to support the claim. The reasoning is logical but could be strengthened with more detailed evidence or examples to fully substantiate the claim. Therefore, the comment is 3, aligning with a score of 3.", "helpfulness_rationale": "The review comment identifies a specific issue with Eq. (5), noting that it only uses one pertinent positive data point, while there are many data points that satisfy Eq. (1) and Eq. (2). The reviewer points out that these data points contribute equally to Eq. (3) but have different perturbation directions, and Eq. (5) lacks an exhaustive test over the diversity of all these data points. This feedback is clear and actionable, as it highlights a potential weakness in the analysis and suggests that the authors should conduct a more comprehensive test to address this issue. By providing specific guidance on what needs to be improved, the comment empowers the authors to enhance the robustness and comprehensiveness of their work. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should compare their results with an existing supervised retriever, given that they already have training signals and trained retrievers that can be used outofthebox for other domains. It implies that the authors should demonstrate how document augmentation can enhance the performance of the final retriever model, regardless of whether it is done with augmented queries, documents, or both. While the comment suggests an action, it does not provide specific guidance on how to implement this comparison or what specific aspects to focus on. The action is implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the results section, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing the document augmentation approach with an existing supervised retriever, highlighting the potential benefits of using augmented queries or documents to enhance performance. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point suggests that the results should be compared with an existing supervised retriever, given that the authors have already used training signals and trained retrievers. The comment implies that the current comparison is incomplete and suggests a more comprehensive evaluation. However, it lacks specific examples or references to support the claim that the current comparison is insufficient. The suggestion to demonstrate the additional performance boost from document augmentation is logical but lacks detailed justification or evidence, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by suggesting a comparison of the results with an existing supervised retriever. This is a valuable insight as it highlights a potential gap in the current analysis, where the authors have already utilized training signals and trained retrievers. The comment also prompts the authors to consider how document augmentation can enhance the performance of the final retriever model, regardless of whether it is done with augmented queries, documents, or both. This feedback is 4 as it offers a specific direction for the authors to enhance their draft by expanding the scope of their comparison and analysis. However, it could be more helpful if it provided examples or detailed guidance on how to implement this comparison. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the cache hierarchy is not discussed, specifically mentioning the order of the three dimensions and how they might share data. It notes that while the individual levels are discussed in terms of their construction and details, there is no discussion on how they are applied together, which contradicts the initial claim of a hierarchy. The comment implies that the authors should address this gap in their discussion. However, it does not provide specific guidance on how to incorporate this information or what aspects of the cache hierarchy should be discussed. The action is implicit and somewhat vague, as the authors know they need to address the issue but are not given detailed instructions on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"cache hierarchy\" and the \"order in which the three dimensions are applied,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what is missing in the discussion, namely the details on how the three dimensions are applied together and how they might share data. The comment highlights a contradiction in the initial claim about the hierarchy, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the cache hierarchy is not discussed, specifically mentioning the order of the three dimensions and how they might share data. It notes that while individual levels are discussed in terms of their construction and details, there is no discussion on how they are applied together, which contradicts the initial hierarchy claim. The comment provides logical reasoning by pointing out the lack of discussion on the application of the cache hierarchy, making the claim 4. However, it could be strengthened by providing specific examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out that the cache hierarchy is not discussed, specifically mentioning the order of the three dimensions and how they might share data. It notes that while individual levels are discussed in terms of their construction and details, there is no discussion on how they are applied together, which contradicts the initial claim of a hierarchy. This feedback is clear and actionable, as it directs the authors to address a critical aspect of their work that is not adequately covered. However, the comment could be more helpful if it provided specific suggestions on how to incorporate this discussion or examples of how to apply the cache hierarchy. Overall, the comment is 4, as it effectively highlights an important area for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the number of forward passes required before a backward pass and how the authors managed their GPU memory to prevent an outofmemory (OOM) issue during pretraining. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to provide more details on their memory management strategy. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 2,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the number of forward passes required before a backward pass and how the authors managed their GPU memory to prevent an OOM issue during pretraining. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of a question asking for clarification about the number of forward passes and memory management during pretraining. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the number of forward passes required before a backward pass and how the authors managed their GPU memory to prevent an OOM issue during pretraining. This feedback is clear and actionable, as it prompts the authors to provide more detailed information about their memory management strategy. By addressing this question, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it offered suggestions on how to manage GPU memory or provided examples of strategies that could be used. Overall, the comment is 4 as it identifies a specific area for improvement and encourages the authors to provide more detailed information."}
{"actionability_label": "5", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the Abstract is not well written and that it is difficult to understand the contributions. It recommends rewriting the Abstract to better present the contributions. This feedback provides a clear and direct action for the authors to take, specifying what needs to be improved and how to do so. The comment is specific and actionable, giving the authors a concrete direction for enhancing their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that the Abstract is not well written and difficult to understand, recommending a rewrite to better present the contributions. However, it does not specify which part of the Abstract is problematic or provide details on what aspects need improvement. Without explicit references to specific sections or elements of the Abstract, the authors cannot confidently determine which parts need revision. The lack of specificity and grounding makes it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the Abstract is not well written and difficult to understand, suggesting that it should be rewritten to better present the contributions. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue effectively. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the Abstract, noting that it is not well written and difficult to understand the contributions. It provides a clear and actionable suggestion to rewrite the Abstract to better present the contributions. This feedback is valuable as it guides the authors on how to improve the clarity and effectiveness of their abstract, which is crucial for conveying the essence of their work to readers. However, the comment could be more helpful if it offered specific suggestions on how to rephrase the abstract or what aspects to focus on. Overall, the comment is 4 as it directs the authors toward a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the dataset ADE, which is used for Image parsing, may be biased across different scenes and could favor the performance of the proposed method. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this potential bias or what steps they should consider to mitigate it. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft in response to this feedback. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"ADE,\" which is a dataset for Image parsing, and mentions that it may be biased across different scenes and could favor the performance of the proposed method. However, it does not specify which part of the paper discusses ADE or where the bias is discussed, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific about the potential bias, it lacks grounding as it does not provide clear guidance on where this issue is discussed in the paper. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the dataset ADE, used for Image parsing, may be biased across different scenes and could favor the performance of the proposed method. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the dataset ADE, which is used for Image parsing. It suggests that the dataset may be biased across different scenes and could favor the performance of the proposed method. While this observation is relevant, the comment lacks depth and does not provide specific guidance or suggestions on how the authors might address this potential bias. Without actionable feedback or detailed reasoning, the authors are left with a general idea of the problem but without clear steps to improve their draft. Therefore, the comment is 3, as it identifies an area for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the use of two matrices to represent each relation (edge type) in section 2.1.2. It suggests that the two matrices might be the same and asks for an explanation. Additionally, it points out that many matrices are not used in the following text. While the comment implies that the authors should clarify the use of these matrices, it does not provide specific guidance on how to address the issue or what changes should be made. The action is implicit and somewhat vague, as the authors need to infer that they should explain the use of two matrices and identify unused matrices. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 2.1.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the use of two matrices to represent each relation (edge type) and suggests that many matrices are not used in the following text. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of two matrices to represent each relation (edge type) in section 2.1.2, suggesting that the two matrices might be the same. It also points out that many matrices are not used in the following text. While the comment raises a valid concern, it lacks specific examples or detailed reasoning to support the claim that the two matrices are the same or why their use is necessary. The comment does not provide sufficient evidence or explanation to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment raises a question about the use of two matrices to represent each relation (edge type) in section 2.1.2, suggesting that the two matrices might be the same. It also points out that many matrices are not used in the following text. While the comment identifies a potential inconsistency in the representation, it lacks specific guidance or suggestions on how the authors might address this issue or clarify the use of matrices. The feedback is 3 as it prompts the authors to reconsider their approach, but it could be more actionable with additional details or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the meaning of a specific statement in the paper, \"the semantics of the upsampled feature map can be stronger than the original one.\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this confusion or clarify the statement. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"the end of Section 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of understanding regarding the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This provides the authors with a clear direction on what needs to be clarified or addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding a statement in the paper, specifically asking for an explanation of what is meant by \"the semantics of the upsampled feature map can be stronger than the original one.\" It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment identifies a specific point of confusion in the paper, namely the statement \"the semantics of the upsampled feature map can be stronger than the original one.\" This is a clear and actionable piece of feedback that highlights a potential area of misunderstanding in the paper. By pointing out this confusion, the reviewer provides the authors with a direct way to improve the clarity and understanding of their work. However, the comment could be more helpful if it offered suggestions on how to clarify or address this point, such as by providing additional context or examples. Overall, the comment is 4 as it directs the authors to a specific area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors clarify the differences between their method and other methods used to predict user personality, such as the one referenced in the provided citation. While the comment implies that the authors should provide a comparison, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to determine the exact nature of the clarification needed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment suggests clarifying the differences between the current method and other methods used to predict user\"s personality, such as the one referenced in the provided citation. However, it does not specify which part of the paper this clarification should be made in, making it weakly grounded. The comment is specific in suggesting the need for clarification and references a specific work, providing some guidance on what might be missing. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors clarify the differences between their method and other methods used to predict user\"s personality, such as the one referenced in the provided citation. However, the comment does not provide any specific reasoning or evidence to support why this clarification is necessary or how it would benefit the paper. The lack of detailed justification or examples makes it difficult for the authors to understand the importance of this suggestion. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors clarify the differences between their method and other methods used to predict user\"s personality, such as the one referenced in the provided citation. This feedback is 3 as it points out a potential area for improvement in terms of comparative analysis. However, the comment lacks specificity and does not provide detailed guidance on how to address this issue or what aspects of the comparison should be clarified. Without more detailed suggestions or examples, the authors may find it challenging to effectively incorporate this feedback into their draft. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises questions about the theoretical justification for LoRA tuning and suggests that the authors should provide a more detailed explanation. It also points out a potential issue with the step size tuning in the experiments. However, the comment does not offer explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The feedback is somewhat vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses specific aspects of LoRA tuning, such as the theoretical justification for imposing B as the basis and A as the coordinate, and the impact of step size tuning. However, it does not explicitly mention which part of the paper these points are discussed in, making it weakly grounded. The comment is specific in detailing the theoretical and practical concerns regarding LoRA tuning, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the theoretical justification for LoRA tuning and suggests that the authors should provide a more detailed explanation. It also points out a potential issue with step size tuning in the experiments. However, the comment lacks specific examples, references, or detailed reasoning to support the claims about the theoretical justification and the impact of step size tuning. This makes the claims 3, as the authors would need to further develop the reasoning to fully understand and address the issues. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises several important points that could enhance the paper\"s theoretical and practical understanding. It questions the theoretical justification for LoRA tuning, specifically regarding why imposing B as the basis and A as the coordinate accelerates convergence. The reviewer also points out a potential issue with step size tuning in the experiments, suggesting that while a constant step size is theoretically sufficient, practical experiments may still require tuning. These points provide valuable insights into areas where the paper could be strengthened, particularly in terms of theoretical justification and practical considerations. However, the comment could be more helpful if it offered specific suggestions or examples for addressing these issues. Overall, the feedback is 3 as it identifies important areas for improvement but lacks detailed guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should conduct more ablation studies or analyses on problems other than the shortest path problem to better support their claims. While the comment implies that the authors should perform additional experiments, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as it lacks specific guidance on which other problems to analyze or how to conduct the ablation studies. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting more ablation studies or analysis on problems other than the shortest path problem, implying that the authors should explore additional experimental environments. However, it does not specify which other problems should be considered or how this would impact the paper\"s conclusions. The authors might infer that they need to expand their analysis beyond the shortest path problem, but the comment lacks specific guidance on what to include or how to conduct the additional analysis. Therefore, the comment is weakly grounded because it does not clearly identify the part of the paper being addressed, and it is not specific because it does not provide detailed guidance on what needs to be done. This aligns with a score of 2.", "verifiability_rationale": "The review point suggests that the experimental environments are closely related to the shortest path problem, and the design of PathGNN aligns with this bias. The reviewer recommends conducting more ablation studies or analysis on problems other than the shortest path problem to strengthen the paper\"s claims. However, the comment lacks specific examples or references to support the claim that the current experimental setup is insufficient or biased. Without detailed reasoning or evidence, the claim remains somewhat vague, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment identifies a potential limitation in the experimental design, noting that most experimental environments are closely related to the shortest path problem. It suggests that the design of PathGNN, which aligns with the BellmanFord algorithm, may introduce a bias towards this type of problem. The comment recommends conducting more ablation studies or analysis on problems other than the shortest path problem to strengthen the paper\"s claims. This feedback is clear and actionable, as it provides a specific direction for the authors to enhance their experimental design and analysis. However, it could be more helpful if it included suggestions on which specific problems to consider or how to conduct the ablation studies. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper should include more recent models, particularly in multilingual settings or other languages beyond English, to provide a more comprehensive comparison. While the comment implies that the authors should consider adding these models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include more recent models and determine which specific models to add. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper should include more recent models, particularly in multilingual settings or other languages beyond English, to provide a more comprehensive comparison. However, it does not specify which part of the paper this suggestion pertains to, such as specific sections or comparisons. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of more recent models, but it lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper should include more recent models, particularly in multilingual settings or other languages beyond English, to provide a more comprehensive comparison. However, the comment lacks specific examples or references to recent models that could be included, making it difficult for the authors to understand the basis of the suggestion or how to address it. The claim is 3 due to the lack of detailed justification or examples, but it provides a direction for improvement. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper should include more recent models, particularly in multilingual settings or other languages beyond English, to provide a more comprehensive comparison. This feedback is 3 as it identifies a potential area for improvement, encouraging the authors to consider a broader range of models in their analysis. However, the comment lacks specific examples or references to recent models that could be included, which would make it more actionable. Overall, the comment provides a direction for improvement but could be more comprehensive with additional guidance. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the lack of visualization of the learned context token, which could help in understanding the differences between context tokens of different groups. It also points out that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. However, the comment does not provide explicit guidance on how to address these issues or what specific visualizations or analyses should be included. The authors are left to infer that they need to add visualizations and analysis, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the lack of visualization of the learned context token, which is a specific aspect of the paper. It also mentions the simplicity and effectiveness of the paper, but notes the limited novelty and absence of analysis for the approach. However, the comment does not specify which part of the paper discusses the context token or where the analysis should be added. This makes it weakly grounded, as the authors cannot confidently determine the exact sections being addressed. The comment is specific in identifying the need for visualization and analysis, but without clear grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. However, it does not provide specific examples or detailed reasoning to support these claims. The comment lacks evidence or references to substantiate the assertion about the novelty or the absence of analysis, making it difficult for the authors to understand and address the feedback effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out the lack of visualization of the learned context token, which could help in understanding the differences between context tokens of different groups. It also notes that the paper is simple and effective but lacks novelty and analysis for the insight of the approach. While the comment highlights important aspects that need attention, it does not provide specific suggestions or guidance on how to address these issues. The authors are left to infer that they need to include visualizations and analysis, but without concrete steps, the feedback remains 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the experimental section, noting that the results show only small benefits over the baseline model. The reviewer suggests that the paper would be stronger if it reported results for other models beyond MetaOptNet, which would emphasize the generality of the method and demonstrate its improvement over multiple baseline models. While the comment implies that the authors should include results for other models, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional models and determine which specific models to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"experimental section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the current results, noting that they show only small benefits over the baseline model. The comment further provides a suggestion for improvement by recommending the inclusion of results for other models beyond MetaOptNet, which would emphasize the generality of the method and demonstrate its improvement over multiple baseline models. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the experimental results, noting that they show only small benefits over the baseline model. The reviewer suggests that reporting results for other models beyond MetaOptNet would strengthen the paper by emphasizing the generality of the method and demonstrating its improvement over multiple baseline models. While the comment identifies a potential weakness in the experimental results, it lacks specific examples or references to other models that could be considered. This makes the claim 3, as the authors would need to further explore and justify the suggestion themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific concern regarding the experimental section, noting that the results show only small benefits over the baseline model. It suggests that the paper would be stronger if it reported results for other models beyond MetaOptNet, which would emphasize the generality of the method and demonstrate its improvement over multiple baseline models. This feedback is clear and actionable, as it provides a concrete suggestion for enhancing the paper\"s strength and relevance. However, the comment could be more helpful if it included specific examples of other models that could be considered or discussed in detail. Overall, the comment is 4, as it guides the authors toward a meaningful improvement in their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the paper could benefit from a more extensive comparison by including wellestablished methods such as FTML and LFW. This feedback provides a clear and explicit action for the authors to take, which is to expand their comparison to include these methods. The comment is specific in its suggestion, detailing which methods should be included and why they are relevant. This level of detail gives the authors a concrete understanding of how to enhance their draft, making the comment 5.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a more extensive comparison by including wellestablished methods such as FTML and LFW. However, it does not specify which part of the paper should be expanded or where these comparisons should be integrated. The authors can infer that it relates to the section discussing the proposed method and its comparisons, but this inference is not direct. The comment is specific in suggesting the inclusion of specific methods, but it lacks grounding as it does not explicitly mention the section or part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from a more extensive comparison by including wellestablished methods such as FTML and LFW. However, the comment does not provide specific reasoning or evidence to support why these methods are particularly relevant or how they would enhance the evaluation of the proposed method. The lack of detailed justification or examples makes it difficult for the authors to understand the basis of the claim and how it applies to their work. Therefore, the comment is considered 2, as it provides a suggestion but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment identifies a limitation in the paper\"s comparison section, noting that while the authors have compared their work with recent baselines, it could benefit from a more extensive comparison with wellestablished methods such as FTML and LFW. This feedback is clear and actionable, as it provides a specific suggestion for improving the paper\"s evaluation by expanding the comparison scope. By recommending the inclusion of these methods, the comment offers a concrete way for the authors to enhance the comprehensiveness and robustness of their evaluation. However, the comment could be more helpful if it provided additional context or rationale for why these specific methods are particularly relevant. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the focus of the paper on modeling the task using CRF should be downgraded due to the superior performance of hierarchical transformers (HiTRF). It also points out that location embeddings provide additional information on the main dataset but not on the dataset in Appendix D, suggesting that they may be useful only for specific types of datasets. However, the comment does not provide explicit guidance on how the authors should adjust their focus or incorporate the findings about location embeddings. The action is implicit and somewhat vague, as the authors are left to infer the necessary changes without clear instructions. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the performance of CRF variants compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset discussed in Appendix D. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific, as it details the issue of underperformance and suggests downgrading the focus on CRF modeling. Additionally, it points out the lack of discussion on the utility of location embeddings for specific datasets, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed CRF variants underperform compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset in Appendix D. This claim is supported by the mention of the datasets and the observation of underperformance, providing a logical basis for the assertion. However, the comment does not provide specific examples or detailed analysis to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is 4, as it provides a reasonable basis for the claim but lacks comprehensive evidence.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the proposed CRF variants underperform compared to hierarchical transformers (HiTRF) on both the main dataset and the dataset in Appendix D. This observation suggests that the focus of the paper on modeling the task using CRF should be downgraded. Additionally, the comment points out that location embeddings provide additional information on the main dataset but not on the dataset in Appendix D, implying that their utility is limited to specific types of datasets. However, the comment does not provide specific suggestions or guidance on how the authors might address these issues or improve their draft. While it highlights important areas for improvement, the feedback could be more actionable with additional details or recommendations. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a lack of clarity regarding the impact of trainingtesting inconsistency. However, it does not provide any explicit or implicit actions for the authors to take to address this issue. There is no guidance on how the authors might explore or clarify this impact, nor are there suggestions for potential improvements or additional analyses that could be conducted. Without any actionable steps or specific advice, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding the impact of trainingtesting inconsistency, but it does not specify which part of the paper this issue is discussed in. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where this issue is addressed. Additionally, the comment lacks specificity in detailing what aspects of the trainingtesting inconsistency are unclear or how they could be clarified. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"it\"s not clear what\"s the impact of the trainingtesting inconsistency.\" However, it does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a lack of clarity regarding the impact of trainingtesting inconsistency, which is a critical issue in evaluating the robustness of experimental results. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their analysis. Without actionable feedback or detailed advice, the authors are left without a clear path forward to enhance their draft. Therefore, the comment is 2, as it highlights a potential weakness but lacks depth and direction for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights that the condition for y membership is unclear due to the disjoint nature of the sets S, as defined above. It also mentions that some claims are not backed up, specifically pointing out the line after Equation (1). However, the comment does not provide explicit guidance on how the authors should clarify these points or address the lack of support for their claims. The action is implicit and vague, as the authors are left to infer that they need to clarify the condition for y membership and provide more support for their claims. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line after Eq.,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out that the condition for y membership is unclear due to the disjoint nature of the sets S, as defined above. Additionally, it highlights that some claims are not backed up, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the condition for y membership is unclear due to the disjoint nature of the sets S, as defined above. However, the comment does not provide any specific reasoning or examples to support this claim, making it difficult for the authors to understand the basis of the concern. Additionally, it mentions that some claims are not backed up but does not specify which claims or provide evidence for this. As a result, the comment is considered 1 due to the lack of detailed justification or examples.", "helpfulness_rationale": "The review comment identifies a specific issue with the clarity of the condition for y membership, noting that the sets S are disjoint as defined above. It also points out that some claims are not supported, specifically mentioning the line after Equation (1). While the comment highlights areas that need clarification, it lacks detailed guidance or suggestions on how the authors might address these issues or improve the clarity of their claims. The feedback is 3 as it points out areas for improvement, but it could be more actionable with specific advice or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that certain key references are not compared and explained, indicating a gap in the paper. However, it does not specify which references are missing or how they should be compared and explained. The action is implicit, as the authors need to infer that they should include comparisons and explanations for these references. Additionally, the comment lacks concrete guidance on how to implement this change, such as suggesting specific comparisons or providing examples of how to explain the references. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to address it.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely that certain key references are not compared and explained. However, it does not specify which references are missing or how they should be compared and explained, making it difficult for the authors to pinpoint the exact parts of the paper that need revision. The lack of specific references or detailed guidance on what needs to be addressed makes the comment weakly grounded. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that certain key references are not compared and explained, indicating a gap in the paper. However, the comment does not provide specific references or examples of what is missing or how it should be addressed. Without detailed evidence or reasoning, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that certain key references are not compared and explained. This feedback highlights a gap in the paper\"s comprehensiveness and provides a clear direction for improvement by suggesting that the authors should include comparisons and explanations for these references. However, the comment lacks specific examples or guidance on which references are missing or how they should be addressed, which could make it more actionable. Overall, the comment is 3 as it points out a critical area for improvement but does not provide detailed instructions for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a concern about the analysis of SCL in section 5.2 regarding fewshot ability. It points out that the results in Figure 7(c) and (d) do not meet expectations, suggesting that COCOLM achieves more improvements with fewer labels, and these improvements diminish with more labels. The comment also suggests that the authors may check if COCOLM benefits sentence retrieval tasks with learned anisotropy text representations. While the comment identifies specific areas of concern and provides a suggestion for further investigation, it does not explicitly instruct the authors to make these changes or provide detailed guidance on how to address the issue. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their analysis. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 5.2\" and \"Figure 7(c) and (d),\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue with the analysis of SCL in fewshot scenarios, pointing out that the results do not meet expectations and suggesting further investigation into the benefits of COCOLM for sentence retrieval tasks. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the analysis of SCL in section 5.2 regarding fewshot ability is not convincing, as the results in Figure 7(c) and (d) do not meet expectations. The reviewer provides specific examples of the results, such as COCOLM achieving more improvements with fewer labels, and suggests that the improvements diminish with more labels. This level of detail provides a clear basis for the claim, making it 4. However, the comment could be strengthened by referencing specific studies or providing more detailed analysis of the results. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue with the analysis of SCL in section 5.2 regarding fewshot ability. It points out that the results in Figure 7(c) and (d) do not meet expectations, suggesting that COCOLM achieves more improvements with fewer labels, and these improvements diminish with more labels. The comment also provides a suggestion for further investigation into the benefits of COCOLM for sentence retrieval tasks with learned anisotropy text representations. This feedback is clear and actionable, offering the authors a direction for improving their analysis and results. However, it could be more helpful if it provided additional guidance on how to conduct this further investigation or what specific aspects to focus on. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests conducting more experiments on other large language models (LLMs) to demonstrate the generalization of the proposed framework. While the action is explicit, it lacks concrete details on which specific LLMs should be tested or how the experiments should be designed. The authors know that they need to expand their experiments, but the comment does not provide specific guidance on how to achieve this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests conducting more experiments on other large language models (LLMs) to demonstrate the generalization of the proposed framework. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or figure where additional experiments should be included. This lack of specificity makes it difficult for the authors to pinpoint where to make the necessary changes. Additionally, the comment does not provide detailed guidance on which LLMs to test or how to design these experiments, further limiting its specificity. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests conducting more experiments on other large language models (LLMs) to demonstrate the generalization of the proposed framework. However, it does not provide any supporting evidence, reasoning, or references to justify why this suggestion is necessary or beneficial. The lack of detailed explanation or examples makes it difficult for the authors to understand the rationale behind the recommendation. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests conducting more experiments on other large language models (LLMs) to demonstrate the generalization of the proposed framework. While this is a relevant and actionable suggestion, it lacks specific guidance on which LLMs to test or how to design these experiments. The comment provides a direction for improvement but does not offer detailed instructions or examples, which limits its helpfulness. Therefore, the comment is 3, as it identifies an area for enhancement but does not fully support the authors in making those improvements."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors need to clarify what constitutes short and long video to decide the downsample layers. It also recommends seeing an appleapple comparison of SOTA VLM/VideoLLM outputs for the qualitative examples added. While the comment provides a clear action for the authors to take\u2014clarifying the distinction between short and long videos and conducting a comparison\u2014it does not specify how to implement this clarification or comparison. The action is explicit but lacks concrete guidance on execution, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Line 223,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a need for clarity on what constitutes short and long video to decide the downsample layers. Additionally, it recommends seeing an appleapple comparison of SOTA VLM/VideoLLM outputs for the qualitative examples added, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two parts: a request for clarification on what constitutes short and long video to decide the downsample layers, and a suggestion to see an appleapple comparison of SOTA VLM/VideoLLM outputs for qualitative examples. The first part is a request for clarification, which does not contain a claim. The second part is a suggestion for further analysis, which also does not constitute a claim. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment provides two specific suggestions for improvement. First, it requests clarification on what constitutes short and long video to decide the downsample layers, which is a clear and actionable request for the authors to address. Second, it suggests seeing an appleapple comparison of SOTA VLM/VideoLLM outputs for the qualitative examples added, offering a concrete way to enhance the analysis and provide a more comprehensive understanding of the results. These suggestions are clear and actionable, providing the authors with specific directions to improve their draft. However, the comment could be more helpful if it included additional context or explanation on why these suggestions are important. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly for scenes with a high number of objects or complex interactions. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this limitation or improve the efficiency of their method. Without specific suggestions or steps, the authors are left without a clear understanding of what changes are needed to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper related to the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. However, it does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying a potential limitation in terms of efficiency, which provides clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that generating multiple objects takes longer, depending on the number of objects, indicating a potential limitation in efficiency. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 2, as it provides some indication of a problem but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper regarding the efficiency of generating multiple objects, particularly in scenes with a high number of objects or complex interactions. This feedback is 3 as it highlights a critical area that the authors need to address to improve the efficiency of their method. However, the comment lacks specific suggestions or guidance on how the authors might mitigate this issue or improve the efficiency of their approach. Without actionable advice or detailed examples, the authors are left with a general understanding of the problem but without clear steps to resolve it. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the technical contribution of the paper is thin and recommends the authors to focus on finding additional applications and deeply evaluating the approach. It implies that the authors should explore the approach\"s properties to enhance the manuscript\"s value. While the comment provides a general direction for improvement, it lacks specific guidance on how to identify additional applications or evaluate the approach. The action is implicit and somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the technical contribution is thin and recommends focusing on finding additional applications and evaluating the approach. However, it does not specify which part of the paper discusses the algorithm or the interpolative decomposition, making it difficult for the authors to pinpoint the exact section that needs revision. While the comment provides a general direction for improvement, it lacks specific guidance on what aspects should be emphasized or explored. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that the technical contribution is thin, suggesting that the algorithm may be considered incremental due to the use of interpolative decomposition, which is not proposed by the paper. The reviewer recommends focusing on finding additional applications and evaluating the approach to enhance the manuscript\"s value. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to support the assertion that the algorithm is incremental or to illustrate how additional applications could be found. This makes the claim 3, as the authors would need to further develop the reasoning to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s technical contribution, suggesting that the algorithm may be considered incremental due to the use of interpolative decomposition, which is not proposed by the paper. It provides a constructive suggestion for improvement by recommending that the authors focus on finding additional applications and deeply evaluating the approach. This feedback is clear and actionable, offering a specific direction for the authors to enhance the manuscript\"s value. However, it could be more helpful if it provided examples of potential applications or suggested methods for evaluating the approach. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly asks for clarification on which neural network library was used for implementing the system, noting the absence of details on the implementation. This is a direct and clear request for information, providing the authors with a specific action to take. The comment is explicit and concrete, as it clearly identifies what information is missing and what the authors need to provide. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly asks for clarification on the neural network library used for implementing the system, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what information is missing\u2014details on the implementation. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the neural network library used for implementing the system. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific gap in the paper by pointing out the lack of information regarding the neural network library used for implementing the system. This is a clear and actionable piece of feedback that can help the authors improve the transparency and reproducibility of their work. By specifying what information is missing, the comment guides the authors on what additional details they need to include in their manuscript. However, while it effectively highlights a critical area for improvement, it could be more helpful if it suggested potential sources or considerations for selecting a neural network library. Overall, the comment is 4 as it provides a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that some descriptions are unclear, specifically mentioning undefined math notations and missing details in figure illustrations. However, it does not provide explicit guidance on how the authors should clarify these issues or suggest specific changes to make the descriptions clearer. The feedback is somewhat vague, as it identifies areas needing improvement but lacks concrete instructions on how to address them. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights specific issues with the clarity of descriptions, mentioning undefined math notations and missing details in figure illustrations. However, it does not specify which sections or figures are affected, making it weakly grounded. The comment is specific in detailing what needs to be clarified, such as undefined math notations and missing details in figure illustrations. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that some descriptions are unclear, specifically mentioning undefined math notations and missing details in figure illustrations. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate these claims. Without additional context or explanation, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the clarity of descriptions is lacking, such as undefined math notations and missing details in figure illustrations. This feedback is 3 as it highlights particular weaknesses that the authors need to address. However, it lacks depth and does not provide actionable suggestions or guidance on how to improve these aspects. The comment could be more helpful if it offered specific examples or detailed advice on how to clarify the descriptions. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors mention the meaning of the notation \nu in the text, in addition to its explanation in Algorithm 1. This is a clear and direct action for the authors to take, providing them with a concrete step to improve their draft. The suggestion is specific and leaves no ambiguity about what needs to be done, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is mentioning the meaning of the notation \nu in the text. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the explanation of the notation \nu in Algorithm 1 should also be mentioned in the text. This is a request for clarification and does not contain any subjective claims or opinions that require verification. It is purely a suggestion for improvement, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the explanation of the notation \nu in Algorithm 1 is not mentioned in the text. This is a clear and actionable suggestion that would help the authors ensure that all notations are consistently explained throughout the paper. By addressing this feedback, the authors can improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it provided additional guidance on how to effectively integrate the notation explanation into the text. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the performance of noise robust loss on pseudolabels compared to positive learning from Eq 9. It suggests that the model might be underfit due to the accuracy of pseudolabels, which could benefit from positive learning. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their draft. The action is implicit and vague, as it leaves the authors to infer that they need to explore or explain the relationship between pseudolabels and model performance. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"appendix A.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the performance of noise robust loss on pseudolabels compared to positive learning from Eq 9, and explores the possibility of underfitting due to the accuracy of pseudolabels. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the performance of noise robust loss on pseudolabels compared to positive learning from Eq 9. It suggests that the model might be underfit due to the accuracy of pseudolabels. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the performance of noise robust loss on pseudolabels compared to positive learning from Eq 9. It suggests that the model might be underfit due to the accuracy of pseudolabels, which could benefit from positive learning. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve their draft. While it identifies a potential area for exploration, the feedback lacks actionable advice, making it 3. The authors would need to infer the need for further investigation or explanation, which limits the utility of the comment. Therefore, it is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a concern about the claim made in the paper regarding the impact of an extra exponentiation on runtime. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this concern or what specific changes could be made to clarify or refute the claim. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L248,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the claim about the impact of an extra exponentiation on runtime, providing a clear direction for the authors to address the concern. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a question about the claim made in the paper regarding the impact of an extra exponentiation on runtime. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks detailed justification or examples to help the authors understand the basis of the concern. As a result, the claim is 1, making it difficult for the authors to address the issue effectively. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the claim made in the paper regarding the impact of an extra exponentiation on runtime. It questions the validity of the claim, suggesting that the increase in runtime might not be as significant as implied. However, the comment does not provide specific guidance or suggestions on how the authors might address this concern or clarify the claim. Without actionable feedback or detailed reasoning, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the lack of comparison with stateoftheart (SOTA) methods, suggesting that the experiments are insufficient. However, it does not provide explicit guidance on how the authors should address this issue. The comment implies that the authors should include comparisons with SOTA methods, but it does not specify which methods to include or how to structure these comparisons. The action is implicit and somewhat vague, as the authors need to infer the need for additional comparisons and determine the specifics of how to implement them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the introduction and abstract, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the lack of comparison with stateoftheart (SOTA) methods and suggests that the experiments are insufficient. The comment provides a clear request for comparison with these methods, which helps the authors understand what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experiments are lacking in comparison with stateoftheart (SOTA) methods. However, the comment does not provide specific examples or references to support this claim, nor does it explain why the comparison is important or how it would enhance the paper. Without detailed justification or evidence, the claim remains 1, making it difficult for the authors to understand and address the issue. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, specifically the lack of comparison with stateoftheart (SOTA) methods. It points out that the experiments are insufficient and suggests that the authors should include comparisons with these methods to strengthen their claims. However, the comment does not provide specific guidance on which SOTA methods to compare with or how to structure these comparisons. While it highlights an important area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it provides insight into a potential area for enhancement but lacks actionable details."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point notes that the proposed method enhances performance, but it is not surprising because it introduces more learnable parameters, including a temperature parameter, whose effectiveness has been proven in previous works. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this observation or incorporate the feedback into their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the experiments and the proposed method, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it highlights the observation that the enhancement in performance is not surprising due to the introduction of more learnable parameters, including the temperature parameter, whose effectiveness has been previously proven. This provides clear guidance on what aspect of the experiments needs further explanation or discussion. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the enhancement in performance is not surprising because the introduction of more learnable parameters, including the temperature parameter, has been proven effective in previous works. This claim is 3 as it references the effectiveness of the temperature parameter, which is a common element in machine learning models. However, the comment lacks specific references to previous works or detailed reasoning about why the temperature parameter is effective, which would strengthen the claim. Therefore, the comment is rated as 3, as it provides some justification but requires more detailed evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment points out that the experiments demonstrate the proposed method\"s enhanced performance, but it notes that this outcome is not surprising because the method introduces more learnable parameters, including a temperature parameter, whose effectiveness has been previously proven. While the comment highlights a potential redundancy or lack of novelty in the results, it does not provide specific suggestions or guidance on how the authors might address this observation or improve their draft. The feedback lacks actionable advice or constructive feedback, making it 3 as it identifies an area for potential improvement but does not fully support the authors in making those improvements. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, which makes the main work distracting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue or what changes could be made to make the main work less distracting. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making the main work distracting. However, it does not specify which part of the paper this observation pertains to, nor does it provide details on what aspects of the neuroscience research are considered simple or unnecessary. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making the main work distracting. However, the comment lacks specific examples or detailed reasoning to support this claim. Without concrete evidence or references to substantiate the assertion, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the inspiration from neuroscience research is simple and unnecessary to the main processing pipeline of the main work, making the main work distracting. While it identifies a potential issue with the paper, it lacks specificity and does not provide actionable feedback or suggestions on how the authors might address this concern. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly instructs the authors to update the caption of Table 3 to include information about the source dataset used. It also mentions that the image and table captions should contain all necessary information so that the reader does not have to search for this information in the main text. The comment provides clear and concrete actions for the authors to take, specifying exactly what needs to be added to the captions. This level of detail ensures that the authors know precisely how to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the addition of information about the source dataset in the caption. The comment further suggests that the image and table captions should contain all necessary information so that the reader does not have to search for it in the main text. This provides clear guidance on what needs to be improved, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the caption of Table 3 is unclear regarding the source dataset used. The reviewer suggests adding information about the source dataset in the caption and mentions that the image and table captions should contain all necessary information so that the reader does not have to search for it in the main text. While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to include information in the captions is logical, but without further explanation or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment is 4 as it identifies a specific issue with the clarity of information in Table 3, particularly regarding the source dataset used. It provides a clear and actionable suggestion to update the caption to include this information, ensuring that the reader does not have to search for it elsewhere in the paper. Additionally, the comment emphasizes the importance of comprehensive captions, which is a valuable piece of feedback. However, the comment could be more helpful if it offered further guidance on how to effectively present the information or suggested alternative ways to convey the necessary details. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that there is no explicit description of the specific architectures of value network, policy networks, and uncertainty aware networks used in the paper. This feedback provides a clear and direct action for the authors to take, which is to include detailed descriptions of these architectures. The comment is specific in its request, as it specifies exactly what information is missing and why it is important for readers to replicate and evaluate the approach. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of explicit descriptions of the specific architectures of value network, policy networks, and uncertainty aware networks used in the paper. This allows the authors to accurately identify the part of the paper being addressed. The comment is also specific because it clearly specifies what is missing\u2014explicit descriptions of these architectures\u2014and why this is important, as it makes it difficult for readers to replicate and evaluate the approach. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks explicit descriptions of the specific architectures of value network, policy networks, and uncertainty aware networks used. This is a subjective opinion that could be supported by providing examples or references to the absence of such descriptions in the paper. However, the comment does not offer specific examples or references to support the claim, making it 3. The authors would need to infer the lack of detail themselves, which limits the verifiability. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of explicit descriptions of the specific architectures of value network, policy networks, and uncertainty aware networks used. This is crucial information for readers to understand and replicate the approach described in the paper. By highlighting this omission, the comment provides clear and actionable feedback that can help the authors improve the clarity and comprehensibility of their work. However, the comment could be more helpful if it suggested ways to address this gap or provided examples of how to include such descriptions. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point discusses the relationship between explicitness (E) and size (S) in the context of a given dataset and suggests that the evaluation of disentanglement should consider capacity, training time, cost, and learning rate. However, it does not provide explicit instructions or concrete steps for the authors to take to address these considerations. The comment implies that the authors should evaluate these factors, but it lacks specific guidance on how to do so. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment discusses the relationship between explicitness (E) and size (S) in the context of a given dataset, suggesting that the evaluation of disentanglement should consider capacity, training time, cost, and learning rate. However, it does not specify which part of the paper this discussion pertains to, such as a particular section or paragraph. The authors might infer that it relates to the evaluation section, but this inference is not direct. The comment is specific in detailing what needs to be considered in the evaluation, but it lacks grounding as it does not explicitly mention the part of the paper being addressed. Therefore, this comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point discusses the relationship between explicitness (E) and size (S) in the context of a given dataset and suggests that the evaluation of disentanglement should consider capacity, training time, cost, and learning rate. However, the comment lacks specific examples or references to support the claim that these factors are related to the dataset or evaluation. The reasoning is somewhat vague, as it does not provide detailed evidence or examples to substantiate the claim. Therefore, the comment is categorized as 2, as it provides some reasoning but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment provides a detailed analysis of the relationship between explicitness (E) and size (S) in the context of a given dataset. It suggests that the evaluation of disentanglement should consider factors such as capacity, training time, cost, and learning rate, which may influence the final value of DCI. This feedback is clear and actionable, as it guides the authors to consider additional factors that could impact their evaluation. However, the comment could be more helpful if it provided specific examples or suggestions on how to incorporate these considerations into the evaluation process. Overall, the comment is 4, as it offers valuable insights and direction for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper title does not need to include abbreviations. This is a clear and direct action for the authors to take, as it provides a specific instruction on how to improve the title. The comment is concrete, as it gives precise guidance on what needs to be done, leaving no ambiguity for the authors to follow. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper title, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the need to remove abbreviations from the title. This provides clear guidance on what needs to be addressed. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the inclusion of abbreviations in the paper title. It does not contain any subjective opinions, judgments, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment is straightforward and provides a clear suggestion for improvement by stating that the paper title does not need to include abbreviations. This feedback is actionable and directly informs the authors of a specific change they can make to enhance the clarity and professionalism of their title. However, the comment could be more helpful if it offered additional guidance on how to revise the title or why abbreviations are unnecessary. Despite this, the comment is 4 as it directs the authors toward a concrete step to improve their draft."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises questions about the transferability of the discriminator to other tasks and domains without further training, suggesting that it can be effectively trained with very little data. It also mentions that the discriminator can be small at L400, which is an important insight. However, the comment does not provide explicit guidance or suggestions on how the authors should address these points or what specific actions they should take to improve their draft. The feedback is implicit and lacks concrete details, making it difficult for the authors to know how to apply the suggestions. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises questions about the transferability of the discriminator to other tasks and domains without further training, suggesting that it can be effectively trained with very little data. It also mentions that the discriminator can be small at L400, which is an important insight. However, the comment does not specify which part of the paper these questions or insights are related to, making it difficult for the authors to pinpoint the exact sections that need attention. While the authors might have an idea of where these points are discussed, the comment lacks full grounding. It is specific in its questioning and observation about the discriminator\"s properties, but without clear references, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises questions about the transferability of the discriminator to other tasks and domains without further training, suggesting that it can be effectively trained with very little data. It also mentions that the discriminator can be small at L400, which is an important insight. However, the comment lacks specific examples, references, or detailed reasoning to support these claims. The authors would need to infer the significance of these observations, making the claim 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment raises questions about the transferability of the discriminator to other tasks and domains without further training, suggesting that it can be effectively trained with very little data. It also mentions that the discriminator can be small at L400, which is an important insight. However, the comment lacks specific guidance or suggestions on how the authors might address these points or improve their draft. While it identifies potential areas for improvement, it does not provide actionable feedback or detailed advice, making it 3. The authors would need to infer the significance of these observations and determine how to incorporate them into their work, which limits the comment\"s usefulness. Therefore, the comment is rated as 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly instructs the authors to include the current SOTA GNNQE as a baseline and to compare it with the approach in question. This is a clear and direct action, providing the authors with a specific task to address. The comment is concrete, as it specifies exactly what needs to be done\u2014add the baseline and compare it. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"current SOTA GNNQE\" and the \"closest work in terms of components,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the omission of the current SOTA GNNQE from the baselines and the need to add and compare it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the current SOTA GNNQE is omitted from the baselines, despite being the closest work in terms of components to the approach. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or justification, the authors may find it challenging to understand the basis of this claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific omission in the paper, noting that the current SOTA GNNQE is not included in the baselines, despite being the closest work in terms of components to the approach. This is a clear and actionable suggestion that would help the authors improve their draft by ensuring that all relevant baselines are considered. By adding this baseline and comparing it, the authors can provide a more comprehensive evaluation of their approach. The feedback is specific and provides a direct path for improvement, making it 5 for the authors."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the use of pretraining data and its impact on GPT2\"s understanding of language. It suggests that if the pretraining data is used, it might not be sufficient for GPT2 to understand language, and if not used, the setting may be unreasonable. The reviewer acknowledges that the paper explores an interesting topic but emphasizes the importance of addressing these concerns to validate the findings. However, the comment does not provide explicit guidance or suggestions on how the authors might address these concerns, such as recommending specific analyses or experiments to clarify the issue. The action is implicit and somewhat vague, as the authors need to infer what steps to take to address the concerns. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses concerns about the use of pretraining data and its impact on GPT2\"s understanding of language. It raises a question about whether the pretraining data is sufficient for GPT2 to understand language and suggests that if not used, the setting might be unreasonable. The reviewer acknowledges that the paper explores an interesting topic but emphasizes the need to address these concerns to validate the findings. However, the comment does not specify which part of the paper discusses the use of pretraining data or where the concerns are raised, making it weakly grounded. The comment is specific in its critique of the pretraining data\"s impact on GPT2\"s understanding of language. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the use of pretraining data and its impact on GPT2\"s understanding of language. The reviewer questions whether the pretraining data is sufficient for GPT2 to understand language and suggests that if not used, the setting might be unreasonable, potentially leading to facts being learned in GPT2 before training. The comment acknowledges that the paper explores an interesting topic but emphasizes the importance of addressing these concerns to validate the findings. However, the comment lacks specific examples, references, or detailed reasoning to fully substantiate the claims, making it 3. The authors would need to further develop the argument to fully understand and address the concerns raised.", "helpfulness_rationale": "The review comment raises a valid concern about the use of pretraining data and its impact on GPT2\"s understanding of language. It questions whether the pretraining data is sufficient for GPT2 to understand language and suggests that if not used, the setting might be unreasonable, potentially leading to facts being learned in GPT2 before training. The reviewer acknowledges the paper\"s interesting topic but emphasizes the importance of addressing these concerns to validate the findings. While the comment identifies a critical issue, it lacks specific suggestions or guidance on how the authors might address these concerns or improve their draft. The feedback is 3 as it highlights an important area for improvement but does not provide actionable steps for the authors to take. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of thorough explanation for the proposed method, specifically mentioning missing computations and optimization algorithms, such as the calculation of $p(x_k|d)$. It suggests that if the idea is expressed using mathematical formulas, every term should be clearly explained, except for those that are extremely obvious. While the comment identifies specific areas that need clarification, it does not provide explicit instructions on how to address these issues or suggest specific ways to improve the explanation. The action is implicit and somewhat vague, as the authors need to infer that they should provide more detailed explanations for the missing computations and optimization algorithms. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the specific terms in equation (4), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details what is missing in the explanation, such as the computation of certain terms and the optimization algorithm, particularly the calculation of $p(x_k|d)$. This provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the proposed method is not thoroughly explained, specifically mentioning missing computations and optimization algorithms, such as the calculation of $p(x_k|d)$. The reviewer provides a specific example of a missing term, which supports the claim. However, the comment lacks broader context or references to similar issues in the field, which could strengthen the claim. While the specific example is helpful, the overall claim is 3 due to the need for more comprehensive evidence or references to fully substantiate the critique.", "helpfulness_rationale": "The review comment identifies a significant gap in the explanation of the proposed method, specifically pointing out missing computations and optimization algorithms, such as the calculation of $p(x_k|d)$. This feedback is clear and actionable, as it directs the authors to provide a more detailed explanation of these aspects to enhance the clarity and comprehensibility of their work. By addressing these specific areas, the authors can significantly improve the understanding and execution of their proposed method. However, the comment could be more helpful if it offered suggestions on how to present these details or examples of similar approaches in the literature. Overall, the comment is 4, as it provides a clear direction for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "5", "actionability_rationale": "The review comment explicitly identifies several areas where implementation details are missing, including the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It also notes that the lack of these details makes it difficult to reproduce the experimental results and assess the fairness of comparisons with existing methods. The comment provides a clear and direct action for the authors to take, which is to provide a thorough description of the implementation details. This feedback is specific and actionable, giving the authors a clear understanding of what needs to be addressed to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the need for implementation details for the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. This allows the authors to accurately identify the parts of the paper being addressed. The comment is also specific because it details the missing information and the challenges it poses to the reproducibility and fairness of the comparisons. It provides clear guidance on what needs to be addressed to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the experimental results are not reproducible due to the lack of implementation details for the RAMP algorithm, the algorithms compared with, and the discretization used in the state coverage metric. The reviewer also notes that the absence of these details makes it difficult to assess the fairness of comparisons with existing methods and the significance of the experimental results. This claim is supported by logical reasoning, as the lack of implementation details undermines the reproducibility and fairness of the comparisons. However, the comment could be strengthened by providing specific examples or references to the missing details. Overall, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies several critical areas where the paper lacks implementation details, including the RAMP algorithm, the algorithms compared with, the discretization used in the state coverage metric, and other aspects of the experiments. It highlights that the absence of these details makes the experimental results difficult to reproduce and limits the assessment of the fairness of comparisons with existing methods. This is a significant issue that could hinder the evaluation of the experimental results\" significance. The comment provides clear and actionable feedback by suggesting that a thorough description of the implementation details is needed to address these issues. This feedback is 5 as it guides the authors on what specific information is missing and how to improve the reproducibility and fairness of their comparisons. Therefore, the comment is rated as 5, aligning with a score of 5."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point discusses the concept of using a mixture of experts (MoE) for a task, noting that it is not unusual given its applications in various tasks. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address the critique or improve their draft. Without specific suggestions or recommendations, the authors are left without a clear understanding of what steps to take in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment discusses the concept of employing a mixture of experts (MoE) for a task, noting its application in various tasks such as general LLM, summarization, and machine translation. However, it does not specify which part of the paper this concept is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of the MoE concept is being critiqued or what improvements could be made. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the concept of employing a mixture of experts (MoE) is not unusual, given its extensive application in various tasks. However, it does not provide specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique. The lack of detailed justification or evidence weakens the verifiability of the claim, leaving the authors uncertain about the validity of the critique. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment acknowledges the novelty of using a mixture of experts (MoE) for text detection, noting that while the concept is not new, it is relatively new in this specific context. However, it does not provide any specific feedback or suggestions on how the authors might address this novelty or improve their draft. The comment lacks actionable guidance or constructive advice, leaving the authors without a clear path for enhancing their work. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of statistical analysis to support the claim of SpaceTGN\"s performance improvement over other baselines. While it identifies a gap in the paper, it does not explicitly instruct the authors to include such an analysis. The action is implicit, as the authors can infer that they need to add statistical analysis, but it is vague because it does not specify how to conduct the analysis or which statistical methods to use. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific claim made by the authors regarding the performance improvement of SpaceTGN over other baselines. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in identifying the need for a statistical analysis to support the claim of significance. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that \"SpaceTGN achieves significant performance improvement ... than other baselines,\" but it does not provide any statistical analysis or evidence to support this claim. The comment lacks specific examples, references, or detailed reasoning to substantiate the assertion, making it difficult for the authors to understand and address the claim. As a result, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific claim made by the authors regarding the performance improvement of SpaceTGN over other baselines, but it points out the absence of statistical analysis to support this claim. This feedback is valuable as it highlights a critical gap in the paper\"s evidence, prompting the authors to provide a more rigorous basis for their performance claims. However, the comment could be more helpful if it offered suggestions on how to conduct the statistical analysis or what specific statistical methods to use. Overall, the comment is 4 as it directs the authors\" attention to an important aspect of their work that needs further substantiation."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out a potential issue of confusion regarding why certain scores are excerpted versus reproduced. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. The comment lacks guidance on how the authors might clarify this point or what specific changes could be made to improve the clarity. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment highlights a potential issue of confusion regarding why certain scores are excerpted versus reproduced. However, it does not specify which part of the paper this issue is related to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity in detailing what needs to be clarified or how the authors might address the confusion. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a concern about potential confusion regarding why certain scores are excerpted versus reproduced. However, it does not provide any supporting evidence, reasoning, or examples to justify why this distinction is unclear or problematic. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment identifies a potential issue of confusion regarding why certain scores are excerpted versus reproduced. However, it lacks specificity and does not provide any suggestions or guidance on how the authors might address this confusion. Without actionable feedback or detailed examples, the authors are left without a clear understanding of what changes could be made to clarify the issue. As a result, the comment is 2, as it points out a potential problem but does not offer a comprehensive solution."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the method is not novel because it simply applies consistency models in place of other generative models. The reviewer implies that the authors should provide more insight into how consistency models achieve something that previous generative models cannot. However, the comment does not explicitly instruct the authors to address this issue or provide specific guidance on how to improve the novelty of their method. The action is implicit and somewhat vague, as the authors need to infer that they should expand on the novelty of their approach. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses a specific aspect of the paper, mentioning the use of consistency models and suggesting that the method lacks novelty. It implies that the authors should provide more insight into how consistency models achieve something that previous generative models cannot. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The comment is specific in its critique of the novelty of the method, but without explicit grounding, the authors may struggle to identify the exact part of the paper that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method lacks novelty because it simply applies consistency models in place of other generative models. The reviewer suggests that the authors should provide more insight into how consistency models achieve something that previous generative models cannot. However, the comment does not provide specific examples or references to support the claim that the method is not novel or innovative. This lack of detailed justification or evidence makes the claim 3, as the authors may find it challenging to fully understand and address the critique without additional context or examples. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper, suggesting that the method lacks novelty because it simply applies consistency models in place of other generative models. The reviewer provides a clear critique of the novelty of the method and suggests that the authors should comment more on how consistency models achieve something that previous generative models cannot. This feedback is 3 as it highlights an area for improvement and prompts the authors to provide more detailed explanations or evidence to support the novelty of their method. However, the comment could be more helpful if it offered specific suggestions or examples of how to enhance the novelty of the method. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the evaluation metric in Table 2 uses MSE, which may not accurately reflect the accuracy of nowcasting. However, it does not provide any explicit or implicit suggestions on how the authors should address this issue. There is no guidance on whether the authors should consider using a different metric, how to implement a new metric, or what specific changes should be made to the evaluation process. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly identifies the issue with the evaluation metric, stating that MSE cannot reflect the accuracy of nowcasting. This provides clear guidance on what needs to be addressed in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the evaluation metric in Table 2 uses MSE, which may not accurately reflect the accuracy of nowcasting. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the evaluation metric used in Table 2, noting that MSE may not accurately reflect the accuracy of nowcasting. This feedback is clear and actionable, as it highlights a potential flaw in the methodology and suggests that the authors consider using a different metric that better reflects the accuracy of nowcasting. By addressing this issue, the authors can improve the validity and reliability of their evaluation. However, the comment could be more helpful if it provided suggestions on alternative metrics or how to implement them. Overall, the feedback is 4 as it points out a critical area for improvement and provides a clear direction for the authors to follow."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly suggests that the authors should add specific components, namely \"CapCapNEClipNEEA\" and \"CapCapNEClipNENEEA,\" to the ablation study of ENGINE. It also recommends that the authors provide a more detailed analysis of the ablation results. These suggestions are clear and concrete, giving the authors a direct path to improve their draft by adding the required components and enhancing the analysis. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"ablation study of ENGINE,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be added, namely \"CapCapNEClipNEEA\" and \"CapCapNEClipNENEEA,\" and suggests that the authors should give more detailed analysis to the ablation results. This provides clear direction on how to enhance the study. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the ablation study of ENGINE is incomplete and suggests specific components to be added, namely \"CapCapNEClipNEEA\" and \"CapCapNEClipNENEEA,\" based on the overview model of ENGINE. However, the comment does not provide any supporting evidence, reasoning, or references to justify why these specific components should be added or why the current ablation study is incomplete. Without this additional information, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the ablation study of ENGINE, noting that it is incomplete. It provides clear and actionable suggestions for improvement by recommending the addition of specific components, namely \"CapCapNEClipNEEA\" and \"CapCapNEClipNENEEA,\" based on the overview model of ENGINE. Additionally, the comment suggests that the authors should provide a more detailed analysis of the ablation results. This feedback is clear, specific, and offers concrete steps for the authors to enhance their draft, making it 5 for improving the quality and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the mode coverage in GAN optimization between GDIM and DDGAN. It suggests that the authors should provide results on more challenging highresolution datasets like LSUN and ImageNet to support their findings. While the comment implies that the authors should conduct additional experiments, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include results on these datasets and understand how to implement this. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the mode coverage in GAN optimization between GDIM and DDGAN, suggesting that the authors should provide results on more challenging datasets like LSUN and ImageNet. While it does not explicitly mention a specific section of the paper, the authors can infer that it relates to the discussion of GAN optimization or results. The comment is specific in suggesting that the authors should include results on more challenging datasets, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a question about the mode coverage in GAN optimization between GDIM and DDGAN. It suggests that the authors should provide results on more challenging datasets like LSUN and ImageNet to support their findings. The comment is 3 as it points out a potential gap in the experimental validation, but it lacks specific examples or references to support the claim that methods tested on CIFAR10/Celeb64 might struggle with LSUN/ImageNet. This makes it difficult for the authors to fully understand and address the issue, thus aligning with a score of 3.", "helpfulness_rationale": "The review comment raises a question about the mode coverage in GAN optimization between GDIM and DDGAN, suggesting that the authors should provide results on more challenging datasets like LSUN and ImageNet to support their findings. This feedback is 3 as it identifies a potential gap in the experimental validation and provides a direction for the authors to enhance their work. However, the comment could be more helpful if it offered specific suggestions on how to conduct these experiments or what aspects of the results should be highlighted. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the meaning of each attribute in the table feature, specifically questioning what it represents. While the comment implies that the authors should clarify this point, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide an explanation for the attributes. However, the comment does not offer specific guidance on how to address the question, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 5.1\" and the specific line \"Each attribute of the table feature represents a scene,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what the comment is asking about, namely the meaning of each attribute in the table feature. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the meaning of each attribute in the table feature. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the meaning of each attribute in the table feature, specifically asking what it represents. While this is a valid point that could help clarify the paper, the comment does not provide any suggestions or guidance on how the authors might address this issue. It lacks actionable feedback or detailed insights, making it 2. The authors are left with a question that does not offer a clear path for improvement, thus aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises concerns about the absence of an ablation study comparing the impact of token reweighting with the logsumexp aggregation scheme. It suggests that the authors should provide evidence to show how much better the logsumexp aggregation is compared to direct addition, which would correspond to basic prototype comparison with reweighted averages. Additionally, the comment questions the compatibility of the token reweighting scheme with existing tokentotoken classifiers and the comparison of the logsumexp aggregator. While the comment identifies specific areas for improvement, it does not provide explicit instructions or detailed guidance on how to conduct the ablation study or compare the logsumexp aggregator. The actions are implicit and somewhat vague, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the absence of an ablation study comparing the impact of token reweighting with the logsumexp aggregation scheme. It specifically questions how much better the logsumexp aggregation is compared to direct addition, which would correspond to basic prototype comparison with reweighted averages. Additionally, it raises concerns about the compatibility of the token reweighting scheme with existing tokentotoken classifiers like CTX and FRN, and the comparison of the logsumexp aggregator. While the comment does not explicitly mention a specific section of the paper, the authors can infer that it relates to the methodology or results sections where these comparisons are typically discussed. The comment is specific in detailing what needs to be addressed, such as the absence of an ablation study and the need for comparisons. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point raises a claim about the absence of an ablation study comparing the impact of token reweighting with the logsumexp aggregation scheme. It questions the effectiveness of the logsumexp aggregation compared to direct addition and the compatibility of the token reweighting scheme with existing classifiers. While the comment provides a logical reasoning for the need for such a study, it lacks specific examples or references to support the claim. The authors would need to conduct further research or experimentation to fully address the feedback, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the absence of an ablation study comparing the impact of token reweighting with the logsumexp aggregation scheme. It raises a critical question about the effectiveness of the logsumexp aggregation compared to direct addition, which would correspond to basic prototype comparison with reweighted averages. Additionally, the comment questions the compatibility of the token reweighting scheme with existing tokentotoken classifiers like CTX and FRN, and it asks how the logsumexp aggregator compares. This feedback is valuable as it highlights areas where the paper could be strengthened by providing evidence and comparisons, which would help the authors improve their draft. However, the comment could be more helpful if it provided specific suggestions on how to conduct the ablation study or compare the logsumexp aggregator. Overall, the comment is 4 as it directs the authors to important aspects of their work that need further exploration and justification."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a limitation in the use of limited datasets to evaluate the effectiveness of ECGs and suggests considering largescale datasets mentioned in references 1 and 2. While the comment identifies a specific issue and provides references for further consideration, it does not explicitly instruct the authors to incorporate these datasets into their work. The action is implicit, as the authors can infer that they should include the suggested datasets, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the issue of using limited datasets to evaluate the effectiveness of ECGs and suggests considering largescale datasets mentioned in references 1 and 2. However, it does not specify which part of the paper discusses the evaluation of ECGs or where the datasets are used. This makes it weakly grounded, as the authors cannot confidently determine which sections or parts of the paper are being addressed. The comment is specific in suggesting the inclusion of largescale datasets, but without clear grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the use of limited datasets is insufficient to evaluate the effectiveness of ECGs and suggests considering largescale datasets from references 1 and 2. The comment provides specific references to support the claim, which adds credibility to the suggestion. However, the reasoning could be strengthened by explaining why the suggested datasets are more appropriate or how they would improve the evaluation. Overall, the claim is 4 due to the references provided, but it could be further supported with additional explanation. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a limitation in the use of limited datasets to evaluate the effectiveness of ECGs and suggests considering largescale datasets from specific references. This feedback is clear and actionable, as it provides the authors with a concrete direction to enhance their evaluation by incorporating more comprehensive datasets. However, the comment could be more helpful if it offered additional guidance on how to implement these changes or why the suggested datasets are particularly relevant. Despite this, the comment is 4 as it directs the authors toward a meaningful improvement in their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the paper only analyzes fully connected ResNets, which is an obvious limitation, and suggests that the authors should clearly state this limitation and include it in the Broader Impact section. The comment provides a direct action for the authors to take, which is to address this limitation and include it in the Broader Impact section. The action is explicit and concrete, giving the authors clear guidance on how to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the analysis of fully connected ResNets, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the limitation of analyzing only fully connected ResNets, and suggests that this limitation should be clearly stated and included in the Broader Impact section. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper only analyzes fully connected ResNets, which is an obvious limitation, and suggests that this should be clearly stated and included in the Broader Impact section. However, the comment does not provide any supporting evidence or reasoning to justify why this is a limitation or why it should be included in the Broader Impact section. The lack of detailed explanation or examples makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 2, as it provides a general observation without sufficient justification or evidence.", "helpfulness_rationale": "The review comment identifies a limitation in the paper, specifically that it only analyzes fully connected ResNets, which is an obvious limitation in the context of ResNet architecture. It suggests that the authors should clearly state this limitation and include it in the Broader Impact section. This feedback is clear and actionable, providing the authors with a specific area to address and improve their draft. However, the comment could be more helpful if it offered additional guidance on how to effectively communicate this limitation or its implications. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point discusses the training of a student model on the training set, specifically mentioning the use of a ResNet18 as the student model. It provides examples of performance metrics on different datasets, such as MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods like Hinton et al., 2015, and FitNets (Romero et al., 2015). However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address the findings or improve their work. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment discusses the training of a student model on the training set, specifically mentioning the use of a ResNet18 as the student model. It provides examples of performance metrics on different datasets, such as MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods like Hinton et al., 2015, and FitNets (Romero et al., 2015). However, the comment does not specify which part of the paper this discussion pertains to, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the performance metrics and references, but without clear grounding, it is challenging for the authors to pinpoint the exact areas needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point discusses the performance of a student model trained on the training set, specifically mentioning the use of a ResNet18 as the student model. It provides examples of performance metrics on different datasets, such as MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods like Hinton et al., 2015, and FitNets (Romero et al., 2015). The comment is 4 as it provides specific examples and references to support the claim about the performance of the student model. However, it could be strengthened by including more detailed explanations or comparisons to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment discusses the performance of a student model trained on the training set, specifically mentioning the use of a ResNet18 as the student model. It provides examples of performance metrics on different datasets, such as MNIST, SVHN, and CIFAR10, and references standard knowledge distillation (KD) methods like Hinton et al., 2015, and FitNets (Romero et al., 2015). However, the comment lacks actionable feedback or suggestions on how the authors might improve their work or address the findings. It does not provide specific guidance on what aspects of the model or training process could be optimized or what improvements could be made. As a result, the comment is 3, as it identifies a potential area for consideration but does not offer detailed guidance for improvement."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It questions whether this assumption holds for certain GCN variants, such as Geniepath or Gated GNN, which learn the message and passing routes in a coupled way, potentially breaking the causal graph assumption. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes to make to their framework. The action is implicit and vague, as it leaves the authors to infer that they need to consider the impact of these variants on their assumption and potentially revise their approach. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a concern about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It specifically questions this assumption in the context of certain GCN variants, such as Geniepath and Gated GNN, which learn the message and passing routes in a coupled way. However, the comment does not specify which part of the paper discusses these assumptions or the specific section where the authors should address this concern. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its questioning of the assumption and its implications for the proposed framework, but without clear grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point raises a concern about the assumption that only node attributes X affect the causal factors and no path in the inverse direction. It questions whether this assumption holds for certain GCN variants, such as Geniepath and Gated GNN, which learn the message and passing routes in a coupled way. However, the comment does not provide specific examples or detailed reasoning to support the claim that these variants would break the causal graph assumption. The lack of explicit evidence or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment raises a critical question about the assumption made in the paper regarding the causal factors and node attributes. It points out that for certain GCN variants, such as Geniepath and Gated GNN, the message and passing routes are learned in a coupled way, potentially challenging the causal graph assumption. This feedback is valuable as it prompts the authors to reconsider their assumptions and explore the implications of these variants on their framework. However, the comment lacks specific guidance or suggestions on how the authors might address this issue or what changes could be made to their approach. While it identifies a potential weakness, it does not provide actionable steps for improvement, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment provides several explicit actions for the authors to take. It suggests that the authors should consider preprocessing and postprocessing layers, not just messagepassing layers, and that it is not convincing to state that messagepassing is the most important part of GNN due to the variability in pre/postprocessing modules across different tasks. The comment also recommends listing the performance of the stateoftheart (SOTA) algorithm in each dataset discussed in Table 1 to help readers understand the gap between NAS models and humanengineered architectures. These suggestions are clear and provide concrete steps for the authors to improve their draft, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"messagepassing layers\" and \"preprocessing,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the issue with the current approach, noting that it only considers messagepassing layers and questions the validity of this claim given the variability in pre/postprocessing modules across different tasks. Additionally, the comment suggests a specific action for the authors to take, which is to list the performance of the stateoftheart (SOTA) algorithm in each dataset discussed in Table 1. This provides clear guidance on how to address the issue. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a claim that the authors only considered messagepassing layers and questions the validity of this claim, suggesting that it is not convincing to directly state that messagepassing is the most important part of GNN due to the variability in pre/postprocessing modules across different tasks. The reviewer provides a logical reasoning by pointing out the potential insufficiency of focusing solely on messagepassing layers. However, the comment could be strengthened by providing specific examples or references to support the claim, such as citing studies or literature that demonstrate the importance of pre/postprocessing in different tasks. While the reasoning is sound, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a detailed critique of the paper\"s focus on messagepassing layers, questioning the validity of this approach given the variability in pre/postprocessing modules across different tasks. It suggests that the authors should consider these aspects and offers a specific suggestion to enhance the paper\"s comprehensiveness by listing the performance of the stateoftheart (SOTA) algorithm in each dataset discussed in Table 1. This feedback is clear and actionable, providing the authors with a concrete direction to improve their draft by addressing the limitations of their current approach. The comment is 4 as it offers a clear path for improvement but could be further enhanced by providing more detailed guidance on how to implement the suggested changes. Therefore, it aligns with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that it would be useful to show whether learning the advantage directly is important, despite the authors\" argument for the advantage being a quantity of interest. However, the comment does not provide explicit guidance on how to address this issue or what specific evidence should be included. The action is implicit, as the authors can infer that they need to provide evidence or analysis to support the importance of learning the advantage directly, but the comment lacks concrete details on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests that it would be useful to show whether learning the advantage directly is important, despite the authors\" argument for the advantage being a quantity of interest. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its request for evidence or analysis to support the importance of learning the advantage directly, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper lacks evidence to support the importance of learning the advantage directly with the proposed method compared to other methods. However, the comment does not provide specific examples, references, or detailed reasoning to substantiate this claim. The lack of supporting evidence or detailed explanation makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides a general suggestion but lacks the necessary details to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by suggesting that it would be useful to demonstrate the importance of learning the advantage directly with the proposed method. It acknowledges the authors\" argument for the advantage being a quantity of interest but points out the lack of evidence supporting why learning it directly is important compared to other methods. This feedback is 3 as it highlights a specific area for improvement, prompting the authors to provide evidence or analysis to support their claims. However, the comment could be more actionable by offering suggestions on how to present this evidence or by providing examples of how other methods might be compared. Overall, the comment provides some insight but lacks depth and specificity, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should provide more explanations about the meaning of variable symbols like \u03c2, r_i, \u03b1_i, and so on in the appended algorithms. While the comment implies that these explanations are needed, it does not explicitly instruct the authors to do so. The action is clear but inferred, and the comment lacks specific guidance on which symbols need clarification or how to provide these explanations. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests adding explanations for the meaning of variable symbols like \u03c2, r_i, \u03b1_i, and so on in the appended algorithms. However, it does not specify which part of the paper these symbols are introduced or discussed, making it weakly grounded. The comment is specific in its request for additional explanations, but without clear grounding, the authors may struggle to identify the exact sections that need revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that additional explanations for the meaning of variable symbols like \u03c2, r_i, \u03b1_i, and so on in the appended algorithms would be beneficial. However, the comment does not provide any specific reasoning or examples to support why these explanations are necessary or how they would improve the paper. Without detailed justification or references, the claim remains vague and 1, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that additional explanations for the meaning of variable symbols like \u03c2, r_i, \u03b1_i, and so on in the appended algorithms would be beneficial. While the comment identifies a specific area for improvement, it lacks depth and does not provide specific guidance on which symbols need clarification or how to present these explanations effectively. This limits the comment\"s usefulness, as it offers a general suggestion without actionable steps for the authors to follow. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the limited performance gains indicate a lack of innovation in the method, which could mean it represents incremental changes to established methods. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might improve the innovation or demonstrate the significance of their method. As a result, the comment lacks actionability, leaving the authors without a clear path forward. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment critiques the limited performance gains of the method, suggesting that it lacks innovation and may represent incremental changes to established methods. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs attention. While the comment is specific in its critique, it lacks grounding as it does not reference a particular section or element of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the limited performance gains suggest the method lacks innovation and may represent incremental changes to established methods. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment critiques the limited performance gains of the method, suggesting that it lacks innovation and may represent incremental changes to established methods. While this feedback highlights a potential issue with the method\"s originality, it does not provide specific suggestions or guidance on how the authors might address this concern or improve the innovation of their work. The comment lacks actionable advice or detailed feedback, making it 3 as it points out a critical area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback implies that the authors should conduct additional comparisons to better understand the strengths and weaknesses of their proposed system. However, the comment does not provide specific guidance on which existing methods or systems to compare with, nor does it offer concrete steps on how to conduct these comparisons. The action is implicit and somewhat vague, as the authors need to infer the specific comparisons to make and how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include a comparative analysis, but without clear guidance on which methods or systems to compare with, it lacks detailed specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. While the comment implies that this would provide a clearer picture of the relative strengths and weaknesses of the proposed system, it does not provide specific examples of existing methods or systems that could be compared with, nor does it offer detailed reasoning or evidence to support the claim. This lack of specificity and detailed justification makes the claim 2, as the authors would need to infer the necessary information to address the suggestion effectively.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from a more extensive comparative analysis with other existing methods or systems for mental health monitoring. This feedback is valuable as it provides a clear direction for the authors to enhance their work by comparing their proposed system with existing solutions. However, the comment lacks specific guidance on which methods or systems to compare with, or how to conduct the analysis effectively. While it identifies a potential area for improvement, the lack of detailed suggestions limits its helpfulness. Therefore, the comment is 3, as it offers a direction for improvement but requires further elaboration to be fully actionable."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point criticizes the comparison of the proposed algorithm with offline RL algorithms for single agent, arguing that the target of those algorithms is not to find an equilibrium. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this issue or improve the comparison. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment critiques the comparison of the proposed algorithm with offline RL algorithms for single agent, arguing that the target of those algorithms is not to find an equilibrium. However, it does not specify which part of the paper this comparison is made in, nor does it provide details on what aspects of the comparison are unfair or how they should be addressed. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need revision. The comment lacks grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is unfair to compare the proposed algorithm with offline RL algorithms for single agent because the target of those algorithms is not to find an equilibrium. However, the comment does not provide specific examples or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique and address it effectively. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of the proposed algorithm with offline RL algorithms for single agent, suggesting that the target of those algorithms is not to find an equilibrium. This feedback highlights a critical aspect of the comparison that may affect the validity of the results. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the comparison. While it points out a potential weakness, it lacks actionable advice, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights the overlap of the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014with prior benchmarks. It suggests that the paper could clarify its unique contributions in methodology and purpose, with more detailed comparisons to similar works. While the comment identifies a potential area for improvement, it does not provide explicit guidance on how to address the overlap or how to clarify the unique contributions. The action is implicit and somewhat vague, as the authors need to infer the specific steps to take to improve the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the overlap of three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014with prior benchmarks. It suggests that the paper could clarify its unique contributions in methodology and purpose, with more detailed comparisons to similar works. However, the comment does not specify which sections of the paper discuss these tasks or where the comparisons to prior work are made, making it weakly grounded. The comment is specific in suggesting the need for clarification and comparisons, but without explicit references to parts of the paper, it remains weakly grounded. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014have been partially covered in prior benchmarks. The reviewer suggests that the paper could clarify its unique contributions in methodology and purpose by providing more detailed comparisons to similar works. However, the comment lacks specific references to the prior work mentioned (14), which would help substantiate the claim. The absence of detailed examples or comparisons makes it 3, as the authors would need to infer the specific areas where the paper could improve. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential overlap with prior work in the three tasks\u2014unanswerable, inconsistent, and counterfactual\u2014highlighting the need for the paper to clarify its unique contributions in methodology and purpose. It suggests that the paper could benefit from more detailed comparisons to similar works, which would help differentiate its contributions. While the comment points out a specific area for improvement, it lacks detailed guidance or examples on how to address the overlap or clarify the unique contributions. This makes the feedback 3, as it provides a direction for improvement but does not fully support the authors in executing it. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the statement in Section 1, \"human perception is usually invariant to the texture resampling,\" lacks support materials. While it identifies a gap in the paper, it does not explicitly instruct the authors to provide additional support materials or specify what kind of support is needed. The action is implicit and somewhat vague, as the authors can infer that they need to add support materials but may not be entirely sure how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the lack of support materials for the statement \"human perception is usually invariant to the texture resampling,\" providing clear guidance on what is missing. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the statement in Section 1, \"human perception is usually invariant to the texture resampling,\" lacks support materials. However, the comment does not provide any specific examples, references, or detailed reasoning to substantiate this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the statement in Section 1, \"human perception is usually invariant to the texture resampling,\" lacks support materials. This feedback is clear and actionable, as it highlights a gap in the paper that the authors need to address by providing additional support materials. However, the comment could be more helpful if it suggested specific types of support materials or examples of what kind of evidence or references would be appropriate. Despite this, the comment still provides valuable guidance for improving the draft, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper primarily focuses on MiPKD\"s performance in singleimage superresolution (SR) tasks but does not emphasize its design for this specific task. The reviewer recommends that the authors demonstrate the applicability of MiPKD to other computer vision (CV) tasks to enhance its perceived generalizability. While the comment implies that additional experiments on a broader range of tasks should be conducted, it does not provide specific guidance on which tasks to include or how to design these experiments. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s focus on MiPKD\"s performance in SR tasks, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks and conduct additional experiments on a broader range of tasks to enhance the method\"s perceived generalizability. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper primarily focuses on MiPKD\"s performance in singleimage superresolution (SR) tasks but does not emphasize its design for this specific task. The reviewer suggests that the authors should demonstrate the applicability of MiPKD to other CV tasks to enhance its perceived generalizability. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim that MiPKD is not specially designed for SR tasks. This makes the claim 3, as the authors would need to further explore and substantiate the claim themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential limitation in the paper\"s focus on MiPKD\"s performance in singleimage superresolution (SR) tasks, suggesting that the method is not specifically designed for this task. It provides a clear and actionable recommendation for the authors to demonstrate the applicability of MiPKD to other computer vision tasks, which could enhance the method\"s perceived generalizability. By suggesting additional experiments on a broader range of tasks, the comment offers a concrete way for the authors to improve the comprehensiveness and impact of their work. This feedback is 4 as it guides the authors toward a more comprehensive evaluation of their method, but it could be further enhanced by providing specific examples of other CV tasks that could be explored. Therefore, the comment is rated as 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Equations 21 and 22 describe an alternative scheme that is not actually used and believes they may be omitted without affecting the flow of the section. While the comment implies that these equations should be removed, it does not explicitly instruct the authors to do so. The action is inferred and somewhat vague, as the authors need to determine whether to remove the equations and how to ensure the flow remains unaffected. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equations 21 and 22,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is that the equations describe an alternative scheme that is not actually used and suggests that they may be omitted without affecting the flow of the section. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Equations 21 and 22 describe an alternative scheme that is not actually used and suggests that they may be omitted without affecting the flow of the section. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of this suggestion. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that Equations 21 and 22 describe an alternative scheme that is not actually used. The reviewer suggests that these equations may be omitted without affecting the flow of the section. This feedback is clear and actionable, as it provides a direct suggestion for simplification and clarity in the paper. However, the comment could be more helpful if it offered additional context or explanation about why these equations are included or how their omission might impact the overall understanding of the section. Despite this, the comment is 4 as it guides the authors on a specific area for improvement. Therefore, it aligns with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the optimization module uses a simple iteration strategy to optimize two loss functions and claims that the overall model is incremental, standing on the shoulder of traditional approaches. However, it does not provide explicit guidance or suggestions on how the authors should address this concern or improve the model. The comment lacks actionable details, such as recommending specific strategies or improvements to make the model more robust or innovative. As a result, the authors are left without a clear understanding of what steps to take to enhance their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the optimization module and its strategy for optimizing two loss functions, suggesting that the overall model is incremental and stands on the shoulder of traditional approaches. However, it does not specify which part of the paper this observation pertains to, such as a particular section or figure. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in its critique of the optimization strategy and the incremental nature of the model, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the optimization module uses a simple iteration strategy to optimize two loss functions and suggests that the overall model is incremental, standing on the shoulder of traditional approaches. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential limitation in the optimization strategy used in the paper, suggesting that the overall model is incremental and stands on the shoulder of traditional approaches. While it highlights a concern about the originality and innovation of the work, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the novelty of their approach. The feedback is 3 as it prompts the authors to reconsider the originality of their work, but it lacks actionable advice or detailed suggestions for improvement. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper\"s writing could be improved and specifically points out the choice of F(X) for the E(d) case, asking which are the 2^d O(d) matrices. The reviewer implies that the authors should elaborate on one of the examples in the main paper and provide the other two in the appendix. This feedback is explicit and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment suggests that the paper\"s writing could be improved and specifically points out the choice of F(X) for the E(d) case, asking which are the 2^d O(d) matrices. It implies that the authors should elaborate on one of the examples in the main paper and provide the other two in the appendix. This feedback is specific, as it clearly identifies the issue with the choice of F(X) and provides a concrete suggestion for improvement. However, it does not explicitly mention a specific section of the paper, making it weakly grounded. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper\"s writing could be improved, specifically regarding the choice of F(X) for the E(d) case. The reviewer questions which are the 2^d O(d) matrices and suggests that the authors elaborate on one example in the main paper and provide the other two in the appendix. While the comment identifies a specific area for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for elaboration is clear, but the lack of specific guidance or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper\"s writing, particularly regarding the choice of F(X) for the E(d) case. It questions which are the 2^d O(d) matrices and suggests that the authors elaborate on one example in the main paper and provide the other two in the appendix. This feedback is clear and actionable, offering a concrete way for the authors to enhance the clarity and comprehensiveness of their paper. However, it could be more helpful if it provided additional guidance on how to effectively elaborate on the examples or if it offered specific suggestions for improving the writing. Overall, the comment is 4 as it directs the authors\" attention to a specific area for improvement and provides a clear path for enhancement."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the implicit assumptions the paper makes to achieve success in fewshot learning, specifically comparing it to common assumptions like metadistribution or distributioncloseness. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what specific assumptions to consider. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the implicit assumptions the paper makes regarding fewshot learning, specifically comparing it to common assumptions like metadistribution or distributioncloseness. However, it does not specify which part of the paper this question pertains to, making it difficult for the authors to identify the exact section that needs attention. While the authors might have an idea of where these assumptions are discussed, the comment lacks full grounding. It is specific in questioning the assumptions but does not provide detailed guidance on how to address them. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the implicit assumptions made in the paper regarding fewshot learning, specifically comparing them to common assumptions like metadistribution or distributioncloseness. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises an important question about the implicit assumptions the paper makes regarding the success of fewshot learning, specifically comparing them to common assumptions like metadistribution or distributioncloseness. This is a valuable point that could help the authors clarify their methodology and assumptions, potentially leading to a more robust and transparent explanation of their approach. However, the comment lacks specific suggestions or guidance on how the authors might address this question or incorporate these assumptions into their work. While it identifies a potential area for improvement, it does not provide actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models. It also recommends providing results for more standard benchmarks in the literature to facilitate comparison. While the comment provides a clear direction for improvement, it lacks specific guidance on which tasks or benchmarks to include or how to effectively present the results. The action is explicit but somewhat vague, as the authors need to infer the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, as well as providing results for more standard benchmarks in the literature. However, it does not specify which sections of the paper should be revised or how these comparisons should be integrated. The authors can infer that it relates to the discussion or results sections, but this inference is not direct. The comment is specific in suggesting additional comparisons and benchmarks, but it lacks grounding as it does not explicitly mention the parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the comparison to prior work could be more thorough by considering other tasks and largescale models, as well as providing results for more standard benchmarks. However, the comment does not provide specific examples or references to prior work that could be compared to, nor does it offer detailed reasoning or evidence to support the claim. This lack of specificity and supporting details makes the claim 2, as the authors may find it challenging to understand and address the suggestions without further guidance.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on how to enhance the comparison to prior work. It suggests that the authors should consider additional tasks and largescale models in their comparisons, as well as provide results for more standard benchmarks in the literature. This guidance is clear and offers a concrete way for the authors to improve the comprehensiveness and depth of their comparison section. However, the comment could be more helpful if it included examples of specific tasks or benchmarks that would be beneficial to include. Overall, the feedback is 4 as it directs the authors toward meaningful improvements in their draft."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment suggests that the manuscript is more akin to an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved. However, the comment does not provide specific guidance on what aspects could be enhanced or how the authors might address the reviewer\"s concern. The feedback lacks explicit instructions or concrete suggestions for improvement, leaving the authors uncertain about how to proceed. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment suggests that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, it does not specify which part of the paper this observation is based on, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the method could be improved or how the contribution could be enhanced. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the manuscript is more like an experimental discovery paper and that the proposed method is similar to a traditional removal method. However, the comment lacks specific details or examples to support this claim, making it difficult for the authors to understand the basis of the critique. Without additional context or evidence, the claim remains 1, as it does not provide a clear rationale or references to support the assertion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the manuscript is more akin to an experimental discovery paper and that the proposed method is similar to a traditional removal method. It implies that the contribution of the manuscript could be improved. However, the comment lacks specificity and does not provide detailed feedback or suggestions on how the authors might enhance their work. Without actionable guidance or concrete examples, the authors are left with a general idea of potential improvements but without a clear path forward. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, despite the qualitative results being impressive. It suggests that the authors should provide quantitative results to better judge the effectiveness of their approach. However, the comment does not explicitly instruct the authors to include these results or provide guidance on how to present them. The action is implicit and somewhat vague, as the authors need to infer that they should include quantitative results and determine the best way to present them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a specific issue regarding the absence of quantitative results for the Human Shape Bases Synchronization problem, despite the qualitative results being impressive. It suggests that the authors should provide quantitative results to better judge the effectiveness of their approach. However, the comment does not specify which part of the paper should include these quantitative results, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not as direct as it could be. The comment is specific in identifying the need for quantitative results, but it lacks grounding in terms of where these results should be included. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the absence of quantitative results for the Human Shape Bases Synchronization problem, despite the qualitative results being impressive. The reviewer suggests that the authors should provide quantitative results to better judge the effectiveness of their approach. However, the comment does not provide specific examples, references, or detailed reasoning to support the claim that quantitative results are necessary. This lack of detailed justification makes the claim 3, as the authors would need to infer the importance of quantitative results and understand the reasoning behind it. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area of concern regarding the absence of quantitative results for the Human Shape Bases Synchronization problem, despite the qualitative results being impressive. It suggests that providing quantitative results would help judge the effectiveness of the approach, which is a valuable piece of feedback. However, the comment does not offer specific guidance on how to include these quantitative results or what kind of metrics or experiments would be appropriate. While it highlights an important aspect of the paper, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it points out a potential weakness but does not provide detailed guidance for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the categorization of the paper under \"Fairness/Accountability/Transparency,\" but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this question or what steps they should consider to clarify the categorization. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the categorization of the paper under \"Fairness/Accountability/Transparency,\" but it does not specify which part of the paper this question pertains to. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine where the issue lies. Additionally, the comment lacks specificity regarding what the authors should do to address the categorization question. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about the categorization of the paper under \"Fairness/Accountability/Transparency.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the categorization of the paper under \"Fairness/Accountability/Transparency,\" but it does not provide any context or explanation for why this categorization is in question. It lacks specificity and does not offer any actionable feedback or suggestions for the authors to address this issue. Without additional information or guidance, the authors are left without a clear understanding of what might be incorrect or how to improve the categorization. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should include machine learning 2step baselines for comparison, as the improvement might be due to the different class of algorithm rather than the assertion that NaviFormer outperforms baselines. While the comment implies that the authors should add these baselines, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors need to determine how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the comparison of approaches to baselines, suggesting the inclusion of machine learning 2step baselines for a more accurate comparison. However, it does not specify which part of the paper this comparison is made in, making it weakly grounded. The comment is specific in suggesting the inclusion of a machine learning 2step baseline to clarify the improvement, but it lacks detailed guidance on how to implement this suggestion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the comparison to baselines is misleading because all approaches appear to be heuristic methods, and the improvement might be due to the different class of algorithm rather than the authors\" assertion. The reviewer suggests including machine learning 2step baselines for a more accurate comparison. However, the comment lacks specific examples or references to support the claim that the improvement is due to the algorithm class. Without detailed evidence or examples, the claim remains 3, as the authors would need to further investigate and provide additional context to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the comparison of approaches to baselines, suggesting that the improvement might be due to the different class of algorithm rather than the authors\" assertion. It provides a specific suggestion to include machine learning 2step baselines for a more accurate comparison. This feedback is clear and actionable, as it guides the authors to consider a more comprehensive evaluation of their results. However, the comment could be more helpful if it provided additional context or examples of how to implement this suggestion. Overall, the comment is 4, as it offers valuable insight and direction for improving the draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the results appear better than other methods, but it is unclear whether this improvement is due to the image generative model. The reviewer recommends a fair comparison by applying the planning and layering method to the design image generated by other image generative models. This feedback provides a clear and explicit action for the authors to take, which is to conduct a fair comparison. The suggestion is concrete, as it specifies the method to apply and the goal of the comparison. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests a fair comparison by recommending the application of the planning and layering method to the design image generated by other image generative models. However, it does not specify which part of the paper this suggestion pertains to, such as a specific section or result that needs to be compared. The authors can infer that it relates to the results section, but this inference is not direct. The comment is specific in suggesting a method for comparison, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the claim that the results are better than other methods, suggesting that the improvement might be due to the image generative model. The reviewer recommends a fair comparison by applying the planning and layering method to the design image generated by other models. However, the comment lacks specific examples or detailed reasoning to support the claim that the results are better due to the image generative model. Without concrete evidence or references, the claim remains 3, as it provides a suggestion but lacks the necessary details to fully substantiate the argument. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the results presented in the paper, questioning whether the observed improvements are due to the image generative model. It suggests a fair comparison by recommending the application of the planning and layering method to the design image generated by other image generative models. This feedback is clear and actionable, as it provides a specific suggestion for the authors to enhance the rigor of their comparison. However, the comment could be more helpful if it included examples or detailed guidance on how to implement this suggestion. Overall, the comment is 4 as it directs the authors toward a meaningful improvement in their analysis, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a confusion in the discussion of a dataset, specifically mentioning that the task is described as plain polarity classification but also refers to \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these additional terms are not relevant to the experiments, they should not be mentioned. While the comment implies that the authors should clarify or remove these references, it does not provide explicit instructions on how to do so. The action is implicit and somewhat vague, as the authors need to determine whether to keep or remove the mentioned terms. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions lines 329334, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the discussion of the dataset, pointing out the confusion between \"plain polarity classification\" and the mention of \"opinion holder\" and \"opinion targets.\" The comment suggests that these additional terms should not be included if they are not relevant to the experiments. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the discussion of the dataset is confusing, specifically mentioning the mention of \"opinion holder\" and \"opinion targets\" in addition to \"plain polarity classification.\" The reviewer suggests that these terms might not be relevant to the experiments and should be removed. However, the comment lacks specific examples or detailed reasoning to support why these terms are confusing or unnecessary. Without further explanation or evidence, the claim is 3, as it provides a general observation but lacks the depth needed for full verification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the discussion of a dataset in the paper, noting that the task is described as plain polarity classification but also refers to \"opinion holder\" and \"opinion targets.\" The reviewer suggests that if these terms are not relevant to the experiments, they should not be mentioned. This feedback is clear and actionable, as it directs the authors to clarify or remove potentially confusing or irrelevant information. However, the comment could be more helpful if it provided additional context or explanation on why these terms are confusing or how they might impact the understanding of the experiments. Overall, the comment is 4 as it provides a clear direction for improvement, but it could be more comprehensive with additional guidance. Therefore, it aligns with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the restriction of capsule networks and questions the necessity of this restriction. It also points out that the authors do not provide the number of parameters in the group CapNet, which is necessary for evaluating the benefit of enforcing equivariance strictly. However, the comment does not offer explicit guidance on how to address these issues or suggest specific actions for the authors to take. The feedback is implicit and lacks concrete details, making it difficult for the authors to know what steps to follow to improve their draft. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the previous comment and the experiments involving the group CapNet, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a concern about the unnecessary restriction of capsule networks and questions the lack of parameter count in the group CapNet, which affects the evaluation of the benefit of enforcing equivariance strictly. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point raises a concern about the restriction of capsule networks and questions the necessity of this restriction. It also points out that the authors do not provide the number of parameters in the group CapNet, which is necessary for evaluating the benefit of enforcing equivariance strictly. The comment is 3 as it provides a logical reasoning for the concern, but it lacks specific examples or references to support the claim about the benefit of enforcing equivariance. The authors would need to further explore the reasoning to fully understand the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a concern about the restriction of capsule networks and questions the necessity of this restriction. It points out that the authors do not provide the number of parameters in the group CapNet, which is necessary for evaluating the benefit of enforcing equivariance strictly. The comment is 3 as it identifies a potential issue with the experimental setup and suggests that the authors should provide more details to address this concern. However, it could be more helpful by offering specific suggestions on how to improve the evaluation or by providing examples of how to measure the benefit of enforcing equivariance. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point discusses the challenge of obtaining meaningful gradients with respect to noisy intermediate images and mentions that this issue has been addressed before in various approaches, such as DiME, which computes gradients with respect to denoised images. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve their work. It lacks concrete actions or recommendations for the authors to take, leaving them uncertain about how to proceed. The comment is vague and does not offer actionable steps, making it 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"page 4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by discussing the challenge of obtaining meaningful gradients with respect to noisy intermediate images and mentions specific approaches like DiME and FastDiME, as well as He et al.(https://openreview.net/forum?id=o3BxOLoxm1), which have efficient implementations of the Tweedie approach. This provides clear guidance on what the authors need to address or improve. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point discusses the challenge of obtaining meaningful gradients with respect to noisy intermediate images and mentions that this issue has been addressed before in various approaches, such as DiME, which computes gradients with respect to denoised images. The comment also references FastDiME and He et al.(https://openreview.net/forum?id=o3BxOLoxm1) as having more efficient implementations of the Tweedie approach. This provides specific references to existing solutions, making the claim 4. However, the comment could be strengthened by providing more detailed reasoning or examples of how these approaches address the challenge, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment addresses a specific challenge related to obtaining meaningful gradients with respect to noisy intermediate images, which is discussed on page 4. It acknowledges that this issue has been addressed before in various approaches, such as DiME, which computes gradients with respect to denoised images, and mentions that FastDiME and He et al.(https://openreview.net/forum?id=o3BxOLoxm1) have more efficient implementations of the Tweedie approach. This feedback is 3 as it identifies a known issue and provides references to existing solutions, which could guide the authors in understanding and addressing the problem. However, the comment could be more helpful by offering specific suggestions or insights on how the authors might improve their approach or integrate these solutions. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors include an evaluation of inference speed on the hardware. This is an explicit action, as it clearly states what the authors should do to improve their draft. However, it does not provide specific guidance on how to conduct this evaluation or what aspects of inference speed should be considered. While the action is clear, the lack of detailed instructions on execution makes it 3.", "grounding_specificity_rationale": "The comment suggests including an evaluation of inference speed on the hardware, but it does not specify which part of the paper this evaluation should be included in. This makes it weakly grounded, as the authors cannot confidently determine where this evaluation should be placed. However, the comment is specific in its suggestion to include an evaluation of inference speed, providing clear guidance on what needs to be addressed. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors include an evaluation of inference speed on the hardware. However, it does not provide any supporting evidence, reasoning, or examples to justify why this evaluation is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that the authors include an evaluation of inference speed on the hardware, which is a specific and actionable suggestion. This feedback is clear and provides a concrete direction for the authors to enhance their draft by addressing a practical aspect of their work. However, the comment could be more helpful if it offered additional guidance on how to conduct this evaluation or what specific metrics or methods should be considered. Despite this, the suggestion is valuable and actionable, making the comment 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point explicitly states that the modified problem is convex and can be solved via an SDP, but it does not provide any guidance on how the authors should address the lack of SDP formulation in their draft. The comment lacks specific instructions or suggestions on how to incorporate or clarify the SDP formulation, leaving the authors without a clear path forward. As a result, the comment is 1 because it does not provide actionable steps for the authors to take in response to the feedback.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"modified problem\" and \"SDP,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the SDP formulation, and requests that the authors provide it. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the modified problem is convex and can be solved via an SDP, but it does not provide any supporting evidence or reasoning to substantiate this claim. The comment lacks specific details or references that would help the authors understand why this claim is relevant or how it impacts their work. As a result, the claim is 1 due to the absence of supporting information or justification.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the modified problem is convex and can be solved via an SDP, but it does not provide any indication of where the SDP formulation is discussed or how it is relevant to the paper. This lack of context or explanation leaves the authors without guidance on how to address this point or improve their draft. The comment is vague and does not offer actionable feedback, making it unhelpful for the authors. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly points out two issues: the lack of information on the number of new task combinations used to evaluate compositional generalisability and the limited test results in Table 7 to only 30 composite instructions. These are clear and direct actions for the authors to take, providing specific guidance on what needs to be addressed. The comment is 5 as it clearly identifies the missing information and the need for more comprehensive test results, allowing the authors to make precise improvements to their draft. Therefore, this comment is rated as 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"line 558\" and \"Table 7,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed: the number of new task combinations used to evaluate compositional generalisability and the limited test results in Table 7. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point consists of two separate claims: one about the lack of information on the number of task combinations used to evaluate compositional generalisability, and another about the limited test results in Table 7. The first claim is 3 as it highlights a potential oversight in the paper, but it lacks specific examples or references to support the claim. The second claim is also 3, as it points out a limitation in the test results, but it does not provide detailed reasoning or examples to substantiate the claim. Overall, the comment is 3 due to the lack of detailed justification or evidence for both claims.", "helpfulness_rationale": "The review comment identifies two specific areas for improvement in the paper. It points out a lack of information regarding the number of new task combinations used to evaluate compositional generalisability, which is crucial for understanding the scope and robustness of the study. Additionally, it notes that the test results in Table 7 are limited to only 30 composite instructions, suggesting that the authors should provide more comprehensive test results. These observations are clear and actionable, offering the authors a direct path to enhance the clarity and comprehensiveness of their work. However, the comment could be more helpful if it provided suggestions on how to address these issues or examples of how to improve the test results. Overall, the feedback is 4 as it directs the authors to specific areas needing improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the paper, particularly the figures, is not wellformatted in terms of layout. However, it does not provide specific details on what aspects of the layout are problematic or how the authors should improve it. The comment lacks explicit guidance or concrete suggestions for enhancing the layout, leaving the authors uncertain about what changes to make. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment indicates that the paper, particularly the figures, is not wellformatted in terms of layout. However, it does not specify which figures or sections are affected, nor does it provide details on what aspects of the layout are problematic. This lack of specificity and grounding makes it difficult for the authors to identify the exact parts of the paper that need improvement. Therefore, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"the paper, especially the figures, is not formed in a good layout.\" However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the specific issues with the layout or how to address them. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment points out that the paper, particularly the figures, is not wellformatted in terms of layout. However, it lacks specificity and does not provide any details on what aspects of the layout are problematic or how the authors could improve it. Without actionable feedback or suggestions, the authors are left without guidance on how to enhance the layout of their figures. This makes the comment 2, as it identifies a potential issue but does not offer a clear path for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point explicitly asks the authors to explain the discrepancy between the baseline results in Table 2 and Table 3 from reference 3. This is a direct and clear request for clarification, providing the authors with a specific action to take. The comment is explicit and concrete, as it clearly identifies what needs to be addressed and how to do so. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 2\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is explaining the discrepancy between the baseline results in these tables. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the baseline results in Table 2 and Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment requests an explanation for the discrepancy between the baseline results in Table 2 and Table 3 from reference 3. This is a straightforward and actionable request that prompts the authors to clarify and understand the differences in their results. By addressing this feedback, the authors can improve the clarity and comprehensibility of their paper, ensuring that readers can understand the basis of their findings. However, the comment could be more helpful if it provided additional context or suggested ways to investigate the discrepancy. Overall, the comment is 3 as it identifies a specific area for improvement but lacks depth and guidance."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review point identifies a misleading use of the term \"execution feedback\" in the title and Figure 2, suggesting that no actual execution feedback is used in the work. It clarifies that execution feedback is based on structural perturbations in the AST and that the authors assume any such perturbation results in a failure. The reviewer also points out a discrepancy between the definition of EF in Lines 233238 and Equation 1, noting that there is no guarantee that perturbations will make tests fail. While the comment highlights specific issues, it does not provide explicit guidance on how the authors should address these concerns. The authors are left to infer that they need to correct the terminology and clarify the assumptions and definitions related to execution feedback. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"execution feedback\" in the title and Figure 2, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the misleading use of the term \"execution feedback,\" explaining that no actual execution feedback is used in the work. The comment further specifies the issue by discussing the assumption that perturbations result in a failure and the discrepancy between the definition of EF in Lines 233238 and Equation 1. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the use of \"execution feedback\" is misleading, as no actual execution feedback is used in the work. It provides specific examples from Lines 233238 and Equation 1 to support this claim, explaining that execution feedback is based on structural perturbations in the AST and that the authors assume any such perturbation results in a failure. The comment also highlights a discrepancy between the definition of EF in the text and the equation, further supporting the claim. This detailed analysis makes the claim 5, as it provides clear reasoning and examples to justify the assertion. Therefore, the comment is rated as 5.", "helpfulness_rationale": "The review comment identifies a misleading use of the term \"execution feedback\" in the title and Figure 2, suggesting that no actual execution feedback is used in the work. It clarifies that execution feedback is based on structural perturbations in the AST and that the authors assume any such perturbation results in a failure. The comment also points out a discrepancy between the definition of EF in Lines 233238 and Equation 1, noting that there is no guarantee that perturbations will make tests fail. This feedback is clear and actionable, as it directs the authors to correct the terminology and clarify their assumptions and definitions. However, it could be more helpful if it provided specific suggestions on how to address these issues or examples of how to improve the clarity of the text. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights the lack of information regarding the \"40 target words\" used and the methodology for using \"a sequence of dots\" to remove bias in the model. It also points out the absence of detail on how many games are sampled to assess the severity of the bias problem. While the comment identifies specific areas where the authors need to provide more information, it does not explicitly instruct them to add this information or suggest where to find this information. The action is implicit and somewhat vague, as the authors need to infer that they should include this information in their draft. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses specific issues related to the use of \"40 target words\" and the methodology for removing bias in the model, as well as the lack of detail on how many games are sampled to assess bias severity. However, it does not explicitly mention which part of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing what needs to be addressed, such as the lack of information on target words and the methodology for bias removal. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises concerns about the lack of information regarding the \"40 target words\" used and the methodology for removing bias in the model. It also questions the absence of detail on how many games are sampled to assess the severity of the bias problem. However, the comment does not provide specific examples, references, or detailed reasoning to support these claims. The lack of explicit evidence or detailed explanation makes it difficult for the authors to understand and address the issues effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies specific areas where the paper lacks clarity and detail. It points out the absence of information regarding the \"40 target words\" used and the methodology for removing bias in the model, as well as the lack of detail on how many games are sampled to assess the severity of the bias problem. This feedback is clear and actionable, as it directs the authors to provide additional information and details to enhance the comprehensiveness and clarity of their work. However, the comment could be more helpful if it offered suggestions on how to address these issues or provided examples of how to present the information effectively. Overall, the comment is 4, as it provides valuable insights for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address these issues, such as suggesting alternative datasets or methods to make the experiments more realistic. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the experiments conducted on simple datasets and the unrealistic nature of uniformly random missing data. However, it does not specify which part of the paper these issues are discussed in, making it difficult for the authors to pinpoint the exact sections that need revision. While the authors might have an idea of where these topics are covered, the comment lacks full grounding. It is specific in identifying the issues with the experiments, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique or how to address it. The absence of detailed reasoning or evidence makes the claim 2, as it provides some insight but lacks the necessary depth to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a limitation in the experimental setup, noting that the experiments are conducted on simple datasets and that the uniformly random missing data is unrealistic in practice. While this feedback highlights areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues. The comment provides some insight into potential weaknesses but does not offer actionable steps for the authors to enhance their work. Therefore, the comment is 3, as it points out areas for improvement but does not fully support the authors in making those improvements."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that Figure 4 lacks legends for the plots, making them difficult to interpret. It suggests that including legends would be beneficial. This feedback provides a clear and direct action for the authors to take, specifying what needs to be done to improve the figure. The comment is specific and actionable, as it clearly identifies the issue and offers a concrete solution. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the figure, namely the lack of legends for the plots, and suggests that including these would make the figure easier to interpret. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that Figure 4 lacks legends, making the plots difficult to interpret. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the overall understanding of the paper. Without additional context or explanation, the authors may find it challenging to understand the importance of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 4, noting that it lacks legends for the plots, which makes them difficult to interpret. It suggests that including legends would be beneficial for clarity. This feedback is clear and actionable, providing the authors with a direct way to improve the interpretability of their figures. However, the comment could be more helpful if it offered additional guidance on how to effectively incorporate legends or suggested specific ways to enhance the clarity of the plots. Overall, the comment is 4 as it directs the authors toward a clear and practical improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about whether the paper is specifically concerned with sequencetosequence (seq2seq) models, suggesting that the general quantization aware training strategy could be extended to other models. It also asks if there is anything specific about the proposed robustnessaware quantization scheme that benefits seq2seq models. While the comment implies that the authors should clarify the scope of their work, it does not provide explicit instructions or concrete guidance on how to address these questions. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the specific aspects of their work related to seq2seq models. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about whether the paper is specifically concerned with sequencetosequence (seq2seq) models, suggesting that the general quantization aware training strategy could be extended to other models. It also asks if there is anything specific about the proposed robustnessaware quantization scheme that benefits seq2seq models. While the comment does not explicitly mention a specific section or part of the paper, the authors can infer that it relates to the discussion of quantization strategies and their application to different models. The comment is specific in its request for clarification about the specificity of the work related to seq2seq models. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the paper\"s focus on sequencetosequence (seq2seq) models and the applicability of the proposed robustnessaware quantization scheme. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about whether the paper is specifically focused on sequencetosequence (seq2seq) models, suggesting that the general quantization aware training strategy could be extended to other models. It also asks if there is anything specific about the proposed robustnessaware quantization scheme that benefits seq2seq models. While the comment identifies a potential area for clarification, it does not provide specific suggestions or guidance on how the authors might address this issue. The feedback is 3 as it prompts the authors to clarify the scope of their work, but it lacks depth and actionable advice. Therefore, it aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors provide more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. While the comment implies that the authors should conduct additional experiments or analyses, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should perform these studies and may not be entirely sure how to execute them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the authors provide more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. However, it does not specify which part of the paper this analysis should be included in, making it weakly grounded. The comment is specific in suggesting that the authors should conduct additional experiments or analyses to explore the impact of lambda on the algorithm\"s behavior and Q estimates. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors provide more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. However, the comment does not provide any supporting evidence, reasoning, or references to justify why this analysis is necessary or how it would benefit the paper. Without additional context or explanation, the claim remains 1, as it lacks the necessary details to support the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests that the authors provide more ablation studies on how the algorithm\"s behavior and the accuracy of its Q estimates change as the hyperparameter lambda varies. This feedback is 3 as it identifies a specific area for improvement, prompting the authors to conduct additional experiments or analyses to better understand the impact of the hyperparameter. However, the comment lacks depth and does not provide specific guidance on how to conduct these ablation studies or what aspects to focus on. While it highlights an important aspect of the paper, it does not offer detailed suggestions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point poses a question about the base encoder of the proposed model or whether the authors train the model from scratch. While it implies that the authors should clarify this information in their paper, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should provide this clarification but are not given specific guidance on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises a question about the base encoder of the proposed model or whether the authors train the model from scratch. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references, the authors may find it challenging to determine where to address this question. Additionally, the comment lacks specificity regarding what information is missing or what needs to be clarified. Therefore, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about the base encoder of the proposed model or whether the authors train the model from scratch. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the base encoder of the proposed model and whether the authors train the model from scratch. This is a relevant inquiry that could help clarify important aspects of the methodology, potentially impacting the reproducibility and understanding of the work. However, the comment does not provide any suggestions or guidance on how the authors might address this question or improve their draft. While it identifies a potential area for clarification, it lacks actionable feedback, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the Ethical Statement should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment implies that the authors should add these discussions, it does not explicitly instruct them to do so. The action is clear but inferred, and the authors are given a specific direction on what to include in the Ethical Statement. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Ethical Statement,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides clear guidance on what needs to be extended, namely a more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This provides the authors with a clear understanding of what additional information is needed to enhance the Ethical Statement. Therefore, this comment is categorized as 5.", "verifiability_rationale": "The review point suggests that the Ethical Statement should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that these aspects are not adequately addressed. The authors would need to infer the need for such a discussion, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific area for improvement in the paper, namely the Ethical Statement. It suggests that the statement should be extended with more concrete discussion of challenges not addressed in the dataset, such as gender beyond the binary, races other than Black, and other sources of social bias. This feedback is clear and actionable, providing the authors with a specific direction for enhancing the depth and comprehensiveness of their ethical considerations. However, the comment could be more helpful if it included examples or specific suggestions on how to address these challenges. Overall, the comment is 4 as it guides the authors toward a more thorough and nuanced discussion of ethical issues."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors clarify the length of the minibatches tau_t, noting that it may be nonintegers and questioning the implications of tau_t being much smaller than 1. This feedback provides a clear and direct action for the authors to take, which is to ensure that the length of the minibatches is clearly explained and that the analysis remains valid under different conditions. The comment is specific and provides concrete guidance on how to address the issue, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the length of the minibatches tau_t, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the length of the minibatches, questioning whether the analysis remains valid if tau_t is much smaller than 1. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the validity of the analysis when the length of the minibatches tau_t is noninteger or much smaller than 1. The reviewer questions the implications of these scenarios and suggests that the analysis may not hold under such conditions. However, the comment lacks specific examples or references to substantiate the claim, making it difficult for the authors to fully understand and address the issue. The lack of detailed reasoning or evidence makes the claim 3, as it provides a basis for concern but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a potential issue with the length of the minibatches tau_t, noting that it may be nonintegers and questioning the validity of the analysis in such cases. This feedback is clear and actionable, as it prompts the authors to clarify the conditions under which the analysis holds and to consider the implications of tau_t being much smaller than 1. By addressing this concern, the authors can improve the robustness and reliability of their analysis. However, the comment could be more helpful if it provided specific examples or suggestions on how to handle these scenarios. Overall, the feedback is 4 as it directs the authors to a critical area that needs attention, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point highlights the importance of examining the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors should address this issue or what specific steps they should consider to evaluate the computational cost. Without actionable advice or suggestions, the authors are left without a clear understanding of how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"SCALE model\" and the \"inference cost,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue of computational cost associated with the inference process of the SCALE model, particularly mentioning the two types of decoding involved. This provides clear guidance on what aspect of the paper needs attention. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that this aspect is important or needs further examination. Without additional context or justification, the authors may find it challenging to understand the basis of the concern or how it impacts the paper. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential area for improvement by highlighting the importance of examining the computational cost associated with the inference process of the SCALE model, which involves two types of decoding: STM decoding and LLM decoding. This feedback is 3 as it points out a specific aspect of the paper that could be explored further, potentially leading to a more comprehensive understanding of the model\"s performance. However, the comment lacks depth and does not provide specific suggestions or guidance on how the authors might address this issue or what kind of analysis would be beneficial. To be more helpful, the comment could include recommendations on how to evaluate or compare the computational costs of the two decoding methods. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two main issues: the use of a subset of the dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. Additionally, it points out peculiar experimental results. While the comment identifies these issues, it does not provide explicit guidance on how to address them. The authors are left to infer that they need to expand their dataset usage and include comparisons with stateoftheart models to strengthen their claims. The mention of peculiar results suggests that the authors should investigate and clarify these findings, but it does not offer specific steps on how to do so. Therefore, the comment is 3, as it provides some direction but lacks concrete details on execution.", "grounding_specificity_rationale": "The comment addresses two main issues: the use of a subset of the dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. It also mentions peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. However, the comment does not specify which sections of the paper these issues are discussed in, making it weakly grounded. The comment is specific in detailing the issues with dataset usage and the peculiar results, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the article only uses a subset of the complete dataset and lacks performance comparisons with stateoftheart models, making it difficult to demonstrate the effectiveness of the proposed methods. It also mentions peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. The claim is 3 as it provides a logical reasoning for the issue with dataset usage and highlights specific experimental results that are unusual. However, the comment lacks detailed references or examples to fully substantiate the claim, making it 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two main issues with the article: the use of a subset of the dataset and the lack of performance comparisons with stateoftheart models, which makes it difficult to demonstrate the effectiveness of the proposed methods. It also points out peculiar experimental results, such as the unsupervised result outperforming the supervised result in the 5th row of Table 2. While the comment highlights these issues, it does not provide specific suggestions or guidance on how the authors might address them, such as suggesting additional experiments or comparisons. The feedback is 3 as it points out areas for improvement but lacks actionable details, leaving the authors with a general idea of what needs to be addressed without clear direction on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific aspects need clarification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment points out that the phrase \"lacks inherent semantic meaning\" is used but not further elaborated upon. However, it does not specify which part of the paper this phrase is mentioned in, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the phrase need elaboration or clarification. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the phrase \"lacks inherent semantic meaning\" is used but not elaborated upon. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the phrase \"lacks inherent semantic meaning\" is used but not elaborated upon, indicating a lack of clarity in the paper. However, the comment does not provide specific guidance or suggestions on how the authors might address this issue or improve the clarity of the phrase. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights two issues: the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros, which is not justified. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific actions for the authors to take. The authors are left to infer that they need to provide more details and justification for their choices and address the potential bias, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses two specific issues: the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, and the potential bias introduced by treating unobserved ratings as zeros, which is not justified. However, it does not specify which part of the paper discusses these topics, making it difficult for the authors to pinpoint the exact sections that need revision. The comment is specific in detailing what needs to be addressed but lacks grounding as it does not reference specific sections or elements of the paper. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the authors do not provide sufficient details or justification for using a large number of hidden units and an additional elementwise function. It also criticizes the treatment of unobserved ratings as zeros, suggesting that this approach may introduce bias without justification. While the comment identifies specific issues, it lacks detailed reasoning or examples to fully substantiate the claims. The authors would need to infer the lack of justification and potential bias, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment identifies two specific areas where the paper could be improved. It points out the lack of sufficient details or justification for using a large number of hidden units and an additional elementwise function, which is crucial for understanding the methodology. Additionally, it highlights a potential bias introduced by treating unobserved ratings as zeros, which is not justified. While the comment effectively identifies weaknesses, it lacks specific suggestions or guidance on how the authors might address these issues. Providing more detailed feedback or actionable steps would enhance its helpfulness. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out a lack of robustness in the claim regarding motivation, suggesting that the high accuracy achieved by MathGLM on a constructed dataset for complex computations could be replicated with 100% accuracy using other tools. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or improve the robustness of their claim. The action is implicit and vague, as it does not specify how to demonstrate the lack of robustness or what steps should be taken to enhance the claim. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific claim regarding the motivation, suggesting that the high accuracy achieved by MathGLM on a constructed dataset for complex computations could be replicated with 100% accuracy using other tools. However, it does not specify which part of the paper this claim is made in, making it weakly grounded. The comment is specific in detailing the issue with the claim, suggesting that the authors should address the lack of robustness in their motivation. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the claim regarding motivation is not robust, suggesting that the high accuracy achieved by MathGLM on a constructed dataset for complex computations could be replicated with 100% accuracy using other tools. This claim is 3 as it provides a logical reasoning by pointing out the potential for replication with other tools, which could undermine the uniqueness or significance of MathGLM\"s results. However, the comment lacks specific examples or references to other tools that could achieve the same accuracy, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper\"s claim regarding motivation, specifically questioning the robustness of the motivation presented. It points out that the high accuracy achieved by MathGLM on a constructed dataset for complex computations could be replicated with 100% accuracy using other tools. This feedback is 3 as it highlights a critical issue that the authors need to address to strengthen their claim. However, the comment lacks specific suggestions or guidance on how the authors might address this concern or improve the robustness of their motivation. Therefore, the comment provides some insight but does not offer comprehensive guidance, aligning with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a lack of clarity in the motivation of the paper, suggesting that it opposes a common understanding without strong justification. It also points out that the experiments are limited in terms of dataset and LLM size, and the results are unconvincing. However, the comment does not provide explicit guidance on how the authors should address these issues or what specific changes are needed to improve the motivation or experimental design. The feedback is vague and lacks concrete suggestions, leaving the authors uncertain about how to proceed. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment addresses the motivation of the paper, suggesting that it opposes a common understanding without strong justification. It also critiques the experiments, noting that the dataset and LLM size are limited, and the results are unconvincing. However, the comment does not specify which sections of the paper discuss the motivation or the experiments, making it weakly grounded. The authors can infer that it relates to the introduction or motivation sections, but this inference is not direct. The comment is specific in detailing the issues with the motivation and the experiments, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the motivation of the paper is unclear and opposes a common understanding without strong justification. It also critiques the experiments, noting that the dataset and LLM size are limited, and the results are unconvincing. The comment provides some reasoning by pointing out the lack of justification for opposing a common understanding and the limited scope of the experiments. However, it lacks specific examples or references to support the claim about the motivation being unclear. The critique of the experiments is 3, as it highlights the limitations of the dataset and LLM size, but it could be strengthened with more detailed analysis or comparisons to similar studies. Therefore, the comment is rated as 3, as it provides some justification but lacks comprehensive evidence or references to fully substantiate the claims.", "helpfulness_rationale": "The review comment identifies a lack of clarity in the motivation of the paper, suggesting that it opposes a common understanding without strong justification. It critiques the experiments, noting that the dataset and LLM size are limited, and the results are unconvincing. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or strengthen their motivation and experimental design. The feedback is 3 as it points out areas needing attention, but it could be more actionable with detailed suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the absence of confidence intervals in Table 3, specifically regarding the substitution ASR. While it identifies a potential issue, it does not provide explicit guidance on how the authors should address this concern. The comment implies that the authors should consider adding confidence intervals, but it lacks concrete instructions on how to do so or what specific aspects of the confidence intervals should be included. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the absence of confidence intervals on the substitution ASR in Table 3. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the absence of confidence intervals in Table 3. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies a specific issue with Table 3, noting the absence of confidence intervals on the substitution ASR. This is a clear and actionable piece of feedback that highlights a potential gap in the presentation of results. By pointing out this omission, the comment provides the authors with a concrete direction to improve their draft, specifically suggesting that confidence intervals should be included. However, the comment could be more helpful if it offered additional guidance on how to incorporate these intervals or why they are important. Overall, the comment is 4 as it directs the authors to a specific area for improvement, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a lack of clarity regarding how to obtain or estimate the mean element mu_g for different kernel spaces. While it identifies a specific issue, it does not provide explicit guidance or suggestions on how the authors might address this problem. The action is implicit, as the authors need to infer that they should clarify or provide a method for estimating mu_g. However, the comment lacks concrete details on how to achieve this, making it somewhat vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment highlights a lack of clarity regarding how to obtain or estimate the mean element mu_g for different kernel spaces. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs attention. While the authors might have an idea of where this information is typically addressed, the comment lacks full grounding. It is specific in identifying the issue of unclear methodology for estimating mu_g, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the clarity of how to obtain or estimate the mean element mu_g for different kernel spaces. However, it does not provide any supporting evidence, reasoning, or examples to justify why this is a significant issue or how it affects the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, namely the lack of clarity regarding how to obtain or estimate the mean element mu_g for different kernel spaces. This feedback is clear and actionable, as it highlights a critical area where the paper may be lacking in detail or explanation. By addressing this issue, the authors can improve the comprehensibility and robustness of their methodology. However, the comment could be more helpful if it provided suggestions on how to approach this problem or offered examples of similar methods used in the field. Overall, the comment is 4 as it points out a significant area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. While the comment implies that the authors should explore this approach, it does not explicitly instruct them to do so. The action is inferred and somewhat vague, as the authors are left to determine how to implement this suggestion. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, it does not specify which part of the paper this suggestion pertains to, such as a particular section or analysis. The authors might infer that it relates to the discussion of datasets or experimental results, but this inference is not direct. The comment is specific in suggesting a particular dataset to consider, but it lacks grounding as it does not clearly identify the part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. However, the comment lacks specific reasoning or evidence to support why this approach would be beneficial or how it would enhance the study. Without detailed justification or examples, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 2.", "helpfulness_rationale": "The review comment suggests considering datasets with a larger number of clusters, such as ImageNet with reduced samples and feature dimensions, to make the story more complete. While the comment identifies a potential area for improvement, it lacks specific guidance or examples on how to implement this suggestion or why it would be beneficial. The feedback is 3 as it points out a potential enhancement to the study, but it does not provide detailed instructions or reasoning to fully support the authors\" understanding of the suggestion. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the suitability of using cosine similarity score versus Euclidean distance for computing the Decidability. However, it does not provide any explicit or implicit suggestions for action. The comment lacks guidance on whether the authors should consider using cosine similarity score, how it might affect the results, or if it would indeed work better. Without any actionable advice or detailed reasoning, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the suitability of using cosine similarity score versus Euclidean distance for computing the Decidability. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspect of the comparison is unclear or needs further exploration. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the suitability of using cosine similarity score versus Euclidean distance for computing the Decidability. However, it does not provide any supporting evidence, reasoning, or references to justify why this question is important or how it might impact the results. The comment lacks specific examples or detailed explanations, making it difficult for the authors to understand the basis of the question or how to address it. As a result, the claim is 1.", "helpfulness_rationale": "The review comment raises a relevant question about the suitability of using cosine similarity score versus Euclidean distance for computing the Decidability. This is a valuable point that could help the authors improve their draft by considering different metrics for evaluation. However, the comment lacks depth and does not provide specific suggestions or guidance on how to address this question or what aspects of the comparison might be more appropriate. While it identifies an area for improvement, the feedback is incomplete and could be more helpful with additional context or suggestions. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights several issues with the experiments conducted in the paper, including the lack of a toy experiment and comparison with other counterpart methods. It also notes that the experimental results are insufficient to validate the effectiveness of the proposed method. While the comment identifies specific areas for improvement, it does not provide explicit guidance on how to address these issues or suggest specific experiments or comparisons to include. The authors are left to infer that they need to conduct additional experiments and include comparisons with other methods, but without concrete instructions, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the experiments conducted in the paper, specifically mentioning the lack of a toy experiment and comparison with other counterpart methods. It also notes that the experimental results are insufficient to validate the effectiveness of the proposed method. However, the comment does not specify which sections of the paper contain these experiments or comparisons, making it weakly grounded. The authors can infer that it relates to the experimental section, but this inference is not direct. The comment is specific in detailing the issues with the experiments, such as the lack of a toy experiment and comparison with other methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the experiments are weak, citing the lack of a toy experiment and comparison with other counterpart methods. It also notes that the experimental results are insufficient to validate the effectiveness of the proposed method. While the comment identifies specific areas for improvement, it lacks detailed reasoning or examples to fully substantiate the claim. The absence of specific references or detailed explanations makes it 3, as the authors would need to infer the basis of the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies several weaknesses in the experimental section of the paper. It points out the lack of a toy experiment and the absence of comparison with other counterpart methods, which are crucial for validating the effectiveness of the proposed method. Additionally, it notes that the experimental results are insufficient to support the claims made in the paper. While the comment highlights important areas for improvement, it lacks specific suggestions or guidance on how to address these issues, such as recommending additional experiments or comparisons. This limits the comment\"s usefulness, as it provides a general direction for improvement but does not offer detailed, actionable feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. While it identifies a missing reference, it does not explicitly instruct the authors to add these references or specify which figures are missing. The action is implicit, as the authors can infer that they need to reference these figures in the analysis sections, but the comment lacks concrete guidance on how to do so. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment identifies a specific issue with the figures related to completion errors not being referenced in the relevant analysis sections of the appendix. This provides clear guidance on what needs to be addressed, making the comment specific. However, it does not explicitly mention which figures or sections are missing references, leaving the authors to infer the exact parts of the paper that need attention. Therefore, the comment is weakly grounded but specific, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the figures related to completion errors are not referenced in the relevant analysis sections of the appendix. This is a clear and actionable piece of feedback that highlights a missing element in the paper\"s structure and presentation. By pointing out this omission, the comment provides the authors with a concrete step to take in organizing their appendix to ensure all figures are appropriately referenced. However, the comment could be more helpful if it suggested how to integrate these references or provided examples of how to do so. Overall, the feedback is 4 as it directs the authors\" attention to a critical omission, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the consistency of perplexity measurements across different validation sets at various levels. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to ensure consistency. Without any actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the consistency of perplexity measurements across different validation sets at various levels. However, it does not specify which part of the paper this issue pertains to, making it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the measurements are unclear or how they could be improved. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point raises a question about the consistency of perplexity measurements across different validation sets at various levels. However, it does not provide any supporting evidence, reasoning, or references to justify why this is an issue or how it affects the paper. Without additional context or explanation, the authors may find it challenging to understand the significance of the question or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment raises a question about the consistency of perplexity measurements across different validation sets at various levels. While it identifies a potential area of concern, it does not provide any guidance or suggestions on how the authors might address this issue or improve their methodology. The comment lacks actionable advice or specific recommendations, making it 2. The authors are left with a vague point of concern but no clear path forward for improvement. Therefore, the comment aligns with a score of 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the originality and innovation of the setting and algorithm, suggesting that they might seem incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment highlights a potential issue with originality, it does not provide explicit guidance or suggestions on how the authors could address this concern or enhance the originality of their work. The feedback lacks actionable details, leaving the authors uncertain about how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses an opinion about the originality and innovation of the setting and algorithm, suggesting that they might seem incremental combinations of existing methods. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the algorithm or setting could be improved. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment lacks specificity and grounding, making it difficult for the authors to pinpoint the exact areas needing improvement. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point expresses an opinion about the originality and innovation of the setting and algorithm, suggesting that they might seem incremental combinations of existing methods. However, it also acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment provides some reasoning about the potential lack of originality, it lacks specific examples or references to support the claim that the methods are incremental. This makes the claim 3, as the authors would need to further explore and substantiate the critique themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment expresses a concern about the originality and innovation of the setting and algorithm, suggesting that they might seem incremental combinations of existing methods. However, it acknowledges the efficiency and novelty of the algorithm for graph labelings. While the comment highlights a potential weakness in the originality of the work, it does not provide specific suggestions or guidance on how the authors could address this concern or enhance the originality of their work. The feedback is 3 as it identifies an area for improvement but lacks actionable advice, making it less valuable for the authors to use in refining their draft."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that using the state action of the current policy in the target environment as regularization could harm learning, as a suboptimal policy might lead to a suboptimal state action distribution used for regularization. However, the comment does not provide explicit guidance or suggestions on how the authors should address this issue or what specific changes to make to mitigate the potential harm. The action is implicit, as the authors can infer that they need to consider the impact of their regularization method, but the comment lacks concrete details on how to implement this change. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment critiques the use of the state action of the current policy in the target environment as a form of regularization, suggesting that this could harm learning. However, it does not specify which part of the paper this critique is based on, making it weakly grounded. The comment is specific in its critique of the potential harm to learning, but without clear grounding, the authors may struggle to identify the exact section that needs revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that using the state action of the current policy in the target environment as regularization can harm learning. However, the comment lacks specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 2, as it provides a general observation but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the state action of the current policy in the target environment as a form of regularization. It highlights that this approach could harm learning, as a suboptimal policy might lead to a suboptimal state action distribution used for regularization. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their approach. While it points out a potential weakness, it lacks actionable advice, making it 3. The authors would need to infer that they should consider the impact of their regularization method and possibly adjust it, but the comment does not fully support them in making these improvements. Therefore, the comment is rated as 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two questions: \"What is the insight from this work to develop new methods?\" and \"How to prevent the attention collapse in CL?\" These questions imply that the authors should provide insights or suggestions on how their work can contribute to the development of new methods and address the issue of attention collapse in CL. However, the comment does not explicitly instruct the authors to provide these insights or suggestions, nor does it offer concrete guidance on how to address the attention collapse issue. The action is implicit and somewhat vague, as the authors need to infer what needs to be done and how to apply the suggestions. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment raises two questions: \"What is the insight from this work to develop new methods?\" and \"How to prevent the attention collapse in CL?\" However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to identify the exact sections that need attention. The questions are general and do not provide specific guidance on what needs to be addressed or improved. As a result, the comment lacks grounding and specificity, aligning with a score of 1.", "verifiability_rationale": "The review point consists of two questions asking for clarification on the insights from the work and the issue of attention collapse in CL. These are not claims or opinions but rather requests for further explanation or discussion. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises two questions: \"What is the insight from this work to develop new methods?\" and \"How to prevent the attention collapse in CL?\" These questions are relevant and could guide the authors in clarifying the significance of their work and addressing a potential issue. However, the comment does not provide specific suggestions or guidance on how to answer these questions or address the attention collapse issue. While it points out areas for improvement, it lacks depth and actionable advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a specific area of the paper that needs clarification, namely the impact of the CHC model on the capabilities of MLLMs. It suggests that the authors should provide more detailed explanations, including specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. Additionally, it implies that the authors should include case studies or pilot experiments to illustrate the significance of this influence. While the comment identifies a clear area for improvement, it does not provide explicit instructions on how to address these issues or what specific details should be included. The action is implicit and somewhat vague, as the authors need to infer the necessary steps to improve their draft. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the paper\"s content, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue of unclear explanations regarding the impact of the CHC model on MLLMs\" capabilities, asking for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. Additionally, it suggests the inclusion of case studies or pilot experiments to illustrate the significance of this influence. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the extent to which the paper discusses the impact of the CHC model on MLLMs\" capabilities. It suggests that the paper should provide more detailed explanations, including specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. The comment implies that the authors should include case studies or pilot experiments to illustrate the significance of this influence. However, the comment does not provide specific examples or references to support the claim, making it 3. The authors would need to infer the necessary details to address the feedback effectively.", "helpfulness_rationale": "The review comment identifies a specific area of the paper that requires clarification, namely the impact of the CHC model on the capabilities of MLLMs. It questions how the CHC model affects these capabilities and asks for specific attributes or behaviors that a powerful MLLM grounded in CHC theory would exhibit. Additionally, it suggests the inclusion of case studies or pilot experiments to illustrate the significance of this influence. This feedback is clear and actionable, providing the authors with a concrete direction for improving the clarity and depth of their paper. However, it could be more helpful if it offered specific examples or guidance on how to address these questions. Overall, the comment is 4, as it effectively guides the authors toward enhancing their draft."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors consider integrating more recent pretraining models, such as those mentioned in the references, to enhance the significance and practical usage of their approach. The comment provides specific examples of recent works that could be relevant, offering a clear and concrete action for the authors to take. By recommending the inclusion of these models, the comment gives the authors a specific direction to improve their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests integrating more recent pretraining models, such as those mentioned in the references, to enhance the significance and practical usage of the approach. However, it does not specify which part of the paper should include these models or how they should be integrated. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in suggesting the inclusion of recent models, but it lacks grounding as it does not explicitly mention the sections or parts of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the pretraining model, PreGNN (Hu et al., 2020), is relatively old and recommends integrating more recent models to showcase the significance and practical usage of the approach. The reviewer supports this claim by providing specific references to recent works, such as \"UniCorn\" and \"Adapting Differential Molecular Representation,\" which are relevant to the topic. This provides a clear rationale and examples, making the claim 4. However, the comment could be strengthened by further elaboration on how these recent models would enhance the approach or by providing more context on why they are more relevant. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by pointing out that the pretraining model, PreGNN (Hu et al., 2020), is relatively old in the context of molecular pretraining. It suggests that the authors consider integrating more recent and powerful models to enhance the significance and practical usage of their approach. The comment is 4 as it provides a clear and actionable suggestion for the authors to incorporate more uptodate models, which could strengthen their work. However, it could be more helpful if it offered specific examples or guidance on how to integrate these models effectively. Overall, the feedback is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a potential engineering challenge with the model\"s input, which is the difference between the current object pose and the target object pose. It acknowledges that this can be a significant issue in realworld applications due to difficulties in object segmentation and pose tracking. However, it does not provide any explicit or implicit suggestions for how the authors might address this challenge or improve their approach. The comment lacks actionable guidance, leaving the authors without a clear path forward for potential improvements. As a result, the comment is 1.", "grounding_specificity_rationale": "The comment addresses the input of the model, specifically mentioning the difference between the current object pose and the target object pose. It acknowledges the potential engineering challenge this input presents and notes that the authors documented their approach well in Section A.3. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the input issue and the documentation of the approach, but it lacks grounding. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the model\"s input, which is the difference between the current object pose and the target object pose, can present significant engineering challenges. This claim is 3 as it highlights a potential issue with the model\"s input, which is a logical observation. However, the comment does not provide specific examples or references to support the claim about the difficulties in realworld applications, such as object segmentation and pose tracking. The mention of the authors\" documentation in Section A.3 adds some context but does not substantiate the claim further. Therefore, the comment is rated as 3, as it provides some reasoning but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the model\"s input, specifically the difference between the current object pose and the target object pose. It acknowledges the engineering challenges this input might present, particularly in realworld applications where object segmentation and pose tracking can be difficult. However, the comment does not provide specific suggestions or guidance on how the authors might address this challenge or improve their approach. While it highlights a potential weakness, it lacks actionable feedback, making it 3. The authors are given a starting point for consideration but are left without detailed direction on how to improve their work. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should provide more downstream performance evaluations for their controllable text generation models, specifically mentioning style transfer as a potential area to explore. However, the comment does not provide explicit guidance on how to conduct these evaluations or what specific aspects should be emphasized. The authors are informed that they have addressed most of the previous comments and suggestions, but the current comment itself does not offer concrete steps for improvement. The action is implicit and vague, leaving the authors uncertain about how to proceed. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Lines 116117,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting that the authors should provide more downstream performance evaluations for their controllable text generation models, particularly focusing on style transfer as a potential area to explore. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should provide more downstream performance evaluations for their controllable text generation models, specifically mentioning style transfer as a potential area to explore. However, the comment does not provide specific examples or detailed reasoning to support why style transfer is a suitable choice or how it would demonstrate the advantage of the proposed models. The lack of explicit justification or evidence makes the claim 3, as the authors would need to infer the reasoning behind the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the authors should provide more downstream performance evaluations for their controllable text generation models, specifically mentioning style transfer as a potential area to explore. This feedback is 3 as it identifies a specific area for improvement and provides a direction for the authors to consider. However, the comment lacks depth and does not offer detailed guidance or examples on how to conduct these evaluations or what specific aspects should be emphasized. While it prompts the authors to expand their analysis, it does not fully support the suggestion with actionable steps, making it 3 but incomplete."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point expresses confusion about the test set performance on GLUE datasets, specifically questioning whether the labels for these sets are publicly available. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this confusion or what steps they should consider to clarify or resolve it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"GLUE datasets,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises a question about the availability of labels for the test set performance on these datasets, which provides clear guidance on what needs to be clarified or addressed. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point expresses confusion about the test set performance on GLUE datasets, specifically questioning whether the labels for these sets are publicly available. However, it does not provide any supporting evidence, reasoning, or references to justify this claim. The lack of detailed explanation or context makes it difficult for the authors to understand the basis of the concern or how to address it. As a result, the comment is considered 1.", "helpfulness_rationale": "The comment raises a question about the availability of labels for the test set performance on GLUE datasets, which could be a source of confusion for readers. However, it does not provide any actionable feedback or suggestions on how the authors might address this issue or clarify the situation. Without specific guidance or recommendations, the comment lacks clarity and does not assist the authors in improving their draft. Therefore, it is rated as 2, as it identifies a potential issue but does not offer a clear path for resolution."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that Section 3.2 may be shortened because many equations are already known in the community and not proposed by the work. This implies that the authors should consider removing these equations to save space and include more important details. While the action is implicit, it is concrete because it specifies which part of the section should be shortened and what the benefit of doing so is. The authors know exactly what needs to be addressed to improve their draft. Therefore, this comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests that many equations in this section are already known in the community and proposes shortening the section to save space and include more important details. This provides clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that Section 3.2 may be shortened because many equations are already known in the community and not proposed by the work. This claim is 3 as it provides a logical reasoning for shortening the section, but it lacks specific examples or references to support the assertion that these equations are already known. The comment could be strengthened by providing more detailed information or references to the known equations, making it easier for the authors to understand and address the suggestion. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that Section 3.2 may be shortened because many equations are already known in the community and not proposed by the work. This feedback is actionable as it provides a clear and specific suggestion for improving the draft by saving space and including more important details. By shortening the section, the authors can focus on presenting novel contributions and avoid redundancy. However, the comment could be more helpful if it included examples of the known equations or suggested how to integrate the important details more effectively. Overall, the comment is 4 as it offers a clear direction for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point raises a question about the evaluation methods used in specific figures and tables, but it does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors should address this issue or what changes are needed. Without any suggestions or recommendations, the authors are left without a clear understanding of what to do to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 3,\" \"Table 3,\" and \"Figure 5,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the evaluation method used between automatic and human evaluation in these figures and tables. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the evaluation methods used in specific figures and tables. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the evaluation methods used in specific figures and tables, which could be crucial for understanding the methodology and results presented in the paper. However, it does not provide any guidance or suggestions on how the authors might address this issue or improve their draft. The comment lacks actionable feedback, leaving the authors without a clear path to enhance their work. Therefore, it is rated as 2, as it identifies a potential area for improvement but does not offer actionable advice."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that using one translator per language for annotations may not be sufficient due to the diversity in choices among different translators. However, it does not provide explicit guidance on how the authors should address this issue or what specific actions they should take to improve their annotations. The comment implies that the authors should consider using multiple translators or a more diverse approach, but it lacks concrete steps or examples on how to implement this suggestion. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of using different choices of translators for annotations, suggesting that using one translator per language may not be sufficient. However, it does not specify which part of the paper this issue is discussed in, making it difficult for the authors to pinpoint the exact section that needs revision. The comment is specific in its critique of the approach, but without clear grounding, it lacks specificity. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that using one translator per language for annotations may not be sufficient due to the diversity in choices among different translators. However, the comment lacks specific examples or references to support this claim, making it difficult for the authors to understand the basis of the critique or how to address it. The absence of detailed reasoning or evidence makes the claim 2, as it provides some intuition but lacks the necessary support to fully substantiate the argument.", "helpfulness_rationale": "The review comment raises a concern about the diversity of choices among different translators and suggests that using one translator per language for annotations may not be sufficient. This feedback is 3 as it identifies a potential limitation in the methodology or approach used in the paper. However, it lacks specific guidance or suggestions on how the authors might address this issue or improve their annotation process. The comment provides a starting point for the authors to consider, but it does not offer detailed advice or examples on how to enhance the annotation process. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about the original statement, \"people wear a hat and play guitar not vice versa,\" and asks, \"why not?\" However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this question or what changes could be made to the paper. Without specific suggestions or actions, the authors are left without a clear understanding of what to do in response to this feedback. Therefore, the comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the original statement, \"people wear a hat and play guitar not vice versa,\" but it does not specify which part of the paper this statement is from or where it appears. This lack of grounding makes it difficult for the authors to identify the exact section or context that needs attention. Additionally, the comment does not provide specific guidance or suggestions on how to address the question or improve the paper. As a result, the comment is 1 and lacks specificity, making it difficult for the authors to act on the feedback. Therefore, this comment aligns with a score of 1.", "verifiability_rationale": "The review point consists of a question asking for clarification about a statement, \"people wear a hat and play guitar not vice versa.\" It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, making it a normal statement. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the original statement, \"people wear a hat and play guitar not vice versa,\" but it does not provide any context or explanation for why this statement is being questioned. It lacks specificity and does not offer any actionable feedback or suggestions for improvement. Without additional information or guidance, the authors are left without a clear understanding of what aspect of the statement needs clarification or how it might be improved. As a result, the comment is 1, aligning with a score of 1."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review point suggests that 2000 examples may be insufficient for the model to learn a transformation correctly. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on whether the authors should increase the number of examples, what specific examples to use, or how to address the issue. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment suggests that 2000 examples may be insufficient for the model to learn a transformation correctly. However, it does not specify which part of the paper this issue is related to, such as a particular section, table, or figure. Without explicit references, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding what aspects of the model or learning process might be affected by the number of examples. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"2000 examples may be insufficient for the model to learn this transformation correctly.\" However, it does not provide any supporting evidence, reasoning, or references to justify why 2000 examples might be insufficient. Without additional context or explanation, the authors may find it challenging to understand the basis of this claim and address it effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the number of examples used in the study, suggesting that 2000 examples may be insufficient for the model to learn a transformation correctly. However, the comment lacks specificity and does not provide any guidance or suggestions on how the authors might address this issue or what additional steps could be taken to improve the model\"s learning process. Without actionable feedback or detailed reasoning, the authors are left without a clear path forward for improving their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the differences between Algorithm 1 and variational inference, specifically regarding the use of a Gaussian distribution to approximate the target distribution. While it prompts the authors to explain the differences and advantages, it does not provide explicit instructions or concrete guidance on how to address these points. The action is implicit and somewhat vague, as the authors need to infer that they should clarify these aspects in their paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by asking about the differences between Algorithm 1 and variational inference, as well as the advantages of the approach. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the differences between Algorithm 1 and variational inference, as well as the advantages of the approach. It does not contain any subjective claims, opinions, or suggestions that require verification. Therefore, it is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a question about the differences between Algorithm 1 and variational inference, specifically regarding the use of a Gaussian distribution to approximate the target distribution. While it prompts the authors to clarify these aspects, it does not provide specific guidance or suggestions on how to address these points. The comment is 3 as it identifies an area for improvement, but it lacks depth and actionable advice, making it less valuable for the authors to use effectively. Therefore, it aligns with a score of 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the entailment exercise lacks basic details and that it is difficult to assess the efficacy of the technique based on the information provided in the paper. It suggests that the exercise should either be removed from the paper or provided with more empirical and analyzed information. This feedback is clear and provides a direct action for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"entailment exercise,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the exercise, stating that it lacks basic details and that it is difficult to assess the efficacy of the technique. The comment suggests that the exercise should either be removed or provided with more empirical and analyzed information, offering a clear direction for improvement. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the entailment exercise lacks basic details, making it difficult to assess the efficacy of the technique. The reviewer suggests that the exercise should either be removed or provided with more empirical and analyzed information. However, the comment does not provide specific examples or references to support the claim that the exercise is lacking in detail. This lack of detailed justification or examples makes the claim 3, as the authors may find it challenging to understand and address the issue without further guidance. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that the entailment exercise lacks basic details, making it difficult to assess the efficacy of the technique. It provides a clear and actionable suggestion by recommending that the exercise be either removed from the paper or supplemented with more empirical and analyzed information. This feedback is valuable as it guides the authors on how to enhance the clarity and comprehensiveness of their work, ensuring that readers can better understand and evaluate the technique. However, the comment could be more helpful if it provided specific examples or suggestions on how to improve the exercise. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the mathematical expressions of the Gaussian distribution in lines 225 and 227 are ambiguous. However, it does not provide any explicit guidance or suggestions on how the authors should clarify these expressions. The comment lacks concrete details on what specific aspects are ambiguous or how the authors might improve the clarity of the expressions. As a result, the authors are left without a clear understanding of what steps to take to address the issue. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (225 and 227) where the mathematical expressions of the Gaussian distribution are ambiguous. This allows the authors to accurately identify the parts of the paper being addressed. Additionally, the comment is specific because it clearly specifies what is wrong with these expressions, namely that they are ambiguous. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the mathematical expressions of the Gaussian distribution in lines 225 and 227 are ambiguous. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why these expressions are ambiguous or how they could be clarified. Without additional context or explanation, the authors may find it challenging to understand and address the issue. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the mathematical expressions of the Gaussian distribution in lines 225 and 227, noting that they are ambiguous. While it highlights a potential area for improvement, it lacks detailed guidance or suggestions on how the authors might clarify these expressions. The comment provides some actionable feedback but does not offer a comprehensive or constructive approach for the authors to address the issue. Therefore, the comment is 3, as it points out a problem but does not fully support the authors in making improvements."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the current testing approach is insufficient because it only uses a limited set of tokens. It implies that additional types of responses should be considered to improve the testing. However, the comment does not provide specific guidance on which additional types of responses to include or how to implement this suggestion. The action is implicit and somewhat vague, as the authors know they need to consider more response types but are not given concrete steps on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests that the current testing approach is insufficient because it only uses a limited set of tokens. However, it does not specify which tokens are being used or where in the paper this issue is discussed, making it weakly grounded. The comment does specify what needs to be addressed, namely the consideration of additional types of responses, which adds some level of specificity. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the current testing approach is insufficient because it only uses a limited set of tokens. However, it does not provide any specific examples, reasoning, or references to support why additional types of responses should be considered. The lack of detailed justification or evidence makes it difficult for the authors to understand the basis of the claim and how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a potential limitation in the testing approach, noting that it only uses a limited set of tokens. It suggests that additional types of responses should be considered to enhance the testing. While the comment highlights an area for improvement, it lacks specific guidance or examples on how to implement this suggestion or what additional response types might be beneficial. This limits the comment\"s usefulness, as it provides a general direction but not detailed actionable feedback. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point highlights a concern about the privacy protection capability, specifically noting that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also mentions that relying solely on manipulating the temperature (T) may not effectively achieve text sanitization. While the comment identifies a potential issue, it does not provide explicit guidance on how to address it or suggest specific actions for the authors to take. The authors are left to infer that they need to improve their privacy protection mechanisms, but without concrete steps, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the privacy protection capability, specifically mentioning the use of chatGPT for text paraphrasing and the potential insufficiency of relying on temperature manipulation for text sanitization. However, it does not specify which part of the paper discusses these issues, making it weakly grounded. The comment is specific in detailing the concern about the privacy protection capability and the potential insufficiency of the current methods. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the privacy protection capability is insufficient, specifically mentioning the use of chatGPT for text paraphrasing and the reliance on temperature manipulation. The reviewer provides a logical reasoning by explaining that this approach may not effectively remove privacy information. However, the comment lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the issue to fully understand and address the concern. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the privacy protection capability of the paper, specifically pointing out that the use of chatGPT for text paraphrasing does not guarantee the removal of privacy information. It also highlights the potential insufficiency of relying solely on temperature manipulation for text sanitization. This feedback is clear and actionable, as it directs the authors to reconsider their approach to ensuring privacy protection in their work. However, the comment could be more helpful if it provided suggestions on how to improve the privacy protection mechanism or alternative methods to achieve text sanitization. Overall, the comment is 4 as it highlights a critical area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment points out that the manuscript describes an approach in sentiment analysis using word embeddings to define the weight of each lexicon term, but it claims that the novelty is not significant enough. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address the perceived lack of novelty or what specific changes could be made to enhance the manuscript\"s contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment provides a general critique of the manuscript\"s approach in sentiment analysis, mentioning the use of word embeddings to define the weight of each lexicon term. However, it does not specify which part of the paper this critique is based on, making it difficult for the authors to pinpoint the exact section that needs revision. Additionally, the comment lacks specificity regarding what aspects of the approach are considered lacking in novelty. As a result, the comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the manuscript\"s approach in sentiment analysis is not significant enough. However, it does not provide any specific examples, references, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment provides a general critique of the manuscript\"s approach in sentiment analysis, noting that the novelty of the method using word embeddings to define the weight of each lexicon term is not significant enough. However, the comment lacks specificity and does not offer actionable feedback or suggestions on how the authors might enhance the novelty or significance of their approach. Without detailed guidance or examples, the authors are left without a clear path to improve their draft. Therefore, the comment is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. This feedback provides a clear and explicit action for the authors to take, which is to include such a comparison. The comment also specifies what needs to be done\u2014comparing the proposed method to nonNeRF methods\u2014and how it can help readers understand the method\"s advantages. However, it does not provide detailed guidance on how to conduct this comparison or what specific aspects to focus on. While the action is clear, the lack of detailed instructions makes it 3.", "grounding_specificity_rationale": "The comment suggests comparing the proposed method to nonNeRF methods on the mentioned tasks, which implies that it is relevant to the sections discussing the methodology or results. However, it does not explicitly mention which part of the paper this comparison should be made in, making it weakly grounded. The comment is specific in suggesting a comparison to nonNeRF methods, which provides clear guidance on what needs to be addressed. Therefore, the comment is weakly grounded but specific, aligning with category 3.", "verifiability_rationale": "The review point suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. This claim is 3 as it provides a logical reasoning for why such a comparison would be beneficial, helping readers understand the proposed method\"s advantages. However, the comment lacks specific examples or references to nonNeRF methods, which would strengthen the justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests that the paper could benefit from comparing its method to nonNeRF methods on the mentioned tasks. This feedback is clear and actionable, as it provides a specific area for improvement that could enhance the paper\"s understanding and evaluation of the proposed method. By comparing to nonNeRF methods, the authors can better position their work within the broader context of related research and highlight the advantages of their approach. However, the comment could be more helpful if it provided guidance on how to conduct this comparison or what specific aspects to focus on. Overall, the comment is 4 as it offers a concrete suggestion for improvement, aligning with a score of 4."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the use of the term \"NLU\" in the paper, specifically questioning whether some of the lowerlevel tasks might be considered syntactic tasks rather than NLU. However, it does not provide explicit guidance or suggestions on how the authors should address this issue. The comment implies that the authors should clarify the terminology, but it lacks concrete steps or examples of how to do so. As a result, the action is implicit and vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the line numbers (178:181), allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the use of the term \"NLU\" and whether some of the lowerlevel tasks might be considered syntactic tasks. This provides clear guidance on what needs to be clarified or addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the use of the term \"NLU\" in the paper, specifically questioning whether some of the lowerlevel tasks might be considered syntactic tasks rather than NLU. The comment references a specific literature, \"LINSPECTOR: Multilingual Probing Tasks for Word Representations,\" which provides a basis for the claim. However, the comment does not elaborate on how this literature relates to the issue of terminology or how it might impact the interpretation of the tasks described in the paper. While the reference is relevant, the lack of detailed explanation or connection to the specific issue makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the use of the term \"NLU\" in the paper, specifically questioning whether some of the lowerlevel tasks might be considered syntactic tasks rather than NLU. This feedback is 3 as it highlights a potential ambiguity in terminology that could affect the interpretation of the tasks described in the paper. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue, such as clarifying the terminology or providing examples of tasks that might be considered syntactic. Without actionable advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 3, indicating that the comment is 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors should briefly discuss the relationship of their idea to traditional attempts in computer vision, specifically mentioning the use of longterm motion trajectories and the comparison between Eulerian and Lagrangian views. While the comment implies that this discussion would strengthen the theoretical and academic value of the approach, it does not explicitly instruct the authors to include this discussion. The action is implicit and somewhat vague, as the authors need to infer that they should add a brief discussion on the relationship to traditional methods. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of longterm motion trajectories and references a specific paper, allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the suggestion to discuss the relationship of the authors\" idea to traditional attempts in computer vision, particularly in the context of motion trajectory segmentation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that using longterm motion trajectories is a traditional idea in computer vision, particularly for motion segmentation, and suggests that the authors should briefly discuss the relationship of their idea to these traditional attempts. The comment provides a reference to a specific paper (a) that discusses motion trajectory segmentation, which supports the claim about the traditional nature of the idea. However, the comment does not provide additional examples or detailed reasoning to fully substantiate the claim, leaving some gaps in the justification. Therefore, the comment is 3, as it provides some support but lacks comprehensive evidence or detailed explanation.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper by noting that the use of longterm motion trajectories is a traditional idea in computer vision, particularly for motion segmentation. It suggests that the authors should briefly discuss the relationship of their idea to these traditional attempts, which could strengthen the theoretical and academic value of their approach. The comment provides a clear and actionable suggestion for improvement by recommending a discussion on the relationship to traditional methods. However, it could be more helpful if it offered specific examples or references to how this discussion could be integrated into the paper. Overall, the comment is 4 as it guides the authors toward enhancing the depth and relevance of their work."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the problem formalization section lacks a clear description of the specific task types addressed on graph data, which makes the purpose of the section unclear. While it identifies a gap in the section, it does not provide explicit guidance on how to address this issue or what specific tasks should be included. The action is implicit, as the authors need to infer that they should provide a clearer description of the task types, but it is vague because it does not specify how to achieve this clarity. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"problem formalization section,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of a clear description of the specific task types addressed on graph data, and it highlights the purpose of the section being unclear. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the problem formalization section lacks a clear description of the specific task types addressed on graph data. However, the comment does not provide any supporting evidence, examples, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a significant issue with the problem formalization section, noting that it lacks a clear description of the specific task types addressed on graph data. This critique highlights a critical gap in the paper\"s purpose, as the section\"s goal is unclear without a clear task objective. The comment is 3 as it points out a specific area for improvement, but it could be more helpful if it provided suggestions on how to address the lack of clarity or examples of task types that could be included. Overall, the feedback provides some insight but lacks depth and actionable guidance, aligning with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of an ablation study on the training techniques introduced in the paper, specifically Informative Prior Initialization (IPI) and vprediction. It suggests that including such a study would help assess the impact of these techniques and allow for a direct comparison of YOSO\"s performance with other models that could benefit from these methods. While the comment implies that an ablation study should be conducted, it does not provide specific guidance on how to design or execute the study. The action is explicit but somewhat vague, as the authors know they need to include an ablation study but may not be entirely sure of the exact steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. It suggests that including such a study would help assess the impact of these techniques and allow for a direct comparison of YOSO\"s performance with other models. However, the comment does not specify which part of the paper should include this ablation study, making it weakly grounded. The comment is specific in detailing what is missing and why it is important, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks an ablation study on training techniques, specifically mentioning Informative Prior Initialization (IPI) and vprediction. The reviewer suggests that these techniques could benefit other models and that the absence of an ablation study makes it difficult to assess their impact. However, the comment does not provide specific examples or references to support the claim that these techniques are valuable or how an ablation study would clarify their impact. This lack of detailed justification or evidence makes the claim 3, as the authors would need to infer the importance of the ablation study and its potential benefits. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of an ablation study on the training techniques introduced, such as Informative Prior Initialization (IPI) and vprediction. It highlights the potential impact of these techniques on other models and suggests that an ablation study would be beneficial to assess their specific impact and compare YOSO\"s performance with other models. This feedback is clear and actionable, as it provides a specific area for improvement and offers a constructive suggestion for enhancing the paper\"s analysis. However, the comment could be more helpful if it included examples of how to conduct the ablation study or provided guidance on what aspects to focus on. Overall, the comment is 4, as it effectively directs the authors toward a meaningful enhancement of their work."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a limitation in the paper, noting that the content is limited and that there are redundant descriptions, specifically mentioning two paragraphs that redundantly describe the motivation and work approach already covered in the introduction. The reviewer also suggests that since the authors have mentioned the lack of domain knowledge in LLMs for specific tasks, it would be beneficial to present a smallscale validation experiment using any of the datasets mentioned in the paper. This feedback provides explicit actions for the authors to take, including identifying redundant content and suggesting a validation experiment. The comment is clear and provides concrete guidance on how to improve the paper, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific lines (line 229 to line 272) and provides a clear reference to the introduction, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it details the issue of redundant descriptions and suggests a smallscale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. This provides clear guidance on what needs to be improved. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is limited in content and contains redundant descriptions, specifically mentioning two paragraphs that redundantly describe the motivation and work approach already covered in the introduction. The reviewer also suggests a smallscale validation experiment to address the lack of domain knowledge in LLMs for specific tasks. While the comment identifies a specific issue with redundancy, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion for a validation experiment is logical but could be more robust with additional justification or references. Therefore, the comment is 3, as it provides some support but requires more detailed evidence to be fully convincing.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper, noting that the content is limited and contains redundant descriptions, specifically mentioning two paragraphs that redundantly describe the motivation and work approach already covered in the introduction. This feedback is valuable as it highlights a critical area for improvement, prompting the authors to streamline their content and avoid redundancy. Additionally, the comment suggests a smallscale validation experiment to address the lack of domain knowledge in LLMs for specific tasks, providing a concrete suggestion for enhancing the paper\"s contribution. While the comment is clear and actionable, it could be more helpful by offering specific examples or guidance on how to implement the suggested validation experiment. Overall, the feedback is 4, as it effectively guides the authors toward improving the paper\"s structure and content."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly instructs the authors to rewrite the section to clarify the connections between the theoretical contributions and the proposed method. It provides a clear action by specifying that the section should be rewritten to make the connections clearer. However, it does not provide specific guidance on how to rewrite the section or what specific aspects should be emphasized. While the action is explicit, the lack of detailed instructions on how to achieve this makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the section of the paper that discusses the theoretical contributions, allowing the authors to accurately identify the part being addressed. It is also specific because it clearly specifies the issue with the abstractness of the theoretical contributions and the lack of connection to the proposed method, particularly regarding the use of segregated feature vectors for backdoored vs. clean data and its relation to EigenGuard. The comment provides a clear request for rewriting the section to clarify these connections. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the theoretical contributions are too abstract and lack clarity in their connection to the proposed method. The reviewer provides a specific example of the abstractness by mentioning the use of segregated feature vectors for backdoored vs. clean data and its relation to EigenGuard. This detailed reasoning supports the claim, making it 4. However, the comment could be strengthened by providing more examples or references to further substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant issue with the theoretical contributions, noting that they are too abstract and lack clarity in their connection to the proposed method. It specifically points out the use of segregated feature vectors for backdoored vs. clean data and its relation to EigenGuard, suggesting that this aspect is artificial and not directly connected to the proposed method. The comment provides a clear and actionable suggestion to rewrite the section to clarify these connections, which would help the authors improve the clarity and relevance of their theoretical contributions. However, the comment could be more helpful if it offered specific guidance on how to rephrase the section or what aspects to emphasize. Overall, the feedback is 4 as it directs the authors to a critical area for improvement, but it could be more comprehensive with additional suggestions."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses uncertainty about whether the code will be released, particularly due to the difficulty of reproducing the GCN implementation without the original code. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this uncertainty or what steps they could take to clarify it. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the clarity of the code release, specifically mentioning the GCN implementation and the difficulty in reproducing it without the original code. However, it does not specify which part of the paper this issue pertains to, such as a particular section or figure where the implementation details are discussed. The authors might infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in identifying the issue of code reproducibility but lacks grounding as it does not pinpoint the exact part of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point expresses uncertainty about the release of the code, particularly due to the difficulty of reproducing the GCN implementation without the original code. However, it does not provide any supporting evidence, reasoning, or references to substantiate this claim. The comment lacks specific examples or detailed explanations that would help the authors understand the issue or how to address it. As a result, the claim is 1, making it difficult for the authors to make informed decisions based on this feedback. Therefore, the comment is rated as 1.", "helpfulness_rationale": "The review comment raises a concern about the reproducibility of the code, specifically noting that the GCN implementation may be difficult to reproduce without the original code, despite the detailed descriptions provided by the authors. This feedback highlights a potential issue with the transparency and accessibility of the work, which is an important aspect for reproducibility and verification in research. However, the comment does not offer specific suggestions or guidance on how the authors might address this issue, such as providing additional resources or clarifications. While it identifies a potential weakness, the lack of actionable advice limits its helpfulness. Therefore, the comment is 3, as it provides insight into a critical area but lacks detailed guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "4", "actionability_rationale": "The review point raises a question about the use of secondorder Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. While it implies that the authors should consider using the differential functions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they should replace the Taylor expansions with the differential functions. However, the comment provides a clear direction for improvement, making it 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Equations (9) and (10),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the use of secondorder Taylor expansions in place of differential functions. The comment requests clarification on why the differential functions were not used, providing a clear direction for improvement. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the use of secondorder Taylor expansions in Equations (9) and (10) instead of using the differential functions themselves. While the comment raises a valid point about the choice of approximation method, it does not provide any supporting evidence, reasoning, or references to justify why the differential functions should be used instead. This lack of detailed explanation or justification makes the claim 2, as the authors may find it challenging to understand the basis of the critique without further context or reasoning.", "helpfulness_rationale": "The review comment raises a specific question about the use of secondorder Taylor expansions in Equations (9) and (10), suggesting that the differential functions themselves might be more appropriate. This feedback is clear and actionable, as it prompts the authors to reconsider their choice of approximation method and potentially improve the accuracy or relevance of their equations. However, the comment could be more helpful if it provided additional context or reasoning for why the differential functions might be preferable, or if it suggested alternative approaches for comparison. Overall, the comment is 4 as it identifies a potential area for improvement and encourages the authors to explore a more precise method."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly identifies a missing element in Table 3, specifically the recall on lemmas/forms seen in training. It also provides references to support the claim, which adds context and helps the authors understand the issue. The comment is clear and actionable, as it specifies what is missing and suggests that the authors should include this information. The references provided offer additional context, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 3,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what is missing, namely the recall on lemmas/forms seen in training, and provides references to support the claim. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that encs BPE to character results are missing the recall on lemmas/forms seen in training. It supports this claim by referencing three external works that discuss similar issues, providing a logical basis for the critique. The inclusion of references adds credibility to the claim, making it 4. However, the comment could be strengthened by providing more detailed explanations or examples from the referenced works. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a specific issue in Table 3, noting that the encs BPE to character results are missing the recall on lemmas/forms seen in training. It also provides references to relevant works that discuss similar issues, which can help the authors understand the context and significance of the problem. By pointing out this missing information and offering references, the comment provides clear and actionable feedback that can guide the authors in improving their draft. However, the comment could be more helpful if it offered suggestions on how to address the issue or how to incorporate the missing information effectively. Overall, the feedback is 4 as it directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the impact of the proposed method on the MLSC setup, specifically questioning why the method has no impact despite the claim about better wordalignment improving manytomany translation. While the comment implies that the authors should provide an explanation for this discrepancy, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should explain the lack of impact. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 4\" and \"Table 3,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it raises a question about the impact of the proposed method on the MLSC setup, despite the claim about better wordalignment improving manytomany translation. The comment specifies what needs to be addressed, namely the lack of explanation regarding the impact on the MLSC setup. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the claim that better wordalignment improves manytomany translation, specifically regarding the impact on the MLSC setup as presented in Table 3. While the comment raises a valid concern, it lacks specific examples or detailed reasoning to support the claim or explain why the proposed method has no impact. The absence of supporting evidence or references makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a valid question about the impact of the proposed method on the MLSC setup, despite the claim that better wordalignment improves manytomany translation. It points out that the authors have not provided an explanation for this discrepancy, which is a critical area for clarification. By identifying this gap, the comment highlights a potential weakness in the paper and suggests that the authors should address it to strengthen their argument. However, the comment could be more helpful if it provided specific suggestions on how to explain or address this issue. Overall, the feedback is 3 as it prompts the authors to clarify an important aspect of their work, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment highlights a limitation of the method, specifically its reliance on precollected offline datasets and its inability to be applied in an online setting. While it points out this limitation, it does not provide explicit guidance on how the authors should address this issue or suggest potential solutions. The comment implies that the authors should consider expanding the applicability of their method to online settings, but it lacks concrete steps or suggestions on how to achieve this. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment addresses a specific limitation of the method, noting that it is restricted to offline settings and cannot be applied in an online setting. This provides some specificity regarding the issue, as it highlights a particular aspect of the method\"s applicability. However, the comment does not explicitly mention which part of the paper this issue is discussed in, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the method is restricted to offline settings and cannot be applied in an online setting. The comment provides a logical reasoning by stating that the method requires precollected offline datasets, which limits its applicability. However, it lacks specific examples or references to support the claim, making it 3. The authors would need to further explore the reasoning to fully understand and address the limitation. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant limitation of the method, noting that it is restricted to offline settings and cannot be applied in an online setting. This is an important observation that could impact the applicability and relevance of the method. However, the comment lacks specific suggestions or guidance on how the authors might address this limitation or expand the applicability of their method. While it highlights a critical issue, the feedback could be more helpful if it provided actionable advice or examples of how to overcome the restriction. Therefore, the comment is 3, as it points out a crucial weakness but does not offer comprehensive guidance for improvement."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the quality of the learned representation was only evaluated on a linear setting, which is insufficient for drawing a clear conclusion. It suggests that other downstream tasks, such as finetuning, detection, and segmentation, could be used as reported in the literature. While the comment implies that the authors should consider expanding their evaluation to include these tasks, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include additional tasks in their evaluation. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the evaluation of the learned representation, specifically noting that it was only assessed in a linear setting. It suggests that other downstream tasks, such as finetuning, detection, and segmentation, could be used to provide a more comprehensive evaluation. However, the comment does not specify which part of the paper discusses the evaluation or where these tasks are mentioned in the literature. This makes it weakly grounded, as the authors cannot confidently determine which sections or parts of the paper are being addressed. The comment is specific in suggesting additional tasks for evaluation, but without clear grounding, it remains 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point claims that the quality of the learned representation was only evaluated on a linear setting, which is insufficient for a clear conclusion. The reviewer suggests that other downstream tasks, such as finetuning, detection, and segmentation, could be used to provide a more comprehensive evaluation. While the comment identifies a potential limitation, it lacks specific examples or references to support the claim that these additional tasks would provide a more robust evaluation. The suggestion is logical but could be strengthened with more detailed reasoning or evidence. Therefore, the comment is 3, as it provides a reasonable basis for the claim but requires further elaboration to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a limitation in the evaluation of the learned representation, noting that it was only assessed in a linear setting. It suggests that other downstream tasks, such as finetuning, detection, and segmentation, could be used to provide a more comprehensive evaluation. This feedback is 3 as it highlights an area for improvement and suggests additional tasks that could be considered. However, the comment could be more helpful if it provided specific examples or guidance on how to incorporate these tasks into the evaluation. Overall, the comment offers a clear direction for enhancing the draft, but it could be more comprehensive with additional details."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment expresses a concern about the novelty of the paper, suggesting that the proposed method is not novel as it builds upon existing techniques like stagewise and progressive training, which have been used for a long time. However, the comment does not provide any explicit or implicit actions for the authors to take to address this concern. It lacks guidance on how the authors might enhance the novelty of their work or what specific aspects they could explore to differentiate their contribution. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses a concern about the novelty of the paper, suggesting that the proposed method is not novel as it builds upon existing techniques like stagewise and progressive training, which have been used for a long time. However, it does not specify which part of the paper this critique is based on, nor does it provide details on what aspects of the method are lacking in novelty. Without explicit references to sections, figures, or specific elements of the paper, the authors cannot confidently determine which parts need attention or improvement. The comment lacks both grounding and specificity, making it difficult for the authors to address the feedback effectively. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the novelty of the paper is very low, as it suggests that stagewise and progressive training have been used for a long time and are common practices. The reviewer supports this claim by stating that the authors do not exhibit any novel aspects in their use of these techniques. However, the comment lacks specific examples or references to existing works that have used these methods, making it difficult for the authors to understand the basis of the claim or how to address it. The absence of detailed justification or evidence makes the claim 3, as it provides a general observation but lacks the depth needed for full verification.", "helpfulness_rationale": "The review comment points out a concern about the novelty of the paper, suggesting that the proposed method is not novel as it builds upon existing techniques like stagewise and progressive training, which have been used for a long time. However, the comment lacks specificity and does not provide any actionable feedback or suggestions on how the authors might enhance the novelty of their work. It does not offer guidance on what aspects of the method could be improved or how the authors might differentiate their contribution from existing literature. Without detailed insights or constructive advice, the comment does not empower the authors to make meaningful improvements to their draft. Therefore, it is rated as 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the generalizability of the analysis, specifically asking how it can be extended to more general cases, such as more general Markov chains, and whether it can handle additional complexities like FFN and nonlinearity on top of the attention layer. While the comment implies that the authors should explore these extensions, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to address these questions. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises questions about the generalizability of the analysis, specifically asking how it can be extended to more general cases, such as more general Markov chains, and whether it can handle additional complexities like FFN and nonlinearity on top of the attention layer. However, it does not specify which part of the paper these questions pertain to, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where these topics are discussed, the comment lacks full grounding. It is specific in its inquiry about generalizability and additional complexities, but without clear grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the generalizability of the analysis, specifically asking how it can be extended to more general cases and whether it can handle additional complexities like FFN and nonlinearity on top of the attention layer. These are questions seeking clarification rather than making subjective claims or judgments. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises important questions about the generalizability of the analysis, specifically asking how it can be extended to more general cases and whether it can handle additional complexities like FFN and nonlinearity on top of the attention layer. This feedback is valuable as it prompts the authors to consider the broader applicability and robustness of their analysis, which is crucial for improving the paper\"s scope and relevance. However, the comment could be more helpful if it provided specific suggestions or guidance on how to address these questions or explored potential extensions. Overall, the comment is 4 as it identifies a significant area for improvement and encourages the authors to consider broader applications of their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the authors discuss 19 but do not clearly explain why it is not obvious in section 3.1. (and line 57) that 19 uses the same Fine state automaton, or if there is any difference. While the comment identifies a specific area where clarification is needed, it does not provide explicit guidance on how the authors should address this issue. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the use of the Fine state automaton in the context of 19. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 3.1. (and line 57),\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out a lack of clarity regarding the use of the Fine state automaton in the context of 19, prompting the authors to clarify this aspect. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the clarity of the discussion regarding the use of the Fine state automaton in the context of 19. It points out that while the authors mention 19, it is not clear in section 3.1. (and line 57) whether 19 uses the same Fine state automaton or if there is a difference. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that the discussion is unclear. This lack of detailed justification makes the claim 2, as the authors would need to infer the basis of the critique without further information.", "helpfulness_rationale": "The review comment identifies a specific area of confusion in the paper, pointing out that the authors discuss 19 but do not clearly explain why it is not obvious in section 3.1. (and line 57) that 19 uses the same Fine state automaton, or if there is any difference. This feedback is 3 as it highlights a potential gap in the clarity of the discussion, prompting the authors to clarify this point. However, the comment could be more helpful if it provided suggestions on how to address this issue or offered examples of how to improve the clarity of the discussion. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a potential issue with the memory requirements of the auto_weight scheme in Algorithm 1, suggesting that it might require a lot of memory. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what specific changes could be made to reduce memory usage. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Algorithm 1,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by pointing out the memory requirements of the auto_weight scheme, which might be a concern. Additionally, it references two external works, FedGP and FLamby, which provides context and suggests potential solutions or areas for further exploration. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the auto_weight scheme in Algorithm 1 requires intermediate gradients for each domain, which might lead to high memory usage. The comment references two external works, FedGP and FLamby, which are cited to support the claim. However, the explanation does not provide detailed reasoning or specific examples from these works to substantiate the claim fully. The references are relevant, but the lack of detailed analysis or direct connection to the issue makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the memory requirements of the auto_weight scheme in Algorithm 1, noting that it might require a lot of memory. It references two external works, FedGP and FLamby, which could provide context or potential solutions for addressing the memory issue. However, the comment lacks specific suggestions or guidance on how the authors might mitigate the memory requirements or integrate the referenced works into their approach. While it highlights an important consideration, the feedback could be more actionable and helpful if it provided more detailed guidance or examples. Therefore, the comment is 3, aligning with a score of 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point highlights a limitation in the current approach, noting that the backbone is constrained to a double LSTM and that pretrained language models are not covered as well. It suggests that the application of the method to more extensive model structures remains a potential concern. However, the comment does not provide explicit guidance or suggestions on how the authors might address these limitations or expand their model structures. The action is implicit and vague, as the authors are left to infer that they need to explore more model structures, but without concrete steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses the limitation of the backbone being constrained to a double LSTM and the lack of coverage for pretrained language models. It also mentions the potential concern of applying the method to more extensive model structures. However, the comment does not specify which sections of the paper discuss these limitations or where the authors should focus their improvements. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing what needs to be addressed, but it lacks grounding as it does not explicitly mention the parts of the paper being discussed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the backbone is constrained to a double LSTM and that pretrained language models are not covered as well. It suggests that the application of the method to more extensive model structures remains a potential concern. However, the comment lacks specific examples or references to support these claims, making it difficult for the authors to understand the basis of the critique. The reasoning is not detailed enough to provide a clear understanding of why the current approach is limiting or how it could be improved. Therefore, the comment is considered 2, as it provides some reasoning but lacks sufficient evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a limitation in the current approach, noting that the backbone is constrained to a double LSTM and that pretrained language models are not covered as well. It also mentions the potential concern of applying the method to more extensive model structures. While the comment highlights an area for improvement, it lacks specific suggestions or guidance on how the authors might address these limitations or expand their model structures. The feedback is 3 as it points out a critical area for improvement, but it could be more actionable with additional details or recommendations. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "2", "actionability_rationale": "The review comment highlights the limited contribution and novelty of the paper, noting that the proposed model combines existing techniques such as structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for model parameter learning. However, it does not provide any explicit or implicit actions for the authors to take to address these concerns. There is no guidance on how the authors might enhance the contribution or novelty of their work, nor are there suggestions for alternative approaches or improvements. As a result, the comment lacks actionability, leaving the authors without a clear path forward for improving their draft. Therefore, this comment is rated as 1.", "grounding_specificity_rationale": "The comment highlights the limited contribution and novelty of the paper, specifically mentioning the combination of existing techniques like structure learning regularization (NOTEARS) and missing value imputation, along with the use of variational inference for model parameter learning. However, it does not specify which part of the paper discusses these techniques or where the authors might address the issue of novelty. The authors can infer that it relates to the introduction or methodology sections, but this inference is not direct. The comment is specific in detailing what is considered limited in terms of contribution and novelty but lacks grounding as it does not pinpoint the exact section of the paper being addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the contribution and novelty of the paper are limited, as the model combines existing techniques such as structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for model parameter learning. While the comment identifies specific techniques and methods used, it lacks detailed reasoning or examples to fully substantiate the claim of limited contribution and novelty. The authors would need to further explore and justify why these techniques are insufficient or how they could be improved to better differentiate the paper from existing work. Therefore, the comment is 3, as it provides a basis for the claim but requires additional evidence or explanation to fully support it.", "helpfulness_rationale": "The review comment points out that the contribution and novelty of the paper are limited, as the model combines existing techniques such as structure learning regularization (NOTEARS) and missing value imputation, and uses variational inference for model parameter learning. While this feedback highlights a potential issue with the originality of the work, it does not provide specific suggestions or guidance on how the authors might enhance the contribution or novelty of their paper. Without actionable feedback or constructive advice, the comment offers limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests comparing the performance of MSLR, which requires knowing unimodal optimal learning rates in advance, with a latefusion model that can be tuned separately for each modality. This implies that the authors should conduct an experiment or analysis to evaluate the performance of both approaches. While the action is implicit, it is concrete as it specifies the comparison to be made. The authors know exactly what needs to be done to address the comment, making it 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"MSLR\" and the concept of \"unimodal optimal learning rates,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests comparing MSLR with a latefusion model that can be tuned separately for each modality, providing a clear direction for improvement. Therefore, this comment is labeled as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests comparing MSLR with a latefusion model that can be tuned separately for each modality. While the comment provides a logical reasoning for the suggestion, it lacks specific examples or references to support the claim. The authors would need to infer the importance of this comparison, making the claim 3. Therefore, the comment is classified as 3.", "helpfulness_rationale": "The review comment provides a meaningful suggestion for improvement by comparing MSLR with a latefusion model that can be tuned separately for each modality. This comparison could offer insights into the effectiveness of different approaches and help the authors optimize their model. However, the comment could be more helpful if it included specific details or examples of how to conduct this comparison or what aspects of the models should be considered. Overall, the feedback is 3 as it identifies a potential area for improvement but lacks depth and specificity."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "2", "actionability_rationale": "The review point questions the novelty of the work by pointing out that 8bit batch normalization has been proposed before in literature. However, it does not provide any explicit or implicit suggestions for how the authors might address this concern or enhance the novelty of their work. There is no guidance on how the authors could differentiate their approach or justify the use of 8bit representation. As a result, the comment lacks actionability, leaving the authors without any clear direction on how to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment questions the novelty of the work by pointing out that 8bit batch normalization has been proposed before in literature, as referenced by a specific paper. This provides a clear reference to a specific part of the literature, making it fully grounded. The comment also specifies the issue by questioning the point of using 8 bits and how it undermines the novelty of the work. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the novelty of the work is undermined by the use of 8bit batch normalization, as it has been previously proposed in literature. The comment provides a specific reference to a paper (https://arxiv.org/pdf/1805.11046.pdf) that discusses 8bit batch normalization, which supports the claim. However, the comment could be strengthened by explaining how this prior work affects the novelty of the current study or by providing more context on the specific aspects of the work that are being questioned. Overall, the claim is 4 due to the reference, but it could be more robust with additional explanation or context. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment raises a valid concern about the novelty of the work by pointing out that 8bit batch normalization has been previously proposed in literature. This observation is supported by a specific reference, which provides a clear basis for the claim. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or enhance the novelty of their work. Without actionable feedback or constructive advice, the comment provides limited value to the authors in terms of improving their draft. Therefore, it aligns with a score of 2, indicating that the comment is 2."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the practical relevance of the proposed framework due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the practical relevance of their framework or suggest ways to mitigate the perceived limitation. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a concern about the practical relevance of the proposed framework due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, it does not specify which part of the paper this concern pertains to, such as the methodology, results, or discussion sections. Without explicit references to sections or specific elements, the authors cannot confidently determine which part of the paper needs attention. Additionally, the comment lacks specificity regarding how the proposed framework could be made more relevant or how the dominance of GNNs affects its practicality. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the practical relevance of the proposed framework may be limited due to the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. However, the comment lacks specific evidence, examples, or references to support this claim. Without detailed reasoning or comparison, the authors may find it challenging to understand and address the concern. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment raises a concern about the practical relevance of the proposed framework, noting the dominance of Graph Neural Networks (GNNs) in the graph representation learning domain. While it identifies a potential limitation, it does not provide specific suggestions or guidance on how the authors might address this issue or enhance the practical relevance of their framework. The comment lacks actionable feedback or detailed insights, making it 3 as it highlights an area for improvement but does not fully support the authors in making those improvements. Therefore, it aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that it is not surprising that problems involving MLPs have higher complexity than those involving FBDDs and perceptrons. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this observation or what changes could be made to the paper to improve its clarity or relevance. Without any actionable suggestions or recommendations, the authors are left without a clear understanding of what steps to take in response to this comment. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is 1 as it does not specify which part of the paper it addresses, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity because it does not provide details on what aspect of the comparison between MLPs and FBDDs/perceptrons is being questioned or what needs to be clarified. Without specific references or detailed feedback, the authors are left without a clear understanding of what needs to be addressed. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that it is not surprising that problems involving MLPs have higher complexity than those involving FBDDs and perceptrons. However, the comment lacks any supporting evidence, reasoning, or references to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how it relates to the paper\"s content. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment states that it is not surprising that problems involving MLPs have higher complexity than those involving FBDDs and perceptrons. However, it does not provide any specific feedback or suggestions on how the authors might address this observation or improve their draft. Without actionable guidance or constructive criticism, the comment offers little value to the authors in terms of improving their work. Therefore, it aligns with a score of 1, indicating that the comment is 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors discuss the generalizability of their observations, particularly those in Figure 4. It also implies that the authors should consider various hyperparameters, such as optimization algorithms, weight initialization methods, batch size, learning rate, and scheduling, as they could influence implicit biases in the algorithm. While the comment provides a clear direction for the authors to expand their analysis, it does not specify which aspects of generalizability to focus on or how to implement this discussion. The action is explicit but somewhat vague, as it lacks detailed guidance on how to address the suggested points. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing the generalizability of the observations, particularly those in Figure 4, and highlights the influence of various hyperparameters on implicit biases in the algorithm. However, it does not specify which part of the paper Figure 4 is located in, making it weakly grounded. The comment is specific in suggesting that the authors should consider discussing the generalizability and the impact of different hyperparameters, but it lacks detailed guidance on how to implement this discussion. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that the authors discuss the generalizability of their observations, particularly those in Figure 4, and highlights the potential influence of various hyperparameters on implicit biases in the algorithm. While the comment identifies a potential area for improvement, it lacks specific examples or references to support the claim that certain hyperparameters could influence the algorithm\"s implicit biases. The suggestion is 3, as it provides a direction for the authors to consider, but it does not offer detailed justification or evidence to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment suggests discussing the generalizability of the observations, particularly those in Figure 4, and highlights the potential influence of various hyperparameters on implicit biases in the algorithm. This feedback is 3 as it identifies an area for improvement by suggesting a discussion on the generalizability of the results. However, the comment lacks specific guidance on how to address this issue or what aspects of generalizability should be explored. While it provides a direction for the authors to consider, it does not offer detailed suggestions or examples, making it 3 but incomplete. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that the paper is not wellorganized and uses nonstandard terminology, specifically mentioning the term \"semihonst\" in section 4. It suggests that the authors should use the more standard term \"honestbutcurious\" to describe the server. While the comment identifies a specific issue and provides a clear suggestion for improvement, it does not explicitly instruct the authors to make these changes. The action is implicit and somewhat vague, as the authors need to infer that they should replace the term and ensure consistency throughout the paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"section 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it points out the use of nonstandard terminology, such as \"semihonest,\" and suggests a more standard term, \"honestbutcurious,\" to describe the server. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper is not wellorganized and uses nonstandard terminology, specifically mentioning the term \"semihonest\" in section 4. The reviewer suggests that the term should be replaced with the more standard \"honestbutcurious.\" While the comment identifies a specific issue, it lacks detailed reasoning or examples to fully substantiate the claim. The suggestion to use a more standard term is logical, but without additional context or references, the claim remains 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a significant issue with the paper\"s organization and terminology, specifically pointing out the use of nonstandard terms like \"semihonest\" in section 4. It suggests that the authors should use the more standard term \"honestbutcurious\" to describe the server. This feedback is clear and actionable, as it provides a specific example of a terminology issue and offers a clear suggestion for improvement. By addressing this feedback, the authors can enhance the clarity and professionalism of their paper. However, the comment could be more helpful if it included additional suggestions or examples of other nonstandard terms that need attention. Overall, the comment is 4, as it effectively guides the authors toward improving their draft."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "5", "actionability_rationale": "The review point explicitly identifies three specific areas where experimental details are missing: the optimizer, initialization, and PPOzero. This provides clear and direct actions for the authors to take, ensuring they know exactly what information is needed to improve their draft. The comment is explicit and concrete, offering precise guidance on what needs to be added to the experimental details. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"lots of experimental details are missing,\" allowing the authors to identify the specific areas where information is lacking. It also specifies what is missing by asking for details on \"what is the optimizer,\" \"what is the initialization,\" and \"what is PPOzero.\" This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for additional information regarding the experimental details, specifically asking for clarification on the optimizer, initialization, and PPOzero. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment identifies specific areas where experimental details are missing, namely the optimizer, initialization, and PPOzero. This feedback is clear and actionable, providing the authors with a direct path to improve their draft by specifying what information is needed to enhance the clarity and comprehensiveness of their experimental setup. By addressing these points, the authors can significantly strengthen their paper, making the comment 5. Therefore, it aligns with a score of 5."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should conduct a detailed comparison in terms of efficiency analysis, including total model parameters, FLOPs, and memory, with and without the detector and LaVIT components. This provides a clear and concrete action for the authors to take, specifying exactly what needs to be done to improve the paper. The comment is 5 as it offers specific guidance on how to address the issue of efficiency and complexity in the proposed method.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the proposed method and the components involved, such as LaVIT and EvaCLIP, allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by suggesting a detailed comparison in terms of efficiency analysis, including total model parameters, FLOPs, and memory, with and without the detector and LaVIT components. This provides clear guidance on what needs to be addressed, making the comment 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point claims that the proposed method requires more components than other existing works, specifically mentioning two image encoders and a detector in the decoding process. The reviewer suggests that a detailed comparison in terms of efficiency analysis, including total model parameters, FLOPs, and memory, is needed. While the comment provides a logical reasoning for the claim, it lacks specific examples or references to existing works that support the assertion of requiring more components. This makes the claim 3, as the authors would need to further substantiate the claim with detailed comparisons or references to existing literature.", "helpfulness_rationale": "The review comment identifies a specific issue with the proposed method, noting that it requires more components than other existing works, such as two image encoders and a detector in the decoding process. The reviewer suggests that a detailed comparison in terms of efficiency analysis, including total model parameters, FLOPs, and memory, is needed to justify the necessity of these additional components. This feedback is clear and actionable, providing the authors with a specific direction to improve their draft by conducting a comparative analysis. However, the comment could be more helpful if it included examples or specific metrics for the comparison. Overall, the comment is 4 as it guides the authors toward a meaningful enhancement of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a lack of evidence supporting the claim that extrapolation error is a major issue in MARL and questions the relevance of the proposed techniques to this issue. It suggests that the authors should provide evidence to support their claims and clarify the relationship between the techniques and the issue of extrapolation error. While the comment identifies a gap in the paper, it does not provide specific guidance on how to address this issue or what evidence should be included. The action is implicit and somewhat vague, as the authors need to infer that they should provide evidence and clarify the issue, but they are not given concrete steps to take. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the claim that extrapolation error is a major issue in MARL and questions the relevance of the proposed techniques to this issue. It specifies that the authors do not provide evidence to support their claim and that the techniques are for bias/variance reduction, not directly related to extrapolation error. This provides clear guidance on what needs to be addressed in the paper. However, the comment does not explicitly mention a specific section or part of the paper where this issue is discussed, making it weakly grounded. The authors can infer that it relates to the discussion of extrapolation error, but this inference is not as direct as it could be. Therefore, the comment is 3, aligning with a score of 3.", "verifiability_rationale": "The review point claims that the paper lacks evidence to support the assertion that extrapolation error is a major issue in MARL. It also questions the relevance of the proposed techniques, which are for bias/variance reduction, to the issue of extrapolation error. The comment provides some reasoning by suggesting that the techniques do not directly address extrapolation error, but it lacks specific examples or references to substantiate the claim. This makes the claim 3, as the authors would need to provide more detailed evidence or examples to fully address the critique. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s claim that extrapolation error is a major issue in MARL, noting the lack of evidence to support this claim. It also questions the relevance of the proposed techniques, which are for bias/variance reduction, to the issue of extrapolation error. This feedback is valuable as it prompts the authors to provide evidence and clarify the relationship between their techniques and the issue of extrapolation error. However, the comment could be more helpful if it offered suggestions on how to address these concerns or provided examples of how the techniques might mitigate extrapolation error. Overall, the comment is 4 as it highlights important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "2", "grounding_specificity_label": "1", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM). However, it does not provide explicit guidance on what alternative name to use or how to address the potential confusion. The comment implies that the authors should consider renaming the strategy to avoid confusion with LSTM, but it lacks concrete suggestions or steps for implementation. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM). However, it does not specify which part of the paper this suggestion pertains to, such as a section, table, or figure where the strategy is discussed. Without explicit references, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what aspects of the name choice need to be reconsidered or how the suggestion could be implemented. Therefore, this comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM). However, the comment lacks specific reasoning or evidence to support why this resemblance is problematic or how it affects the paper. Without detailed explanation or examples, the claim is not 5, making it difficult for the authors to understand the basis of the suggestion. Therefore, the comment is categorized as 2.", "helpfulness_rationale": "The review comment suggests reconsidering the name of the strategy, \"LongShortTerm Strategy,\" due to its resemblance to Long Short Term Memory (LSTM). This feedback is 3 as it identifies a potential source of confusion in the paper\"s terminology. However, the comment lacks depth and does not provide specific suggestions or alternative names to consider, which would be more actionable for the authors. Without detailed guidance, the authors may struggle to address the issue effectively. Therefore, the comment is rated as 3, aligning with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point states that the proposed method is not the best performer in terms of robustness and fidelity, as indicated by the experiments results. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might address this issue, such as suggesting improvements, additional experiments, or modifications to the method. Without any actionable steps, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"experiments results,\" which is a general term and does not specify which part of the paper it addresses. This makes it difficult for the authors to pinpoint the exact section or results being discussed. Additionally, the comment lacks specificity regarding what aspects of the experiments results are being criticized\u2014whether it is the robustness, fidelity, or other factors. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that the proposed method is not the best performer in terms of robustness and fidelity, as indicated by the experiments results. However, the comment does not provide any specific data, examples, or detailed reasoning to support this claim. Without additional context or evidence, the authors may find it challenging to understand and address the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential weakness in the proposed method, stating that it is not the best performer in terms of robustness and fidelity. However, it lacks specificity and does not provide any detailed feedback or suggestions on how the authors might address this issue. Without actionable guidance or examples, the authors are left without a clear path to improve their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "5", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of clarity in the motivation and logical connections between the concepts of isometry, OT (optimal transport), and disentanglement. It points out that the paper does not adequately explain how isometry can help disentanglement and why OT is required for isometry. The reviewer suggests that the authors should provide clearer explanations of these connections. While the comment identifies specific areas that need clarification, it does not offer concrete steps on how to improve the explanations. The action is implicit and somewhat vague, as the authors need to infer that they should expand the explanations but are not given explicit guidance on how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the concepts of isometry, OT, and disentanglement, allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the lack of clarity in the motivation and logical connections between these concepts, particularly regarding how isometry can help disentanglement and why OT is required for isometry. The comment provides a clear request for more detailed explanations of these connections, making it 5.", "verifiability_rationale": "The review point claims that the motivation and logical connections between the concepts of isometry, OT, and disentanglement are unclear. The reviewer provides a specific example of the lack of explanation regarding how isometry can help disentanglement and why OT is required for isometry. This detailed critique supports the claim with logical reasoning and examples, making the comment 5. The authors would benefit from addressing these specific issues to improve the clarity of their paper.", "helpfulness_rationale": "The review comment identifies a significant issue with the clarity of motivation and logical connections in the paper, specifically regarding the concepts of isometry, OT (optimal transport), and disentanglement. It points out that the paper does not adequately explain how isometry can help disentanglement and why OT is required for isometry. The reviewer provides a clear and actionable suggestion for improvement by recommending that the authors provide more detailed explanations of these connections. This feedback is 4 as it directs the authors to a specific area needing clarification and offers a clear path for improvement. However, it could be more helpful if it included examples or further elaboration on how to enhance the explanations. Therefore, the comment is rated as 4."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment acknowledges the positive results on regular languages but questions their relevance to explaining how and why realworld language models work. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address this concern or what specific aspects of the results should be explored further. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment acknowledges the positive results on regular languages but questions their relevance to explaining how and why realworld language models work. However, it does not specify which part of the paper discusses the results on regular languages or where the authors might need to address the connection to realworld language models. This lack of specific guidance makes it difficult for the authors to pinpoint the exact areas that need improvement. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point questions the relevance of the results on regular languages to explaining how and why realworld language models work. However, it does not provide any specific reasoning, examples, or references to support this claim. Without additional context or evidence, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The comment acknowledges the positive results on regular languages but raises a valid question about their relevance to explaining how and why realworld language models work. This feedback highlights a potential gap in the paper\"s discussion, prompting the authors to consider the broader implications of their findings. However, the comment lacks specific suggestions or guidance on how the authors might address this gap or integrate their results into a more comprehensive explanation. While it identifies an area for improvement, the feedback could be more helpful with additional details or examples. Therefore, it is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the novelty of the paper compared to the Venom paper 1, specifically asking whether V:N:M was proposed in that paper and how it differs from Venom 1. While the comment implies that the authors should clarify these differences, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should address the novelty aspect by providing a detailed comparison with the Venom paper. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the novelty of the paper compared to the Venom paper 1, specifically asking about the differences between V:N:M and Venom 1. However, it does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its request for clarification regarding the differences between the two papers, but without explicit grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the novelty of the paper compared to the Venom paper 1, specifically asking about the differences between V:N:M and Venom 1. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim that the paper is not novel or lacks originality. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the novelty of the paper compared to the Venom paper 1, specifically asking about the differences between V:N:M and Venom 1. This is a relevant and important question for assessing the originality and contribution of the paper. However, the comment does not provide any suggestions or guidance on how the authors might address this issue or improve their draft. While it identifies a potential area for improvement, it lacks actionable feedback, making it 3. The authors would need to infer that they should clarify the differences between their work and the Venom paper, but the comment does not offer specific advice on how to do so. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment expresses a concern about the qualitative intuition behind the attribution maps, specifically noting that the attended areas in the image do not seem to relate to the actual task, such as in 3D tasks where the attended 3D worth pixels do not have a clear semantic meaning. However, it acknowledges that the resulting analysis using these attribution maps appears to have quantitative value. The comment does not provide explicit guidance on how the authors should address this issue or improve the qualitative understanding of the attribution maps. The action is implicit and vague, as the authors are left to infer that they need to enhance the qualitative intuition of the attribution maps but are not given specific steps on how to do so. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it details the issue with the attribution maps, noting that the attended areas of the image do not seem to relate to the actual task, such as in 3D tasks where the attended 3D worth pixels do not have a clear semantic meaning. Additionally, it mentions the lack of clusters of attended pixels with clear semantic meaning. The comment also highlights the quantitative value of the analysis using the attribution maps, but it does not address the qualitative value, which is the main concern. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the qualitative intuition behind the attribution maps, specifically questioning the relationship between the attended areas and the actual task. The reviewer provides examples, such as the attended 3D worth pixels in 3D tasks not having a clear semantic meaning, which supports the claim. However, the comment does not provide additional evidence or references to substantiate the claim further. While the reasoning is logical, the lack of specific examples or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the qualitative intuition behind the attribution maps, particularly in the context of 3D tasks. It points out that the attended areas of the image do not seem to relate to the actual task, such as the 3D worth pixels not having a clear semantic meaning. However, it acknowledges that the resulting analysis using the attribution maps appears to have quantitative value. The comment highlights a gap in the qualitative understanding of the attribution maps, which is a valuable insight for the authors to address. While it does not provide specific suggestions for improvement, it directs the authors to a critical area that needs clarification. Therefore, the comment is 3, as it prompts the authors to consider and address a potential weakness in their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the overclaiming nature of the paper\"s title, noting that the results are only shown on two specific language models, BERT and RoBERTa, and questions whether the proposed method can be scalable to other large language models like Llama270b. The reviewer suggests that if the method is scalable, the authors should provide empirical justification. Additionally, the comment includes minor feedback about the consistency of the term \"ROBERTA\" in the paper. While the comment highlights a potential issue with the title and suggests a specific area for improvement, it does not provide explicit instructions on how to address these concerns. The action is implicit and somewhat vague, as the authors need to infer that they should revise the title and possibly include results for Llama270b. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the title and the results presented in the paper, allowing the authors to accurately identify the parts being addressed. It is also specific because it raises a concern about the overclaiming nature of the title and questions whether the proposed method can be scalable to large language models like Llama270b, suggesting that the authors should provide empirical justification if they claim scalability. Additionally, it includes minor feedback about the consistency of the term \"ROBERTA\" in the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises a concern about the overclaiming nature of the paper\"s title, suggesting that the results are only shown on two specific language models, BERT and RoBERTa, and questions whether the proposed method can be scalable to other large language models like Llama270b. The reviewer provides a logical reasoning by pointing out the lack of results on a broader range of models, which could impact the paper\"s claims. However, the comment does not provide specific examples or references to support the claim that the results are limited to BERT and RoBERTa. While the reasoning is logical, the lack of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the overclaiming nature of the paper\"s title, noting that the results are only demonstrated on two specific language models, BERT and RoBERTa, and questions whether the proposed method can be scalable to other large language models like Llama270b. This feedback is clear and actionable, as it prompts the authors to consider the scalability of their method and provide empirical justification if applicable. Additionally, the comment includes minor feedback about the consistency of the term \"ROBERTA\" in the paper, which is a helpful suggestion for improving the draft. Overall, the comment provides valuable insights and constructive feedback that can guide the authors in refining their work, making it 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper does not provide any specific motivation for choosing date and country as possible spurious correlating variables with gender. It suggests that the authors should explain why these variables were selected, apart from speculating that they could show spurious correlations. However, the comment does not provide explicit guidance on how to address this issue or what specific aspects should be clarified. The action is implicit and somewhat vague, as the authors need to infer that they should provide motivation for their choice of variables and may not know exactly how to do so. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the lack of motivation for choosing date and country as possible spurious correlating variables with gender. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for motivation regarding the choice of variables, but it lacks detailed guidance on how to address this issue. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper lacks motivation for choosing date and country as possible spurious correlating variables with gender. However, the comment does not provide any specific reasoning or examples to support this claim. It merely states an observation without offering detailed justification or evidence, making it difficult for the authors to understand the basis of the critique. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment identifies a lack of motivation for choosing date and country as possible spurious correlating variables with gender. It points out that the paper only speculates about the possibility of spurious correlations without providing any specific reasoning or evidence. This feedback is 3 as it highlights an area where the authors need to provide more detailed justification or explanation. However, the comment could be more helpful if it offered suggestions on how to address this issue or provided examples of how to strengthen the motivation for selecting these variables. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a concern about the depth of studies needed to establish the contribution of the work, particularly in relation to damping in secondorder methods. It suggests that more indepth studies are required. However, the comment does not provide specific guidance on what kind of studies or analyses are needed to address this concern. Additionally, the comment includes a minor question about the exact meaning of \"K\" and whether it equals \"NC,\" which could be clarified by the authors. While the comment identifies an area for improvement, it lacks concrete instructions or detailed guidance on how to address the concern, making it 3.", "grounding_specificity_rationale": "The comment addresses two distinct points. First, it questions the depth of studies needed to establish the contribution of the work, particularly in relation to damping in secondorder methods. This part is 1 as it does not specify which section or part of the paper this issue pertains to. Second, the comment includes a minor question about the exact meaning of \"K\" and whether it equals \"NC,\" which is also 1 as it does not reference a specific section or part of the paper. Since both parts of the comment are 1 and lack specificity, the comment is 1 at all.", "verifiability_rationale": "The review point raises a concern about the depth of studies needed to establish the contribution of the work, particularly in relation to damping in secondorder methods. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The minor question about the exact meaning of \"K\" and whether it equals \"NC\" is also not addressed with any supporting evidence. As a result, the comment is considered 1 due to the lack of detailed justification or evidence to support the claim. Therefore, it aligns with a score of 1.", "helpfulness_rationale": "The review comment raises a concern about the depth of studies needed to establish the contribution of the work, particularly in relation to damping in secondorder methods. It suggests that more indepth studies are required to validate the practical method\"s effectiveness. However, the comment does not provide specific guidance or suggestions on how to conduct these studies or what aspects to focus on. Additionally, the comment includes a minor question about the exact meaning of \"K\" and whether it equals \"NC,\" which could be clarified by the authors. While the comment identifies an important area for improvement, it lacks actionable advice or detailed guidance, making it 3. Therefore, it aligns with a score of 3."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically the impact of these parameters on the running time. This feedback provides explicit actions for the authors to take, such as conducting further analysis and providing detailed insights. However, the comment does not specify how to conduct this analysis or what specific aspects should be focused on, leaving some details implicit. The minor comment about a potential mismatch between Figure 2 and the description is more of a factual observation rather than an action. Overall, the comment is 4 as it provides clear guidance on what additional analyses should be conducted, but it could be more detailed to be fully actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"an indepth analysis of the parameters k and N in the ablation study\" and \"the running time or complexity,\" allowing the authors to accurately identify the parts of the paper being addressed. It also specifies the need for additional analysis, particularly regarding the impact of these parameters on the running time. The minor comment about a potential mismatch between Figure 2 and the description is also fully grounded, as it refers to a specific figure and its description. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also recommends analyzing the running time or complexity, specifically the impact of these parameters on the running time. While the comment provides a logical suggestion for improvement, it lacks specific examples or references to support the claim that such an analysis would be beneficial. The suggestion is 3, as it offers a direction for improvement but does not provide detailed evidence or examples to fully substantiate the claim. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback by suggesting that an indepth analysis of the parameters k and N in the ablation study would enhance readers\" understanding of the algorithm. It also recommends analyzing the running time or complexity, particularly the impact of these parameters on the running time. This guidance is clear and constructive, offering the authors a clear path for improving their draft. However, the comment could be more helpful if it included specific suggestions on how to conduct this analysis or what aspects to focus on. Overall, the feedback is 4 as it directs the authors toward meaningful improvements in their work."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises two specific questions about the details in Appendix B: whether the standard deviation is indicated and whether the 10 runs were conducted over random hyperparameter configurations or with the best selected hyperparameter values. While the questions are explicit, they do not provide concrete guidance on how the authors should address these issues. The authors are left to infer that they need to include standard deviation and clarify the experimental setup, but without specific instructions on how to do so, the action remains vague. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Appendix B,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it raises two clear questions about the details in Appendix B: whether the standard deviation is indicated and whether the 10 runs were conducted over random hyperparameter configurations or with the best selected hyperparameter values. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point consists of questions seeking clarification about the experimental setup and results presented in Appendix B. It does not contain any subjective claims, opinions, or suggestions that require verification. The questions are factual and seek additional information, making the comment purely descriptive. Therefore, it should be labeled as \"No.\"", "helpfulness_rationale": "The review comment raises two specific questions about the details in Appendix B, which could be addressed by the authors to improve the clarity and comprehensiveness of their paper. The first question asks why there is no indication of standard deviation, which is a crucial statistical measure for understanding the variability of results. The second question seeks clarification on whether the 10 runs were conducted over random hyperparameter configurations or with the best selected hyperparameter values. Addressing these questions would provide the authors with actionable feedback to enhance the transparency and robustness of their experimental results. However, the comment could be more helpful if it offered suggestions on how to present the information or emphasized the importance of these details. Overall, the comment is 3 as it identifies areas for improvement but lacks depth and guidance for full enhancement."}
{"actionability_label": "5", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that more details about the task generation process should be included in the main text, not just in the appendix. This provides a clear and direct action for the authors to take, specifying where these details should be added. The suggestion is concrete, as it outlines exactly where the additional information is needed, and it is explicit in its request for inclusion. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment suggests that more details about the task generation process should be included in the main text, not just in the appendix. However, it does not specify which part of the paper discusses the task generation process, making it difficult for the authors to pinpoint the exact section that needs revision. While the authors might have an idea of where this information is typically presented, the comment lacks full grounding. It is specific in recommending the inclusion of more details, but without clear grounding, it is challenging for the authors to address the feedback effectively. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that more details about the task generation process should be included in the main text, not just in the appendix. This claim is 3 as it implies that the current presentation of the task generation process is insufficient, but it lacks specific examples or references to support the need for more details. The authors would need to infer the importance of these details themselves, making the claim 3. Therefore, the comment aligns with a score of 3.", "helpfulness_rationale": "The review comment provides a clear and actionable suggestion for improving the paper by recommending that more details about the task generation process be included in the main text, rather than just in the appendix. This feedback is valuable as it helps the authors enhance the clarity and comprehensiveness of their presentation, ensuring that readers gain a better understanding of the experimental setup. By addressing this suggestion, the authors can significantly strengthen the paper\"s presentation. However, the comment could be more helpful if it provided specific examples or guidance on what aspects of the task generation process should be detailed. Overall, the comment is 4, as it offers a clear direction for improvement but could be more comprehensive with additional details."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "5", "actionability_rationale": "The review comment suggests that the authors should clarify the dependency of entropy on a datapoint, using a specific notation like $H(p^a|x)$. This feedback provides a clear and explicit action for the authors to take, which is to make the formulas more understandable by explicitly indicating the dependency on a datapoint. The comment is concrete, as it specifies exactly what needs to be changed and how to do it, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Individuallevel entropy and Grouplevel entropy\" paragraphs, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it provides a clear suggestion for improvement, recommending that the authors clarify the dependency of entropy on a datapoint using a specific notation like $H(p^a|x)$. This guidance helps the authors understand what needs to be addressed in terms of clarity and notation. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should clarify the dependency of entropy on a datapoint, using a specific notation like $H(p^a|x)$. This claim is 3 as it provides a logical reasoning for the suggestion, explaining how the current notation might be unclear and how the proposed change would enhance understanding. However, the comment lacks specific examples or references to support the claim fully, which could make it harder for the authors to understand the necessity of the change. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides a specific and actionable suggestion for improving the clarity of the paper. It points out that the use of entropy ($H$) in the paragraphs on Individuallevel entropy and Grouplevel entropy could be more understandable if it explicitly indicates the dependency on a datapoint, using a notation like $H(p^a|x)$. This feedback is clear and constructive, as it offers a concrete way to enhance the readability and comprehension of the formulas presented in the paper. By addressing this suggestion, the authors can significantly improve the clarity of their work, making it more accessible to readers. Therefore, the comment is 5, aligning with a score of 5."}
{"actionability_label": "3", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide explicit guidance on how to implement this suggestion or what specific changes should be made to the draft. The action is implicit, as the authors can infer that they need to explore or implement this method, but the lack of concrete details makes it difficult for them to know exactly how to proceed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not specify which part of the paper this suggestion relates to, making it difficult for the authors to identify the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspects of the method should be explored or how it should be implemented. As a result, the comment is 1 and highly unspecific, aligning with a score of 1.", "verifiability_rationale": "The review point suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it does not provide any supporting evidence, reasoning, or examples to justify why this method is necessary or beneficial. Without additional context or explanation, the claim remains vague and difficult for the authors to understand and address. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests a method for connecting tokens beyond local windows by forming new groups across previous local windows. However, it lacks specificity and does not provide any guidance or examples on how to implement this method or why it would be beneficial. Without additional context or detailed suggestions, the authors are left without actionable feedback on how to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment suggests that the authors provide a more comprehensive illustration of the advantage of using a specific distance metric in the context of Distributionally Robust Optimization (DRO). It questions the benefit of this metric compared to others used in DRO literature, such as $f$divergence, Wasserstein distance, and MMD distance. The comment implies that the authors should clarify the advantages of their chosen distance metric and how it leads to better generalization performance. While the action is implicit, it is concrete in terms of what the authors need to do\u2014provide a more comprehensive illustration. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"Relationship with Distributionally Robust Optimization\" and the specific risk formulation, allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the advantage of using a particular distance metric and suggests providing a more comprehensive illustration of this. The comment provides clear guidance on what needs to be addressed, making it 5. Therefore, this comment aligns with category 5.", "verifiability_rationale": "The review point questions the advantage of using a specific distance metric in the context of Distributionally Robust Optimization (DRO). It references existing works that use different distance metrics, such as $f$divergence, Wasserstein distance, and MMD distance, and suggests that the authors should provide a more comprehensive illustration of the benefits of their chosen metric. The comment is 4 as it provides a logical reasoning by referencing existing literature and suggesting a need for further explanation. However, it could be strengthened by including specific examples or references to support the claim about the advantage of the specific distance metric. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a potential gap in the paper by questioning the advantage of using a specific distance metric in the context of Distributionally Robust Optimization (DRO). It suggests that the authors should provide a more comprehensive illustration of the benefits of their chosen metric compared to others used in DRO literature. This feedback is clear and actionable, as it prompts the authors to clarify and elaborate on the advantages of their approach, which could enhance the paper\"s contribution and understanding. However, the comment could be more helpful if it provided specific examples or references to support the claim about the advantage of the chosen distance metric. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the nature of the TREx dataset, suggesting that it is a distantly supervised dataset with no human labels. The reviewer also asks if it is possible to evaluate over an annotated dataset, providing examples like TACRED or FewRel. While the comment implies that the authors should consider evaluating their work on annotated datasets, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should evaluate their work on annotated datasets and choose specific examples to guide them. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the nature of the TREx dataset, suggesting it is a distantly supervised dataset with no human labels. It also asks if it is possible to evaluate over an annotated dataset, providing examples like TACRED or FewRel. However, the comment does not specify which part of the paper this question pertains to, making it weakly grounded. The comment is specific in its inquiry about the dataset\"s nature and the possibility of evaluation on annotated datasets, but without clear grounding, the authors may struggle to identify the exact section that needs attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the nature of the TREx dataset, suggesting it is a distantly supervised dataset with no human labels. The reviewer also asks if it is possible to evaluate over an annotated dataset, providing examples like TACRED or FewRel. However, the comment does not provide any supporting evidence, reasoning, or references to substantiate the claim that TREx is a distantly supervised dataset. Without additional context or justification, the claim remains 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment raises a question about the nature of the TREx dataset, suggesting it is a distantly supervised dataset with no human labels. It also asks if it is possible to evaluate over an annotated dataset, providing examples like TACRED or FewRel. This feedback is 3 as it prompts the authors to consider alternative evaluation methods and provides specific examples for further exploration. However, the comment could be more helpful if it offered a clear rationale or guidance on why evaluating on annotated datasets would be beneficial or how it could be implemented. Overall, the comment provides some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the appendix should be proofread for clarity and correctness, specifically mentioning issues with terminology such as \"poster mean\" and \"piecewiselinear\" on pages 6 and 9, respectively. It also points out that while limitations and societal impacts are discussed, the potential negative societal impacts could be elaborated upon. This feedback provides clear and concrete actions for the authors to take, making the comment 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions specific sections of the paper, such as the appendix, and provides detailed feedback on the content of these sections. It specifies the issues with terminology, such as \"poster mean\" and \"piecewiselinear,\" and suggests that the potential negative societal impacts could be elaborated upon. This level of detail provides clear guidance for the authors to address the feedback. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the appendix should be proofread for clarity and correctness, specifically pointing out issues with terminology such as \"poster mean\" and \"piecewiselinear.\" It also mentions that while limitations and societal impacts are discussed, the potential negative societal impacts could be elaborated upon. While the comment identifies specific issues, it lacks detailed reasoning or references to support the claim that the appendix is not using NeurIPS 2021 style files. The suggestion to proofread the appendix is 3, as it provides a clear direction for improvement but lacks comprehensive justification. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment provides specific and actionable feedback on the draft, particularly regarding the formatting and content of the appendix. It suggests that the appendix should be proofread for clarity and correctness, pointing out specific issues such as terminology like \"poster mean\" and \"piecewiselinear.\" Additionally, it highlights the need to elaborate on potential negative societal impacts, which is a valuable suggestion for enhancing the paper\"s impact assessment. While the comment is clear and provides concrete guidance, it could be more helpful by offering examples of how to address the identified issues or by suggesting specific ways to improve the elaboration of societal impacts. Overall, the feedback is 4 as it directs the authors to areas for improvement and provides actionable steps to enhance the quality and comprehensiveness of their work."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that the authors should examine the training and validation curves of the different losses to determine if the model can simultaneously reduce all three losses. It also questions whether there are any tricks related to weighing these losses. While the comment implies that the authors should perform this analysis, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should analyze the curves and consider loss weighting strategies. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment suggests examining training and validation curves of different losses and questions whether the model can simultaneously reduce all three losses. However, it does not specify which part of the paper these curves are discussed in, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, such as analyzing the curves and considering loss weighting strategies. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests examining training and validation curves of different losses and questions whether the model can simultaneously reduce all three losses. However, it does not provide any specific reasoning, examples, or references to support why this analysis is important or how it could be beneficial. The lack of detailed justification or evidence makes the claim 1, as the authors may not understand the basis for the suggestion. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests examining the training and validation curves of different losses to determine if the model can simultaneously reduce all three losses. It also questions whether there are any tricks related to weighing these losses. While the comment identifies a potential area for improvement, it lacks specific guidance or suggestions on how to analyze these curves or what specific aspects to consider regarding loss weighting. The feedback is 3 as it points out a potential area for further investigation, but it could be more actionable with additional details or examples. Therefore, the comment is rated as 3, consistent with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment highlights a lack of rigorous theoretical argument or proof for the NPhardness claim regarding the GOSPA metric. It suggests that the authors should provide a more detailed explanation or proof to support their claim. Additionally, the comment points out a potential issue with the assumption of access to the optimal assignment matrix, which could limit the applicability of the paper. While the comment identifies specific areas that need clarification and provides some guidance on what might be missing, it does not offer concrete steps on how to address these issues. The authors are left to infer the necessary actions, making the comment 3.", "grounding_specificity_rationale": "The comment addresses the claim of NPhardness regarding the GOSPA metric, providing specific details about the lack of a rigorous theoretical argument or proof. It also critiques the assumption of access to the optimal assignment matrix, which could limit the applicability of the paper. However, the comment does not explicitly mention which part of the paper discusses the NPhardness claim or the specific section where the assumption is made. This makes it weakly grounded, as the authors cannot confidently determine the exact parts of the paper being addressed. The comment is specific in detailing the issues with the NPhardness claim and the assumption about the optimal assignment matrix. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that computing the GOSPA metric is NPhard, but it lacks a rigorous theoretical argument or proof. The comment provides a specific example, stating that due to the binary constraint in (4), it is NPhard to compute (5), and references a lack of proof. However, the reviewer also points out that NPhardness is not generally true for assignment problems and suggests that it might be possible to reduce GOSPA to an exact polynomialtime computable assignment problem, which would limit the applicability. While the comment provides some reasoning and a critique, it lacks detailed examples or references to support the claim fully. Therefore, the claim is 3, as it provides some justification but requires more detailed evidence or references to be fully substantiated.", "helpfulness_rationale": "The review comment identifies a critical issue with the paper\"s claim regarding the NPhardness of computing the GOSPA metric. It points out the lack of a rigorous theoretical argument or proof, which is a significant gap in the paper\"s claims. The comment also critiques the assumption of access to the optimal assignment matrix, which could limit the applicability of the paper. This feedback is clear and actionable, as it directs the authors to provide a more robust theoretical foundation and to reconsider the assumptions made in their work. However, the comment could be more helpful if it offered specific suggestions on how to address these issues or provided examples of alternative approaches. Overall, the comment is 4, as it effectively highlights important areas for improvement but could be more comprehensive with additional guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. This is an explicit action, as it clearly states what the authors should do to improve their draft. However, it lacks concrete details on how to present the algorithmic solution or what specific aspects should be included in the writeup. While the action is clear, the lack of detailed guidance on execution makes it 3.", "grounding_specificity_rationale": "The comment suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. However, it does not specify which part of the paper this suggestion pertains to, making it weakly grounded. The comment is specific in its suggestion to include an algorithmic writeup, but without clear guidance on how to present it or what aspects should be included, it lacks full specificity. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. However, it does not provide any supporting evidence, reasoning, or examples to justify why this suggestion is necessary or beneficial. Without additional context or explanation, the claim remains vague and lacks verifiability. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment suggests that an algorithmic writeup of the solution to the pricing problem would be helpful. This feedback is 3 as it identifies a potential area for improvement, specifically the inclusion of a detailed algorithmic explanation. However, the comment lacks depth and does not provide specific guidance on how to present the algorithmic solution or what aspects should be included in the writeup. While it points out a relevant area for enhancement, it does not fully support the authors in making a meaningful improvement to their draft. Therefore, the comment is rated as 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward. It suggests that the policy should explore intelligently and update gradually during initialization, but it does not provide explicit guidance on how to address this issue or suggest specific actions for the authors to take. The comment implies that the authors should explore alternative mechanisms or explanations, but it lacks concrete steps or suggestions on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the issue of model averaging and its role in balancing the tradeoff between KL divergence and reward. However, it does not specify which part of the paper discusses this topic, making it weakly grounded. The comment is specific in questioning the effectiveness of model averaging and suggesting that the policy should explore intelligently and update gradually during initialization. It also implies that there might be other mechanisms or explanations, but it does not provide detailed guidance on how to address these points. Therefore, the comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a question about the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward. It suggests that the policy should explore intelligently and update gradually during initialization, but it does not provide specific examples, references, or detailed reasoning to support this claim. The lack of explicit evidence or justification makes it difficult for the authors to understand and address the issue effectively. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment raises a valid concern about the effectiveness of model averaging in balancing the tradeoff between KL divergence and reward. It questions the approach and suggests that the policy should explore intelligently and update gradually during initialization. However, the comment does not provide specific suggestions or guidance on how the authors might address this issue or improve their technique. While it identifies a potential weakness, it lacks actionable feedback or detailed explanations, making it 3. The authors would gain some insight into the problem but may need further guidance to fully address the feedback. Therefore, the comment is rated as 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point suggests that a discussion on a possible generalization with a different distribution for the size of the batches could be included. While the comment implies that this discussion should be added, it does not explicitly instruct the authors to do so. The action is implicit, as the authors can infer that they need to include this discussion, but it lacks concrete details on how to implement it. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not specify which part of the paper this discussion should be included in, making it weakly grounded. The comment is specific in suggesting what needs to be addressed, but without clear grounding, the authors may struggle to identify the exact section to focus on. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point suggests discussing a possible generalization with a different distribution for the size of the batches. However, it does not provide any supporting evidence, reasoning, or examples to justify why this discussion is necessary or beneficial. Without additional context or explanation, the claim remains vague and 1. Therefore, the comment is classified as 1.", "helpfulness_rationale": "The review comment suggests including a discussion on a possible generalization with a different distribution for the size of the batches. While it identifies a potential area for improvement, it lacks specificity and does not provide detailed guidance on how to implement this discussion or what aspects of the distribution should be explored. The comment offers a general direction for enhancement but does not offer actionable advice or detailed suggestions, making it 3. The authors may gain some insight into potential areas for expansion, but the feedback could be more comprehensive and actionable to be fully helpful."}
{"actionability_label": "2", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment points out a limitation in the analysis, specifically that it only considers the case of batch size = 1 and does not explore how the batch size affects the effective initialization scale. While the comment identifies a gap in the analysis, it does not provide explicit guidance on how the authors should address this issue. The authors are left to infer that they need to expand their analysis to include different batch sizes, but the comment does not specify which batch sizes to consider or how to analyze their impact. As a result, the action is implicit and somewhat vague, making the comment barely actionable.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"analysis\" and the \"case of batch size = 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue, which is the lack of consideration for how the batch size affects the effective initialization scale. This provides clear guidance on what needs to be addressed in the analysis. Therefore, the comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that the analysis only considers the case of batch size = 1 and does not explore how the batch size affects the effective initialization scale. However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific limitation in the analysis, noting that it only considers the case of batch size = 1 and does not explore how the batch size affects the effective initialization scale. This feedback is clear and actionable, as it highlights a gap in the analysis that the authors need to address. By suggesting that the authors expand their analysis to include different batch sizes, the comment provides a concrete direction for improving the comprehensiveness and robustness of their study. However, the comment could be more helpful if it offered specific examples or guidance on how to conduct this additional analysis. Overall, the comment is 4 as it effectively points out a critical area for improvement and encourages the authors to enhance their draft."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "1", "actionability_rationale": "The review point raises a question about Figure 7, specifically questioning why more data leads to lower results on the ImageNet linear evaluation. It provides an example of sampling 50% of the data yielding better results than sampling 100% of the data. However, the comment does not provide any explicit or implicit actions for the authors to take. It lacks guidance on how the authors might address this issue or what changes could be made to the analysis or interpretation of the results. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 7,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the results presented in Figure 7, particularly the observation that more data leads to lower results on the ImageNet linear evaluation. The comment provides a clear point of inquiry, prompting the authors to reconsider the implications of their findings. Therefore, this comment is categorized as 5, aligning with category 5.", "verifiability_rationale": "The review point questions the results presented in Figure 7, specifically the observation that more data leads to lower results on the ImageNet linear evaluation. The reviewer provides an example of sampling 50% of the data yielding better results than sampling 100% of the data. However, the comment lacks detailed reasoning or evidence to support the claim that more data leads to lower results. Without further explanation or references, the authors may find it challenging to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some context but lacks sufficient detail to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a question about the results presented in Figure 7, specifically questioning why more data leads to lower results on the ImageNet linear evaluation. It provides an example of sampling 50% of the data yielding better results than sampling 100% of the data. However, the comment does not offer any suggestions or guidance on how the authors might address this issue or improve their analysis. It lacks actionable feedback or constructive advice, making it difficult for the authors to respond effectively. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly suggests that the authors should include quantitative results on FVD, a widely recognized and robust metric for evaluating temporal video prediction. This feedback provides a clear and concrete action for the authors to take, as it specifies which metric to include and why it is important. The comment also highlights the need for a more comprehensive evaluation, which gives the authors a specific direction to enhance their work. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the use of VBench as the primary evaluation benchmark, allowing the authors to identify the specific part of the paper being addressed. It also specifies the issue by suggesting the inclusion of quantitative results on FVD, a widely recognized and robust metric for evaluating temporal video prediction. This provides clear guidance on what needs to be addressed to enhance the paper\"s credibility and comprehensiveness. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the paper lacks a comprehensive evaluation, specifically suggesting the inclusion of quantitative results on FVD, a widely recognized and robust metric for evaluating temporal video prediction. The comment provides a logical reasoning by pointing out that the absence of such results limits the paper\"s credibility and makes it less comparable to other video generation methods. However, the comment could be strengthened by providing specific examples or references to studies that have used FVD, which would make the claim more robust. Overall, the comment is 4, as it provides a clear rationale but lacks detailed evidence or references to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper by pointing out the lack of comprehensive evaluation using mainstream metrics like FVD. It suggests that including these metrics would enhance the paper\"s credibility and make it more comparable to other video generation methods. The feedback is clear and actionable, providing a specific suggestion for improvement that could significantly strengthen the paper\"s impact. However, the comment could be more helpful if it offered additional guidance on how to incorporate FVD or suggested alternative metrics. Overall, the comment is 4 as it directs the authors to a critical area for improvement, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "2", "actionability_rationale": "The review comment indicates that the technical details in section 2.2 are difficult to follow, but it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors might improve the clarity of the technical details or what specific aspects need clarification. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"2.2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly states that the technical details are hard to follow, providing a direct indication of what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the technical details in section 2.2 are hard to follow. However, it does not provide any specific examples, reasoning, or references to support this claim. Without detailed justification or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment points out that the technical details in section 2.2 are difficult to follow, indicating a potential issue with the clarity of the paper. However, the comment lacks specificity and does not provide any suggestions or guidance on how the authors might improve the clarity of these technical details. Without actionable feedback or detailed advice, the authors are left without a clear path to enhance their draft. Therefore, the comment is 2, aligning with a score of 2."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point raises questions about the improvements offered by EVA over backbone models like OTFlow, specifically in terms of designability and success rates on the RFDiffusion benchmark. It also questions whether the addition of geometry information and motifinterpolation in the work benefits over prior backbones. While the comment identifies areas for clarification and potential improvements, it does not provide explicit instructions or concrete steps for the authors to address these questions. The action is implicit and somewhat vague, as the authors need to infer what specific changes or clarifications are needed. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the \"RFDiffusion benchmark\" and \"insilico vaccine design benchmark,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it questions the improvements over backbone models like OTFlow and asks about the benefits of adding geometry information and motifinterpolation. This provides clear guidance on what needs to be addressed in the paper. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point raises questions about the improvements offered by EVA over backbone models like OTFlow, specifically in terms of designability and success rates on the RFDiffusion benchmark. It questions whether the addition of geometry information and motifinterpolation in the work benefits over prior backbones. While the comment identifies areas for improvement, it lacks specific evidence or detailed reasoning to support the claim that EVA offers superior performance over OTFlow. The authors would need to conduct further analysis or provide evidence to address these questions, making the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a critical question about the improvements offered by the work over existing backbone models like OTFlow, specifically in terms of designability and success rates on the RFDiffusion benchmark. It also questions whether the addition of geometry information and motifinterpolation in the work provides any benefits over prior backbones. This feedback is valuable as it prompts the authors to clarify and substantiate their claims regarding the effectiveness of their approach. However, the comment could be more helpful if it provided specific suggestions or examples of how the authors might address these questions. Overall, the comment is 4 as it identifies a significant area for improvement and encourages the authors to provide more detailed evidence to support their claims."}
{"actionability_label": "2", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that there are too many identical sentences in the Abstract, Introduction, and Conclusion. While it identifies a specific issue, it does not provide explicit guidance on how to address it or suggest ways to reduce the repetition. The authors are left to infer that they need to revise these sections to eliminate redundancy, but without concrete steps or examples, the action remains vague. Therefore, this comment is barely actionable.", "grounding_specificity_rationale": "The comment identifies a specific issue with the paper, namely the presence of too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not specify which sentences are redundant or provide guidance on how to address this issue. The authors can infer that they need to revise these sections, but the comment lacks detailed information on what needs to be changed or how to improve the draft. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point claims that there are too many identical sentences in the Abstract, Introduction, and Conclusion. However, it does not provide any supporting evidence, reasoning, or examples to justify this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the concern or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper, noting that there are too many identical sentences in the Abstract, Introduction, and Conclusion. While it highlights a potential redundancy that could be addressed, it lacks actionable guidance or suggestions on how to eliminate these duplicates or improve the draft. The comment provides some insight into the problem but does not offer detailed feedback or constructive advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reward function used in the ablation studies, specifically asking if it is sEH. This is a direct inquiry that prompts the authors to clarify their methodology. While the comment does not explicitly instruct the authors to provide this information, it clearly implies that they should address it in their draft. The action is explicit but somewhat vague, as it does not specify how to incorporate this information into the paper. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Reward Function\" and \"ablation studies,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the question of which reward function was used in the ablation studies, particularly asking if it is sEH. This provides clear guidance on what information is missing or needs clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question seeking clarification about the reward function used in ablation studies. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely factual and descriptive, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the reward function used in the ablation studies, asking if it is sEH. This is a direct and actionable inquiry that prompts the authors to clarify their methodology and ensure the accuracy of their experimental setup. By addressing this question, the authors can improve the transparency and reproducibility of their work. However, the comment could be more helpful if it provided additional context or suggested ways to address the question, such as recommending specific sections or data to include. Overall, the comment is 3 as it identifies a specific area for clarification but lacks depth and actionable guidance."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "4", "helpfulness_label": "3", "actionability_rationale": "The review point critiques the use of selfgenerated code for a fair comparison with previous work, noting that it samples the model twice for each generation. It suggests that using a placeholder code was intended, implying that the authors should clarify this aspect in their draft. While the comment implies that the authors should address this issue, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should clarify the comparison method. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the use of selfgenerated code for comparison with previous work, specifically mentioning that it samples the model twice for each generation. It also clarifies that using a placeholder code was intended. However, the comment does not specify which part of the paper discusses this comparison, making it weakly grounded. The authors can infer that it relates to the methodology or results sections, but this inference is not direct. The comment is specific in detailing the issue with the comparison method, but without explicit grounding, it is 3. Therefore, this comment aligns with category 3.", "verifiability_rationale": "The review point critiques the use of selfgenerated code for a fair comparison with previous work, noting that it samples the model twice for each generation. The reviewer provides a logical explanation by stating that using a placeholder code was intended, which only generates the code itself once. This reasoning is clear and provides a basis for the claim, making it 4. However, the comment could be strengthened by referencing specific examples or studies where this issue has been addressed, which would enhance its verifiability. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment critiques the use of selfgenerated code for a fair comparison with previous work, noting that it samples the model twice for each generation. It suggests that using a placeholder code was intended, which only generates the code itself once. This feedback is 3 as it identifies a potential issue with the methodology and provides a rationale for why the comparison might not be fair. However, the comment could be more helpful if it offered specific suggestions on how to address this issue or provided examples of how to improve the comparison. Overall, the comment provides some insight but lacks depth and actionable guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment points out that Sections 3 and 4, which are considered the main contributions of the paper, are squeezed into a single page. It specifically mentions the absence of precise mathematical definitions of the quantum states in Eq (4), making it difficult for readers to follow the content. While the comment identifies a specific issue with the layout and content, it does not provide explicit guidance on how to address this problem. The authors are left to infer that they need to either expand these sections or provide clearer explanations of the mathematical definitions. The action is implicit and somewhat vague, as the authors need to determine the exact steps to take to resolve the issue. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Sections 3 and 4,\" allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it highlights the issue of missing precise mathematical definitions of the quantum states in Eq (4), which makes it difficult to follow. The comment provides clear guidance on what needs to be addressed, namely the inclusion of these definitions. Therefore, this comment is 5, corresponding to label 5.", "verifiability_rationale": "The review point claims that Sections 3 and 4, which are considered the main contributions of the paper, are squeezed into a single page. It further criticizes the lack of precise mathematical definitions of the quantum states in Eq (4), making it difficult for readers to follow the content. While the comment identifies a specific issue with the layout and content, it does not provide detailed reasoning or examples to fully substantiate the claim. The absence of specific references or detailed explanations makes it 3, as the authors may need to infer the issues themselves. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a specific issue with the paper\"s structure and content, noting that Sections 3 and 4, which are considered the main contributions, are squeezed into a single page. It highlights the absence of precise mathematical definitions of the quantum states in Eq (4), which makes it difficult for readers to follow the content. This feedback is clear and actionable, as it points out a structural issue and a specific content gap that needs to be addressed. By providing a concrete example of the problem, the comment guides the authors on how to improve the clarity and comprehensiveness of their paper. However, it could be more helpful if it offered suggestions on how to present the information more effectively or included examples of how to improve the clarity. Overall, the comment is 4, as it effectively directs the authors\" attention to a critical area for improvement."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the fairness of the results concerning underrepresented groups, specifically asking whether females or blacks might be discriminated by the recommendations of LLMs. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or what steps they should consider to ensure fairness. Without specific suggestions or actions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment raises a question about the fairness of the results concerning underrepresented groups, specifically mentioning females or blacks. However, it does not specify which part of the paper this question pertains to, such as a particular section, table, or figure. This makes it difficult for the authors to pinpoint the exact location in the paper where this issue needs to be addressed. While the question is specific about the issue of fairness, the lack of grounding makes it challenging for the authors to effectively address the feedback. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point raises a question about the fairness of the results concerning underrepresented groups, specifically asking whether females or blacks might be discriminated by the recommendations of LLMs. However, it does not provide any supporting evidence, reasoning, or references to substantiate the claim. The comment lacks specific examples or detailed analysis to justify the concern, making it difficult for the authors to understand the basis of the critique. As a result, the claim is 1.", "helpfulness_rationale": "The review comment raises a relevant question about the fairness of the results concerning underrepresented groups, specifically questioning whether females or blacks might be discriminated by the recommendations of LLMs. This is a valuable point that could significantly impact the paper\"s conclusions and implications. However, the comment lacks specific suggestions or guidance on how the authors might address this issue or improve the fairness of their results. While it identifies an important area for consideration, it does not provide actionable feedback or detailed advice, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the necessary changes required to make ECDiffusers work on realworld data. However, it does not provide any explicit or implicit suggestions or guidance on how to address this issue. The comment lacks actionable details, such as specific steps, considerations, or examples that the authors could follow to make ECDiffusers compatible with realworld data. Without any actionable advice or direction, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment poses a question about the necessary changes to make ECDiffusers work on realworld data. However, it does not specify which part of the paper this question pertains to, such as a particular section, figure, or discussion. Without explicit references to the paper, the authors cannot confidently determine which part of the paper is being addressed. Additionally, the comment lacks specificity regarding what changes are needed or how to make ECDiffusers work on realworld data. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point is a question asking for clarification on the necessary changes to make ECDiffusers work on realworld data. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment poses a question about the necessary changes required to make ECDiffusers work on realworld data. However, it does not provide any specific guidance, suggestions, or insights on how to address this issue. Without actionable feedback or detailed advice, the authors are left without a clear understanding of what steps to take to improve their draft. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "X", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the reliability of the evaluation and suggests that there should be a human study to gauge the efficacy of the evaluation protocol of the benchmark. While the comment implies that the authors should conduct such a study, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors are left to infer that they need to perform a human study to address the question. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment raises a question about the reliability of the evaluation and suggests that there should be a human study to gauge the efficacy of the evaluation protocol of the benchmark. However, it does not specify which part of the paper this question pertains to, such as a particular section or figure where the evaluation is discussed. This makes it weakly grounded, as the authors cannot confidently determine which part of the paper is being addressed. The comment is specific in its request for a human study to validate the evaluation protocol, but without clear grounding, it is challenging for the authors to know where to focus their efforts. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point consists of questions seeking clarification about the reliability of the evaluation and the need for a human study to gauge the efficacy of the evaluation protocol. These are factual inquiries and do not contain subjective claims, opinions, or suggestions that require verification. Therefore, the comment is classified as \"No.\"", "helpfulness_rationale": "The review comment raises a pertinent question about the reliability of the evaluation and suggests that a human study could be conducted to gauge the efficacy of the evaluation protocol of the benchmark. This feedback is 3 as it identifies a potential area for improvement and prompts the authors to consider additional validation methods. However, the comment could be more helpful if it provided specific guidance on how to conduct such a study or suggested alternative approaches to assess the evaluation protocol. Overall, the comment offers some insight but lacks depth and actionable advice, making it 3."}
{"actionability_label": "1", "grounding_specificity_label": "2", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point expresses concern about the novelty of the work, noting that the technical contribution appears somewhat incremental compared to prior work. However, it does not provide any explicit or implicit actions for the authors to take to address this concern. There is no guidance on how the authors might enhance the novelty or differentiate their work from previous studies. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment expresses concern about the novelty of the work and compares it to prior work, specifically mentioning \"von Kugelgen et al. 2021\" and \"Daunhawer et al. 2023.\" This provides some grounding as the authors can identify the specific works being referenced. However, the comment lacks specificity regarding what aspects of the work are considered incremental or how the authors might address the concern about novelty. It does not provide detailed guidance on how to enhance the novelty or differentiate the work from previous studies. Therefore, the comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point expresses concern about the novelty of the work, comparing it to prior work by von Kugelgen et al. (2021) and Daunhawer et al. (2023). However, the comment lacks specific details or examples to substantiate the claim that the technical contribution is somewhat incremental. Without additional context or evidence, the authors may find it challenging to understand the basis of the concern and address it effectively. Therefore, the comment is considered 2, as it provides some indication of the issue but lacks sufficient detail to be 5.", "helpfulness_rationale": "The review comment expresses concern about the novelty of the work, noting that the technical contribution appears somewhat incremental compared to prior work. While it identifies a potential weakness in the paper, it lacks specific suggestions or guidance on how the authors might address this concern or enhance the novelty of their work. The comment does not provide actionable feedback or detailed insights into what aspects of the work could be improved to differentiate it from previous studies. As a result, the comment is 3, as it highlights an area for improvement but does not offer comprehensive guidance for the authors to follow."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the performance of PromptMix depends on the quality of questions/answers generated by the LLM and recommends an analysis on which opensource LLMs would work with this approach or determining a parameter count cutoff (e.g., 7B) below which performance might degrade. While the comment provides a clear direction for the authors to consider, it does not explicitly instruct them to conduct this analysis or provide specific guidance on how to implement it. The action is implicit and somewhat vague, as the authors need to infer the need for such an analysis and determine the exact parameters to consider. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"another thing to note,\" which allows the authors to identify the specific part of the paper being addressed. It also specifies the issue by discussing the dependence of PromptMix\"s performance on the quality of questions/answers generated by the LLM and suggests an analysis on which opensource LLMs would work with this approach or determining a parameter count cutoff. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the performance of PromptMix depends on the quality of questions/answers generated by the LLM and suggests that a highquality model is essential for success. The reviewer provides a logical reasoning by suggesting an analysis on which opensource LLMs would work with this approach and determining a parameter count cutoff. However, the comment lacks specific examples or references to support the claim about the parameter count cutoff, making it 3. The authors would need to further explore this suggestion to fully understand and address the issue. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential weakness in the paper regarding the dependence of PromptMix\"s performance on the quality of questions/answers generated by the LLM. It suggests that a highquality model is essential for success and provides actionable feedback by recommending an analysis on which opensource LLMs would work with this approach or determining a parameter count cutoff (e.g., 7B) below which performance might degrade. This feedback is clear and constructive, offering the authors a specific direction for further investigation and potential improvements to their work. However, it could be more helpful if it included examples or specific suggestions for the analysis. Overall, the comment is 4 as it provides valuable insights and guidance for enhancing the draft."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the authors should comment on the feasibility of the submodularity approach, specifically questioning the runtimes of simulations for large models in Section 6. While the comment implies that the authors should provide more detailed information about the computational feasibility, it does not explicitly instruct them to do so. The action is implicit and somewhat vague, as the authors need to infer that they should include runtime information and determine how to present it. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"appendix D.4,\" allowing the authors to accurately identify the part of the paper being addressed. It also specifies the issue by questioning the feasibility of the submodularity approach and suggesting that the authors comment on the runtimes of simulations for large models in Section 6. This provides clear guidance on what needs to be addressed. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the feasibility of the submodularity approach by referencing the SATURATE algorithm and its scaling with N^5. It suggests that the authors should comment on the runtimes of simulations for large models in Section 6. However, the comment does not provide specific examples or detailed reasoning to support the claim about the feasibility or the need for further analysis. The lack of explicit evidence or detailed explanation makes it difficult for the authors to understand the basis of the critique. Therefore, the comment is considered 2, as it provides some direction but lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a potential issue with the feasibility of the submodularity approach, specifically referencing the SATURATE algorithm and its scaling with N^5. It suggests that the authors should comment on the runtimes of simulations for large models in Section 6. This feedback is 3 as it prompts the authors to consider the practicality and scalability of their approach, which is an important aspect of evaluating the effectiveness of their method. However, the comment could be more helpful if it provided specific guidance on how to analyze or present the runtimes, or if it offered suggestions on how to address the feasibility concerns. Overall, the comment provides a clear direction for improvement but lacks depth and actionable advice, making it 3."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review comment explicitly states that the inference at test time is briefly explained and suggests that it would benefit from more details. This provides a clear and direct action for the authors to take, which is to expand on the explanation of inference at test time. The comment is specific and gives concrete guidance on how to improve the draft, making it 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"594,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the need for more details in explaining inference at test time. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that \"inference at test time is briefly explained,\" but it does not provide any supporting evidence, reasoning, or examples to justify why this is a problem or how it could be improved. Without additional context or explanation, the authors may find it challenging to understand the basis of the claim or how to address it. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the inference at test time is briefly explained. It suggests that the authors should provide more details to enhance the clarity and comprehensiveness of their explanation. This feedback is clear and actionable, as it directs the authors to a particular aspect of their draft that needs further elaboration. However, the comment could be more helpful if it offered suggestions on how to expand the explanation or provided examples of what additional details might be beneficial. Overall, the comment is 4 as it highlights a clear area for improvement, but it could be more comprehensive with additional guidance."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises concerns about the correctness and soundness of the evaluation, specifically regarding the modality and reusability of programs generated by CodeChain on a Likert scale. It questions how this evaluation aligns with human preference and suggests that the effectiveness of submodule generation is unclear. Additionally, it points out a slight performance drop in the chain of selfrevisions in the 5th iteration, indicating a potential limitation with selfrevise prompting. However, the comment does not provide explicit guidance or suggestions on how the authors should address these issues or improve their evaluation. The actions are implicit and vague, leaving the authors uncertain about how to proceed. Therefore, the comment is barely actionable.", "grounding_specificity_rationale": "The comment addresses several specific issues related to the evaluation of the programs generated by CodeChain. It raises concerns about the modality and reusability of these programs on a Likert scale, questioning how this evaluation aligns with human preference. It also questions the effectiveness of submodule generation and points out a slight performance drop in the chain of selfrevisions in the 5th iteration, suggesting a potential limitation with selfrevise prompting. However, the comment does not specify which sections or parts of the paper these issues pertain to, making it weakly grounded. The comment is specific in detailing the issues, but without explicit references to sections, the authors may struggle to identify the exact parts needing attention. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises several concerns about the evaluation of the programs generated by CodeChain. It questions the alignment of the evaluation with human preference, the effectiveness of submodule generation, and the performance drop in selfrevise prompting. However, the comment lacks specific examples, detailed reasoning, or references to support these claims. Without additional context or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 2, as it provides some insight but lacks sufficient detail to be fully substantiated.", "helpfulness_rationale": "The review comment raises several important concerns about the evaluation of the programs generated by CodeChain. It questions the alignment of the evaluation with human preference, the effectiveness of submodule generation, and the performance drop in selfrevision prompting. However, the comment lacks specific suggestions or guidance on how the authors might address these issues or improve their evaluation. While it identifies areas for improvement, the feedback is vague and does not provide actionable steps for the authors to take. Therefore, the comment is 3, as it highlights potential weaknesses but does not offer detailed guidance for improvement."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review point explicitly suggests that the authors should report the improvement in object classification directly, in addition to the overall scene graph results. This feedback provides a clear and concrete action for the authors to take, as it specifies exactly what additional information should be included to support the claim made in the paper. The comment is specific and actionable, giving the authors a direct path to enhance their draft. Therefore, this comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"L107,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, namely the lack of results supporting the claim that the relational embedding module significantly improves object classification. The comment suggests reporting the improvement on object classification directly in addition to the overall scene graph results, providing a clear direction for the authors to enhance their paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the relational embedding module significantly improves object classification but lacks supporting evidence or results. The reviewer suggests that the paper would strengthen its case by reporting the improvement on object classification directly in addition to the overall scene graph results. While the comment identifies a gap in the paper, it does not provide specific examples or references to substantiate the claim. The suggestion for additional results is logical but lacks detailed guidance on how to implement it. Therefore, the comment is 3, as it provides a direction for improvement but lacks comprehensive evidence or detailed reasoning.", "helpfulness_rationale": "The review comment identifies a specific claim made in the paper regarding the improvement of object classification by the relational embedding module, but it lacks supporting evidence or results. The reviewer suggests that the paper would strengthen its case by reporting the improvement on object classification directly, in addition to the overall scene graph results. This feedback is clear and actionable, as it provides a concrete suggestion for the authors to enhance the credibility and impact of their paper. By addressing this feedback, the authors can improve the robustness of their claims and provide a more comprehensive analysis. Therefore, the comment is 4, aligning with a score of 4."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "1", "actionability_rationale": "The review point poses a question about the difficulty of finding intuitive attention examples, as mentioned in Figure 4. However, it does not provide any explicit or implicit actions for the authors to take. The comment lacks guidance on how the authors might address this issue or improve their work in this regard. Without any actionable suggestions or recommendations, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 4,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it questions the difficulty of finding intuitive attention examples, providing a clear direction for the authors to consider. This feedback highlights a specific area where the paper could be improved by providing more intuitive examples. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a question asking for clarification about the difficulty of finding intuitive attention examples as mentioned in Figure 4. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a request for clarification, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a question about the difficulty of finding intuitive attention examples, as mentioned in Figure 4. However, it does not provide any specific guidance or suggestions on how the authors might address this issue or improve their work in this area. The comment lacks actionable feedback, leaving the authors without a clear direction for improvement. As a result, it is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "5", "verifiability_label": "X", "helpfulness_label": "2", "actionability_rationale": "The review point poses a question about the difference between 01 and 10 in Figure 1. While it implies that the authors should clarify this difference, it does not explicitly instruct them to do so. The action is implicit, as the authors can infer that they need to provide a clearer explanation or clarification in their draft. However, the comment lacks concrete guidance on how to address the issue, such as suggesting specific ways to clarify the difference or what information should be included. Therefore, the comment is 3, as it identifies an area for improvement but does not provide detailed instructions on how to implement it.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Figure 1,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies what needs to be addressed, which is the difference between 01 and 10 in Figure 1. This provides clear guidance on what aspect of the figure requires clarification. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point is a request for clarification regarding the difference between 01 and 10 in Figure 1. It does not contain any subjective claims, opinions, or suggestions that require verification. It is purely a factual request for information, fitting the classification of \"No.\"", "helpfulness_rationale": "The review comment raises a specific question about the difference between 01 and 10 in Figure 1. While it identifies a potential area for clarification, it does not provide any actionable feedback or suggestions on how the authors might address this issue. The comment lacks depth and does not offer guidance on what the authors should do to improve their draft. As a result, it is 2, as it points out a potential issue but does not assist the authors in making improvements. Therefore, it aligns with a score of 2."}
{"actionability_label": null, "grounding_specificity_label": null, "verifiability_label": null, "helpfulness_label": null, "actionability_rationale": null, "grounding_specificity_rationale": null, "verifiability_rationale": null, "helpfulness_rationale": null}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the paper devotes significant space to describing the rules and data augmentation methods used in constructing the benchmark, but it suggests that the overall process and rationale for construction could be presented more clearly. While the comment implies that the authors should improve the clarity of their explanation, it does not provide specific guidance on how to achieve this. The action is implicit and somewhat vague, as the authors are left to infer that they need to enhance the clarity of their description of the benchmark construction process. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the paper\"s focus on describing the rules and data augmentation methods used in constructing the benchmark, suggesting that the overall process and rationale for construction could be presented more clearly. However, it does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in identifying the need for clearer presentation of the process and rationale, but without explicit references to sections or figures, the authors may struggle to pinpoint the exact areas needing improvement. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the paper devotes significant space to describing the rules and data augmentation methods used in constructing the benchmark, but it suggests that the overall process and rationale for construction could be presented more clearly. However, the comment does not provide specific examples or detailed reasoning to support the claim that the process and rationale are unclear. Without additional context or evidence, the authors may find it challenging to understand and address the issue. Therefore, the comment is considered 2, as it lacks sufficient justification or examples to fully substantiate the claim.", "helpfulness_rationale": "The review comment identifies a specific area for improvement by pointing out that the paper devotes significant space to describing the rules and data augmentation methods used in constructing the benchmark, but it suggests that the overall process and rationale for construction could be presented more clearly. This feedback is 3 as it highlights a potential weakness in the paper\"s presentation, prompting the authors to consider organizing their content more effectively. However, the comment could be more actionable if it provided specific suggestions on how to improve the clarity of the process and rationale. Overall, the comment offers some insight but lacks detailed guidance, making it 3."}
{"actionability_label": "3", "grounding_specificity_label": "4", "verifiability_label": "4", "helpfulness_label": "4", "actionability_rationale": "The review comment identifies a lack of literature review in the paper, specifically mentioning the absence of recent advances in active learning, particularly in Bayesian learning, such as Bayesian Coreset. It suggests that the paper should include a discussion on how the current setup is more advanced than related studies. The comment provides a clear action for the authors to take, which is to conduct a more comprehensive literature review, particularly focusing on Bayesian Coreset and related works. However, it does not provide specific guidance on which works to include or how to integrate this information into the paper. While the action is explicit, the lack of detailed instructions on execution makes the comment 3.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions the lack of literature review and the absence of recent advances in active learning, particularly in Bayesian learning, such as Bayesian Coreset. It also suggests discussing how the current setup is more advanced than related studies. This provides clear guidance on what needs to be addressed in the paper. However, the comment lacks specificity regarding which parts of the paper should be revised or expanded to include these literature reviews and discussions. Therefore, the comment is fully grounded but underspecific, aligning with a score of 4.", "verifiability_rationale": "The review point claims that the paper lacks a literature review of recent advances in active learning, particularly in Bayesian learning, such as Bayesian Coreset. It provides specific examples, like Bayesian Coreset, to support the claim, making it 4. However, the comment could be strengthened by providing more detailed references or examples of related works to fully substantiate the claim. Therefore, the comment is rated as 4.", "helpfulness_rationale": "The review comment identifies a significant gap in the paper\"s literature review, specifically pointing out the lack of discussion on recent advances in active learning, particularly in Bayesian learning. It highlights the relevance of Bayesian Coreset, which is directly relevant to the work, and suggests that the paper should include a discussion on this topic. Additionally, the comment notes that there have been multiple works discussing similar directions, such as combining uncertainty with Coreset, and suggests that the current setup might be more advanced than related studies. This feedback is clear and actionable, providing the authors with specific areas to expand upon in their literature review. However, it could be more helpful if it offered suggestions on how to integrate these discussions or provided examples of relevant works. Overall, the comment is 4, aligning with a score of 4."}
{"actionability_label": "1", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment points out that the \"onetomany relationship\" in Figure 2 makes it difficult to understand the presented trends and suggests that the plots contain a significant amount of noise. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how to address the issue of the \"onetomany relationship\" or how to reduce the noise in the plots. Without actionable advice or suggestions, the authors are left without a clear path forward. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Fig 2,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it clearly specifies the issue with the \"onetomany relationship\" in the plot and notes the presence of a considerable amount of noise. This provides clear guidance on what needs to be addressed in the figure. Therefore, the comment is 5, aligning with category 5.", "verifiability_rationale": "The review point claims that the \"onetomany relationship\" in Figure 2 makes it difficult to understand the presented trends and that the plots contain a significant amount of noise. However, the comment does not provide any specific examples, reasoning, or references to support these claims. Without detailed justification or evidence, the authors may find it challenging to understand and address the issues raised. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Figure 2, noting that the \"onetomany relationship\" makes it difficult to understand the presented trends and that the plots contain a significant amount of noise. This feedback is clear and actionable, as it highlights areas where the authors can improve the clarity and interpretability of their visualizations. However, the comment could be more helpful if it provided suggestions on how to address the noise or improve the clarity of the \"onetomany relationship.\" While it points out a critical area for improvement, it lacks depth and specific guidance, making it 3. Therefore, the comment aligns with a score of 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "3", "helpfulness_label": "3", "actionability_rationale": "The review comment raises concerns about the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that their lack of deep optimization might make the comparison unfair. It also questions whether DFSSATTEN supports training from scratch, which is a significant direction given the current popularity of pretraining. While the comment identifies areas for improvement, it does not provide explicit guidance on how to address these issues or what specific actions the authors should take to improve their draft. The feedback is 3 as it highlights potential areas for improvement but lacks concrete steps or suggestions for the authors to follow. Therefore, the comment is 3.", "grounding_specificity_rationale": "The comment addresses the speedup provided by DFSSATTEN, specifically mentioning the lowlevel optimization and hardware support as the primary contributors. It also compares this with existing algorithms like Performer and Reformer, suggesting that direct comparison might be unfair. Additionally, it questions whether DFSSATTEN supports training from scratch, which is a significant direction given the current focus on pretraining. While the comment provides specific details about the speedup and the comparison with existing algorithms, it does not explicitly mention which part of the paper this feedback pertains to, making it weakly grounded. However, the comment is specific in its critique and suggestions, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point claims that the speedup provided by DFSSATTEN is mostly due to lowlevel optimization and hardware support, and suggests that comparing it with existing algorithms like Performer and Reformer might be unfair. The reviewer also questions whether DFSSATTEN supports training from scratch, which is a significant direction in the current context of pretraining. While the comment provides some logical reasoning about the comparison and the importance of pretraining, it lacks specific examples or references to substantiate the claim that existing algorithms are not deeply optimized. This makes the claim 3, as the authors would need to further develop the argument with more detailed evidence or examples to fully understand and address the feedback. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment raises a valid concern about the fairness of comparing DFSSATTEN with existing algorithms like Performer and Reformer, suggesting that their lack of deep optimization might make the comparison unfair. It also questions whether DFSSATTEN supports training from scratch, which is a significant direction given the current focus on pretraining. While the comment identifies an important area for improvement, it lacks specific suggestions or guidance on how the authors might address these issues or what additional experiments or analyses could be conducted to strengthen the paper. The feedback is 3 as it highlights potential weaknesses and areas for improvement, but it could be more actionable with detailed suggestions or examples. Therefore, it aligns with a score of 3."}
{"actionability_label": "1", "grounding_specificity_label": "1", "verifiability_label": "1", "helpfulness_label": "1", "actionability_rationale": "The review point highlights a potential issue with the evaluation of the method VMISITIDIFDSM, specifically mentioning that it was examined on a blackbox setting. However, it does not provide any explicit or implicit actions for the authors to take. There is no guidance on how the authors should address this issue, such as suggesting alternative evaluation methods or providing additional context. Without any actionable steps or suggestions, the authors are left without a clear understanding of what needs to be done to improve their draft. Therefore, this comment is 1.", "grounding_specificity_rationale": "The comment refers to \"VMISITIDIFDSM,\" which is a specific method, but it does not specify which part of the paper this method is discussed in. This makes it difficult for the authors to pinpoint the exact section that needs attention. Additionally, the comment lacks specificity regarding what aspect of the evaluation on a blackbox setting is problematic or needs clarification. Without clear grounding and specificity, the authors cannot effectively address the feedback. Therefore, this comment is 1 and not specific, aligning with a score of 1.", "verifiability_rationale": "The review point claims that \"VMISITIDIFDSM was examined on a blackbox setting when their method was evaluated on defended model.\" However, the comment does not provide any supporting evidence, reasoning, or examples to substantiate this claim. Without additional context or explanation, the authors may find it challenging to understand the basis of the critique or how it impacts the paper. Therefore, the claim is considered 1.", "helpfulness_rationale": "The review comment points out a potential issue with the evaluation of the method VMISITIDIFDSM, specifically mentioning that it was examined on a blackbox setting. However, the comment lacks depth and does not provide any suggestions or guidance on how the authors might address this issue or improve their evaluation approach. Without actionable feedback or specific recommendations, the authors are left without a clear understanding of how to enhance their work. Therefore, the comment is 1, aligning with a score of 1."}
{"actionability_label": "3", "grounding_specificity_label": "2", "verifiability_label": "1", "helpfulness_label": "3", "actionability_rationale": "The review comment suggests that the clarity of the proposed method\"s description could be improved and advises the authors to refer to the questions section for details. While the action is explicit in suggesting that the authors should refer to the questions section, it does not provide specific guidance on what aspects of the description need clarification. The comment lacks concrete details on which parts of the description are unclear or how the questions section can help improve clarity. As a result, the authors are given an implicit action but without concrete instructions, making the comment 3.", "grounding_specificity_rationale": "The comment suggests that the clarity of the proposed method\"s description could be improved and advises the authors to refer to the questions section for details. However, it does not specify which part of the paper the description is unclear or where the questions section is located, making it difficult for the authors to pinpoint the exact areas needing improvement. The lack of specific guidance or detailed information about what aspects of the description need clarification makes the comment weakly grounded. It is also not specific in terms of what needs to be addressed. Therefore, this comment is 2, aligning with a score of 2.", "verifiability_rationale": "The review point suggests that the clarity of the proposed method\"s description could be improved, but it does not provide any specific examples, reasoning, or evidence to support this claim. The comment lacks detailed guidance or justification, making it difficult for the authors to understand the basis of the suggestion or how to address it. As a result, the claim is 1 due to the absence of supporting information or reasoning.", "helpfulness_rationale": "The review comment suggests that the clarity of the proposed method\"s description could be improved and advises the authors to refer to the questions section for details. While it identifies a potential area for enhancement, it lacks specificity and does not provide detailed guidance on what aspects of the description need clarification or how the questions section can assist in improving it. The feedback is 3 as it points out a potential improvement area, but it does not offer actionable steps or detailed suggestions for the authors to follow. Therefore, the comment aligns with a score of 3, indicating that it is 3."}
{"actionability_label": "3", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review point raises a question about the independence of pruning strategies across different layers in a Graph Neural Network (GNN). It suggests that if an edge is pruned in one layer, it might be pruned in other layers as well, and it asks whether such observations are made in the empirical evaluations or if the authors can explain why these correlations are not considered. While the comment implies that the authors should address this issue, it does not provide explicit instructions or concrete steps on how to do so. The action is implicit and somewhat vague, as the authors need to infer that they should investigate and explain the correlations between pruning strategies across layers. Therefore, this comment is 3.", "grounding_specificity_rationale": "The comment addresses the independence of pruning strategies across different layers in a Graph Neural Network (GNN), suggesting that if an edge is pruned in one layer, it might be pruned in other layers as well. It questions whether such observations are made in the empirical evaluations and asks for an explanation of why these correlations are not considered. However, the comment does not specify which part of the paper discusses the pruning strategy or where the empirical evaluations are conducted, making it weakly grounded. The comment is specific in its questioning and request for explanation, providing clear guidance on what needs to be addressed. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point questions the independence of pruning strategies across different layers in a Graph Neural Network (GNN) and suggests that if an edge is pruned in one layer, it might be pruned in other layers as well. The reviewer implies that this observation should be considered in the empirical evaluations but does not provide specific examples or references to support this claim. The lack of detailed evidence or references makes it difficult for the authors to understand and address the concern effectively. Therefore, the comment is considered 2, as it provides a logical reasoning but lacks sufficient support to be 5.", "helpfulness_rationale": "The review comment raises a relevant question about the independence of pruning strategies across different layers in a Graph Neural Network (GNN). It suggests that if an edge is pruned in one layer, it might be pruned in other layers as well, and it questions whether such observations are made in the empirical evaluations or if the authors can explain why these correlations are not considered. This feedback is 3 as it prompts the authors to consider the interdependencies between layers and to explore these relationships in their empirical evaluations. However, the comment could be more helpful if it provided specific guidance or suggestions on how to investigate or address these correlations. Overall, the comment offers a valuable insight but lacks detailed actionable advice, making it 3."}
{"actionability_label": "2", "grounding_specificity_label": "3", "verifiability_label": "2", "helpfulness_label": "3", "actionability_rationale": "The review comment raises a concern about the generalizability of the experimental results to other indistribution datasets, suggesting that the authors should consider whether their conclusions would hold for different datasets. However, it does not provide explicit guidance on how to address this issue or suggest specific steps for the authors to take. The comment implies that the authors should explore the generalizability of their results, but it lacks concrete instructions or examples on how to do so. As a result, the action is implicit and vague, making it barely actionable.", "grounding_specificity_rationale": "The comment addresses the experimental validation section, specifically mentioning the use of CIFAR10/100 as indistribution data. It raises a concern about the generalizability of the results to other indistribution datasets, suggesting that the authors should consider whether their conclusions would hold for different datasets. However, the comment does not specify which part of the paper this issue is discussed in, making it weakly grounded. The comment is specific in its request for consideration of generalizability, but without explicit references to sections or figures, the authors may find it challenging to pinpoint the exact area needing revision. Therefore, this comment is 3, aligning with category 3.", "verifiability_rationale": "The review point raises a concern about the generalizability of the experimental results to other indistribution datasets, suggesting that the authors should consider whether their conclusions would hold for different datasets. However, the comment does not provide specific examples, references, or detailed reasoning to support this claim. The lack of concrete evidence or examples makes it difficult for the authors to understand the basis of the concern and address it effectively. Therefore, the claim is considered 2, as it highlights a potential issue but lacks sufficient justification or evidence to fully substantiate the claim.", "helpfulness_rationale": "The review comment raises a concern about the generalizability of the experimental results to other indistribution datasets, suggesting that the authors should consider whether their conclusions would hold for different datasets. This feedback is 3 as it prompts the authors to think about the broader applicability of their findings, which is an important aspect of validating experimental results. However, the comment lacks specific guidance or suggestions on how to address this concern, such as recommending additional experiments or analyses to test generalizability. While it identifies a potential weakness, it does not provide actionable steps for improvement, making it 3 but incomplete."}
{"actionability_label": "5", "grounding_specificity_label": "5", "verifiability_label": "1", "helpfulness_label": "4", "actionability_rationale": "The review point suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alphadivergence to provide insights. This feedback is explicit, as it clearly states what the authors should do to improve their draft. The action is concrete because it specifies exactly what additional information should be included to address the concern. Therefore, the comment is 5.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Table 8,\" allowing the authors to accurately identify the part of the paper being addressed. It is also specific because it suggests a specific action to take, namely showing the gradient conflicts ratio for AlphaNets trained with alphadivergence. This provides clear guidance on what needs to be addressed in the table to improve the paper. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point suggests that the authors should show the gradient conflicts ratio for AlphaNets trained with alphadivergence to provide insights. However, the comment does not provide any supporting evidence, reasoning, or examples to justify why this is necessary or how it would improve the paper. Without additional context or explanation, the claim remains vague and difficult for the authors to address effectively. Therefore, the comment is considered 1.", "helpfulness_rationale": "The review comment identifies a specific issue with Table 8, noting that AlphaNets trained with alphadivergence do not benefit from the proposed method. It suggests that the authors should show the gradient conflicts ratio to provide insights. This feedback is clear and actionable, as it directs the authors to a specific area for improvement and offers a concrete suggestion for enhancing the analysis. By addressing this suggestion, the authors can provide a more comprehensive understanding of their method\"s effectiveness. Therefore, the comment is 4, as it offers a clear and actionable direction for improvement, but it could be more comprehensive with additional guidance on how to present the gradient conflicts ratio."}
{"actionability_label": "4", "grounding_specificity_label": "5", "verifiability_label": "3", "helpfulness_label": "4", "actionability_rationale": "The review comment raises a concern about the explicit SDF supervision in Section 3.2, specifically questioning why occlusion handling and viewawareness are included. The reviewer suggests that a simpler approach, such as sampling a subset of the sparse point cloud and applying the loss without occlusion reasoning, might be more straightforward. The comment implies that the current setup is unnecessarily complex and suggests that a good reason or ablation study is missing. While the action is implicit, it provides a clear direction for the authors to consider simplifying their approach and justifying the complexity of their current setup. Therefore, the comment is 4.", "grounding_specificity_rationale": "The comment is fully grounded as it explicitly mentions \"Section 3.2\" and specific lines (L. 165, L. 173, L. 177178), allowing the authors to accurately identify the parts of the paper being addressed. It is also specific because it clearly specifies the issue with the explicit SDF supervision, questioning the necessity of occlusion handling and viewawareness, and suggests a simpler approach. The comment further implies that a good reason or ablation study is missing, providing clear guidance on what needs to be addressed. Therefore, this comment is 5, aligning with category 5.", "verifiability_rationale": "The review point questions the necessity of occlusion handling and viewawareness in the explicit SDF supervision, suggesting that a simpler approach could be used. The reviewer provides a logical reasoning by comparing the current setup to a simpler method, implying that the complexity of the current approach is not justified. However, the comment lacks specific examples or references to support the claim that the current setup is unnecessarily complex. While the reasoning is logical, the absence of detailed evidence or references makes the claim 3. Therefore, the comment is rated as 3.", "helpfulness_rationale": "The review comment identifies a potential issue with the explicit SDF supervision in Section 3.2, specifically questioning the necessity of occlusion handling and viewawareness. It suggests that a simpler approach, such as sampling a subset of the sparse point cloud and applying the loss without occlusion reasoning, might be more straightforward. The comment implies that a good reason or ablation study is missing, which could help the authors justify the complexity of their current setup. While the comment highlights a potential weakness and provides a suggestion for improvement, it lacks specific guidance on how to conduct the ablation study or what specific aspects should be addressed. Therefore, the comment is 4, as it provides insight into an area for improvement but could be more comprehensive with additional details."}
